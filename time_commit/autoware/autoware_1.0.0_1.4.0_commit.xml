<?xml version="1.0" encoding="utf-8"?>
<Root>
	<commit hash="1cbd16fc089f6adf0cf281b4d6c8788f5983a99c" fix_time="0,0">
		<msg>Fix dependencies</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set.cpp">
				<diff>@@ -29,19 +29,8 @@
  */
 
 #include &lt;ros/ros.h&gt;
-#include &lt;geometry_msgs/TwistStamped.h&gt;
-#include &lt;geometry_msgs/PoseArray.h&gt;
-#include &lt;geometry_msgs/Point.h&gt;
-#include &lt;nav_msgs/Odometry.h&gt;
-#include &lt;visualization_msgs/Marker.h&gt;
 #include &lt;visualization_msgs/MarkerArray.h&gt;
-#include &lt;sensor_msgs/PointCloud2.h&gt;
 #include &lt;pcl_conversions/pcl_conversions.h&gt;
-#include &lt;pcl/io/io.h&gt;
-#include &lt;pcl/io/pcd_io.h&gt;
-#include &lt;pcl/point_types.h&gt;
-#include &lt;std_msgs/String.h&gt;
-#include &lt;std_msgs/Float32.h&gt;
 #include &lt;std_msgs/Int32.h&gt;
 #include &lt;runtime_manager/ConfigVelocitySet.h&gt;
 #include &lt;iostream&gt;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &lt;ros/ros.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/PoseArray.h&gt;
#include &lt;geometry_msgs/Point.h&gt;
#include &lt;nav_msgs/Odometry.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/io/io.h&gt;
#include &lt;pcl/io/pcd_io.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;std_msgs/Float32.h&gt;
#include &lt;std_msgs/Int32.h&gt;
#include &lt;runtime_manager/ConfigVelocitySet.h&gt;
#include &lt;iostream&gt;

#include &quot;waypoint_follower/libwaypoint_follower.h&quot;
#include &quot;libvelocity_set.h&quot;
#include &quot;velocity_set_path.h&quot;

namespace
{
const int LOOP_RATE = 10;

geometry_msgs::TwistStamped g_current_twist;
geometry_msgs::PoseStamped g_localizer_pose;  // pose of sensor
geometry_msgs::PoseStamped g_control_pose;  // pose of base_link
pcl::PointCloud&lt;pcl::PointXYZ&gt; g_points;

const std::string pedestrian_sound = &quot;pedestrian&quot;;
bool g_pose_flag = false;
bool g_path_flag = false;
bool g_points_flag = false;
int g_obstacle_waypoint = -1;
double g_deceleration_search_distance = 30;
double g_search_distance = 60;
double g_current_vel = 0.0;  // (m/s)
CrossWalk vmap;
ObstaclePoints g_obstacle;

// Config Parameter
double g_detection_range = 0;                   // if obstacle is in this range, stop
double g_deceleration_range = 1.8;              // if obstacle is in this range, decelerate
int g_threshold_points = 15;
double g_detection_height_top = 2.0;
double g_detection_height_bottom = -2.0;
double g_others_distance = 8.0;            // (meter) stopping distance from obstacles
double g_decel = 1.5;                      // (m/s^2) deceleration
double g_velocity_change_limit = 2.778;    // (m/s)
double g_temporal_waypoints_size = 100.0;  // (meter)

// Publisher
ros::Publisher g_range_pub;
ros::Publisher g_deceleration_range_pub;
ros::Publisher g_safety_waypoint_pub;
ros::Publisher g_temporal_waypoints_pub;
ros::Publisher g_crosswalk_points_pub;
ros::Publisher g_obstacle_pub;

WayPoints g_path_dk;
VelocitySetPath g_path_change;

void configCallback(const runtime_manager::ConfigVelocitySetConstPtr &amp;config)
{
  g_others_distance = config-&gt;others_distance;
  g_detection_range = config-&gt;detection_range;
  g_threshold_points = config-&gt;threshold_points;
  g_detection_height_top = config-&gt;detection_height_top;
  g_detection_height_bottom = config-&gt;detection_height_bottom;
  g_decel = config-&gt;deceleration;
  g_velocity_change_limit = kmph2mps(config-&gt;velocity_change_limit);
  g_deceleration_range = config-&gt;deceleration_range;
  g_temporal_waypoints_size = config-&gt;temporal_waypoints_size;
}

void currentVelCallback(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  g_current_vel = msg-&gt;twist.linear.x;
}

void baseWaypointCallback(const waypoint_follower::laneConstPtr &amp;msg)
{
  g_path_dk.setPath(*msg);
  g_path_change.setPath(*msg);
  if (g_path_flag == false)
  {
    g_path_flag = true;
  }
}

void pointsCallback(const sensor_msgs::PointCloud2ConstPtr &amp;msg)
{
  pcl::PointCloud&lt;pcl::PointXYZ&gt; sub_points;
  pcl::fromROSMsg(*msg, sub_points);

  // if x is less than this, we regard the point as our vehicle's one
  double ignore_range = 2.0;
  g_points.clear();
  for (const auto &amp;v : sub_points)
  {
    if (v.x == 0 &amp;&amp; v.y == 0)
      continue;
    if (v.z &gt; g_detection_height_top || v.z &lt; g_detection_height_bottom)
      continue;
    if (v.x &lt; ignore_range)
      continue;
    g_points.push_back(v);
  }

  if (g_points_flag == false)
  {
    g_points_flag = true;
  }
}

void controlCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  if (!g_pose_flag)
    g_pose_flag = true;

  g_control_pose.header = msg-&gt;header;
  g_control_pose.pose = msg-&gt;pose;
}

void localizerCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  g_localizer_pose.header = msg-&gt;header;
  g_localizer_pose.pose = msg-&gt;pose;
}

// Display a detected obstacle
void displayObstacle(const EControl &amp;kind)
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;/map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;my_namespace&quot;;
  marker.id = 0;
  marker.type = visualization_msgs::Marker::CUBE;
  marker.action = visualization_msgs::Marker::ADD;
  marker.pose.position = g_obstacle.getObstaclePoint(kind);
  if (kind == OTHERS)
    marker.pose.position = g_obstacle.getPreviousDetection();
  marker.pose.orientation = g_localizer_pose.pose.orientation;
  marker.scale.x = 1.0;
  marker.scale.y = 1.0;
  marker.scale.z = 2.0;
  marker.color.a = 0.7;
  if (kind == STOP)
  {
    marker.color.r = 1.0;
    marker.color.g = 0.0;
    marker.color.b = 0.0;
  }
  else
  {
    marker.color.r = 1.0;
    marker.color.g = 1.0;
    marker.color.b = 0.0;
  }
  marker.lifetime = ros::Duration(0.1);
  marker.frame_locked = true;

  //g_obstacle_pub.publish(marker);
}

void displayDetectionRange(const int &amp;crosswalk_id, const int &amp;num, const EControl &amp;kind)
{
  // set up for marker array
  visualization_msgs::MarkerArray marker_array;
  visualization_msgs::Marker crosswalk_marker;
  visualization_msgs::Marker waypoint_marker_stop;
  visualization_msgs::Marker waypoint_marker_decelerate;
  visualization_msgs::Marker stop_line;
  crosswalk_marker.header.frame_id = &quot;/map&quot;;
  crosswalk_marker.header.stamp = ros::Time();
  crosswalk_marker.id = 0;
  crosswalk_marker.type = visualization_msgs::Marker::SPHERE_LIST;
  crosswalk_marker.action = visualization_msgs::Marker::ADD;
  waypoint_marker_stop = crosswalk_marker;
  waypoint_marker_decelerate = crosswalk_marker;
  stop_line = crosswalk_marker;
  stop_line.type = visualization_msgs::Marker::CUBE;

  // set each namespace
  crosswalk_marker.ns = &quot;Crosswalk Detection&quot;;
  waypoint_marker_stop.ns = &quot;Stop Detection&quot;;
  waypoint_marker_decelerate.ns = &quot;Decelerate Detection&quot;;
  stop_line.ns = &quot;Stop Line&quot;;

  // set scale and color
  double scale = 2 * g_detection_range;
  waypoint_marker_stop.scale.x = scale;
  waypoint_marker_stop.scale.y = scale;
  waypoint_marker_stop.scale.z = scale;
  waypoint_marker_stop.color.a = 0.2;
  waypoint_marker_stop.color.r = 0.0;
  waypoint_marker_stop.color.g = 1.0;
  waypoint_marker_stop.color.b = 0.0;
  waypoint_marker_stop.frame_locked = true;

  scale = 2 * (g_detection_range + g_deceleration_range);
  waypoint_marker_decelerate.scale.x = scale;
  waypoint_marker_decelerate.scale.y = scale;
  waypoint_marker_decelerate.scale.z = scale;
  waypoint_marker_decelerate.color.a = 0.15;
  waypoint_marker_decelerate.color.r = 1.0;
  waypoint_marker_decelerate.color.g = 1.0;
  waypoint_marker_decelerate.color.b = 0.0;
  waypoint_marker_decelerate.frame_locked = true;

  if (g_obstacle_waypoint &gt; -1)
  {
    stop_line.pose.position = g_path_dk.getWaypointPosition(g_obstacle_waypoint);
    stop_line.pose.orientation = g_path_dk.getWaypointOrientation(g_obstacle_waypoint);
  }
  stop_line.pose.position.z += 1.0;
  stop_line.scale.x = 0.1;
  stop_line.scale.y = 15.0;
  stop_line.scale.z = 2.0;
  stop_line.color.a = 0.3;
  stop_line.color.r = 1.0;
  stop_line.color.g = 0.0;
  stop_line.color.b = 0.0;
  stop_line.lifetime = ros::Duration(0.1);
  stop_line.frame_locked = true;

  if (crosswalk_id &gt; 0)
    scale = vmap.getDetectionPoints(crosswalk_id).width;
  crosswalk_marker.scale.x = scale;
  crosswalk_marker.scale.y = scale;
  crosswalk_marker.scale.z = scale;
  crosswalk_marker.color.a = 0.5;
  crosswalk_marker.color.r = 0.0;
  crosswalk_marker.color.g = 1.0;
  crosswalk_marker.color.b = 0.0;
  crosswalk_marker.frame_locked = true;

  // set marker points coordinate
  for (int i = 0; i &lt; g_search_distance; i++)
  {
    if (num &lt; 0 || i + num &gt; g_path_dk.getSize() - 1)
      break;

    geometry_msgs::Point point;
    point = g_path_dk.getWaypointPosition(num + i);

    waypoint_marker_stop.points.push_back(point);

    if (i &gt; g_deceleration_search_distance)
      continue;
    waypoint_marker_decelerate.points.push_back(point);
  }

  if (crosswalk_id &gt; 0)
  {
    for (const auto &amp;p : vmap.getDetectionPoints(crosswalk_id).points)
      crosswalk_marker.points.push_back(p);
  }

  // publish marker
  marker_array.markers.push_back(crosswalk_marker);
  marker_array.markers.push_back(waypoint_marker_stop);
  marker_array.markers.push_back(waypoint_marker_decelerate);
  if (kind == STOP)
    marker_array.markers.push_back(stop_line);
  g_range_pub.publish(marker_array);
  marker_array.markers.clear();
}

// find the closest cross walk against following waypoints
int findCrossWalk(int closest_waypoint)
{
  if (!vmap.set_points || closest_waypoint &lt; 0)
    return -1;

  double find_distance = 2.0 * 2.0;      // meter
  double ignore_distance = 20.0 * 20.0;  // meter
  static std::vector&lt;int&gt; bdid = vmap.getBDID();
  // Find near cross walk
  for (int num = closest_waypoint; num &lt; closest_waypoint + g_search_distance; num++)
  {
    geometry_msgs::Point waypoint = g_path_dk.getWaypointPosition(num);
    waypoint.z = 0.0;  // ignore Z axis
    for (const auto &amp;i : bdid)
    {
      // ignore far crosswalk
      geometry_msgs::Point crosswalk_center = vmap.getDetectionPoints(i).center;
      crosswalk_center.z = 0.0;
      if (calcSquareOfLength(crosswalk_center, waypoint) &gt; ignore_distance)
        continue;

      for (auto p : vmap.getDetectionPoints(i).points)
      {
        p.z = waypoint.z;
        if (calcSquareOfLength(p, waypoint) &lt; find_distance)
        {
          vmap.setDetectionCrossWalkID(i);
          return num;
        }
      }
    }
  }

  vmap.setDetectionCrossWalkID(-1);
  return -1;  // no near crosswalk
}

// obstacle detection for crosswalk
EControl crossWalkDetection(const int &amp;crosswalk_id)
{
  double search_radius = vmap.getDetectionPoints(crosswalk_id).width / 2;

  // Search each calculated points in the crosswalk
  for (const auto &amp;p : vmap.getDetectionPoints(crosswalk_id).points)
  {
    geometry_msgs::Point detection_point = calcRelativeCoordinate(p, g_localizer_pose.pose);
    tf::Vector3 detection_vector = point2vector(detection_point);
    detection_vector.setZ(0.0);

    int stop_count = 0;  // the number of points in the detection area
    for (const auto &amp;vscan : g_points)
    {
      tf::Vector3 vscan_vector(vscan.x, vscan.y, 0.0);
      double distance = tf::tfDistance(vscan_vector, detection_vector);
      if (distance &lt; search_radius)
      {
        stop_count++;
        geometry_msgs::Point vscan_temp;
        vscan_temp.x = vscan.x;
        vscan_temp.y = vscan.y;
        vscan_temp.z = vscan.z;
	g_obstacle.setStopPoint(calcAbsoluteCoordinate(vscan_temp, g_localizer_pose.pose));
      }
      if (stop_count &gt; g_threshold_points)
        return STOP;
    }

    g_obstacle.clearStopPoints();
  }

  return KEEP;  // find no obstacles
}

// Detect an obstacle by using pointcloud
EControl vscanDetection(int closest_waypoint)
{
  if (g_points.empty() == true || closest_waypoint &lt; 0)
    return KEEP;

  int decelerate_or_stop = -10000;
  int decelerate2stop_waypoints = 15;

  for (int i = closest_waypoint; i &lt; closest_waypoint + g_search_distance; i++)
  {
    g_obstacle.clearStopPoints();
    if (!g_obstacle.isDecided())
      g_obstacle.clearDeceleratePoints();

    decelerate_or_stop++;
    if (decelerate_or_stop &gt; decelerate2stop_waypoints || (decelerate_or_stop &gt;= 0 &amp;&amp; i &gt;= g_path_dk.getSize() - 1) ||
        (decelerate_or_stop &gt;= 0 &amp;&amp; i == closest_waypoint + g_search_distance - 1))
      return DECELERATE;
    if (i &gt; g_path_dk.getSize() - 1)
      return KEEP;

    // Detection for cross walk
    if (i == vmap.getDetectionWaypoint())
    {
      if (crossWalkDetection(vmap.getDetectionCrossWalkID()) == STOP)
      {
        g_obstacle_waypoint = i;
        return STOP;
      }
    }

    // waypoint seen by vehicle
    geometry_msgs::Point waypoint = calcRelativeCoordinate(g_path_dk.getWaypointPosition(i), g_localizer_pose.pose);
    tf::Vector3 tf_waypoint = point2vector(waypoint);
    tf_waypoint.setZ(0);

    int stop_point_count = 0;
    int decelerate_point_count = 0;
    for (pcl::PointCloud&lt;pcl::PointXYZ&gt;::const_iterator item = g_points.begin(); item != g_points.end(); item++)
    {
      tf::Vector3 vscan_vector((double)item-&gt;x, (double)item-&gt;y, 0);

      // 2D distance between waypoint and vscan points(obstacle)
      // ---STOP OBSTACLE DETECTION---
      double dt = tf::tfDistance(vscan_vector, tf_waypoint);
      if (dt &lt; g_detection_range)
      {
        stop_point_count++;
        geometry_msgs::Point vscan_temp;
        vscan_temp.x = item-&gt;x;
        vscan_temp.y = item-&gt;y;
        vscan_temp.z = item-&gt;z;
	g_obstacle.setStopPoint(calcAbsoluteCoordinate(vscan_temp, g_localizer_pose.pose));
      }
      if (stop_point_count &gt; g_threshold_points)
      {
        g_obstacle_waypoint = i;
        return STOP;
      }

      // without deceleration range
      if (g_deceleration_range &lt; 0.01)
        continue;
      // deceleration search runs &quot;decelerate_search_distance&quot; waypoints from closest
      if (i &gt; closest_waypoint + g_deceleration_search_distance || decelerate_or_stop &gt;= 0)
        continue;

      // ---DECELERATE OBSTACLE DETECTION---
      if (dt &gt; g_detection_range &amp;&amp; dt &lt; g_detection_range + g_deceleration_range)
      {
        bool count_flag = true;

        // search overlaps between DETECTION range and DECELERATION range
        for (int waypoint_search = -5; waypoint_search &lt;= 5; waypoint_search++)
        {
          if (i + waypoint_search &lt; 0 || i + waypoint_search &gt;= g_path_dk.getSize() || !waypoint_search)
            continue;
          geometry_msgs::Point temp_waypoint =
              calcRelativeCoordinate(g_path_dk.getWaypointPosition(i + waypoint_search), g_localizer_pose.pose);
          tf::Vector3 waypoint_vector = point2vector(temp_waypoint);
          waypoint_vector.setZ(0);
          // if there is a overlap, give priority to DETECTION range
          if (tf::tfDistance(vscan_vector, waypoint_vector) &lt; g_detection_range)
          {
            count_flag = false;
            break;
          }
        }
        if (count_flag)
        {
          decelerate_point_count++;
          geometry_msgs::Point vscan_temp;
          vscan_temp.x = item-&gt;x;
          vscan_temp.y = item-&gt;y;
          vscan_temp.z = item-&gt;z;
	  g_obstacle.setDeceleratePoint(calcAbsoluteCoordinate(vscan_temp, g_localizer_pose.pose));
        }
      }

      // found obstacle to DECELERATE
      if (decelerate_point_count &gt; g_threshold_points)
      {
        g_obstacle_waypoint = i;
        decelerate_or_stop = 0;  // for searching near STOP obstacle
        g_obstacle.setDecided(true);
      }
    }
  }

  return KEEP;  // no obstacles
}

EControl obstacleDetection(int closest_waypoint)
{
  static int false_count = 0;
  static EControl prev_detection = KEEP;

  EControl vscan_result = vscanDetection(closest_waypoint);
  displayDetectionRange(vmap.getDetectionCrossWalkID(), closest_waypoint, vscan_result);

  if (prev_detection == KEEP)
  {
    if (vscan_result != KEEP)
    {  // found obstacle
      displayObstacle(vscan_result);
      prev_detection = vscan_result;
      // SoundPlay();
      false_count = 0;
      return vscan_result;
    }
    else
    {  // no obstacle
      prev_detection = KEEP;
      return vscan_result;
    }
  }
  else
  {  // prev_detection = STOP or DECELERATE
    if (vscan_result != KEEP)
    {  // found obstacle
      displayObstacle(vscan_result);
      prev_detection = vscan_result;
      false_count = 0;
      return vscan_result;
    }
    else
    {  // no obstacle
      false_count++;

      // fail-safe
      if (false_count &gt;= LOOP_RATE / 2)
      {
        g_obstacle_waypoint = -1;
        false_count = 0;
        prev_detection = KEEP;
        return vscan_result;
      }
      else
      {
        displayObstacle(OTHERS);
        return prev_detection;
      }
    }
  }
}

void changeWaypoint(EControl detection_result, int closest_waypoint)
{
  int obs = g_obstacle_waypoint;

  if (detection_result == STOP)
  {  // STOP for obstacle
    // stop_waypoint is about g_others_distance meter away from obstacles
    int stop_waypoint = obs - ((int)(g_others_distance / g_path_change.getInterval()));
    // change waypoints to stop by the stop_waypoint
    g_path_change.changeWaypoints(stop_waypoint, closest_waypoint, g_decel, g_path_dk);
    g_path_change.avoidSuddenBraking(g_velocity_change_limit, g_current_vel, g_decel, closest_waypoint);
    g_path_change.setTemporalWaypoints(g_temporal_waypoints_size, closest_waypoint, g_control_pose);
    g_temporal_waypoints_pub.publish(g_path_change.getTemporalWaypoints());
  }
  else if (detection_result == DECELERATE)
  {  // DECELERATE for obstacles
    g_path_change.setPath(g_path_dk.getCurrentWaypoints());
    g_path_change.setDeceleration(g_current_vel, g_decel, closest_waypoint);
    g_path_change.setTemporalWaypoints(g_temporal_waypoints_size, closest_waypoint, g_control_pose);
    g_temporal_waypoints_pub.publish(g_path_change.getTemporalWaypoints());
  }
  else
  {  // ACELERATE or KEEP
    g_path_change.setPath(g_path_dk.getCurrentWaypoints());
    g_path_change.avoidSuddenAceleration(g_current_vel, g_decel, closest_waypoint);
    g_path_change.avoidSuddenBraking(g_velocity_change_limit, g_current_vel, g_decel, closest_waypoint);
    g_path_change.setTemporalWaypoints(g_temporal_waypoints_size, closest_waypoint, g_control_pose);
    g_temporal_waypoints_pub.publish(g_path_change.getTemporalWaypoints());
  }

  return;
}

} // end namespace


int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;velocity_set&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  bool use_crosswalk_detection;
  std::string points_topic;
  private_nh.param&lt;bool&gt;(&quot;use_crosswalk_detection&quot;, use_crosswalk_detection, true);
  private_nh.param&lt;std::string&gt;(&quot;points_topic&quot;, points_topic, &quot;points_lanes&quot;);

  ros::Subscriber localizer_sub = nh.subscribe(&quot;localizer_pose&quot;, 1, localizerCallback);
  ros::Subscriber control_pose_sub = nh.subscribe(&quot;current_pose&quot;, 1, controlCallback);
  ros::Subscriber points_sub = nh.subscribe(points_topic, 1, pointsCallback);
  ros::Subscriber base_waypoint_sub = nh.subscribe(&quot;base_waypoints&quot;, 1, baseWaypointCallback);
  ros::Subscriber current_vel_sub = nh.subscribe(&quot;current_velocity&quot;, 1, currentVelCallback);
  ros::Subscriber config_sub = nh.subscribe(&quot;config/velocity_set&quot;, 10, configCallback);

  // vector map subscribers
  ros::Subscriber sub_dtlane = nh.subscribe(&quot;vector_map_info/cross_walk&quot;, 1, &amp;CrossWalk::crossWalkCallback, &amp;vmap);
  ros::Subscriber sub_area = nh.subscribe(&quot;vector_map_info/area&quot;, 1, &amp;CrossWalk::areaCallback, &amp;vmap);
  ros::Subscriber sub_line = nh.subscribe(&quot;vector_map_info/line&quot;, 1, &amp;CrossWalk::lineCallback, &amp;vmap);
  ros::Subscriber sub_point = nh.subscribe(&quot;vector_map_info/point&quot;, 1, &amp;CrossWalk::pointCallback, &amp;vmap);

  g_range_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;detection_range&quot;, 0);
  g_temporal_waypoints_pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;temporal_waypoints&quot;, 1000, true);
  ros::Publisher closest_waypoint_pub;
  closest_waypoint_pub = nh.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 1000);
  g_obstacle_pub = nh.advertise&lt;visualization_msgs::Marker&gt;(&quot;obstacle&quot;, 0);

  ros::Rate loop_rate(LOOP_RATE);
  while (ros::ok())
  {
    ros::spinOnce();

    if (vmap.loaded_all &amp;&amp; !vmap.set_points)
      vmap.setCrossWalkPoints();

    if (g_pose_flag == false || g_path_flag == false)
    {
      loop_rate.sleep();
      continue;
    }

    int closest_waypoint = getClosestWaypoint(g_path_change.getCurrentWaypoints(), g_control_pose.pose);

    std_msgs::Int32 closest_waypoint_msg;
    closest_waypoint_msg.data = closest_waypoint;
    closest_waypoint_pub.publish(closest_waypoint_msg);

    if (use_crosswalk_detection)
      vmap.setDetectionWaypoint(findCrossWalk(closest_waypoint));

    EControl detection_result = obstacleDetection(closest_waypoint);

    changeWaypoint(detection_result, closest_waypoint);

    g_points.clear();

    loop_rate.sleep();
  }

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="a9ae2631280dbb924087042a2797175d45d50de6" fix_time="76,42915">
		<msg>Fixes</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/Cluster.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/Cluster.cpp">
				<diff>@@ -197,7 +197,7 @@ void Cluster::SetCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_origin_cloud
 		}
 		double slope= (current_cluster-&gt;points.size()*sum_xy - (sum_x*sum_y))/(current_cluster-&gt;points.size()*sum_xx - sum_x*sum_x);
 
-		rz = atan(slope);
+		rz = atan(-slope);
 	}
 
 	//set bounding box direction
</diff>
				<old_file>/*
 * Cluster.cpp
 *
 *  Created on: Oct 19, 2016
 *      Author: Ne0
 */

#include &quot;Cluster.h&quot;

Cluster::Cluster()
{

}

jsk_recognition_msgs::BoundingBox Cluster::GetBoundingBox()
{
	return bounding_box_;
}

pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr Cluster::GetCloud()
{
	return pointcloud_;
}

pcl::PointXYZ Cluster::GetMinPoint()
{
	return min_point_;
}

pcl::PointXYZ Cluster::GetMaxPoint()
{
	return max_point_;
}

pcl::PointXYZ Cluster::GetCentroid()
{
	return centroid_;
}

pcl::PointXYZ Cluster::GetAveragePoint()
{
	return average_point_;
}

double Cluster::GetOrientationAngle()
{
	return orientation_angle_;
}

Eigen::Matrix3f Cluster::GetEigenVectors()
{
	return eigen_vectors_;
}

Eigen::Vector3f Cluster::GetEigenValues()
{
	return eigen_values_;
}

void Cluster::ToRosMessage(std_msgs::Header in_ros_header, lidar_tracker::CloudCluster&amp; out_cluster_message)
{
	sensor_msgs::PointCloud2 cloud_msg;

	pcl::toROSMsg(*(this-&gt;GetCloud()), cloud_msg);
	cloud_msg.header=in_ros_header;

	out_cluster_message.header = in_ros_header;

	out_cluster_message.cloud = cloud_msg;
	out_cluster_message.min_point.header = in_ros_header;
	out_cluster_message.min_point.point.x = this-&gt;GetMinPoint().x;
	out_cluster_message.min_point.point.y = this-&gt;GetMinPoint().y;
	out_cluster_message.min_point.point.z = this-&gt;GetMinPoint().z;

	out_cluster_message.max_point.header = in_ros_header;
	out_cluster_message.max_point.point.x = this-&gt;GetMaxPoint().x;
	out_cluster_message.max_point.point.y = this-&gt;GetMaxPoint().y;
	out_cluster_message.max_point.point.z = this-&gt;GetMaxPoint().z;

	out_cluster_message.avg_point.header = in_ros_header;
	out_cluster_message.avg_point.point.x = this-&gt;GetAveragePoint().x;
	out_cluster_message.avg_point.point.y = this-&gt;GetAveragePoint().y;
	out_cluster_message.avg_point.point.z = this-&gt;GetAveragePoint().z;

	out_cluster_message.centroid_point.header = in_ros_header;
	out_cluster_message.centroid_point.point.x = this-&gt;GetCentroid().x;
	out_cluster_message.centroid_point.point.y = this-&gt;GetCentroid().y;
	out_cluster_message.centroid_point.point.z = this-&gt;GetCentroid().z;

	out_cluster_message.estimated_angle = this-&gt;GetOrientationAngle();

	out_cluster_message.dimensions = this-&gt;GetBoundingBox().dimensions;

	out_cluster_message.bounding_box = this-&gt;GetBoundingBox();

	Eigen::Vector3f eigen_values = this-&gt;GetEigenValues();
	out_cluster_message.eigen_values.x = eigen_values.x();
	out_cluster_message.eigen_values.y = eigen_values.y();
	out_cluster_message.eigen_values.z = eigen_values.z();

	Eigen::Matrix3f eigen_vectors = this-&gt;GetEigenVectors();
	for (unsigned int i=0; i &lt; 3 ; i++)
	{
		geometry_msgs::Vector3 eigen_vector;
		eigen_vector.x = eigen_vectors(i, 0);
		eigen_vector.y = eigen_vectors(i, 1);
		eigen_vector.z = eigen_vectors(i, 2);
		out_cluster_message.eigen_vectors.push_back(eigen_vector);
	}

	std::vector&lt;float&gt; fpfh_descriptor = GetFpfhDescriptor(8, 0.3, 0.3);
	out_cluster_message.fpfh_descriptor.data = fpfh_descriptor;
}

void Cluster::SetCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_origin_cloud_ptr, const std::vector&lt;int&gt;&amp; in_cluster_indices, std_msgs::Header in_ros_header, int in_id, int in_r, int in_g, int in_b, std::string in_label, bool in_estimate_pose)
{
	label_ 	= in_label;	id_		= in_id;
	r_		= in_r;	g_		= in_g;	b_		= in_b;
	//extract pointcloud using the indices
	//calculate min and max points
	pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr current_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);
	float min_x=std::numeric_limits&lt;float&gt;::max();float max_x=-std::numeric_limits&lt;float&gt;::max();
	float min_y=std::numeric_limits&lt;float&gt;::max();float max_y=-std::numeric_limits&lt;float&gt;::max();
	float min_z=std::numeric_limits&lt;float&gt;::max();float max_z=-std::numeric_limits&lt;float&gt;::max();
	float average_x = 0, average_y = 0, average_z = 0;

	for (auto pit = in_cluster_indices.begin(); pit != in_cluster_indices.end(); ++pit)
	{
		//fill new colored cluster point by point
		pcl::PointXYZRGB p;
		p.x = in_origin_cloud_ptr-&gt;points[*pit].x;
		p.y = in_origin_cloud_ptr-&gt;points[*pit].y;
		p.z = in_origin_cloud_ptr-&gt;points[*pit].z;
		p.r = in_r;
		p.g = in_g;
		p.b = in_b;

		average_x+=p.x;		average_y+=p.y;		average_z+=p.z;
		centroid_.x += p.x; centroid_.y += p.y;	centroid_.z += p.z;
		current_cluster-&gt;points.push_back(p);

		if(p.x&lt;min_x)	min_x = p.x;
		if(p.y&lt;min_y)	min_y = p.y;
		if(p.z&lt;min_z)	min_z = p.z;
		if(p.x&gt;max_x)	max_x = p.x;
		if(p.y&gt;max_y)	max_y = p.y;
		if(p.z&gt;max_z)	max_z = p.z;
	}
	//min, max points
	min_point_.x = min_x;	min_point_.y = min_y;	min_point_.z = min_z;
	max_point_.x = max_x;	max_point_.y = max_y;	max_point_.z = max_z;

	//calculate centroid, average
	if (in_cluster_indices.size() &gt; 0)
	{
		centroid_.x /= in_cluster_indices.size();
		centroid_.y /= in_cluster_indices.size();
		centroid_.z /= in_cluster_indices.size();

		average_x /= in_cluster_indices.size();
		average_y /= in_cluster_indices.size();
		average_z /= in_cluster_indices.size();
	}

	average_point_.x = average_x; average_point_.y = average_y;	average_point_.z = average_z;

	//calculate bounding box
	length_ = max_point_.x - min_point_.x;
	width_ = max_point_.y - min_point_.y;
	height_ = max_point_.z - min_point_.z;

	bounding_box_.header = in_ros_header;

	bounding_box_.pose.position.x = min_point_.x + length_/2;
	bounding_box_.pose.position.y = min_point_.y + width_/2;
	bounding_box_.pose.position.z = min_point_.z + height_/2;

	bounding_box_.dimensions.x = ((length_&lt;0)?-1*length_:length_);
	bounding_box_.dimensions.y = ((width_&lt;0)?-1*width_:width_);
	bounding_box_.dimensions.z = ((height_&lt;0)?-1*height_:height_);

	//pose estimation
	double rz = 0;

	if (in_estimate_pose)
	{
		//pose estimation for the cluster
		//test using linear regression
		//Slope(b) = (NΣXY - (ΣX)(ΣY)) / (NΣX2 - (ΣX)2)
		float sum_x=0, sum_y=0, sum_xy=0, sum_xx=0;
		for (unsigned int i=0; i&lt;current_cluster-&gt;points.size(); i++)
		{
			sum_x+= current_cluster-&gt;points[i].x;
			sum_y+= current_cluster-&gt;points[i].y;
			sum_xy+= current_cluster-&gt;points[i].x*current_cluster-&gt;points[i].y;
			sum_xx+= current_cluster-&gt;points[i].x*current_cluster-&gt;points[i].x;
		}
		double slope= (current_cluster-&gt;points.size()*sum_xy - (sum_x*sum_y))/(current_cluster-&gt;points.size()*sum_xx - sum_x*sum_x);

		rz = atan(slope);
	}

	//set bounding box direction
	tf::Quaternion quat = tf::createQuaternionFromRPY(0.0, 0.0, rz);
	tf::quaternionTFToMsg(quat, bounding_box_.pose.orientation);

	current_cluster-&gt;width = current_cluster-&gt;points.size();
	current_cluster-&gt;height = 1;
	current_cluster-&gt;is_dense = true;

	//Get EigenValues, eigenvectors
	if (current_cluster-&gt;points.size() &gt; 0)
	{
		pcl::PCA&lt;pcl::PointXYZ&gt; current_cluster_pca;
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr current_cluster_mono (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);

		pcl::copyPointCloud&lt;pcl::PointXYZRGB, pcl::PointXYZ&gt;(*current_cluster, *current_cluster_mono);

		current_cluster_pca.setInputCloud(current_cluster_mono);
		eigen_vectors_ = current_cluster_pca.getEigenVectors();
		eigen_values_ = current_cluster_pca.getEigenValues();
	}

	valid_cluster_ = true;
	pointcloud_ = current_cluster;
}

std::vector&lt;float&gt; Cluster::GetFpfhDescriptor(const unsigned int&amp; in_ompnum_threads, const double&amp; in_normal_search_radius, const double&amp; in_fpfh_search_radius)
{
	std::vector&lt;float&gt; cluster_fpfh_histogram(33,0.0);

	pcl::search::KdTree&lt;pcl::PointXYZRGB&gt;::Ptr norm_tree (new pcl::search::KdTree&lt;pcl::PointXYZRGB&gt;);
	if (pointcloud_-&gt;points.size() &gt; 0)
		norm_tree-&gt;setInputCloud(pointcloud_);

	pcl::PointCloud&lt;pcl::Normal&gt;::Ptr normals (new pcl::PointCloud&lt;pcl::Normal&gt;);
	pcl::NormalEstimationOMP&lt;pcl::PointXYZRGB, pcl::Normal&gt; normal_estimation;
	normal_estimation.setNumberOfThreads(in_ompnum_threads);
	normal_estimation.setInputCloud (pointcloud_);
	normal_estimation.setSearchMethod (norm_tree);
	normal_estimation.setViewPoint (std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max (),std::numeric_limits&lt;float&gt;::max ());
	normal_estimation.setRadiusSearch (in_normal_search_radius);
	normal_estimation.compute (*normals);

	pcl::PointCloud&lt;pcl::FPFHSignature33&gt;::Ptr fpfh_histograms (new pcl::PointCloud&lt;pcl::FPFHSignature33&gt; ());

	pcl::FPFHEstimationOMP&lt;pcl::PointXYZRGB, pcl::Normal, pcl::FPFHSignature33&gt; fpfh;
	fpfh.setNumberOfThreads(in_ompnum_threads);
	fpfh.setInputCloud(pointcloud_);
	fpfh.setInputNormals(normals);
	fpfh.setSearchMethod(norm_tree);
	fpfh.setRadiusSearch(in_fpfh_search_radius);
	fpfh.compute(*fpfh_histograms);

	float fpfh_max = std::numeric_limits&lt;float&gt;::min();
	float fpfh_min = std::numeric_limits&lt;float&gt;::max();

	for (unsigned int i=0; i&lt;fpfh_histograms-&gt;size(); i++) //for each point fpfh
	{
		for(unsigned int j=0; j&lt; cluster_fpfh_histogram.size(); j++)//sum each histogram's bin for all points, get min/max
		{
			cluster_fpfh_histogram[j]= cluster_fpfh_histogram[j] + fpfh_histograms-&gt;points[i].histogram[j];
			if(cluster_fpfh_histogram[j] &lt; fpfh_min)
				fpfh_min = cluster_fpfh_histogram[j];
			if(cluster_fpfh_histogram[j] &gt; fpfh_max)
				fpfh_max = cluster_fpfh_histogram[j];
		}

		float fpfh_dif = fpfh_max - fpfh_min;
		for(unsigned int j=0; fpfh_dif &gt; 0, j &lt; cluster_fpfh_histogram.size(); j++)//substract the min from each and normalize
		{
			cluster_fpfh_histogram[j]= (cluster_fpfh_histogram[j] - fpfh_min)/fpfh_dif;
		}
	}

	return cluster_fpfh_histogram;
}

bool Cluster::IsValid()
{
	return valid_cluster_;
}

void Cluster::SetValidity(bool in_valid)
{
	valid_cluster_ = in_valid;
}

Cluster::~Cluster() {
	// TODO Auto-generated destructor stub
}

</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp">
				<diff>@@ -452,7 +452,6 @@ void segmentByDistance(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
 		if (	all_clusters[i]-&gt;IsValid() &amp;&amp;
 				bounding_box.dimensions.x &gt;0 &amp;&amp; bounding_box.dimensions.y &gt;0 &amp;&amp; bounding_box.dimensions.z &gt; 0 &amp;&amp;
 				bounding_box.dimensions.x &lt; _max_boundingbox_side &amp;&amp; bounding_box.dimensions.y &lt; _max_boundingbox_side
-				&amp;&amp;max_point.z &gt; -1.5 &amp;&amp; min_point.z &gt; -1.5 &amp;&amp; min_point.z &lt; 1.0
 				)
 		{
 			in_out_boundingbox_array.boxes.push_back(bounding_box);
@@ -466,7 +465,7 @@ void segmentByDistance(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
 	}
 }
 
-void removeFloor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_nofloor_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_onlyfloor_cloud_ptr, float in_max_height=0.2, float in_floor_max_angle=0.35)
+void removeFloor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_nofloor_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_onlyfloor_cloud_ptr, float in_max_height=0.2, float in_floor_max_angle=0.1)
 {
 	/*pcl::PointIndicesPtr ground (new pcl::PointIndices);
 	// Create the filtering object
@@ -643,7 +642,6 @@ void velodyne_callback(const sensor_msgs::PointCloud2ConstPtr&amp; in_sensor_cloud)
 
 		_velodyne_header = in_sensor_cloud-&gt;header;
 
-
 		cv::TickMeter timer;
 
 		timer.reset();timer.start();
@@ -655,20 +653,25 @@ void velodyne_callback(const sensor_msgs::PointCloud2ConstPtr&amp; in_sensor_cloud)
 		else
 			removed_points_cloud_ptr = current_sensor_cloud_ptr;
 
+		//std::cout &lt;&lt; &quot;Downsample before: &quot; &lt;&lt;removed_points_cloud_ptr-&gt;points.size();
 		if (_downsample_cloud)
 			downsampleCloud(removed_points_cloud_ptr, downsampled_cloud_ptr, _leaf_size);
 		else
-			downsampled_cloud_ptr=current_sensor_cloud_ptr;
-		timer.stop(); //std::cout &lt;&lt; &quot;downsampleCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
+			downsampled_cloud_ptr =removed_points_cloud_ptr;
+
+		//std::cout &lt;&lt; &quot; after: &quot; &lt;&lt;downsampled_cloud_ptr-&gt;points.size();
+		timer.stop(); std::cout &lt;&lt; &quot;downsampleCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
 
-		downsampled_cloud_ptr=removed_points_cloud_ptr;
+		timer.reset();timer.start();
+		clipCloud(downsampled_cloud_ptr, clipped_cloud_ptr, _clip_min_height, _clip_max_height);
+		timer.stop(); std::cout &lt;&lt; &quot;clipCloud:&quot; &lt;&lt; clipped_cloud_ptr-&gt;points.size() &lt;&lt; &quot;time &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
 
 		timer.reset();timer.start();
 		if(_keep_lanes)
-			keepLanePoints(downsampled_cloud_ptr, inlanes_cloud_ptr, _keep_lane_left_distance, _keep_lane_right_distance);
+			keepLanePoints(clipped_cloud_ptr, inlanes_cloud_ptr, _keep_lane_left_distance, _keep_lane_right_distance);
 		else
-			inlanes_cloud_ptr = downsampled_cloud_ptr;
-		timer.stop(); //std::cout &lt;&lt; &quot;keepLanePoints:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
+			inlanes_cloud_ptr = clipped_cloud_ptr;
+		timer.stop(); std::cout &lt;&lt; &quot;keepLanePoints:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
 
 		timer.reset();timer.start();
 		if(_remove_ground)
@@ -678,38 +681,35 @@ void velodyne_callback(const sensor_msgs::PointCloud2ConstPtr&amp; in_sensor_cloud)
 		}
 		else
 			nofloor_cloud_ptr = inlanes_cloud_ptr;
-		timer.stop(); //std::cout &lt;&lt; &quot;removeFloor:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
+		timer.stop(); std::cout &lt;&lt; &quot;removeFloor:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
 
-		timer.reset();timer.start();
-		clipCloud(nofloor_cloud_ptr, clipped_cloud_ptr, _clip_min_height, _clip_max_height);
-		publishCloud(&amp;_pub_points_lanes_cloud, clipped_cloud_ptr);
-		timer.stop(); //std::cout &lt;&lt; &quot;clipCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
+		publishCloud(&amp;_pub_points_lanes_cloud, nofloor_cloud_ptr);
 
 		timer.reset();timer.start();
 		if (_use_diffnormals)
-			differenceNormalsSegmentation(clipped_cloud_ptr, diffnormals_cloud_ptr);
+			differenceNormalsSegmentation(nofloor_cloud_ptr, diffnormals_cloud_ptr);
 		else
-			diffnormals_cloud_ptr = clipped_cloud_ptr;
-		timer.stop(); //std::cout &lt;&lt; &quot;differenceNormalsSegmentation:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
+			diffnormals_cloud_ptr = nofloor_cloud_ptr;
+		timer.stop(); std::cout &lt;&lt; &quot;differenceNormalsSegmentation:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
 
 		timer.reset();timer.start();
 		segmentByDistance(diffnormals_cloud_ptr, colored_clustered_cloud_ptr, boundingbox_array, centroids, cloud_clusters);
-		timer.stop(); //std::cout &lt;&lt; &quot;segmentByDistance:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
+		timer.stop(); std::cout &lt;&lt; &quot;segmentByDistance:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
 
 		timer.reset();timer.start();
 		publishColorCloud(&amp;_pub_cluster_cloud, colored_clustered_cloud_ptr);
-		timer.stop(); //std::cout &lt;&lt; &quot;publishColorCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
+		timer.stop(); std::cout &lt;&lt; &quot;publishColorCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
 		// Publish BB
 		boundingbox_array.header = _velodyne_header;
 
 		timer.reset();timer.start();
 		publishBoundingBoxArray(&amp;_pub_jsk_boundingboxes, boundingbox_array, _output_frame, _velodyne_header);
 		centroids.header = _velodyne_header;
-		timer.stop(); //std::cout &lt;&lt; &quot;publishBoundingBoxArray:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
+		timer.stop(); std::cout &lt;&lt; &quot;publishBoundingBoxArray:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
 
 		timer.reset();timer.start();
 		publishCentroids(&amp;_centroid_pub, centroids, _output_frame, _velodyne_header);
-		timer.stop(); //std::cout &lt;&lt; &quot;publishCentroids:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
+		timer.stop(); std::cout &lt;&lt; &quot;publishCentroids:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
 
 		_marker_pub.publish(_visualization_marker);
 		_visualization_marker.points.clear();//transform? is it used?
@@ -717,7 +717,7 @@ void velodyne_callback(const sensor_msgs::PointCloud2ConstPtr&amp; in_sensor_cloud)
 
 		timer.reset();timer.start();
 		publishCloudClusters(&amp;_pub_clusters_message, cloud_clusters, _output_frame, _velodyne_header);
-		timer.stop(); //std::cout &lt;&lt; &quot;publishCloudClusters:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl &lt;&lt; std::endl;
+		timer.stop(); std::cout &lt;&lt; &quot;publishCloudClusters:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl &lt;&lt; std::endl;
 
 		_using_sensor_cloud = false;
 	}
</diff>
				<old_file>#include &lt;ros/ros.h&gt;

#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/PCLPointCloud2.h&gt;
#include &lt;pcl/conversions.h&gt;
#include &lt;pcl_ros/transforms.h&gt;
#include &lt;pcl_ros/point_cloud.h&gt;

#include &lt;pcl/ModelCoefficients.h&gt;
#include &lt;pcl/point_types.h&gt;

#include &lt;pcl/filters/extract_indices.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;
#include &lt;pcl/filters/conditional_removal.h&gt;

#include &lt;pcl/features/normal_3d.h&gt;
#include &lt;pcl/features/normal_3d_omp.h&gt;
#include &lt;pcl/features/don.h&gt;
#include &lt;pcl/features/fpfh_omp.h&gt;

#include &lt;pcl/kdtree/kdtree.h&gt;

#include &lt;pcl/sample_consensus/method_types.h&gt;
#include &lt;pcl/sample_consensus/model_types.h&gt;

#include &lt;pcl/segmentation/sac_segmentation.h&gt;
#include &lt;pcl/segmentation/extract_clusters.h&gt;
#include &lt;pcl/segmentation/conditional_euclidean_clustering.h&gt;
#include &lt;pcl/segmentation/progressive_morphological_filter.h&gt;

#include &lt;pcl/common/common.h&gt;

#include &lt;pcl/search/organized.h&gt;
#include &lt;pcl/search/kdtree.h&gt;

#include &lt;pcl/segmentation/extract_clusters.h&gt;

#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;

#include &lt;std_msgs/Float32MultiArray.h&gt;
#include &lt;std_msgs/MultiArrayLayout.h&gt;
#include &lt;std_msgs/MultiArrayDimension.h&gt;

#include &lt;lidar_tracker/centroids.h&gt;
#include &lt;lidar_tracker/CloudCluster.h&gt;
#include &lt;lidar_tracker/CloudClusterArray.h&gt;

#include &lt;vector_map_server/PositionState.h&gt;

#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;

#include &lt;tf/tf.h&gt;

#include &lt;limits&gt;
#include &lt;cmath&gt;

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/contrib/contrib.hpp&gt;

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;

#include &quot;Cluster.h&quot;

//#include &lt;vector_map/vector_map.h&gt;
//#include &lt;vector_map_server/GetSignal.h&gt;

using namespace cv;

std::vector&lt;cv::Scalar&gt; _colors;
ros::Publisher _pub_cluster_cloud;
ros::Publisher _pub_ground_cloud;
ros::Publisher _centroid_pub;
ros::Publisher _marker_pub;
ros::Publisher _pub_clusters_message;
visualization_msgs::Marker _visualization_marker;

ros::Publisher _pub_points_lanes_cloud;
ros::Publisher _pub_jsk_boundingboxes;

ros::ServiceClient _vectormap_server;

std_msgs::Header _velodyne_header;

pcl::PointCloud&lt;pcl::PointXYZ&gt; _sensor_cloud;

std::vector&lt;double&gt; _clustering_thresholds;
std::vector&lt;double&gt; _clustering_distances;

tf::StampedTransform* _transform;
tf::StampedTransform* _velodyne_output_transform;
tf::TransformListener* _transform_listener;

std::string _output_frame;
std::string _vectormap_frame;
static bool _velodyne_transform_available;
static bool _downsample_cloud;
static bool _pose_estimation;
static double _leaf_size;
static int _cluster_size_min;
static int _cluster_size_max;

static bool _remove_ground;	//only ground

static bool _using_sensor_cloud;
static bool _use_diffnormals;
static bool _use_vector_map;

static double _clip_min_height;
static double _clip_max_height;

static bool _keep_lanes;
static double _keep_lane_left_distance;
static double _keep_lane_right_distance;

static double _max_boundingbox_side;
static double _remove_points_upto;

void transformBoundingBox(const jsk_recognition_msgs::BoundingBox&amp; in_boundingbox, jsk_recognition_msgs::BoundingBox&amp; out_boundingbox, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	geometry_msgs::PoseStamped pose_in, pose_out;
	pose_in.header = in_header;
	pose_in.pose = in_boundingbox.pose;
	try
	{
		_transform_listener-&gt;transformPose(in_target_frame, ros::Time(), pose_in, in_header.frame_id,  pose_out);
	}
	catch (tf::TransformException &amp;ex)
	{
		ROS_ERROR(&quot;transformBoundingBox: %s&quot;,ex.what());
	}
	out_boundingbox.pose = pose_out.pose;
	out_boundingbox.header = in_header;
	out_boundingbox.header.frame_id = in_target_frame;
	out_boundingbox.dimensions = in_boundingbox.dimensions;
	out_boundingbox.value = in_boundingbox.value;
	out_boundingbox.label = in_boundingbox.label;
}

void publishCloudClusters(const ros::Publisher* in_publisher, const lidar_tracker::CloudClusterArray&amp; in_clusters, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		lidar_tracker::CloudClusterArray clusters_transformed;
		clusters_transformed.header = in_header;
		clusters_transformed.header.frame_id = in_target_frame;
		for (auto i=clusters_transformed.clusters.begin(); i!= clusters_transformed.clusters.end(); i++)
		{
			lidar_tracker::CloudCluster cluster_transformed;
			cluster_transformed.header = in_header;
			try
			{
				_transform_listener-&gt;lookupTransform(in_target_frame, _velodyne_header.frame_id,
										ros::Time(), *_transform);
				pcl_ros::transformPointCloud(in_target_frame, *_transform, i-&gt;cloud, cluster_transformed.cloud);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;min_point, in_header.frame_id, cluster_transformed.min_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;max_point, in_header.frame_id, cluster_transformed.max_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;avg_point, in_header.frame_id, cluster_transformed.avg_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;centroid_point, in_header.frame_id, cluster_transformed.centroid_point);

				cluster_transformed.dimensions = i-&gt;dimensions;
				cluster_transformed.eigen_values = i-&gt;eigen_values;
				cluster_transformed.eigen_vectors = i-&gt;eigen_vectors;

				transformBoundingBox(i-&gt;bounding_box, cluster_transformed.bounding_box, in_target_frame, in_header);

				clusters_transformed.clusters.push_back(cluster_transformed);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCloudClusters: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(clusters_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_clusters);
	}
}

void publishCentroids(const ros::Publisher* in_publisher, const lidar_tracker::centroids&amp; in_centroids, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		lidar_tracker::centroids centroids_transformed;
		centroids_transformed.header = in_header;
		centroids_transformed.header.frame_id = in_target_frame;
		for (auto i=centroids_transformed.points.begin(); i!= centroids_transformed.points.end(); i++)
		{
			geometry_msgs::PointStamped centroid_in, centroid_out;
			centroid_in.header = in_header;
			centroid_in.point = *i;
			try
			{
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), centroid_in, in_header.frame_id, centroid_out);

				centroids_transformed.points.push_back(centroid_out.point);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCentroids: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(centroids_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_centroids);
	}
}

void publishBoundingBoxArray(const ros::Publisher* in_publisher, const jsk_recognition_msgs::BoundingBoxArray&amp; in_boundingbox_array, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		jsk_recognition_msgs::BoundingBoxArray boundingboxes_transformed;
		boundingboxes_transformed.header = in_header;
		boundingboxes_transformed.header.frame_id = in_target_frame;
		for (auto i=in_boundingbox_array.boxes.begin(); i!= in_boundingbox_array.boxes.end(); i++)
		{
			jsk_recognition_msgs::BoundingBox boundingbox_transformed;
			transformBoundingBox(*i, boundingbox_transformed, in_target_frame, in_header);
			boundingboxes_transformed.boxes.push_back(boundingbox_transformed);
		}
		in_publisher-&gt;publish(boundingboxes_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_boundingbox_array);
	}
}

void publishCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void publishColorCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void keepLanePoints(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
					pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr,
					float in_left_lane_threshold = 1.5,
					float in_right_lane_threshold = 1.5)
{
	pcl::PointIndices::Ptr far_indices (new pcl::PointIndices);
	for(unsigned int i=0; i&lt; in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x=in_cloud_ptr-&gt;points[i].x;
		current_point.y=in_cloud_ptr-&gt;points[i].y;
		current_point.z=in_cloud_ptr-&gt;points[i].z;

		if (
				current_point.y &gt; (in_left_lane_threshold) || current_point.y &lt; -1.0*in_right_lane_threshold
			)
		{
			far_indices-&gt;indices.push_back(i);
		}
	}
	out_cloud_ptr-&gt;points.clear();
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(far_indices);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_cloud_ptr);
}

std::vector&lt;ClusterPtr&gt; clusterAndColor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		lidar_tracker::centroids&amp; in_out_centroids,
		double in_max_cluster_distance=0.5)
{
	pcl::search::KdTree&lt;pcl::PointXYZ&gt;::Ptr tree (new pcl::search::KdTree&lt;pcl::PointXYZ&gt;);

	if (in_cloud_ptr-&gt;points.size() &gt; 0)
		tree-&gt;setInputCloud (in_cloud_ptr);

	std::vector&lt;pcl::PointIndices&gt; cluster_indices;

	pcl::EuclideanClusterExtraction&lt;pcl::PointXYZ&gt; ec;
	ec.setClusterTolerance (in_max_cluster_distance); //
	ec.setMinClusterSize (_cluster_size_min);
	ec.setMaxClusterSize (_cluster_size_max);
	ec.setSearchMethod(tree);
	ec.setInputCloud (in_cloud_ptr);
	ec.extract (cluster_indices);


	/*pcl::ConditionalEuclideanClustering&lt;pcl::PointXYZ&gt; cec (true);
	cec.setInputCloud (in_cloud_ptr);
	cec.setConditionFunction (&amp;independentDistance);
	cec.setMinClusterSize (cluster_size_min);
	cec.setMaxClusterSize (cluster_size_max);
	cec.setClusterTolerance (_distance*2.0f);
	cec.segment (cluster_indices);*/

	/////////////////////////////////
	//---	3. Color clustered points
	/////////////////////////////////
	unsigned int k = 0;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr final_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

	std::vector&lt;ClusterPtr&gt; clusters;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr cloud_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);//coord + color cluster
	for (auto it = cluster_indices.begin(); it != cluster_indices.end(); ++it)
	{
		ClusterPtr cluster(new Cluster());
		cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;indices, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		clusters.push_back(cluster);

		k++;
	}
	//std::cout &lt;&lt; &quot;Clusters: &quot; &lt;&lt; k &lt;&lt; std::endl;
	return clusters;

}

void segmentByDistance(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		lidar_tracker::centroids&amp; in_out_centroids,
		lidar_tracker::CloudClusterArray&amp; in_out_clusters)
{
	//cluster the pointcloud according to the distance of the points using different thresholds (not only one for the entire pc)
	//in this way, the points farther in the pc will also be clustered

	//0 =&gt; 0-15m d=0.5
	//1 =&gt; 15-30 d=1
	//2 =&gt; 30-45 d=1.6
	//3 =&gt; 45-60 d=2.1
	//4 =&gt; &gt;60   d=2.6

	std::vector&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr&gt; cloud_segments_array(5);

	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr tmp_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		cloud_segments_array[i] = tmp_cloud;
	}

	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x = in_cloud_ptr-&gt;points[i].x;
		current_point.y = in_cloud_ptr-&gt;points[i].y;
		current_point.z = in_cloud_ptr-&gt;points[i].z;

		float origin_distance = sqrt( pow(current_point.x,2) + pow(current_point.y,2) );

		if 		(origin_distance &lt; _clustering_distances[0] )	{cloud_segments_array[0]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[1])		{cloud_segments_array[1]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[2])		{cloud_segments_array[2]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[3])		{cloud_segments_array[3]-&gt;points.push_back (current_point);}
		else													{cloud_segments_array[4]-&gt;points.push_back (current_point);}
	}

	std::vector &lt;ClusterPtr&gt; all_clusters;
	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
		std::vector&lt;ClusterPtr&gt; local_clusters = clusterAndColor(cloud_segments_array[i], out_cloud_ptr, in_out_boundingbox_array, in_out_centroids, _clustering_thresholds[i]);

		all_clusters.insert(all_clusters.end(), local_clusters.begin(), local_clusters.end());
	}

	//Clusters can be merged or checked in here
	//....
	tf::StampedTransform vectormap_transform;
	if (_use_vector_map)
	{
		cv::TickMeter timer;

		try
		{
			//if the frame of the vectormap is different than the input, obtain transform
			if (_vectormap_frame != _velodyne_header.frame_id)
			{
				_transform_listener-&gt;lookupTransform(_vectormap_frame, _velodyne_header.frame_id, ros::Time(), vectormap_transform);
			}

			timer.reset();timer.start();

			//check if centroids are inside the drivable area
			for(unsigned int i=0; i&lt;all_clusters.size(); i++)
			{
				//transform centroid points to vectormap frame
				pcl::PointXYZ pcl_centroid = all_clusters[i]-&gt;GetCentroid();
				tf::Vector3 vector_centroid (pcl_centroid.x, pcl_centroid.y, pcl_centroid.z);
				tf::Vector3 transformed_centroid;

				if (_vectormap_frame != _velodyne_header.frame_id)
					transformed_centroid = vectormap_transform*vector_centroid;
				else
					transformed_centroid = vector_centroid;

				vector_map_server::PositionState position_state;
				position_state.request.position.x = transformed_centroid.getX();
				position_state.request.position.y = transformed_centroid.getY();
				position_state.request.position.z = transformed_centroid.getZ();


				if (_vectormap_server.call(position_state))
				{
					all_clusters[i]-&gt;SetValidity(position_state.response.state);
					/*std::cout &lt;&lt; &quot;Original:&quot; &lt;&lt; pcl_centroid.x &lt;&lt; &quot;,&quot; &lt;&lt; pcl_centroid.y &lt;&lt; &quot;,&quot; &lt;&lt; pcl_centroid.z &lt;&lt;
							&quot; Transformed:&quot; &lt;&lt; transformed_centroid.x() &lt;&lt; &quot;,&quot; &lt;&lt; transformed_centroid.y() &lt;&lt; &quot;,&quot; &lt;&lt; transformed_centroid.z() &lt;&lt;
							&quot; Validity:&quot; &lt;&lt; position_state.response.state &lt;&lt; std::endl;*/
				}
				else
				{
					ROS_INFO(&quot;vectormap_filtering: VectorMap Server Call failed. Make sure vectormap_server is running. No filtering performed.&quot;);
					all_clusters[i]-&gt;SetValidity(true);
				}
			}
			timer.stop();
			//std::cout &lt;&lt; &quot;vm server took &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot; ms to check &quot; &lt;&lt; all_clusters.size() &lt;&lt; std::endl;
		}
		catch(tf::TransformException &amp;ex)
		{
			ROS_INFO(&quot;vectormap_filtering: %s&quot;, ex.what());
		}
	}
	//Get final PointCloud to be published

	for(unsigned int i=0; i&lt;all_clusters.size(); i++)
	{
		*out_cloud_ptr = *out_cloud_ptr + *(all_clusters[i]-&gt;GetCloud());

		jsk_recognition_msgs::BoundingBox bounding_box = all_clusters[i]-&gt;GetBoundingBox();
		pcl::PointXYZ min_point = all_clusters[i]-&gt;GetMinPoint();
		pcl::PointXYZ max_point = all_clusters[i]-&gt;GetMaxPoint();
		pcl::PointXYZ center_point = all_clusters[i]-&gt;GetCentroid();
		geometry_msgs::Point centroid;
		centroid.x = center_point.x; centroid.y = center_point.y; centroid.z = center_point.z;
		bounding_box.header = _velodyne_header;

		if (	all_clusters[i]-&gt;IsValid() &amp;&amp;
				bounding_box.dimensions.x &gt;0 &amp;&amp; bounding_box.dimensions.y &gt;0 &amp;&amp; bounding_box.dimensions.z &gt; 0 &amp;&amp;
				bounding_box.dimensions.x &lt; _max_boundingbox_side &amp;&amp; bounding_box.dimensions.y &lt; _max_boundingbox_side
				&amp;&amp;max_point.z &gt; -1.5 &amp;&amp; min_point.z &gt; -1.5 &amp;&amp; min_point.z &lt; 1.0
				)
		{
			in_out_boundingbox_array.boxes.push_back(bounding_box);
			in_out_centroids.points.push_back(centroid);
			_visualization_marker.points.push_back(centroid);

			lidar_tracker::CloudCluster cloud_cluster;
			all_clusters[i]-&gt;ToRosMessage(_velodyne_header, cloud_cluster);
			in_out_clusters.clusters.push_back(cloud_cluster);
		}
	}
}

void removeFloor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_nofloor_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_onlyfloor_cloud_ptr, float in_max_height=0.2, float in_floor_max_angle=0.35)
{
	/*pcl::PointIndicesPtr ground (new pcl::PointIndices);
	// Create the filtering object
	pcl::ProgressiveMorphologicalFilter&lt;pcl::PointXYZ&gt; pmf;
	pmf.setInputCloud (in_cloud_ptr);
	pmf.setMaxWindowSize (20);
	pmf.setSlope (1.0f);
	pmf.setInitialDistance (0.5f);
	pmf.setMaxDistance (3.0f);
	pmf.extract (ground-&gt;indices);

	// Create the filtering object
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices (ground);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_nofloor_cloud_ptr);

	//EXTRACT THE FLOOR FROM THE CLOUD
	extract.setNegative(false);//true removes the indices, false leaves only the indices
	extract.filter(*out_onlyfloor_cloud_ptr);*/

	pcl::SACSegmentation&lt;pcl::PointXYZ&gt; seg;
	pcl::PointIndices::Ptr inliers (new pcl::PointIndices);
	pcl::ModelCoefficients::Ptr coefficients (new pcl::ModelCoefficients);

	seg.setOptimizeCoefficients (true);
	seg.setModelType(pcl::SACMODEL_PERPENDICULAR_PLANE);
	seg.setMethodType(pcl::SAC_RANSAC);
	seg.setMaxIterations(100);
	seg.setAxis(Eigen::Vector3f(0,0,1));
	seg.setEpsAngle(in_floor_max_angle);

	seg.setDistanceThreshold (in_max_height);//floor distance
	seg.setOptimizeCoefficients(true);
	seg.setInputCloud(in_cloud_ptr);
	seg.segment(*inliers, *coefficients);
	if (inliers-&gt;indices.size () == 0)
	{
		std::cout &lt;&lt; &quot;Could not estimate a planar model for the given dataset.&quot; &lt;&lt; std::endl;
	}

	//REMOVE THE FLOOR FROM THE CLOUD
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(inliers);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_nofloor_cloud_ptr);

	//EXTRACT THE FLOOR FROM THE CLOUD
	extract.setNegative(false);//true removes the indices, false leaves only the indices
	extract.filter(*out_onlyfloor_cloud_ptr);
}

void downsampleCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_leaf_size=0.2)
{
	pcl::VoxelGrid&lt;pcl::PointXYZ&gt; sor;
	sor.setInputCloud(in_cloud_ptr);
	sor.setLeafSize((float)in_leaf_size, (float)in_leaf_size, (float)in_leaf_size);
	sor.filter(*out_cloud_ptr);
}

void clipCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_min_height=-1.3, float in_max_height=0.5)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		if (in_cloud_ptr-&gt;points[i].z &gt;= in_min_height &amp;&amp;
				in_cloud_ptr-&gt;points[i].z &lt;= in_max_height)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void differenceNormalsSegmentation(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr)
{
	float small_scale=0.5;
	float large_scale=2.0;
	float angle_threshold=0.5;
	pcl::search::Search&lt;pcl::PointXYZ&gt;::Ptr tree;
	if (in_cloud_ptr-&gt;isOrganized ())
	{
		tree.reset (new pcl::search::OrganizedNeighbor&lt;pcl::PointXYZ&gt; ());
	}
	else
	{
		tree.reset (new pcl::search::KdTree&lt;pcl::PointXYZ&gt; (false));
	}

	// Set the input pointcloud for the search tree
	tree-&gt;setInputCloud (in_cloud_ptr);

	pcl::NormalEstimationOMP&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	//pcl::gpu::NormalEstimation&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	normal_estimation.setInputCloud (in_cloud_ptr);
	normal_estimation.setSearchMethod (tree);

	normal_estimation.setViewPoint (std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max ());

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_small_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_large_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	normal_estimation.setRadiusSearch (small_scale);
	normal_estimation.compute (*normals_small_scale);

	normal_estimation.setRadiusSearch (large_scale);
	normal_estimation.compute (*normals_large_scale);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::copyPointCloud&lt;pcl::PointXYZ, pcl::PointNormal&gt;(*in_cloud_ptr, *diffnormals_cloud);

	// Create DoN operator
	pcl::DifferenceOfNormalsEstimation&lt;pcl::PointXYZ, pcl::PointNormal, pcl::PointNormal&gt; diffnormals_estimator;
	diffnormals_estimator.setInputCloud (in_cloud_ptr);
	diffnormals_estimator.setNormalScaleLarge (normals_large_scale);
	diffnormals_estimator.setNormalScaleSmall (normals_small_scale);

	diffnormals_estimator.initCompute();

	diffnormals_estimator.computeFeature(*diffnormals_cloud);

	pcl::ConditionOr&lt;pcl::PointNormal&gt;::Ptr range_cond (new pcl::ConditionOr&lt;pcl::PointNormal&gt;() );
	range_cond-&gt;addComparison (pcl::FieldComparison&lt;pcl::PointNormal&gt;::ConstPtr (
			new pcl::FieldComparison&lt;pcl::PointNormal&gt; (&quot;curvature&quot;, pcl::ComparisonOps::GT, angle_threshold) )
			);
	// Build the filter
	pcl::ConditionalRemoval&lt;pcl::PointNormal&gt; cond_removal;
	cond_removal.setCondition(range_cond);
	cond_removal.setInputCloud (diffnormals_cloud);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud_filtered (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	// Apply filter
	cond_removal.filter (*diffnormals_cloud_filtered);

	pcl::copyPointCloud&lt;pcl::PointNormal, pcl::PointXYZ&gt;(*diffnormals_cloud, *out_cloud_ptr);
}

void removePointsUpTo(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, const double in_distance)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		float origin_distance = sqrt( pow(in_cloud_ptr-&gt;points[i].x,2) + pow(in_cloud_ptr-&gt;points[i].y,2) );
		if (origin_distance &gt; in_distance)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void velodyne_callback(const sensor_msgs::PointCloud2ConstPtr&amp; in_sensor_cloud)
{
	if (!_using_sensor_cloud)
	{
		_using_sensor_cloud = true;

		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr current_sensor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr removed_points_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr downsampled_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr inlanes_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr nofloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr onlyfloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr diffnormals_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr clipped_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr colored_clustered_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

		lidar_tracker::centroids centroids;
		lidar_tracker::CloudClusterArray cloud_clusters;
		jsk_recognition_msgs::BoundingBoxArray boundingbox_array;

		pcl::fromROSMsg(*in_sensor_cloud, *current_sensor_cloud_ptr);

		_velodyne_header = in_sensor_cloud-&gt;header;


		cv::TickMeter timer;

		timer.reset();timer.start();

		if (_remove_points_upto &gt; 0.0)
		{
			removePointsUpTo(current_sensor_cloud_ptr, removed_points_cloud_ptr, _remove_points_upto);
		}
		else
			removed_points_cloud_ptr = current_sensor_cloud_ptr;

		if (_downsample_cloud)
			downsampleCloud(removed_points_cloud_ptr, downsampled_cloud_ptr, _leaf_size);
		else
			downsampled_cloud_ptr=current_sensor_cloud_ptr;
		timer.stop(); //std::cout &lt;&lt; &quot;downsampleCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		downsampled_cloud_ptr=removed_points_cloud_ptr;

		timer.reset();timer.start();
		if(_keep_lanes)
			keepLanePoints(downsampled_cloud_ptr, inlanes_cloud_ptr, _keep_lane_left_distance, _keep_lane_right_distance);
		else
			inlanes_cloud_ptr = downsampled_cloud_ptr;
		timer.stop(); //std::cout &lt;&lt; &quot;keepLanePoints:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		if(_remove_ground)
		{
			removeFloor(inlanes_cloud_ptr, nofloor_cloud_ptr, onlyfloor_cloud_ptr);
			publishCloud(&amp;_pub_ground_cloud, onlyfloor_cloud_ptr);
		}
		else
			nofloor_cloud_ptr = inlanes_cloud_ptr;
		timer.stop(); //std::cout &lt;&lt; &quot;removeFloor:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		clipCloud(nofloor_cloud_ptr, clipped_cloud_ptr, _clip_min_height, _clip_max_height);
		publishCloud(&amp;_pub_points_lanes_cloud, clipped_cloud_ptr);
		timer.stop(); //std::cout &lt;&lt; &quot;clipCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		if (_use_diffnormals)
			differenceNormalsSegmentation(clipped_cloud_ptr, diffnormals_cloud_ptr);
		else
			diffnormals_cloud_ptr = clipped_cloud_ptr;
		timer.stop(); //std::cout &lt;&lt; &quot;differenceNormalsSegmentation:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		segmentByDistance(diffnormals_cloud_ptr, colored_clustered_cloud_ptr, boundingbox_array, centroids, cloud_clusters);
		timer.stop(); //std::cout &lt;&lt; &quot;segmentByDistance:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		publishColorCloud(&amp;_pub_cluster_cloud, colored_clustered_cloud_ptr);
		timer.stop(); //std::cout &lt;&lt; &quot;publishColorCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
		// Publish BB
		boundingbox_array.header = _velodyne_header;

		timer.reset();timer.start();
		publishBoundingBoxArray(&amp;_pub_jsk_boundingboxes, boundingbox_array, _output_frame, _velodyne_header);
		centroids.header = _velodyne_header;
		timer.stop(); //std::cout &lt;&lt; &quot;publishBoundingBoxArray:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		publishCentroids(&amp;_centroid_pub, centroids, _output_frame, _velodyne_header);
		timer.stop(); //std::cout &lt;&lt; &quot;publishCentroids:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		_marker_pub.publish(_visualization_marker);
		_visualization_marker.points.clear();//transform? is it used?
		cloud_clusters.header = _velodyne_header;

		timer.reset();timer.start();
		publishCloudClusters(&amp;_pub_clusters_message, cloud_clusters, _output_frame, _velodyne_header);
		timer.stop(); //std::cout &lt;&lt; &quot;publishCloudClusters:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl &lt;&lt; std::endl;

		_using_sensor_cloud = false;
	}
}

/*
void vectormap_callback(const visualization_msgs::MarkerArray::Ptr in_vectormap_markers)
{
	float min_x=std::numeric_limits&lt;float&gt;::max();float max_x=-std::numeric_limits&lt;float&gt;::max();
	float min_y=std::numeric_limits&lt;float&gt;::max();float max_y=-std::numeric_limits&lt;float&gt;::max();
	pcl::PointXYZ min_point;
	pcl::PointXYZ max_point;
	std::vector&lt;geometry_msgs::Point&gt; vectormap_points;
	std::string marker_frame;
	double map_scale = -10.0;
	for(auto i=in_vectormap_markers-&gt;markers.begin(); i!= in_vectormap_markers-&gt;markers.end(); i++)
	{
		visualization_msgs::Marker current_marker = *i;
		marker_frame = current_marker.header.frame_id;
		if (current_marker.ns == &quot;road_edge&quot;)
		{
			for (unsigned int j=0; j&lt; current_marker.points.size(); j++)
			{
				geometry_msgs::Point p = current_marker.points[j];
				p.x*=map_scale;
				p.y*=map_scale;
				if(p.x&lt;min_x)	min_x = p.x;
				if(p.y&lt;min_y)	min_y = p.y;
				if(p.x&gt;max_x)	max_x = p.x;
				if(p.y&gt;max_y)	max_y = p.y;
				vectormap_points.push_back(p);
			}
		}
	}
	min_point.x = min_x;	min_point.y = min_y;
	max_point.x = max_x;	max_point.y = max_y;

	min_point.x*=-1.0;
	min_point.y*=-1.0;
	//translate the points to the minimum point
	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		(*i).x+=min_point.x;
		(*i).y+=min_point.y;
	}
	max_point.x+=min_point.x;
	max_point.y+=min_point.y;
	//get world tf
	std::string error_transform_msg;
	tf::Vector3 map_origin_point;
	if(_transform_listener-&gt;waitForTransform(&quot;/map&quot;, marker_frame, ros::Time(0), ros::Duration(5), ros::Duration(0.1), &amp;error_transform_msg))
	{
		_transform_listener-&gt;lookupTransform(&quot;/map&quot;, marker_frame, ros::Time(0), *_transform);
		map_origin_point = _transform-&gt;getOrigin();
		map_origin_point.setX( map_origin_point.x() - min_point.x);
		map_origin_point.setY( map_origin_point.y() - min_point.y);
	}
	else
	{
		ROS_INFO(&quot;Euclidean Cluster (vectormap_callback): %s&quot;, error_transform_msg.c_str());
	}

	cv::Mat map_image = cv::Mat::zeros(max_point.y, max_point.x, CV_8UC3);

	std::cout &lt;&lt; &quot;W,H:&quot; &lt;&lt; max_point &lt;&lt; std::endl;

	cv::Point image_start_point (vectormap_points[0].x, vectormap_points[0].y);
	cv::Point prev_point = image_start_point;
	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		cv::line(map_image, prev_point, cv::Point((int)(i-&gt;x), (int)(i-&gt;y)), cv::Scalar::all(255));

		prev_point.x = (int)(i-&gt;x);
		prev_point.y = (int)(i-&gt;y);
	}
	cv::circle(map_image, image_start_point, 3, cv::Scalar(255,0,0));
	cv::imshow(&quot;vectormap&quot;, map_image);
	cv::waitKey(0);
}*/

int main (int argc, char** argv)
{
	// Initialize ROS
	ros::init (argc, argv, &quot;euclidean_cluster&quot;);

	ros::NodeHandle h;
	ros::NodeHandle private_nh(&quot;~&quot;);

	tf::StampedTransform transform;
	tf::TransformListener listener;

	_transform = &amp;transform;
	_transform_listener = &amp;listener;

	cv::generateColors(_colors, 100);

	_pub_cluster_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_cluster&quot;,1);
	_pub_ground_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_ground&quot;,1);
	_centroid_pub = h.advertise&lt;lidar_tracker::centroids&gt;(&quot;/cluster_centroids&quot;,1);
	_marker_pub = h.advertise&lt;visualization_msgs::Marker&gt;(&quot;centroid_marker&quot;,1);

	_pub_points_lanes_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_lanes&quot;,1);
	_pub_jsk_boundingboxes = h.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(&quot;/bounding_boxes&quot;,1);
	_pub_clusters_message = h.advertise&lt;lidar_tracker::CloudClusterArray&gt;(&quot;/cloud_clusters&quot;,1);

	std::string points_topic;

	_using_sensor_cloud = false;

	if (private_nh.getParam(&quot;points_node&quot;, points_topic))
	{
		ROS_INFO(&quot;euclidean_cluster &gt; Setting points node to %s&quot;, points_topic.c_str());
	}
	else
	{
		ROS_INFO(&quot;euclidean_cluster &gt; No points node received, defaulting to points_raw, you can use _points_node:=YOUR_TOPIC&quot;);
		points_topic = &quot;/points_raw&quot;;
	}

	_use_diffnormals = false;
	if (private_nh.getParam(&quot;use_diffnormals&quot;, _use_diffnormals))
	{
		if (_use_diffnormals)
			ROS_INFO(&quot;Euclidean Clustering: Applying difference of normals on clustering pipeline&quot;);
		else
			ROS_INFO(&quot;Euclidean Clustering: Difference of Normals will not be used.&quot;);
	}

	/* Initialize tuning parameter */
	private_nh.param(&quot;downsample_cloud&quot;, _downsample_cloud, false);	ROS_INFO(&quot;downsample_cloud: %d&quot;, _downsample_cloud);
	private_nh.param(&quot;remove_ground&quot;, _remove_ground, true);		ROS_INFO(&quot;remove_ground: %d&quot;, _remove_ground);
	private_nh.param(&quot;leaf_size&quot;, _leaf_size, 0.1);					ROS_INFO(&quot;leaf_size: %f&quot;, _leaf_size);
	private_nh.param(&quot;cluster_size_min&quot;, _cluster_size_min, 20);	ROS_INFO(&quot;cluster_size_min %d&quot;, _cluster_size_min);
	private_nh.param(&quot;cluster_size_max&quot;, _cluster_size_max, 100000);ROS_INFO(&quot;cluster_size_max: %d&quot;, _cluster_size_max);
	private_nh.param(&quot;pose_estimation&quot;, _pose_estimation, false);	ROS_INFO(&quot;pose_estimation: %d&quot;, _pose_estimation);
	private_nh.param(&quot;clip_min_height&quot;, _clip_min_height, -1.3);	ROS_INFO(&quot;clip_min_height: %f&quot;, _clip_min_height);
	private_nh.param(&quot;clip_max_height&quot;, _clip_max_height, 0.5);		ROS_INFO(&quot;clip_max_height: %f&quot;, _clip_max_height);
	private_nh.param(&quot;keep_lanes&quot;, _keep_lanes, false);				ROS_INFO(&quot;keep_lanes: %d&quot;, _keep_lanes);
	private_nh.param(&quot;keep_lane_left_distance&quot;, _keep_lane_left_distance, 5.0);		ROS_INFO(&quot;keep_lane_left_distance: %f&quot;, _keep_lane_left_distance);
	private_nh.param(&quot;keep_lane_right_distance&quot;, _keep_lane_right_distance, 5.0);	ROS_INFO(&quot;keep_lane_right_distance: %f&quot;, _keep_lane_right_distance);
	private_nh.param(&quot;clustering_thresholds&quot;, _clustering_thresholds);
	private_nh.param(&quot;clustering_distances&quot;, _clustering_distances);
	private_nh.param(&quot;max_boundingbox_side&quot;, _max_boundingbox_side, 10.0);				ROS_INFO(&quot;max_boundingbox_side: %f&quot;, _max_boundingbox_side);
	private_nh.param&lt;std::string&gt;(&quot;output_frame&quot;, _output_frame, &quot;velodyne&quot;);			ROS_INFO(&quot;output_frame: %s&quot;, _output_frame.c_str());

	private_nh.param(&quot;use_vector_map&quot;, _use_vector_map, false);							ROS_INFO(&quot;use_vector_map: %d&quot;, _use_vector_map);
	private_nh.param&lt;std::string&gt;(&quot;vectormap_frame&quot;, _vectormap_frame, &quot;map&quot;);			ROS_INFO(&quot;vectormap_frame: %s&quot;, _output_frame.c_str());

	private_nh.param(&quot;remove_points_upto&quot;, _remove_points_upto, 0.0);		ROS_INFO(&quot;remove_points_upto: %f&quot;, _remove_points_upto);


	_velodyne_transform_available = false;

	if (_clustering_distances.size()!=4)
	{
		_clustering_distances = {15, 30, 45, 60};//maximum distance from sensor origin to separate segments
	}
	if (_clustering_thresholds.size()!=5)
	{
		_clustering_thresholds = {0.5, 1.1, 1.6, 2.1, 2.6};//Nearest neighbor distance threshold for each segment
	}

	std::cout &lt;&lt; &quot;_clustering_thresholds: &quot;; for (auto i = _clustering_thresholds.begin(); i != _clustering_thresholds.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt; std::endl;
	std::cout &lt;&lt; &quot;_clustering_distances: &quot;;for (auto i = _clustering_distances.begin(); i != _clustering_distances.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt;std::endl;

	// Create a ROS subscriber for the input point cloud
	ros::Subscriber sub = h.subscribe (points_topic, 1, velodyne_callback);
	//ros::Subscriber sub_vectormap = h.subscribe (&quot;vector_map&quot;, 1, vectormap_callback);
	_vectormap_server = h.serviceClient&lt;vector_map_server::PositionState&gt;(&quot;vector_map_server/is_way_area&quot;);

	_visualization_marker.header.frame_id = &quot;velodyne&quot;;
	_visualization_marker.header.stamp = ros::Time();
	_visualization_marker.ns = &quot;my_namespace&quot;;
	_visualization_marker.id = 0;
	_visualization_marker.type = visualization_msgs::Marker::SPHERE_LIST;
	_visualization_marker.action = visualization_msgs::Marker::ADD;
	_visualization_marker.scale.x = 1.0;
	_visualization_marker.scale.y = 1.0;
	_visualization_marker.scale.z = 1.0;
	_visualization_marker.color.a = 1.0;
	_visualization_marker.color.r = 0.0;
	_visualization_marker.color.g = 0.0;
	_visualization_marker.color.b = 1.0;
	// marker.lifetime = ros::Duration(0.1);
	_visualization_marker.frame_locked = true;

	// Spin
	ros::spin ();
}
</old_file>
			</file>
			<file old_path="ros/src/sensing/fusion/packages/points2image/nodes/points2vscan/mainwindow.h" new_path="ros/src/sensing/fusion/packages/points2image/nodes/points2vscan/mainwindow.h">
				<diff>@@ -9,6 +9,7 @@
 #include&lt;rosinterface.h&gt;
 #include&lt;fastvirtualscan.h&gt;
 #include&lt;sensor_msgs/LaserScan.h&gt;
+#include&lt;string&gt;
 
 //#define DEBUG_GUI
 
</diff>
				<old_file>#ifndef MAINWINDOW_H
#define MAINWINDOW_H

#include &lt;QMainWindow&gt;
#include&lt;QPainter&gt;
#include&lt;QImage&gt;
#include&lt;QTime&gt;

#include&lt;rosinterface.h&gt;
#include&lt;fastvirtualscan.h&gt;
#include&lt;sensor_msgs/LaserScan.h&gt;

//#define DEBUG_GUI

namespace Ui {
class MainWindow;
}

class MainWindow : public QMainWindow
{
    Q_OBJECT

public:
    explicit MainWindow(QWidget *parent = 0);
    ~MainWindow();

private:
    Ui::MainWindow *ui;
protected:
    ROSSub&lt;sensor_msgs::PointCloud2ConstPtr&gt; * velodyne;
    ROSPub&lt;sensor_msgs::PointCloud2&gt; * vsros;
    ROSPub&lt;sensor_msgs::LaserScan&gt; * scanros;
    FastVirtualScan virtualscan;
    QVector&lt;double&gt; beams;
    QVector&lt;double&gt; heights;
    QImage image;
public slots:
    void generateVirtualScanSlot();
    void showMatrixSlot(int beamid);
    void recalculateSlot();
protected:
    QPointF convert2RealPoint(QPoint point);
    QPoint convert2ImagePoint(QPointF point);
    void drawGrid();
    void drawPoints();
    void drawBeam(int beamid);
};

#endif // MAINWINDOW_H
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="c4be752a666dae02e5c49091464eab981146ff8e" fix_time="29,5309">
		<msg>Bug fix for linear interpolation flag and command velocity</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit.cpp" new_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit.cpp">
				<diff>@@ -240,7 +240,7 @@ bool PurePursuit::canGetCurvature(double *output_kappa)
     return false;
   }
 
-  // if g_linear_interpolate_mode is false or next waypoint is first or last
+  // if is_linear_interpolation_ is false or next waypoint is first or last
   if (!is_linear_interpolation_ || next_waypoint_number_ == 0 ||
       next_waypoint_number_ == (static_cast&lt;int&gt;(current_waypoints_.size() - 1)))
   {
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;pure_pursuit.h&quot;

namespace waypoint_follower
{
// Constructor
PurePursuit::PurePursuit()
  : RADIUS_MAX_(9e10)
  , KAPPA_MIN_(1 / RADIUS_MAX_)
  , is_linear_interpolation_(false)
  , next_waypoint_number_(-1)
  , lookahead_distance_(0)
  , current_linear_velocity_(0)
{
}

// Destructor
PurePursuit::~PurePursuit()
{
}

double PurePursuit::calcCurvature(geometry_msgs::Point target) const
{
  double kappa;
  double denominator = pow(getPlaneDistance(target, current_pose_.position), 2);
  double numerator = 2 * calcRelativeCoordinate(target, current_pose_).y;

  if (denominator != 0)
    kappa = numerator / denominator;
  else
  {
    if (numerator &gt; 0)
      kappa = KAPPA_MIN_;
    else
      kappa = -KAPPA_MIN_;
  }
  ROS_INFO(&quot;kappa : %lf&quot;, kappa);
  return kappa;
}

// linear interpolation of next target
bool PurePursuit::interpolateNextTarget(int next_waypoint, geometry_msgs::Point *next_target) const
{
  constexpr double ERROR = pow(10, -5);  // 0.00001

  int path_size = static_cast&lt;int&gt;(current_waypoints_.size());
  if (next_waypoint == path_size - 1)
  {
    *next_target = current_waypoints_.at(next_waypoint).pose.pose.position;
    return true;
  }
  double search_radius = lookahead_distance_;
  geometry_msgs::Point zero_p;
  geometry_msgs::Point end = current_waypoints_.at(next_waypoint).pose.pose.position;
  geometry_msgs::Point start = current_waypoints_.at(next_waypoint - 1).pose.pose.position;

  // let the linear equation be &quot;ax + by + c = 0&quot;
  // if there are two points (x1,y1) , (x2,y2), a = &quot;y2-y1, b = &quot;(-1) * x2 - x1&quot; ,c = &quot;(-1) * (y2-y1)x1 + (x2-x1)y1&quot;
  double a = 0;
  double b = 0;
  double c = 0;
  double get_linear_flag = getLinearEquation(start, end, &amp;a, &amp;b, &amp;c);
  if (!get_linear_flag)
    return false;

  // let the center of circle be &quot;(x0,y0)&quot;, in my code , the center of circle is vehicle position
  // the distance  &quot;d&quot; between the foot of a perpendicular line and the center of circle is ...
  //    | a * x0 + b * y0 + c |
  // d = -------------------------------
  //          √( a~2 + b~2)
  double d = getDistanceBetweenLineAndPoint(current_pose_.position, a, b, c);

  // ROS_INFO(&quot;a : %lf &quot;, a);
  // ROS_INFO(&quot;b : %lf &quot;, b);
  // ROS_INFO(&quot;c : %lf &quot;, c);
  // ROS_INFO(&quot;distance : %lf &quot;, d);

  if (d &gt; search_radius)
    return false;

  // unit vector of point 'start' to point 'end'
  tf::Vector3 v((end.x - start.x), (end.y - start.y), 0);
  tf::Vector3 unit_v = v.normalize();

  // normal unit vectors of v
  tf::Vector3 unit_w1 = rotateUnitVector(unit_v, 90);   // rotate to counter clockwise 90 degree
  tf::Vector3 unit_w2 = rotateUnitVector(unit_v, -90);  // rotate to counter clockwise 90 degree

  // the foot of a perpendicular line
  geometry_msgs::Point h1;
  h1.x = current_pose_.position.x + d * unit_w1.getX();
  h1.y = current_pose_.position.y + d * unit_w1.getY();
  h1.z = current_pose_.position.z;

  geometry_msgs::Point h2;
  h2.x = current_pose_.position.x + d * unit_w2.getX();
  h2.y = current_pose_.position.y + d * unit_w2.getY();
  h2.z = current_pose_.position.z;

  // ROS_INFO(&quot;error : %lf&quot;, error);
  // ROS_INFO(&quot;whether h1 on line : %lf&quot;, h1.y - (slope * h1.x + intercept));
  // ROS_INFO(&quot;whether h2 on line : %lf&quot;, h2.y - (slope * h2.x + intercept));

  // check which of two foot of a perpendicular line is on the line equation
  geometry_msgs::Point h;
  if (fabs(a * h1.x + b * h1.y + c) &lt; ERROR)
  {
    h = h1;
    //   ROS_INFO(&quot;use h1&quot;);
  }
  else if (fabs(a * h2.x + b * h2.y + c) &lt; ERROR)
  {
    //   ROS_INFO(&quot;use h2&quot;);
    h = h2;
  }
  else
  {
    return false;
  }

  // get intersection[s]
  // if there is a intersection
  if (d == search_radius)
  {
    *next_target = h;
    return true;
  }
  else
  {
    // if there are two intersection
    // get intersection in front of vehicle
    double s = sqrt(pow(search_radius, 2) - pow(d, 2));
    geometry_msgs::Point target1;
    target1.x = h.x + s * unit_v.getX();
    target1.y = h.y + s * unit_v.getY();
    target1.z = current_pose_.position.z;

    geometry_msgs::Point target2;
    target2.x = h.x - s * unit_v.getX();
    target2.y = h.y - s * unit_v.getY();
    target2.z = current_pose_.position.z;

    // ROS_INFO(&quot;target1 : ( %lf , %lf , %lf)&quot;, target1.x, target1.y, target1.z);
    // ROS_INFO(&quot;target2 : ( %lf , %lf , %lf)&quot;, target2.x, target2.y, target2.z);
    // displayLinePoint(a, b, c, target1, target2, h);  // debug tool

    // check intersection is between end and start
    double interval = getPlaneDistance(end, start);
    if (getPlaneDistance(target1, end) &lt; interval)
    {
      // ROS_INFO(&quot;result : target1&quot;);
      *next_target = target1;
      return true;
    }
    else if (getPlaneDistance(target2, end) &lt; interval)
    {
      // ROS_INFO(&quot;result : target2&quot;);
      *next_target = target2;
      return true;
    }
    else
    {
      // ROS_INFO(&quot;result : false &quot;);
      return false;
    }
  }
}

void PurePursuit::getNextWaypoint()
{
  int path_size = static_cast&lt;int&gt;(current_waypoints_.size());

  // if waypoints are not given, do nothing.
  if (path_size == 0)
  {
    next_waypoint_number_ = -1;
    return;
  }

  // look for the next waypoint.
  for (int i = 0; i &lt; path_size; i++)
  {
    // if search waypoint is the last
    if (i == (path_size - 1))
    {
      ROS_INFO(&quot;search waypoint is the last&quot;);
      next_waypoint_number_ = i;
      return;
    }

    // if there exists an effective waypoint
    if (getPlaneDistance(current_waypoints_.at(i).pose.pose.position, current_pose_.position) &gt; lookahead_distance_)
    {
      next_waypoint_number_ = i;
      return;
    }
  }

  // if this program reaches here , it means we lost the waypoint!
  next_waypoint_number_ = -1;
  return;
}

bool PurePursuit::canGetCurvature(double *output_kappa)
{
  // search next waypoint
  getNextWaypoint();
  if (next_waypoint_number_ == -1)
  {
    ROS_INFO(&quot;lost next waypoint&quot;);
    return false;
  }

  // if g_linear_interpolate_mode is false or next waypoint is first or last
  if (!is_linear_interpolation_ || next_waypoint_number_ == 0 ||
      next_waypoint_number_ == (static_cast&lt;int&gt;(current_waypoints_.size() - 1)))
  {
    next_target_position_ = current_waypoints_.at(next_waypoint_number_).pose.pose.position;
    *output_kappa = calcCurvature(next_target_position_);
    return true;
  }

  // linear interpolation and calculate angular velocity
  bool interpolation = interpolateNextTarget(next_waypoint_number_, &amp;next_target_position_);

  if (!interpolation)
  {
    ROS_INFO_STREAM(&quot;lost target! &quot;);
    return false;
  }

  // ROS_INFO(&quot;next_target : ( %lf , %lf , %lf)&quot;, next_target.x, next_target.y,next_target.z);

  *output_kappa = calcCurvature(next_target_position_);
  return true;
}

}  // waypoint_follower</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit_core.cpp" new_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit_core.cpp">
				<diff>@@ -124,7 +124,7 @@ void PurePursuitNode::publishTwistStamped(const bool &amp;can_get_curvature, const d
 {
   geometry_msgs::TwistStamped ts;
   ts.header.stamp = ros::Time::now();
-  ts.twist.linear.x = can_get_curvature ? command_linear_velocity_ : 0;
+  ts.twist.linear.x = can_get_curvature ? computeCommandVelocity() : 0;
   ts.twist.angular.z = can_get_curvature ? kappa * ts.twist.linear.x : 0;
   pub1_.publish(ts);
 }
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;pure_pursuit_core.h&quot;

namespace waypoint_follower
{
// Constructor
PurePursuitNode::PurePursuitNode()
  : private_nh_(&quot;~&quot;)
  , pp_()
  , LOOP_RATE_(30)
  , is_waypoint_set_(false)
  , is_pose_set_(false)
  , is_velocity_set_(false)
  , is_config_set_(false)
  , current_linear_velocity_(0)
  , command_linear_velocity_(0)
  , param_flag_(-1)
  , const_lookahead_distance_(4.0)
  , const_velocity_(5.0)
  , lookahead_distance_ratio_(2.0)
  , minimum_lookahead_distance_(6.0)
{
  initForROS();

  // initialize for PurePursuit
  pp_.setLinearInterpolationParameter(is_linear_interpolation_);
}

// Destructor
PurePursuitNode::~PurePursuitNode()
{
}

void PurePursuitNode::initForROS()
{
  // ros parameter settings
  private_nh_.param(&quot;is_linear_interpolation&quot;, is_linear_interpolation_, bool(true));
  // ROS_INFO_STREAM(&quot;is_linear_interpolation : &quot; &lt;&lt; is_linear_interpolation_);
  private_nh_.param(&quot;publishes_for_steering_robot&quot;, publishes_for_steering_robot_, bool(false));
  private_nh_.param(&quot;vehicle_info/wheel_base&quot;, wheel_base_, double(2.7));

  // setup subscriber
  sub1_ = nh_.subscribe(&quot;final_waypoints&quot;, 10, &amp;PurePursuitNode::callbackFromWayPoints, this);
  sub2_ = nh_.subscribe(&quot;current_pose&quot;, 10, &amp;PurePursuitNode::callbackFromCurrentPose, this);
  sub3_ = nh_.subscribe(&quot;config/waypoint_follower&quot;, 10, &amp;PurePursuitNode::callbackFromConfig, this);
  sub4_ = nh_.subscribe(&quot;current_velocity&quot;, 10, &amp;PurePursuitNode::callbackFromCurrentVelocity, this);

  // setup publisher
  pub1_ = nh_.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;twist_raw&quot;, 10);
  pub2_ = nh_.advertise&lt;waypoint_follower::ControlCommandStamped&gt;(&quot;ctrl_cmd&quot;, 10);
  pub11_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;next_waypoint_mark&quot;, 0);
  pub12_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;next_target_mark&quot;, 0);
  pub13_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;search_circle_mark&quot;, 0);
  pub14_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;line_point_mark&quot;, 0);  // debug tool
  pub15_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;trajectory_circle_mark&quot;, 0);
  // pub7_ = nh.advertise&lt;std_msgs::Bool&gt;(&quot;wf_stat&quot;, 0);
}

void PurePursuitNode::run()
{
  ROS_INFO_STREAM(&quot;pure pursuit start&quot;);
  ros::Rate loop_rate(LOOP_RATE_);
  while (ros::ok())
  {
    ros::spinOnce();
    if (!is_pose_set_ || !is_waypoint_set_ || !is_velocity_set_ || !is_config_set_)
    {
      ROS_WARN(&quot;Necessary topics are not subscribed yet ... &quot;);
      loop_rate.sleep();
      continue;
    }

    pp_.setLookaheadDistance(computeLookaheadDistance());

    double kappa = 0;
    bool can_get_curvature = pp_.canGetCurvature(&amp;kappa);
    publishTwistStamped(can_get_curvature, kappa);
    publishControlCommandStamped(can_get_curvature, kappa);

    // for visualization with Rviz
    pub11_.publish(displayNextWaypoint(pp_.getPoseOfNextWaypoint()));
    pub13_.publish(displaySearchRadius(pp_.getCurrentPose().position, pp_.getLookaheadDistance()));
    pub12_.publish(displayNextTarget(pp_.getPoseOfNextTarget()));
    pub15_.publish(displayTrajectoryCircle(
        waypoint_follower::generateTrajectoryCircle(pp_.getPoseOfNextTarget(), pp_.getCurrentPose())));

    is_pose_set_ = false;
    is_velocity_set_ = false;
    is_waypoint_set_ = false;
    loop_rate.sleep();
  }
}

void PurePursuitNode::publishTwistStamped(const bool &amp;can_get_curvature, const double &amp;kappa) const
{
  geometry_msgs::TwistStamped ts;
  ts.header.stamp = ros::Time::now();
  ts.twist.linear.x = can_get_curvature ? command_linear_velocity_ : 0;
  ts.twist.angular.z = can_get_curvature ? kappa * ts.twist.linear.x : 0;
  pub1_.publish(ts);
}

void PurePursuitNode::publishControlCommandStamped(const bool &amp;can_get_curvature, const double &amp;kappa) const
{
  if (!publishes_for_steering_robot_)
    return;

  waypoint_follower::ControlCommandStamped ccs;
  ccs.header.stamp = ros::Time::now();
  ccs.cmd.linear_velocity = can_get_curvature ? computeCommandVelocity() : 0;
  ccs.cmd.steering_angle = can_get_curvature ? convertCurvatureToSteeringAngle(wheel_base_, kappa) : 0;

  pub2_.publish(ccs);
}

double PurePursuitNode::computeLookaheadDistance() const
{
  if (param_flag_ == enumToInteger(Mode::dialog))
    return const_lookahead_distance_;

  double maximum_lookahead_distance = current_linear_velocity_ * 10;
  double ld = current_linear_velocity_ * lookahead_distance_ratio_;

  return ld &lt; minimum_lookahead_distance_ ? minimum_lookahead_distance_
        : ld &gt; maximum_lookahead_distance ? maximum_lookahead_distance
        : ld;
}

double PurePursuitNode::computeCommandVelocity() const
{
  if (param_flag_ == enumToInteger(Mode::dialog))
    return kmph2mps(const_velocity_);

  return command_linear_velocity_;
}

void PurePursuitNode::callbackFromConfig(const runtime_manager::ConfigWaypointFollowerConstPtr &amp;config)
{
  param_flag_ = config-&gt;param_flag;
  const_lookahead_distance_ = config-&gt;lookahead_distance;
  const_velocity_ = config-&gt;velocity;
  lookahead_distance_ratio_ = config-&gt;lookahead_ratio;
  minimum_lookahead_distance_ = config-&gt;minimum_lookahead_distance;
  is_config_set_ = true;
}

void PurePursuitNode::callbackFromCurrentPose(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  pp_.setCurrentPose(msg);
  is_pose_set_ = true;
}

void PurePursuitNode::callbackFromCurrentVelocity(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  current_linear_velocity_ = msg-&gt;twist.linear.x;
  pp_.setCurrentVelocity(current_linear_velocity_);
  is_velocity_set_ = true;
}

void PurePursuitNode::callbackFromWayPoints(const waypoint_follower::laneConstPtr &amp;msg)
{
  if (!msg-&gt;waypoints.empty())
    command_linear_velocity_ = msg-&gt;waypoints.at(0).twist.twist.linear.x;
  else
    command_linear_velocity_ = 0;

  pp_.setCurrentWaypoints(msg-&gt;waypoints);
  is_waypoint_set_ = true;
}

double convertCurvatureToSteeringAngle(const double &amp;wheel_base, const double &amp;kappa)
{
  return atan(wheel_base * kappa);
}

}  // waypoint_follower
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="f5050cd85ccd230400c0977e330895415905347a" fix_time="517,33963">
		<msg>New simulator with angle and position errors</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/wf_simulator/wf_simulator.cpp" new_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/wf_simulator/wf_simulator.cpp">
				<diff>@@ -37,6 +37,7 @@
 #include &lt;tf/tf.h&gt;
 #include &lt;iostream&gt;
 #include &lt;std_msgs/Int32.h&gt;
+#include &lt;random&gt;
 
 #include &quot;waypoint_follower/libwaypoint_follower.h&quot;
 
@@ -56,6 +57,8 @@ WayPoints _current_waypoints;
 ros::Publisher g_odometry_publisher;
 ros::Publisher g_velocity_publisher;
 int32_t g_closest_waypoint = -1;
+double g_position_error;
+double g_angle_error;
 
 constexpr int LOOP_RATE = 50; // 50Hz
 
@@ -180,10 +183,17 @@ void publishOdometry()
   current_time = ros::Time::now();
 
   // compute odometry in a typical way given the velocities of the robot
+  std::random_device rnd;
+  std::mt19937 mt(rnd());
+  std::uniform_real_distribution&lt;double&gt; rnd_dist(0.0, 2.0);
+  double rnd_value_x = rnd_dist(mt) - 1.0;
+  double rnd_value_y = rnd_dist(mt) - 1.0;
+  double rnd_value_th = rnd_dist(mt) - 1.0;
+
   double dt = (current_time - last_time).toSec();
-  double delta_x = (vx * cos(th)) * dt;
-  double delta_y = (vx * sin(th)) * dt;
-  double delta_th = vth * dt;
+  double delta_x = (vx * cos(th)) * dt + rnd_value_x * g_position_error;
+  double delta_y = (vx * sin(th)) * dt + rnd_value_y * g_position_error;
+  double delta_th = vth * dt + rnd_value_th * g_angle_error * M_PI / 180;
 
   pose.position.x += delta_x;
   pose.position.y += delta_y;
@@ -245,6 +255,10 @@ int main(int argc, char **argv)
   double accel_rate;
   private_nh.param(&quot;accel_rate&quot;,accel_rate,double(1.0));
   ROS_INFO_STREAM(&quot;accel_rate : &quot; &lt;&lt; accel_rate);
+
+
+  private_nh.param(&quot;position_error&quot;, g_position_error, double(0.0));
+  private_nh.param(&quot;angle_error&quot;, g_angle_error, double(0.0));
   // publish topic
   g_odometry_publisher = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;sim_pose&quot;, 10);
   g_velocity_publisher = nh.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;sim_velocity&quot;, 10);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;tf/tf.h&gt;
#include &lt;iostream&gt;
#include &lt;std_msgs/Int32.h&gt;

#include &quot;waypoint_follower/libwaypoint_follower.h&quot;

namespace
{
geometry_msgs::Twist _current_velocity;

const std::string SIMULATION_FRAME = &quot;sim_base_link&quot;;
const std::string MAP_FRAME = &quot;map&quot;;

geometry_msgs::Pose _initial_pose;
bool _initial_set = false;
bool _pose_set = false;
bool _waypoint_set = false;
bool g_is_closest_waypoint_subscribed = false;
WayPoints _current_waypoints;
ros::Publisher g_odometry_publisher;
ros::Publisher g_velocity_publisher;
int32_t g_closest_waypoint = -1;

constexpr int LOOP_RATE = 50; // 50Hz

void CmdCallBack(const geometry_msgs::TwistStampedConstPtr &amp;msg, double accel_rate)
{

  static double previous_linear_velocity = 0;

  if(_current_velocity.linear.x &lt; msg-&gt;twist.linear.x)
  {
    _current_velocity.linear.x = previous_linear_velocity + accel_rate / (double)LOOP_RATE;

    if(_current_velocity.linear.x &gt; msg-&gt;twist.linear.x)
    {
      _current_velocity.linear.x = msg-&gt;twist.linear.x;
    }
  }
  else
  {
    _current_velocity.linear.x = previous_linear_velocity - accel_rate / (double)LOOP_RATE;

    if(_current_velocity.linear.x &lt; msg-&gt;twist.linear.x)
    {
      _current_velocity.linear.x = msg-&gt;twist.linear.x;
    }
  }

  previous_linear_velocity = _current_velocity.linear.x;

  _current_velocity.angular.z = msg-&gt;twist.angular.z;


  //_current_velocity = msg-&gt;twist;
}

void getTransformFromTF(const std::string parent_frame, const std::string child_frame, tf::StampedTransform &amp;transform)
{
  static tf::TransformListener listener;

  while (1)
  {
    try
    {
      listener.lookupTransform(parent_frame, child_frame, ros::Time(0), transform);
      break;
    }
    catch (tf::TransformException ex)
    {
      ROS_ERROR(&quot;%s&quot;, ex.what());
      ros::Duration(1.0).sleep();
    }
  }
}

void initialposeCallback(const geometry_msgs::PoseWithCovarianceStampedConstPtr &amp;input)
{
  tf::StampedTransform transform;
  getTransformFromTF(MAP_FRAME, &quot;world&quot;, transform);

  _initial_pose.position.x = input-&gt;pose.pose.position.x + transform.getOrigin().x();
  _initial_pose.position.y = input-&gt;pose.pose.position.y + transform.getOrigin().y();
  _initial_pose.position.z = input-&gt;pose.pose.position.z + transform.getOrigin().z();
  _initial_pose.orientation = input-&gt;pose.pose.orientation;

  _initial_set = true;
  _pose_set = false;
}

void callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  _initial_pose = msg-&gt;pose;
  _initial_set = true;
}

void waypointCallback(const waypoint_follower::laneConstPtr &amp;msg)
{
  // _path_og.setPath(msg);
  _current_waypoints.setPath(*msg);
  _waypoint_set = true;
  //ROS_INFO_STREAM(&quot;waypoint subscribed&quot;);
}

void callbackFromClosestWaypoint(const std_msgs::Int32ConstPtr &amp;msg)
{
  g_closest_waypoint = msg-&gt;data;
  g_is_closest_waypoint_subscribed = true;
}

void publishOdometry()
{
  static ros::Time current_time = ros::Time::now();
  static ros::Time last_time = ros::Time::now();
  static geometry_msgs::Pose pose;
  static double th = 0;
  static tf::TransformBroadcaster odom_broadcaster;

  if (!_pose_set)
  {
    pose.position = _initial_pose.position;
    pose.orientation = _initial_pose.orientation;
    th = tf::getYaw(pose.orientation);
    ROS_INFO_STREAM(&quot;pose set : (&quot; &lt;&lt; pose.position.x &lt;&lt; &quot; &quot; &lt;&lt; pose.position.y &lt;&lt; &quot; &quot; &lt;&lt; pose.position.z &lt;&lt; &quot; &quot; &lt;&lt; th
                                   &lt;&lt; &quot;)&quot;);
    _pose_set = true;
  }

  /*int closest_waypoint = getClosestWaypoint(_current_waypoints.getCurrentWaypoints(), pose);
  if (closest_waypoint == -1)
  {
    ROS_INFO(&quot;cannot publish odometry because closest waypoint is -1.&quot;);
    return;
  }
  else
  {
    pose.position.z = _current_waypoints.getWaypointPosition(closest_waypoint).z;
  }
*/if(_waypoint_set &amp;&amp; g_is_closest_waypoint_subscribed)
    pose.position.z = _current_waypoints.getWaypointPosition(g_closest_waypoint).z;

  double vx = _current_velocity.linear.x;
  double vth = _current_velocity.angular.z;
  current_time = ros::Time::now();

  // compute odometry in a typical way given the velocities of the robot
  double dt = (current_time - last_time).toSec();
  double delta_x = (vx * cos(th)) * dt;
  double delta_y = (vx * sin(th)) * dt;
  double delta_th = vth * dt;

  pose.position.x += delta_x;
  pose.position.y += delta_y;
  th += delta_th;
  pose.orientation = tf::createQuaternionMsgFromYaw(th);

  // std::cout &lt;&lt; &quot;delta (x y th) : (&quot; &lt;&lt; delta_x &lt;&lt; &quot; &quot; &lt;&lt; delta_y &lt;&lt; &quot; &quot; &lt;&lt; delta_th &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
  // std::cout &lt;&lt; &quot;current_velocity(linear.x angular.z) : (&quot; &lt;&lt; _current_velocity.linear.x &lt;&lt; &quot; &quot; &lt;&lt;
  // _current_velocity.angular.z &lt;&lt; &quot;)&quot;&lt;&lt; std::endl;
  //    std::cout &lt;&lt; &quot;current_pose : (&quot; &lt;&lt; pose.position.x &lt;&lt; &quot; &quot; &lt;&lt; pose.position.y&lt;&lt; &quot; &quot; &lt;&lt; pose.position.z &lt;&lt; &quot; &quot; &lt;&lt;
  //    th &lt;&lt; &quot;)&quot; &lt;&lt; std::endl &lt;&lt; std::endl;

  // first, we'll publish the transform over tf
  geometry_msgs::TransformStamped odom_trans;
  odom_trans.header.stamp = current_time;
  odom_trans.header.frame_id = MAP_FRAME;
  odom_trans.child_frame_id = SIMULATION_FRAME;

  odom_trans.transform.translation.x = pose.position.x;
  odom_trans.transform.translation.y = pose.position.y;
  odom_trans.transform.translation.z = pose.position.z;
  odom_trans.transform.rotation = pose.orientation;

  // send the transform
  odom_broadcaster.sendTransform(odom_trans);

  // next, we'll publish the odometry message over ROS
  std_msgs::Header h;
  h.stamp = current_time;
  h.frame_id = MAP_FRAME;

  geometry_msgs::PoseStamped ps;
  ps.header = h;
  ps.pose = pose;

  geometry_msgs::TwistStamped ts;
  ts.header = h;
  ts.twist.linear.x = vx;
  ts.twist.angular.z = vth;

  // publish the message
  g_odometry_publisher.publish(ps);
  g_velocity_publisher.publish(ts);

  last_time = current_time;
}
}
int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;wf_simulator&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  std::string initialize_source;
  private_nh.getParam(&quot;initialize_source&quot;, initialize_source);
  ROS_INFO_STREAM(&quot;initialize_source : &quot; &lt;&lt; initialize_source);

  double accel_rate;
  private_nh.param(&quot;accel_rate&quot;,accel_rate,double(1.0));
  ROS_INFO_STREAM(&quot;accel_rate : &quot; &lt;&lt; accel_rate);
  // publish topic
  g_odometry_publisher = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;sim_pose&quot;, 10);
  g_velocity_publisher = nh.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;sim_velocity&quot;, 10);

  // subscribe topic
  ros::Subscriber cmd_subscriber = nh.subscribe&lt;geometry_msgs::TwistStamped&gt;(&quot;twist_cmd&quot;, 10, boost::bind(CmdCallBack, _1, accel_rate));
  ros::Subscriber waypoint_subcscriber = nh.subscribe(&quot;base_waypoints&quot;, 10, waypointCallback);
  ros::Subscriber closest_sub = nh.subscribe(&quot;closest_waypoint&quot;, 10, callbackFromClosestWaypoint);
  ros::Subscriber initialpose_subscriber;

  if (initialize_source == &quot;Rviz&quot;)
  {
    initialpose_subscriber = nh.subscribe(&quot;initialpose&quot;, 10, initialposeCallback);
  }
  else if (initialize_source == &quot;ndt_localizer&quot;)
  {
    initialpose_subscriber = nh.subscribe(&quot;ndt_pose&quot;, 10, callbackFromPoseStamped);
  }
  else if (initialize_source == &quot;GNSS&quot;)
  {
    initialpose_subscriber = nh.subscribe(&quot;gnss_pose&quot;, 10, callbackFromPoseStamped);
  }
  else
  {
    ROS_INFO(&quot;Set pose initializer!!&quot;);
  }

  ros::Rate loop_rate(LOOP_RATE);
  while (ros::ok())
  {
    ros::spinOnce();  // check subscribe topic

    /*if (!_waypoint_set)
    {
      loop_rate.sleep();
      continue;
    }*/

    if (!_initial_set)
    {
      loop_rate.sleep();
      continue;
    }

    publishOdometry();

    loop_rate.sleep();
  }

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="036ddc3091761cd8731d8aad37d86089f3daf4c2" fix_time="0,0">
		<msg>Fix Indent</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine.cpp" new_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine.cpp">
				<diff>@@ -32,24 +32,23 @@
 
 namespace state_machine
 {
-
 void StateTrafficLightStop::update(StateContext *context)
 {
-  //if light is GREEN, Go to MOVE_FORWARD
-  if(context-&gt;getLightColor() == TrafficLight::GREEN)
-  context-&gt;setState(StateMoveForward::create());
+  // if light is GREEN, Go to MOVE_FORWARD
+  if (context-&gt;getLightColor() == TrafficLight::GREEN)
+    context-&gt;setState(StateMoveForward::create());
 }
 
 void StateMoveForward::update(StateContext *context)
 {
-  //if light is RED, Go to TRAFFIC_LIGHT_STOP
+  // if light is RED, Go to TRAFFIC_LIGHT_STOP
   if (context-&gt;getLightColor() == TrafficLight::RED)
     context-&gt;setState(StateTrafficLightStop::create());
 }
 
 void StateLaneChange::update(StateContext *context)
 {
-  //lane change
+  // lane change
 }
 
 }  // state_machine
\ No newline at end of file
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;state_machine.h&quot;

namespace state_machine
{

void StateTrafficLightStop::update(StateContext *context)
{
  //if light is GREEN, Go to MOVE_FORWARD
  if(context-&gt;getLightColor() == TrafficLight::GREEN)
  context-&gt;setState(StateMoveForward::create());
}

void StateMoveForward::update(StateContext *context)
{
  //if light is RED, Go to TRAFFIC_LIGHT_STOP
  if (context-&gt;getLightColor() == TrafficLight::RED)
    context-&gt;setState(StateTrafficLightStop::create());
}

void StateLaneChange::update(StateContext *context)
{
  //lane change
}

}  // state_machine</old_file>
			</file>
			<file old_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine.h" new_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine.h">
				<diff>@@ -36,7 +36,6 @@
 
 namespace state_machine
 {
-
 enum class StateList : int32_t
 {
   MOVE_FORWARD,
@@ -69,7 +68,7 @@ typename std::underlying_type&lt;T&gt;::type enumToInteger(T t)
   return static_cast&lt;typename std::underlying_type&lt;T&gt;::type&gt;(t);
 }
 
-//Forward Decralation
+// Forward Decralation
 class StateContext;
 
 // abstract class for states
@@ -78,8 +77,14 @@ class BaseState
 public:
   virtual ~BaseState() = default;
   virtual void update(StateContext *context) = 0;
-  virtual int32_t getStateName() { return 0;};
-  virtual std::unique_ptr&lt;std::string&gt; getStateNameString() { return 0;};
+  virtual int32_t getStateName()
+  {
+    return 0;
+  };
+  virtual std::unique_ptr&lt;std::string&gt; getStateNameString()
+  {
+    return 0;
+  };
 };
 
 // State : MOVE_FORWARD
@@ -129,7 +134,7 @@ private:
 // State : LANE_CHANGE
 class StateLaneChange : public BaseState
 {
- public:
+public:
   void update(StateContext *context) override;
   int32_t getStateName() override
   {
@@ -144,14 +149,14 @@ class StateLaneChange : public BaseState
     return std::unique_ptr&lt;BaseState&gt;(new StateLaneChange);
   };
 
- private:
+private:
   StateLaneChange() = default;
 };
 
 // State : EMERGENCY
 class StateEmergency : public BaseState
 {
- public:
+public:
   void update(StateContext *context) override;
   int32_t getStateName() override
   {
@@ -166,14 +171,14 @@ class StateEmergency : public BaseState
     return std::unique_ptr&lt;BaseState&gt;(new StateEmergency);
   };
 
- private:
+private:
   StateEmergency() = default;
 };
 
 // State : MISSION_COMPLETE
 class StateMissionComplete : public BaseState
 {
- public:
+public:
   void update(StateContext *context) override;
   int32_t getStateName() override
   {
@@ -188,18 +193,14 @@ class StateMissionComplete : public BaseState
     return std::unique_ptr&lt;BaseState&gt;(new StateMissionComplete);
   };
 
- private:
+private:
   StateMissionComplete() = default;
 };
 
-
 class StateContext
 {
 public:
-  StateContext()
-    : state_(StateMoveForward::create())
-    , light_color_(TrafficLight::UNKNOWN)
-  {};
+  StateContext() : state_(StateMoveForward::create()), light_color_(TrafficLight::UNKNOWN){};
   void setState(std::unique_ptr&lt;BaseState&gt; newState)
   {
     state_ = std::move(newState);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef STATE_MACHINE_H
#define STATE_MACHINE_H

#include &lt;memory&gt;
#include &lt;iostream&gt;

namespace state_machine
{

enum class StateList : int32_t
{
  MOVE_FORWARD,
  TRAFFIC_LIGHT_STOP,
  LANE_CHANGE,
  MISSION_COMPLETE,

  EMERGENCY = -1,
};

enum class TrafficLight : int32_t
{
  RED,
  GREEN,
  UNKNOWN,
};

enum class ChangeFlag : int32_t
{
  straight,
  right,
  left,

  unknown = -1,
};

template &lt;class T&gt;
typename std::underlying_type&lt;T&gt;::type enumToInteger(T t)
{
  return static_cast&lt;typename std::underlying_type&lt;T&gt;::type&gt;(t);
}

//Forward Decralation
class StateContext;

// abstract class for states
class BaseState
{
public:
  virtual ~BaseState() = default;
  virtual void update(StateContext *context) = 0;
  virtual int32_t getStateName() { return 0;};
  virtual std::unique_ptr&lt;std::string&gt; getStateNameString() { return 0;};
};

// State : MOVE_FORWARD
class StateMoveForward : public BaseState
{
public:
  void update(StateContext *context) override;
  int32_t getStateName() override
  {
    return enumToInteger(StateList::MOVE_FORWARD);
  }
  std::unique_ptr&lt;std::string&gt; getStateNameString() override
  {
    return std::unique_ptr&lt;std::string&gt;(new std::string(&quot;MOVE_FORWARD&quot;));
  }
  static std::unique_ptr&lt;BaseState&gt; create()
  {
    return std::unique_ptr&lt;BaseState&gt;(new StateMoveForward);
  };

private:
  StateMoveForward() = default;
};

// State : TRAFFIC_LIGHT_STOP
class StateTrafficLightStop : public BaseState
{
public:
  void update(StateContext *context) override;
  int32_t getStateName() override
  {
    return enumToInteger(StateList::TRAFFIC_LIGHT_STOP);
  }
  std::unique_ptr&lt;std::string&gt; getStateNameString() override
  {
    return std::unique_ptr&lt;std::string&gt;(new std::string(&quot;TRAFFIC_LIGHT_STOP&quot;));
  }
  static std::unique_ptr&lt;BaseState&gt; create()
  {
    return std::unique_ptr&lt;BaseState&gt;(new StateTrafficLightStop);
  };

private:
  StateTrafficLightStop() = default;
};

// State : LANE_CHANGE
class StateLaneChange : public BaseState
{
 public:
  void update(StateContext *context) override;
  int32_t getStateName() override
  {
    return enumToInteger(StateList::LANE_CHANGE);
  }
  std::unique_ptr&lt;std::string&gt; getStateNameString() override
  {
    return std::unique_ptr&lt;std::string&gt;(new std::string(&quot;LANE_CHANGE&quot;));
  }
  static std::unique_ptr&lt;BaseState&gt; create()
  {
    return std::unique_ptr&lt;BaseState&gt;(new StateLaneChange);
  };

 private:
  StateLaneChange() = default;
};

// State : EMERGENCY
class StateEmergency : public BaseState
{
 public:
  void update(StateContext *context) override;
  int32_t getStateName() override
  {
    return enumToInteger(StateList::EMERGENCY);
  }
  std::unique_ptr&lt;std::string&gt; getStateNameString() override
  {
    return std::unique_ptr&lt;std::string&gt;(new std::string(&quot;EMERGENCY&quot;));
  }
  static std::unique_ptr&lt;BaseState&gt; create()
  {
    return std::unique_ptr&lt;BaseState&gt;(new StateEmergency);
  };

 private:
  StateEmergency() = default;
};

// State : MISSION_COMPLETE
class StateMissionComplete : public BaseState
{
 public:
  void update(StateContext *context) override;
  int32_t getStateName() override
  {
    return enumToInteger(StateList::MISSION_COMPLETE);
  }
  std::unique_ptr&lt;std::string&gt; getStateNameString() override
  {
    return std::unique_ptr&lt;std::string&gt;(new std::string(&quot;MISSION_COMPLETE&quot;));
  }
  static std::unique_ptr&lt;BaseState&gt; create()
  {
    return std::unique_ptr&lt;BaseState&gt;(new StateMissionComplete);
  };

 private:
  StateMissionComplete() = default;
};


class StateContext
{
public:
  StateContext()
    : state_(StateMoveForward::create())
    , light_color_(TrafficLight::UNKNOWN)
  {};
  void setState(std::unique_ptr&lt;BaseState&gt; newState)
  {
    state_ = std::move(newState);
  };
  void update()
  {
    state_-&gt;update(this);
  }
  void setLightColor(const int32_t &amp;msg)
  {
    light_color_ = static_cast&lt;TrafficLight&gt;(msg);
  }
  void setChangeFlag(const int32_t &amp;msg)
  {
    change_flag_ = static_cast&lt;ChangeFlag&gt;(msg);
  }

  TrafficLight getLightColor() const
  {
    return light_color_;
  }
  int32_t getCurrentState() const
  {
    return state_-&gt;getStateName();
  }
  std::unique_ptr&lt;std::string&gt; getCurrentStateString() const
  {
    return state_-&gt;getStateNameString();
  }

private:
  std::unique_ptr&lt;BaseState&gt; state_;
  TrafficLight light_color_;
  ChangeFlag change_flag_;
};

}  // state_machine
#endif  // STATE_MACHINE_H</old_file>
			</file>
			<file old_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine_core.cpp" new_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine_core.cpp">
				<diff>@@ -34,9 +34,7 @@
 namespace state_machine
 {
 // Constructor
-StateMachineNode::StateMachineNode()
-  : private_nh_(&quot;~&quot;)
-  , sc_()
+StateMachineNode::StateMachineNode() : private_nh_(&quot;~&quot;), sc_()
 {
   initForROS();
 }
@@ -49,14 +47,14 @@ StateMachineNode::~StateMachineNode()
 void StateMachineNode::initForROS()
 {
   // ros parameter settings
-  private_nh_.param&lt;bool&gt;(&quot;is_manual_light_detection&quot;,is_manual_light_detection_,true);
+  private_nh_.param&lt;bool&gt;(&quot;is_manual_light_detection&quot;, is_manual_light_detection_, true);
 
   // setup subscriber
   sub1_ = nh_.subscribe(&quot;light_color&quot;, 100, &amp;StateMachineNode::callbackFromLightColor, this);
   sub2_ = nh_.subscribe(&quot;light_color_managed&quot;, 100, &amp;StateMachineNode::callbackFromLightColorManaged, this);
 
   // setup publisher
-  pub_ = nh_.advertise&lt;std_msgs::String&gt;(&quot;state&quot;,10);
+  pub_ = nh_.advertise&lt;std_msgs::String&gt;(&quot;state&quot;, 10);
 }
 
 void StateMachineNode::run()
@@ -88,7 +86,6 @@ void StateMachineNode::callbackFromLightColor(const runtime_manager::traffic_lig
   sc_.setLightColor(msg-&gt;traffic_light);
   sc_.update();
   publish();
-
 }
 
 void StateMachineNode::callbackFromLightColorManaged(const runtime_manager::traffic_lightConstPtr&amp; msg)
@@ -102,4 +99,4 @@ void StateMachineNode::callbackFromLightColorManaged(const runtime_manager::traf
   publish();
 }
 
-} //state_machine
+}  // state_machine
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;state_machine_core.h&quot;

namespace state_machine
{
// Constructor
StateMachineNode::StateMachineNode()
  : private_nh_(&quot;~&quot;)
  , sc_()
{
  initForROS();
}

// Destructor
StateMachineNode::~StateMachineNode()
{
}

void StateMachineNode::initForROS()
{
  // ros parameter settings
  private_nh_.param&lt;bool&gt;(&quot;is_manual_light_detection&quot;,is_manual_light_detection_,true);

  // setup subscriber
  sub1_ = nh_.subscribe(&quot;light_color&quot;, 100, &amp;StateMachineNode::callbackFromLightColor, this);
  sub2_ = nh_.subscribe(&quot;light_color_managed&quot;, 100, &amp;StateMachineNode::callbackFromLightColorManaged, this);

  // setup publisher
  pub_ = nh_.advertise&lt;std_msgs::String&gt;(&quot;state&quot;,10);
}

void StateMachineNode::run()
{
  ros::spin();
}

void StateMachineNode::publish() const
{
  /*
  std_msgs::Int32 msg;
  msg.data = sc_.getCurrentState();
  ROS_INFO(&quot;Current State: %d&quot;,sc_.getCurrentState());
  pub_.publish(msg);
  */

  std_msgs::String msg;
  msg.data = *sc_.getCurrentStateString();
  ROS_INFO_STREAM(&quot;Current State String : &quot; &lt;&lt; msg.data);
  pub_.publish(msg);
}

void StateMachineNode::callbackFromLightColor(const runtime_manager::traffic_lightConstPtr&amp; msg)
{
  ROS_INFO(&quot;Light color callback&quot;);
  if (is_manual_light_detection_)
    return;

  sc_.setLightColor(msg-&gt;traffic_light);
  sc_.update();
  publish();

}

void StateMachineNode::callbackFromLightColorManaged(const runtime_manager::traffic_lightConstPtr&amp; msg)
{
  ROS_INFO(&quot;Light color managed callback&quot;);
  if (!is_manual_light_detection_)
    return;

  sc_.setLightColor(msg-&gt;traffic_light);
  sc_.update();
  publish();
}

} //state_machine
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine_core.h" new_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine_core.h">
				<diff>@@ -45,14 +45,12 @@ namespace state_machine
 class StateMachineNode
 {
 public:
-
   StateMachineNode();
   ~StateMachineNode();
 
   void run();
 
 private:
-
   // handle
   ros::NodeHandle nh_;
   ros::NodeHandle private_nh_;
@@ -64,7 +62,7 @@ private:
   ros::Publisher pub_;
 
   // subscriber
-  ros::Subscriber sub1_,sub2_;
+  ros::Subscriber sub1_, sub2_;
 
   // variables
   bool is_manual_light_detection_;
@@ -79,5 +77,5 @@ private:
   // functions
   void publish() const;
 };
-} // state_machine
+}  // state_machine
 #endif  // STATE_MACHINE_CORE_H
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef STATE_MACHINE_CORE_H
#define STATE_MACHINE_CORE_H

// ROS includes
#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;std_msgs/Int32.h&gt;

// User Defined includes
#include &quot;runtime_manager/traffic_light.h&quot;
#include &quot;state_machine.h&quot;

namespace state_machine
{
class StateMachineNode
{
public:

  StateMachineNode();
  ~StateMachineNode();

  void run();

private:

  // handle
  ros::NodeHandle nh_;
  ros::NodeHandle private_nh_;

  // State context class
  StateContext sc_;

  // publisher
  ros::Publisher pub_;

  // subscriber
  ros::Subscriber sub1_,sub2_;

  // variables
  bool is_manual_light_detection_;

  // callbacks
  void callbackFromLightColor(const runtime_manager::traffic_lightConstPtr &amp;msg);
  void callbackFromLightColorManaged(const runtime_manager::traffic_lightConstPtr &amp;msg);

  // initializer
  void initForROS();

  // functions
  void publish() const;
};
} // state_machine
#endif  // STATE_MACHINE_CORE_H
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine_node.cpp" new_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine_node.cpp">
				<diff>@@ -38,6 +38,6 @@ int main(int argc, char **argv)
   ros::init(argc, argv, &quot;state_machine&quot;);
   state_machine::StateMachineNode smn;
   smn.run();
- 
+
   return 0;
 }
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

// ROS Includes
#include &lt;ros/ros.h&gt;

#include &quot;state_machine_core.h&quot;

int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;state_machine&quot;);
  state_machine::StateMachineNode smn;
  smn.run();
 
  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="2fc6e912f5e2994d8662f2db6033320451892afa" fix_time="0,2045">
		<msg>Fix if condition</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine.cpp" new_path="ros/src/computing/planning/state/state_machine/nodes/state_machine/state_machine.cpp">
				<diff>@@ -43,13 +43,13 @@ void StateMoveForward::update(StateContext *context)
   if (context-&gt;getLightColor() == TrafficLight::RED)
     context-&gt;setState(StateTrafficLightStop::create());
 
-  if(context-&gt;getChangeFlag() != ChangeFlag::straight)
+  if(context-&gt;getChangeFlag() == ChangeFlag::right || context-&gt;getChangeFlag() == ChangeFlag::left)
     context-&gt;setState(StateLaneChange::create());
 }
 
 void StateLaneChange::update(StateContext *context)
 {
-  if(context-&gt;getChangeFlag() != ChangeFlag::right || context-&gt;getChangeFlag() != ChangeFlag::left)
+  if(context-&gt;getChangeFlag() == ChangeFlag::straight)
     context-&gt;setState(StateMoveForward::create());
 }
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;state_machine.h&quot;

namespace state_machine
{
void StateTrafficLightStop::update(StateContext *context)
{
  if (context-&gt;getLightColor() == TrafficLight::GREEN)
    context-&gt;setState(StateMoveForward::create());
}

void StateMoveForward::update(StateContext *context)
{
  if (context-&gt;getLightColor() == TrafficLight::RED)
    context-&gt;setState(StateTrafficLightStop::create());

  if(context-&gt;getChangeFlag() != ChangeFlag::straight)
    context-&gt;setState(StateLaneChange::create());
}

void StateLaneChange::update(StateContext *context)
{
  if(context-&gt;getChangeFlag() != ChangeFlag::right || context-&gt;getChangeFlag() != ChangeFlag::left)
    context-&gt;setState(StateMoveForward::create());
}

void StateStopSignStop::update(StateContext *context)
{
  // stop sign stop
}

}  // state_machine</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="763bafdccf7d5f9d9ed0db13d8570d86ef3ff1f9" fix_time="33,2978">
		<msg>Fix bug for searching closest wapoint</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp">
				<diff>@@ -220,8 +220,8 @@ bool LaneSelectNode::getClosestWaypointNumberForEachLanes()
 {
   for (auto &amp;el : tuple_vec_)
   {
-    std::get&lt;1&gt;(el) =
-        getClosestWaypointNumber(std::get&lt;0&gt;(el), current_pose_.pose, current_velocity_.twist, std::get&lt;1&gt;(el));
+    std::get&lt;1&gt;(el) = getClosestWaypointNumber(std::get&lt;0&gt;(el), current_pose_.pose, current_velocity_.twist,
+                                               std::get&lt;1&gt;(el), distance_threshold_);
     ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(el));
 
     std::get&lt;2&gt;(el) = (std::get&lt;1&gt;(el) != -1)
@@ -735,7 +735,8 @@ double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry
 
 // get closest waypoint from current pose
 int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
-                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number)
+                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number,
+                                 const double distance_threshold)
 {
   if (current_lane.waypoints.empty())
     return -1;
@@ -761,18 +762,16 @@ int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, co
   }
   else
   {
-    double ratio = 3;
-    double minimum_dt = 2.0;
-    double dt = current_velocity.linear.x * ratio &gt; minimum_dt ? current_velocity.linear.x * ratio : minimum_dt;
-
-    if (dt &lt;
+    if (distance_threshold &lt;
         getTwoDimensionalDistance(current_lane.waypoints.at(previous_number).pose.pose.position, current_pose.position))
     {
       ROS_WARN(&quot;Current_pose is far away from previous closest waypoint. Initilized...&quot;);
       return -1;
     }
 
-    idx_vec.reserve(static_cast&lt;uint32_t&gt;(dt));
+    double ratio = 3;
+    double minimum_dt = 2.0;
+    double dt = current_velocity.linear.x * ratio &gt; minimum_dt ? current_velocity.linear.x * ratio : minimum_dt;
 
     auto range_max = static_cast&lt;uint32_t&gt;(previous_number + dt) &lt; current_lane.waypoints.size()
                          ? static_cast&lt;uint32_t&gt;(previous_number + dt)
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;lane_select_core.h&quot;

namespace lane_planner
{
// Constructor
LaneSelectNode::LaneSelectNode()
  : private_nh_(&quot;~&quot;)
  , current_lane_idx_(-1)
  , right_lane_idx_(-1)
  , left_lane_idx_(-1)
  , is_lane_array_subscribed_(false)
  , is_current_pose_subscribed_(false)
  , is_current_velocity_subscribed_(false)
  , is_current_state_subscribed_(false)
  , last_change_time_(ros::Time::now())
  , current_change_flag_(ChangeFlag::unknown)
  , current_state_(&quot;UNKNOWN&quot;)
  , LANE_SIZE_(1.0)
{
  initForROS();
}

// Destructor
LaneSelectNode::~LaneSelectNode()
{
}

void LaneSelectNode::initForROS()
{
  // setup subscriber
  sub1_ = nh_.subscribe(&quot;traffic_waypoints_array&quot;, 100, &amp;LaneSelectNode::callbackFromLaneArray, this);
  sub2_ = nh_.subscribe(&quot;current_pose&quot;, 100, &amp;LaneSelectNode::callbackFromPoseStamped, this);
  sub3_ = nh_.subscribe(&quot;current_velocity&quot;, 100, &amp;LaneSelectNode::callbackFromTwistStamped, this);
  sub4_ = nh_.subscribe(&quot;state&quot;, 100, &amp;LaneSelectNode::callbackFromState, this);

  // setup publisher
  pub1_ = nh_.advertise&lt;waypoint_follower::lane&gt;(&quot;base_waypoints&quot;, 10);
  pub2_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 10);
  pub3_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;change_flag&quot;, 10);
  vis_pub1_ = nh_.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;lane_select_marker&quot;, 10);

  // get from rosparam
  private_nh_.param&lt;int32_t&gt;(&quot;lane_change_interval&quot;, lane_change_interval_, int32_t(2));
  private_nh_.param&lt;double&gt;(&quot;distance_threshold&quot;, distance_threshold_, double(3.0));
}

void LaneSelectNode::processing()
{
  if (!is_current_pose_subscribed_ || !is_lane_array_subscribed_ || !is_current_velocity_subscribed_)
  {
    ROS_WARN(&quot;Necessary topics are not subscribed yet. Waiting...&quot;);
    return;
  }

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    current_lane_idx_ = -1;
    right_lane_idx_ = -1;
    left_lane_idx_ = -1;
    publishVisualizer();
    return;
  }

  // if current_lane_idx_ = -1, find the lane index which has the most closest waypoint
  if (current_lane_idx_ == -1)
  {
    findCurrentLane();
    findNeighborLanes();
    publish();
    publishVisualizer();
    return;
  }

  // if closest waypoint on current lane is -1,
  if (std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) == -1)
  {
    current_lane_idx_ = -1;
    right_lane_idx_ = -1;
    left_lane_idx_ = -1;
    publishVisualizer();
    return;
  }

  if(right_lane_idx_ != -1)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) == -1)
      right_lane_idx_ = -1;
  }
  if(left_lane_idx_ != -1)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) == -1)
      left_lane_idx_ = -1;
  }

  ROS_INFO(&quot;current_lane_idx: %d&quot;, current_lane_idx_);
  ROS_INFO(&quot;right_lane_idx: %d&quot;, right_lane_idx_);
  ROS_INFO(&quot;left_lane_idx: %d&quot;, left_lane_idx_);
  ROS_INFO(&quot;current change_flag: %d&quot;, enumToInteger(std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_))));

  updateChangeFlag();
  if (current_state_ == &quot;LANE_CHANGE&quot;)
    changeLane();

  publish();
  publishVisualizer();
}



void LaneSelectNode::updateChangeFlag()
{
  if(current_change_flag_ == ChangeFlag::unknown || current_change_flag_ == ChangeFlag::straight)
  {
    current_change_flag_ = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));

    if ((current_change_flag_ == ChangeFlag::left &amp;&amp; left_lane_idx_ == -1) ||
        (current_change_flag_ == ChangeFlag::right &amp;&amp; right_lane_idx_ == -1))
      current_change_flag_ = ChangeFlag::straight;
    return;
  }

  // if current change flag is right or left
  double a, b, c;

  if (std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) == 0 ||
                  std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) ==
                    static_cast&lt;int32_t&gt;(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.size()))
  {
    geometry_msgs::Point &amp;closest_p = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_))
                                          .waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)))
                                          .pose.pose.position;
    geometry_msgs::Point &amp;front_of_closest_p = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_))
                                                   .waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) - 1)
                                                   .pose.pose.position;
    getLinearEquation(front_of_closest_p, closest_p, &amp;a, &amp;b, &amp;c);
  }
  else
  {
    geometry_msgs::Point &amp;closest_p = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_))
                                          .waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) - 1)
                                          .pose.pose.position;
    geometry_msgs::Point &amp;front_of_closest_p = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_))
                                                   .waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)))
                                                   .pose.pose.position;
    getLinearEquation(front_of_closest_p, closest_p, &amp;a, &amp;b, &amp;c);
  }
  geometry_msgs::Point &amp;current_point = current_pose_.pose.position;
  double d = getDistanceBetweenLineAndPoint(current_point, a, b, c);

  double threshold = 1.0;
  if(d &lt; threshold)
  {
    current_change_flag_ = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  }
}

void LaneSelectNode::changeLane()
{
  ros::Time current_time = ros::Time::now();
  double dt = (current_time - last_change_time_).toSec();
  if (dt &lt; lane_change_interval_)
    return;

  if (current_change_flag_ == ChangeFlag::right &amp;&amp; right_lane_idx_ != -1)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) != -1)
    {
      current_lane_idx_ = right_lane_idx_;
      findNeighborLanes();
      last_change_time_ = ros::Time::now();
      return;
    }
  }

  if (current_change_flag_ == ChangeFlag::left &amp;&amp; left_lane_idx_ != -1)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) != -1)
    {
      current_lane_idx_ = left_lane_idx_;
      findNeighborLanes();
      last_change_time_ = ros::Time::now();
      return;
    }
  }
}

bool LaneSelectNode::getClosestWaypointNumberForEachLanes()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;1&gt;(el) =
        getClosestWaypointNumber(std::get&lt;0&gt;(el), current_pose_.pose, current_velocity_.twist, std::get&lt;1&gt;(el));
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(el));

    std::get&lt;2&gt;(el) = (std::get&lt;1&gt;(el) != -1)
                          ? static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(el).waypoints.at(std::get&lt;1&gt;(el)).change_flag)
                          : ChangeFlag::unknown;
    ROS_INFO(&quot;change_flag: %d&quot;, enumToInteger(std::get&lt;2&gt;(el)));
  }

  // confirm if all closest waypoint numbers are -1. If so, output warning
  int32_t accum = 0;
  for (const auto &amp;el : tuple_vec_)
  {
    accum += std::get&lt;1&gt;(el);
  }
  if (accum == (-1) * static_cast&lt;int32_t&gt;(tuple_vec_.size()))
  {
    ROS_WARN(&quot;Cannot get closest waypoints. All closest waypoints are changed to -1...&quot;);
    return false;
  }

  return true;
}

void LaneSelectNode::findCurrentLane()
{
  std::vector&lt;uint32_t&gt; idx_vec;
  idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;
    idx_vec.push_back(i);
  }
  current_lane_idx_ = findMostClosestLane(idx_vec, current_pose_.pose.position);
}

int32_t LaneSelectNode::findMostClosestLane(const std::vector&lt;uint32_t&gt; idx_vec, const geometry_msgs::Point p)
{
  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    int32_t closest_number = std::get&lt;1&gt;(tuple_vec_.at(el));
    dist_vec.push_back(
        getTwoDimensionalDistance(p, std::get&lt;0&gt;(tuple_vec_.at(el)).waypoints.at(closest_number).pose.pose.position));
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  return idx_vec.at(std::distance(dist_vec.begin(), itr));
}

void LaneSelectNode::findNeighborLanes()
{
  int32_t current_closest_num = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const geometry_msgs::Pose &amp;current_closest_pose =
      std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.at(current_closest_num).pose.pose;

  std::vector&lt;uint32_t&gt; left_lane_idx_vec;
  left_lane_idx_vec.reserve(tuple_vec_.size());
  std::vector&lt;uint32_t&gt; right_lane_idx_vec;
  right_lane_idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (i == static_cast&lt;uint32_t&gt;(current_lane_idx_) || std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    int32_t target_num = std::get&lt;1&gt;(tuple_vec_.at(i));
    const geometry_msgs::Point &amp;target_p = std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(target_num).pose.pose.position;

    geometry_msgs::Point converted_p;
    convertPointIntoRelativeCoordinate(target_p, current_closest_pose, &amp;converted_p);

    ROS_INFO(&quot;distance: %lf&quot;, converted_p.y);
    if (fabs(converted_p.y) &gt; distance_threshold_)
    {
      ROS_INFO(&quot;%d lane is far from current lane...&quot;, i);
      continue;
    }

    if (converted_p.y &gt; 0)
      left_lane_idx_vec.push_back(i);
    else
      right_lane_idx_vec.push_back(i);
  }

  if (!left_lane_idx_vec.empty())
    left_lane_idx_ = findMostClosestLane(left_lane_idx_vec, current_closest_pose.position);
  else
    left_lane_idx_ = -1;

  if (!right_lane_idx_vec.empty())
    right_lane_idx_ = findMostClosestLane(right_lane_idx_vec, current_closest_pose.position);
  else
    right_lane_idx_ = -1;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createCurrentLaneMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;current_lane_marker&quot;;

  if (current_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker-&gt;type = visualization_msgs::Marker::LINE_STRIP;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.05;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;
  marker-&gt;color = color_current;

  marker-&gt;points = *createRectangleFromWaypoints(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints, LANE_SIZE_);

  return marker;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createRightLaneMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;right_lane_marker&quot;;

  if (right_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker-&gt;type = visualization_msgs::Marker::LINE_STRIP;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker-&gt;color = change_flag == ChangeFlag::right ? color_neighbor_change : color_neighbor;

  marker-&gt;points = *createRectangleFromWaypoints(std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_)).waypoints, LANE_SIZE_);

  return marker;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createLeftLaneMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;left_lane_marker&quot;;

  if (left_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker-&gt;type = visualization_msgs::Marker::LINE_STRIP;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker-&gt;color = change_flag == ChangeFlag::left ? color_neighbor_change : color_neighbor;

  marker-&gt;points = *createRectangleFromWaypoints(std::get&lt;0&gt;(tuple_vec_.at(left_lane_idx_)).waypoints, LANE_SIZE_);

  return marker;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createClosestWaypointsMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  std_msgs::ColorRGBA color_closest_wp;
  color_closest_wp.r = 1.0;
  color_closest_wp.b = 1.0;
  color_closest_wp.g = 1.0;
  color_closest_wp.a = 1.0;

  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;closest_waypoints_marker&quot;;
  marker-&gt;type = visualization_msgs::Marker::POINTS;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.5;
  marker-&gt;color = color_closest_wp;

  marker-&gt;points.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    marker-&gt;points.push_back(
        std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(i))).pose.pose.position);
  }

  return marker;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createCurrentLaneFlagMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;current_lane_flag_marker&quot;;

  if (current_lane_idx_ == -1)
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  std_msgs::ColorRGBA red;
  red.r = 1.0;
  red.a = 1.0;

  marker-&gt;type = visualization_msgs::Marker::LINE_STRIP;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.05;
  marker-&gt;color = red;

  const int32_t &amp;start = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const size_t &amp;end = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.size();
  const auto &amp;wps = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints;

  std::vector&lt;waypoint_follower::waypoint&gt; wps_extracted;
  for (uint32_t i = start; i &lt; end; i++)
  {
    if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::right)
    {
      wps_extracted.push_back(wps.at(i));
      if (i == end - 1)
        break;

      if (static_cast&lt;ChangeFlag&gt;(wps.at(i + 1).change_flag) != ChangeFlag::right)
        break;
    }
    else if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::left)
    {
      wps_extracted.push_back(wps.at(i));
      if (i == end - 1)
        break;

      if (static_cast&lt;ChangeFlag&gt;(wps.at(i + 1).change_flag) != ChangeFlag::left)
        break;
    }
  }

  if (wps_extracted.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }
  marker-&gt;points = *createRectangleFromWaypoints(wps_extracted, LANE_SIZE_ * 0.8);

  return marker;
}

std::unique_ptr&lt;std::vector&lt;geometry_msgs::Point&gt;&gt;
LaneSelectNode::createRectangleFromWaypoints(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, const double &amp;width)
{
  std::vector&lt;std::tuple&lt;geometry_msgs::Point, geometry_msgs::Point&gt;&gt; vertex;

  for (const auto &amp;el : wps)
  {
    geometry_msgs::Point relative_p1;
    relative_p1.y = width / 2;
    geometry_msgs::Point relative_p2;
    relative_p2.y = -width / 2;
    vertex.push_back(std::make_tuple(*convertPointIntoWorldCoordinate(relative_p1, el.pose.pose),
                                     *convertPointIntoWorldCoordinate(relative_p2, el.pose.pose)));
  }

  std::unique_ptr&lt;std::vector&lt;geometry_msgs::Point&gt;&gt; rectangle(new std::vector&lt;geometry_msgs::Point&gt;);
  for (const auto &amp;el : vertex)
    rectangle-&gt;push_back(std::get&lt;0&gt;(el));

  std::reverse(vertex.begin(), vertex.end());
  for (const auto &amp;el : vertex)
    rectangle-&gt;push_back(std::get&lt;1&gt;(el));
  std::reverse(vertex.begin(), vertex.end());
  rectangle-&gt;push_back(std::get&lt;0&gt;(vertex.at(0)));

  return rectangle;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createCurrentLaneFlagArrowMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);

  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;current_lane_flag_arrow_marker&quot;;

  if (current_lane_idx_ == -1)
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  std_msgs::ColorRGBA red;
  red.r = 1.0;
  red.a = 1.0;

  marker-&gt;type = visualization_msgs::Marker::ARROW;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;color = red;
  marker-&gt;scale.x = 0.25;
  marker-&gt;scale.y = 0.5;

  const int32_t &amp;start = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const size_t &amp;end = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.size();
  const auto &amp;wps = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints;

  std::vector&lt;waypoint_follower::waypoint&gt; wps_extracted;
  for (uint32_t i = start; i &lt; end; i++)
  {
    if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::right)
    {
      wps_extracted.push_back(wps.at(i));
      if (i == end - 1)
        break;

      if (static_cast&lt;ChangeFlag&gt;(wps.at(i + 1).change_flag) != ChangeFlag::right)
        break;
    }
    else if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::left)
    {
      wps_extracted.push_back(wps.at(i));
      if (i == end - 1)
        break;

      if (static_cast&lt;ChangeFlag&gt;(wps.at(i + 1).change_flag) != ChangeFlag::left)
        break;
    }
  }

  if (wps_extracted.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }
  uint32_t num = static_cast&lt;uint32_t&gt;(wps_extracted.size() / 2.0);
  geometry_msgs::Point relative_p1;
  relative_p1.y =
      static_cast&lt;ChangeFlag&gt;(wps_extracted.at(0).change_flag) == ChangeFlag::right ? -LANE_SIZE_ / 2 : LANE_SIZE_ / 2;
  marker-&gt;points.push_back(*convertPointIntoWorldCoordinate(relative_p1, wps_extracted.at(num).pose.pose));
  geometry_msgs::Point relative_p2;
  relative_p2.y = 3 * relative_p1.y;
  marker-&gt;points.push_back(*convertPointIntoWorldCoordinate(relative_p2, wps_extracted.at(num).pose.pose));

  return marker;
}

void LaneSelectNode::publishVisualizer()
{
  visualization_msgs::MarkerArray marker_array;

  marker_array.markers.push_back(*createCurrentLaneMarker());
  marker_array.markers.push_back(*createCurrentLaneFlagMarker());
  marker_array.markers.push_back(*createCurrentLaneFlagArrowMarker());
  marker_array.markers.push_back(*createRightLaneMarker());
  marker_array.markers.push_back(*createLeftLaneMarker());
  marker_array.markers.push_back(*createClosestWaypointsMarker());

  vis_pub1_.publish(marker_array);
}

void LaneSelectNode::publish()
{
  // publish current global lane
  waypoint_follower::lane global_lane;
  global_lane = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_));
  pub1_.publish(global_lane);

  // publish closest waypoint
  std_msgs::Int32 closest_waypoint;
  closest_waypoint.data = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  pub2_.publish(closest_waypoint);

  std_msgs::Int32 change_flag;
  change_flag.data = enumToInteger(current_change_flag_);
  pub3_.publish(change_flag);

  is_current_pose_subscribed_ = false;
  is_current_velocity_subscribed_ = false;
  is_current_state_subscribed_ = false;
}

void LaneSelectNode::callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg)
{
  tuple_vec_.clear();
  tuple_vec_.shrink_to_fit();
  tuple_vec_.reserve(msg-&gt;lanes.size());
  for (const auto &amp;el : msg-&gt;lanes)
  {
    auto t = std::make_tuple(el, -1, ChangeFlag::unknown);
    tuple_vec_.push_back(t);
  }

  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  is_lane_array_subscribed_ = true;

  processing();
}

void LaneSelectNode::callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  current_pose_ = *msg;
  is_current_pose_subscribed_ = true;

  processing();
}

void LaneSelectNode::callbackFromTwistStamped(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  current_velocity_ = *msg;
  is_current_velocity_subscribed_ = true;

  processing();
}

void LaneSelectNode::callbackFromState(const std_msgs::StringConstPtr &amp;msg)
{
  current_state_ = msg-&gt;data;
  is_current_state_subscribed_ = true;

  processing();
}

void LaneSelectNode::run()
{
  ros::spin();
}

// distance between target 1 and target2 in 2-D
double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2)
{
  double distance = sqrt(pow(target1.x - target2.x, 2) + pow(target1.y - target2.y, 2));
  return distance;
}

void convertPointIntoRelativeCoordinate(const geometry_msgs::Point &amp;input_point, const geometry_msgs::Pose &amp;pose,
                                        geometry_msgs::Point *output_point)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);
  tf::Transform transform = inverse.inverse();

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = transform * p;
  pointTFToMsg(tf_p, *output_point);
}

std::unique_ptr&lt;geometry_msgs::Point&gt; convertPointIntoWorldCoordinate(const geometry_msgs::Point &amp;input_point,
                                                                      const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = inverse * p;

  std::unique_ptr&lt;geometry_msgs::Point&gt; tf_point_msg(new geometry_msgs::Point);
  pointTFToMsg(tf_p, *tf_point_msg);
  return tf_point_msg;
}

double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry_msgs::Pose &amp;current_pose)
{
  tf::Vector3 x_axis(1, 0, 0);
  tf::Transform waypoint_tfpose;
  tf::poseMsgToTF(waypoint_pose, waypoint_tfpose);
  tf::Vector3 waypoint_v = waypoint_tfpose.getBasis() * x_axis;
  tf::Transform current_tfpose;
  tf::poseMsgToTF(current_pose, current_tfpose);
  tf::Vector3 current_v = current_tfpose.getBasis() * x_axis;

  return current_v.angle(waypoint_v) * 180 / M_PI;
}

// get closest waypoint from current pose
int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number)
{
  if (current_lane.waypoints.empty())
    return -1;

  // ROS_INFO(&quot;number: %d&quot;,previous_number);
  std::vector&lt;uint32_t&gt; idx_vec;
  // if previous number is -1, search closest waypoint from waypoints in front of current pose
  if (previous_number == -1)
  {
    idx_vec.reserve(current_lane.waypoints.size());
    for (uint32_t i = 0; i &lt; current_lane.waypoints.size(); i++)
    {
      geometry_msgs::Point converted_p;
      convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose, &amp;converted_p);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      // ROS_INFO(&quot;angle: %lf&quot;,angle);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
      {
        idx_vec.push_back(i);
        // ROS_INFO(&quot;input idx: %d&quot;,i);
      }
    }
  }
  else
  {
    double ratio = 3;
    double minimum_dt = 2.0;
    double dt = current_velocity.linear.x * ratio &gt; minimum_dt ? current_velocity.linear.x * ratio : minimum_dt;

    if (dt &lt;
        getTwoDimensionalDistance(current_lane.waypoints.at(previous_number).pose.pose.position, current_pose.position))
    {
      ROS_WARN(&quot;Current_pose is far away from previous closest waypoint. Initilized...&quot;);
      return -1;
    }

    idx_vec.reserve(static_cast&lt;uint32_t&gt;(dt));

    auto range_max = static_cast&lt;uint32_t&gt;(previous_number + dt) &lt; current_lane.waypoints.size()
                         ? static_cast&lt;uint32_t&gt;(previous_number + dt)
                         : current_lane.waypoints.size();
    for (uint32_t i = static_cast&lt;uint32_t&gt;(previous_number); i &lt; range_max; i++)
    {
      geometry_msgs::Point converted_p;
      convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose, &amp;converted_p);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      // ROS_INFO(&quot;angle: %lf&quot;,angle);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
      {
        idx_vec.push_back(i);
        // ROS_INFO(&quot;input idx: %d&quot;,i);
      }
    }
  }

  if (idx_vec.empty())
    return -1;

  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    double dt = getTwoDimensionalDistance(current_pose.position, current_lane.waypoints.at(el).pose.pose.position);
    dist_vec.push_back(dt);
    // ROS_INFO(&quot;dt: %lf&quot;,dt);
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  int32_t found_number = idx_vec.at(static_cast&lt;uint32_t&gt;(std::distance(dist_vec.begin(), itr)));
  // ROS_INFO(&quot;found number: %d&quot;,found_number);
  return found_number;
}

// let the linear equation be &quot;ax + by + c = 0&quot;
// if there are two points (x1,y1) , (x2,y2), a = &quot;y2-y1, b = &quot;(-1) * x2 - x1&quot; ,c = &quot;(-1) * (y2-y1)x1 + (x2-x1)y1&quot;
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c)
{
  //(x1, y1) = (start.x, star.y), (x2, y2) = (end.x, end.y)
  double sub_x = fabs(start.x - end.x);
  double sub_y = fabs(start.y - end.y);
  double error = pow(10, -5);  // 0.00001

  if (sub_x &lt; error &amp;&amp; sub_y &lt; error)
  {
    ROS_INFO(&quot;two points are the same point!!&quot;);
    return false;
  }

  *a = end.y - start.y;
  *b = (-1) * (end.x - start.x);
  *c = (-1) * (end.y - start.y) * start.x + (end.x - start.x) * start.y;

  return true;
}
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double a, double b, double c)
{
  double d = fabs(a * point.x + b * point.y + c) / sqrt(pow(a, 2) + pow(b, 2));

  return d;
}

}  // lane_planner
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.h" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.h">
				<diff>@@ -137,7 +137,7 @@ private:
 };
 
 int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
-                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number);
+                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number, const double distance_threshold);
 
 double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2);
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef LANE_SELECT_CORE_H
#define LANE_SELECT_CORE_H

// ROS includes
#include &lt;ros/ros.h&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;std_msgs/Int32.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;std_msgs/String.h&gt;

// C++ includes
#include &lt;iostream&gt;
#include &lt;numeric&gt;
#include &lt;tuple&gt;

// User defined includes
#include &quot;waypoint_follower/LaneArray.h&quot;
#include &quot;waypoint_follower/libwaypoint_follower.h&quot;

namespace lane_planner
{
enum class ChangeFlag : int32_t
{
  straight,
  right,
  left,

  unknown = -1,
};

template &lt;class T&gt;
typename std::underlying_type&lt;T&gt;::type enumToInteger(T t)
{
  return static_cast&lt;typename std::underlying_type&lt;T&gt;::type&gt;(t);
}

class LaneSelectNode
{
public:
  LaneSelectNode();
  ~LaneSelectNode();

  void run();

private:
  // handle
  ros::NodeHandle nh_;
  ros::NodeHandle private_nh_;

  // publisher
  ros::Publisher pub1_, pub2_, pub3_;
  ros::Publisher vis_pub1_;

  // subscriber
  ros::Subscriber sub1_, sub2_, sub3_, sub4_;

  // variables
  int32_t current_lane_idx_;  // the index of the lane we are driving
  int32_t right_lane_idx_;
  int32_t left_lane_idx_;
  std::vector&lt;std::tuple&lt;waypoint_follower::lane, int32_t, ChangeFlag&gt;&gt; tuple_vec_;  // lane, closest_waypoint,
                                                                                     // change_flag
  bool is_lane_array_subscribed_, is_current_pose_subscribed_, is_current_velocity_subscribed_, is_current_state_subscribed_;
  ros::Time last_change_time_;
  ChangeFlag current_change_flag_;

  // rosparam
  double distance_threshold_;
  int32_t lane_change_interval_;

  // topics
  geometry_msgs::PoseStamped current_pose_;
  geometry_msgs::TwistStamped current_velocity_;
  std::string current_state_;

  // callbacks
  void callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg);
  void callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg);
  void callbackFromTwistStamped(const geometry_msgs::TwistStampedConstPtr &amp;msg);
  void callbackFromState(const std_msgs::StringConstPtr &amp;msg);

  // initializer
  void initForROS();

  // visualizer
  const double LANE_SIZE_;
  void publishVisualizer();
  std::unique_ptr&lt;visualization_msgs::Marker&gt; createCurrentLaneMarker();
  std::unique_ptr&lt;visualization_msgs::Marker&gt; createCurrentLaneFlagMarker();
  std::unique_ptr&lt;visualization_msgs::Marker&gt; createCurrentLaneFlagArrowMarker();
  std::unique_ptr&lt;std::vector&lt;geometry_msgs::Point&gt;&gt;
  createRectangleFromWaypoints(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, const double &amp;width);
  std::unique_ptr&lt;visualization_msgs::Marker&gt; createRightLaneMarker();
  std::unique_ptr&lt;visualization_msgs::Marker&gt; createLeftLaneMarker();
  std::unique_ptr&lt;visualization_msgs::Marker&gt; createClosestWaypointsMarker();

  // functions
  void processing();
  void publish();
  bool getClosestWaypointNumberForEachLanes();
  int32_t findMostClosestLane(const std::vector&lt;uint32_t&gt; idx_vec, const geometry_msgs::Point p);
  void findCurrentLane();
  void findNeighborLanes();
  void changeLane();
  void updateChangeFlag();
};

int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number);

double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2);

void convertPointIntoRelativeCoordinate(const geometry_msgs::Point &amp;input_point, const geometry_msgs::Pose &amp;pose,
                                        geometry_msgs::Point *output_point);

std::unique_ptr&lt;geometry_msgs::Point&gt; convertPointIntoWorldCoordinate(const geometry_msgs::Point &amp;input_point,
                                                                      const geometry_msgs::Pose &amp;pose);
double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry_msgs::Pose &amp;current_pose);
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c);
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double sa, double b, double c);
}
#endif  // LANE_SELECT_CORE_H
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="732cb241c3b81f3a116c3e20dd99f2c514d2e316" fix_time="66,1721">
		<msg>Fix typo</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set.cpp">
				<diff>@@ -437,7 +437,7 @@ void changeWaypoints(const VelocitySetInfo&amp; vs_info, const EControl&amp; detection_r
 
     // change waypoints to stop by the stop_waypoint
     vs_path-&gt;changeWaypoints(stop_waypoint, closest_waypoint, vs_info.getDeceleration());
-    vs_path-&gt;avoidSuddenAceleration(vs_info.getDeceleration(), closest_waypoint);
+    vs_path-&gt;avoidSuddenAcceleration(vs_info.getDeceleration(), closest_waypoint);
     vs_path-&gt;avoidSuddenBraking(vs_info.getVelocityChangeLimit(), vs_info.getDeceleration(), closest_waypoint);
     vs_path-&gt;setTemporalWaypoints(vs_info.getTemporalWaypointsSize(), closest_waypoint, vs_info.getControlPose());
     temporal_waypoints_pub.publish(vs_path-&gt;getTemporalWaypoints());
@@ -450,9 +450,9 @@ void changeWaypoints(const VelocitySetInfo&amp; vs_info, const EControl&amp; detection_r
     temporal_waypoints_pub.publish(vs_path-&gt;getTemporalWaypoints());
   }
   else
-  {  // ACELERATE or KEEP
+  {  // ACCELERATE or KEEP
     vs_path-&gt;initializeNewWaypoints();
-    vs_path-&gt;avoidSuddenAceleration(vs_info.getDeceleration(), closest_waypoint);
+    vs_path-&gt;avoidSuddenAcceleration(vs_info.getDeceleration(), closest_waypoint);
     vs_path-&gt;avoidSuddenBraking(vs_info.getVelocityChangeLimit(), vs_info.getDeceleration(), closest_waypoint);
     vs_path-&gt;setTemporalWaypoints(vs_info.getTemporalWaypointsSize(), closest_waypoint, vs_info.getControlPose());
     temporal_waypoints_pub.publish(vs_path-&gt;getTemporalWaypoints());
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &lt;ros/ros.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;iostream&gt;

#include &quot;libvelocity_set.h&quot;
#include &quot;velocity_set_path.h&quot;
#include &quot;velocity_set_info.h&quot;

namespace
{
constexpr int LOOP_RATE = 10;
constexpr double DECELERATION_SEARCH_DISTANCE = 30;
constexpr double STOP_SEARCH_DISTANCE = 60;


// Display a detected obstacle
void displayObstacle(const EControl &amp;kind, const ObstaclePoints&amp; obstacle_points, const ros::Publisher&amp; obstacle_pub)
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;/map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;my_namespace&quot;;
  marker.id = 0;
  marker.type = visualization_msgs::Marker::CUBE;
  marker.action = visualization_msgs::Marker::ADD;

  static geometry_msgs::Point prev_obstacle_point;
  if (kind == STOP || kind == DECELERATE)
  {
    marker.pose.position = obstacle_points.getObstaclePoint(kind);
    prev_obstacle_point = marker.pose.position;
  }
  else // kind == OTHERS
  {
    marker.pose.position = prev_obstacle_point;
  }
  geometry_msgs::Quaternion quat;
  marker.pose.orientation = quat;

  marker.scale.x = 1.0;
  marker.scale.y = 1.0;
  marker.scale.z = 2.0;
  marker.color.a = 0.7;
  if (kind == STOP)
  {
    marker.color.r = 1.0;
    marker.color.g = 0.0;
    marker.color.b = 0.0;
  }
  else
  {
    marker.color.r = 1.0;
    marker.color.g = 1.0;
    marker.color.b = 0.0;
  }
  marker.lifetime = ros::Duration(0.1);
  marker.frame_locked = true;

  //obstacle_pub.publish(marker);
}

void displayDetectionRange(const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, const int closest_waypoint, const EControl &amp;kind, const int obstacle_waypoint, const double stop_range, const double deceleration_range, const ros::Publisher&amp; detection_range_pub)
{
  // set up for marker array
  visualization_msgs::MarkerArray marker_array;
  visualization_msgs::Marker crosswalk_marker;
  visualization_msgs::Marker waypoint_marker_stop;
  visualization_msgs::Marker waypoint_marker_decelerate;
  visualization_msgs::Marker stop_line;
  crosswalk_marker.header.frame_id = &quot;/map&quot;;
  crosswalk_marker.header.stamp = ros::Time();
  crosswalk_marker.id = 0;
  crosswalk_marker.type = visualization_msgs::Marker::SPHERE_LIST;
  crosswalk_marker.action = visualization_msgs::Marker::ADD;
  waypoint_marker_stop = crosswalk_marker;
  waypoint_marker_decelerate = crosswalk_marker;
  stop_line = crosswalk_marker;
  stop_line.type = visualization_msgs::Marker::CUBE;

  // set each namespace
  crosswalk_marker.ns = &quot;Crosswalk Detection&quot;;
  waypoint_marker_stop.ns = &quot;Stop Detection&quot;;
  waypoint_marker_decelerate.ns = &quot;Decelerate Detection&quot;;
  stop_line.ns = &quot;Stop Line&quot;;

  // set scale and color
  double scale = 2 * stop_range;
  waypoint_marker_stop.scale.x = scale;
  waypoint_marker_stop.scale.y = scale;
  waypoint_marker_stop.scale.z = scale;
  waypoint_marker_stop.color.a = 0.2;
  waypoint_marker_stop.color.r = 0.0;
  waypoint_marker_stop.color.g = 1.0;
  waypoint_marker_stop.color.b = 0.0;
  waypoint_marker_stop.frame_locked = true;

  scale = 2 * (stop_range + deceleration_range);
  waypoint_marker_decelerate.scale.x = scale;
  waypoint_marker_decelerate.scale.y = scale;
  waypoint_marker_decelerate.scale.z = scale;
  waypoint_marker_decelerate.color.a = 0.15;
  waypoint_marker_decelerate.color.r = 1.0;
  waypoint_marker_decelerate.color.g = 1.0;
  waypoint_marker_decelerate.color.b = 0.0;
  waypoint_marker_decelerate.frame_locked = true;

  if (obstacle_waypoint &gt; -1)
  {
    stop_line.pose.position = lane.waypoints[obstacle_waypoint].pose.pose.position;
    stop_line.pose.orientation = lane.waypoints[obstacle_waypoint].pose.pose.orientation;
  }
  stop_line.pose.position.z += 1.0;
  stop_line.scale.x = 0.1;
  stop_line.scale.y = 15.0;
  stop_line.scale.z = 2.0;
  stop_line.color.a = 0.3;
  stop_line.color.r = 1.0;
  stop_line.color.g = 0.0;
  stop_line.color.b = 0.0;
  stop_line.lifetime = ros::Duration(0.1);
  stop_line.frame_locked = true;

  int crosswalk_id = crosswalk.getDetectionCrossWalkID();
  if (crosswalk_id &gt; 0)
    scale = crosswalk.getDetectionPoints(crosswalk_id).width;
  crosswalk_marker.scale.x = scale;
  crosswalk_marker.scale.y = scale;
  crosswalk_marker.scale.z = scale;
  crosswalk_marker.color.a = 0.5;
  crosswalk_marker.color.r = 0.0;
  crosswalk_marker.color.g = 1.0;
  crosswalk_marker.color.b = 0.0;
  crosswalk_marker.frame_locked = true;

  // set marker points coordinate
  for (int i = 0; i &lt; STOP_SEARCH_DISTANCE; i++)
  {
    if (closest_waypoint &lt; 0 || i + closest_waypoint &gt; static_cast&lt;int&gt;(lane.waypoints.size()) - 1)
      break;

    geometry_msgs::Point point;
    point = lane.waypoints[closest_waypoint + i].pose.pose.position;

    waypoint_marker_stop.points.push_back(point);

    if (i &gt; DECELERATION_SEARCH_DISTANCE)
      continue;
    waypoint_marker_decelerate.points.push_back(point);
  }

  if (crosswalk_id &gt; 0)
  {
    for (const auto &amp;p : crosswalk.getDetectionPoints(crosswalk_id).points)
      crosswalk_marker.points.push_back(p);
  }

  // publish marker
  marker_array.markers.push_back(crosswalk_marker);
  marker_array.markers.push_back(waypoint_marker_stop);
  marker_array.markers.push_back(waypoint_marker_decelerate);
  if (kind == STOP)
    marker_array.markers.push_back(stop_line);
  detection_range_pub.publish(marker_array);
  marker_array.markers.clear();
}

// obstacle detection for crosswalk
EControl crossWalkDetection(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const CrossWalk&amp; crosswalk, const geometry_msgs::PoseStamped&amp; localizer_pose, const int points_threshold, ObstaclePoints* obstacle_points)
{
  int crosswalk_id = crosswalk.getDetectionCrossWalkID();
  double search_radius = crosswalk.getDetectionPoints(crosswalk_id).width / 2;

  // Search each calculated points in the crosswalk
  for (const auto &amp;p : crosswalk.getDetectionPoints(crosswalk_id).points)
  {
    geometry_msgs::Point detection_point = calcRelativeCoordinate(p, localizer_pose.pose);
    tf::Vector3 detection_vector = point2vector(detection_point);
    detection_vector.setZ(0.0);

    int stop_count = 0;  // the number of points in the detection area
    for (const auto &amp;p : points)
    {
      tf::Vector3 point_vector(p.x, p.y, 0.0);
      double distance = tf::tfDistance(point_vector, detection_vector);
      if (distance &lt; search_radius)
      {
        stop_count++;
        geometry_msgs::Point point_temp;
        point_temp.x = p.x;
        point_temp.y = p.y;
        point_temp.z = p.z;
	obstacle_points-&gt;setStopPoint(calcAbsoluteCoordinate(point_temp, localizer_pose.pose));
      }
      if (stop_count &gt; points_threshold)
        return STOP;
    }

    obstacle_points-&gt;clearStopPoints();
  }

  return KEEP;  // find no obstacles
}

int detectStopObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, double stop_range, double points_threshold, const geometry_msgs::PoseStamped&amp; localizer_pose, ObstaclePoints* obstacle_points)
{
  int stop_obstacle_waypoint = -1;
  // start search from the closest waypoint
  for (int i = closest_waypoint; i &lt; closest_waypoint + STOP_SEARCH_DISTANCE; i++)
  {
    // reach the end of waypoints
    if (i &gt;= static_cast&lt;int&gt;(lane.waypoints.size()))
      break;

    // Detection for cross walk
    if (i == crosswalk.getDetectionWaypoint())
    {
      // found an obstacle in the cross walk
      if (crossWalkDetection(points, crosswalk, localizer_pose, points_threshold, obstacle_points) == STOP)
      {
        stop_obstacle_waypoint = i;
        break;
      }
    }

    // waypoint seen by localizer
    geometry_msgs::Point waypoint = calcRelativeCoordinate(lane.waypoints[i].pose.pose.position, localizer_pose.pose);
    tf::Vector3 tf_waypoint = point2vector(waypoint);
    tf_waypoint.setZ(0);

    int stop_point_count = 0;
    for (const auto&amp; p : points)
    {
      tf::Vector3 point_vector(p.x, p.y, 0);

      // 2D distance between waypoint and points (obstacle)
      double dt = tf::tfDistance(point_vector, tf_waypoint);
      if (dt &lt; stop_range)
      {
        stop_point_count++;
        geometry_msgs::Point point_temp;
        point_temp.x = p.x;
        point_temp.y = p.y;
        point_temp.z = p.z;
	obstacle_points-&gt;setStopPoint(calcAbsoluteCoordinate(point_temp, localizer_pose.pose));
      }
    }

    // there is an obstacle if the number of points exceeded the threshold
    if (stop_point_count &gt; points_threshold)
    {
      stop_obstacle_waypoint = i;
      break;
    }

    obstacle_points-&gt;clearStopPoints();

    // check next waypoint...
  }

  return stop_obstacle_waypoint;
}

int detectDecelerateObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower::lane&amp; lane, const double stop_range, const double deceleration_range, const double points_threshold, const geometry_msgs::PoseStamped&amp; localizer_pose, ObstaclePoints* obstacle_points)
{
  int decelerate_obstacle_waypoint = -1;
  // start search from the closest waypoint
  for (int i = closest_waypoint; i &lt; closest_waypoint + DECELERATION_SEARCH_DISTANCE; i++)
  {
    // reach the end of waypoints
    if (i &gt;= static_cast&lt;int&gt;(lane.waypoints.size()))
      break;

    // waypoint seen by localizer
    geometry_msgs::Point waypoint = calcRelativeCoordinate(lane.waypoints[i].pose.pose.position, localizer_pose.pose);
    tf::Vector3 tf_waypoint = point2vector(waypoint);
    tf_waypoint.setZ(0);

    int decelerate_point_count = 0;
    for (const auto&amp; p : points)
    {
      tf::Vector3 point_vector(p.x, p.y, 0);

      // 2D distance between waypoint and points (obstacle)
      double dt = tf::tfDistance(point_vector, tf_waypoint);
      if (dt &gt; stop_range &amp;&amp; dt &lt; stop_range + deceleration_range)
      {
        decelerate_point_count++;
        geometry_msgs::Point point_temp;
        point_temp.x = p.x;
        point_temp.y = p.y;
        point_temp.z = p.z;
	obstacle_points-&gt;setDeceleratePoint(calcAbsoluteCoordinate(point_temp, localizer_pose.pose));
      }
    }

    // there is an obstacle if the number of points exceeded the threshold
    if (decelerate_point_count &gt; points_threshold)
    {
      decelerate_obstacle_waypoint = i;
      break;
    }

    obstacle_points-&gt;clearDeceleratePoints();

    // check next waypoint...
  }

  return decelerate_obstacle_waypoint;
}


// Detect an obstacle by using pointcloud
EControl pointsDetection(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo&amp; vs_info, int* obstacle_waypoint, ObstaclePoints* obstacle_points)
{
  if (points.empty() == true || closest_waypoint &lt; 0)
    return KEEP;

  int stop_obstacle_waypoint = detectStopObstacle(points, closest_waypoint, lane, crosswalk, vs_info.getStopRange(), vs_info.getPointsThreshold(), vs_info.getLocalizerPose(), obstacle_points);

  // skip searching deceleration range
  if (vs_info.getDecelerationRange() &lt; 0.01)
  {
    *obstacle_waypoint = stop_obstacle_waypoint;
    return stop_obstacle_waypoint &lt; 0 ? KEEP : STOP;
  }

  int decelerate_obstacle_waypoint = detectDecelerateObstacle(points, closest_waypoint, lane, vs_info.getStopRange(), vs_info.getDecelerationRange(), vs_info.getPointsThreshold(), vs_info.getLocalizerPose(), obstacle_points);

  // stop obstacle was not found
  if (stop_obstacle_waypoint &lt; 0)
  {
    *obstacle_waypoint  = decelerate_obstacle_waypoint;
    return decelerate_obstacle_waypoint &lt; 0 ? KEEP : DECELERATE;
  }

  // stop obstacle was found but decelerate obstacle was not found
  if (decelerate_obstacle_waypoint &lt; 0)
  {
    *obstacle_waypoint = stop_obstacle_waypoint;
    return STOP;
  }

  // about 5.0 meter
  double waypoint_interval = getPlaneDistance(lane.waypoints[0].pose.pose.position, lane.waypoints[1].pose.pose.position);
  int stop_decelerate_threshold = 5 / waypoint_interval;

  // both were found
  if (stop_obstacle_waypoint - decelerate_obstacle_waypoint &gt; stop_decelerate_threshold)
  {
    *obstacle_waypoint = decelerate_obstacle_waypoint;
    return DECELERATE;
  }
  else
  {
    *obstacle_waypoint = stop_obstacle_waypoint;
    return STOP;
  }

}

EControl obstacleDetection(int closest_waypoint, const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo vs_info, const ros::Publisher&amp; detection_range_pub, const ros::Publisher&amp; obstacle_pub, int* obstacle_waypoint)
{
  ObstaclePoints obstacle_points;
  EControl detection_result = pointsDetection(vs_info.getPoints(), closest_waypoint, lane, crosswalk, vs_info, obstacle_waypoint, &amp;obstacle_points);
  displayDetectionRange(lane, crosswalk, closest_waypoint, detection_result, *obstacle_waypoint, vs_info.getStopRange(), vs_info.getDecelerationRange(), detection_range_pub);

  static int false_count = 0;
  static EControl prev_detection = KEEP;
  static int prev_obstacle_waypoint = -1;

  // stop or decelerate because we found obstacles
  if (detection_result == STOP || detection_result == DECELERATE)
  {
    displayObstacle(detection_result, obstacle_points, obstacle_pub);
      prev_detection = detection_result;
      false_count = 0;
      prev_obstacle_waypoint = *obstacle_waypoint;
      return detection_result;
  }

  // there are no obstacles, but wait a little for safety
  if (prev_detection == STOP || prev_detection == DECELERATE)
  {
    false_count++;

    if (false_count &lt; LOOP_RATE / 2)
    {
      *obstacle_waypoint = prev_obstacle_waypoint;
      displayObstacle(OTHERS, obstacle_points, obstacle_pub);
      return prev_detection;
    }
  }

  // there are no obstacles, so we move forward
  *obstacle_waypoint = -1;
  false_count = 0;
  prev_detection = KEEP;
  return detection_result;
}

void changeWaypoints(const VelocitySetInfo&amp; vs_info, const EControl&amp; detection_result, int closest_waypoint, int obstacle_waypoint, const ros::Publisher&amp; temporal_waypoints_pub, VelocitySetPath* vs_path)
{
  if (detection_result == STOP)
  {  // STOP for obstacle
    // stop_waypoint is about g_stop_distance meter away from obstacles
    int stop_waypoint = obstacle_waypoint - vs_info.getStopDistance() / vs_path-&gt;calcInterval(0, 1);

    // change waypoints to stop by the stop_waypoint
    vs_path-&gt;changeWaypoints(stop_waypoint, closest_waypoint, vs_info.getDeceleration());
    vs_path-&gt;avoidSuddenAceleration(vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;avoidSuddenBraking(vs_info.getVelocityChangeLimit(), vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;setTemporalWaypoints(vs_info.getTemporalWaypointsSize(), closest_waypoint, vs_info.getControlPose());
    temporal_waypoints_pub.publish(vs_path-&gt;getTemporalWaypoints());
  }
  else if (detection_result == DECELERATE)
  {  // DECELERATE for obstacles
    vs_path-&gt;initializeNewWaypoints();
    vs_path-&gt;setDeceleration(vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;setTemporalWaypoints(vs_info.getTemporalWaypointsSize(), closest_waypoint, vs_info.getControlPose());
    temporal_waypoints_pub.publish(vs_path-&gt;getTemporalWaypoints());
  }
  else
  {  // ACELERATE or KEEP
    vs_path-&gt;initializeNewWaypoints();
    vs_path-&gt;avoidSuddenAceleration(vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;avoidSuddenBraking(vs_info.getVelocityChangeLimit(), vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;setTemporalWaypoints(vs_info.getTemporalWaypointsSize(), closest_waypoint, vs_info.getControlPose());
    temporal_waypoints_pub.publish(vs_path-&gt;getTemporalWaypoints());
  }
}

} // end namespace


int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;velocity_set&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  bool use_crosswalk_detection;
  std::string points_topic;
  private_nh.param&lt;bool&gt;(&quot;use_crosswalk_detection&quot;, use_crosswalk_detection, true);
  private_nh.param&lt;std::string&gt;(&quot;points_topic&quot;, points_topic, &quot;points_lanes&quot;);

  // class
  CrossWalk crosswalk;
  VelocitySetPath vs_path;
  VelocitySetInfo vs_info;

  // velocity set subscriber
  ros::Subscriber waypoints_sub = nh.subscribe(&quot;base_waypoints&quot;, 1, &amp;VelocitySetPath::waypointsCallback, &amp;vs_path);
  ros::Subscriber current_vel_sub = nh.subscribe(&quot;current_velocity&quot;, 1, &amp;VelocitySetPath::currentVelocityCallback, &amp;vs_path);

  // velocity set info subscriber
  ros::Subscriber config_sub = nh.subscribe(&quot;config/velocity_set&quot;, 1, &amp;VelocitySetInfo::configCallback, &amp;vs_info);
  ros::Subscriber points_sub = nh.subscribe(points_topic, 1, &amp;VelocitySetInfo::pointsCallback, &amp;vs_info);
  ros::Subscriber localizer_sub = nh.subscribe(&quot;localizer_pose&quot;, 1, &amp;VelocitySetInfo::localizerPoseCallback, &amp;vs_info);
  ros::Subscriber control_pose_sub = nh.subscribe(&quot;current_pose&quot;, 1, &amp;VelocitySetInfo::controlPoseCallback, &amp;vs_info);
  ros::Subscriber closest_waypoint_sub = nh.subscribe(&quot;closest_waypoint&quot;, 1, &amp;VelocitySetInfo::closestWaypointCallback, &amp;vs_info);

  // vector map subscriber
  ros::Subscriber sub_dtlane = nh.subscribe(&quot;vector_map_info/cross_walk&quot;, 1, &amp;CrossWalk::crossWalkCallback, &amp;crosswalk);
  ros::Subscriber sub_area = nh.subscribe(&quot;vector_map_info/area&quot;, 1, &amp;CrossWalk::areaCallback, &amp;crosswalk);
  ros::Subscriber sub_line = nh.subscribe(&quot;vector_map_info/line&quot;, 1, &amp;CrossWalk::lineCallback, &amp;crosswalk);
  ros::Subscriber sub_point = nh.subscribe(&quot;vector_map_info/point&quot;, 1, &amp;CrossWalk::pointCallback, &amp;crosswalk);

  // publisher
  ros::Publisher detection_range_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;detection_range&quot;, 0);
  ros::Publisher temporal_waypoints_pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;temporal_waypoints&quot;, 1000, true);
  ros::Publisher obstacle_pub = nh.advertise&lt;visualization_msgs::Marker&gt;(&quot;obstacle&quot;, 0);

  ros::Rate loop_rate(LOOP_RATE);
  while (ros::ok())
  {
    ros::spinOnce();

    if (crosswalk.loaded_all &amp;&amp; !crosswalk.set_points)
      crosswalk.setCrossWalkPoints();

    if (!vs_info.getSetPose() || !vs_path.getSetPath())
    {
      loop_rate.sleep();
      continue;
    }

    if (use_crosswalk_detection)
      crosswalk.setDetectionWaypoint(crosswalk.findClosestCrosswalk(vs_info.getClosestWaypoint(), vs_path.getPrevWaypoints(), STOP_SEARCH_DISTANCE));

    int obstacle_waypoint = -1;
    EControl detection_result = obstacleDetection(vs_info.getClosestWaypoint(), vs_path.getPrevWaypoints(), crosswalk, vs_info, detection_range_pub, obstacle_pub, &amp;obstacle_waypoint);

    changeWaypoints(vs_info, detection_result, vs_info.getClosestWaypoint(), obstacle_waypoint, temporal_waypoints_pub, &amp;vs_path);

    vs_info.clearPoints();

    loop_rate.sleep();
  }

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.cpp">
				<diff>@@ -110,13 +110,13 @@ void VelocitySetPath::setDeceleration(double deceleration, int closest_waypoint)
   return;
 }
 
-void VelocitySetPath::avoidSuddenAceleration(double deceleration, int closest_waypoint)
+void VelocitySetPath::avoidSuddenAcceleration(double deceleration, int closest_waypoint)
 {
   double square_current_vel = current_vel_ * current_vel_;
 
   for (int i = 0;; i++)
   {
-    if (!checkWaypoint(closest_waypoint + i, &quot;avoidSuddenAceleration&quot;))
+    if (!checkWaypoint(closest_waypoint + i, &quot;avoidSuddenAcceleration&quot;))
       return;
 
     // accelerate with constant acceleration
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &quot;velocity_set_path.h&quot;

VelocitySetPath::VelocitySetPath()
  : set_path_(false),
    current_vel_(0)
{
  ros::NodeHandle private_nh_(&quot;~&quot;);
  private_nh_.param&lt;double&gt;(&quot;velocity_offset&quot;, velocity_offset_, 1.2);
}

VelocitySetPath::~VelocitySetPath()
{
}

// check if waypoint number is valid
bool VelocitySetPath::checkWaypoint(int num, const char *name) const
{
  if (num &lt; 0 || num &gt;= getPrevWaypointsSize())
  {
    return false;
  }
  return true;
}

// set about '_temporal_waypoints_size' meter waypoints from closest waypoint
void VelocitySetPath::setTemporalWaypoints(int temporal_waypoints_size, int closest_waypoint, geometry_msgs::PoseStamped control_pose)
{
  if (closest_waypoint &lt; 0)
    return;

  temporal_waypoints_.waypoints.clear();
  temporal_waypoints_.header = new_waypoints_.header;
  temporal_waypoints_.increment = new_waypoints_.increment;
  // push current pose
  waypoint_follower::waypoint current_point;

  current_point.pose = control_pose;
  current_point.twist = new_waypoints_.waypoints[closest_waypoint].twist;
  current_point.dtlane = new_waypoints_.waypoints[closest_waypoint].dtlane;
  temporal_waypoints_.waypoints.push_back(current_point);
  for (int i = 0; i &lt; temporal_waypoints_size; i++)
  {
    if (closest_waypoint + i &gt;= getNewWaypoints().waypoints.size())
      return;

    temporal_waypoints_.waypoints.push_back(new_waypoints_.waypoints[closest_waypoint + i]);
  }

  return;
}

void VelocitySetPath::setDeceleration(double deceleration, int closest_waypoint)
{
  int velocity_change_range = 5;
  double intervel = calcInterval(0, 1);
  double temp1 = current_vel_ * current_vel_;
  double temp2 = 2 * deceleration * intervel;
  double deceleration_minimum = kmph2mps(4.0);

  for (int i = 0; i &lt; velocity_change_range; i++)
  {
    if (!checkWaypoint(closest_waypoint + i, &quot;setDeceleration&quot;))
      continue;
    double waypoint_velocity = prev_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x;
    double changed_vel = temp1 - temp2;
    if (changed_vel &lt; 0)
    {
      changed_vel = deceleration_minimum * deceleration_minimum;
    }
    if (sqrt(changed_vel) &gt; waypoint_velocity || deceleration_minimum &gt; waypoint_velocity)
      continue;
    if (sqrt(changed_vel) &lt; deceleration_minimum)
    {
      new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x = deceleration_minimum;
      continue;
    }
    new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x = sqrt(changed_vel);
  }

  return;
}

void VelocitySetPath::avoidSuddenAceleration(double deceleration, int closest_waypoint)
{
  double square_current_vel = current_vel_ * current_vel_;

  for (int i = 0;; i++)
  {
    if (!checkWaypoint(closest_waypoint + i, &quot;avoidSuddenAceleration&quot;))
      return;

    // accelerate with constant acceleration
    // v = root((v0)^2 + 2ax)
    double changed_vel = std::sqrt(square_current_vel + 2 * deceleration * calcInterval(closest_waypoint, closest_waypoint + i)) + velocity_offset_;

    // Don't exceed original velocity
    if (changed_vel &gt; new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x)
      return;

    new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x = changed_vel;
  }

  return;
}

void VelocitySetPath::avoidSuddenBraking(double velocity_change_limit, double deceleration, int closest_waypoint)
{
  int i = 0;
  int fill_in_zero = 20;
  int fill_in_vel = 15;
  int examin_range = 1;  // need to change according to waypoint interval?
  int num;
  double interval = calcInterval(0, 1);
  double changed_vel;

  for (int j = -1; j &lt; examin_range; j++)
  {
    if (!checkWaypoint(closest_waypoint + j, &quot;avoidSuddenBraking&quot;))
      return;
    if (new_waypoints_.waypoints[closest_waypoint + j].twist.twist.linear.x &lt;
        current_vel_ - velocity_change_limit)  // we must change waypoints
      break;
    if (j == examin_range - 1)  // we don't have to change waypoints
      return;
  }

  ROS_INFO(&quot;avoid sudden braking!!&quot;);

  // fill in waypoints velocity behind vehicle
  for (num = closest_waypoint - 1; fill_in_vel &gt; 0; fill_in_vel--)
  {
    if (!checkWaypoint(num - fill_in_vel, &quot;avoidSuddenBraking&quot;))
      continue;
    new_waypoints_.waypoints[num - fill_in_vel].twist.twist.linear.x = current_vel_;
  }

  // decelerate gradually
  double temp1 = (current_vel_ - velocity_change_limit + 1.389) * (current_vel_ - velocity_change_limit + 1.389);
  double temp2 = 2 * deceleration * interval;
  for (num = closest_waypoint - 1;; num++)
  {
    if (num &gt;= getPrevWaypointsSize())
      return;
    if (!checkWaypoint(num, &quot;avoidSuddenBraking&quot;))
      continue;
    changed_vel = temp1 - temp2 * (double)i;  // sqrt(v^2 - 2*a*x)
    if (changed_vel &lt;= 0)
      break;
    new_waypoints_.waypoints[num].twist.twist.linear.x = sqrt(changed_vel);

    i++;
  }

  for (int j = 0; j &lt; fill_in_zero; j++)
  {
    if (!checkWaypoint(num + j, &quot;avoidSuddenBraking&quot;))
      continue;
    new_waypoints_.waypoints[num + j].twist.twist.linear.x = 0.0;
  }


  return;
}

void VelocitySetPath::changeWaypoints(int stop_waypoint, int closest_waypoint, double deceleration)
{
  int i = 0;
  int close_waypoint_threshold = 4;
  int fill_in_zero = 20;
  double changed_vel;
  double interval = calcInterval(0, 1);

  // change waypoints to decelerate
  for (int num = stop_waypoint; num &gt; closest_waypoint - close_waypoint_threshold; num--)
  {
    if (!checkWaypoint(num, &quot;changeWaypoints&quot;))
      continue;

    changed_vel = sqrt(2.0 * deceleration * (interval * i));  // sqrt(2*a*x)

    waypoint_follower::waypoint initial_waypoint = prev_waypoints_.waypoints[num];
    if (changed_vel &gt; initial_waypoint.twist.twist.linear.x)
    {  // avoid acceleration
      new_waypoints_.waypoints[num].twist.twist.linear.x = initial_waypoint.twist.twist.linear.x;
    }
    else
    {
      new_waypoints_.waypoints[num].twist.twist.linear.x = changed_vel;
    }

    i++;
  }

  // fill in 0
  for (int j = 1; j &lt; fill_in_zero; j++)
  {
    if (!checkWaypoint(stop_waypoint + j, &quot;changeWaypoints&quot;))
      continue;
    new_waypoints_.waypoints[stop_waypoint + j].twist.twist.linear.x = 0.0;
  }


  return;
}

void VelocitySetPath::initializeNewWaypoints()
{
  new_waypoints_ = prev_waypoints_;
}

double VelocitySetPath::calcInterval(const int begin, const int end) const
{
  // check index
  if (begin &lt; 0 || begin &gt;= getPrevWaypointsSize() || end &lt; 0 || end &gt;= getPrevWaypointsSize())
  {
    ROS_WARN(&quot;Invalid index&quot;);
    return -1;
  }

  // Calculate the inteval of waypoints
  double dist_sum = 0;
  for (int i = begin; i &lt; end; i++)
  {
    tf::Vector3 v1(prev_waypoints_.waypoints[i].pose.pose.position.x,
                   prev_waypoints_.waypoints[i].pose.pose.position.y, 0);

    tf::Vector3 v2(prev_waypoints_.waypoints[i + 1].pose.pose.position.x,
                   prev_waypoints_.waypoints[i + 1].pose.pose.position.y, 0);

    dist_sum += tf::tfDistance(v1, v2);
  }

  return dist_sum;
}


void VelocitySetPath::waypointsCallback(const waypoint_follower::laneConstPtr&amp; msg)
{
  prev_waypoints_ = *msg;
  new_waypoints_ = *msg;

  if (!set_path_)
    set_path_ = true;
}

void VelocitySetPath::currentVelocityCallback(const geometry_msgs::TwistStampedConstPtr&amp; msg)
{
  current_vel_ = msg-&gt;twist.linear.x;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.h" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.h">
				<diff>@@ -52,7 +52,7 @@ class VelocitySetPath
 
   void changeWaypoints(int stop_waypoint, int closest_waypoint, double deceleration);
   void avoidSuddenBraking(double velocity_change_limit, double deceleration, int closest_waypoint);
-  void avoidSuddenAceleration(double decelerationint, int closest_waypoint);
+  void avoidSuddenAcceleration(double decelerationint, int closest_waypoint);
   void setDeceleration(double deceleration, int closest_waypoint);
   void setTemporalWaypoints(int temporal_waypoints_size, int closest_waypoint, geometry_msgs::PoseStamped control_pose);
   void initializeNewWaypoints();
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#ifndef VELOCITY_SET_PATH_H
#define VELOCITY_SET_PATH_H

#include &quot;waypoint_follower/libwaypoint_follower.h&quot;
class VelocitySetPath
{
 private:
  waypoint_follower::lane prev_waypoints_;
  waypoint_follower::lane new_waypoints_;
  waypoint_follower::lane temporal_waypoints_;
  bool set_path_;
  double current_vel_;

  // ROS param
  double velocity_offset_; // m/s

  bool checkWaypoint(int num, const char *name) const;

 public:
  VelocitySetPath();
  ~VelocitySetPath();

  void changeWaypoints(int stop_waypoint, int closest_waypoint, double deceleration);
  void avoidSuddenBraking(double velocity_change_limit, double deceleration, int closest_waypoint);
  void avoidSuddenAceleration(double decelerationint, int closest_waypoint);
  void setDeceleration(double deceleration, int closest_waypoint);
  void setTemporalWaypoints(int temporal_waypoints_size, int closest_waypoint, geometry_msgs::PoseStamped control_pose);
  void initializeNewWaypoints();

  // ROS Callbacks
  void waypointsCallback(const waypoint_follower::laneConstPtr&amp; msg);
  void currentVelocityCallback(const geometry_msgs::TwistStampedConstPtr&amp; msg);

  double calcInterval(const int begin, const int end) const;

  waypoint_follower::lane getPrevWaypoints() const
  {
    return prev_waypoints_;
  }

  waypoint_follower::lane getNewWaypoints() const
  {
    return new_waypoints_;
  }

  waypoint_follower::lane getTemporalWaypoints() const
  {
    return temporal_waypoints_;
  }

  bool getSetPath() const
  {
    return set_path_;
  }

  double getCurrentVelocity() const
  {
    return current_vel_;
  }

  int getPrevWaypointsSize() const
  {
    return prev_waypoints_.waypoints.size();
  }  
};

#endif // VELOCITY_SET_PATH_H
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="fa108c777813aa4d44fb75942d51742a569f2f66" fix_time="56,3999">
		<msg>Remove debug code</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp">
				<diff>@@ -741,7 +741,7 @@ int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, co
   if (current_lane.waypoints.empty())
     return -1;
 
-  // ROS_INFO(&quot;number: %d&quot;,previous_number);
+
   std::vector&lt;uint32_t&gt; idx_vec;
   // if previous number is -1, search closest waypoint from waypoints in front of current pose
   if (previous_number == -1)
@@ -752,12 +752,8 @@ int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, co
       geometry_msgs::Point converted_p;
       convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose, &amp;converted_p);
       double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
-      // ROS_INFO(&quot;angle: %lf&quot;,angle);
       if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
-      {
         idx_vec.push_back(i);
-        // ROS_INFO(&quot;input idx: %d&quot;,i);
-      }
     }
   }
   else
@@ -781,12 +777,9 @@ int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, co
       geometry_msgs::Point converted_p;
       convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose, &amp;converted_p);
       double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
-      // ROS_INFO(&quot;angle: %lf&quot;,angle);
       if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
-      {
         idx_vec.push_back(i);
-        // ROS_INFO(&quot;input idx: %d&quot;,i);
-      }
+
     }
   }
 
@@ -799,11 +792,9 @@ int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, co
   {
     double dt = getTwoDimensionalDistance(current_pose.position, current_lane.waypoints.at(el).pose.pose.position);
     dist_vec.push_back(dt);
-    // ROS_INFO(&quot;dt: %lf&quot;,dt);
   }
   std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
   int32_t found_number = idx_vec.at(static_cast&lt;uint32_t&gt;(std::distance(dist_vec.begin(), itr)));
-  // ROS_INFO(&quot;found number: %d&quot;,found_number);
   return found_number;
 }
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;lane_select_core.h&quot;

namespace lane_planner
{
// Constructor
LaneSelectNode::LaneSelectNode()
  : private_nh_(&quot;~&quot;)
  , current_lane_idx_(-1)
  , right_lane_idx_(-1)
  , left_lane_idx_(-1)
  , is_lane_array_subscribed_(false)
  , is_current_pose_subscribed_(false)
  , is_current_velocity_subscribed_(false)
  , is_current_state_subscribed_(false)
  , last_change_time_(ros::Time::now())
  , current_change_flag_(ChangeFlag::unknown)
  , current_state_(&quot;UNKNOWN&quot;)
  , LANE_SIZE_(1.0)
{
  initForROS();
}

// Destructor
LaneSelectNode::~LaneSelectNode()
{
}

void LaneSelectNode::initForROS()
{
  // setup subscriber
  sub1_ = nh_.subscribe(&quot;traffic_waypoints_array&quot;, 100, &amp;LaneSelectNode::callbackFromLaneArray, this);
  sub2_ = nh_.subscribe(&quot;current_pose&quot;, 100, &amp;LaneSelectNode::callbackFromPoseStamped, this);
  sub3_ = nh_.subscribe(&quot;current_velocity&quot;, 100, &amp;LaneSelectNode::callbackFromTwistStamped, this);
  sub4_ = nh_.subscribe(&quot;state&quot;, 100, &amp;LaneSelectNode::callbackFromState, this);

  // setup publisher
  pub1_ = nh_.advertise&lt;waypoint_follower::lane&gt;(&quot;base_waypoints&quot;, 10);
  pub2_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 10);
  pub3_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;change_flag&quot;, 10);
  vis_pub1_ = nh_.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;lane_select_marker&quot;, 10);

  // get from rosparam
  private_nh_.param&lt;int32_t&gt;(&quot;lane_change_interval&quot;, lane_change_interval_, int32_t(2));
  private_nh_.param&lt;double&gt;(&quot;distance_threshold&quot;, distance_threshold_, double(3.0));
}

void LaneSelectNode::processing()
{
  if (!is_current_pose_subscribed_ || !is_lane_array_subscribed_ || !is_current_velocity_subscribed_)
  {
    ROS_WARN(&quot;Necessary topics are not subscribed yet. Waiting...&quot;);
    return;
  }

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    current_lane_idx_ = -1;
    right_lane_idx_ = -1;
    left_lane_idx_ = -1;
    publishVisualizer();
    return;
  }

  // if current_lane_idx_ = -1, find the lane index which has the most closest waypoint
  if (current_lane_idx_ == -1)
  {
    findCurrentLane();
    findNeighborLanes();
    publish();
    publishVisualizer();
    return;
  }

  // if closest waypoint on current lane is -1,
  if (std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) == -1)
  {
    current_lane_idx_ = -1;
    right_lane_idx_ = -1;
    left_lane_idx_ = -1;
    publishVisualizer();
    return;
  }

  if(right_lane_idx_ != -1)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) == -1)
      right_lane_idx_ = -1;
  }
  if(left_lane_idx_ != -1)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) == -1)
      left_lane_idx_ = -1;
  }

  ROS_INFO(&quot;current_lane_idx: %d&quot;, current_lane_idx_);
  ROS_INFO(&quot;right_lane_idx: %d&quot;, right_lane_idx_);
  ROS_INFO(&quot;left_lane_idx: %d&quot;, left_lane_idx_);
  ROS_INFO(&quot;current change_flag: %d&quot;, enumToInteger(std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_))));

  updateChangeFlag();
  if (current_state_ == &quot;LANE_CHANGE&quot;)
    changeLane();

  publish();
  publishVisualizer();
}



void LaneSelectNode::updateChangeFlag()
{
  if(current_change_flag_ == ChangeFlag::unknown || current_change_flag_ == ChangeFlag::straight)
  {
    current_change_flag_ = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));

    if ((current_change_flag_ == ChangeFlag::left &amp;&amp; left_lane_idx_ == -1) ||
        (current_change_flag_ == ChangeFlag::right &amp;&amp; right_lane_idx_ == -1))
      current_change_flag_ = ChangeFlag::straight;
    return;
  }

  // if current change flag is right or left
  double a, b, c;

  if (std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) == 0 ||
                  std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) ==
                    static_cast&lt;int32_t&gt;(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.size()))
  {
    geometry_msgs::Point &amp;closest_p = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_))
                                          .waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)))
                                          .pose.pose.position;
    geometry_msgs::Point &amp;front_of_closest_p = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_))
                                                   .waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) - 1)
                                                   .pose.pose.position;
    getLinearEquation(front_of_closest_p, closest_p, &amp;a, &amp;b, &amp;c);
  }
  else
  {
    geometry_msgs::Point &amp;closest_p = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_))
                                          .waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) - 1)
                                          .pose.pose.position;
    geometry_msgs::Point &amp;front_of_closest_p = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_))
                                                   .waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)))
                                                   .pose.pose.position;
    getLinearEquation(front_of_closest_p, closest_p, &amp;a, &amp;b, &amp;c);
  }
  geometry_msgs::Point &amp;current_point = current_pose_.pose.position;
  double d = getDistanceBetweenLineAndPoint(current_point, a, b, c);

  double threshold = 1.0;
  if(d &lt; threshold)
  {
    current_change_flag_ = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  }
}

void LaneSelectNode::changeLane()
{
  ros::Time current_time = ros::Time::now();
  double dt = (current_time - last_change_time_).toSec();
  if (dt &lt; lane_change_interval_)
    return;

  if (current_change_flag_ == ChangeFlag::right &amp;&amp; right_lane_idx_ != -1)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) != -1)
    {
      current_lane_idx_ = right_lane_idx_;
      findNeighborLanes();
      last_change_time_ = ros::Time::now();
      return;
    }
  }

  if (current_change_flag_ == ChangeFlag::left &amp;&amp; left_lane_idx_ != -1)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) != -1)
    {
      current_lane_idx_ = left_lane_idx_;
      findNeighborLanes();
      last_change_time_ = ros::Time::now();
      return;
    }
  }
}

bool LaneSelectNode::getClosestWaypointNumberForEachLanes()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;1&gt;(el) = getClosestWaypointNumber(std::get&lt;0&gt;(el), current_pose_.pose, current_velocity_.twist,
                                               std::get&lt;1&gt;(el), distance_threshold_);
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(el));

    std::get&lt;2&gt;(el) = (std::get&lt;1&gt;(el) != -1)
                          ? static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(el).waypoints.at(std::get&lt;1&gt;(el)).change_flag)
                          : ChangeFlag::unknown;
    ROS_INFO(&quot;change_flag: %d&quot;, enumToInteger(std::get&lt;2&gt;(el)));
  }

  // confirm if all closest waypoint numbers are -1. If so, output warning
  int32_t accum = 0;
  for (const auto &amp;el : tuple_vec_)
  {
    accum += std::get&lt;1&gt;(el);
  }
  if (accum == (-1) * static_cast&lt;int32_t&gt;(tuple_vec_.size()))
  {
    ROS_WARN(&quot;Cannot get closest waypoints. All closest waypoints are changed to -1...&quot;);
    return false;
  }

  return true;
}

void LaneSelectNode::findCurrentLane()
{
  std::vector&lt;uint32_t&gt; idx_vec;
  idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;
    idx_vec.push_back(i);
  }
  current_lane_idx_ = findMostClosestLane(idx_vec, current_pose_.pose.position);
}

int32_t LaneSelectNode::findMostClosestLane(const std::vector&lt;uint32_t&gt; idx_vec, const geometry_msgs::Point p)
{
  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    int32_t closest_number = std::get&lt;1&gt;(tuple_vec_.at(el));
    dist_vec.push_back(
        getTwoDimensionalDistance(p, std::get&lt;0&gt;(tuple_vec_.at(el)).waypoints.at(closest_number).pose.pose.position));
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  return idx_vec.at(std::distance(dist_vec.begin(), itr));
}

void LaneSelectNode::findNeighborLanes()
{
  int32_t current_closest_num = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const geometry_msgs::Pose &amp;current_closest_pose =
      std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.at(current_closest_num).pose.pose;

  std::vector&lt;uint32_t&gt; left_lane_idx_vec;
  left_lane_idx_vec.reserve(tuple_vec_.size());
  std::vector&lt;uint32_t&gt; right_lane_idx_vec;
  right_lane_idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (i == static_cast&lt;uint32_t&gt;(current_lane_idx_) || std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    int32_t target_num = std::get&lt;1&gt;(tuple_vec_.at(i));
    const geometry_msgs::Point &amp;target_p = std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(target_num).pose.pose.position;

    geometry_msgs::Point converted_p;
    convertPointIntoRelativeCoordinate(target_p, current_closest_pose, &amp;converted_p);

    ROS_INFO(&quot;distance: %lf&quot;, converted_p.y);
    if (fabs(converted_p.y) &gt; distance_threshold_)
    {
      ROS_INFO(&quot;%d lane is far from current lane...&quot;, i);
      continue;
    }

    if (converted_p.y &gt; 0)
      left_lane_idx_vec.push_back(i);
    else
      right_lane_idx_vec.push_back(i);
  }

  if (!left_lane_idx_vec.empty())
    left_lane_idx_ = findMostClosestLane(left_lane_idx_vec, current_closest_pose.position);
  else
    left_lane_idx_ = -1;

  if (!right_lane_idx_vec.empty())
    right_lane_idx_ = findMostClosestLane(right_lane_idx_vec, current_closest_pose.position);
  else
    right_lane_idx_ = -1;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createCurrentLaneMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;current_lane_marker&quot;;

  if (current_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker-&gt;type = visualization_msgs::Marker::LINE_STRIP;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.05;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;
  marker-&gt;color = color_current;

  marker-&gt;points = *createRectangleFromWaypoints(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints, LANE_SIZE_);

  return marker;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createRightLaneMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;right_lane_marker&quot;;

  if (right_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker-&gt;type = visualization_msgs::Marker::LINE_STRIP;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker-&gt;color = change_flag == ChangeFlag::right ? color_neighbor_change : color_neighbor;

  marker-&gt;points = *createRectangleFromWaypoints(std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_)).waypoints, LANE_SIZE_);

  return marker;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createLeftLaneMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;left_lane_marker&quot;;

  if (left_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker-&gt;type = visualization_msgs::Marker::LINE_STRIP;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker-&gt;color = change_flag == ChangeFlag::left ? color_neighbor_change : color_neighbor;

  marker-&gt;points = *createRectangleFromWaypoints(std::get&lt;0&gt;(tuple_vec_.at(left_lane_idx_)).waypoints, LANE_SIZE_);

  return marker;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createClosestWaypointsMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  std_msgs::ColorRGBA color_closest_wp;
  color_closest_wp.r = 1.0;
  color_closest_wp.b = 1.0;
  color_closest_wp.g = 1.0;
  color_closest_wp.a = 1.0;

  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;closest_waypoints_marker&quot;;
  marker-&gt;type = visualization_msgs::Marker::POINTS;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.5;
  marker-&gt;color = color_closest_wp;

  marker-&gt;points.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    marker-&gt;points.push_back(
        std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(i))).pose.pose.position);
  }

  return marker;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createCurrentLaneFlagMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);
  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;current_lane_flag_marker&quot;;

  if (current_lane_idx_ == -1)
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  std_msgs::ColorRGBA red;
  red.r = 1.0;
  red.a = 1.0;

  marker-&gt;type = visualization_msgs::Marker::LINE_STRIP;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;scale.x = 0.05;
  marker-&gt;color = red;

  const int32_t &amp;start = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const size_t &amp;end = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.size();
  const auto &amp;wps = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints;

  std::vector&lt;waypoint_follower::waypoint&gt; wps_extracted;
  for (uint32_t i = start; i &lt; end; i++)
  {
    if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::right)
    {
      wps_extracted.push_back(wps.at(i));
      if (i == end - 1)
        break;

      if (static_cast&lt;ChangeFlag&gt;(wps.at(i + 1).change_flag) != ChangeFlag::right)
        break;
    }
    else if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::left)
    {
      wps_extracted.push_back(wps.at(i));
      if (i == end - 1)
        break;

      if (static_cast&lt;ChangeFlag&gt;(wps.at(i + 1).change_flag) != ChangeFlag::left)
        break;
    }
  }

  if (wps_extracted.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }
  marker-&gt;points = *createRectangleFromWaypoints(wps_extracted, LANE_SIZE_ * 0.8);

  return marker;
}

std::unique_ptr&lt;std::vector&lt;geometry_msgs::Point&gt;&gt;
LaneSelectNode::createRectangleFromWaypoints(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, const double &amp;width)
{
  std::vector&lt;std::tuple&lt;geometry_msgs::Point, geometry_msgs::Point&gt;&gt; vertex;

  for (const auto &amp;el : wps)
  {
    geometry_msgs::Point relative_p1;
    relative_p1.y = width / 2;
    geometry_msgs::Point relative_p2;
    relative_p2.y = -width / 2;
    vertex.push_back(std::make_tuple(*convertPointIntoWorldCoordinate(relative_p1, el.pose.pose),
                                     *convertPointIntoWorldCoordinate(relative_p2, el.pose.pose)));
  }

  std::unique_ptr&lt;std::vector&lt;geometry_msgs::Point&gt;&gt; rectangle(new std::vector&lt;geometry_msgs::Point&gt;);
  for (const auto &amp;el : vertex)
    rectangle-&gt;push_back(std::get&lt;0&gt;(el));

  std::reverse(vertex.begin(), vertex.end());
  for (const auto &amp;el : vertex)
    rectangle-&gt;push_back(std::get&lt;1&gt;(el));
  std::reverse(vertex.begin(), vertex.end());
  rectangle-&gt;push_back(std::get&lt;0&gt;(vertex.at(0)));

  return rectangle;
}

std::unique_ptr&lt;visualization_msgs::Marker&gt; LaneSelectNode::createCurrentLaneFlagArrowMarker()
{
  std::unique_ptr&lt;visualization_msgs::Marker&gt; marker(new visualization_msgs::Marker);

  marker-&gt;header.frame_id = &quot;map&quot;;
  marker-&gt;header.stamp = ros::Time();
  marker-&gt;ns = &quot;current_lane_flag_arrow_marker&quot;;

  if (current_lane_idx_ == -1)
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  std_msgs::ColorRGBA red;
  red.r = 1.0;
  red.a = 1.0;

  marker-&gt;type = visualization_msgs::Marker::ARROW;
  marker-&gt;action = visualization_msgs::Marker::ADD;
  marker-&gt;color = red;
  marker-&gt;scale.x = 0.25;
  marker-&gt;scale.y = 0.5;

  const int32_t &amp;start = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const size_t &amp;end = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.size();
  const auto &amp;wps = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints;

  std::vector&lt;waypoint_follower::waypoint&gt; wps_extracted;
  for (uint32_t i = start; i &lt; end; i++)
  {
    if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::right)
    {
      wps_extracted.push_back(wps.at(i));
      if (i == end - 1)
        break;

      if (static_cast&lt;ChangeFlag&gt;(wps.at(i + 1).change_flag) != ChangeFlag::right)
        break;
    }
    else if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::left)
    {
      wps_extracted.push_back(wps.at(i));
      if (i == end - 1)
        break;

      if (static_cast&lt;ChangeFlag&gt;(wps.at(i + 1).change_flag) != ChangeFlag::left)
        break;
    }
  }

  if (wps_extracted.empty())
  {
    marker-&gt;action = visualization_msgs::Marker::DELETE;
    return marker;
  }
  uint32_t num = static_cast&lt;uint32_t&gt;(wps_extracted.size() / 2.0);
  geometry_msgs::Point relative_p1;
  relative_p1.y =
      static_cast&lt;ChangeFlag&gt;(wps_extracted.at(0).change_flag) == ChangeFlag::right ? -LANE_SIZE_ / 2 : LANE_SIZE_ / 2;
  marker-&gt;points.push_back(*convertPointIntoWorldCoordinate(relative_p1, wps_extracted.at(num).pose.pose));
  geometry_msgs::Point relative_p2;
  relative_p2.y = 3 * relative_p1.y;
  marker-&gt;points.push_back(*convertPointIntoWorldCoordinate(relative_p2, wps_extracted.at(num).pose.pose));

  return marker;
}

void LaneSelectNode::publishVisualizer()
{
  visualization_msgs::MarkerArray marker_array;

  marker_array.markers.push_back(*createCurrentLaneMarker());
  marker_array.markers.push_back(*createCurrentLaneFlagMarker());
  marker_array.markers.push_back(*createCurrentLaneFlagArrowMarker());
  marker_array.markers.push_back(*createRightLaneMarker());
  marker_array.markers.push_back(*createLeftLaneMarker());
  marker_array.markers.push_back(*createClosestWaypointsMarker());

  vis_pub1_.publish(marker_array);
}

void LaneSelectNode::publish()
{
  // publish current global lane
  waypoint_follower::lane global_lane;
  global_lane = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_));
  pub1_.publish(global_lane);

  // publish closest waypoint
  std_msgs::Int32 closest_waypoint;
  closest_waypoint.data = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  pub2_.publish(closest_waypoint);

  std_msgs::Int32 change_flag;
  change_flag.data = enumToInteger(current_change_flag_);
  pub3_.publish(change_flag);

  is_current_pose_subscribed_ = false;
  is_current_velocity_subscribed_ = false;
  is_current_state_subscribed_ = false;
}

void LaneSelectNode::callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg)
{
  tuple_vec_.clear();
  tuple_vec_.shrink_to_fit();
  tuple_vec_.reserve(msg-&gt;lanes.size());
  for (const auto &amp;el : msg-&gt;lanes)
  {
    auto t = std::make_tuple(el, -1, ChangeFlag::unknown);
    tuple_vec_.push_back(t);
  }

  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  is_lane_array_subscribed_ = true;

  processing();
}

void LaneSelectNode::callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  current_pose_ = *msg;
  is_current_pose_subscribed_ = true;

  processing();
}

void LaneSelectNode::callbackFromTwistStamped(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  current_velocity_ = *msg;
  is_current_velocity_subscribed_ = true;

  processing();
}

void LaneSelectNode::callbackFromState(const std_msgs::StringConstPtr &amp;msg)
{
  current_state_ = msg-&gt;data;
  is_current_state_subscribed_ = true;

  processing();
}

void LaneSelectNode::run()
{
  ros::spin();
}

// distance between target 1 and target2 in 2-D
double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2)
{
  double distance = sqrt(pow(target1.x - target2.x, 2) + pow(target1.y - target2.y, 2));
  return distance;
}

void convertPointIntoRelativeCoordinate(const geometry_msgs::Point &amp;input_point, const geometry_msgs::Pose &amp;pose,
                                        geometry_msgs::Point *output_point)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);
  tf::Transform transform = inverse.inverse();

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = transform * p;
  pointTFToMsg(tf_p, *output_point);
}

std::unique_ptr&lt;geometry_msgs::Point&gt; convertPointIntoWorldCoordinate(const geometry_msgs::Point &amp;input_point,
                                                                      const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = inverse * p;

  std::unique_ptr&lt;geometry_msgs::Point&gt; tf_point_msg(new geometry_msgs::Point);
  pointTFToMsg(tf_p, *tf_point_msg);
  return tf_point_msg;
}

double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry_msgs::Pose &amp;current_pose)
{
  tf::Vector3 x_axis(1, 0, 0);
  tf::Transform waypoint_tfpose;
  tf::poseMsgToTF(waypoint_pose, waypoint_tfpose);
  tf::Vector3 waypoint_v = waypoint_tfpose.getBasis() * x_axis;
  tf::Transform current_tfpose;
  tf::poseMsgToTF(current_pose, current_tfpose);
  tf::Vector3 current_v = current_tfpose.getBasis() * x_axis;

  return current_v.angle(waypoint_v) * 180 / M_PI;
}

// get closest waypoint from current pose
int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number,
                                 const double distance_threshold)
{
  if (current_lane.waypoints.empty())
    return -1;

  // ROS_INFO(&quot;number: %d&quot;,previous_number);
  std::vector&lt;uint32_t&gt; idx_vec;
  // if previous number is -1, search closest waypoint from waypoints in front of current pose
  if (previous_number == -1)
  {
    idx_vec.reserve(current_lane.waypoints.size());
    for (uint32_t i = 0; i &lt; current_lane.waypoints.size(); i++)
    {
      geometry_msgs::Point converted_p;
      convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose, &amp;converted_p);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      // ROS_INFO(&quot;angle: %lf&quot;,angle);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
      {
        idx_vec.push_back(i);
        // ROS_INFO(&quot;input idx: %d&quot;,i);
      }
    }
  }
  else
  {
    if (distance_threshold &lt;
        getTwoDimensionalDistance(current_lane.waypoints.at(previous_number).pose.pose.position, current_pose.position))
    {
      ROS_WARN(&quot;Current_pose is far away from previous closest waypoint. Initilized...&quot;);
      return -1;
    }

    double ratio = 3;
    double minimum_dt = 2.0;
    double dt = current_velocity.linear.x * ratio &gt; minimum_dt ? current_velocity.linear.x * ratio : minimum_dt;

    auto range_max = static_cast&lt;uint32_t&gt;(previous_number + dt) &lt; current_lane.waypoints.size()
                         ? static_cast&lt;uint32_t&gt;(previous_number + dt)
                         : current_lane.waypoints.size();
    for (uint32_t i = static_cast&lt;uint32_t&gt;(previous_number); i &lt; range_max; i++)
    {
      geometry_msgs::Point converted_p;
      convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose, &amp;converted_p);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      // ROS_INFO(&quot;angle: %lf&quot;,angle);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
      {
        idx_vec.push_back(i);
        // ROS_INFO(&quot;input idx: %d&quot;,i);
      }
    }
  }

  if (idx_vec.empty())
    return -1;

  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    double dt = getTwoDimensionalDistance(current_pose.position, current_lane.waypoints.at(el).pose.pose.position);
    dist_vec.push_back(dt);
    // ROS_INFO(&quot;dt: %lf&quot;,dt);
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  int32_t found_number = idx_vec.at(static_cast&lt;uint32_t&gt;(std::distance(dist_vec.begin(), itr)));
  // ROS_INFO(&quot;found number: %d&quot;,found_number);
  return found_number;
}

// let the linear equation be &quot;ax + by + c = 0&quot;
// if there are two points (x1,y1) , (x2,y2), a = &quot;y2-y1, b = &quot;(-1) * x2 - x1&quot; ,c = &quot;(-1) * (y2-y1)x1 + (x2-x1)y1&quot;
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c)
{
  //(x1, y1) = (start.x, star.y), (x2, y2) = (end.x, end.y)
  double sub_x = fabs(start.x - end.x);
  double sub_y = fabs(start.y - end.y);
  double error = pow(10, -5);  // 0.00001

  if (sub_x &lt; error &amp;&amp; sub_y &lt; error)
  {
    ROS_INFO(&quot;two points are the same point!!&quot;);
    return false;
  }

  *a = end.y - start.y;
  *b = (-1) * (end.x - start.x);
  *c = (-1) * (end.y - start.y) * start.x + (end.x - start.x) * start.y;

  return true;
}
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double a, double b, double c)
{
  double d = fabs(a * point.x + b * point.y + c) / sqrt(pow(a, 2) + pow(b, 2));

  return d;
}

}  // lane_planner
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="0926701fc1af9721ae44d1e220ab15b665a4dd76" fix_time="0,0">
		<msg>add error avoidance</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp">
				<diff>@@ -193,6 +193,14 @@ void LaneSelectNode::createLaneForChange()
     return;
   }
 
+  if((static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right &amp;&amp; right_lane_idx_ &lt; 0)
+    || (static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::left &amp;&amp; left_lane_idx_ &lt; 0))
+  {
+    ROS_WARN(&quot;current lane doesn't have the lane for lane change&quot;);
+    return;
+  }
+
+
   double dt = getTwoDimensionalDistance(cur_lane.waypoints.at(num_lane_change).pose.pose.position, cur_lane.waypoints.at(clst_wp).pose.pose.position);
   double ratio = 3.0;
   double minimum = 5.0;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;lane_select_core.h&quot;

namespace lane_planner
{
// Constructor
LaneSelectNode::LaneSelectNode()
  : private_nh_(&quot;~&quot;)
  , current_lane_idx_(-1)
  , right_lane_idx_(-1)
  , left_lane_idx_(-1)
  , is_lane_array_subscribed_(false)
  , is_current_pose_subscribed_(false)
  , is_current_velocity_subscribed_(false)
  , is_current_state_subscribed_(false)
  , current_state_(&quot;UNKNOWN&quot;)
{
  initForROS();
}

// Destructor
LaneSelectNode::~LaneSelectNode()
{
}

void LaneSelectNode::initForROS()
{
  // setup subscriber
  sub1_ = nh_.subscribe(&quot;traffic_waypoints_array&quot;, 100, &amp;LaneSelectNode::callbackFromLaneArray, this);
  sub2_ = nh_.subscribe(&quot;current_pose&quot;, 100, &amp;LaneSelectNode::callbackFromPoseStamped, this);
  sub3_ = nh_.subscribe(&quot;current_velocity&quot;, 100, &amp;LaneSelectNode::callbackFromTwistStamped, this);
  sub4_ = nh_.subscribe(&quot;state&quot;, 100, &amp;LaneSelectNode::callbackFromState, this);

  // setup publisher
  pub1_ = nh_.advertise&lt;waypoint_follower::lane&gt;(&quot;base_waypoints&quot;, 10);
  pub2_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 10);
  pub3_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;change_flag&quot;, 10);
  vis_pub1_ = nh_.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;lane_select_marker&quot;, 10);

  // get from rosparam
  private_nh_.param&lt;int32_t&gt;(&quot;lane_change_interval&quot;, lane_change_interval_, int32_t(2));
  private_nh_.param&lt;double&gt;(&quot;distance_threshold&quot;, distance_threshold_, double(3.0));
}

bool LaneSelectNode::isAllTopicsSubscribed()
{
  if (!is_current_pose_subscribed_ || !is_lane_array_subscribed_ || !is_current_velocity_subscribed_)
  {
    ROS_WARN(&quot;Necessary topics are not subscribed yet. Waiting...&quot;);
    return false;
  }
  return true;
}

void LaneSelectNode::initForLaneSelect()
{
  if(!isAllTopicsSubscribed())
    return;

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    resetLaneIdx();
    return;
  }

  findCurrentLane();
  findNeighborLanes();
  updateChangeFlag();
  createLaneForChange();
  publish(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)), std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)),
          std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)));
  publishVisualizer();
  return;
}

void LaneSelectNode::resetLaneIdx()
{
  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  publishVisualizer();
}

void LaneSelectNode::processing()
{
  if(!isAllTopicsSubscribed())
    return;

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    resetLaneIdx();
    return;
  }

  // if closest waypoint on current lane is -1,
  if (std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) == -1)
  {
    resetLaneIdx();
    return;
  }

  if (right_lane_idx_ != -1 &amp;&amp; std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) == -1)
    right_lane_idx_ = -1;

  if (left_lane_idx_ != -1 &amp;&amp; std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) == -1)
    left_lane_idx_ = -1;

  ROS_INFO(&quot;current_lane_idx: %d&quot;, current_lane_idx_);
  ROS_INFO(&quot;right_lane_idx: %d&quot;, right_lane_idx_);
  ROS_INFO(&quot;left_lane_idx: %d&quot;, left_lane_idx_);

  if (current_state_ == &quot;LANE_CHANGE&quot;)
  {
    changeLane();
    std::get&lt;1&gt;(lane_for_change_) =
        getClosestWaypointNumber(std::get&lt;0&gt;(lane_for_change_), current_pose_.pose, current_velocity_.twist,
                                 std::get&lt;1&gt;(lane_for_change_), distance_threshold_);
    std::get&lt;2&gt;(lane_for_change_) =
        static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(lane_for_change_).waypoints.at(std::get&lt;1&gt;(lane_for_change_)).change_flag);
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(lane_for_change_));
    publish(std::get&lt;0&gt;(lane_for_change_), std::get&lt;1&gt;(lane_for_change_), std::get&lt;2&gt;(lane_for_change_));
  }
  else
  {
    updateChangeFlag();
    createLaneForChange();
    publish(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)), std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)),
            std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)));
  }
  publishVisualizer();
}

int32_t LaneSelectNode::getClosestLaneChangeWaypointNumber(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, int32_t cl_wp)
{

  for (uint32_t i = cl_wp; i &lt; wps.size(); i++)
  {
    if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::right ||
      static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::left)
    {
      return i;
    }
  }
  return -1;
}

void LaneSelectNode::createLaneForChange()
{
  std::get&lt;0&gt;(lane_for_change_).waypoints.clear();
  std::get&lt;0&gt;(lane_for_change_).waypoints.shrink_to_fit();
  std::get&lt;1&gt;(lane_for_change_) = -1;

  const waypoint_follower::lane &amp;cur_lane = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_));
  const int32_t &amp;clst_wp = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));

  int32_t num_lane_change = getClosestLaneChangeWaypointNumber(cur_lane.waypoints, clst_wp);
  ROS_INFO(&quot;num_lane_change: %d&quot;,num_lane_change);
  if (num_lane_change &lt; 0 || num_lane_change &gt;= static_cast&lt;int32_t&gt;(cur_lane.waypoints.size()))
  {
    ROS_INFO(&quot;current lane doesn't have change flag&quot;);
    return;
  }

  double dt = getTwoDimensionalDistance(cur_lane.waypoints.at(num_lane_change).pose.pose.position, cur_lane.waypoints.at(clst_wp).pose.pose.position);
  double ratio = 3.0;
  double minimum = 5.0;
  double dt_by_vel = current_velocity_.twist.linear.x * ratio &gt; minimum ? current_velocity_.twist.linear.x * ratio : minimum;
  ROS_INFO(&quot;dt : %lf, dt_by_vel : %lf&quot;,dt,dt_by_vel);
  waypoint_follower::lane &amp;nghbr_lane =
      static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
          ? std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_))
          : std::get&lt;0&gt;(tuple_vec_.at(left_lane_idx_));
  const int32_t &amp;nghbr_clst_wp = static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
                                      ? std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_))
                                      : std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_));

  int32_t target_num = -1;
  for (uint32_t i = nghbr_clst_wp; i &lt; nghbr_lane.waypoints.size(); i++)
  {
    if(i == nghbr_lane.waypoints.size() - 1 ||
      dt + dt_by_vel &lt; getTwoDimensionalDistance(nghbr_lane.waypoints.at(nghbr_clst_wp).pose.pose.position,nghbr_lane.waypoints.at(i).pose.pose.position))
    {
      target_num = i;
      break;
    }
  }

  ROS_INFO(&quot;target_num : %d&quot;, target_num);
  if(target_num &lt; 0)
    return;

  std::get&lt;0&gt;(lane_for_change_).header.stamp = nghbr_lane.header.stamp;
  std::vector&lt;waypoint_follower::waypoint&gt; hermite_wps = generateHermiteCurveForROS(
      cur_lane.waypoints.at(num_lane_change).pose.pose, nghbr_lane.waypoints.at(target_num).pose.pose,
      cur_lane.waypoints.at(num_lane_change).twist.twist.linear.x, 5);

  for(auto &amp;&amp;el : hermite_wps)
    el.change_flag = cur_lane.waypoints.at(num_lane_change).change_flag;

  std::get&lt;0&gt;(lane_for_change_).waypoints.reserve(nghbr_lane.waypoints.size() + hermite_wps.size());
  std::copy(hermite_wps.begin(), hermite_wps.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
  auto itr = nghbr_lane.waypoints.begin();
  std::advance(itr, target_num);
  for(auto i = itr; i != nghbr_lane.waypoints.end();i++)
  {
    if(getTwoDimensionalDistance(itr-&gt;pose.pose.position,i-&gt;pose.pose.position) &lt; 10)
      i-&gt;change_flag = enumToInteger(ChangeFlag::straight);
    else
      break;
  }
  std::copy(itr,nghbr_lane.waypoints.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
}

void LaneSelectNode::updateChangeFlag()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;2&gt;(el) = (std::get&lt;1&gt;(el) != -1)
                          ? static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(el).waypoints.at(std::get&lt;1&gt;(el)).change_flag)
                          : ChangeFlag::unknown;

    if(std::get&lt;2&gt;(el) == ChangeFlag::right &amp;&amp; right_lane_idx_ == -1)
      std::get&lt;2&gt;(el) = ChangeFlag::unknown;
    else if(std::get&lt;2&gt;(el) == ChangeFlag::left &amp;&amp; left_lane_idx_ == -1)
      std::get&lt;2&gt;(el) = ChangeFlag::unknown;

    ROS_INFO(&quot;change_flag: %d&quot;, enumToInteger(std::get&lt;2&gt;(el)));
  }
}

void LaneSelectNode::changeLane()
{
  if (std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)) == ChangeFlag::right &amp;&amp; right_lane_idx_ != -1 &amp;&amp;
      std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) != -1)
  {
    current_lane_idx_ = right_lane_idx_;
  }
  else if (std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)) == ChangeFlag::left &amp;&amp; left_lane_idx_ != -1 &amp;&amp;
           std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) != -1)
  {
    current_lane_idx_ = left_lane_idx_;
  }

  findNeighborLanes();
  return;
}

bool LaneSelectNode::getClosestWaypointNumberForEachLanes()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;1&gt;(el) = getClosestWaypointNumber(std::get&lt;0&gt;(el), current_pose_.pose, current_velocity_.twist,
                                               std::get&lt;1&gt;(el), distance_threshold_);
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(el));
  }

  // confirm if all closest waypoint numbers are -1. If so, output warning
  int32_t accum = 0;
  for (const auto &amp;el : tuple_vec_)
  {
    accum += std::get&lt;1&gt;(el);
  }
  if (accum == (-1) * static_cast&lt;int32_t&gt;(tuple_vec_.size()))
  {
    ROS_WARN(&quot;Cannot get closest waypoints. All closest waypoints are changed to -1...&quot;);
    return false;
  }

  return true;
}

void LaneSelectNode::findCurrentLane()
{
  std::vector&lt;uint32_t&gt; idx_vec;
  idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;
    idx_vec.push_back(i);
  }
  current_lane_idx_ = findMostClosestLane(idx_vec, current_pose_.pose.position);
}

int32_t LaneSelectNode::findMostClosestLane(const std::vector&lt;uint32_t&gt; idx_vec, const geometry_msgs::Point p)
{
  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    int32_t closest_number = std::get&lt;1&gt;(tuple_vec_.at(el));
    dist_vec.push_back(
        getTwoDimensionalDistance(p, std::get&lt;0&gt;(tuple_vec_.at(el)).waypoints.at(closest_number).pose.pose.position));
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  return idx_vec.at(std::distance(dist_vec.begin(), itr));
}

void LaneSelectNode::findNeighborLanes()
{
  int32_t current_closest_num = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const geometry_msgs::Pose &amp;current_closest_pose =
      std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.at(current_closest_num).pose.pose;

  std::vector&lt;uint32_t&gt; left_lane_idx_vec;
  left_lane_idx_vec.reserve(tuple_vec_.size());
  std::vector&lt;uint32_t&gt; right_lane_idx_vec;
  right_lane_idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (i == static_cast&lt;uint32_t&gt;(current_lane_idx_) || std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    int32_t target_num = std::get&lt;1&gt;(tuple_vec_.at(i));
    const geometry_msgs::Point &amp;target_p = std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(target_num).pose.pose.position;

    geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(target_p, current_closest_pose);

    ROS_INFO(&quot;distance: %lf&quot;, converted_p.y);
    if (fabs(converted_p.y) &gt; distance_threshold_)
    {
      ROS_INFO(&quot;%d lane is far from current lane...&quot;, i);
      continue;
    }

    if (converted_p.y &gt; 0)
      left_lane_idx_vec.push_back(i);
    else
      right_lane_idx_vec.push_back(i);
  }

  if (!left_lane_idx_vec.empty())
    left_lane_idx_ = findMostClosestLane(left_lane_idx_vec, current_closest_pose.position);
  else
    left_lane_idx_ = -1;

  if (!right_lane_idx_vec.empty())
    right_lane_idx_ = findMostClosestLane(right_lane_idx_vec, current_closest_pose.position);
  else
    right_lane_idx_ = -1;
}
visualization_msgs::Marker LaneSelectNode::createCurrentLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;current_lane_marker&quot;;

  if (current_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;
  marker.color = color_current;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createRightLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;right_lane_marker&quot;;

  if (right_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker.color = change_flag == ChangeFlag::right ? color_neighbor_change : color_neighbor;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_)).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createLeftLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;left_lane_marker&quot;;

  if (left_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker.color = change_flag == ChangeFlag::left ? color_neighbor_change : color_neighbor;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at((left_lane_idx_))).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createChangeLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;change_lane_marker&quot;;

  if (std::get&lt;0&gt;(lane_for_change_).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color;
  color.r = 1.0;
  color.a = 0.5;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;

  marker.color = current_state_ == &quot;LANE_CHANGE&quot; ? color_current : color;
  for(const auto &amp;em : std::get&lt;0&gt;(lane_for_change_).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createClosestWaypointsMarker()
{
  visualization_msgs::Marker marker;
  std_msgs::ColorRGBA color_closest_wp;
  color_closest_wp.r = 1.0;
  color_closest_wp.b = 1.0;
  color_closest_wp.g = 1.0;
  color_closest_wp.a = 1.0;

  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;closest_waypoints_marker&quot;;
  marker.type = visualization_msgs::Marker::POINTS;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.5;
  marker.color = color_closest_wp;

  marker.points.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    marker.points.push_back(
        std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(i))).pose.pose.position);
  }

  return marker;
}

void LaneSelectNode::publishVisualizer()
{
  visualization_msgs::MarkerArray marker_array;
  marker_array.markers.push_back(createChangeLaneMarker());
  marker_array.markers.push_back(createCurrentLaneMarker());
  marker_array.markers.push_back(createRightLaneMarker());
  marker_array.markers.push_back(createLeftLaneMarker());
  marker_array.markers.push_back(createClosestWaypointsMarker());

  vis_pub1_.publish(marker_array);
}

void LaneSelectNode::publish(const waypoint_follower::lane &amp;lane, const int32_t clst_wp, const ChangeFlag flag)
{
  // publish global lane
  pub1_.publish(lane);

  // publish closest waypoint
  std_msgs::Int32 closest_waypoint;
  closest_waypoint.data = clst_wp;
  pub2_.publish(closest_waypoint);

  std_msgs::Int32 change_flag;
  change_flag.data = enumToInteger(flag);
  pub3_.publish(change_flag);

  is_current_pose_subscribed_ = false;
  is_current_velocity_subscribed_ = false;
  is_current_state_subscribed_ = false;
}

void LaneSelectNode::callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg)
{
  tuple_vec_.clear();
  tuple_vec_.shrink_to_fit();
  tuple_vec_.reserve(msg-&gt;lanes.size());
  for (const auto &amp;el : msg-&gt;lanes)
  {
    auto t = std::make_tuple(el, -1, ChangeFlag::unknown);
    tuple_vec_.push_back(t);
  }

  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  is_lane_array_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  current_pose_ = *msg;
  is_current_pose_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromTwistStamped(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  current_velocity_ = *msg;
  is_current_velocity_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromState(const std_msgs::StringConstPtr &amp;msg)
{
  current_state_ = msg-&gt;data;
  is_current_state_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::run()
{
  ros::spin();
}

// distance between target 1 and target2 in 2-D
double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2)
{
  double distance = sqrt(pow(target1.x - target2.x, 2) + pow(target1.y - target2.y, 2));
  return distance;
}

geometry_msgs::Point convertPointIntoRelativeCoordinate(const geometry_msgs::Point &amp;input_point, const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);
  tf::Transform transform = inverse.inverse();

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = transform * p;
  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);
  return tf_point_msg;
}

geometry_msgs::Point convertPointIntoWorldCoordinate(const geometry_msgs::Point &amp;input_point,
                                                                      const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = inverse * p;

  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);
  return tf_point_msg;
}

double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry_msgs::Pose &amp;current_pose)
{
  tf::Vector3 x_axis(1, 0, 0);
  tf::Transform waypoint_tfpose;
  tf::poseMsgToTF(waypoint_pose, waypoint_tfpose);
  tf::Vector3 waypoint_v = waypoint_tfpose.getBasis() * x_axis;
  tf::Transform current_tfpose;
  tf::poseMsgToTF(current_pose, current_tfpose);
  tf::Vector3 current_v = current_tfpose.getBasis() * x_axis;

  return current_v.angle(waypoint_v) * 180 / M_PI;
}

// get closest waypoint from current pose
int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number,
                                 const double distance_threshold)
{
  if (current_lane.waypoints.empty())
    return -1;


  std::vector&lt;uint32_t&gt; idx_vec;
  // if previous number is -1, search closest waypoint from waypoints in front of current pose
  if (previous_number == -1)
  {
    idx_vec.reserve(current_lane.waypoints.size());
    for (uint32_t i = 0; i &lt; current_lane.waypoints.size(); i++)
    {
      geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
        idx_vec.push_back(i);
    }
  }
  else
  {
    if (distance_threshold &lt;
        getTwoDimensionalDistance(current_lane.waypoints.at(previous_number).pose.pose.position, current_pose.position))
    {
      ROS_WARN(&quot;Current_pose is far away from previous closest waypoint. Initilized...&quot;);
      return -1;
    }

    double ratio = 3;
    double minimum_dt = 2.0;
    double dt = current_velocity.linear.x * ratio &gt; minimum_dt ? current_velocity.linear.x * ratio : minimum_dt;

    auto range_max = static_cast&lt;uint32_t&gt;(previous_number + dt) &lt; current_lane.waypoints.size()
                         ? static_cast&lt;uint32_t&gt;(previous_number + dt)
                         : current_lane.waypoints.size();
    for (uint32_t i = static_cast&lt;uint32_t&gt;(previous_number); i &lt; range_max; i++)
    {
      geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
        idx_vec.push_back(i);

    }
  }

  if (idx_vec.empty())
    return -1;

  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    double dt = getTwoDimensionalDistance(current_pose.position, current_lane.waypoints.at(el).pose.pose.position);
    dist_vec.push_back(dt);
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  int32_t found_number = idx_vec.at(static_cast&lt;uint32_t&gt;(std::distance(dist_vec.begin(), itr)));
  return found_number;
}

// let the linear equation be &quot;ax + by + c = 0&quot;
// if there are two points (x1,y1) , (x2,y2), a = &quot;y2-y1, b = &quot;(-1) * x2 - x1&quot; ,c = &quot;(-1) * (y2-y1)x1 + (x2-x1)y1&quot;
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c)
{
  //(x1, y1) = (start.x, star.y), (x2, y2) = (end.x, end.y)
  double sub_x = fabs(start.x - end.x);
  double sub_y = fabs(start.y - end.y);
  double error = pow(10, -5);  // 0.00001

  if (sub_x &lt; error &amp;&amp; sub_y &lt; error)
  {
    ROS_INFO(&quot;two points are the same point!!&quot;);
    return false;
  }

  *a = end.y - start.y;
  *b = (-1) * (end.x - start.x);
  *c = (-1) * (end.y - start.y) * start.x + (end.x - start.x) * start.y;

  return true;
}
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double a, double b, double c)
{
  double d = fabs(a * point.x + b * point.y + c) / sqrt(pow(a, 2) + pow(b, 2));

  return d;
}

}  // lane_planner
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="33981fcc47b6adb969f2e8e2b61c77889eb3ed38" fix_time="23,3005">
		<msg>Fix definition of function</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp">
				<diff>@@ -687,8 +687,7 @@ double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry
 
 // get closest waypoint from current pose
 int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
-                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number,
-                                 const double distance_threshold)
+                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number, const double distance_threshold)
 {
   if (current_lane.waypoints.empty())
     return -1;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;lane_select_core.h&quot;

namespace lane_planner
{
// Constructor
LaneSelectNode::LaneSelectNode()
  : private_nh_(&quot;~&quot;)
  , current_lane_idx_(-1)
  , right_lane_idx_(-1)
  , left_lane_idx_(-1)
  , is_lane_array_subscribed_(false)
  , is_current_pose_subscribed_(false)
  , is_current_velocity_subscribed_(false)
  , is_current_state_subscribed_(false)
  , current_state_(&quot;UNKNOWN&quot;)
{
  initForROS();
}

// Destructor
LaneSelectNode::~LaneSelectNode()
{
}

void LaneSelectNode::initForROS()
{
  // setup subscriber
  sub1_ = nh_.subscribe(&quot;traffic_waypoints_array&quot;, 100, &amp;LaneSelectNode::callbackFromLaneArray, this);
  sub2_ = nh_.subscribe(&quot;current_pose&quot;, 100, &amp;LaneSelectNode::callbackFromPoseStamped, this);
  sub3_ = nh_.subscribe(&quot;current_velocity&quot;, 100, &amp;LaneSelectNode::callbackFromTwistStamped, this);
  sub4_ = nh_.subscribe(&quot;state&quot;, 100, &amp;LaneSelectNode::callbackFromState, this);

  // setup publisher
  pub1_ = nh_.advertise&lt;waypoint_follower::lane&gt;(&quot;base_waypoints&quot;, 10);
  pub2_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 10);
  pub3_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;change_flag&quot;, 10);
  vis_pub1_ = nh_.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;lane_select_marker&quot;, 10);

  // get from rosparam
  private_nh_.param&lt;int32_t&gt;(&quot;lane_change_interval&quot;, lane_change_interval_, int32_t(2));
  private_nh_.param&lt;double&gt;(&quot;distance_threshold&quot;, distance_threshold_, double(3.0));
}

bool LaneSelectNode::isAllTopicsSubscribed()
{
  if (!is_current_pose_subscribed_ || !is_lane_array_subscribed_ || !is_current_velocity_subscribed_)
  {
    ROS_WARN(&quot;Necessary topics are not subscribed yet. Waiting...&quot;);
    return false;
  }
  return true;
}

void LaneSelectNode::initForLaneSelect()
{
  if(!isAllTopicsSubscribed())
    return;

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    resetLaneIdx();
    return;
  }

  findCurrentLane();
  findNeighborLanes();
  updateChangeFlag();
  createLaneForChange();
  publish(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)), std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)),
          std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)));
  publishVisualizer();
  return;
}

void LaneSelectNode::resetLaneIdx()
{
  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  publishVisualizer();
}

void LaneSelectNode::processing()
{
  if(!isAllTopicsSubscribed())
    return;

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    resetLaneIdx();
    return;
  }

  // if closest waypoint on current lane is -1,
  if (std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) == -1)
  {
    resetLaneIdx();
    return;
  }

  if (right_lane_idx_ != -1 &amp;&amp; std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) == -1)
    right_lane_idx_ = -1;

  if (left_lane_idx_ != -1 &amp;&amp; std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) == -1)
    left_lane_idx_ = -1;

  ROS_INFO(&quot;current_lane_idx: %d&quot;, current_lane_idx_);
  ROS_INFO(&quot;right_lane_idx: %d&quot;, right_lane_idx_);
  ROS_INFO(&quot;left_lane_idx: %d&quot;, left_lane_idx_);

  if (current_state_ == &quot;LANE_CHANGE&quot;)
  {
    changeLane();
    std::get&lt;1&gt;(lane_for_change_) =
        getClosestWaypointNumber(std::get&lt;0&gt;(lane_for_change_), current_pose_.pose, current_velocity_.twist,
                                 std::get&lt;1&gt;(lane_for_change_), distance_threshold_);
    std::get&lt;2&gt;(lane_for_change_) =
        static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(lane_for_change_).waypoints.at(std::get&lt;1&gt;(lane_for_change_)).change_flag);
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(lane_for_change_));
    publish(std::get&lt;0&gt;(lane_for_change_), std::get&lt;1&gt;(lane_for_change_), std::get&lt;2&gt;(lane_for_change_));
  }
  else
  {
    updateChangeFlag();
    createLaneForChange();
    publish(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)), std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)),
            std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)));
  }
  publishVisualizer();
}

int32_t LaneSelectNode::getClosestLaneChangeWaypointNumber(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, int32_t cl_wp)
{

  for (uint32_t i = cl_wp; i &lt; wps.size(); i++)
  {
    if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::right ||
      static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::left)
    {
      return i;
    }
  }
  return -1;
}

void LaneSelectNode::createLaneForChange()
{
  std::get&lt;0&gt;(lane_for_change_).waypoints.clear();
  std::get&lt;0&gt;(lane_for_change_).waypoints.shrink_to_fit();
  std::get&lt;1&gt;(lane_for_change_) = -1;

  const waypoint_follower::lane &amp;cur_lane = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_));
  const int32_t &amp;clst_wp = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));

  int32_t num_lane_change = getClosestLaneChangeWaypointNumber(cur_lane.waypoints, clst_wp);
  ROS_INFO(&quot;num_lane_change: %d&quot;,num_lane_change);
  if (num_lane_change &lt; 0 || num_lane_change &gt;= static_cast&lt;int32_t&gt;(cur_lane.waypoints.size()))
  {
    ROS_INFO(&quot;current lane doesn't have change flag&quot;);
    return;
  }

  if((static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right &amp;&amp; right_lane_idx_ &lt; 0)
    || (static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::left &amp;&amp; left_lane_idx_ &lt; 0))
  {
    ROS_WARN(&quot;current lane doesn't have the lane for lane change&quot;);
    return;
  }


  double dt = getTwoDimensionalDistance(cur_lane.waypoints.at(num_lane_change).pose.pose.position, cur_lane.waypoints.at(clst_wp).pose.pose.position);
  double ratio = 3.0;
  double minimum = 5.0;
  double dt_by_vel = current_velocity_.twist.linear.x * ratio &gt; minimum ? current_velocity_.twist.linear.x * ratio : minimum;
  ROS_INFO(&quot;dt : %lf, dt_by_vel : %lf&quot;,dt,dt_by_vel);
  waypoint_follower::lane &amp;nghbr_lane =
      static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
          ? std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_))
          : std::get&lt;0&gt;(tuple_vec_.at(left_lane_idx_));
  const int32_t &amp;nghbr_clst_wp = static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
                                      ? std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_))
                                      : std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_));

  int32_t target_num = -1;
  for (uint32_t i = nghbr_clst_wp; i &lt; nghbr_lane.waypoints.size(); i++)
  {
    if(i == nghbr_lane.waypoints.size() - 1 ||
      dt + dt_by_vel &lt; getTwoDimensionalDistance(nghbr_lane.waypoints.at(nghbr_clst_wp).pose.pose.position,nghbr_lane.waypoints.at(i).pose.pose.position))
    {
      target_num = i;
      break;
    }
  }

  ROS_INFO(&quot;target_num : %d&quot;, target_num);
  if(target_num &lt; 0)
    return;

  std::get&lt;0&gt;(lane_for_change_).header.stamp = nghbr_lane.header.stamp;
  std::vector&lt;waypoint_follower::waypoint&gt; hermite_wps = generateHermiteCurveForROS(
      cur_lane.waypoints.at(num_lane_change).pose.pose, nghbr_lane.waypoints.at(target_num).pose.pose,
      cur_lane.waypoints.at(num_lane_change).twist.twist.linear.x, 5);

  for(auto &amp;&amp;el : hermite_wps)
    el.change_flag = cur_lane.waypoints.at(num_lane_change).change_flag;

  std::get&lt;0&gt;(lane_for_change_).waypoints.reserve(nghbr_lane.waypoints.size() + hermite_wps.size());
  std::move(hermite_wps.begin(), hermite_wps.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
  auto itr = nghbr_lane.waypoints.begin();
  std::advance(itr, target_num);
  for(auto i = itr; i != nghbr_lane.waypoints.end();i++)
  {
    if(getTwoDimensionalDistance(itr-&gt;pose.pose.position,i-&gt;pose.pose.position) &lt; 10)
      i-&gt;change_flag = enumToInteger(ChangeFlag::straight);
    else
      break;
  }
  std::copy(itr,nghbr_lane.waypoints.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
}

void LaneSelectNode::updateChangeFlag()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;2&gt;(el) = (std::get&lt;1&gt;(el) != -1)
                          ? static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(el).waypoints.at(std::get&lt;1&gt;(el)).change_flag)
                          : ChangeFlag::unknown;

    if(std::get&lt;2&gt;(el) == ChangeFlag::right &amp;&amp; right_lane_idx_ == -1)
      std::get&lt;2&gt;(el) = ChangeFlag::unknown;
    else if(std::get&lt;2&gt;(el) == ChangeFlag::left &amp;&amp; left_lane_idx_ == -1)
      std::get&lt;2&gt;(el) = ChangeFlag::unknown;

    ROS_INFO(&quot;change_flag: %d&quot;, enumToInteger(std::get&lt;2&gt;(el)));
  }
}

void LaneSelectNode::changeLane()
{
  if (std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)) == ChangeFlag::right &amp;&amp; right_lane_idx_ != -1 &amp;&amp;
      std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) != -1)
  {
    current_lane_idx_ = right_lane_idx_;
  }
  else if (std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)) == ChangeFlag::left &amp;&amp; left_lane_idx_ != -1 &amp;&amp;
           std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) != -1)
  {
    current_lane_idx_ = left_lane_idx_;
  }

  findNeighborLanes();
  return;
}

bool LaneSelectNode::getClosestWaypointNumberForEachLanes()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;1&gt;(el) = getClosestWaypointNumber(std::get&lt;0&gt;(el), current_pose_.pose, current_velocity_.twist,
                                               std::get&lt;1&gt;(el), distance_threshold_);
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(el));
  }

  // confirm if all closest waypoint numbers are -1. If so, output warning
  int32_t accum = 0;
  for (const auto &amp;el : tuple_vec_)
  {
    accum += std::get&lt;1&gt;(el);
  }
  if (accum == (-1) * static_cast&lt;int32_t&gt;(tuple_vec_.size()))
  {
    ROS_WARN(&quot;Cannot get closest waypoints. All closest waypoints are changed to -1...&quot;);
    return false;
  }

  return true;
}

void LaneSelectNode::findCurrentLane()
{
  std::vector&lt;uint32_t&gt; idx_vec;
  idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;
    idx_vec.push_back(i);
  }
  current_lane_idx_ = findMostClosestLane(idx_vec, current_pose_.pose.position);
}

int32_t LaneSelectNode::findMostClosestLane(const std::vector&lt;uint32_t&gt; idx_vec, const geometry_msgs::Point p)
{
  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    int32_t closest_number = std::get&lt;1&gt;(tuple_vec_.at(el));
    dist_vec.push_back(
        getTwoDimensionalDistance(p, std::get&lt;0&gt;(tuple_vec_.at(el)).waypoints.at(closest_number).pose.pose.position));
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  return idx_vec.at(std::distance(dist_vec.begin(), itr));
}

void LaneSelectNode::findNeighborLanes()
{
  int32_t current_closest_num = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const geometry_msgs::Pose &amp;current_closest_pose =
      std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.at(current_closest_num).pose.pose;

  std::vector&lt;uint32_t&gt; left_lane_idx_vec;
  left_lane_idx_vec.reserve(tuple_vec_.size());
  std::vector&lt;uint32_t&gt; right_lane_idx_vec;
  right_lane_idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (i == static_cast&lt;uint32_t&gt;(current_lane_idx_) || std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    int32_t target_num = std::get&lt;1&gt;(tuple_vec_.at(i));
    const geometry_msgs::Point &amp;target_p = std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(target_num).pose.pose.position;

    geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(target_p, current_closest_pose);

    ROS_INFO(&quot;distance: %lf&quot;, converted_p.y);
    if (fabs(converted_p.y) &gt; distance_threshold_)
    {
      ROS_INFO(&quot;%d lane is far from current lane...&quot;, i);
      continue;
    }

    if (converted_p.y &gt; 0)
      left_lane_idx_vec.push_back(i);
    else
      right_lane_idx_vec.push_back(i);
  }

  if (!left_lane_idx_vec.empty())
    left_lane_idx_ = findMostClosestLane(left_lane_idx_vec, current_closest_pose.position);
  else
    left_lane_idx_ = -1;

  if (!right_lane_idx_vec.empty())
    right_lane_idx_ = findMostClosestLane(right_lane_idx_vec, current_closest_pose.position);
  else
    right_lane_idx_ = -1;
}
visualization_msgs::Marker LaneSelectNode::createCurrentLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;current_lane_marker&quot;;

  if (current_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;
  marker.color = color_current;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createRightLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;right_lane_marker&quot;;

  if (right_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker.color = change_flag == ChangeFlag::right ? color_neighbor_change : color_neighbor;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_)).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createLeftLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;left_lane_marker&quot;;

  if (left_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker.color = change_flag == ChangeFlag::left ? color_neighbor_change : color_neighbor;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at((left_lane_idx_))).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createChangeLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;change_lane_marker&quot;;

  if (std::get&lt;0&gt;(lane_for_change_).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color;
  color.r = 1.0;
  color.a = 0.5;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;

  marker.color = current_state_ == &quot;LANE_CHANGE&quot; ? color_current : color;
  for(const auto &amp;em : std::get&lt;0&gt;(lane_for_change_).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createClosestWaypointsMarker()
{
  visualization_msgs::Marker marker;
  std_msgs::ColorRGBA color_closest_wp;
  color_closest_wp.r = 1.0;
  color_closest_wp.b = 1.0;
  color_closest_wp.g = 1.0;
  color_closest_wp.a = 1.0;

  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;closest_waypoints_marker&quot;;
  marker.type = visualization_msgs::Marker::POINTS;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.5;
  marker.color = color_closest_wp;

  marker.points.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    marker.points.push_back(
        std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(i))).pose.pose.position);
  }

  return marker;
}

void LaneSelectNode::publishVisualizer()
{
  visualization_msgs::MarkerArray marker_array;
  marker_array.markers.push_back(createChangeLaneMarker());
  marker_array.markers.push_back(createCurrentLaneMarker());
  marker_array.markers.push_back(createRightLaneMarker());
  marker_array.markers.push_back(createLeftLaneMarker());
  marker_array.markers.push_back(createClosestWaypointsMarker());

  vis_pub1_.publish(marker_array);
}

void LaneSelectNode::publish(const waypoint_follower::lane &amp;lane, const int32_t clst_wp, const ChangeFlag flag)
{
  // publish global lane
  pub1_.publish(lane);

  // publish closest waypoint
  std_msgs::Int32 closest_waypoint;
  closest_waypoint.data = clst_wp;
  pub2_.publish(closest_waypoint);

  std_msgs::Int32 change_flag;
  change_flag.data = enumToInteger(flag);
  pub3_.publish(change_flag);

  is_current_pose_subscribed_ = false;
  is_current_velocity_subscribed_ = false;
  is_current_state_subscribed_ = false;
}

void LaneSelectNode::callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg)
{
  tuple_vec_.clear();
  tuple_vec_.shrink_to_fit();
  tuple_vec_.reserve(msg-&gt;lanes.size());
  for (const auto &amp;el : msg-&gt;lanes)
  {
    auto t = std::make_tuple(el, -1, ChangeFlag::unknown);
    tuple_vec_.push_back(t);
  }

  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  is_lane_array_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  current_pose_ = *msg;
  is_current_pose_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromTwistStamped(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  current_velocity_ = *msg;
  is_current_velocity_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromState(const std_msgs::StringConstPtr &amp;msg)
{
  current_state_ = msg-&gt;data;
  is_current_state_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::run()
{
  ros::spin();
}

// distance between target 1 and target2 in 2-D
double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2)
{
  double distance = sqrt(pow(target1.x - target2.x, 2) + pow(target1.y - target2.y, 2));
  return distance;
}

geometry_msgs::Point convertPointIntoRelativeCoordinate(const geometry_msgs::Point &amp;input_point, const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);
  tf::Transform transform = inverse.inverse();

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = transform * p;
  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);
  return tf_point_msg;
}

geometry_msgs::Point convertPointIntoWorldCoordinate(const geometry_msgs::Point &amp;input_point,
                                                                      const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = inverse * p;

  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);
  return tf_point_msg;
}

double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry_msgs::Pose &amp;current_pose)
{
  tf::Vector3 x_axis(1, 0, 0);
  tf::Transform waypoint_tfpose;
  tf::poseMsgToTF(waypoint_pose, waypoint_tfpose);
  tf::Vector3 waypoint_v = waypoint_tfpose.getBasis() * x_axis;
  tf::Transform current_tfpose;
  tf::poseMsgToTF(current_pose, current_tfpose);
  tf::Vector3 current_v = current_tfpose.getBasis() * x_axis;

  return current_v.angle(waypoint_v) * 180 / M_PI;
}

// get closest waypoint from current pose
int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number,
                                 const double distance_threshold)
{
  if (current_lane.waypoints.empty())
    return -1;


  std::vector&lt;uint32_t&gt; idx_vec;
  // if previous number is -1, search closest waypoint from waypoints in front of current pose
  if (previous_number == -1)
  {
    idx_vec.reserve(current_lane.waypoints.size());
    for (uint32_t i = 0; i &lt; current_lane.waypoints.size(); i++)
    {
      geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
        idx_vec.push_back(i);
    }
  }
  else
  {
    if (distance_threshold &lt;
        getTwoDimensionalDistance(current_lane.waypoints.at(previous_number).pose.pose.position, current_pose.position))
    {
      ROS_WARN(&quot;Current_pose is far away from previous closest waypoint. Initilized...&quot;);
      return -1;
    }

    double ratio = 3;
    double minimum_dt = 2.0;
    double dt = current_velocity.linear.x * ratio &gt; minimum_dt ? current_velocity.linear.x * ratio : minimum_dt;

    auto range_max = static_cast&lt;uint32_t&gt;(previous_number + dt) &lt; current_lane.waypoints.size()
                         ? static_cast&lt;uint32_t&gt;(previous_number + dt)
                         : current_lane.waypoints.size();
    for (uint32_t i = static_cast&lt;uint32_t&gt;(previous_number); i &lt; range_max; i++)
    {
      geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
        idx_vec.push_back(i);

    }
  }

  if (idx_vec.empty())
    return -1;

  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    double dt = getTwoDimensionalDistance(current_pose.position, current_lane.waypoints.at(el).pose.pose.position);
    dist_vec.push_back(dt);
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  int32_t found_number = idx_vec.at(static_cast&lt;uint32_t&gt;(std::distance(dist_vec.begin(), itr)));
  return found_number;
}

// let the linear equation be &quot;ax + by + c = 0&quot;
// if there are two points (x1,y1) , (x2,y2), a = &quot;y2-y1, b = &quot;(-1) * x2 - x1&quot; ,c = &quot;(-1) * (y2-y1)x1 + (x2-x1)y1&quot;
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c)
{
  //(x1, y1) = (start.x, star.y), (x2, y2) = (end.x, end.y)
  double sub_x = fabs(start.x - end.x);
  double sub_y = fabs(start.y - end.y);
  double error = pow(10, -5);  // 0.00001

  if (sub_x &lt; error &amp;&amp; sub_y &lt; error)
  {
    ROS_INFO(&quot;two points are the same point!!&quot;);
    return false;
  }

  *a = end.y - start.y;
  *b = (-1) * (end.x - start.x);
  *c = (-1) * (end.y - start.y) * start.x + (end.x - start.x) * start.y;

  return true;
}
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double a, double b, double c)
{
  double d = fabs(a * point.x + b * point.y + c) / sqrt(pow(a, 2) + pow(b, 2));

  return d;
}

}  // lane_planner
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="b80a102257622c799f81058b8d212dfb07da6a94" fix_time="0,8186">
		<msg>Fix style</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp">
				<diff>@@ -188,37 +188,43 @@ void LaneSelectNode::createLaneForChange()
   const int32_t &amp;clst_wp = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
 
   int32_t num_lane_change = getClosestLaneChangeWaypointNumber(cur_lane.waypoints, clst_wp);
-  ROS_INFO(&quot;num_lane_change: %d&quot;,num_lane_change);
+  ROS_INFO(&quot;num_lane_change: %d&quot;, num_lane_change);
   if (num_lane_change &lt; 0 || num_lane_change &gt;= static_cast&lt;int32_t&gt;(cur_lane.waypoints.size()))
   {
     ROS_WARN(&quot;current lane doesn't have change flag&quot;);
     return;
   }
 
-  if((static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right &amp;&amp; right_lane_idx_ &lt; 0)
-    || (static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::left &amp;&amp; left_lane_idx_ &lt; 0))
+  if ((static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right &amp;&amp;
+       right_lane_idx_ &lt; 0) ||
+      (static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::left &amp;&amp;
+       left_lane_idx_ &lt; 0))
   {
     ROS_WARN(&quot;current lane doesn't have the lane for lane change&quot;);
     return;
   }
 
-
-  double dt = getTwoDimensionalDistance(cur_lane.waypoints.at(num_lane_change).pose.pose.position, cur_lane.waypoints.at(clst_wp).pose.pose.position);
-  double dt_by_vel = current_velocity_.twist.linear.x * lane_change_target_ratio_ &gt; lane_change_target_minimum_ ? current_velocity_.twist.linear.x * lane_change_target_ratio_ : lane_change_target_minimum_;
-  ROS_INFO(&quot;dt : %lf, dt_by_vel : %lf&quot;,dt,dt_by_vel);
+  double dt = getTwoDimensionalDistance(cur_lane.waypoints.at(num_lane_change).pose.pose.position,
+                                        cur_lane.waypoints.at(clst_wp).pose.pose.position);
+  double dt_by_vel = current_velocity_.twist.linear.x * lane_change_target_ratio_ &gt; lane_change_target_minimum_
+                         ? current_velocity_.twist.linear.x * lane_change_target_ratio_
+                         : lane_change_target_minimum_;
+  ROS_INFO(&quot;dt : %lf, dt_by_vel : %lf&quot;, dt, dt_by_vel);
   waypoint_follower::lane &amp;nghbr_lane =
       static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
           ? std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_))
           : std::get&lt;0&gt;(tuple_vec_.at(left_lane_idx_));
-  const int32_t &amp;nghbr_clst_wp = static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
-                                      ? std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_))
-                                      : std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_));
+  const int32_t &amp;nghbr_clst_wp =
+      static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
+          ? std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_))
+          : std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_));
 
   int32_t target_num = -1;
   for (uint32_t i = nghbr_clst_wp; i &lt; nghbr_lane.waypoints.size(); i++)
   {
-    if(i == nghbr_lane.waypoints.size() - 1 ||
-      dt + dt_by_vel &lt; getTwoDimensionalDistance(nghbr_lane.waypoints.at(nghbr_clst_wp).pose.pose.position,nghbr_lane.waypoints.at(i).pose.pose.position))
+    if (i == nghbr_lane.waypoints.size() - 1 ||
+        dt + dt_by_vel &lt; getTwoDimensionalDistance(nghbr_lane.waypoints.at(nghbr_clst_wp).pose.pose.position,
+                                                   nghbr_lane.waypoints.at(i).pose.pose.position))
     {
       target_num = i;
       break;
@@ -226,7 +232,7 @@ void LaneSelectNode::createLaneForChange()
   }
 
   ROS_INFO(&quot;target_num : %d&quot;, target_num);
-  if(target_num &lt; 0)
+  if (target_num &lt; 0)
     return;
 
   std::get&lt;0&gt;(lane_for_change_).header.stamp = nghbr_lane.header.stamp;
@@ -234,21 +240,21 @@ void LaneSelectNode::createLaneForChange()
       cur_lane.waypoints.at(num_lane_change).pose.pose, nghbr_lane.waypoints.at(target_num).pose.pose,
       cur_lane.waypoints.at(num_lane_change).twist.twist.linear.x, vlength_hermite_curve_);
 
-  for(auto &amp;&amp;el : hermite_wps)
+  for (auto &amp;&amp;el : hermite_wps)
     el.change_flag = cur_lane.waypoints.at(num_lane_change).change_flag;
 
   std::get&lt;0&gt;(lane_for_change_).waypoints.reserve(nghbr_lane.waypoints.size() + hermite_wps.size());
   std::move(hermite_wps.begin(), hermite_wps.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
   auto itr = nghbr_lane.waypoints.begin();
   std::advance(itr, target_num);
-  for(auto i = itr; i != nghbr_lane.waypoints.end();i++)
+  for (auto i = itr; i != nghbr_lane.waypoints.end(); i++)
   {
-    if(getTwoDimensionalDistance(itr-&gt;pose.pose.position,i-&gt;pose.pose.position) &lt; lane_change_interval_)
+    if (getTwoDimensionalDistance(itr-&gt;pose.pose.position, i-&gt;pose.pose.position) &lt; lane_change_interval_)
       i-&gt;change_flag = enumToInteger(ChangeFlag::straight);
     else
       break;
   }
-  std::copy(itr,nghbr_lane.waypoints.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
+  std::copy(itr, nghbr_lane.waypoints.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
 }
 
 void LaneSelectNode::updateChangeFlag()
@@ -702,12 +708,12 @@ double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry
 
 // get closest waypoint from current pose
 int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
-                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number, const double distance_threshold)
+                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number,
+                                 const double distance_threshold)
 {
   if (current_lane.waypoints.empty())
     return -1;
 
-
   std::vector&lt;uint32_t&gt; idx_vec;
   // if previous number is -1, search closest waypoint from waypoints in front of current pose
   if (previous_number == -1)
@@ -715,7 +721,8 @@ int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, co
     idx_vec.reserve(current_lane.waypoints.size());
     for (uint32_t i = 0; i &lt; current_lane.waypoints.size(); i++)
     {
-      geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
+      geometry_msgs::Point converted_p =
+          convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
       double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
       if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
         idx_vec.push_back(i);
@@ -739,11 +746,11 @@ int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, co
                          : current_lane.waypoints.size();
     for (uint32_t i = static_cast&lt;uint32_t&gt;(previous_number); i &lt; range_max; i++)
     {
-      geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
+      geometry_msgs::Point converted_p =
+          convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
       double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
       if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
         idx_vec.push_back(i);
-
     }
   }
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;lane_select_core.h&quot;

namespace lane_planner
{
// Constructor
LaneSelectNode::LaneSelectNode()
  : private_nh_(&quot;~&quot;)
  , current_lane_idx_(-1)
  , right_lane_idx_(-1)
  , left_lane_idx_(-1)
  , is_lane_array_subscribed_(false)
  , is_current_pose_subscribed_(false)
  , is_current_velocity_subscribed_(false)
  , is_current_state_subscribed_(false)
  , is_config_subscribed_(false)
  , distance_threshold_(3.0)
  , lane_change_interval_(10.0)
  , lane_change_target_ratio_(2.0)
  , lane_change_target_minimum_(5.0)
  , vlength_hermite_curve_(10)
  , current_state_(&quot;UNKNOWN&quot;)
{
  initForROS();
}

// Destructor
LaneSelectNode::~LaneSelectNode()
{
}

void LaneSelectNode::initForROS()
{
  // setup subscriber
  sub1_ = nh_.subscribe(&quot;traffic_waypoints_array&quot;, 1, &amp;LaneSelectNode::callbackFromLaneArray, this);
  sub2_ = nh_.subscribe(&quot;current_pose&quot;, 1, &amp;LaneSelectNode::callbackFromPoseStamped, this);
  sub3_ = nh_.subscribe(&quot;current_velocity&quot;, 1, &amp;LaneSelectNode::callbackFromTwistStamped, this);
  sub4_ = nh_.subscribe(&quot;state&quot;, 1, &amp;LaneSelectNode::callbackFromState, this);
  sub5_ = nh_.subscribe(&quot;/config/lane_select&quot;, 1, &amp;LaneSelectNode::callbackFromConfig, this);

  // setup publisher
  pub1_ = nh_.advertise&lt;waypoint_follower::lane&gt;(&quot;base_waypoints&quot;, 1);
  pub2_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 1);
  pub3_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;change_flag&quot;, 1);
  vis_pub1_ = nh_.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;lane_select_marker&quot;, 1);

  // get from rosparam
  private_nh_.param&lt;double&gt;(&quot;lane_change_interval&quot;, lane_change_interval_, double(2));
  private_nh_.param&lt;double&gt;(&quot;distance_threshold&quot;, distance_threshold_, double(3.0));
}

bool LaneSelectNode::isAllTopicsSubscribed()
{
  if (!is_current_pose_subscribed_ || !is_lane_array_subscribed_ || !is_current_velocity_subscribed_)
  {
    ROS_WARN(&quot;Necessary topics are not subscribed yet. Waiting...&quot;);
    return false;
  }
  return true;
}

void LaneSelectNode::initForLaneSelect()
{
  if(!isAllTopicsSubscribed())
    return;

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    resetLaneIdx();
    return;
  }

  findCurrentLane();
  findNeighborLanes();
  updateChangeFlag();
  createLaneForChange();
  publish(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)), std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)),
          std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)));
  publishVisualizer();
  return;
}

void LaneSelectNode::resetLaneIdx()
{
  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  publishVisualizer();
}

void LaneSelectNode::processing()
{
  if(!isAllTopicsSubscribed())
    return;

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    resetLaneIdx();
    return;
  }

  // if closest waypoint on current lane is -1,
  if (std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) == -1)
  {
    resetLaneIdx();
    return;
  }

  findNeighborLanes();
  ROS_INFO(&quot;current_lane_idx: %d&quot;, current_lane_idx_);
  ROS_INFO(&quot;right_lane_idx: %d&quot;, right_lane_idx_);
  ROS_INFO(&quot;left_lane_idx: %d&quot;, left_lane_idx_);

  if (current_state_ == &quot;LANE_CHANGE&quot;)
  {
    changeLane();
    std::get&lt;1&gt;(lane_for_change_) =
        getClosestWaypointNumber(std::get&lt;0&gt;(lane_for_change_), current_pose_.pose, current_velocity_.twist,
                                 std::get&lt;1&gt;(lane_for_change_), distance_threshold_);
    std::get&lt;2&gt;(lane_for_change_) =
        static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(lane_for_change_).waypoints.at(std::get&lt;1&gt;(lane_for_change_)).change_flag);
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(lane_for_change_));
    publish(std::get&lt;0&gt;(lane_for_change_), std::get&lt;1&gt;(lane_for_change_), std::get&lt;2&gt;(lane_for_change_));
  }
  else
  {
    updateChangeFlag();
    createLaneForChange();
    publish(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)), std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)),
            std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)));
  }
  publishVisualizer();
}

int32_t LaneSelectNode::getClosestLaneChangeWaypointNumber(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, int32_t cl_wp)
{

  for (uint32_t i = cl_wp; i &lt; wps.size(); i++)
  {
    if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::right ||
      static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::left)
    {
      return i;
    }
  }
  return -1;
}

void LaneSelectNode::createLaneForChange()
{
  std::get&lt;0&gt;(lane_for_change_).waypoints.clear();
  std::get&lt;0&gt;(lane_for_change_).waypoints.shrink_to_fit();
  std::get&lt;1&gt;(lane_for_change_) = -1;

  const waypoint_follower::lane &amp;cur_lane = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_));
  const int32_t &amp;clst_wp = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));

  int32_t num_lane_change = getClosestLaneChangeWaypointNumber(cur_lane.waypoints, clst_wp);
  ROS_INFO(&quot;num_lane_change: %d&quot;,num_lane_change);
  if (num_lane_change &lt; 0 || num_lane_change &gt;= static_cast&lt;int32_t&gt;(cur_lane.waypoints.size()))
  {
    ROS_WARN(&quot;current lane doesn't have change flag&quot;);
    return;
  }

  if((static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right &amp;&amp; right_lane_idx_ &lt; 0)
    || (static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::left &amp;&amp; left_lane_idx_ &lt; 0))
  {
    ROS_WARN(&quot;current lane doesn't have the lane for lane change&quot;);
    return;
  }


  double dt = getTwoDimensionalDistance(cur_lane.waypoints.at(num_lane_change).pose.pose.position, cur_lane.waypoints.at(clst_wp).pose.pose.position);
  double dt_by_vel = current_velocity_.twist.linear.x * lane_change_target_ratio_ &gt; lane_change_target_minimum_ ? current_velocity_.twist.linear.x * lane_change_target_ratio_ : lane_change_target_minimum_;
  ROS_INFO(&quot;dt : %lf, dt_by_vel : %lf&quot;,dt,dt_by_vel);
  waypoint_follower::lane &amp;nghbr_lane =
      static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
          ? std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_))
          : std::get&lt;0&gt;(tuple_vec_.at(left_lane_idx_));
  const int32_t &amp;nghbr_clst_wp = static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
                                      ? std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_))
                                      : std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_));

  int32_t target_num = -1;
  for (uint32_t i = nghbr_clst_wp; i &lt; nghbr_lane.waypoints.size(); i++)
  {
    if(i == nghbr_lane.waypoints.size() - 1 ||
      dt + dt_by_vel &lt; getTwoDimensionalDistance(nghbr_lane.waypoints.at(nghbr_clst_wp).pose.pose.position,nghbr_lane.waypoints.at(i).pose.pose.position))
    {
      target_num = i;
      break;
    }
  }

  ROS_INFO(&quot;target_num : %d&quot;, target_num);
  if(target_num &lt; 0)
    return;

  std::get&lt;0&gt;(lane_for_change_).header.stamp = nghbr_lane.header.stamp;
  std::vector&lt;waypoint_follower::waypoint&gt; hermite_wps = generateHermiteCurveForROS(
      cur_lane.waypoints.at(num_lane_change).pose.pose, nghbr_lane.waypoints.at(target_num).pose.pose,
      cur_lane.waypoints.at(num_lane_change).twist.twist.linear.x, vlength_hermite_curve_);

  for(auto &amp;&amp;el : hermite_wps)
    el.change_flag = cur_lane.waypoints.at(num_lane_change).change_flag;

  std::get&lt;0&gt;(lane_for_change_).waypoints.reserve(nghbr_lane.waypoints.size() + hermite_wps.size());
  std::move(hermite_wps.begin(), hermite_wps.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
  auto itr = nghbr_lane.waypoints.begin();
  std::advance(itr, target_num);
  for(auto i = itr; i != nghbr_lane.waypoints.end();i++)
  {
    if(getTwoDimensionalDistance(itr-&gt;pose.pose.position,i-&gt;pose.pose.position) &lt; lane_change_interval_)
      i-&gt;change_flag = enumToInteger(ChangeFlag::straight);
    else
      break;
  }
  std::copy(itr,nghbr_lane.waypoints.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
}

void LaneSelectNode::updateChangeFlag()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;2&gt;(el) = (std::get&lt;1&gt;(el) != -1)
                          ? static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(el).waypoints.at(std::get&lt;1&gt;(el)).change_flag)
                          : ChangeFlag::unknown;

    if(std::get&lt;2&gt;(el) == ChangeFlag::right &amp;&amp; right_lane_idx_ == -1)
      std::get&lt;2&gt;(el) = ChangeFlag::unknown;
    else if(std::get&lt;2&gt;(el) == ChangeFlag::left &amp;&amp; left_lane_idx_ == -1)
      std::get&lt;2&gt;(el) = ChangeFlag::unknown;

    ROS_INFO(&quot;change_flag: %d&quot;, enumToInteger(std::get&lt;2&gt;(el)));
  }
}

void LaneSelectNode::changeLane()
{
  if (std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)) == ChangeFlag::right &amp;&amp; right_lane_idx_ != -1 &amp;&amp;
      std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) != -1)
  {
    current_lane_idx_ = right_lane_idx_;
  }
  else if (std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)) == ChangeFlag::left &amp;&amp; left_lane_idx_ != -1 &amp;&amp;
           std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) != -1)
  {
    current_lane_idx_ = left_lane_idx_;
  }

  findNeighborLanes();
  return;
}

bool LaneSelectNode::getClosestWaypointNumberForEachLanes()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;1&gt;(el) = getClosestWaypointNumber(std::get&lt;0&gt;(el), current_pose_.pose, current_velocity_.twist,
                                               std::get&lt;1&gt;(el), distance_threshold_);
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(el));
  }

  // confirm if all closest waypoint numbers are -1. If so, output warning
  int32_t accum = 0;
  for (const auto &amp;el : tuple_vec_)
  {
    accum += std::get&lt;1&gt;(el);
  }
  if (accum == (-1) * static_cast&lt;int32_t&gt;(tuple_vec_.size()))
  {
    ROS_WARN(&quot;Cannot get closest waypoints. All closest waypoints are changed to -1...&quot;);
    return false;
  }

  return true;
}

void LaneSelectNode::findCurrentLane()
{
  std::vector&lt;uint32_t&gt; idx_vec;
  idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;
    idx_vec.push_back(i);
  }
  current_lane_idx_ = findMostClosestLane(idx_vec, current_pose_.pose.position);
}

int32_t LaneSelectNode::findMostClosestLane(const std::vector&lt;uint32_t&gt; idx_vec, const geometry_msgs::Point p)
{
  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    int32_t closest_number = std::get&lt;1&gt;(tuple_vec_.at(el));
    dist_vec.push_back(
        getTwoDimensionalDistance(p, std::get&lt;0&gt;(tuple_vec_.at(el)).waypoints.at(closest_number).pose.pose.position));
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  return idx_vec.at(std::distance(dist_vec.begin(), itr));
}

void LaneSelectNode::findNeighborLanes()
{
  int32_t current_closest_num = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const geometry_msgs::Pose &amp;current_closest_pose =
      std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.at(current_closest_num).pose.pose;

  std::vector&lt;uint32_t&gt; left_lane_idx_vec;
  left_lane_idx_vec.reserve(tuple_vec_.size());
  std::vector&lt;uint32_t&gt; right_lane_idx_vec;
  right_lane_idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (i == static_cast&lt;uint32_t&gt;(current_lane_idx_) || std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    int32_t target_num = std::get&lt;1&gt;(tuple_vec_.at(i));
    const geometry_msgs::Point &amp;target_p = std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(target_num).pose.pose.position;

    geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(target_p, current_closest_pose);

    ROS_INFO(&quot;distance: %lf&quot;, converted_p.y);
    if (fabs(converted_p.y) &gt; distance_threshold_)
    {
      ROS_INFO(&quot;%d lane is far from current lane...&quot;, i);
      continue;
    }

    if (converted_p.y &gt; 0)
      left_lane_idx_vec.push_back(i);
    else
      right_lane_idx_vec.push_back(i);
  }

  if (!left_lane_idx_vec.empty())
    left_lane_idx_ = findMostClosestLane(left_lane_idx_vec, current_closest_pose.position);
  else
    left_lane_idx_ = -1;

  if (!right_lane_idx_vec.empty())
    right_lane_idx_ = findMostClosestLane(right_lane_idx_vec, current_closest_pose.position);
  else
    right_lane_idx_ = -1;
}
visualization_msgs::Marker LaneSelectNode::createCurrentLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;current_lane_marker&quot;;

  if (current_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;
  marker.color = color_current;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createRightLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;right_lane_marker&quot;;

  if (right_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker.color = change_flag == ChangeFlag::right ? color_neighbor_change : color_neighbor;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_)).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createLeftLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;left_lane_marker&quot;;

  if (left_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker.color = change_flag == ChangeFlag::left ? color_neighbor_change : color_neighbor;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at((left_lane_idx_))).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createChangeLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;change_lane_marker&quot;;

  if (std::get&lt;0&gt;(lane_for_change_).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color;
  color.r = 1.0;
  color.a = 1.0;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;

  marker.color = current_state_ == &quot;LANE_CHANGE&quot; ? color_current : color;
  for(const auto &amp;em : std::get&lt;0&gt;(lane_for_change_).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createClosestWaypointsMarker()
{
  visualization_msgs::Marker marker;
  std_msgs::ColorRGBA color_closest_wp;
  color_closest_wp.r = 1.0;
  color_closest_wp.b = 1.0;
  color_closest_wp.g = 1.0;
  color_closest_wp.a = 1.0;

  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;closest_waypoints_marker&quot;;
  marker.type = visualization_msgs::Marker::POINTS;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.5;
  marker.color = color_closest_wp;

  marker.points.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    marker.points.push_back(
        std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(i))).pose.pose.position);
  }

  return marker;
}

void LaneSelectNode::publishVisualizer()
{
  visualization_msgs::MarkerArray marker_array;
  marker_array.markers.push_back(createChangeLaneMarker());
  marker_array.markers.push_back(createCurrentLaneMarker());
  marker_array.markers.push_back(createRightLaneMarker());
  marker_array.markers.push_back(createLeftLaneMarker());
  marker_array.markers.push_back(createClosestWaypointsMarker());

  vis_pub1_.publish(marker_array);
}

void LaneSelectNode::publish(const waypoint_follower::lane &amp;lane, const int32_t clst_wp, const ChangeFlag flag)
{
  // publish global lane
  pub1_.publish(lane);

  // publish closest waypoint
  std_msgs::Int32 closest_waypoint;
  closest_waypoint.data = clst_wp;
  pub2_.publish(closest_waypoint);

  std_msgs::Int32 change_flag;
  change_flag.data = enumToInteger(flag);
  pub3_.publish(change_flag);

  is_current_pose_subscribed_ = false;
  is_current_velocity_subscribed_ = false;
  is_current_state_subscribed_ = false;
}

void LaneSelectNode::callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg)
{
  tuple_vec_.clear();
  tuple_vec_.shrink_to_fit();
  tuple_vec_.reserve(msg-&gt;lanes.size());
  for (const auto &amp;el : msg-&gt;lanes)
  {
    auto t = std::make_tuple(el, -1, ChangeFlag::unknown);
    tuple_vec_.push_back(t);
  }

  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  is_lane_array_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  current_pose_ = *msg;
  is_current_pose_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromTwistStamped(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  current_velocity_ = *msg;
  is_current_velocity_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromState(const std_msgs::StringConstPtr &amp;msg)
{
  current_state_ = msg-&gt;data;
  is_current_state_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromConfig(const runtime_manager::ConfigLaneSelectConstPtr &amp;msg)
{
  distance_threshold_ = msg-&gt; distance_threshold_neighbor_lanes;
  lane_change_interval_= msg-&gt;lane_change_interval;
    lane_change_target_ratio_ = msg-&gt;lane_change_target_ratio;
  lane_change_target_minimum_ = msg-&gt;lane_change_target_minimum;
    vlength_hermite_curve_= msg-&gt;vector_length_hermite_curve;
  is_config_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::run()
{
  ros::spin();
}

// distance between target 1 and target2 in 2-D
double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2)
{
  double distance = sqrt(pow(target1.x - target2.x, 2) + pow(target1.y - target2.y, 2));
  return distance;
}

geometry_msgs::Point convertPointIntoRelativeCoordinate(const geometry_msgs::Point &amp;input_point, const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);
  tf::Transform transform = inverse.inverse();

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = transform * p;
  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);
  return tf_point_msg;
}

geometry_msgs::Point convertPointIntoWorldCoordinate(const geometry_msgs::Point &amp;input_point,
                                                                      const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = inverse * p;

  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);
  return tf_point_msg;
}

double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry_msgs::Pose &amp;current_pose)
{
  tf::Vector3 x_axis(1, 0, 0);
  tf::Transform waypoint_tfpose;
  tf::poseMsgToTF(waypoint_pose, waypoint_tfpose);
  tf::Vector3 waypoint_v = waypoint_tfpose.getBasis() * x_axis;
  tf::Transform current_tfpose;
  tf::poseMsgToTF(current_pose, current_tfpose);
  tf::Vector3 current_v = current_tfpose.getBasis() * x_axis;

  return current_v.angle(waypoint_v) * 180 / M_PI;
}

// get closest waypoint from current pose
int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number, const double distance_threshold)
{
  if (current_lane.waypoints.empty())
    return -1;


  std::vector&lt;uint32_t&gt; idx_vec;
  // if previous number is -1, search closest waypoint from waypoints in front of current pose
  if (previous_number == -1)
  {
    idx_vec.reserve(current_lane.waypoints.size());
    for (uint32_t i = 0; i &lt; current_lane.waypoints.size(); i++)
    {
      geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
        idx_vec.push_back(i);
    }
  }
  else
  {
    if (distance_threshold &lt;
        getTwoDimensionalDistance(current_lane.waypoints.at(previous_number).pose.pose.position, current_pose.position))
    {
      ROS_WARN(&quot;Current_pose is far away from previous closest waypoint. Initilized...&quot;);
      return -1;
    }

    double ratio = 3;
    double minimum_dt = 2.0;
    double dt = current_velocity.linear.x * ratio &gt; minimum_dt ? current_velocity.linear.x * ratio : minimum_dt;

    auto range_max = static_cast&lt;uint32_t&gt;(previous_number + dt) &lt; current_lane.waypoints.size()
                         ? static_cast&lt;uint32_t&gt;(previous_number + dt)
                         : current_lane.waypoints.size();
    for (uint32_t i = static_cast&lt;uint32_t&gt;(previous_number); i &lt; range_max; i++)
    {
      geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
        idx_vec.push_back(i);

    }
  }

  if (idx_vec.empty())
    return -1;

  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    double dt = getTwoDimensionalDistance(current_pose.position, current_lane.waypoints.at(el).pose.pose.position);
    dist_vec.push_back(dt);
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  int32_t found_number = idx_vec.at(static_cast&lt;uint32_t&gt;(std::distance(dist_vec.begin(), itr)));
  return found_number;
}

// let the linear equation be &quot;ax + by + c = 0&quot;
// if there are two points (x1,y1) , (x2,y2), a = &quot;y2-y1, b = &quot;(-1) * x2 - x1&quot; ,c = &quot;(-1) * (y2-y1)x1 + (x2-x1)y1&quot;
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c)
{
  //(x1, y1) = (start.x, star.y), (x2, y2) = (end.x, end.y)
  double sub_x = fabs(start.x - end.x);
  double sub_y = fabs(start.y - end.y);
  double error = pow(10, -5);  // 0.00001

  if (sub_x &lt; error &amp;&amp; sub_y &lt; error)
  {
    ROS_INFO(&quot;two points are the same point!!&quot;);
    return false;
  }

  *a = end.y - start.y;
  *b = (-1) * (end.x - start.x);
  *c = (-1) * (end.y - start.y) * start.x + (end.x - start.x) * start.y;

  return true;
}
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double a, double b, double c)
{
  double d = fabs(a * point.x + b * point.y + c) / sqrt(pow(a, 2) + pow(b, 2));

  return d;
}

}  // lane_planner
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="b9e09acdffe3dd6d28f22b6430801ad7dd3c8468" fix_time="0,12574">
		<msg>Fix hermite curve</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.cpp">
				<diff>@@ -95,9 +95,9 @@ std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D
 {
   std::vector&lt;Element2D&gt; result;
   const double interval = 1.0;
-  const double error = 1e-3;
   int32_t divide = 2;
-  while (divide &lt; 100)
+  const int32_t loop = 100;
+  while (divide &lt; loop)
   {
     result.reserve(divide);
     for (int32_t i = 0; i &lt; divide; i++)
@@ -114,9 +114,10 @@ std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D
           Element2D((p0.x * coeff_p0 + vlength * v0.x * coeff_v0 + p1.x * coeff_p1 + vlength * v1.x * coeff_v1),
                     (p0.y * coeff_p0 + vlength * v0.y * coeff_v0 + p1.y * coeff_p1 + vlength * v1.y * coeff_v1)));
     }
-    ROS_INFO_STREAM(sqrt(pow((result.at(0).x - result.at(1).x), 2) + pow((result.at(0).y - result.at(1).y), 2)));
-    if (fabs(interval &lt; sqrt(pow((result.at(0).x - result.at(1).x), 2) + pow((result.at(0).y - result.at(1).y), 2))) &lt;
-        error)
+
+    double dt = sqrt(pow((result.at(divide/2 - 1).x - result.at(divide/2).x), 2) + pow((result.at(divide/2 - 1).y - result.at(divide/2).y), 2));
+    std::cout &lt;&lt; &quot;interval : &quot; &lt;&lt; dt &lt;&lt; std::endl;
+    if (interval &gt; dt || divide == loop -1)
       return result;
     else
     {
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;hermite_curve.h&quot;

namespace lane_planner
{
void createVectorFromPose(const geometry_msgs::Pose &amp;p, tf::Vector3 *v)
{
  tf::Transform pose;
  tf::poseMsgToTF(p, pose);
  tf::Vector3 x_axis(1, 0, 0);
  *v = pose.getBasis() * x_axis;
}

void getPointAndVectorFromPose(const geometry_msgs::Pose &amp;pose, Element2D *point, Element2D *vector)
{
  point-&gt;set(pose.position.x, pose.position.y);

  tf::Vector3 tmp_tf_vevtor;
  createVectorFromPose(pose, &amp;tmp_tf_vevtor);
  vector-&gt;set(tmp_tf_vevtor.getX(), tmp_tf_vevtor.getY());
}

std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start,
                                                                    const geometry_msgs::Pose &amp;end,
                                                                    const double velocity_mps, const double vlength)
{
  std::vector&lt;waypoint_follower::waypoint&gt; wps;
  Element2D p0(0, 0), v0(0, 0), p1(0, 0), v1(0, 0);
  getPointAndVectorFromPose(start, &amp;p0, &amp;v0);
  getPointAndVectorFromPose(end, &amp;p1, &amp;v1);

  std::vector&lt;Element2D&gt; result = generateHermiteCurve(p0, v0, p1, v1, vlength);

  double height_d = fabs(start.position.z - end.position.z);
  for (uint32_t i = 0; i &lt; result.size(); i++)
  {
    waypoint_follower::waypoint wp;
    wp.pose.pose.position.x = result.at(i).x;
    wp.pose.pose.position.y = result.at(i).y;
    wp.twist.twist.linear.x = velocity_mps;

    // height
    wp.pose.pose.position.z = (i == 0) ? start.position.z
                                       : (i == result.size() - 1) ? end.position.z
                                       : start.position.z &lt; end.position.z ?start.position.z + height_d * i / result.size()
                                       : start.position.z - height_d * i / result.size();

    // orientation
    if (i != result.size() - 1)
    {
      double radian = atan2(result.at(i + 1).y - result.at(i).y, result.at(i + 1).x - result.at(i).x);
      wp.pose.pose.orientation = tf::createQuaternionMsgFromYaw(radian);
    }
    else
    {
      wp.pose.pose.orientation = wps.at(wps.size() - 1).pose.pose.orientation;
    }

    wps.push_back(wp);
  }
  return wps;
}

std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1, const Element2D &amp;v1, const double vlength)
{
  std::vector&lt;Element2D&gt; result;
  const double interval = 1.0;
  const double error = 1e-3;
  int32_t divide = 2;
  while (divide &lt; 100)
  {
    result.reserve(divide);
    for (int32_t i = 0; i &lt; divide; i++)
    {
      double u = i * 1.0 / (divide - 1);
      double u_square = pow(u, 2);
      double u_cube = pow(u, 3);
      double coeff_p0 = 2 * u_cube - 3 * u_square + 1;
      double coeff_v0 = u_cube - 2 * u_square + u;
      double coeff_p1 = (-1) * 2 * u_cube + 3 * u_square;
      double coeff_v1 = u_cube - u_square;
      //printf(&quot;u: %lf, u^2: %lf, u^3: %lf, coeff_p0: %lf, coeff_v0: %lf, coeff_p1: %lf, coeff_v1: %lf\n&quot;, u, u_square, u_cube, coeff_p0, coeff_p1, coeff_v0, coeff_v1);
      result.push_back(
          Element2D((p0.x * coeff_p0 + vlength * v0.x * coeff_v0 + p1.x * coeff_p1 + vlength * v1.x * coeff_v1),
                    (p0.y * coeff_p0 + vlength * v0.y * coeff_v0 + p1.y * coeff_p1 + vlength * v1.y * coeff_v1)));
    }
    ROS_INFO_STREAM(sqrt(pow((result.at(0).x - result.at(1).x), 2) + pow((result.at(0).y - result.at(1).y), 2)));
    if (fabs(interval &lt; sqrt(pow((result.at(0).x - result.at(1).x), 2) + pow((result.at(0).y - result.at(1).y), 2))) &lt;
        error)
      return result;
    else
    {
      result.clear();
      result.shrink_to_fit();
      divide++;
    }
  }
  return result;
}
}  // namespace
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="3025300194b202ffff7af34c91f4d2c140e9d929" fix_time="0,8522">
		<msg>Fix style</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.cpp">
				<diff>@@ -70,9 +70,9 @@ std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geomet
     wp.twist.twist.linear.x = velocity_mps;
 
     // height
-    wp.pose.pose.position.z = (i == 0) ? start.position.z
-                                       : (i == result.size() - 1) ? end.position.z
-                                       : start.position.z &lt; end.position.z ?start.position.z + height_d * i / result.size()
+    wp.pose.pose.position.z = (i == 0) ? start.position.z : (i == result.size() - 1)
+                                       ? end.position.z : start.position.z &lt; end.position.z
+                                       ? start.position.z + height_d * i / result.size()
                                        : start.position.z - height_d * i / result.size();
 
     // orientation
@@ -91,7 +91,8 @@ std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geomet
   return wps;
 }
 
-std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1, const Element2D &amp;v1, const double vlength)
+std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1,
+                                            const Element2D &amp;v1, const double vlength)
 {
   std::vector&lt;Element2D&gt; result;
   const double interval = 1.0;
@@ -109,15 +110,17 @@ std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D
       double coeff_v0 = u_cube - 2 * u_square + u;
       double coeff_p1 = (-1) * 2 * u_cube + 3 * u_square;
       double coeff_v1 = u_cube - u_square;
-      //printf(&quot;u: %lf, u^2: %lf, u^3: %lf, coeff_p0: %lf, coeff_v0: %lf, coeff_p1: %lf, coeff_v1: %lf\n&quot;, u, u_square, u_cube, coeff_p0, coeff_p1, coeff_v0, coeff_v1);
+      // printf(&quot;u: %lf, u^2: %lf, u^3: %lf, coeff_p0: %lf, coeff_v0: %lf, coeff_p1: %lf, coeff_v1: %lf\n&quot;, u, u_square,
+      // u_cube, coeff_p0, coeff_p1, coeff_v0, coeff_v1);
       result.push_back(
           Element2D((p0.x * coeff_p0 + vlength * v0.x * coeff_v0 + p1.x * coeff_p1 + vlength * v1.x * coeff_v1),
                     (p0.y * coeff_p0 + vlength * v0.y * coeff_v0 + p1.y * coeff_p1 + vlength * v1.y * coeff_v1)));
     }
 
-    double dt = sqrt(pow((result.at(divide/2 - 1).x - result.at(divide/2).x), 2) + pow((result.at(divide/2 - 1).y - result.at(divide/2).y), 2));
+    double dt = sqrt(pow((result.at(divide / 2 - 1).x - result.at(divide / 2).x), 2) +
+                     pow((result.at(divide / 2 - 1).y - result.at(divide / 2).y), 2));
     std::cout &lt;&lt; &quot;interval : &quot; &lt;&lt; dt &lt;&lt; std::endl;
-    if (interval &gt; dt || divide == loop -1)
+    if (interval &gt; dt || divide == loop - 1)
       return result;
     else
     {
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;hermite_curve.h&quot;

namespace lane_planner
{
void createVectorFromPose(const geometry_msgs::Pose &amp;p, tf::Vector3 *v)
{
  tf::Transform pose;
  tf::poseMsgToTF(p, pose);
  tf::Vector3 x_axis(1, 0, 0);
  *v = pose.getBasis() * x_axis;
}

void getPointAndVectorFromPose(const geometry_msgs::Pose &amp;pose, Element2D *point, Element2D *vector)
{
  point-&gt;set(pose.position.x, pose.position.y);

  tf::Vector3 tmp_tf_vevtor;
  createVectorFromPose(pose, &amp;tmp_tf_vevtor);
  vector-&gt;set(tmp_tf_vevtor.getX(), tmp_tf_vevtor.getY());
}

std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start,
                                                                    const geometry_msgs::Pose &amp;end,
                                                                    const double velocity_mps, const double vlength)
{
  std::vector&lt;waypoint_follower::waypoint&gt; wps;
  Element2D p0(0, 0), v0(0, 0), p1(0, 0), v1(0, 0);
  getPointAndVectorFromPose(start, &amp;p0, &amp;v0);
  getPointAndVectorFromPose(end, &amp;p1, &amp;v1);

  std::vector&lt;Element2D&gt; result = generateHermiteCurve(p0, v0, p1, v1, vlength);

  double height_d = fabs(start.position.z - end.position.z);
  for (uint32_t i = 0; i &lt; result.size(); i++)
  {
    waypoint_follower::waypoint wp;
    wp.pose.pose.position.x = result.at(i).x;
    wp.pose.pose.position.y = result.at(i).y;
    wp.twist.twist.linear.x = velocity_mps;

    // height
    wp.pose.pose.position.z = (i == 0) ? start.position.z
                                       : (i == result.size() - 1) ? end.position.z
                                       : start.position.z &lt; end.position.z ?start.position.z + height_d * i / result.size()
                                       : start.position.z - height_d * i / result.size();

    // orientation
    if (i != result.size() - 1)
    {
      double radian = atan2(result.at(i + 1).y - result.at(i).y, result.at(i + 1).x - result.at(i).x);
      wp.pose.pose.orientation = tf::createQuaternionMsgFromYaw(radian);
    }
    else
    {
      wp.pose.pose.orientation = wps.at(wps.size() - 1).pose.pose.orientation;
    }

    wps.push_back(wp);
  }
  return wps;
}

std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1, const Element2D &amp;v1, const double vlength)
{
  std::vector&lt;Element2D&gt; result;
  const double interval = 1.0;
  int32_t divide = 2;
  const int32_t loop = 100;
  while (divide &lt; loop)
  {
    result.reserve(divide);
    for (int32_t i = 0; i &lt; divide; i++)
    {
      double u = i * 1.0 / (divide - 1);
      double u_square = pow(u, 2);
      double u_cube = pow(u, 3);
      double coeff_p0 = 2 * u_cube - 3 * u_square + 1;
      double coeff_v0 = u_cube - 2 * u_square + u;
      double coeff_p1 = (-1) * 2 * u_cube + 3 * u_square;
      double coeff_v1 = u_cube - u_square;
      //printf(&quot;u: %lf, u^2: %lf, u^3: %lf, coeff_p0: %lf, coeff_v0: %lf, coeff_p1: %lf, coeff_v1: %lf\n&quot;, u, u_square, u_cube, coeff_p0, coeff_p1, coeff_v0, coeff_v1);
      result.push_back(
          Element2D((p0.x * coeff_p0 + vlength * v0.x * coeff_v0 + p1.x * coeff_p1 + vlength * v1.x * coeff_v1),
                    (p0.y * coeff_p0 + vlength * v0.y * coeff_v0 + p1.y * coeff_p1 + vlength * v1.y * coeff_v1)));
    }

    double dt = sqrt(pow((result.at(divide/2 - 1).x - result.at(divide/2).x), 2) + pow((result.at(divide/2 - 1).y - result.at(divide/2).y), 2));
    std::cout &lt;&lt; &quot;interval : &quot; &lt;&lt; dt &lt;&lt; std::endl;
    if (interval &gt; dt || divide == loop -1)
      return result;
    else
    {
      result.clear();
      result.shrink_to_fit();
      divide++;
    }
  }
  return result;
}
}  // namespace
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.h" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.h">
				<diff>@@ -63,8 +63,11 @@ struct Element2D
   double y;
 };
 
-std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1, const Element2D &amp;v1, const double vlength = 20);
-std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start, const geometry_msgs::Pose &amp;end, const double velocity,  const double vlength);
+std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1,
+                                            const Element2D &amp;v1, const double vlength = 20);
+std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start,
+                                                                    const geometry_msgs::Pose &amp;end,
+                                                                    const double velocity, const double vlength);
 void createVectorFromPose(const geometry_msgs::Pose &amp;p, tf::Vector3 *v);
 }  // namespace
 #endif  // HERMITE_CURVE_H
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef HERMITE_CURVE_H
#define HERMITE_CURVE_H

// C++ includes
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;cmath&gt;
#include &lt;cstdio&gt;

// ROS includes
#include &lt;ros/ros.h&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;geometry_msgs/Pose.h&gt;

#include &quot;waypoint_follower/lane.h&quot;

namespace lane_planner
{
struct Element2D
{
  Element2D(double x, double y)
  {
    this-&gt;x = x;
    this-&gt;y = y;
  }
  void set(double x, double y)
  {
    this-&gt;x = x;
    this-&gt;y = y;
  }
  double x;
  double y;
};

std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1, const Element2D &amp;v1, const double vlength = 20);
std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start, const geometry_msgs::Pose &amp;end, const double velocity,  const double vlength);
void createVectorFromPose(const geometry_msgs::Pose &amp;p, tf::Vector3 *v);
}  // namespace
#endif  // HERMITE_CURVE_H
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="577c9868d7189024eaaa6a0d9141a572a20a7550" fix_time="0,0">
		<msg>bug fix</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_matching/ndt_matching.cpp" new_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_matching/ndt_matching.cpp">
				<diff>@@ -290,6 +290,9 @@ static void map_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
   if (points_map_num != input-&gt;width)
   {
     std::cout &lt;&lt; &quot;Update points_map.&quot; &lt;&lt; std::endl;
+
+    points_map_num = input-&gt;width;
+
     // Convert the data type(from sensor_msgs to pcl).
     pcl::fromROSMsg(*input, map);
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

/*
 Localization program using Normal Distributions Transform

 Yuki KITSUKAWA
 */

#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;fstream&gt;
#include &lt;string&gt;
#include &lt;chrono&gt;

#include &lt;pthread.h&gt;

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/Float32.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;std_msgs/Bool.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;velodyne_pointcloud/point_types.h&gt;
#include &lt;velodyne_pointcloud/rawdata.h&gt;

#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;

#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;tf/transform_listener.h&gt;

#include &lt;pcl/io/io.h&gt;
#include &lt;pcl/io/pcd_io.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#ifdef USE_FAST_PCL
#include &lt;fast_pcl/registration/ndt.h&gt;
#else
#include &lt;pcl/registration/ndt.h&gt;
#endif

#include &lt;pcl_ros/point_cloud.h&gt;
#include &lt;pcl_ros/transforms.h&gt;

#include &lt;runtime_manager/ConfigNdt.h&gt;

#include &lt;ndt_localizer/ndt_stat.h&gt;

#define PREDICT_POSE_THRESHOLD 0.5

#define Wa 0.4
#define Wb 0.3
#define Wc 0.3

struct pose
{
  double x;
  double y;
  double z;
  double roll;
  double pitch;
  double yaw;
};

static pose initial_pose, predict_pose, previous_pose, ndt_pose, current_pose, localizer_pose, previous_gnss_pose,
    current_gnss_pose;

static double offset_x, offset_y, offset_z, offset_yaw;  // current_pos - previous_pose

// Can't load if typed &quot;pcl::PointCloud&lt;pcl::PointXYZRGB&gt; map, add;&quot;
static pcl::PointCloud&lt;pcl::PointXYZ&gt; map, add;

// If the map is loaded, map_loaded will be 1.
static int map_loaded = 0;
static int _use_gnss = 1;
static int init_pos_set = 0;

static pcl::NormalDistributionsTransform&lt;pcl::PointXYZ, pcl::PointXYZ&gt; ndt;
// Default values
static int iter = 30;            // Maximum iterations
static float ndt_res = 1.0;      // Resolution
static double step_size = 0.1;   // Step size
static double trans_eps = 0.01;  // Transformation epsilon

static ros::Publisher predict_pose_pub;
static geometry_msgs::PoseStamped predict_pose_msg;

static ros::Publisher ndt_pose_pub;
static geometry_msgs::PoseStamped ndt_pose_msg;

// current_pose is published by vel_pose_mux
/*
static ros::Publisher current_pose_pub;
static geometry_msgs::PoseStamped current_pose_msg;
*/

static ros::Publisher localizer_pose_pub;
static geometry_msgs::PoseStamped localizer_pose_msg;

static ros::Publisher estimate_twist_pub;
static geometry_msgs::TwistStamped estimate_twist_msg;

static ros::Time current_scan_time;
static ros::Time previous_scan_time;
static ros::Duration scan_duration;

static double exe_time = 0.0;
static int iteration = 0;
static double fitness_score = 0.0;
static double trans_probability = 0.0;

static double diff = 0.0;
static double diff_x = 0.0, diff_y = 0.0, diff_z = 0.0, diff_yaw;

static double current_velocity = 0.0, previous_velocity = 0.0, previous_previous_velocity = 0.0;  // [m/s]
static double current_velocity_x = 0.0, previous_velocity_x = 0.0;
static double current_velocity_y = 0.0, previous_velocity_y = 0.0;
static double current_velocity_z = 0.0, previous_velocity_z = 0.0;
// static double current_velocity_yaw = 0.0, previous_velocity_yaw = 0.0;
static double current_velocity_smooth = 0.0;

static double current_accel = 0.0, previous_accel = 0.0;  // [m/s^2]
static double current_accel_x = 0.0;
static double current_accel_y = 0.0;
static double current_accel_z = 0.0;
// static double current_accel_yaw = 0.0;

static double angular_velocity = 0.0;

static int use_predict_pose = 0;

static ros::Publisher estimated_vel_mps_pub, estimated_vel_kmph_pub, estimated_vel_pub;
static std_msgs::Float32 estimated_vel_mps, estimated_vel_kmph, previous_estimated_vel_kmph;

static std::chrono::time_point&lt;std::chrono::system_clock&gt; matching_start, matching_end;

static ros::Publisher time_ndt_matching_pub;
static std_msgs::Float32 time_ndt_matching;

static int _queue_size = 1000;

static ros::Publisher ndt_stat_pub;
static ndt_localizer::ndt_stat ndt_stat_msg;

static double predict_pose_error = 0.0;

static double _tf_x, _tf_y, _tf_z, _tf_roll, _tf_pitch, _tf_yaw;
static Eigen::Matrix4f tf_btol, tf_ltob;

static std::string _localizer = &quot;velodyne&quot;;
static std::string _offset = &quot;linear&quot;;  // linear, zero, quadratic

static ros::Publisher ndt_reliability_pub;
static std_msgs::Float32 ndt_reliability;

static bool _use_openmp = false;
static bool _get_height = false;
static bool _use_local_transform = false;

static std::ofstream ofs;
static std::string filename;

// static tf::TransformListener local_transform_listener;
static tf::StampedTransform local_transform;

static int points_map_num = 0;

pthread_mutex_t mutex;

static void param_callback(const runtime_manager::ConfigNdt::ConstPtr&amp; input)
{
  if (_use_gnss != input-&gt;init_pos_gnss)
  {
    init_pos_set = 0;
  }
  else if (_use_gnss == 0 &amp;&amp;
           (initial_pose.x != input-&gt;x || initial_pose.y != input-&gt;y || initial_pose.z != input-&gt;z ||
            initial_pose.roll != input-&gt;roll || initial_pose.pitch != input-&gt;pitch || initial_pose.yaw != input-&gt;yaw))
  {
    init_pos_set = 0;
  }

  _use_gnss = input-&gt;init_pos_gnss;

  // Setting parameters
  if (input-&gt;resolution != ndt_res)
  {
    ndt_res = input-&gt;resolution;
    ndt.setResolution(ndt_res);
  }
  if (input-&gt;step_size != step_size)
  {
    step_size = input-&gt;step_size;
    ndt.setStepSize(step_size);
  }
  if (input-&gt;trans_esp != trans_eps)
  {
    trans_eps = input-&gt;trans_esp;
    ndt.setTransformationEpsilon(trans_eps);
  }

  if (_use_gnss == 0 &amp;&amp; init_pos_set == 0)
  {
    initial_pose.x = input-&gt;x;
    initial_pose.y = input-&gt;y;
    initial_pose.z = input-&gt;z;
    initial_pose.roll = input-&gt;roll;
    initial_pose.pitch = input-&gt;pitch;
    initial_pose.yaw = input-&gt;yaw;

    if (_use_local_transform == true)
    {
      tf::Vector3 v(input-&gt;x, input-&gt;y, input-&gt;z);
      tf::Quaternion q;
      q.setRPY(input-&gt;roll, input-&gt;pitch, input-&gt;yaw);
      tf::Transform transform(q, v);
      initial_pose.x = (local_transform.inverse() * transform).getOrigin().getX();
      initial_pose.y = (local_transform.inverse() * transform).getOrigin().getY();
      initial_pose.z = (local_transform.inverse() * transform).getOrigin().getZ();

      tf::Matrix3x3 m(q);
      m.getRPY(initial_pose.roll, initial_pose.pitch, initial_pose.yaw);

      std::cout &lt;&lt; &quot;initial_pose.x: &quot; &lt;&lt; initial_pose.x &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.y: &quot; &lt;&lt; initial_pose.y &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.z: &quot; &lt;&lt; initial_pose.z &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.roll: &quot; &lt;&lt; initial_pose.roll &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.pitch: &quot; &lt;&lt; initial_pose.pitch &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.yaw: &quot; &lt;&lt; initial_pose.yaw &lt;&lt; std::endl;
    }

    // Setting position and posture for the first time.
    localizer_pose.x = initial_pose.x;
    localizer_pose.y = initial_pose.y;
    localizer_pose.z = initial_pose.z;
    localizer_pose.roll = initial_pose.roll;
    localizer_pose.pitch = initial_pose.pitch;
    localizer_pose.yaw = initial_pose.yaw;

    previous_pose.x = initial_pose.x;
    previous_pose.y = initial_pose.y;
    previous_pose.z = initial_pose.z;
    previous_pose.roll = initial_pose.roll;
    previous_pose.pitch = initial_pose.pitch;
    previous_pose.yaw = initial_pose.yaw;

    current_pose.x = initial_pose.x;
    current_pose.y = initial_pose.y;
    current_pose.z = initial_pose.z;
    current_pose.roll = initial_pose.roll;
    current_pose.pitch = initial_pose.pitch;
    current_pose.yaw = initial_pose.yaw;

    init_pos_set = 1;
  }
}

static void map_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  //if (map_loaded == 0)
  if (points_map_num != input-&gt;width)
  {
    std::cout &lt;&lt; &quot;Update points_map.&quot; &lt;&lt; std::endl;
    // Convert the data type(from sensor_msgs to pcl).
    pcl::fromROSMsg(*input, map);

    if (_use_local_transform == true)
    {
      tf::TransformListener local_transform_listener;
      try
      {
        ros::Time now = ros::Time(0);
        local_transform_listener.waitForTransform(&quot;/map&quot;, &quot;/world&quot;, now, ros::Duration(10.0));
        local_transform_listener.lookupTransform(&quot;/map&quot;, &quot;world&quot;, now, local_transform);
      }
      catch (tf::TransformException&amp; ex)
      {
        ROS_ERROR(&quot;%s&quot;, ex.what());
      }

      pcl_ros::transformPointCloud(map, map, local_transform.inverse());
    }

    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(map));

    pcl::NormalDistributionsTransform&lt;pcl::PointXYZ, pcl::PointXYZ&gt; new_ndt;
    // Setting point cloud to be aligned to.
    new_ndt.setInputTarget(map_ptr);

    // Setting NDT parameters to default values
    new_ndt.setMaximumIterations(iter);
    new_ndt.setResolution(ndt_res);
    new_ndt.setStepSize(step_size);
    new_ndt.setTransformationEpsilon(trans_eps);

    pthread_mutex_lock(&amp;mutex);
    ndt = new_ndt;
    pthread_mutex_unlock(&amp;mutex);

    map_loaded = 1;
  }
}

static void gnss_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; input)
{
  tf::Quaternion gnss_q(input-&gt;pose.orientation.x, input-&gt;pose.orientation.y, input-&gt;pose.orientation.z,
                        input-&gt;pose.orientation.w);
  tf::Matrix3x3 gnss_m(gnss_q);
  current_gnss_pose.x = input-&gt;pose.position.x;
  current_gnss_pose.y = input-&gt;pose.position.y;
  current_gnss_pose.z = input-&gt;pose.position.z;
  gnss_m.getRPY(current_gnss_pose.roll, current_gnss_pose.pitch, current_gnss_pose.yaw);

  if ((_use_gnss == 1 &amp;&amp; init_pos_set == 0) || fitness_score &gt;= 500.0)
  {
    previous_pose.x = previous_gnss_pose.x;
    previous_pose.y = previous_gnss_pose.y;
    previous_pose.z = previous_gnss_pose.z;
    previous_pose.roll = previous_gnss_pose.roll;
    previous_pose.pitch = previous_gnss_pose.pitch;
    previous_pose.yaw = previous_gnss_pose.yaw;

    current_pose.x = current_gnss_pose.x;
    current_pose.y = current_gnss_pose.y;
    current_pose.z = current_gnss_pose.z;
    current_pose.roll = current_gnss_pose.roll;
    current_pose.pitch = current_gnss_pose.pitch;
    current_pose.yaw = current_gnss_pose.yaw;

    offset_x = current_pose.x - previous_pose.x;
    offset_y = current_pose.y - previous_pose.y;
    offset_z = current_pose.z - previous_pose.z;
    offset_yaw = current_pose.yaw - previous_pose.yaw;

    init_pos_set = 1;
  }

  previous_gnss_pose.x = current_gnss_pose.x;
  previous_gnss_pose.y = current_gnss_pose.y;
  previous_gnss_pose.z = current_gnss_pose.z;
  previous_gnss_pose.roll = current_gnss_pose.roll;
  previous_gnss_pose.pitch = current_gnss_pose.pitch;
  previous_gnss_pose.yaw = current_gnss_pose.yaw;
}

static void initialpose_callback(const geometry_msgs::PoseWithCovarianceStamped::ConstPtr&amp; input)
{
  tf::TransformListener listener;
  tf::StampedTransform transform;
  try
  {
    ros::Time now = ros::Time(0);
    listener.waitForTransform(&quot;/map&quot;, &quot;/world&quot;, now, ros::Duration(10.0));
    listener.lookupTransform(&quot;/map&quot;, &quot;world&quot;, now, transform);
  }
  catch (tf::TransformException&amp; ex)
  {
    ROS_ERROR(&quot;%s&quot;, ex.what());
  }

  tf::Quaternion q(input-&gt;pose.pose.orientation.x, input-&gt;pose.pose.orientation.y, input-&gt;pose.pose.orientation.z,
                   input-&gt;pose.pose.orientation.w);
  tf::Matrix3x3 m(q);

  if (_use_local_transform == true)
  {
    current_pose.x = input-&gt;pose.pose.position.x;
    current_pose.y = input-&gt;pose.pose.position.y;
    current_pose.z = input-&gt;pose.pose.position.z;
  }
  else
  {
    current_pose.x = input-&gt;pose.pose.position.x + transform.getOrigin().x();
    current_pose.y = input-&gt;pose.pose.position.y + transform.getOrigin().y();
    current_pose.z = input-&gt;pose.pose.position.z + transform.getOrigin().z();
  }
  m.getRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);

  if (_get_height == true &amp;&amp; map_loaded == 1)
  {
    double min_distance = DBL_MAX;
    double nearest_z = current_pose.z;
    for (const auto&amp; p : map)
    {
      double distance = hypot(current_pose.x - p.x, current_pose.y - p.y);
      if (distance &lt; min_distance)
      {
        min_distance = distance;
        nearest_z = p.z;
      }
    }
    current_pose.z = nearest_z;
  }

  previous_pose.x = current_pose.x;
  previous_pose.y = current_pose.y;
  previous_pose.z = current_pose.z;
  previous_pose.roll = current_pose.roll;
  previous_pose.pitch = current_pose.pitch;
  previous_pose.yaw = current_pose.yaw;

  offset_x = 0.0;
  offset_y = 0.0;
  offset_z = 0.0;
  offset_yaw = 0.0;
}

static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  if (map_loaded == 1 &amp;&amp; init_pos_set == 1)
  {
    matching_start = std::chrono::system_clock::now();

    static tf::TransformBroadcaster br;
    tf::Transform transform;
    tf::Quaternion predict_q, ndt_q, current_q, localizer_q;

    pcl::PointXYZ p;
    pcl::PointCloud&lt;pcl::PointXYZ&gt; filtered_scan;

    current_scan_time = input-&gt;header.stamp;

    pcl::fromROSMsg(*input, filtered_scan);
    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(filtered_scan));
    int scan_points_num = filtered_scan_ptr-&gt;size();

    Eigen::Matrix4f t(Eigen::Matrix4f::Identity());   // base_link
    Eigen::Matrix4f t2(Eigen::Matrix4f::Identity());  // localizer

    std::chrono::time_point&lt;std::chrono::system_clock&gt; align_start, align_end, getFitnessScore_start,
        getFitnessScore_end;
    static double align_time, getFitnessScore_time = 0.0;

    // Setting point cloud to be aligned.
    pthread_mutex_lock(&amp;mutex);
    ndt.setInputSource(filtered_scan_ptr);

    // Guess the initial gross estimation of the transformation
    predict_pose.x = previous_pose.x + offset_x;
    predict_pose.y = previous_pose.y + offset_y;
    predict_pose.z = previous_pose.z + offset_z;
    predict_pose.roll = previous_pose.roll;
    predict_pose.pitch = previous_pose.pitch;
    predict_pose.yaw = previous_pose.yaw + offset_yaw;

    Eigen::Translation3f init_translation(predict_pose.x, predict_pose.y, predict_pose.z);
    Eigen::AngleAxisf init_rotation_x(predict_pose.roll, Eigen::Vector3f::UnitX());
    Eigen::AngleAxisf init_rotation_y(predict_pose.pitch, Eigen::Vector3f::UnitY());
    Eigen::AngleAxisf init_rotation_z(predict_pose.yaw, Eigen::Vector3f::UnitZ());
    Eigen::Matrix4f init_guess = (init_translation * init_rotation_z * init_rotation_y * init_rotation_x) * tf_btol;

    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
#ifdef USE_FAST_PCL
    if (_use_openmp == true)
    {
      align_start = std::chrono::system_clock::now();
      ndt.omp_align(*output_cloud, init_guess);
      align_end = std::chrono::system_clock::now();
    }
    else
    {
#endif
      align_start = std::chrono::system_clock::now();
      ndt.align(*output_cloud, init_guess);
      align_end = std::chrono::system_clock::now();
#ifdef USE_FAST_PCL
    }
#endif
    align_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(align_end - align_start).count() / 1000.0;

    t = ndt.getFinalTransformation();  // localizer
    t2 = t * tf_ltob;                  // base_link

    iteration = ndt.getFinalNumIteration();
#ifdef USE_FAST_PCL
    if (_use_openmp == true)
    {
      getFitnessScore_start = std::chrono::system_clock::now();
      fitness_score = ndt.omp_getFitnessScore();
      getFitnessScore_end = std::chrono::system_clock::now();
    }
    else
    {
#endif
      getFitnessScore_start = std::chrono::system_clock::now();
      fitness_score = ndt.getFitnessScore();
      getFitnessScore_end = std::chrono::system_clock::now();
#ifdef USE_FAST_PCL
    }
#endif
    getFitnessScore_time =
        std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(getFitnessScore_end - getFitnessScore_start).count() /
        1000.0;

    trans_probability = ndt.getTransformationProbability();
    pthread_mutex_unlock(&amp;mutex);

    tf::Matrix3x3 mat_l;  // localizer
    mat_l.setValue(static_cast&lt;double&gt;(t(0, 0)), static_cast&lt;double&gt;(t(0, 1)), static_cast&lt;double&gt;(t(0, 2)),
                   static_cast&lt;double&gt;(t(1, 0)), static_cast&lt;double&gt;(t(1, 1)), static_cast&lt;double&gt;(t(1, 2)),
                   static_cast&lt;double&gt;(t(2, 0)), static_cast&lt;double&gt;(t(2, 1)), static_cast&lt;double&gt;(t(2, 2)));

    // Update localizer_pose
    localizer_pose.x = t(0, 3);
    localizer_pose.y = t(1, 3);
    localizer_pose.z = t(2, 3);
    mat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1);

    tf::Matrix3x3 mat_b;  // base_link
    mat_b.setValue(static_cast&lt;double&gt;(t2(0, 0)), static_cast&lt;double&gt;(t2(0, 1)), static_cast&lt;double&gt;(t2(0, 2)),
                   static_cast&lt;double&gt;(t2(1, 0)), static_cast&lt;double&gt;(t2(1, 1)), static_cast&lt;double&gt;(t2(1, 2)),
                   static_cast&lt;double&gt;(t2(2, 0)), static_cast&lt;double&gt;(t2(2, 1)), static_cast&lt;double&gt;(t2(2, 2)));

    // Update ndt_pose
    ndt_pose.x = t2(0, 3);
    ndt_pose.y = t2(1, 3);
    ndt_pose.z = t2(2, 3);
    mat_b.getRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw, 1);

    // Calculate the difference between ndt_pose and predict_pose
    predict_pose_error = sqrt((ndt_pose.x - predict_pose.x) * (ndt_pose.x - predict_pose.x) +
                              (ndt_pose.y - predict_pose.y) * (ndt_pose.y - predict_pose.y) +
                              (ndt_pose.z - predict_pose.z) * (ndt_pose.z - predict_pose.z));

    if (predict_pose_error &lt;= PREDICT_POSE_THRESHOLD)
    {
      use_predict_pose = 0;
    }
    else
    {
      use_predict_pose = 1;
    }
    use_predict_pose = 0;

    if (use_predict_pose == 0)
    {
      current_pose.x = ndt_pose.x;
      current_pose.y = ndt_pose.y;
      current_pose.z = ndt_pose.z;
      current_pose.roll = ndt_pose.roll;
      current_pose.pitch = ndt_pose.pitch;
      current_pose.yaw = ndt_pose.yaw;
    }
    else
    {
      current_pose.x = predict_pose.x;
      current_pose.y = predict_pose.y;
      current_pose.z = predict_pose.z;
      current_pose.roll = predict_pose.roll;
      current_pose.pitch = predict_pose.pitch;
      current_pose.yaw = predict_pose.yaw;
    }

    // Compute the velocity and acceleration
    scan_duration = current_scan_time - previous_scan_time;
    double secs = scan_duration.toSec();
    diff_x = current_pose.x - previous_pose.x;
    diff_y = current_pose.y - previous_pose.y;
    diff_z = current_pose.z - previous_pose.z;
    diff_yaw = current_pose.yaw - previous_pose.yaw;
    diff = sqrt(diff_x * diff_x + diff_y * diff_y + diff_z * diff_z);

    current_velocity = diff / secs;
    current_velocity_x = diff_x / secs;
    current_velocity_y = diff_y / secs;
    current_velocity_z = diff_z / secs;
    angular_velocity = diff_yaw / secs;

    current_velocity_smooth = (current_velocity + previous_velocity + previous_previous_velocity) / 3.0;
    if (current_velocity_smooth &lt; 0.2)
    {
      current_velocity_smooth = 0.0;
    }

    current_accel = (current_velocity - previous_velocity) / secs;
    current_accel_x = (current_velocity_x - previous_velocity_x) / secs;
    current_accel_y = (current_velocity_y - previous_velocity_y) / secs;
    current_accel_z = (current_velocity_z - previous_velocity_z) / secs;

    estimated_vel_mps.data = current_velocity;
    estimated_vel_kmph.data = current_velocity * 3.6;

    estimated_vel_mps_pub.publish(estimated_vel_mps);
    estimated_vel_kmph_pub.publish(estimated_vel_kmph);

    // Set values for publishing pose
    predict_q.setRPY(predict_pose.roll, predict_pose.pitch, predict_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(predict_pose.x, predict_pose.y, predict_pose.z);
      tf::Transform transform(predict_q, v);
      predict_pose_msg.header.frame_id = &quot;/map&quot;;
      predict_pose_msg.header.stamp = current_scan_time;
      predict_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      predict_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      predict_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      predict_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      predict_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      predict_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      predict_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      predict_pose_msg.header.frame_id = &quot;/map&quot;;
      predict_pose_msg.header.stamp = current_scan_time;
      predict_pose_msg.pose.position.x = predict_pose.x;
      predict_pose_msg.pose.position.y = predict_pose.y;
      predict_pose_msg.pose.position.z = predict_pose.z;
      predict_pose_msg.pose.orientation.x = predict_q.x();
      predict_pose_msg.pose.orientation.y = predict_q.y();
      predict_pose_msg.pose.orientation.z = predict_q.z();
      predict_pose_msg.pose.orientation.w = predict_q.w();
    }

    ndt_q.setRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(ndt_pose.x, ndt_pose.y, ndt_pose.z);
      tf::Transform transform(ndt_q, v);
      ndt_pose_msg.header.frame_id = &quot;/map&quot;;
      ndt_pose_msg.header.stamp = current_scan_time;
      ndt_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      ndt_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      ndt_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      ndt_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      ndt_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      ndt_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      ndt_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      ndt_pose_msg.header.frame_id = &quot;/map&quot;;
      ndt_pose_msg.header.stamp = current_scan_time;
      ndt_pose_msg.pose.position.x = ndt_pose.x;
      ndt_pose_msg.pose.position.y = ndt_pose.y;
      ndt_pose_msg.pose.position.z = ndt_pose.z;
      ndt_pose_msg.pose.orientation.x = ndt_q.x();
      ndt_pose_msg.pose.orientation.y = ndt_q.y();
      ndt_pose_msg.pose.orientation.z = ndt_q.z();
      ndt_pose_msg.pose.orientation.w = ndt_q.w();
    }

    current_q.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);
    // current_pose is published by vel_pose_mux
    /*
    current_pose_msg.header.frame_id = &quot;/map&quot;;
    current_pose_msg.header.stamp = current_scan_time;
    current_pose_msg.pose.position.x = current_pose.x;
    current_pose_msg.pose.position.y = current_pose.y;
    current_pose_msg.pose.position.z = current_pose.z;
    current_pose_msg.pose.orientation.x = current_q.x();
    current_pose_msg.pose.orientation.y = current_q.y();
    current_pose_msg.pose.orientation.z = current_q.z();
    current_pose_msg.pose.orientation.w = current_q.w();
    */

    localizer_q.setRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(localizer_pose.x, localizer_pose.y, localizer_pose.z);
      tf::Transform transform(localizer_q, v);
      localizer_pose_msg.header.frame_id = &quot;/map&quot;;
      localizer_pose_msg.header.stamp = current_scan_time;
      localizer_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      localizer_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      localizer_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      localizer_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      localizer_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      localizer_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      localizer_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      localizer_pose_msg.header.frame_id = &quot;/map&quot;;
      localizer_pose_msg.header.stamp = current_scan_time;
      localizer_pose_msg.pose.position.x = localizer_pose.x;
      localizer_pose_msg.pose.position.y = localizer_pose.y;
      localizer_pose_msg.pose.position.z = localizer_pose.z;
      localizer_pose_msg.pose.orientation.x = localizer_q.x();
      localizer_pose_msg.pose.orientation.y = localizer_q.y();
      localizer_pose_msg.pose.orientation.z = localizer_q.z();
      localizer_pose_msg.pose.orientation.w = localizer_q.w();
    }

    predict_pose_pub.publish(predict_pose_msg);
    ndt_pose_pub.publish(ndt_pose_msg);
    // current_pose is published by vel_pose_mux
    //    current_pose_pub.publish(current_pose_msg);
    localizer_pose_pub.publish(localizer_pose_msg);

    // Send TF &quot;/base_link&quot; to &quot;/map&quot;
    transform.setOrigin(tf::Vector3(current_pose.x, current_pose.y, current_pose.z));
    transform.setRotation(current_q);
    //    br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    if (_use_local_transform == true)
    {
      br.sendTransform(tf::StampedTransform(local_transform * transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    }
    else
    {
      br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    }

    matching_end = std::chrono::system_clock::now();
    exe_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(matching_end - matching_start).count() / 1000.0;
    time_ndt_matching.data = exe_time;
    time_ndt_matching_pub.publish(time_ndt_matching);

    // Set values for /estimate_twist
    estimate_twist_msg.header.stamp = current_scan_time;
    estimate_twist_msg.header.frame_id = &quot;/base_link&quot;;
    estimate_twist_msg.twist.linear.x = current_velocity;
    estimate_twist_msg.twist.linear.y = 0.0;
    estimate_twist_msg.twist.linear.z = 0.0;
    estimate_twist_msg.twist.angular.x = 0.0;
    estimate_twist_msg.twist.angular.y = 0.0;
    estimate_twist_msg.twist.angular.z = angular_velocity;

    estimate_twist_pub.publish(estimate_twist_msg);

    geometry_msgs::Vector3Stamped estimate_vel_msg;
    estimate_vel_msg.header.stamp = current_scan_time;
    estimate_vel_msg.vector.x = current_velocity;
    estimated_vel_pub.publish(estimate_vel_msg);

    // Set values for /ndt_stat
    ndt_stat_msg.header.stamp = current_scan_time;
    ndt_stat_msg.exe_time = time_ndt_matching.data;
    ndt_stat_msg.iteration = iteration;
    ndt_stat_msg.score = fitness_score;
    ndt_stat_msg.velocity = current_velocity;
    ndt_stat_msg.acceleration = current_accel;
    ndt_stat_msg.use_predict_pose = 0;

    ndt_stat_pub.publish(ndt_stat_msg);

    /* Compute NDT_Reliability */
    ndt_reliability.data = Wa * (exe_time / 100.0) * 100.0 + Wb * (iteration / 10.0) * 100.0 +
                           Wc * ((2.0 - trans_probability) / 2.0) * 100.0;
    ndt_reliability_pub.publish(ndt_reliability);

    // Write log
    if (!ofs)
    {
      std::cerr &lt;&lt; &quot;Could not open &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
      exit(1);
    }
    ofs &lt;&lt; input-&gt;header.seq &lt;&lt; &quot;,&quot; &lt;&lt; scan_points_num &lt;&lt; &quot;,&quot; &lt;&lt; step_size &lt;&lt; &quot;,&quot; &lt;&lt; trans_eps &lt;&lt; &quot;,&quot; &lt;&lt; std::fixed
        &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; std::fixed &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.y &lt;&lt; &quot;,&quot;
        &lt;&lt; std::fixed &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.pitch
        &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.y &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.z &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose.roll &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.pitch &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.x - predict_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.y - predict_pose.y &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.z - predict_pose.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll - predict_pose.roll &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.pitch - predict_pose.pitch &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw - predict_pose.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose_error &lt;&lt; &quot;,&quot; &lt;&lt; iteration &lt;&lt; &quot;,&quot; &lt;&lt; fitness_score &lt;&lt; &quot;,&quot; &lt;&lt; trans_probability &lt;&lt; &quot;,&quot;
        &lt;&lt; ndt_reliability.data &lt;&lt; &quot;,&quot; &lt;&lt; current_velocity &lt;&lt; &quot;,&quot; &lt;&lt; current_velocity_smooth &lt;&lt; &quot;,&quot; &lt;&lt; current_accel
        &lt;&lt; &quot;,&quot; &lt;&lt; angular_velocity &lt;&lt; &quot;,&quot; &lt;&lt; time_ndt_matching.data &lt;&lt; &quot;,&quot; &lt;&lt; align_time &lt;&lt; &quot;,&quot; &lt;&lt; getFitnessScore_time
        &lt;&lt; std::endl;

    std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Sequence: &quot; &lt;&lt; input-&gt;header.seq &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Timestamp: &quot; &lt;&lt; input-&gt;header.stamp &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Frame ID: &quot; &lt;&lt; input-&gt;header.frame_id &lt;&lt; std::endl;
    //		std::cout &lt;&lt; &quot;Number of Scan Points: &quot; &lt;&lt; scan_ptr-&gt;size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Number of Filtered Scan Points: &quot; &lt;&lt; scan_points_num &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;NDT has converged: &quot; &lt;&lt; ndt.hasConverged() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Fitness Score: &quot; &lt;&lt; fitness_score &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Transformation Probability: &quot; &lt;&lt; ndt.getTransformationProbability() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Execution Time: &quot; &lt;&lt; exe_time &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Number of Iterations: &quot; &lt;&lt; ndt.getFinalNumIteration() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;NDT Reliability: &quot; &lt;&lt; ndt_reliability.data &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;(x,y,z,roll,pitch,yaw): &quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;(&quot; &lt;&lt; current_pose.x &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.y &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.z &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.roll
              &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.pitch &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Transformation Matrix: &quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; t &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;

    // Update offset
    if (_offset == &quot;linear&quot;)
    {
      offset_x = diff_x;
      offset_y = diff_y;
      offset_z = diff_z;
      offset_yaw = diff_yaw;
    }
    else if (_offset == &quot;quadratic&quot;)
    {
      offset_x = (current_velocity_x + current_accel_x * secs) * secs;
      offset_y = (current_velocity_y + current_accel_y * secs) * secs;
      offset_z = diff_z;
      offset_yaw = diff_yaw;
    }
    else if (_offset == &quot;zero&quot;)
    {
      offset_x = 0.0;
      offset_y = 0.0;
      offset_z = 0.0;
      offset_yaw = 0.0;
    }

    // Update previous_***
    previous_pose.x = current_pose.x;
    previous_pose.y = current_pose.y;
    previous_pose.z = current_pose.z;
    previous_pose.roll = current_pose.roll;
    previous_pose.pitch = current_pose.pitch;
    previous_pose.yaw = current_pose.yaw;

    previous_scan_time.sec = current_scan_time.sec;
    previous_scan_time.nsec = current_scan_time.nsec;

    previous_previous_velocity = previous_velocity;
    previous_velocity = current_velocity;
    previous_velocity_x = current_velocity_x;
    previous_velocity_y = current_velocity_y;
    previous_velocity_z = current_velocity_z;
    previous_accel = current_accel;

    previous_estimated_vel_kmph.data = estimated_vel_kmph.data;
  }
}

void *thread_func(void *args)
{
  ros::NodeHandle nh_map;
  ros::CallbackQueue map_callback_queue;
  nh_map.setCallbackQueue(&amp;map_callback_queue);

  ros::Subscriber map_sub = nh_map.subscribe(&quot;points_map&quot;, 10, map_callback);
  while (nh_map.ok())
  {
    map_callback_queue.callAvailable(ros::WallDuration());
  }
}

int main(int argc, char** argv)
{
  ros::init(argc, argv, &quot;ndt_matching&quot;);
  pthread_mutex_init(&amp;mutex, NULL);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  // Set log file name.
  char buffer[80];
  std::time_t now = std::time(NULL);
  std::tm* pnow = std::localtime(&amp;now);
  std::strftime(buffer, 80, &quot;%Y%m%d_%H%M%S&quot;, pnow);
  filename = &quot;ndt_matching_&quot; + std::string(buffer) + &quot;.csv&quot;;
  ofs.open(filename.c_str(), std::ios::app);

  // Geting parameters
  private_nh.getParam(&quot;use_gnss&quot;, _use_gnss);
  private_nh.getParam(&quot;queue_size&quot;, _queue_size);
  private_nh.getParam(&quot;offset&quot;, _offset);
  private_nh.getParam(&quot;use_openmp&quot;, _use_openmp);
  private_nh.getParam(&quot;get_height&quot;, _get_height);
  private_nh.getParam(&quot;use_local_transform&quot;, _use_local_transform);

  if (nh.getParam(&quot;localizer&quot;, _localizer) == false)
  {
    std::cout &lt;&lt; &quot;localizer is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }

  if (nh.getParam(&quot;tf_x&quot;, _tf_x) == false)
  {
    std::cout &lt;&lt; &quot;tf_x is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_y&quot;, _tf_y) == false)
  {
    std::cout &lt;&lt; &quot;tf_y is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_z&quot;, _tf_z) == false)
  {
    std::cout &lt;&lt; &quot;tf_z is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_roll&quot;, _tf_roll) == false)
  {
    std::cout &lt;&lt; &quot;tf_roll is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_pitch&quot;, _tf_pitch) == false)
  {
    std::cout &lt;&lt; &quot;tf_pitch is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_yaw&quot;, _tf_yaw) == false)
  {
    std::cout &lt;&lt; &quot;tf_yaw is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }

  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Log file: &quot; &lt;&lt; filename &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_gnss: &quot; &lt;&lt; _use_gnss &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;queue_size: &quot; &lt;&lt; _queue_size &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;offset: &quot; &lt;&lt; _offset &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_openmp: &quot; &lt;&lt; _use_openmp &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;get_height: &quot; &lt;&lt; _get_height &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_local_transform: &quot; &lt;&lt; _use_local_transform &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;localizer: &quot; &lt;&lt; _localizer &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;(tf_x,tf_y,tf_z,tf_roll,tf_pitch,tf_yaw): (&quot; &lt;&lt; _tf_x &lt;&lt; &quot;, &quot; &lt;&lt; _tf_y &lt;&lt; &quot;, &quot; &lt;&lt; _tf_z &lt;&lt; &quot;, &quot;
            &lt;&lt; _tf_roll &lt;&lt; &quot;, &quot; &lt;&lt; _tf_pitch &lt;&lt; &quot;, &quot; &lt;&lt; _tf_yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;

  Eigen::Translation3f tl_btol(_tf_x, _tf_y, _tf_z);                 // tl: translation
  Eigen::AngleAxisf rot_x_btol(_tf_roll, Eigen::Vector3f::UnitX());  // rot: rotation
  Eigen::AngleAxisf rot_y_btol(_tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_btol(_tf_yaw, Eigen::Vector3f::UnitZ());
  tf_btol = (tl_btol * rot_z_btol * rot_y_btol * rot_x_btol).matrix();

  Eigen::Translation3f tl_ltob((-1.0) * _tf_x, (-1.0) * _tf_y, (-1.0) * _tf_z);  // tl: translation
  Eigen::AngleAxisf rot_x_ltob((-1.0) * _tf_roll, Eigen::Vector3f::UnitX());     // rot: rotation
  Eigen::AngleAxisf rot_y_ltob((-1.0) * _tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_ltob((-1.0) * _tf_yaw, Eigen::Vector3f::UnitZ());
  tf_ltob = (tl_ltob * rot_z_ltob * rot_y_ltob * rot_x_ltob).matrix();

  // Updated in initialpose_callback or gnss_callback
  initial_pose.x = 0.0;
  initial_pose.y = 0.0;
  initial_pose.z = 0.0;
  initial_pose.roll = 0.0;
  initial_pose.pitch = 0.0;
  initial_pose.yaw = 0.0;

  // Publishers
  predict_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose&quot;, 1000);
  ndt_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/ndt_pose&quot;, 1000);
  // current_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/current_pose&quot;, 1000);
  localizer_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/localizer_pose&quot;, 1000);
  estimate_twist_pub = nh.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;/estimate_twist&quot;, 1000);
  estimated_vel_mps_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/estimated_vel_mps&quot;, 1000);
  estimated_vel_kmph_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/estimated_vel_kmph&quot;, 1000);
  estimated_vel_pub = nh.advertise&lt;geometry_msgs::Vector3Stamped&gt;(&quot;/estimated_vel&quot;, 1000);
  time_ndt_matching_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/time_ndt_matching&quot;, 1000);
  ndt_stat_pub = nh.advertise&lt;ndt_localizer::ndt_stat&gt;(&quot;/ndt_stat&quot;, 1000);
  ndt_reliability_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/ndt_reliability&quot;, 1000);

  // Subscribers
  ros::Subscriber param_sub = nh.subscribe(&quot;config/ndt&quot;, 10, param_callback);
  ros::Subscriber gnss_sub = nh.subscribe(&quot;gnss_pose&quot;, 10, gnss_callback);
//  ros::Subscriber map_sub = nh.subscribe(&quot;points_map&quot;, 10, map_callback);
  ros::Subscriber initialpose_sub = nh.subscribe(&quot;initialpose&quot;, 1000, initialpose_callback);
  ros::Subscriber points_sub = nh.subscribe(&quot;filtered_points&quot;, _queue_size, points_callback);

  pthread_t thread;
  pthread_create(&amp;thread, NULL, thread_func, NULL);

  ros::spin();

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="faa485b7b2f9d2d6fdeee49c0faf9ae3401119d0" fix_time="334,40782">
		<msg>Fixed a bug. It is don't publish when subscribing topic data is empty.</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/obj_fusion/obj_fusion.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/obj_fusion/obj_fusion.cpp">
				<diff>@@ -1,16 +1,16 @@
-#include &lt;ros/ros.h&gt;
 #include &lt;cv_tracker/obj_label.h&gt;
+#include &lt;float.h&gt;
+#include &lt;geometry_msgs/Point.h&gt;
 #include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
 #include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;
 #include &lt;lidar_tracker/CloudCluster.h&gt;
 #include &lt;lidar_tracker/CloudClusterArray.h&gt;
-#include &lt;geometry_msgs/Point.h&gt;
 #include &lt;math.h&gt;
-#include &lt;float.h&gt;
-#include &lt;tf/tf.h&gt;
-#include &lt;tf/transform_listener.h&gt;
 #include &lt;mutex&gt;
+#include &lt;ros/ros.h&gt;
 #include &lt;std_msgs/Time.h&gt;
+#include &lt;tf/tf.h&gt;
+#include &lt;tf/transform_listener.h&gt;
 
 /* flag for comfirming whether multiple topics are received */
 static bool isReady_obj_label;
@@ -34,8 +34,8 @@ static double threshold_min_dist;
 static tf::StampedTransform transform;
 
 struct obj_label_t {
-    std::vector&lt;geometry_msgs::Point&gt; reprojected_positions;
-    std::vector&lt;int&gt; obj_id;
+  std::vector&lt;geometry_msgs::Point&gt; reprojected_positions;
+  std::vector&lt;int&gt; obj_id;
 };
 
 obj_label_t obj_label;
@@ -49,213 +49,226 @@ std::mutex mtx_centroids;
 #define UNLOCK(mtx) (mtx).unlock()
 
 static double euclid_distance(const geometry_msgs::Point pos1,
-                              const geometry_msgs::Point pos2)
-{
-    return sqrt(pow(pos1.x - pos2.x, 2) +
-                pow(pos1.y - pos2.y, 2) +
-                pow(pos1.z - pos2.z, 2));
+                              const geometry_msgs::Point pos2) {
+  return sqrt(pow(pos1.x - pos2.x, 2) + pow(pos1.y - pos2.y, 2) +
+              pow(pos1.z - pos2.z, 2));
 
 } /* static double distance() */
 
-
 /* fusion reprojected position and pointcloud centroids */
-static void fusion_objects(void)
-{
-    obj_label_t obj_label_current;
-    std::vector&lt;lidar_tracker::CloudCluster&gt; v_cloud_cluster_current;
-    std_msgs::Header header = sensor_header;
-    std::vector&lt;geometry_msgs::Point&gt; centroids_current;
-
-    LOCK(mtx_reprojected_positions);
-    copy(obj_label.reprojected_positions.begin(), obj_label.reprojected_positions.end(), back_inserter(obj_label_current.reprojected_positions));
-    copy(obj_label.obj_id.begin(), obj_label.obj_id.end(), back_inserter(obj_label_current.obj_id));
-    UNLOCK(mtx_reprojected_positions);
-
-    LOCK(mtx_centroids);
-    copy(centroids.begin(), centroids.end(), back_inserter(centroids_current));
-    copy(v_cloud_cluster.begin(), v_cloud_cluster.end(), back_inserter(v_cloud_cluster_current));
-    UNLOCK(mtx_centroids);
-
-    if (centroids_current.empty() || obj_label_current.reprojected_positions.empty() ||  obj_label_current.obj_id.empty()) {
-        jsk_recognition_msgs::BoundingBoxArray pub_msg;
-        pub_msg.header = header;
-        std_msgs::Time time;
-        obj_pose_pub.publish(pub_msg);
-
-        time.data = obj_pose_timestamp;
-        obj_pose_timestamp_pub.publish(time);
-        return;
-    }
-
-    std::vector&lt;int&gt; obj_indices;
-
-    for(unsigned int i = 0; i &lt; obj_label_current.obj_id.size(); ++i) {
-        unsigned int min_idx      = 0;
-        double       min_distance = DBL_MAX;
-
-        /* calculate each euclid distance between reprojected position and centroids */
-        for (unsigned int j=0; j&lt;centroids_current.size(); j++) {
-            double distance = euclid_distance(obj_label_current.reprojected_positions.at(i), centroids_current.at(j));
-
-            /* Nearest centroid correspond to this reprojected object */
-            if (distance &lt; min_distance)
-            {
-                min_distance = distance;
-                min_idx      = j;
-            }
-        }
-        if (min_distance &lt; threshold_min_dist) {
-            obj_indices.push_back(min_idx);
-        } else {
-            obj_indices.push_back(-1);
-        }
-    }
-
-    /* Publish marker with centroids coordinates */
+static void fusion_objects(void) {
+  obj_label_t obj_label_current;
+  std::vector&lt;lidar_tracker::CloudCluster&gt; v_cloud_cluster_current;
+  std_msgs::Header header = sensor_header;
+  std::vector&lt;geometry_msgs::Point&gt; centroids_current;
+
+  LOCK(mtx_reprojected_positions);
+  copy(obj_label.reprojected_positions.begin(),
+       obj_label.reprojected_positions.end(),
+       back_inserter(obj_label_current.reprojected_positions));
+  copy(obj_label.obj_id.begin(), obj_label.obj_id.end(),
+       back_inserter(obj_label_current.obj_id));
+  UNLOCK(mtx_reprojected_positions);
+
+  LOCK(mtx_centroids);
+  copy(centroids.begin(), centroids.end(), back_inserter(centroids_current));
+  copy(v_cloud_cluster.begin(), v_cloud_cluster.end(),
+       back_inserter(v_cloud_cluster_current));
+  UNLOCK(mtx_centroids);
+
+  if (centroids_current.empty() ||
+      obj_label_current.reprojected_positions.empty() ||
+      obj_label_current.obj_id.empty()) {
     jsk_recognition_msgs::BoundingBoxArray pub_msg;
     pub_msg.header = header;
+    std_msgs::Time time;
+    obj_pose_pub.publish(pub_msg);
     lidar_tracker::CloudClusterArray cloud_clusters_msg;
     cloud_clusters_msg.header = header;
-
-    for(unsigned int i = 0; i &lt; obj_label_current.obj_id.size(); ++i) {
-        jsk_recognition_msgs::BoundingBox bounding_box;
-        if (obj_indices.at(i) == -1)
-            continue;
-
-        if(object_type == &quot;car&quot;)
-          v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 0;
-        else if(object_type == &quot;person&quot;)
-          v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 1;
-        else
-          v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 2;
-
-        v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.value = obj_label_current.obj_id.at(i);
-        bounding_box = v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box;
-        pub_msg.boxes.push_back(bounding_box);
-        cloud_clusters_msg.clusters.push_back(v_cloud_cluster_current.at(obj_indices.at(i)));
-    }
-
-    obj_pose_pub.publish(pub_msg);
     cluster_class_pub.publish(cloud_clusters_msg);
-    std_msgs::Time time;
+
     time.data = obj_pose_timestamp;
     obj_pose_timestamp_pub.publish(time);
+    return;
+  }
+
+  std::vector&lt;int&gt; obj_indices;
+
+  for (unsigned int i = 0; i &lt; obj_label_current.obj_id.size(); ++i) {
+    unsigned int min_idx = 0;
+    double min_distance = DBL_MAX;
+
+    /* calculate each euclid distance between reprojected position and centroids
+     */
+    for (unsigned int j = 0; j &lt; centroids_current.size(); j++) {
+      double distance =
+          euclid_distance(obj_label_current.reprojected_positions.at(i),
+                          centroids_current.at(j));
+
+      /* Nearest centroid correspond to this reprojected object */
+      if (distance &lt; min_distance) {
+        min_distance = distance;
+        min_idx = j;
+      }
+    }
+    if (min_distance &lt; threshold_min_dist) {
+      obj_indices.push_back(min_idx);
+    } else {
+      obj_indices.push_back(-1);
+    }
+  }
+
+  /* Publish marker with centroids coordinates */
+  jsk_recognition_msgs::BoundingBoxArray pub_msg;
+  pub_msg.header = header;
+  lidar_tracker::CloudClusterArray cloud_clusters_msg;
+  cloud_clusters_msg.header = header;
+
+  for (unsigned int i = 0; i &lt; obj_label_current.obj_id.size(); ++i) {
+    jsk_recognition_msgs::BoundingBox bounding_box;
+    if (obj_indices.at(i) == -1)
+      continue;
+
+    v_cloud_cluster_current.at(obj_indices.at(i)).label = object_type;
+
+    if (object_type == &quot;car&quot;) {
+      v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 0;
+    } else if (object_type == &quot;person&quot;) {
+      v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 1;
+    } else {
+      v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 2;
+      v_cloud_cluster_current.at(obj_indices.at(i)).label = &quot;unknown&quot;;
+    }
+    v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.value =
+        obj_label_current.obj_id.at(i);
+    bounding_box = v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box;
+    pub_msg.boxes.push_back(bounding_box);
+    cloud_clusters_msg.clusters.push_back(
+        v_cloud_cluster_current.at(obj_indices.at(i)));
+  }
+
+  obj_pose_pub.publish(pub_msg);
+  cluster_class_pub.publish(cloud_clusters_msg);
+  std_msgs::Time time;
+  time.data = obj_pose_timestamp;
+  obj_pose_timestamp_pub.publish(time);
 }
 
+void obj_label_cb(const cv_tracker::obj_label &amp;obj_label_msg) {
+  object_type = obj_label_msg.type;
+  obj_pose_timestamp = obj_label_msg.header.stamp;
 
-void obj_label_cb(const cv_tracker::obj_label&amp; obj_label_msg)
-{
-    object_type = obj_label_msg.type;
-    obj_pose_timestamp = obj_label_msg.header.stamp;
+  LOCK(mtx_reprojected_positions);
+  obj_label.reprojected_positions.clear();
+  obj_label.obj_id.clear();
+  UNLOCK(mtx_reprojected_positions);
 
-    LOCK(mtx_reprojected_positions);
-    obj_label.reprojected_positions.clear();
-    obj_label.obj_id.clear();
-    UNLOCK(mtx_reprojected_positions);
+  LOCK(mtx_reprojected_positions);
+  for (unsigned int i = 0; i &lt; obj_label_msg.obj_id.size(); ++i) {
+    obj_label.reprojected_positions.push_back(
+        obj_label_msg.reprojected_pos.at(i));
+    obj_label.obj_id.push_back(obj_label_msg.obj_id.at(i));
+  }
+  UNLOCK(mtx_reprojected_positions);
 
-    LOCK(mtx_reprojected_positions);
-    for (unsigned int i = 0; i &lt; obj_label_msg.obj_id.size(); ++i) {
-        obj_label.reprojected_positions.push_back(obj_label_msg.reprojected_pos.at(i));
-        obj_label.obj_id.push_back(obj_label_msg.obj_id.at(i));
-    }
-    UNLOCK(mtx_reprojected_positions);
+  /* confirm obj_label is subscribed */
+  LOCK(mtx_flag_obj_label);
+  isReady_obj_label = true;
+  UNLOCK(mtx_flag_obj_label);
+
+  /* Publish fusion result if both of topics are ready */
+  if (isReady_obj_label &amp;&amp; isReady_cluster_centroids) {
+    fusion_objects();
 
-    /* confirm obj_label is subscribed */
     LOCK(mtx_flag_obj_label);
-    isReady_obj_label = true;
+    isReady_obj_label = false;
     UNLOCK(mtx_flag_obj_label);
 
-    /* Publish fusion result if both of topics are ready */
-   if (isReady_obj_label &amp;&amp; isReady_cluster_centroids)
-        {
-            fusion_objects();
-
-            LOCK(mtx_flag_obj_label);
-            isReady_obj_label = false;
-            UNLOCK(mtx_flag_obj_label);
-
-            LOCK(mtx_flag_cluster_centroids);
-            isReady_cluster_centroids = false;
-            UNLOCK(mtx_flag_cluster_centroids);
-        }
-
-} /* void obj_label_cb() */
-
-
-void cluster_centroids_cb(const lidar_tracker::CloudClusterArray::Ptr&amp; in_cloud_cluster_array_ptr)
-{
-    LOCK(mtx_centroids);
-    centroids.clear();
-    v_cloud_cluster.clear();
-    UNLOCK(mtx_centroids);
-
-    LOCK(mtx_centroids);
-    static tf::TransformListener trf_listener;
-    try {
-        trf_listener.lookupTransform(&quot;map&quot;, &quot;velodyne&quot;, ros::Time(0), transform);
-        for (int i(0) ; i &lt; (int)in_cloud_cluster_array_ptr-&gt;clusters.size(); ++i) {
-            lidar_tracker::CloudCluster cloud_cluster = in_cloud_cluster_array_ptr-&gt;clusters.at(i);
-            /* convert centroids coodinate from velodyne frame to map frame */
-            tf::Vector3 pt(cloud_cluster.centroid_point.point.x, cloud_cluster.centroid_point.point.y, cloud_cluster.centroid_point.point.z);
-            tf::Vector3 converted = transform * pt;
-            sensor_header = cloud_cluster.header;
-            v_cloud_cluster.push_back(cloud_cluster);
-            geometry_msgs::Point point_in_map;
-            point_in_map.x = converted.x();
-            point_in_map.y = converted.y();
-            point_in_map.z = converted.z();
-
-            centroids.push_back(point_in_map);
-        }
-    }
-    catch (tf::TransformException ex) {
-        ROS_INFO(&quot;%s&quot;, ex.what());
-        ros::Duration(1.0).sleep();
-    }
-    UNLOCK(mtx_centroids);
-
     LOCK(mtx_flag_cluster_centroids);
-    isReady_cluster_centroids = true;
+    isReady_cluster_centroids = false;
     UNLOCK(mtx_flag_cluster_centroids);
+  }
 
-    /* Publish fusion result if both of topics are ready */
-    if (isReady_obj_label &amp;&amp; isReady_cluster_centroids) {
-        fusion_objects();
-
-        LOCK(mtx_flag_obj_label);
-        isReady_obj_label = false;
-        UNLOCK(mtx_flag_obj_label);
+} /* void obj_label_cb() */
 
-        LOCK(mtx_flag_cluster_centroids);
-        isReady_cluster_centroids = false;
-        UNLOCK(mtx_flag_cluster_centroids);
+void cluster_centroids_cb(
+    const lidar_tracker::CloudClusterArray::Ptr &amp;in_cloud_cluster_array_ptr) {
+  LOCK(mtx_centroids);
+  centroids.clear();
+  v_cloud_cluster.clear();
+  UNLOCK(mtx_centroids);
+
+  LOCK(mtx_centroids);
+  static tf::TransformListener trf_listener;
+  try {
+    trf_listener.lookupTransform(&quot;map&quot;, &quot;velodyne&quot;, ros::Time(0), transform);
+    for (int i(0); i &lt; (int)in_cloud_cluster_array_ptr-&gt;clusters.size(); ++i) {
+      lidar_tracker::CloudCluster cloud_cluster =
+          in_cloud_cluster_array_ptr-&gt;clusters.at(i);
+      /* convert centroids coodinate from velodyne frame to map frame */
+      tf::Vector3 pt(cloud_cluster.centroid_point.point.x,
+                     cloud_cluster.centroid_point.point.y,
+                     cloud_cluster.centroid_point.point.z);
+      tf::Vector3 converted = transform * pt;
+      sensor_header = cloud_cluster.header;
+      v_cloud_cluster.push_back(cloud_cluster);
+      geometry_msgs::Point point_in_map;
+      point_in_map.x = converted.x();
+      point_in_map.y = converted.y();
+      point_in_map.z = converted.z();
+
+      centroids.push_back(point_in_map);
     }
+  } catch (tf::TransformException ex) {
+    ROS_INFO(&quot;%s&quot;, ex.what());
+    ros::Duration(1.0).sleep();
+  }
+  UNLOCK(mtx_centroids);
 
-} /* void cluster_centroids_cb() */
-
+  LOCK(mtx_flag_cluster_centroids);
+  isReady_cluster_centroids = true;
+  UNLOCK(mtx_flag_cluster_centroids);
 
-int main(int argc, char* argv[])
-{
-    /* ROS initialization */
-    ros::init(argc, argv, &quot;obj_fusion&quot;);
+  /* Publish fusion result if both of topics are ready */
+  if (isReady_obj_label &amp;&amp; isReady_cluster_centroids) {
+    fusion_objects();
 
-    ros::NodeHandle n;
-    ros::NodeHandle private_n (&quot;~&quot;);
+    LOCK(mtx_flag_obj_label);
+    isReady_obj_label = false;
+    UNLOCK(mtx_flag_obj_label);
 
-    if (private_n.getParam(&quot;min_dist&quot;, threshold_min_dist))
-  	{
-      threshold_min_dist = 5.0;
-  	}
-    /* Initialize flags */
-    isReady_obj_label         = false;
+    LOCK(mtx_flag_cluster_centroids);
     isReady_cluster_centroids = false;
+    UNLOCK(mtx_flag_cluster_centroids);
+  }
 
-    ros::Subscriber obj_label_sub         = n.subscribe(&quot;obj_label&quot;, SUBSCRIBE_QUEUE_SIZE, obj_label_cb);
-    ros::Subscriber cluster_centroids_sub = n.subscribe(&quot;/cloud_clusters&quot;, SUBSCRIBE_QUEUE_SIZE, cluster_centroids_cb);
-    obj_pose_pub = n.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(&quot;obj_pose&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
-	  cluster_class_pub = n.advertise&lt;lidar_tracker::CloudClusterArray&gt;(&quot;/cloud_cluster_class&quot;, ADVERTISE_QUEUE_SIZE);
-    obj_pose_timestamp_pub = n.advertise&lt;std_msgs::Time&gt;(&quot;obj_pose_timestamp&quot;, ADVERTISE_QUEUE_SIZE);
-    ros::spin();
+} /* void cluster_centroids_cb() */
 
-    return 0;
+int main(int argc, char *argv[]) {
+  /* ROS initialization */
+  ros::init(argc, argv, &quot;obj_fusion&quot;);
+
+  ros::NodeHandle n;
+  ros::NodeHandle private_n(&quot;~&quot;);
+
+  if (!private_n.getParam(&quot;min_dist&quot;, threshold_min_dist)) {
+    threshold_min_dist = 2.0;
+  }
+  /* Initialize flags */
+  isReady_obj_label = false;
+  isReady_cluster_centroids = false;
+
+  ros::Subscriber obj_label_sub =
+      n.subscribe(&quot;obj_label&quot;, SUBSCRIBE_QUEUE_SIZE, obj_label_cb);
+  ros::Subscriber cluster_centroids_sub = n.subscribe(
+      &quot;/cloud_clusters&quot;, SUBSCRIBE_QUEUE_SIZE, cluster_centroids_cb);
+  obj_pose_pub = n.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(
+      &quot;obj_pose&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
+  cluster_class_pub = n.advertise&lt;lidar_tracker::CloudClusterArray&gt;(
+      &quot;/cloud_cluster_class&quot;, ADVERTISE_QUEUE_SIZE);
+  obj_pose_timestamp_pub =
+      n.advertise&lt;std_msgs::Time&gt;(&quot;obj_pose_timestamp&quot;, ADVERTISE_QUEUE_SIZE);
+  ros::spin();
+
+  return 0;
 }
</diff>
				<old_file>#include &lt;ros/ros.h&gt;
#include &lt;cv_tracker/obj_label.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;
#include &lt;lidar_tracker/CloudCluster.h&gt;
#include &lt;lidar_tracker/CloudClusterArray.h&gt;
#include &lt;geometry_msgs/Point.h&gt;
#include &lt;math.h&gt;
#include &lt;float.h&gt;
#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;mutex&gt;
#include &lt;std_msgs/Time.h&gt;

/* flag for comfirming whether multiple topics are received */
static bool isReady_obj_label;
static bool isReady_cluster_centroids;

static constexpr uint32_t SUBSCRIBE_QUEUE_SIZE = 100;
static constexpr uint32_t ADVERTISE_QUEUE_SIZE = 10;
static constexpr bool ADVERTISE_LATCH = false;
static constexpr double LOOP_RATE = 15.0;

ros::Publisher obj_pose_pub;
ros::Publisher obj_pose_timestamp_pub;
ros::Publisher cluster_class_pub;

static std::string object_type;
static std::vector&lt;geometry_msgs::Point&gt; centroids;
static std_msgs::Header sensor_header;
static std::vector&lt;lidar_tracker::CloudCluster&gt; v_cloud_cluster;
static ros::Time obj_pose_timestamp;
static double threshold_min_dist;
static tf::StampedTransform transform;

struct obj_label_t {
    std::vector&lt;geometry_msgs::Point&gt; reprojected_positions;
    std::vector&lt;int&gt; obj_id;
};

obj_label_t obj_label;

/* mutex to handle objects from within multi thread safely */
std::mutex mtx_flag_obj_label;
std::mutex mtx_flag_cluster_centroids;
std::mutex mtx_reprojected_positions;
std::mutex mtx_centroids;
#define LOCK(mtx) (mtx).lock()
#define UNLOCK(mtx) (mtx).unlock()

static double euclid_distance(const geometry_msgs::Point pos1,
                              const geometry_msgs::Point pos2)
{
    return sqrt(pow(pos1.x - pos2.x, 2) +
                pow(pos1.y - pos2.y, 2) +
                pow(pos1.z - pos2.z, 2));

} /* static double distance() */


/* fusion reprojected position and pointcloud centroids */
static void fusion_objects(void)
{
    obj_label_t obj_label_current;
    std::vector&lt;lidar_tracker::CloudCluster&gt; v_cloud_cluster_current;
    std_msgs::Header header = sensor_header;
    std::vector&lt;geometry_msgs::Point&gt; centroids_current;

    LOCK(mtx_reprojected_positions);
    copy(obj_label.reprojected_positions.begin(), obj_label.reprojected_positions.end(), back_inserter(obj_label_current.reprojected_positions));
    copy(obj_label.obj_id.begin(), obj_label.obj_id.end(), back_inserter(obj_label_current.obj_id));
    UNLOCK(mtx_reprojected_positions);

    LOCK(mtx_centroids);
    copy(centroids.begin(), centroids.end(), back_inserter(centroids_current));
    copy(v_cloud_cluster.begin(), v_cloud_cluster.end(), back_inserter(v_cloud_cluster_current));
    UNLOCK(mtx_centroids);

    if (centroids_current.empty() || obj_label_current.reprojected_positions.empty() ||  obj_label_current.obj_id.empty()) {
        jsk_recognition_msgs::BoundingBoxArray pub_msg;
        pub_msg.header = header;
        std_msgs::Time time;
        obj_pose_pub.publish(pub_msg);

        time.data = obj_pose_timestamp;
        obj_pose_timestamp_pub.publish(time);
        return;
    }

    std::vector&lt;int&gt; obj_indices;

    for(unsigned int i = 0; i &lt; obj_label_current.obj_id.size(); ++i) {
        unsigned int min_idx      = 0;
        double       min_distance = DBL_MAX;

        /* calculate each euclid distance between reprojected position and centroids */
        for (unsigned int j=0; j&lt;centroids_current.size(); j++) {
            double distance = euclid_distance(obj_label_current.reprojected_positions.at(i), centroids_current.at(j));

            /* Nearest centroid correspond to this reprojected object */
            if (distance &lt; min_distance)
            {
                min_distance = distance;
                min_idx      = j;
            }
        }
        if (min_distance &lt; threshold_min_dist) {
            obj_indices.push_back(min_idx);
        } else {
            obj_indices.push_back(-1);
        }
    }

    /* Publish marker with centroids coordinates */
    jsk_recognition_msgs::BoundingBoxArray pub_msg;
    pub_msg.header = header;
    lidar_tracker::CloudClusterArray cloud_clusters_msg;
    cloud_clusters_msg.header = header;

    for(unsigned int i = 0; i &lt; obj_label_current.obj_id.size(); ++i) {
        jsk_recognition_msgs::BoundingBox bounding_box;
        if (obj_indices.at(i) == -1)
            continue;

        if(object_type == &quot;car&quot;)
          v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 0;
        else if(object_type == &quot;person&quot;)
          v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 1;
        else
          v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 2;

        v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.value = obj_label_current.obj_id.at(i);
        bounding_box = v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box;
        pub_msg.boxes.push_back(bounding_box);
        cloud_clusters_msg.clusters.push_back(v_cloud_cluster_current.at(obj_indices.at(i)));
    }

    obj_pose_pub.publish(pub_msg);
    cluster_class_pub.publish(cloud_clusters_msg);
    std_msgs::Time time;
    time.data = obj_pose_timestamp;
    obj_pose_timestamp_pub.publish(time);
}


void obj_label_cb(const cv_tracker::obj_label&amp; obj_label_msg)
{
    object_type = obj_label_msg.type;
    obj_pose_timestamp = obj_label_msg.header.stamp;

    LOCK(mtx_reprojected_positions);
    obj_label.reprojected_positions.clear();
    obj_label.obj_id.clear();
    UNLOCK(mtx_reprojected_positions);

    LOCK(mtx_reprojected_positions);
    for (unsigned int i = 0; i &lt; obj_label_msg.obj_id.size(); ++i) {
        obj_label.reprojected_positions.push_back(obj_label_msg.reprojected_pos.at(i));
        obj_label.obj_id.push_back(obj_label_msg.obj_id.at(i));
    }
    UNLOCK(mtx_reprojected_positions);

    /* confirm obj_label is subscribed */
    LOCK(mtx_flag_obj_label);
    isReady_obj_label = true;
    UNLOCK(mtx_flag_obj_label);

    /* Publish fusion result if both of topics are ready */
   if (isReady_obj_label &amp;&amp; isReady_cluster_centroids)
        {
            fusion_objects();

            LOCK(mtx_flag_obj_label);
            isReady_obj_label = false;
            UNLOCK(mtx_flag_obj_label);

            LOCK(mtx_flag_cluster_centroids);
            isReady_cluster_centroids = false;
            UNLOCK(mtx_flag_cluster_centroids);
        }

} /* void obj_label_cb() */


void cluster_centroids_cb(const lidar_tracker::CloudClusterArray::Ptr&amp; in_cloud_cluster_array_ptr)
{
    LOCK(mtx_centroids);
    centroids.clear();
    v_cloud_cluster.clear();
    UNLOCK(mtx_centroids);

    LOCK(mtx_centroids);
    static tf::TransformListener trf_listener;
    try {
        trf_listener.lookupTransform(&quot;map&quot;, &quot;velodyne&quot;, ros::Time(0), transform);
        for (int i(0) ; i &lt; (int)in_cloud_cluster_array_ptr-&gt;clusters.size(); ++i) {
            lidar_tracker::CloudCluster cloud_cluster = in_cloud_cluster_array_ptr-&gt;clusters.at(i);
            /* convert centroids coodinate from velodyne frame to map frame */
            tf::Vector3 pt(cloud_cluster.centroid_point.point.x, cloud_cluster.centroid_point.point.y, cloud_cluster.centroid_point.point.z);
            tf::Vector3 converted = transform * pt;
            sensor_header = cloud_cluster.header;
            v_cloud_cluster.push_back(cloud_cluster);
            geometry_msgs::Point point_in_map;
            point_in_map.x = converted.x();
            point_in_map.y = converted.y();
            point_in_map.z = converted.z();

            centroids.push_back(point_in_map);
        }
    }
    catch (tf::TransformException ex) {
        ROS_INFO(&quot;%s&quot;, ex.what());
        ros::Duration(1.0).sleep();
    }
    UNLOCK(mtx_centroids);

    LOCK(mtx_flag_cluster_centroids);
    isReady_cluster_centroids = true;
    UNLOCK(mtx_flag_cluster_centroids);

    /* Publish fusion result if both of topics are ready */
    if (isReady_obj_label &amp;&amp; isReady_cluster_centroids) {
        fusion_objects();

        LOCK(mtx_flag_obj_label);
        isReady_obj_label = false;
        UNLOCK(mtx_flag_obj_label);

        LOCK(mtx_flag_cluster_centroids);
        isReady_cluster_centroids = false;
        UNLOCK(mtx_flag_cluster_centroids);
    }

} /* void cluster_centroids_cb() */


int main(int argc, char* argv[])
{
    /* ROS initialization */
    ros::init(argc, argv, &quot;obj_fusion&quot;);

    ros::NodeHandle n;
    ros::NodeHandle private_n (&quot;~&quot;);

    if (private_n.getParam(&quot;min_dist&quot;, threshold_min_dist))
  	{
      threshold_min_dist = 5.0;
  	}
    /* Initialize flags */
    isReady_obj_label         = false;
    isReady_cluster_centroids = false;

    ros::Subscriber obj_label_sub         = n.subscribe(&quot;obj_label&quot;, SUBSCRIBE_QUEUE_SIZE, obj_label_cb);
    ros::Subscriber cluster_centroids_sub = n.subscribe(&quot;/cloud_clusters&quot;, SUBSCRIBE_QUEUE_SIZE, cluster_centroids_cb);
    obj_pose_pub = n.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(&quot;obj_pose&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
	  cluster_class_pub = n.advertise&lt;lidar_tracker::CloudClusterArray&gt;(&quot;/cloud_cluster_class&quot;, ADVERTISE_QUEUE_SIZE);
    obj_pose_timestamp_pub = n.advertise&lt;std_msgs::Time&gt;(&quot;obj_pose_timestamp&quot;, ADVERTISE_QUEUE_SIZE);
    ros::spin();

    return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="4df0375f51b16298ab57e870ed67a801ab6d00bd" fix_time="19,17707">
		<msg>Fix incorrect check for the waypoint index</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.cpp">
				<diff>@@ -144,7 +144,7 @@ void VelocitySetPath::avoidSuddenDeceleration(double velocity_change_limit, doub
   double square_vel = (current_vel_ - velocity_change_limit) * (current_vel_ - velocity_change_limit);
   for (int i = 0;; i++)
   {
-    if (!checkWaypoint(i, __FUNCTION__))
+    if (!checkWaypoint(closest_waypoint + i, __FUNCTION__))
       return;
 
     // sqrt(v^2 - 2ax)
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &quot;velocity_set_path.h&quot;

VelocitySetPath::VelocitySetPath()
  : set_path_(false),
    current_vel_(0)
{
  ros::NodeHandle private_nh_(&quot;~&quot;);
  private_nh_.param&lt;double&gt;(&quot;velocity_offset&quot;, velocity_offset_, 1.2);
  private_nh_.param&lt;double&gt;(&quot;decelerate_vel_min&quot;, decelerate_vel_min_, 1.3);
}

VelocitySetPath::~VelocitySetPath()
{
}

// check if waypoint number is valid
bool VelocitySetPath::checkWaypoint(int num, const char *name) const
{
  if (num &lt; 0 || num &gt;= getPrevWaypointsSize())
  {
    return false;
  }
  return true;
}

// set about '_temporal_waypoints_size' meter waypoints from closest waypoint
void VelocitySetPath::setTemporalWaypoints(int temporal_waypoints_size, int closest_waypoint, geometry_msgs::PoseStamped control_pose)
{
  if (closest_waypoint &lt; 0)
    return;

  temporal_waypoints_.waypoints.clear();
  temporal_waypoints_.header = new_waypoints_.header;
  temporal_waypoints_.increment = new_waypoints_.increment;
  // push current pose
  waypoint_follower::waypoint current_point;

  current_point.pose = control_pose;
  current_point.twist = new_waypoints_.waypoints[closest_waypoint].twist;
  current_point.dtlane = new_waypoints_.waypoints[closest_waypoint].dtlane;
  temporal_waypoints_.waypoints.push_back(current_point);
  for (int i = 0; i &lt; temporal_waypoints_size; i++)
  {
    if (closest_waypoint + i &gt;= getNewWaypointsSize())
      return;

    temporal_waypoints_.waypoints.push_back(new_waypoints_.waypoints[closest_waypoint + i]);
  }

  return;
}

void VelocitySetPath::changeWaypointsForDeceleration(double deceleration, int closest_waypoint, int obstacle_waypoint)
{
  double square_vel_min = decelerate_vel_min_ * decelerate_vel_min_;
  int extra = 4; // for safety

  // decelerate with constant deceleration
  for (int index = obstacle_waypoint + extra; index &gt;= closest_waypoint; index--)
  {
    if (!checkWaypoint(index, __FUNCTION__))
      continue;

    // v = sqrt( (v0)^2 + 2ax )
    double changed_vel = std::sqrt(square_vel_min + 2.0 * deceleration * calcInterval(index, obstacle_waypoint));

    double prev_vel = prev_waypoints_.waypoints[index].twist.twist.linear.x;
    if (changed_vel &gt; prev_vel)
    {
      new_waypoints_.waypoints[index].twist.twist.linear.x = prev_vel;
    }
    else
    {
      new_waypoints_.waypoints[index].twist.twist.linear.x = changed_vel;
    }
  }

}

void VelocitySetPath::avoidSuddenAcceleration(double deceleration, int closest_waypoint)
{
  double square_current_vel = current_vel_ * current_vel_;

  for (int i = 0;; i++)
  {
    if (!checkWaypoint(closest_waypoint + i, __FUNCTION__))
      return;

    // accelerate with constant acceleration
    // v = root((v0)^2 + 2ax)
    double changed_vel = std::sqrt(square_current_vel + 2 * deceleration * calcInterval(closest_waypoint, closest_waypoint + i)) + velocity_offset_;

    // Don't exceed original velocity
    if (changed_vel &gt; new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x)
      return;

    new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x = changed_vel;
  }

  return;
}

void VelocitySetPath::avoidSuddenDeceleration(double velocity_change_limit, double deceleration, int closest_waypoint)
{
  if (closest_waypoint &lt; 0)
    return;

  // not avoid braking
  if (current_vel_ - new_waypoints_.waypoints[closest_waypoint].twist.twist.linear.x &lt; velocity_change_limit)
    return;

  //std::cout &lt;&lt; &quot;avoid sudden braking!&quot; &lt;&lt; std::endl;

  double square_vel = (current_vel_ - velocity_change_limit) * (current_vel_ - velocity_change_limit);
  for (int i = 0;; i++)
  {
    if (!checkWaypoint(i, __FUNCTION__))
      return;

    // sqrt(v^2 - 2ax)
    double changed_vel = square_vel - 2 * deceleration * calcInterval(closest_waypoint, closest_waypoint + i);

    if (changed_vel &lt; 0)
      break;

    new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x = std::sqrt(changed_vel);
  }

}

void VelocitySetPath::changeWaypointsForStopping(int stop_waypoint, int obstacle_waypoint, int closest_waypoint, double deceleration)
{
  if (closest_waypoint &lt; 0)
    return;

  // decelerate with constant deceleration
  for (int index = stop_waypoint; index &gt;= closest_waypoint; index--)
  {
    if (!checkWaypoint(index, __FUNCTION__))
      continue;

    // v = (v0)^2 + 2ax, and v0 = 0
    double changed_vel = std::sqrt(2.0 * deceleration * calcInterval(index, stop_waypoint));

    double prev_vel = prev_waypoints_.waypoints[index].twist.twist.linear.x;
    if (changed_vel &gt; prev_vel)
    {
      new_waypoints_.waypoints[index].twist.twist.linear.x = prev_vel;
    }
    else
    {
      new_waypoints_.waypoints[index].twist.twist.linear.x = changed_vel;
    }
  }

  // fill velocity with 0 for stopping
  for (int i = stop_waypoint; i &lt;= obstacle_waypoint; i++)
  {
    new_waypoints_.waypoints[i].twist.twist.linear.x = 0;
  }

}

void VelocitySetPath::initializeNewWaypoints()
{
  new_waypoints_ = prev_waypoints_;
}

double VelocitySetPath::calcInterval(const int begin, const int end) const
{
  // check index
  if (begin &lt; 0 || begin &gt;= getPrevWaypointsSize() || end &lt; 0 || end &gt;= getPrevWaypointsSize())
  {
    ROS_WARN(&quot;Invalid index&quot;);
    return -1;
  }

  // Calculate the inteval of waypoints
  double dist_sum = 0;
  for (int i = begin; i &lt; end; i++)
  {
    tf::Vector3 v1(prev_waypoints_.waypoints[i].pose.pose.position.x,
                   prev_waypoints_.waypoints[i].pose.pose.position.y, 0);

    tf::Vector3 v2(prev_waypoints_.waypoints[i + 1].pose.pose.position.x,
                   prev_waypoints_.waypoints[i + 1].pose.pose.position.y, 0);

    dist_sum += tf::tfDistance(v1, v2);
  }

  return dist_sum;
}


void VelocitySetPath::waypointsCallback(const waypoint_follower::laneConstPtr&amp; msg)
{
  prev_waypoints_ = *msg;
  new_waypoints_ = *msg;

  if (!set_path_)
    set_path_ = true;
}

void VelocitySetPath::currentVelocityCallback(const geometry_msgs::TwistStampedConstPtr&amp; msg)
{
  current_vel_ = msg-&gt;twist.linear.x;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="35dc261ee9e47326868031ce3975c1e77342473e" fix_time="2,84327">
		<msg>Fixed an indication in review.</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/ssd/ssd_node.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/ssd/ssd_node.cpp">
				<diff>@@ -57,9 +57,6 @@ class RosSsdApp
 
 	//The minimum score required to filter the detected objects by the ConvNet
 	float score_threshold_;
-	std::string image_raw_topic_str_;
-	std::string network_definition_file_;
-	std::string pretrained_model_file_;
 
 	//If GPU is enabled, stores the GPU Device to use
 	unsigned int gpu_device_id_;
@@ -142,12 +139,6 @@ class RosSsdApp
 	void config_cb(const runtime_manager::ConfigSsd::ConstPtr&amp; param)
 	{
 		score_threshold_ 	= param-&gt;score_threshold;
-		//image_raw_topic_str_		= param-&gt;image_raw_topic_str;
-		//network_definition_file_	= param-&gt;network_definition_file;
-		//pretrained_model_file_	= param-&gt;pretrained_model_file;
-		//use_gpu_ 			= param-&gt;use_gpu;
-		//gpu_device_id_ 	 	= param-&gt;gpu_device_id;
-
 	}
 
 public:
@@ -157,29 +148,32 @@ public:
 		ros::NodeHandle private_node_handle(&quot;~&quot;);//to receive args
 
 		//RECEIVE IMAGE TOPIC NAME
-		if (private_node_handle.getParam(&quot;image_raw_node&quot;, image_raw_topic_str_))
+		std::string image_raw_topic_str;
+		if (private_node_handle.getParam(&quot;image_raw_node&quot;, image_raw_topic_str))
 		{
-			ROS_INFO(&quot;Setting image node to %s&quot;, image_raw_topic_str_.c_str());
+			ROS_INFO(&quot;Setting image node to %s&quot;, image_raw_topic_str.c_str());
 		}
 		else
 		{
 			ROS_INFO(&quot;No image node received, defaulting to /image_raw, you can use _image_raw_node:=YOUR_TOPIC&quot;);
-			image_raw_topic_str_ = &quot;/image_raw&quot;;
+			image_raw_topic_str = &quot;/image_raw&quot;;
 		}
 
 		//RECEIVE CONVNET FILENAMES
-		if (private_node_handle.getParam(&quot;network_definition_file&quot;, network_definition_file_))
+		std::string network_definition_file;
+		std::string pretrained_model_file;
+		if (private_node_handle.getParam(&quot;network_definition_file&quot;, network_definition_file))
 		{
-			ROS_INFO(&quot;Network Definition File: %s&quot;, network_definition_file_.c_str());
+			ROS_INFO(&quot;Network Definition File: %s&quot;, network_definition_file.c_str());
 		}
 		else
 		{
 			ROS_INFO(&quot;No Network Definition File was received. Finishing execution.&quot;);
 			return;
 		}
-		if (private_node_handle.getParam(&quot;pretrained_model_file&quot;, pretrained_model_file_))
+		if (private_node_handle.getParam(&quot;pretrained_model_file&quot;, pretrained_model_file))
 		{
-			ROS_INFO(&quot;Pretrained Model File: %s&quot;, pretrained_model_file_.c_str());
+			ROS_INFO(&quot;Pretrained Model File: %s&quot;, pretrained_model_file.c_str());
 		}
 		else
 		{
@@ -204,7 +198,7 @@ public:
 		}
 
 		//SSD STUFF
-		ssd_detector_ = new SsdDetector(network_definition_file_, pretrained_model_file_, pixel_mean_, use_gpu_, gpu_device_id_);
+		ssd_detector_ = new SsdDetector(network_definition_file, pretrained_model_file, pixel_mean_, use_gpu_, gpu_device_id_);
 
 		if (NULL == ssd_detector_)
 		{
@@ -216,12 +210,12 @@ public:
 		publisher_car_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
 		publisher_person_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);
 
-		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str_.c_str());
-		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str_, 1, &amp;RosSsdApp::image_callback, this);
+		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str());
+		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str, 1, &amp;RosSsdApp::image_callback, this);
 
 		std::string config_topic(&quot;/config&quot;);
 		config_topic += &quot;/ssd&quot;;
-		subscriber_ssd_config_ =node_handle_.subscribe(config_topic, 1, &amp;RosSsdApp::config_cb, this);
+		subscriber_ssd_config_ = node_handle_.subscribe(config_topic, 1, &amp;RosSsdApp::config_cb, this);
 
 		ros::spin();
 		ROS_INFO(&quot;END Ssd&quot;);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
#include &lt;string&gt;
#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;runtime_manager/ConfigSsd.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_tracker/image_obj.h&gt;

#include &lt;rect_class_score.h&gt;

#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;

#include &quot;ssd_detector.h&quot;

class RosSsdApp
{
	ros::Subscriber subscriber_image_raw_;
	ros::Subscriber subscriber_ssd_config_;
	ros::Publisher publisher_car_objects_;
	ros::Publisher publisher_person_objects_;
	ros::NodeHandle node_handle_;

	cv::Scalar pixel_mean_;

	//Caffe based Object Detection ConvNet
	SsdDetector* ssd_detector_;

	//The minimum score required to filter the detected objects by the ConvNet
	float score_threshold_;
	std::string image_raw_topic_str_;
	std::string network_definition_file_;
	std::string pretrained_model_file_;

	//If GPU is enabled, stores the GPU Device to use
	unsigned int gpu_device_id_;

	//Sets whether or not use GPU acceleration
	bool use_gpu_;

	//vector of indices of the classes to search for
	std::vector&lt;unsigned int&gt; detect_classes_;

	void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, cv_tracker::image_obj&amp; out_message, cv::Mat&amp; in_image, std::string in_class)
	{
		for (unsigned int i = 0; i &lt; in_objects.size(); ++i)
		{
			if ( (in_objects[i].score &gt; score_threshold_)
				&amp;&amp; (	(in_class == &quot;car&quot; &amp;&amp; (in_objects[i].class_type == Ssd::CAR || in_objects[i].class_type == Ssd::BUS))
						|| (in_class == &quot;person&quot; &amp;&amp; (in_objects[i].class_type == Ssd::PERSON || in_objects[i].class_type == Ssd::BICYCLE))
					)

				)//check if the score is larger than minimum required
			{
				//std::cout &lt;&lt; in_objects[i].toString() &lt;&lt; std::endl;
				cv_tracker::image_rect rect;

				rect.x = in_objects[i].x;
				rect.y = in_objects[i].y;
				rect.width = in_objects[i].w;
				rect.height = in_objects[i].h;
				if (in_objects[i].x &lt; 0)
					rect.x = 0;
				if (in_objects[i].y &lt; 0)
					rect.y = 0;
				if (in_objects[i].w &lt; 0)
					rect.width = 0;
				if (in_objects[i].h &lt; 0)
					rect.height = 0;

				rect.score = in_objects[i].score;

				out_message.obj.push_back(rect);

			}
		}
	}

	void image_callback(const sensor_msgs::Image&amp; image_source)
	{
		//Receive Image, convert it to OpenCV Mat
		cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, &quot;bgr8&quot;);//toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
		cv::Mat image = cv_image-&gt;image;

		//Detect Object in image
		std::vector&lt; RectClassScore&lt;float&gt; &gt; detections;
		//cv::TickMeter timer; timer.start();
		//std::cout &lt;&lt; &quot;score:&quot; &lt;&lt; score_threshold_ &lt;&lt; &quot; slices:&quot; &lt;&lt; image_slices_ &lt;&lt; &quot; slices overlap:&quot; &lt;&lt; slices_overlap_ &lt;&lt; &quot;nms&quot; &lt;&lt; group_threshold_ &lt;&lt; std::endl;
		detections = ssd_detector_-&gt;Detect(image);

		//timer.stop();
		//std::cout &lt;&lt; &quot;Detection took: &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; std::endl;

		//Prepare Output message
		cv_tracker::image_obj output_car_message;
		cv_tracker::image_obj output_person_message;
		output_car_message.header = image_source.header;
		output_car_message.type = &quot;car&quot;;

		output_person_message.header = image_source.header;
		output_person_message.type = &quot;person&quot;;

		//Convert Objects to Message type
		//timer.reset(); timer.start();
		convert_rect_to_image_obj(detections, output_car_message, image, &quot;car&quot;);
		convert_rect_to_image_obj(detections, output_person_message, image, &quot;person&quot;);

		publisher_car_objects_.publish(output_car_message);
		publisher_person_objects_.publish(output_person_message);
	}


	void config_cb(const runtime_manager::ConfigSsd::ConstPtr&amp; param)
	{
		score_threshold_ 	= param-&gt;score_threshold;
		//image_raw_topic_str_		= param-&gt;image_raw_topic_str;
		//network_definition_file_	= param-&gt;network_definition_file;
		//pretrained_model_file_	= param-&gt;pretrained_model_file;
		//use_gpu_ 			= param-&gt;use_gpu;
		//gpu_device_id_ 	 	= param-&gt;gpu_device_id;

	}

public:
	void Run()
	{
		//ROS STUFF
		ros::NodeHandle private_node_handle(&quot;~&quot;);//to receive args

		//RECEIVE IMAGE TOPIC NAME
		if (private_node_handle.getParam(&quot;image_raw_node&quot;, image_raw_topic_str_))
		{
			ROS_INFO(&quot;Setting image node to %s&quot;, image_raw_topic_str_.c_str());
		}
		else
		{
			ROS_INFO(&quot;No image node received, defaulting to /image_raw, you can use _image_raw_node:=YOUR_TOPIC&quot;);
			image_raw_topic_str_ = &quot;/image_raw&quot;;
		}

		//RECEIVE CONVNET FILENAMES
		if (private_node_handle.getParam(&quot;network_definition_file&quot;, network_definition_file_))
		{
			ROS_INFO(&quot;Network Definition File: %s&quot;, network_definition_file_.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Network Definition File was received. Finishing execution.&quot;);
			return;
		}
		if (private_node_handle.getParam(&quot;pretrained_model_file&quot;, pretrained_model_file_))
		{
			ROS_INFO(&quot;Pretrained Model File: %s&quot;, pretrained_model_file_.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Pretrained Model File was received. Finishing execution.&quot;);
			return;
		}

		if (private_node_handle.getParam(&quot;score_threshold&quot;, score_threshold_))
		{
			ROS_INFO(&quot;Score Threshold: %f&quot;, score_threshold_);
		}

		if (private_node_handle.getParam(&quot;use_gpu&quot;, use_gpu_))
		{
			ROS_INFO(&quot;GPU Mode: %d&quot;, use_gpu_);
		}
		int gpu_id;
		if (private_node_handle.getParam(&quot;gpu_device_id&quot;, gpu_id ))
		{
			ROS_INFO(&quot;GPU Device ID: %d&quot;, gpu_id);
			gpu_device_id_ = (unsigned int) gpu_id;
		}

		//SSD STUFF
		ssd_detector_ = new SsdDetector(network_definition_file_, pretrained_model_file_, pixel_mean_, use_gpu_, gpu_device_id_);

		if (NULL == ssd_detector_)
		{
			ROS_INFO(&quot;Error while creating SSD Object&quot;);
			return;
		}
		ROS_INFO(&quot;SSD Detector initialized.&quot;);

		publisher_car_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
		publisher_person_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);

		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str_.c_str());
		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str_, 1, &amp;RosSsdApp::image_callback, this);

		std::string config_topic(&quot;/config&quot;);
		config_topic += &quot;/ssd&quot;;
		subscriber_ssd_config_ =node_handle_.subscribe(config_topic, 1, &amp;RosSsdApp::config_cb, this);

		ros::spin();
		ROS_INFO(&quot;END Ssd&quot;);

	}

	~RosSsdApp()
	{
		if (NULL != ssd_detector_)
			delete ssd_detector_;
	}

	RosSsdApp()
	{
		ssd_detector_ 	= NULL;
		score_threshold_= 0.5;
		use_gpu_ 		= false;
		gpu_device_id_ 	= 0;
		pixel_mean_		= cv::Scalar(102.9801, 115.9465, 122.7717);
	}
};

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;ssd_unc&quot;);

	RosSsdApp app;

	app.Run();

	return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="308db411b4485e3e4ed9a066e9d37ceca5535d3a" fix_time="340,17438">
		<msg>fix circular-dependency</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/lib/fusion/fusion.cpp" new_path="ros/src/computing/perception/detection/lib/fusion/fusion.cpp">
				<diff>@@ -265,7 +265,7 @@ static void showRects(IplImage *image, int object_num, const std::vector&lt;int&gt;&amp; c
 }
 #endif
 
-void setDetectedObjects(const cv_tracker::image_obj&amp; detected_objects)
+void setDetectedObjects(const cv_tracker_msgs::image_obj&amp; detected_objects)
 {
 	objectsStored = false;
 	obj_type = detected_objects.type;
@@ -446,13 +446,13 @@ std::vector&lt;float&gt; getMaxHeights()
 	return filtered_max_heights;
 }
 
-std::vector&lt;cv_tracker::image_rect_ranged&gt; getObjectsRectRanged()
+std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; getObjectsRectRanged()
 {
-	std::vector&lt;cv_tracker::image_rect_ranged&gt; fused_objects;
+	std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; fused_objects;
 	for (int i=0; i&lt;filtered_objects_num; i++)
 	{
 		int base = i * 4;
-		cv_tracker::image_rect_ranged obj_ranged;
+		cv_tracker_msgs::image_rect_ranged obj_ranged;
 		obj_ranged.rect.x      = filtered_corner_points.at(base);
 		obj_ranged.rect.y      = filtered_corner_points.at(base + 1);
 		obj_ranged.rect.width  = filtered_corner_points.at(base + 2);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv/cxcore.h&gt;

#include &quot;fusion_func.h&quot;
#include &quot;search_distance.h&quot;

#if _DEBUG //debug
static const char *window_name = &quot;CAR_TRACK&quot;;
//for imageCallback
static cv_bridge::CvImagePtr cv_image;
static IplImage temp;
static IplImage *image;
static double ratio = 1;	//resize ratio
#endif

/*for obstacle_detectionCallback */
static std::string obj_type;
static std::vector&lt;int&gt; g_corner_points;
static std::vector&lt;float&gt; g_scores;
static std::vector&lt;int&gt; filtered_corner_points;
static std::vector&lt;float&gt; filtered_scores;
static int g_objects_num;
static int filtered_objects_num;
/*for distance_measurementCallback */
static Scan_image g_scan_image;
/* for common Callback */
static std::vector&lt;float&gt; g_distances;
static std::vector&lt;float&gt; filtered_distances;

static std::vector&lt;float&gt; filtered_min_heights;//stores the min height of the object
static std::vector&lt;float&gt; filtered_max_heights;//stores the max height of the object

static points2image::PointsImage points_msg;

static bool objectsStored = false, pointsStored = false;

float Min_low_height = -1.5;
float Max_low_height = -1.0;
float Max_height = 2.0;
int Min_points = 2;
float Dispersion = 1.0;

//checks if a float is close to zero
static inline bool isAlmostZero(float x)
{
	float abs_x  = (float)fabs(x);
	const int rangeScale = 100;
	return(abs_x &lt; FLT_MIN*rangeScale);
}

//receives and sets params from the publisher node
void setParams(float minLowHeight, float maxLowHeight, float maxHeight, int minPoints, float disp)
{
	Min_low_height = minLowHeight;
	Max_low_height = maxLowHeight;
	Max_height = maxHeight;
	Min_points = minPoints;
	Dispersion = disp;
}

//Check wheter vscanpoints are contained in the detected object bounding box(rect) or not, store the vscanpoints indices in outIndices
bool rectangleContainsPoints(cv::Rect rect, std::vector&lt;Point5&gt; &amp;vScanPoints, float object_distance, std::vector&lt;int&gt; &amp;outIndices)
{
	int numPoints = vScanPoints.size();

	if (numPoints &lt;= 0)
		return false;

	int pointsFound = 0;
	for (int i = 0; i &lt; numPoints; i++)
	{
		if (vScanPoints[i].x &gt;= rect.x &amp;&amp; vScanPoints[i].y &gt;= rect.y &amp;&amp;
				(vScanPoints[i].min_h &gt; Min_low_height &amp;&amp; vScanPoints[i].min_h &lt; Max_low_height) &amp;&amp;
				(vScanPoints[i].max_h &lt; Max_height))
		{
			outIndices.push_back(i);//store indices of points inside the bounding box
			pointsFound++;
		}
	}
	if ( pointsFound &gt;= Min_points)
		return true;
	else
		return false;
}

//get the average of the minimum heights for only those vscan points in theindices
float getMinAverage(std::vector&lt;Point5&gt; &amp;vScanPoints, std::vector&lt;int&gt; &amp;indices)
{
	float average = 0.0;
	int num = indices.size();
	if (num &lt; 0)
		return 0.0;
	for (int i = 0 ; i &lt; num ; i++)
	{
		average+=vScanPoints[indices[i]].min_h;
	}
	return average/num;
}

//get the standard deviation of only those min heightsa in the indices vector
float getStdDev(std::vector&lt;Point5&gt; &amp;vScanPoints, std::vector&lt;int&gt; &amp;indices, float avg)
{
	float N = indices.size();
	if(N==0.0)
		return 0.0;
	float stddev = 0.0;
	for (int i = 0 ; i &lt; N ; i++)
	{
		stddev+=(vScanPoints[indices[i]].min_h-avg)*(vScanPoints[indices[i]].min_h-avg);
	}
	stddev/=N;

	return sqrt(stddev);
}

//obtain the coefficient of dispersion of the min height to check for uneven heights
bool dispersed(std::vector&lt;Point5&gt; &amp;vScanPoints, std::vector&lt;int&gt; &amp;indices)
{
	float avg = getMinAverage(vScanPoints, indices);
	float stddev = getStdDev(vScanPoints, indices, avg);

	if(abs(stddev/avg&gt;=Dispersion))
		return true;

	return false;
}

//returns the vscanpoints in the pointcloud
void getVScanPoints(std::vector&lt;Point5&gt; &amp;vScanPoints)
{
	int w = points_msg.image_width;
	int h = points_msg.image_height;
	for(int y=0; y&lt;h; y++)
	{
		for(int x=0; x&lt;w; x++)
		{
			int i = y * w + x;
			double distance = points_msg.distance[i];
			float min_h = points_msg.min_height[i];
			float max_h = points_msg.max_height[i];

			if(distance == 0)
				continue;

			vScanPoints.push_back({x, y, distance, min_h, max_h});//add Real Points so they can be later checked against the detection bounding box
		}
	}
}

void getMinMaxHeight(std::vector&lt;Point5&gt;&amp; vScanPoints, std::vector&lt;int&gt; indices, float&amp; outMinHeight, float&amp; outMaxHeight)
{
	float N = indices.size();
	if(N==0.0)
		return;
	float tmpMinH = 0, tmpMaxH = 0;
	for (int i = 0 ; i &lt; N ; i++)
	{
		if (vScanPoints[indices[i]].min_h &lt; tmpMinH)
			tmpMinH = vScanPoints[indices[i]].min_h;
		if (vScanPoints[indices[i]].max_h &gt; tmpMaxH)
			tmpMaxH = vScanPoints[indices[i]].max_h;
	}
	outMinHeight = tmpMinH;
	outMaxHeight = tmpMaxH;
}

void fuseFilterDetections(std::vector&lt;Point5&gt;&amp; vScanPoints)
{
	std::vector&lt;int&gt; pointsInBoundingBox;
	//reset
	filtered_objects_num = 0;
	filtered_corner_points.clear();
    filtered_scores.clear();
	filtered_distances.clear();
	filtered_max_heights.clear();
	filtered_min_heights.clear();
	for(int i = 0; i &lt; g_objects_num; i++)
	{
		//corner_point[0]=&gt;X1		corner_point[1]=&gt;Y1
		//corner_point[2]=&gt;width	corner_point[3]=&gt;height
		cv::Rect detection = cv::Rect(g_corner_points[0+i*4], g_corner_points[1+i*4], g_corner_points[2+i*4], g_corner_points[3+i*4]);
		if (!isAlmostZero(g_distances.at(i)) &amp;&amp;
			rectangleContainsPoints(detection, vScanPoints, g_distances.at(i), pointsInBoundingBox) &amp;&amp;
			!dispersed(vScanPoints, pointsInBoundingBox)
		    )
		{
			//if all the conditions above are true -&gt; store this detection
			//objects_num
			filtered_objects_num++;
			//corner_points
			filtered_corner_points.push_back(detection.x);
			filtered_corner_points.push_back(detection.y);
			filtered_corner_points.push_back(detection.width);
			filtered_corner_points.push_back(detection.height);
			//detection score
			filtered_scores.push_back(g_scores.at(i));
			//distance
			filtered_distances.push_back(g_distances.at(i));
			//calculate min and max height of the points in the bounding box
			float minHeight = 0.0, maxHeight = 0.0;
			getMinMaxHeight(vScanPoints, pointsInBoundingBox, minHeight, maxHeight);
			filtered_max_heights.push_back(maxHeight);
			filtered_min_heights.push_back(minHeight);
		}
	}
}

void fuse()
{
	if (!pointsStored || !objectsStored)
		return;

	calcDistance();//obtain distance for each object

	//Draw VScan Points and get them before displaying detections
	std::vector&lt;Point5&gt; vScanPoints;

	getVScanPoints(vScanPoints);//store all the vscanpoints and its data

	fuseFilterDetections(vScanPoints);//filter and store fused objects

}

#if _DEBUG
static constexpr CvScalar COLOR_CYAN = {255, 255, 0};

static void showRects(IplImage *image, int object_num, const std::vector&lt;int&gt;&amp; corner_point)
{
	for(int i = 0; i &lt; object_num; i++) {
		CvPoint p1 = cvPoint(corner_point[0+i*4], corner_point[1+i*4]);
		CvPoint p2 = cvPoint(corner_point[0+i*4] + corner_point[2+i*4], corner_point[1+i*4] + corner_point[3+i*4]);
		cvRectangle(image, p1, p2, COLOR_CYAN, 3);
	}
}
#endif

void setDetectedObjects(const cv_tracker::image_obj&amp; detected_objects)
{
	objectsStored = false;
	obj_type = detected_objects.type;
	g_corner_points.resize(4*detected_objects.obj.size());
	g_scores.resize(detected_objects.obj.size());

	g_objects_num = detected_objects.obj.size();
	for (int i = 0 ;i &lt; g_objects_num; i++) {
		g_corner_points[0+i*4] = detected_objects.obj.at(i).x;
		g_corner_points[1+i*4] = detected_objects.obj.at(i).y;
		g_corner_points[2+i*4] = detected_objects.obj.at(i).width;
		g_corner_points[3+i*4] = detected_objects.obj.at(i).height;
		g_scores[i]            = detected_objects.obj.at(i).score;
	}
	objectsStored = true;
}

/*void setScanImage(const scan2image::ScanImage&amp; scan_image)
{
#if _DEBUG
	if(image == nullptr){
		return;
	}
#endif
	//
	// Assign distance and intensity to scan_image
	//
	for(int i = 0; i &lt; (int)scan_image.distance.size(); i++) {
		int height = (int)(i % IMAGE_HEIGHT);
		int width = (int)(i / IMAGE_HEIGHT);
		g_scan_image.distance[width][height] = scan_image.distance.at(i); //unit of length is centimeter
		g_scan_image.intensity[width][height] = scan_image.intensity.at(i);
	}
	g_scan_image.max_y = scan_image.max_y;
	g_scan_image.min_y = scan_image.min_y;
}*/

void setPointsImage(const points2image::PointsImage&amp; points_image)
{
#if _DEBUG
	if(image == nullptr){
		return;
	}
#endif
	points_msg = points_image;//store vscan pointcloud
	pointsStored = false;

	/*
	 * Reset 2D vector
	 */
	for (auto&amp; distance : g_scan_image.distance) {
	    distance.clear();
	}
	for (auto&amp; intensity : g_scan_image.intensity) {
	    intensity.clear();
	}
	g_scan_image.distance.clear();
	g_scan_image.intensity.clear();

	g_scan_image.distance.resize(points_msg.image_width);
	g_scan_image.intensity.resize(points_msg.image_width);
	for (auto i=0; i&lt;points_msg.image_width; i++) {
		g_scan_image.distance[i].resize(points_msg.image_height);
		g_scan_image.intensity[i].resize(points_msg.image_height);
	}

	/*
	* Assign distance and intensity to scan_image
	*/
	for(int i = 0; i &lt; (int)points_image.distance.size(); i++) {
		int height = (int)(i / points_msg.image_width);
		int width = (int)(i % points_msg.image_width);
		if (height &lt; points_msg.image_height &amp;&amp; width &lt; points_msg.image_width) {
			g_scan_image.distance[width][height] = points_image.distance.at(i); //unit of length is centimeter
			g_scan_image.intensity[width][height] = points_image.intensity.at(i);
		}
	}
	g_scan_image.max_y = points_image.max_y;
	g_scan_image.min_y = points_image.min_y;
	pointsStored=true;
}

void calcDistance()
{
	g_distances.clear();
	for(int i = 0; i &lt; g_objects_num; i++)
	{
		float obstacle_distance = NO_DATA;
		int search_scope_max_y;
		int search_scope_min_y;

		if (g_scan_image.max_y &gt; g_corner_points[1+i*4] + g_corner_points[3+i*4]) {
			search_scope_max_y = g_corner_points[1+i*4] + g_corner_points[3+i*4];
		} else {
			search_scope_max_y = g_scan_image.max_y;
		}

		if (g_scan_image.min_y &lt; g_corner_points[1+i*4]) {
			search_scope_min_y = g_corner_points[1+i*4];
		} else {
			search_scope_min_y = g_scan_image.min_y;
		}

		std::vector&lt;float&gt; distance_candidates;
		int max_right_corner_point = (g_corner_points[0+i*4] + g_corner_points[2+i*4])&gt;g_scan_image.distance.size()-1 ? g_scan_image.distance.size()-1 : (g_corner_points[0+i*4] + g_corner_points[2+i*4]);
		for(int j = g_corner_points[0+i*4]; j &lt; max_right_corner_point; j++) {
		    for(int k = search_scope_min_y; k &lt;= search_scope_max_y; k++) {
			if(g_scan_image.distance[j][k] != NO_DATA) {
			    distance_candidates.push_back(g_scan_image.distance[j][k]);
			}
		    }
		}

                /* calculate mode (most common) value in candidates */
                obstacle_distance = getMode(distance_candidates);

		g_distances.push_back(obstacle_distance); //unit of length is centimeter
#if _DEBUG //debug
		if(obstacle_distance != NO_DATA) {
			printf(&quot;%f\n&quot;, obstacle_distance);
		} else {
			printf(&quot;no data\n&quot;);
		}
		char distance_string[32];
		CvFont dfont;
		float hscale      = 1.0f;
		float vscale      = 1.0f;
		float italicscale = 0.0f;
		int  thickness    = 2;

		/*
		 * Plot distances on an image
		 */
		if(obstacle_distance != NO_DATA) {
			cvInitFont (&amp;dfont, CV_FONT_HERSHEY_SIMPLEX , hscale, vscale, italicscale, thickness, CV_AA);
			sprintf(distance_string, &quot;%.2f m&quot;, obstacle_distance / 100);
			cvPutText(image, distance_string, cvPoint(g_corner_points[0+i*4] , g_corner_points[1+i*4] + g_corner_points[3+i*4]), &amp;dfont, CV_RGB(255, 0, 0));
		} else {
			cvInitFont (&amp;dfont, CV_FONT_HERSHEY_SIMPLEX , hscale, vscale, italicscale, thickness, CV_AA);
			sprintf(distance_string, &quot;No data&quot;);
			cvPutText(image, distance_string, cvPoint(g_corner_points[0+i*4] , g_corner_points[1+i*4] + g_corner_points[3+i*4]), &amp;dfont, CV_RGB(255, 0, 0));
		}
#endif
	}

#if _DEBUG //debug
	/*
	 * Plot depth points on an image
	 */
	CvPoint pt;
	for(int i = 0; i &lt; points_msg.image_height; i++) {
		for(int j = 0; j &lt; points_msg.image_width; j++) {
			if (g_scan_image.distance[j][i] != 0.0) {
				pt.x = j;
				pt.y = i;
				cvCircle(image, pt, 2, CV_RGB (0, 255, 0), CV_FILLED, 8, 0);
			}
		}
	}

	showRects(image, g_objects_num, g_corner_points);

	/*
	 * Show image
	 */
	cvShowImage(window_name, image);
	cvWaitKey(2);
#endif
}

std::vector&lt;float&gt; getMinHeights()
{
	return filtered_min_heights;
}

std::vector&lt;float&gt; getMaxHeights()
{
	return filtered_max_heights;
}

std::vector&lt;cv_tracker::image_rect_ranged&gt; getObjectsRectRanged()
{
	std::vector&lt;cv_tracker::image_rect_ranged&gt; fused_objects;
	for (int i=0; i&lt;filtered_objects_num; i++)
	{
		int base = i * 4;
		cv_tracker::image_rect_ranged obj_ranged;
		obj_ranged.rect.x      = filtered_corner_points.at(base);
		obj_ranged.rect.y      = filtered_corner_points.at(base + 1);
		obj_ranged.rect.width  = filtered_corner_points.at(base + 2);
		obj_ranged.rect.height = filtered_corner_points.at(base + 3);
		obj_ranged.rect.score  = filtered_scores.at(i);
		obj_ranged.range       = filtered_distances.at(i);
		obj_ranged.min_height  = filtered_min_heights.at(i);
		obj_ranged.max_height  = filtered_max_heights.at(i);
		fused_objects.push_back(obj_ranged);
	}

	return fused_objects;
}

std::string getObjectsType()
{
	return obj_type;
}

#if _DEBUG //debug
void imageCallback(const sensor_msgs::Image&amp; image_source)
{
	cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
	temp = cv_image-&gt;image;
	image = &amp;temp;
}
#endif

void init()
{
	g_objects_num = 0;
	filtered_objects_num = 0;
#if _DEBUG //debug
	cvNamedWindow(window_name, 2);
	image = nullptr;
#endif
}

void destroy()
{
#if _DEBUG //debug
	cvDestroyWindow(window_name);
#endif
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/lib/fusion/include/fusion_func.h" new_path="ros/src/computing/perception/detection/lib/fusion/include/fusion_func.h">
				<diff>@@ -38,11 +38,11 @@
 #include &lt;vector&gt;
 
 #include &lt;ros/ros.h&gt;
-#include &lt;cv_tracker/image_obj.h&gt;
-#include &lt;cv_tracker/image_rect_ranged.h&gt;
+#include &lt;cv_tracker_msgs/image_obj.h&gt;
+#include &lt;cv_tracker_msgs/image_rect_ranged.h&gt;
 #include &lt;scan2image/ScanImage.h&gt;
 #include &lt;points2image/PointsImage.h&gt;
-#include &lt;cv_tracker/image_obj_tracked.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
 
 #include &lt;opencv2/opencv.hpp&gt;
 
@@ -81,10 +81,10 @@ extern std::vector&lt;float&gt; getMaxHeights();
 extern void setParams(float minLowHeight, float maxLowHeight, float maxHeight, int minPoints, float disp);
 
 extern void calcDistance();
-extern void setDetectedObjects(const cv_tracker::image_obj&amp; image_objects);
+extern void setDetectedObjects(const cv_tracker_msgs::image_obj&amp; image_objects);
 extern void setScanImage(const scan2image::ScanImage&amp; scan_image);
 extern void setPointsImage(const points2image::PointsImage&amp; points_image);
-extern std::vector&lt;cv_tracker::image_rect_ranged&gt; getObjectsRectRanged();
+extern std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; getObjectsRectRanged();
 extern std::string getObjectsType();
 extern void init();
 extern void destroy();
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef INCLUDED_MFunctions_
#define INCLUDED_MFunctions_

#ifndef _DEBUG
#define _DEBUG 0
#endif

#include &lt;vector&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_tracker/image_obj.h&gt;
#include &lt;cv_tracker/image_rect_ranged.h&gt;
#include &lt;scan2image/ScanImage.h&gt;
#include &lt;points2image/PointsImage.h&gt;
#include &lt;cv_tracker/image_obj_tracked.h&gt;

#include &lt;opencv2/opencv.hpp&gt;

#define NO_DATA 0

#if _DEBUG
#define IMAGE_TOPIC &quot;/image_raw&quot;
#define IMAGE_CALLBACK imageCallback
#endif

struct Scan_image{
	std::vector&lt;std::vector&lt;float&gt;&gt; distance;
	std::vector&lt;std::vector&lt;float&gt;&gt; intensity;
	int max_y;
	int min_y;
};

struct Point5
{
	int x;
	int y;
	double distance;
	float min_h;
	float max_h;
};

extern void fuse();
extern void fuseFilterDetections(std::vector&lt;Point5&gt;&amp; vScanPoints);
extern void getVScanPoints(std::vector&lt;Point5&gt; &amp;vScanPoints);
extern bool dispersed(std::vector&lt;Point5&gt; &amp;vScanPoints, std::vector&lt;int&gt; &amp;indices);
extern float getStdDev(std::vector&lt;Point5&gt; &amp;vScanPoints, std::vector&lt;int&gt; &amp;indices, float avg);
extern float getMinAverage(std::vector&lt;Point5&gt; &amp;vScanPoints, std::vector&lt;int&gt; &amp;indices);
extern bool rectangleContainsPoints(cv::Rect rect, std::vector&lt;Point5&gt; &amp;vScanPoints, float object_distance, std::vector&lt;int&gt; &amp;outIndices);
extern std::vector&lt;float&gt; getMinHeights();
extern std::vector&lt;float&gt; getMaxHeights();
extern void setParams(float minLowHeight, float maxLowHeight, float maxHeight, int minPoints, float disp);

extern void calcDistance();
extern void setDetectedObjects(const cv_tracker::image_obj&amp; image_objects);
extern void setScanImage(const scan2image::ScanImage&amp; scan_image);
extern void setPointsImage(const points2image::PointsImage&amp; points_image);
extern std::vector&lt;cv_tracker::image_rect_ranged&gt; getObjectsRectRanged();
extern std::string getObjectsType();
extern void init();
extern void destroy();
#if _DEBUG
extern void imageCallback(const sensor_msgs::Image&amp; image_source);
#endif

#endif
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/lib/image/kf/src/kf.cpp" new_path="ros/src/computing/perception/detection/lib/image/kf/src/kf.cpp">
				<diff>@@ -38,9 +38,9 @@
 #include &lt;sensor_msgs/Image.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
 #include &lt;runtime_manager/ConfigCarKf.h&gt;
-#include &lt;cv_tracker/image_obj_ranged.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
 
-#include &lt;cv_tracker/image_obj_tracked.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
 #include &lt;std_msgs/Header.h&gt;
 
 //TRACKING STUFF
@@ -88,7 +88,7 @@ static bool 		USE_ORB;
 
 static bool 		track_ready_;
 static bool 		detect_ready_;
-static cv_tracker::image_obj_tracked kf_objects_msg_;
+static cv_tracker_msgs::image_obj_tracked kf_objects_msg_;
 
 struct kstate
 {
@@ -815,7 +815,7 @@ void trackAndDrawObjects(cv::Mat&amp; image, int frameNumber, std::vector&lt;ObjectDete
 
 	//ROS
 	int num = tracked_detections.size();
-	std::vector&lt;cv_tracker::image_rect_ranged&gt; rect_ranged_array;
+	std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; rect_ranged_array;
 	std::vector&lt;int&gt; real_data(num,0);
 	std::vector&lt;int&gt; obj_id(num, 0);
 	std::vector&lt;int&gt; lifespan(num, 0);
@@ -824,7 +824,7 @@ void trackAndDrawObjects(cv::Mat&amp; image, int frameNumber, std::vector&lt;ObjectDete
 	for (size_t i = 0; i &lt; tracked_detections.size(); i++)
 	{
 		kstate od = tracked_detections[i];
-		cv_tracker::image_rect_ranged rect_ranged_;
+		cv_tracker_msgs::image_rect_ranged rect_ranged_;
 
 		//od.rect contains x,y, width, height
 		rectangle(image, od.pos, od.color, 3);
@@ -846,7 +846,7 @@ void trackAndDrawObjects(cv::Mat&amp; image, int frameNumber, std::vector&lt;ObjectDete
 		//ENDROS
 	}
 	//more ros
-	cv_tracker::image_obj_tracked kf_objects_msg;
+	cv_tracker_msgs::image_obj_tracked kf_objects_msg;
 
 	kf_objects_msg.type = object_type;
 	kf_objects_msg.total_num = num;
@@ -878,12 +878,12 @@ void image_callback(const sensor_msgs::Image&amp; image_source)
 	_counter++;
 }
 
-void detections_callback(cv_tracker::image_obj_ranged image_objects_msg)
+void detections_callback(cv_tracker_msgs::image_obj_ranged image_objects_msg)
 {
 	if(!detect_ready_)
 	{
 		unsigned int num = image_objects_msg.obj.size();
-		std::vector&lt;cv_tracker::image_rect_ranged&gt; objects = image_objects_msg.obj;
+		std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects = image_objects_msg.obj;
 		object_type = image_objects_msg.type;
 		image_objects_header = image_objects_msg.header;
 		//points are X,Y,W,H and repeat for each instance
@@ -958,7 +958,7 @@ int kf_main(int argc, char* argv[])
 	ros::NodeHandle n;
 	ros::NodeHandle private_nh(&quot;~&quot;);
 
-	image_objects = n.advertise&lt;cv_tracker::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
+	image_objects = n.advertise&lt;cv_tracker_msgs::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
 
 	generateColors(_colors, 25);
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

//ROS STUFF
#include &lt;ros/ros.h&gt;

#include &lt;message_filters/subscriber.h&gt;
#include &lt;message_filters/time_synchronizer.h&gt;

#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;runtime_manager/ConfigCarKf.h&gt;
#include &lt;cv_tracker/image_obj_ranged.h&gt;

#include &lt;cv_tracker/image_obj_tracked.h&gt;
#include &lt;std_msgs/Header.h&gt;

//TRACKING STUFF
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/objdetect/objdetect.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;opencv2/video/tracking.hpp&gt;
#include &lt;opencv2/calib3d/calib3d.hpp&gt;

#include &lt;iostream&gt;
#include &lt;stdio.h&gt;

#include &lt;sstream&gt;
#include &lt;algorithm&gt;
#include &lt;iterator&gt;

#define SSTR( x ) dynamic_cast&lt; std::ostringstream &amp; &gt;( \
        ( std::ostringstream() &lt;&lt; std::dec &lt;&lt; x ) ).str()


#include &quot;gencolors.cpp&quot;

struct ObjectDetection_
{
	//ObjectDetection_();
	//ObjectDetection_(const cv::Rect&amp; rect, float score, int classId=1);
	cv::Rect rect;
	float score;
	int classID;
};

ros::Publisher image_objects;//ROS

static int 			DEFAULT_LIFESPAN; //LIFESPAN of objects before stop being tracked, in frames
static int	 		INITIAL_LIFESPAN; //LIFESPAN of objects before stop being tracked, in frames
static int			ORB_NUM_FEATURES;
static unsigned int	ORB_MIN_MATCHES;
static float		ORB_KNN_RATIO;
static float 		NOISE_COV;
static float 		MEAS_NOISE_COV;
static float 		ERROR_ESTIMATE_COV;
static float 		OVERLAPPING_PERC;
static bool 		SHOW_PREDICTIONS;
static bool 		USE_ORB;

static bool 		track_ready_;
static bool 		detect_ready_;
static cv_tracker::image_obj_tracked kf_objects_msg_;

struct kstate
{
	cv::KalmanFilter	KF;//KalmanFilter for this object
	cv::Rect		pos;//position of the object centerx, centery, width, height
	float			score;//DPM score
	bool			active;//if too old (lifespan) don't use
	unsigned int		id;//id of this tracked object
	cv::Mat			image;//image containing the detected and tracked object
	int			lifespan;//remaining lifespan before deprecate
	//ObjectDetection_ obj;//currently not used
	cv::Scalar	color;
	int		real_data;
	//std::vector&lt;KeyPoint&gt; orbKeypoints;
	//cv::Mat				orbDescriptors;
	float range;//range to this object gotten by range_fusion
	float min_height;//minimum height detected by range_fusion
	float max_height;//maximum height detected by range_fusion
};

//tracking required code
std::vector&lt;kstate&gt; 	_kstates;
std::vector&lt;bool&gt; 	_active;
std::vector&lt;cv::Scalar&gt;	_colors;
std::vector&lt;ObjectDetection_&gt; _dpm_detections;

std::string object_type;
std::vector&lt;float&gt; _ranges;
std::vector&lt;float&gt; _min_heights;
std::vector&lt;float&gt; _max_heights;

std_msgs::Header    image_objects_header;

//static bool _ready;

long int _counter = 0;
//

void getRectFromPoints(std::vector&lt; cv::Point2f &gt; corners, cv::Rect&amp; outBoundingBox)
{
	int min_x=0, min_y=0, max_x=0, max_y=0;
	for (unsigned int i=0; i&lt;corners.size(); i++)
	{
		if (corners[i].x &gt; 0)
		{
			if (corners[i].x &lt; min_x)
				min_x = corners[i].x;
			if (corners[i].x&gt;max_x)
				max_x = corners[i].x;
		}
		if (corners[i].y &gt; 0)
		{
			if (corners[i].y &lt; min_y)
				min_y = corners[i].y;
			if (corners[i].y &gt; max_y)
				max_y = corners[i].y;
		}
	}
	outBoundingBox.x 		= min_x;
	outBoundingBox.y 		= min_y;
	outBoundingBox.width 	= max_x - min_x;
	outBoundingBox.height 	= max_y - min_y;

}

/*bool orbMatch(cv::Mat&amp; inImageScene, cv::Mat&amp; inImageObj, cv::Rect&amp; outBoundingBox, unsigned int inMinMatches=2, float inKnnRatio=0.7)
{
	//vector of keypoints
	std::vector&lt; cv::KeyPoint &gt; keypointsO;
	std::vector&lt; cv::KeyPoint &gt; keypointsS;

	cv::Mat descriptors_object, descriptors_scene;

	cv::Mat outImg;
	inImageScene.copyTo(outImg);

	//-- Step 1: Extract keypoints
	cv::OrbFeatureDetector orb(ORB_NUM_FEATURES);
	orb.detect(inImageScene, keypointsS);
	if (keypointsS.size() &lt; ORB_MIN_MATCHES)
	{
		//cout &lt;&lt; &quot;Not enough keypoints S, object not found&gt;&quot; &lt;&lt; keypointsS.size() &lt;&lt; endl;
		return false;
	}
	orb.detect(inImageObj, keypointsO);
	if (keypointsO.size() &lt; ORB_MIN_MATCHES)
	{
		//cout &lt;&lt; &quot;Not enough keypoints O, object not found&gt;&quot; &lt;&lt; keypointsO.size() &lt;&lt; endl;
		return false;
	}

	//Calculate descriptors (feature vectors)
	cv::OrbDescriptorExtractor extractor;
	extractor.compute(inImageScene, keypointsS, descriptors_scene);
	extractor.compute(inImageObj, keypointsO, descriptors_object);

	//Matching descriptor vectors using FLANN matcher
	cv::BFMatcher matcher;
	//descriptors_scene.size(), keypointsO.size(), keypointsS.size();
	std::vector&lt; std::vector&lt; cv::DMatch &gt;  &gt; matches;
	matcher.knnMatch(descriptors_object, descriptors_scene, matches, 2);
	std::vector&lt; cv::DMatch &gt; good_matches;
	good_matches.reserve(matches.size());

	for (size_t i = 0; i &lt; matches.size(); ++i)
	{
		if (matches[i].size() &lt; 3)
			continue;

		const cv::DMatch &amp;m1 = matches[i][0];
		const cv::DMatch &amp;m2 = matches[i][1];

		if (m1.distance &lt;= inKnnRatio * m2.distance)
			good_matches.push_back(m1);
	}

	if ((good_matches.size() &gt;= inMinMatches))
	{
		std::vector&lt; cv::Point2f &gt; obj;
		std::vector&lt; cv::Point2f &gt; scene;

		for (unsigned int i = 0; i &lt; good_matches.size(); i++)
		{
			// Get the keypoints from the good matches
			obj.push_back(keypointsO[good_matches[i].queryIdx].pt);
			scene.push_back(keypointsS[good_matches[i].trainIdx].pt);
		}

		cv::Mat H = findHomography(obj, scene, CV_RANSAC);

		// Get the corners from the image_1 ( the object to be &quot;detected&quot; )
		std::vector&lt; cv::Point2f &gt; obj_corners(4);
		obj_corners[0] = cvPoint(0, 0); obj_corners[1] = cvPoint(inImageObj.cols, 0);
		obj_corners[2] = cvPoint(inImageObj.cols, inImageObj.rows); obj_corners[3] = cvPoint(0, inImageObj.rows);
		std::vector&lt; cv::Point2f &gt; scene_corners(4);

		perspectiveTransform(obj_corners, scene_corners, H);

		// Draw lines between the corners (the mapped object in the scene - image_2 )
		line(outImg, scene_corners[0], scene_corners[1], cv::Scalar(255, 0, 0), 2); //TOP line
		line(outImg, scene_corners[1], scene_corners[2], cv::Scalar(255, 0, 0), 2);
		line(outImg, scene_corners[2], scene_corners[3], cv::Scalar(255, 0, 0), 2);
		line(outImg, scene_corners[3], scene_corners[0], cv::Scalar(255, 0, 0), 2);

		//imshow(&quot;Scene&quot;, outImg);
		//imshow(&quot;Obj&quot;, inImageObj);
		//cvWaitKey(5);

		return true;
	}

	return false;
}*/

///Returns true if an im1 is contained in im2 or viceversa
bool crossCorr(cv::Mat im1, cv::Mat im2)
{
	//im1 roi from the previous frame
	//im2 roi fromcurrent frame
	if (im1.rows &lt;= 0 || im1.cols &lt;= 0 || im2.rows &lt;= 0 || im2.cols &lt;= 0)
		return false;

	cv::Mat result, larger_im, smaller_im;

	/// Create the result matrix
	int result_cols;
	int result_rows;

	//select largest image
	if (im2.cols &gt; im1.cols)
	{
		larger_im = im2;
		smaller_im = im1;
	}
	else
	{
		larger_im = im1;
		smaller_im = im2;
	}
	//check rows to be also larger otherwise crop the smaller to remove extra rows
	if (larger_im.rows &lt; smaller_im.rows)
	{
		//add rows to match sizes
		cv::Mat rows = cv::Mat::ones(smaller_im.rows - larger_im.rows, larger_im.cols, larger_im.type());
		larger_im.push_back(rows);
	}

	result_cols = larger_im.cols - smaller_im.cols + 1;
	result_rows = larger_im.rows - smaller_im.rows + 1;
	result.create(result_cols, result_rows, CV_32FC1);

	/// Do the Matching and Normalize
	matchTemplate(larger_im, smaller_im, result, CV_TM_CCORR_NORMED);
	//normalize(result, result, 0, 1, NORM_MINMAX, -1, cv::Mat());

	/// Localizing the best match with minMaxLoc
	double minVal; double maxVal; cv::Point minLoc; cv::Point maxLoc;
	cv::Point matchLoc;

	minMaxLoc(result, &amp;minVal, &amp;maxVal, &amp;minLoc, &amp;maxLoc, cv::Mat());

	matchLoc = maxLoc;

	/// Show me what you got
	cv::Mat scene = larger_im.clone();
	rectangle(scene, matchLoc, cv::Point(matchLoc.x + smaller_im.cols, matchLoc.y + smaller_im.rows), cv::Scalar(0, 0, 255), 2, 8, 0);
	//imshow(image_window, scene);
	//imshow(result_window, result);

	//if (maxVal&gt;0.89 &amp;&amp; minVal &lt;0.3)
	bool ret;
	int thresWidth = (larger_im.cols)*.7;
	if ( (maxVal &gt; 0.5) &amp;&amp; (smaller_im.cols &gt; thresWidth) )//good threshold and consistent size
	{

		//std::cout &lt;&lt; &quot;matched&quot; &lt;&lt; endl;
		ret = true;
	}
	else
	{
		//std::cout &lt;&lt; &quot;non matched&quot; &lt;&lt; endl;
		ret = false;
	}
	//cv::imshow(&quot;match1&quot;, scene);
	//cv::imshow(&quot;match2&quot;, smaller_im);

	return ret;
}

void posScaleToBbox(std::vector&lt;kstate&gt; kstates, std::vector&lt;kstate&gt;&amp; trackedDetections)
{
	for (unsigned int i = 0; i &lt; kstates.size(); i++)
	{
		if (kstates[i].active)
		{
			kstate tmp;
			tmp.pos.x = kstates[i].pos.x;// -(kstates[i].pos.width / 2);
			tmp.pos.y = kstates[i].pos.y;// -(kstates[i].pos.height / 2);
			tmp.pos.width = kstates[i].pos.width;
			tmp.pos.height = kstates[i].pos.height;
			tmp.color = kstates[i].color;
			tmp.id = kstates[i].id;
			tmp.score = kstates[i].score;
			tmp.lifespan = kstates[i].lifespan;
			tmp.real_data = kstates[i].real_data;
			tmp.range = kstates[i].range;
			tmp.min_height = kstates[i].min_height;
			tmp.max_height = kstates[i].max_height;

			//fill in also LAtentSvm object
			//tmp.obj.rect = tmp.pos;
			//tmp.obj.score = tmp.score;

			if (tmp.pos.x &lt; 0)
				tmp.pos.x = 0;
			if (tmp.pos.y &lt; 0)
				tmp.pos.y = 0;

			trackedDetections.push_back(tmp);
		}
	}
}

int getAvailableIndex(std::vector&lt;kstate&gt;&amp; kstates)
{
	unsigned int cur_size = kstates.size();
	std::vector&lt;bool&gt; ids;

	ids.resize(cur_size, false);

	for (unsigned int i=0; i&lt;cur_size;i++)
	{
		ids[kstates[i].id]= true;
	}
	for (unsigned int i=0; i&lt;cur_size;i++)
	{
		if(ids[i] == false)
			return i;
	}
	return cur_size;
}

void initTracking(ObjectDetection_ object, std::vector&lt;kstate&gt;&amp; kstates,
		  ObjectDetection_ detection,
		  cv::Mat&amp; image, std::vector&lt;cv::Scalar&gt; colors, float range)
{
	kstate new_state;
	//cv::KalmanFilter KF(4, 2, 0);//XY Only
	cv::KalmanFilter KF(8, 4, 0);

	/*cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(2, 1) &lt;&lt; object.rect.x,//XY Only
		object.rect.y);*/
	cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(4, 1) &lt;&lt; object.rect.x,
		object.rect.y, object.rect.width, object.rect.height);

	/*KF.transitioncv::Matrix = (cv::Mat_&lt;float&gt;(4, 4) &lt;&lt; 1, 0, 1, 0,//XY Only
												0, 1, 0, 1,
												0, 0, 1, 0,
												0, 0, 0, 1);*/
	KF.transitionMatrix = (cv::Mat_&lt;float&gt;(8, 8)
	&lt;&lt;	1, 0, 0, 0, 1, 0, 0, 0,
		0, 1, 0, 0, 0, 1, 0, 0,
		0, 0, 1, 0, 0, 0, 1, 0,
		0, 0, 0, 1, 0, 0, 0, 1,
		0, 0, 0, 0, 1, 0, 0, 0,
		0, 0, 0, 0, 0, 1, 0, 0,
		0, 0, 0, 0, 0, 0, 1, 0,
		0, 0, 0, 0, 0, 0, 0, 1);

	//init pre
	KF.statePre.at&lt;float&gt;(0) = object.rect.x;
	KF.statePre.at&lt;float&gt;(1) = object.rect.y;
	KF.statePre.at&lt;float&gt;(2) = object.rect.width;//XY Only
	KF.statePre.at&lt;float&gt;(3) = object.rect.height;//XY Only
	//init post
	KF.statePost.at&lt;float&gt;(0) = object.rect.x;
	KF.statePost.at&lt;float&gt;(1) = object.rect.y;
	KF.statePost.at&lt;float&gt;(2) = object.rect.width;//XY Only
	KF.statePost.at&lt;float&gt;(3) = object.rect.height;//XY Only

	cv::setIdentity(KF.measurementMatrix);
	cv::setIdentity(KF.processNoiseCov, cv:: Scalar::all(NOISE_COV));//1e-4
	cv::setIdentity(KF.measurementNoiseCov, cv::Scalar::all(MEAS_NOISE_COV));//1e-3
	cv::setIdentity(KF.errorCovPost, cv::Scalar::all(ERROR_ESTIMATE_COV));//100

	//clip detection
	//check that predicted positions are inside the image
	if (detection.rect.x &lt; 0)
		detection.rect.x = 0;
	if (detection.rect.x &gt; image.cols)
		detection.rect.x = image.cols - 1;
	if (detection.rect.y &lt; 0)
		detection.rect.y = 0;
	if (detection.rect.height &gt; image.rows)
		detection.rect.height = image.rows - 1;
	if (detection.rect.width + detection.rect.x &gt; image.cols)
		detection.rect.width = image.cols - detection.rect.x;
	if (detection.rect.height + detection.rect.y &gt; image.rows)
		detection.rect.height = image.rows - detection.rect.y;

	//save data to kstate
	new_state.active = true;
	new_state.image = image(cv::Rect(detection.rect.x,
		detection.rect.y,
		detection.rect.width,
		detection.rect.height)).clone();//Crop image and obtain only object (ROI)
	new_state.KF = KF;
	new_state.lifespan = INITIAL_LIFESPAN;//start only with 1
	new_state.pos = object.rect;
	new_state.score = object.score;
	new_state.id = getAvailableIndex(kstates);
	new_state.color = colors[new_state.id];
	new_state.real_data = 1;
	new_state.range = range;

	//extractOrbFeatures(new_state.image, new_state.orbKeypoints, new_state.orbDescriptors, ORB_NUM_FEATURES);

	kstates.push_back(new_state);

}

//checks whether an index was previously removed
bool isInRemoved(std::vector&lt;unsigned int&gt; removedIndices, unsigned int index)
{
	for (unsigned int i=0; i&lt; removedIndices.size(); i++)
	{
		if (index == removedIndices[i])
			return true;
	}
	return false;
}

void removeUnusedObjects(std::vector&lt;kstate&gt;&amp; states)
{
	std::vector&lt;kstate&gt;::iterator it;
	for(it = states.begin(); it != states.end();)
	{
		if (!(it-&gt;active))
			it = states.erase(it);
		else
			it++;
	}
}

bool alreadyMatched(int check_index, std::vector&lt;int&gt;&amp; matched_indices)
{
	for (unsigned int i = 0; i &lt; matched_indices.size(); i++)
	{
		if (matched_indices[i] == check_index)
			return true;
	}
	return false;
}

void Sort(const std::vector&lt;float&gt; in_scores, std::vector&lt;unsigned int&gt;&amp; in_out_indices)
{
	for (unsigned int i = 0; i &lt; in_scores.size(); i++)
		for (unsigned int j = i + 1; j &lt; in_scores.size(); j++)
		{
			if (in_scores[in_out_indices[j]] &gt; in_scores[in_out_indices[i]])
			{
				//float x_tmp = x[i];
				int index_tmp = in_out_indices[i];
				//x[i] = x[j];
				in_out_indices[i] = in_out_indices[j];
				//x[j] = x_tmp;
				in_out_indices[j] = index_tmp;
			}
		}
}

void ApplyNonMaximumSuppresion(std::vector&lt; kstate &gt;&amp; in_source, float in_nms_threshold)
{
	std::vector&lt; kstate &gt; tmp_source = in_source;

	if (tmp_source.empty())
		return ;

	unsigned int size = in_source.size();

	std::vector&lt;float&gt; area(size);
	std::vector&lt;float&gt; scores(size);
	std::vector&lt;int&gt; x1(size);
	std::vector&lt;int&gt; y1(size);
	std::vector&lt;int&gt; x2(size);
	std::vector&lt;int&gt; y2(size);
	std::vector&lt;unsigned int&gt; indices(size);
	std::vector&lt;bool&gt; is_suppresed(size);

	for(unsigned int i = 0; i&lt; in_source.size(); i++)
	{
		kstate tmp = in_source[i];
		area[i] = tmp.pos.width * tmp.pos.height;
		indices[i] = i;
		is_suppresed[i] = false;
		scores[i] = tmp.score;
		x1[i] = tmp.pos.x;
		y1[i] = tmp.pos.y;
		x2[i] = tmp.pos.width + tmp.pos.x;
		y2[i] = tmp.pos.height + tmp.pos.y;
	}

	Sort(scores, indices);//returns indices ordered based on scores

	for(unsigned int i=0; i&lt; size; i++)
	{
		if(!is_suppresed[indices[i]])
		{
			for(unsigned int j= i+1; j&lt; size; j++)
			{
				int x1_max = std::max(x1[indices[i]], x1[indices[j]]);
				int x2_min = std::min(x2[indices[i]], x2[indices[j]]);
				int y1_max = std::max(y1[indices[i]], y1[indices[j]]);
				int y2_min = std::min(y2[indices[i]], y2[indices[j]]);
				int overlap_width = x2_min - x1_max + 1;
				int overlap_height = y2_min - y1_max + 1;
				if(overlap_width &gt; 0 &amp;&amp; overlap_height&gt;0)
				{
					float overlap_part = (overlap_width*overlap_height)/area[indices[j]];
					if(overlap_part &gt; in_nms_threshold)
					{
						is_suppresed[indices[j]] = true;
					}
				}
			}
		}
	}

	unsigned int size_out = 0;
	for (unsigned int i = 0; i &lt; size; i++)
	{
		if (!is_suppresed[i])
			size_out++;
	}

	std::vector&lt; kstate &gt; filtered_detections(size_out);

	unsigned int index = 0;
	for(unsigned int i = 0 ; i &lt; size_out; i++)
	{
		if(!is_suppresed[indices[i]])
		{
			filtered_detections[index] = in_source[indices[i]];//x1[indices[i]];
			index++;
		}
	}
	in_source = filtered_detections;
}

void doTracking(std::vector&lt;ObjectDetection_&gt;&amp; detections, int frameNumber,
		std::vector&lt;kstate&gt;&amp; kstates, std::vector&lt;bool&gt;&amp; active, cv::Mat&amp; image,
		std::vector&lt;kstate&gt;&amp; trackedDetections, std::vector&lt;cv::Scalar&gt; &amp; colors)
{
	std::vector&lt;ObjectDetection_&gt; objects;
	//vector&lt;LatentSvmDetector::ObjectDetection_&gt; tracked_objects;
	std::vector&lt;bool&gt; predict_indices;//this will correspond to kstates i
	std::vector&lt;bool&gt; correct_indices;//this will correspond to kstates i
	std::vector&lt;int&gt; correct_detection_indices;//this will correspond to kstates i, used to store the index of the corresponding object
	std::vector&lt;bool&gt; add_as_new_indices;//this will correspond to detections j

	//predict_indices.assign(kstates.size(), true);//always predict
	correct_indices.assign(kstates.size(), false);//correct only those matched
	correct_detection_indices.assign(kstates.size(), false);//correct only those matched
	add_as_new_indices.assign(detections.size(), true);//if the detection was not found add as new

	//Convert Bounding box coordinates from (x1,y1,w,h) to (BoxCenterX, BoxCenterY, width, height)
	objects = detections;//bboxToPosScale(detections);

	std::vector&lt;int&gt; already_matched;
	//compare detections from this frame with tracked objects
	for (unsigned int j = 0; j &lt; detections.size(); j++)
	{
		for (unsigned int i = 0; i &lt; kstates.size(); i++)
		{
			//compare only to active tracked objects(not too old)
			if (kstates[i].active)
			{
				//extend the roi 20%
				int new_x = (detections[j].rect.x - detections[j].rect.width*.1);
				int new_y = (detections[j].rect.y - detections[j].rect.height*.1);

				if (new_x &lt; 0)			new_x = 0;
				if (new_x &gt; image.cols)	new_x = image.cols;
				if (new_y &lt; 0)			new_y = 0;
				if (new_y &gt; image.rows) new_y = image.rows;

				int new_width = detections[j].rect.width*1.2;
				int new_height = detections[j].rect.height*1.2;

				if (new_width  + new_x &gt; image.cols)	new_width  = image.cols - new_x;
				if (new_height + new_y &gt; image.rows)	new_height = image.rows - new_y;

				cv::Rect roi_20(new_x, new_y, new_width, new_height);
				//cv::Rect roi(detections[j].rect);
				cv::Rect roi(roi_20);
				cv::Mat currentObjectROI = image(roi).clone();//Crop image and obtain only object (ROI)

				//cv::Rect intersect = detections[j].rect &amp; kstates[i].pos;//check overlapping

				cv::Rect boundingbox;
				bool matched = false;
				//try to match with previous frame
				//if ( !USE_ORB )
					matched = ( !alreadyMatched(j, already_matched) &amp;&amp; crossCorr(kstates[i].image, currentObjectROI));
				//else
				//	matched = (!alreadyMatched(j, already_matched) &amp;&amp; orbMatch(currentObjectROI, kstates[i].image, boundingbox, ORB_MIN_MATCHES, ORB_KNN_RATIO));

				if(matched)
				{
					correct_indices[i] = true;//if ROI on this frame is matched to a previous object, correct
					correct_detection_indices[i] = j;//store the index of the detection corresponding to matched kstate
					add_as_new_indices[j] = false;//if matched do not add as new
					//kstates[i].image = currentObjectROI;//update image with current frame data
					kstates[i].score = detections[j].score;
					kstates[i].range = _ranges[j];
					already_matched.push_back(j);
				}//crossCorr

			}//kstates[i].active
		}//for (int i = 0; i &lt; kstates.size(); i++)
	}//for (int j = 0; j &lt; detections.size(); j++)


	//do prediction and correction for the marked states
	for (unsigned int i = 0; i &lt; kstates.size(); i++)
	{
		if (kstates[i].active)//predict and correct only active states
		{
			//update params before predicting
			cv::setIdentity(kstates[i].KF.measurementMatrix);
			cv::setIdentity(kstates[i].KF.processNoiseCov, cv::Scalar::all(NOISE_COV));//1e-4
			cv::setIdentity(kstates[i].KF.measurementNoiseCov, cv::Scalar::all(MEAS_NOISE_COV));//1e-3
			cv::setIdentity(kstates[i].KF.errorCovPost, cv::Scalar::all(ERROR_ESTIMATE_COV));//100

			cv::Mat prediction = kstates[i].KF.predict();
			cv::Mat correction;
			kstates[i].pos.x = prediction.at&lt;float&gt;(0);
			kstates[i].pos.y = prediction.at&lt;float&gt;(1);
			kstates[i].pos.width = prediction.at&lt;float&gt;(2);
			kstates[i].pos.height = prediction.at&lt;float&gt;(3);
			kstates[i].real_data = 0;
			kstates[i].range = 0.0f;//fixed to zero temporarily as this is not real_data
			kstates[i].min_height = 0.0f;//fixed to zero temporarily as this is not real_data
			kstates[i].max_height = 0.0f;//fixed to zero temporarily as this is not real_data

			//now do respective corrections on KFs (updates)
			if (correct_indices[i])
			{
				//a match was found hence update KF measurement
				int j = correct_detection_indices[i];//obtain the index of the detection

				//cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(2, 1) &lt;&lt; objects[j].rect.x, //XY ONLY
				//												objects[j].rect.y);
				cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(4, 1) &lt;&lt; objects[j].rect.x,
					objects[j].rect.y,
					objects[j].rect.width,
					objects[j].rect.height);

				correction = kstates[i].KF.correct(measurement);//UPDATE KF with new info
				kstates[i].lifespan = DEFAULT_LIFESPAN; //RESET Lifespan of object

				//kstates[i].pos.width = objects[j].rect.width;//XY ONLY
				//kstates[i].pos.height = objects[j].rect.height;//XY ONLY

				//use real data instead of predicted if set
				kstates[i].pos.x = objects[j].rect.x;
				kstates[i].pos.y = objects[j].rect.y;
				kstates[i].pos.width = objects[j].rect.width;
				kstates[i].pos.height = objects[j].rect.height;
				kstates[i].real_data = 1;
				//cv::Mat im1 = image(kstates[i].pos);
				//cv::Mat im2 = image(objects[j].rect);
				kstates[i].range = _ranges[j];
				kstates[i].min_height = _min_heights[j];
				kstates[i].max_height = _max_heights[j];
			}


			//check that new widths and heights don't go beyond the image size
			if (kstates[i].pos.width + kstates[i].pos.x &gt; image.cols)
				kstates[i].pos.width = image.cols - kstates[i].pos.x;
			if (kstates[i].pos.height + kstates[i].pos.y &gt; image.rows)
				kstates[i].pos.height = image.rows - kstates[i].pos.y;

			//check that predicted positions are inside the image
			if (kstates[i].pos.x &lt; 0)
				kstates[i].pos.x = 0;
			if (kstates[i].pos.x &gt; image.cols)
				kstates[i].pos.x = image.cols;
			if (kstates[i].pos.y &lt; 0)
				kstates[i].pos.y = 0;
			if (kstates[i].pos.y &gt; image.rows)
				kstates[i].pos.y = image.rows;

			//remove those where the dimensions of are unlikely to be real
			if (kstates[i].pos.width &gt; kstates[i].pos.height*4)
				kstates[i].active = false;

			if (kstates[i].pos.height &gt; kstates[i].pos.width*2)
				kstates[i].active = false;

			kstates[i].lifespan--;//reduce lifespan
			if (kstates[i].lifespan &lt;= 0)
			{
				kstates[i].active = false; //Too old, stop tracking.
			}
		}
	}

	//finally add non matched detections as new
	for (unsigned int i = 0; i &lt; add_as_new_indices.size(); i++)
	{
		if (add_as_new_indices[i])
		{
			initTracking(objects[i], kstates, detections[i], image, colors, _ranges[i]);
		}
	}
	/*
	//check overlapping states and remove them
	float overlap = (OVERLAPPING_PERC/100);
	std::vector&lt;unsigned int&gt; removedIndices;
	for (unsigned int i = 0; i &lt; kstates.size() ; i++)
	{
		for (unsigned int j = kstates.size() - 1; j &gt; 0; j--)
		{
			if (i==j || isInRemoved(removedIndices, i) || isInRemoved(removedIndices, j))
				continue;
			//cout &lt;&lt; &quot;i:&quot; &lt;&lt; i &lt;&lt; &quot; j:&quot; &lt;&lt; j &lt;&lt; endl;
			cv::Rect intersection = kstates[i].pos &amp; kstates[j].pos;

			if ( ( (intersection.width &gt;= kstates[i].pos.width * overlap) &amp;&amp; (intersection.height &gt;= kstates[i].pos.height * overlap) ) ||
				( (intersection.width &gt;= kstates[j].pos.width * overlap) &amp;&amp; (intersection.height &gt;= kstates[j].pos.height * overlap) ) )
			{
				//if one state is overlapped by &quot;overlap&quot; % remove it (mark it as unused
				if (kstates[i].real_data &amp;&amp; !(kstates[j].real_data))
				{
					kstates[j].active = false;
					removedIndices.push_back(j);
				}
				else if (!(kstates[i].real_data) &amp;&amp; (kstates[j].real_data))
				{
					kstates[i].active = false;
					removedIndices.push_back(i);
				}
				else
				{
					kstates[j].active = false;
					removedIndices.push_back(j);
				}
			}
		}
	}*/
	ApplyNonMaximumSuppresion(kstates, OVERLAPPING_PERC);

	removeUnusedObjects(kstates);

	//return to x,y,w,h
	posScaleToBbox(kstates, trackedDetections);

}

void publish_if_possible()
{
	if (track_ready_ &amp;&amp; detect_ready_)
	{
		image_objects.publish(kf_objects_msg_);
		track_ready_ = false;
		detect_ready_ = false;
	}
}

void trackAndDrawObjects(cv::Mat&amp; image, int frameNumber, std::vector&lt;ObjectDetection_&gt; detections,
			 std::vector&lt;kstate&gt;&amp; kstates, std::vector&lt;bool&gt;&amp; active,
			 std::vector&lt;cv::Scalar&gt; colors, const sensor_msgs::Image&amp; image_source)
{
	std::vector&lt;kstate&gt; tracked_detections;

	cv::TickMeter tm;
	tm.start();
	//std::cout &lt;&lt; &quot;START tracking...&quot;;
	doTracking(detections, frameNumber, kstates, active, image, tracked_detections, colors);
	tm.stop();
	//std::cout &lt;&lt; &quot;END Tracking time = &quot; &lt;&lt; tm.getTimeSec() &lt;&lt; &quot; sec&quot; &lt;&lt; std::endl;

	//ROS
	int num = tracked_detections.size();
	std::vector&lt;cv_tracker::image_rect_ranged&gt; rect_ranged_array;
	std::vector&lt;int&gt; real_data(num,0);
	std::vector&lt;int&gt; obj_id(num, 0);
	std::vector&lt;int&gt; lifespan(num, 0);
	//ENDROS

	for (size_t i = 0; i &lt; tracked_detections.size(); i++)
	{
		kstate od = tracked_detections[i];
		cv_tracker::image_rect_ranged rect_ranged_;

		//od.rect contains x,y, width, height
		rectangle(image, od.pos, od.color, 3);
		putText(image, SSTR(od.id), cv::Point(od.pos.x + 4, od.pos.y + 13), cv::FONT_HERSHEY_SIMPLEX, 0.55, od.color, 2);
		//ROS
		obj_id[i] = od.id; // ?
		rect_ranged_.rect.x	= od.pos.x;
		rect_ranged_.rect.y	= od.pos.y;
		rect_ranged_.rect.width	= od.pos.width;
		rect_ranged_.rect.height = od.pos.height;
		rect_ranged_.range	= od.range;
		rect_ranged_.min_height	= od.min_height;
		rect_ranged_.max_height	= od.max_height;

		rect_ranged_array.push_back(rect_ranged_);

		real_data[i] = od.real_data;
		lifespan[i] = od.lifespan;
		//ENDROS
	}
	//more ros
	cv_tracker::image_obj_tracked kf_objects_msg;

	kf_objects_msg.type = object_type;
	kf_objects_msg.total_num = num;
	copy(rect_ranged_array.begin(), rect_ranged_array.end(), back_inserter(kf_objects_msg.rect_ranged)); // copy vector
	copy(real_data.begin(), real_data.end(), back_inserter(kf_objects_msg.real_data)); // copy vector
	copy(obj_id.begin(), obj_id.end(), back_inserter(kf_objects_msg.obj_id)); // copy vector
	copy(lifespan.begin(), lifespan.end(), back_inserter(kf_objects_msg.lifespan)); // copy vector

//	kf_objects_msg_.header = image_source.header;
	kf_objects_msg.header = image_objects_header;
	kf_objects_msg_ = kf_objects_msg;;
	track_ready_ = true;
	publish_if_possible();

	//cout &lt;&lt; &quot;.&quot;&lt;&lt; endl;
}

void image_callback(const sensor_msgs::Image&amp; image_source)
{
	//if (!_ready)
	//	return;

	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
	cv::Mat imageTrack = cv_image-&gt;image;
	trackAndDrawObjects(imageTrack, _counter, _dpm_detections, _kstates, _active, _colors, image_source);
	//_ready=false;
	//imshow(&quot;Tracked&quot;, imageTrack);

	_counter++;
}

void detections_callback(cv_tracker::image_obj_ranged image_objects_msg)
{
	if(!detect_ready_)
	{
		unsigned int num = image_objects_msg.obj.size();
		std::vector&lt;cv_tracker::image_rect_ranged&gt; objects = image_objects_msg.obj;
		object_type = image_objects_msg.type;
		image_objects_header = image_objects_msg.header;
		//points are X,Y,W,H and repeat for each instance
		_dpm_detections.clear();
		_ranges.clear();
		_min_heights.clear();
		_max_heights.clear();

		for (unsigned int i=0; i&lt;num;i++)
		{
			cv::Rect tmp;
			tmp.x = objects.at(i).rect.x;
			tmp.y = objects.at(i).rect.y;
			tmp.width = objects.at(i).rect.width;
			tmp.height = objects.at(i).rect.height;
			ObjectDetection_ obj_tmp;
			obj_tmp.rect = tmp; obj_tmp.score=0;
			_dpm_detections.push_back(obj_tmp);
			_ranges.push_back(objects.at(i).range);
			_min_heights.push_back(objects.at(i).min_height);
			_max_heights.push_back(objects.at(i).max_height);
		}
		//_ready = true;
		detect_ready_ = true;
	}
	//cout &lt;&lt; &quot;received pos&quot; &lt;&lt; endl;

	publish_if_possible();
}

static void kf_config_cb(const runtime_manager::ConfigCarKf::ConstPtr&amp; param)
{
	if (param-&gt;initial_lifespan &gt; 0)
		INITIAL_LIFESPAN	= param-&gt;initial_lifespan;
	if (param-&gt;default_lifespan &gt; 0)
		DEFAULT_LIFESPAN	= param-&gt;default_lifespan;
	if(param-&gt;noise_covariance &gt; 0)
		NOISE_COV			= param-&gt;noise_covariance;
	if(param-&gt;measurement_noise_covariance &gt; 0)
		MEAS_NOISE_COV		= param-&gt;measurement_noise_covariance;
	if(param-&gt;error_estimate_covariance &gt; 0)
		ERROR_ESTIMATE_COV	= param-&gt;error_estimate_covariance;
	if(param-&gt;percentage_of_overlapping &gt; 0)
		OVERLAPPING_PERC	= param-&gt;percentage_of_overlapping;

	ORB_NUM_FEATURES	= 2000;
	ORB_MIN_MATCHES		= 3;
	ORB_KNN_RATIO		= 0.7;

	USE_ORB				= param-&gt;use_orb;
}

void init_params()
{
	DEFAULT_LIFESPAN	= 8;
	INITIAL_LIFESPAN	= 4;
	NOISE_COV			= 1;
	MEAS_NOISE_COV		= 25;
	ERROR_ESTIMATE_COV	= 1000000;
	OVERLAPPING_PERC	= 80.0;
	SHOW_PREDICTIONS	= false;

	ORB_NUM_FEATURES	= 2000;
	ORB_MIN_MATCHES		= 3;
	ORB_KNN_RATIO		= 0.7;
	USE_ORB				= false;
}

int kf_main(int argc, char* argv[])
{
	ros::init(argc, argv, &quot;kf&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	image_objects = n.advertise&lt;cv_tracker::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);

	generateColors(_colors, 25);

	std::string image_topic;
	std::string obj_topic;
	if (private_nh.getParam(&quot;image_node&quot;, image_topic))
    	{
        	ROS_INFO(&quot;Setting image node to %s&quot;, image_topic.c_str());
    	}
	else
	{
		ROS_INFO(&quot;No image node received, defaulting to image_raw, you can use _image_node:=YOUR_TOPIC&quot;);
		image_topic = &quot;/image_raw&quot;;
	}
	if (private_nh.getParam(&quot;object_node&quot;, image_topic))
    	{
        	ROS_INFO(&quot;Setting object node to %s&quot;, image_topic.c_str());
    	}
	else
	{
		ROS_INFO(&quot;No object node received, defaulting to image_obj_ranged, you can use _object_node:=YOUR_TOPIC&quot;);
		obj_topic = &quot;image_obj_ranged&quot;;
	}

	init_params();

	ros::Subscriber sub_image = n.subscribe(image_topic, 1, image_callback);
	ros::Subscriber sub_dpm = n.subscribe(obj_topic, 1, detections_callback);


	std::string config_topic(&quot;/config&quot;);
	config_topic += ros::this_node::getNamespace() + &quot;/kf&quot;;
	ros::Subscriber config_subscriber = n.subscribe(config_topic, 1, kf_config_cb);

	//TimeSynchronizer&lt;Image, dpm::ImageObjects&gt; sync(image_sub, pos_sub, 10);

	//sync.registerCallback(boost::bind(&amp;sync_callback, _1, _2));
	track_ready_ = false;
	detect_ready_ = false;

	ros::spin();
	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/dpm_ttic/dpm_ttic.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/dpm_ttic/dpm_ttic.cpp">
				<diff>@@ -36,7 +36,7 @@
 #include &lt;sensor_msgs/Image.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
 
-#include &lt;cv_tracker/image_obj.h&gt;
+#include &lt;cv_tracker_msgs/image_obj.h&gt;
 #include &lt;runtime_manager/ConfigCarDpm.h&gt;
 #include &lt;runtime_manager/ConfigPedestrianDpm.h&gt;
 
@@ -67,10 +67,10 @@ static void set_default_param(DPMTTICParam&amp; param)
 	param.num_cells = 8;counter =0;
 }
 
-static void result_to_image_obj_message(cv_tracker::image_obj&amp; msg, const DPMTTICResult result)
+static void result_to_image_obj_message(cv_tracker_msgs::image_obj&amp; msg, const DPMTTICResult result)
 {
 	for (int i = 0; i &lt; result.num; ++i) {
-		cv_tracker::image_rect rect;
+		cv_tracker_msgs::image_rect rect;
 
 		int base = i * 4;
 		rect.x = result.corner_points[base];
@@ -90,7 +90,7 @@ static void image_raw_cb(const sensor_msgs::Image&amp; image_source)
 	IplImage img = cv_image-&gt;image;
 	IplImage *img_ptr = &amp;img;
 
-	cv_tracker::image_obj msg;
+	cv_tracker_msgs::image_obj msg;
 	msg.header = image_source.header;
 	msg.type = object_class;
 
@@ -190,7 +190,7 @@ int main(int argc, char* argv[])
 #endif
 
 	ros::Subscriber sub = n.subscribe(image_topic_name, 1, image_raw_cb);
-	image_obj_pub = n.advertise&lt;cv_tracker::image_obj&gt;(&quot;image_obj&quot;, 1);
+	image_obj_pub = n.advertise&lt;cv_tracker_msgs::image_obj&gt;(&quot;image_obj&quot;, 1);
 
 	ros::Subscriber config_sub;
 	std::string config_topic(&quot;/config&quot;);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;cstdio&gt;
#include &lt;string&gt;
#include &lt;ros/ros.h&gt;

#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;

#include &lt;cv_tracker/image_obj.h&gt;
#include &lt;runtime_manager/ConfigCarDpm.h&gt;
#include &lt;runtime_manager/ConfigPedestrianDpm.h&gt;

#include &lt;dpm_ttic.hpp&gt;

#define XSTR(x) #x
#define STR(x) XSTR(x)

static ros::Publisher image_obj_pub;

#if defined(HAS_GPU)
static DPMTTICGPU *gpu_model;
static bool use_gpu = true;
#endif
static DPMTTIC *ttic_model;

static DPMTTICParam ttic_param;

static std::string object_class;static long int counter;

static std::string image_topic_name;

static void set_default_param(DPMTTICParam&amp; param)
{
	param.overlap = 0.4;
	param.threshold = -0.5;
	param.lambda = 10;
	param.num_cells = 8;counter =0;
}

static void result_to_image_obj_message(cv_tracker::image_obj&amp; msg, const DPMTTICResult result)
{
	for (int i = 0; i &lt; result.num; ++i) {
		cv_tracker::image_rect rect;

		int base = i * 4;
		rect.x = result.corner_points[base];
		rect.y = result.corner_points[base+1];
		rect.width = result.corner_points[base+2];
		rect.height = result.corner_points[base+3];
		rect.score = result.score[i];

		msg.obj.push_back(rect);
	}
}

static void image_raw_cb(const sensor_msgs::Image&amp; image_source)
{

	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
	IplImage img = cv_image-&gt;image;
	IplImage *img_ptr = &amp;img;

	cv_tracker::image_obj msg;
	msg.header = image_source.header;
	msg.type = object_class;

#if defined(HAS_GPU)
	if (use_gpu) {
		DPMTTICResult result = gpu_model-&gt;detect_objects(img_ptr, ttic_param);
		result_to_image_obj_message(msg, result);
	} else {
#endif
		DPMTTICResult result = ttic_model-&gt;detect_objects(img_ptr, ttic_param);
		result_to_image_obj_message(msg, result);
#if defined(HAS_GPU)
	}
#endif

	image_obj_pub.publish(msg);
	counter++;
}

static void config_cb(const runtime_manager::ConfigPedestrianDpm::ConstPtr&amp; param)
{
	ttic_param.threshold = param-&gt;score_threshold;
	ttic_param.overlap   = param-&gt;group_threshold;
	ttic_param.lambda    = param-&gt;Lambda;
	ttic_param.num_cells = param-&gt;num_cells;
}

#if defined(HAS_GPU)
static std::string get_cubin_path(const ros::NodeHandle&amp; n, const char *default_path)
{
	std::string path;
	if (n.hasParam(&quot;/car_detector/cubin&quot;)) {
		n.getParam(&quot;/car_detector/cubin&quot;, path);
	} else {
		path = std::string(default_path);
	}

	return path;
}
#endif

int main(int argc, char* argv[])
{
	ros::init(argc, argv, &quot;dpm_ttic&quot;);

	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	if (!private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
		image_topic_name = &quot;/image_raw&quot;;
	}

	if (!private_nh.getParam(&quot;detection_class_name&quot;, object_class)) {
		object_class = &quot;car&quot;;
	}

	std::string comp_csv_path;
	if (!private_nh.getParam(&quot;comp_model_path&quot;, comp_csv_path)) {
		comp_csv_path = STR(MODEL_DIR) &quot;car_comp.csv&quot;;
	}

	std::string root_csv_path;
	if (!private_nh.getParam(&quot;root_model_path&quot;, root_csv_path)) {
		root_csv_path = STR(MODEL_DIR) &quot;car_root.csv&quot;;
	}

	std::string part_csv_path;
	if (!private_nh.getParam(&quot;part_model_path&quot;, part_csv_path)) {
		part_csv_path = STR(MODEL_DIR) &quot;car_part.csv&quot;;
	}

#if defined(HAS_GPU)
	if (!private_nh.getParam(&quot;use_gpu&quot;, use_gpu)) {
		use_gpu = false;
	}

	std::string cubin = get_cubin_path(n, STR(DEFAULT_CUBIN));
	if (use_gpu) {
		dpm_ttic_gpu_init_cuda(cubin);
	}
#endif

	set_default_param(ttic_param);

	const char *com_csv  = comp_csv_path.c_str();
	const char *root_csv = root_csv_path.c_str();
	const char *part_csv = part_csv_path.c_str();

#if defined(HAS_GPU)
	if (use_gpu) {
		gpu_model = new DPMTTICGPU(com_csv, root_csv, part_csv);
	} else {
#endif
		ttic_model = new DPMTTIC(com_csv, root_csv, part_csv);
#if defined(HAS_GPU)
	}
#endif

	ros::Subscriber sub = n.subscribe(image_topic_name, 1, image_raw_cb);
	image_obj_pub = n.advertise&lt;cv_tracker::image_obj&gt;(&quot;image_obj&quot;, 1);

	ros::Subscriber config_sub;
	std::string config_topic(&quot;/config&quot;);
	config_topic += ros::this_node::getNamespace() + &quot;/dpm&quot;;
	config_sub = n.subscribe(config_topic, 1, config_cb);

	ros::spin();
#if defined(HAS_GPU)
	if (use_gpu) {
		dpm_ttic_gpu_cleanup_cuda();
		delete gpu_model;
	} else {
#endif
		delete ttic_model;
#if defined(HAS_GPU)
	}
#endif

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/dummy_track/dummy_track.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/dummy_track/dummy_track.cpp">
				<diff>@@ -29,14 +29,14 @@
 */
 
 #include &lt;ros/ros.h&gt;
-#include &lt;cv_tracker/image_obj_tracked.h&gt;
-#include &lt;cv_tracker/image_obj_ranged.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
 
 class DummyTrack{
 public:
   DummyTrack(){
     subscriber_image_obj_ = node_handle_.subscribe(&quot;image_obj_ranged&quot;, 1, &amp;DummyTrack::detections_callback, this);
-		publisher_tracked_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
+		publisher_tracked_objects_ = node_handle_.advertise&lt;cv_tracker_msgs::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
   }
   void run(){
     ros::spin();
@@ -46,9 +46,9 @@ private:
   ros::Publisher 		publisher_tracked_objects_;//ROS
   ros::NodeHandle 	node_handle_;
 
-  void detections_callback(cv_tracker::image_obj_ranged image_objects_msg)
+  void detections_callback(cv_tracker_msgs::image_obj_ranged image_objects_msg)
   {
-    cv_tracker::image_obj_tracked pub_msg;
+    cv_tracker_msgs::image_obj_tracked pub_msg;
     pub_msg.header = image_objects_msg.header;
     pub_msg.type = image_objects_msg.type;
     pub_msg.rect_ranged = image_objects_msg.obj;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;cv_tracker/image_obj_tracked.h&gt;
#include &lt;cv_tracker/image_obj_ranged.h&gt;

class DummyTrack{
public:
  DummyTrack(){
    subscriber_image_obj_ = node_handle_.subscribe(&quot;image_obj_ranged&quot;, 1, &amp;DummyTrack::detections_callback, this);
		publisher_tracked_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
  }
  void run(){
    ros::spin();
  }
private:
  ros::Subscriber 	subscriber_image_obj_;
  ros::Publisher 		publisher_tracked_objects_;//ROS
  ros::NodeHandle 	node_handle_;

  void detections_callback(cv_tracker::image_obj_ranged image_objects_msg)
  {
    cv_tracker::image_obj_tracked pub_msg;
    pub_msg.header = image_objects_msg.header;
    pub_msg.type = image_objects_msg.type;
    pub_msg.rect_ranged = image_objects_msg.obj;
    pub_msg.total_num = image_objects_msg.obj.size();
    for (int i = 0; i &lt; pub_msg.total_num; ++i) {
      pub_msg.obj_id.push_back(i);
      pub_msg.real_data.push_back(0);
      pub_msg.lifespan.push_back(45);
    }
    publisher_tracked_objects_.publish(pub_msg);
  }
};

int main(int argc, char* argv[])
{
	ros::init(argc, argv, &quot;dummy_track&quot;);
  DummyTrack dummy_track;
  dummy_track.run();

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/klt_track/klt_track.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/klt_track/klt_track.cpp">
				<diff>@@ -37,9 +37,9 @@
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/Image.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;cv_tracker/image_obj.h&gt;
-#include &lt;cv_tracker/image_obj_tracked.h&gt;
-#include &lt;cv_tracker/image_obj_ranged.h&gt;
+#include &lt;cv_tracker_msgs/image_obj.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
 
 //TRACKING STUFF
 #include &lt;opencv2/core/core.hpp&gt;
@@ -85,7 +85,7 @@ class RosTrackerApp
 	std::vector&lt;float&gt; min_heights_;
 	std::vector&lt;float&gt; max_heights_;
 
-	cv_tracker::image_obj_tracked ros_objects_msg_;//sync
+	cv_tracker_msgs::image_obj_tracked ros_objects_msg_;//sync
 
 	void Sort(const std::vector&lt;float&gt; in_scores, std::vector&lt;unsigned int&gt;&amp; in_out_indices)
 	{
@@ -260,13 +260,13 @@ public:
 
 		//copy results to ros msg
 		unsigned int num = obj_trackers_.size();
-		std::vector&lt;cv_tracker::image_rect_ranged&gt; rect_ranged_array;//tracked rectangles
+		std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; rect_ranged_array;//tracked rectangles
 		std::vector&lt;int&gt; real_data(num,0);//boolean array to show if data in rect_ranged comes from tracking or detection
 		std::vector&lt;unsigned int&gt; obj_id(num, 0);//id number for each rect_range
 		std::vector&lt;unsigned int&gt; lifespan(num, 0);//remaining lifespan of each rectranged
 		for(i=0; i &lt; num; i++)
 		{
-			cv_tracker::image_rect_ranged rect_ranged;
+			cv_tracker_msgs::image_rect_ranged rect_ranged;
 			LkTracker tracker_tmp = *obj_trackers_[i];
 			rect_ranged.rect.x = tracker_tmp.GetTrackedObject().rect.x;
 			rect_ranged.rect.y = tracker_tmp.GetTrackedObject().rect.y;
@@ -292,7 +292,7 @@ public:
 		obj_detections_.clear();
         ranges_.clear();
 
-		cv_tracker::image_obj_tracked tmp_objects_msg;
+		cv_tracker_msgs::image_obj_tracked tmp_objects_msg;
 
 		tmp_objects_msg.type = tracked_type_;
 		tmp_objects_msg.total_num = num;
@@ -317,14 +317,14 @@ public:
 
 	}
 
-	void detections_callback(cv_tracker::image_obj_ranged image_objects_msg)
+	void detections_callback(cv_tracker_msgs::image_obj_ranged image_objects_msg)
 	{
 		//if(ready_)
 		//	return;
 		if (!detect_ready_)//must NOT overwrite, data is probably being used by tracking.
 		{
 			unsigned int num = image_objects_msg.obj.size();
-			std::vector&lt;cv_tracker::image_rect_ranged&gt; objects = image_objects_msg.obj;
+			std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects = image_objects_msg.obj;
 			tracked_type_ = image_objects_msg.type;
 			//points are X,Y,W,H and repeat for each instance
 			obj_detections_.clear();
@@ -350,13 +350,13 @@ public:
 		publish_if_possible();
 		//ready_ = true;
 	}
-	/*void detections_callback(cv_tracker::image_obj image_objects_msg)
+	/*void detections_callback(cv_tracker_msgs::image_obj image_objects_msg)
 	{
 		if (ready_)
 			return;
 		ready_ = false;
 		unsigned int num = image_objects_msg.obj.size();
-		std::vector&lt;cv_tracker::image_rect&gt; objects = image_objects_msg.obj;
+		std::vector&lt;cv_tracker_msgs::image_rect&gt; objects = image_objects_msg.obj;
 		//object_type = image_objects_msg.type;
 		//points are X,Y,W,H and repeat for each instance
 		obj_detections_.clear();
@@ -406,7 +406,7 @@ public:
 		}
 
 
-		publisher_tracked_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
+		publisher_tracked_objects_ = node_handle_.advertise&lt;cv_tracker_msgs::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
 
 		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str());
 		ROS_INFO(&quot;Subscribing to... %s&quot;, image_obj_topic_str.c_str());
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

//ROS STUFF
#include &lt;ros/ros.h&gt;

#include &lt;message_filters/subscriber.h&gt;
#include &lt;message_filters/time_synchronizer.h&gt;

#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_tracker/image_obj.h&gt;
#include &lt;cv_tracker/image_obj_tracked.h&gt;
#include &lt;cv_tracker/image_obj_ranged.h&gt;

//TRACKING STUFF
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/objdetect/objdetect.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
//#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &lt;opencv2/video/tracking.hpp&gt;
#include &lt;opencv2/calib3d/calib3d.hpp&gt;

#include &quot;LkTracker.hpp&quot;

#include &lt;iostream&gt;
#include &lt;stdio.h&gt;

#include &lt;string&gt;
#include &lt;sstream&gt;
#include &lt;algorithm&gt;
#include &lt;iterator&gt;

#include &quot;gencolors.cpp&quot;

class RosTrackerApp
{
	ros::Subscriber 	subscriber_image_raw_;
	ros::Subscriber 	subscriber_image_obj_;
	ros::Subscriber 	subscriber_klt_config_;
	ros::Publisher 		publisher_tracked_objects_;//ROS
	ros::NodeHandle 	node_handle_;

	std::string 		tracked_type_;

	bool 				ready_;

	bool				track_ready_;
	bool				detect_ready_;

	int					num_trackers_;

	std::vector&lt;LkTracker*&gt; obj_trackers_;
	std::vector&lt;ObjectDetection&gt; obj_detections_;

	std::vector&lt;float&gt; ranges_;
	std::vector&lt;float&gt; min_heights_;
	std::vector&lt;float&gt; max_heights_;

	cv_tracker::image_obj_tracked ros_objects_msg_;//sync

	void Sort(const std::vector&lt;float&gt; in_scores, std::vector&lt;unsigned int&gt;&amp; in_out_indices)
	{
		for (unsigned int i = 0; i &lt; in_scores.size(); i++)
			for (unsigned int j = i + 1; j &lt; in_scores.size(); j++)
			{
				if (in_scores[in_out_indices[j]] &gt; in_scores[in_out_indices[i]])
				{
					//float x_tmp = x[i];
					int index_tmp = in_out_indices[i];
					//x[i] = x[j];
					in_out_indices[i] = in_out_indices[j];
					//x[j] = x_tmp;
					in_out_indices[j] = index_tmp;
				}
			}
	}

	void ApplyNonMaximumSuppresion(std::vector&lt; LkTracker* &gt;&amp; in_out_source, float in_nms_threshold)
	{
		if (in_out_source.empty())
			return;

		unsigned int size = in_out_source.size();

		std::vector&lt;float&gt; area(size);
		std::vector&lt;float&gt; scores(size);
		std::vector&lt;int&gt; x1(size);
		std::vector&lt;int&gt; y1(size);
		std::vector&lt;int&gt; x2(size);
		std::vector&lt;int&gt; y2(size);
		std::vector&lt;unsigned int&gt; indices(size);
		std::vector&lt;bool&gt; is_suppresed(size);

		for(unsigned int i = 0; i&lt; in_out_source.size(); i++)
		{
			ObjectDetection tmp = in_out_source[i]-&gt;GetTrackedObject();
			area[i] = tmp.rect.width * tmp.rect.height;
			if (area[i]&gt;0)
				is_suppresed[i] = false;
			else
			{
				is_suppresed[i] = true;
				in_out_source[i]-&gt;NullifyLifespan();
			}
			indices[i] = i;
			scores[i] = tmp.score;
			x1[i] = tmp.rect.x;
			y1[i] = tmp.rect.y;
			x2[i] = tmp.rect.width + tmp.rect.x;
			y2[i] = tmp.rect.height + tmp.rect.y;
		}

		Sort(area, indices);//returns indices ordered based on scores

		for(unsigned int i=0; i&lt; size; i++)
		{

			for(unsigned int j= i+1; j&lt; size; j++)
			{
				if(is_suppresed[indices[i]] || is_suppresed[indices[j]])
					continue;
				int x1_max = std::max(x1[indices[i]], x1[indices[j]]);
				int x2_min = std::min(x2[indices[i]], x2[indices[j]]);
				int y1_max = std::max(y1[indices[i]], y1[indices[j]]);
				int y2_min = std::min(y2[indices[i]], y2[indices[j]]);
				int overlap_width = x2_min - x1_max + 1;
				int overlap_height = y2_min - y1_max + 1;
				if(overlap_width &gt; 0 &amp;&amp; overlap_height&gt;0)
				{
					float overlap_part = (overlap_width*overlap_height)/area[indices[j]];
					if(overlap_part &gt; in_nms_threshold)
					{
						is_suppresed[indices[j]] = true;
						in_out_source[indices[j]]-&gt;NullifyLifespan();
						if (in_out_source[indices[j]]-&gt;GetFrameCount() &gt; in_out_source[indices[i]]-&gt;GetFrameCount())
						{
							in_out_source[indices[i]]-&gt;object_id = in_out_source[indices[j]]-&gt;object_id;
						}

					}
				}
			}
		}
		return ;
	}

	void publish_if_possible()
	{
		if (track_ready_ &amp;&amp; detect_ready_)
		{
			publisher_tracked_objects_.publish(ros_objects_msg_);
			track_ready_ = false;
			detect_ready_ = false;
		}
	}

public:
	void image_callback(const sensor_msgs::Image&amp; image_source)
	{
		cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
		cv::Mat image_track = cv_image-&gt;image;
		
		ObjectDetection empty_detection;
		empty_detection.rect=cv::Rect(0,0,0,0);
		empty_detection.score=0;
		unsigned int i;

		std::vector&lt;bool&gt; tracker_matched(obj_trackers_.size(), false);
		std::vector&lt;bool&gt; object_matched(obj_detections_.size(), false);

		//check object detections vs current trackers
		for (i =0; i&lt; obj_detections_.size(); i++)
		{
			for (unsigned int j = 0; j &lt; obj_trackers_.size(); j++)
			{
				if (tracker_matched[j] || object_matched[i])
					continue;

				ObjectDetection tmp_detection = obj_detections_[i];
				int area = tmp_detection.rect.width * tmp_detection.rect.height;
				cv::Rect intersection = tmp_detection.rect &amp; obj_trackers_[j]-&gt;GetTrackedObject().rect;
				if ( (intersection.width * intersection.height) &gt; area*0.3 )
				{

					obj_trackers_[j]-&gt;Track(image_track, obj_detections_[i], true);
					tracker_matched[j] = true;
					object_matched[i] = true;
					//std::cout &lt;&lt; &quot;matched &quot; &lt;&lt; i &lt;&lt; &quot; with &quot; &lt;&lt; j &lt;&lt; std::endl;
				}
			}
		}

		//run the trackers not matched
		for(i = 0; i &lt; obj_trackers_.size(); i++)
		{
			if(!tracker_matched[i])
			{
				obj_trackers_[i]-&gt;Track(image_track, empty_detection, false);
			}
		}

		//create trackers for those objects not being tracked yet
		for(unsigned int i=0; i&lt;obj_detections_.size(); i++)
		{
			if (!object_matched[i])//if object wasn't matched by overlapping area, create a new tracker
			{
				if (num_trackers_ &gt;10)
					num_trackers_=0;
				LkTracker* new_tracker = new LkTracker(++num_trackers_, min_heights_[i], max_heights_[i], ranges_[i]);
				new_tracker-&gt;Track(image_track, obj_detections_[i], true);

				//std::cout &lt;&lt; &quot;added new tracker&quot; &lt;&lt; std::endl;
				obj_trackers_.push_back(new_tracker);
			}
		}

		ApplyNonMaximumSuppresion(obj_trackers_, 0.3);

		//remove those trackers with its lifespan &lt;=0
		std::vector&lt;LkTracker*&gt;::iterator it;
		for(it = obj_trackers_.begin(); it != obj_trackers_.end();)
		{
			if ( (*it)-&gt;GetRemainingLifespan()&lt;=0 )
			{
				it = obj_trackers_.erase(it);
				//std::cout &lt;&lt; &quot;deleted a tracker &quot; &lt;&lt; std::endl;
			}
			else
				it++;
		}

		//copy results to ros msg
		unsigned int num = obj_trackers_.size();
		std::vector&lt;cv_tracker::image_rect_ranged&gt; rect_ranged_array;//tracked rectangles
		std::vector&lt;int&gt; real_data(num,0);//boolean array to show if data in rect_ranged comes from tracking or detection
		std::vector&lt;unsigned int&gt; obj_id(num, 0);//id number for each rect_range
		std::vector&lt;unsigned int&gt; lifespan(num, 0);//remaining lifespan of each rectranged
		for(i=0; i &lt; num; i++)
		{
			cv_tracker::image_rect_ranged rect_ranged;
			LkTracker tracker_tmp = *obj_trackers_[i];
			rect_ranged.rect.x = tracker_tmp.GetTrackedObject().rect.x;
			rect_ranged.rect.y = tracker_tmp.GetTrackedObject().rect.y;
			rect_ranged.rect.width = tracker_tmp.GetTrackedObject().rect.width;
			rect_ranged.rect.height = tracker_tmp.GetTrackedObject().rect.height;
			rect_ranged.rect.score = tracker_tmp.GetTrackedObject().score;
			rect_ranged.max_height = tracker_tmp.max_height_;
			rect_ranged.min_height = tracker_tmp.min_height_;
			rect_ranged.range = tracker_tmp.range_;

			rect_ranged_array.push_back(rect_ranged);

			lifespan[i] = tracker_tmp.GetRemainingLifespan();
			obj_id[i] = tracker_tmp.object_id;
			if(lifespan[i]==tracker_tmp.DEFAULT_LIFESPAN_)
				real_data[i] = 1;

			cv::rectangle(image_track, tracker_tmp.GetTrackedObject().rect, cv::Scalar(0,255,0), 2);
		}

		//std::cout &lt;&lt; &quot;TRACKERS: &quot; &lt;&lt; obj_trackers_.size() &lt;&lt; std::endl;

		obj_detections_.clear();
        ranges_.clear();

		cv_tracker::image_obj_tracked tmp_objects_msg;

		tmp_objects_msg.type = tracked_type_;
		tmp_objects_msg.total_num = num;
		copy(rect_ranged_array.begin(), rect_ranged_array.end(), back_inserter(tmp_objects_msg.rect_ranged)); // copy vector
		copy(real_data.begin(), real_data.end(), back_inserter(tmp_objects_msg.real_data)); // copy vector
		copy(obj_id.begin(), obj_id.end(), back_inserter(tmp_objects_msg.obj_id)); // copy vector
		copy(lifespan.begin(), lifespan.end(), back_inserter(tmp_objects_msg.lifespan)); // copy vector

		tmp_objects_msg.header = image_source.header;

		ros_objects_msg_ = tmp_objects_msg;

		//publisher_tracked_objects_.publish(ros_objects_msg);

		//cv::imshow(&quot;KLT&quot;,image_track);
		//cv::waitKey(1);

		track_ready_ = true;
		//ready_ = false;

		publish_if_possible();

	}

	void detections_callback(cv_tracker::image_obj_ranged image_objects_msg)
	{
		//if(ready_)
		//	return;
		if (!detect_ready_)//must NOT overwrite, data is probably being used by tracking.
		{
			unsigned int num = image_objects_msg.obj.size();
			std::vector&lt;cv_tracker::image_rect_ranged&gt; objects = image_objects_msg.obj;
			tracked_type_ = image_objects_msg.type;
			//points are X,Y,W,H and repeat for each instance
			obj_detections_.clear();
            ranges_.clear();
            
			for (unsigned int i=0; i&lt;num;i++)
			{
				cv::Rect tmp;
				tmp.x = objects.at(i).rect.x;
				tmp.y = objects.at(i).rect.y;
				tmp.width = objects.at(i).rect.width;
				tmp.height = objects.at(i).rect.height;
				ObjectDetection tmp_obj;
				tmp_obj.rect=tmp; tmp_obj.score=0;
				obj_detections_.push_back(tmp_obj);
				ranges_.push_back(objects.at(i).range);
				min_heights_.push_back(objects.at(i).min_height);
				max_heights_.push_back(objects.at(i).max_height);
			}
			detect_ready_ = true;
		}

		publish_if_possible();
		//ready_ = true;
	}
	/*void detections_callback(cv_tracker::image_obj image_objects_msg)
	{
		if (ready_)
			return;
		ready_ = false;
		unsigned int num = image_objects_msg.obj.size();
		std::vector&lt;cv_tracker::image_rect&gt; objects = image_objects_msg.obj;
		//object_type = image_objects_msg.type;
		//points are X,Y,W,H and repeat for each instance
		obj_detections_.clear();
		tracked_type_ = image_objects_msg.type;
		for (unsigned int i=0; i&lt;num;i++)
		{
			cv::Rect tmp;
			tmp.x = objects.at(i).x;
			tmp.y = objects.at(i).y;
			tmp.width = objects.at(i).width;
			tmp.height = objects.at(i).height;
			obj_detections_.push_back(ObjectDetection(tmp, 0));
		}
		ready_ = true;
	}*/

	void klt_config_cb()
	{

	}


	void Run()
	{
		std::string image_raw_topic_str;
		std::string image_obj_topic_str;

		ros::NodeHandle private_node_handle(&quot;~&quot;);//to receive args

		if (private_node_handle.getParam(&quot;image_raw_node&quot;, image_raw_topic_str))
			{
				ROS_INFO(&quot;Setting image node to %s&quot;, image_raw_topic_str.c_str());
			}
		else
		{
			ROS_INFO(&quot;No image node received, defaulting to /image_raw, you can use _image_raw_node:=YOUR_TOPIC&quot;);
			image_raw_topic_str = &quot;/image_raw&quot;;
		}
		if (private_node_handle.getParam(ros::this_node::getNamespace() + &quot;/img_obj_node&quot;, image_obj_topic_str))
			{
				ROS_INFO(&quot;Setting object node to %s&quot;, image_obj_topic_str.c_str());
			}
		else
		{
			ROS_INFO(&quot;No object node received, defaulting to image_obj_ranged, you can use _img_obj_node:=YOUR_TOPIC&quot;);
			image_obj_topic_str = &quot;image_obj_ranged&quot;;
		}


		publisher_tracked_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);

		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str());
		ROS_INFO(&quot;Subscribing to... %s&quot;, image_obj_topic_str.c_str());
		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str, 1, &amp;RosTrackerApp::image_callback, this);
		subscriber_image_obj_ = node_handle_.subscribe(image_obj_topic_str, 1, &amp;RosTrackerApp::detections_callback, this);

		std::string config_topic(&quot;/config&quot;);
		config_topic += ros::this_node::getNamespace() + &quot;/klt&quot;;
		//node_handle.subscribe(config_topic, 1, &amp;RosTrackerApp::klt_config_cb, this);

		ros::spin();
		ROS_INFO(&quot;END klt&quot;);
	}

	RosTrackerApp()
	{
		ready_ = true;
		num_trackers_ = 0;
		track_ready_  = false;
		detect_ready_ = false;
	}

};

int main(int argc, char* argv[])
{
	ros::init(argc, argv, &quot;klt&quot;);

	RosTrackerApp app;

	app.Run();

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/obj_reproj/obj_reproj.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/obj_reproj/obj_reproj.cpp">
				<diff>@@ -56,7 +56,7 @@
 #include &lt;geometry_msgs/Pose.h&gt;
 #include &lt;visualization_msgs/Marker.h&gt;
 #include &lt;visualization_msgs/MarkerArray.h&gt;
-#include &lt;cv_tracker/image_obj_tracked.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
 #include &lt;tf/tf.h&gt;
 #include &lt;tf/transform_listener.h&gt;
 #include &lt;sensor_msgs/NavSatFix.h&gt;
@@ -65,7 +65,7 @@
 #include &quot;axialMove.h&quot;
 #include &quot;geo_pos_conv.hh&quot;
 #include &quot;CalObjLoc.h&quot;
-#include &quot;cv_tracker/obj_label.h&quot;
+#include &quot;cv_tracker_msgs/obj_label.h&quot;
 #include &quot;calibration_camera_lidar/projection_matrix.h&quot;
 #include &lt;sensor_msgs/CameraInfo.h&gt;
 #include &lt;mutex&gt;
@@ -121,7 +121,7 @@ static tf::StampedTransform transformCam2Map;
 std::string camera_id_str;
 
 
-static visualization_msgs::MarkerArray convert_marker_array(const cv_tracker::obj_label&amp; src)
+static visualization_msgs::MarkerArray convert_marker_array(const cv_tracker_msgs::obj_label&amp; src)
 {
   visualization_msgs::MarkerArray ret;
   int index = 0;
@@ -196,7 +196,7 @@ static visualization_msgs::MarkerArray convert_marker_array(const cv_tracker::ob
 }
 
 #ifdef HAVE_JSK_PLUGIN
-static jsk_recognition_msgs::BoundingBoxArray convertJskBoundingBoxArray(const cv_tracker::obj_label&amp; src)
+static jsk_recognition_msgs::BoundingBoxArray convertJskBoundingBoxArray(const cv_tracker_msgs::obj_label&amp; src)
 {
   jsk_recognition_msgs::BoundingBoxArray ret;
   ret.header.frame_id =&quot;map&quot;;
@@ -254,7 +254,7 @@ void GetRPY(const geometry_msgs::Pose &amp;pose,
 
 void makeSendDataDetectedObj(vector&lt;OBJPOS&gt; car_position_vector,
                              vector&lt;OBJPOS&gt;::iterator cp_iterator,
-                             cv_tracker::obj_label&amp; send_data)
+                             cv_tracker_msgs::obj_label&amp; send_data)
 {
   geometry_msgs::Point tmpPoint;
 
@@ -298,7 +298,7 @@ void locatePublisher(void){
   //get values from sample_corner_point , convert latitude and longitude,
   //and send database server.
 
-  cv_tracker::obj_label obj_label_msg;
+  cv_tracker_msgs::obj_label obj_label_msg;
   visualization_msgs::MarkerArray obj_label_marker_msgs;
 
   vector&lt;OBJPOS&gt;::iterator cp_iterator;
@@ -329,7 +329,7 @@ void locatePublisher(void){
 #endif  // ifdef HAVE_JSK_PLUGIN
 }
 
-static void obj_pos_xyzCallback(const cv_tracker::image_obj_tracked&amp; fused_objects)
+static void obj_pos_xyzCallback(const cv_tracker_msgs::image_obj_tracked&amp; fused_objects)
 {
   if (!ready_)
     return;
@@ -399,7 +399,7 @@ int main(int argc, char **argv){
 
   ros::Subscriber obj_pos_xyz = n.subscribe(&quot;image_obj_tracked&quot;, 1, obj_pos_xyzCallback);
 
-  pub = n.advertise&lt;cv_tracker::obj_label&gt;(&quot;obj_label&quot;,1);
+  pub = n.advertise&lt;cv_tracker_msgs::obj_label&gt;(&quot;obj_label&quot;,1);
   marker_pub = n.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;obj_label_marker&quot;, 1);
 
 #ifdef HAVE_JSK_PLUGIN
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &lt;std_msgs/String.h&gt;
#include &lt;ros/ros.h&gt;

#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;sensor_msgs/CompressedImage.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;
#include &lt;math.h&gt;
#include &lt;vector&gt;
#include &lt;boost/array.hpp&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;sstream&gt;
#include &lt;sys/time.h&gt;
#include &lt;bitset&gt;

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv/cxcore.h&gt;

#include &lt;std_msgs/Float64.h&gt;
#include &lt;std_msgs/Header.h&gt;
#include &lt;scan2image/ScanImage.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/Pose.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;cv_tracker/image_obj_tracked.h&gt;
#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;sensor_msgs/NavSatFix.h&gt;
#include &quot;structure.h&quot;
#include &quot;calcoordinates.h&quot;
#include &quot;axialMove.h&quot;
#include &quot;geo_pos_conv.hh&quot;
#include &quot;CalObjLoc.h&quot;
#include &quot;cv_tracker/obj_label.h&quot;
#include &quot;calibration_camera_lidar/projection_matrix.h&quot;
#include &lt;sensor_msgs/CameraInfo.h&gt;
#include &lt;mutex&gt;

#ifdef HAVE_JSK_PLUGIN
#include &quot;jsk_recognition_msgs/BoundingBox.h&quot;
#include &quot;jsk_recognition_msgs/BoundingBoxArray.h&quot;
#endif  // ifdef HAVE_JSK_PLUGIN

#define XSTR(x) #x
#define STR(x) XSTR(x)

using namespace std;

static constexpr double LOOP_RATE = 15.0;

typedef struct _OBJPOS{
  int x1;
  int y1;
  int x2;
  int y2;
  float distance;
  int id;
}OBJPOS;

static objLocation ol;

//store subscribed value
static vector&lt;OBJPOS&gt; global_cp_vector;

//flag for comfirming whether updating position or not
static bool ready_;

static double cameraMatrix[4][4] = {
  {-7.8577658642752374e-03, -6.2035361880992401e-02,9.9804301981022692e-01, 5.1542126095196206e-01},
  {-9.9821250329813849e-01, 5.9620033356180935e-02,-4.1532977104442731e-03, -2.9214878315161133e-02},
  {-5.9245706805522491e-02, -9.9629165684497312e-01,-6.2392954139163306e-02, -6.6728858508628075e-01},
  {0, 0, 0, 1}
};

static ros::Publisher pub;
static ros::Publisher marker_pub;
#ifdef HAVE_JSK_PLUGIN
static ros::Publisher jsk_bounding_box_pub;
#endif // ifdef HAVE_JSK_PLUGIN

static std::string object_type;
static ros::Time image_obj_tracked_time;

//coordinate system conversion between camera coordinate and map coordinate
static tf::StampedTransform transformCam2Map;

std::string camera_id_str;


static visualization_msgs::MarkerArray convert_marker_array(const cv_tracker::obj_label&amp; src)
{
  visualization_msgs::MarkerArray ret;
  int index = 0;
  std_msgs::ColorRGBA color_red;
  color_red.r = 1.0f;
  color_red.g = 0.0f;
  color_red.b = 0.0f;
  color_red.a = 0.7f;

  std_msgs::ColorRGBA color_blue;
  color_blue.r = 0.0f;
  color_blue.g = 0.0f;
  color_blue.b = 1.0f;
  color_blue.a = 0.7f;

  std_msgs::ColorRGBA color_green;
  color_green.r = 0.0f;
  color_green.g = 1.0f;
  color_green.b = 0.0f;
  color_green.a = 0.7f;

  for (const auto&amp; reproj_pos : src.reprojected_pos)
    {
      visualization_msgs::Marker marker;
      /* Set frame ID */
      marker.header.frame_id = &quot;map&quot;;

      /* Set namespace adn id for this marker */
      marker.ns = object_type;
      marker.id = index;
      index++;

      /* set color */
      if (object_type == &quot;car&quot;) {
        /* Set marker shape */
        marker.type = visualization_msgs::Marker::SPHERE;

        /* set pose of marker  */
        marker.pose.position = reproj_pos;

        /* set scale of marker */
        marker.scale.x = (double)1.5;
        marker.scale.y = (double)1.5;
        marker.scale.z = (double)1.5;

        marker.color = color_blue;
      }
      else if (object_type == &quot;person&quot;) {
        /* Set marker shape */
        marker.type = visualization_msgs::Marker::CUBE;

        /* set pose of marker  */
        marker.pose.position = reproj_pos;

        /* set scale of marker */
        marker.scale.x = (double)0.7;
        marker.scale.y = (double)0.7;
        marker.scale.z = (double)1.8;

        marker.color = color_green;
      }
      else {
        marker.color = color_red;
      }

      marker.lifetime = ros::Duration(0.3);

      ret.markers.push_back(marker);
    }

  return ret;
}

#ifdef HAVE_JSK_PLUGIN
static jsk_recognition_msgs::BoundingBoxArray convertJskBoundingBoxArray(const cv_tracker::obj_label&amp; src)
{
  jsk_recognition_msgs::BoundingBoxArray ret;
  ret.header.frame_id =&quot;map&quot;;

  for (const auto&amp; reproj_pos : src.reprojected_pos)
    {
      jsk_recognition_msgs::BoundingBox bounding_box;
      bounding_box.header.frame_id = &quot;map&quot;;

      bounding_box.pose.position = reproj_pos;

      bounding_box.dimensions.x = 1.5;
      bounding_box.dimensions.y = 1.5;
      bounding_box.dimensions.z = 1.5;

      ret.boxes.push_back(bounding_box);
    }

  return ret;
}
#endif  // ifdef HAVE_JSK_PLUGIN

static void projection_callback(const calibration_camera_lidar::projection_matrix&amp; msg)
{
  for (int row=0; row&lt;4; row++) {
    for (int col=0; col&lt;4; col++) {
      cameraMatrix[row][col] = msg.projection_matrix[row * 4 + col];
    }
  }
  ready_ = true;
}

static void camera_info_callback(const sensor_msgs::CameraInfo&amp; msg)
{
  double fkx = msg.K[0 * 3 + 0]; // get K[0][0]
  double fky = msg.K[1 * 3 + 1]; // get K[1][1]
  double Ox  = msg.K[0 * 3 + 2]; // get K[0][2]
  double Oy  = msg.K[1 * 3 + 2]; // get K[1][2]
  ol.setCameraParam(fkx,fky,Ox,Oy);
}

void GetRPY(const geometry_msgs::Pose &amp;pose,
	    double &amp;roll,
	    double &amp;pitch,
	    double &amp;yaw){
  tf::Quaternion q;
  tf::quaternionMsgToTF(pose.orientation,q);
  tf::Matrix3x3(q).getRPY(roll,pitch,yaw);

  //reverse angle value
  roll  = -roll;
  pitch = -pitch;
  yaw   = -yaw;
}

void makeSendDataDetectedObj(vector&lt;OBJPOS&gt; car_position_vector,
                             vector&lt;OBJPOS&gt;::iterator cp_iterator,
                             cv_tracker::obj_label&amp; send_data)
{
  geometry_msgs::Point tmpPoint;

  for(uint i=0; i&lt;car_position_vector.size() ; i++, cp_iterator++){

    //middle of right-lower and left-upper
    double U = cp_iterator-&gt;x1 + cp_iterator-&gt;x2/2;
    double V = cp_iterator-&gt;y1 + cp_iterator-&gt;y2/2;

    //convert from &quot;image&quot; coordinate system to &quot;camera&quot; coordinate system
    ol.setOriginalValue(U,V,cp_iterator-&gt;distance);
    LOCATION ress = ol.cal();

    /* convert from &quot;camera&quot; coordinate system to &quot;map&quot; coordinate system */
    tf::Vector3 pos_in_camera_coord(ress.X, ress.Y, ress.Z);
    static tf::TransformListener listener;
    try {
        listener.lookupTransform(&quot;map&quot;, camera_id_str, ros::Time(0), transformCam2Map);
    }
    catch (tf::TransformException ex) {
        ROS_INFO(&quot;%s&quot;, ex.what());
        return;
    }
    tf::Vector3 converted = transformCam2Map * pos_in_camera_coord;

    tmpPoint.x = converted.x();
    tmpPoint.y = converted.y();
    tmpPoint.z = converted.z();

    send_data.reprojected_pos.push_back(tmpPoint);
    send_data.obj_id.push_back(cp_iterator-&gt;id);
  }
}

//wrap SendData class
void locatePublisher(void){

  vector&lt;OBJPOS&gt; car_position_vector;
  copy(global_cp_vector.begin(), global_cp_vector.end(), back_inserter(car_position_vector));

  //get values from sample_corner_point , convert latitude and longitude,
  //and send database server.

  cv_tracker::obj_label obj_label_msg;
  visualization_msgs::MarkerArray obj_label_marker_msgs;

  vector&lt;OBJPOS&gt;::iterator cp_iterator;
 
  cp_iterator = car_position_vector.begin();

  //get data of car and pedestrian recognizing
  if(!car_position_vector.empty()){
    makeSendDataDetectedObj(car_position_vector,cp_iterator,obj_label_msg);
  }

  //publish recognized car data
  obj_label_msg.type = object_type;
  obj_label_marker_msgs = convert_marker_array(obj_label_msg);
  /* Extraordinary correspondence because of wrong timestamp(current_pose)
   * if a timestamp of current_pose is modified, this comment out should be removed
   */
//  if(image_obj_tracked_time.sec == current_pose.sec &amp;&amp; image_obj_tracked_time.nsec == current_pose.nsec) {
    obj_label_msg.header.stamp = image_obj_tracked_time;
//  }

  pub.publish(obj_label_msg);
  marker_pub.publish(obj_label_marker_msgs);

#ifdef HAVE_JSK_PLUGIN
  jsk_recognition_msgs::BoundingBoxArray obj_label_bounding_box_msgs = convertJskBoundingBoxArray(obj_label_msg);
  jsk_bounding_box_pub.publish(obj_label_bounding_box_msgs);
#endif  // ifdef HAVE_JSK_PLUGIN
}

static void obj_pos_xyzCallback(const cv_tracker::image_obj_tracked&amp; fused_objects)
{
  if (!ready_)
    return;
  image_obj_tracked_time = fused_objects.header.stamp;

  global_cp_vector.clear();

  OBJPOS cp;

  object_type = fused_objects.type;
  //If angle and position data is not updated from prevous data send,
  //data is not sent
  //  if(gnssGetFlag || ndtGetFlag) {
    for (unsigned int i = 0; i &lt; fused_objects.rect_ranged.size(); i++){

      //If distance is zero, we cannot calculate position of recognized object
      //so skip loop
      if(fused_objects.rect_ranged.at(i).range &lt;= 0) continue;

      cp.x1 = fused_objects.rect_ranged.at(i).rect.x;      // x-axis of the upper left
      cp.y1 = fused_objects.rect_ranged.at(i).rect.y;      // y-axis of the upper left
      cp.x2 = fused_objects.rect_ranged.at(i).rect.width;  // width of detection rectangle
      cp.y2 = fused_objects.rect_ranged.at(i).rect.height; // height of detection rectangle

      /*
        As cameraMatrix[0][3] is offset from lidar to camera,
        this cp.distance is z-axis value of detected object in camera coordinate system.
        (As received distance is in [cm] unit, I convert unit from [cm] to [mm] here)
      */
      cp.distance = (fused_objects.rect_ranged.at(i).range - cameraMatrix[0][3]) * 10;
      cp.id = fused_objects.obj_id.at(i);

      global_cp_vector.push_back(cp);
    }

    locatePublisher();

    //  }
}


int main(int argc, char **argv){

  ros::init(argc ,argv, &quot;obj_reproj&quot;) ;
  cout &lt;&lt; &quot;obj_reproj&quot; &lt;&lt; endl;

  ready_ = false;

  /**
   * NodeHandle is the main access point to communications with the ROS system.
   * The first NodeHandle constructed will fully initialize this node, and the last
   * NodeHandle destructed will close down the node.
   */
  ros::NodeHandle n;
  ros::NodeHandle private_nh(&quot;~&quot;);
  std::string projectionMat_topic_name;
  private_nh.param&lt;std::string&gt;(&quot;projection_matrix_topic&quot;, projectionMat_topic_name, &quot;/projection_matrix&quot;);
  std::string camera_info_topic_name;
  private_nh.param&lt;std::string&gt;(&quot;camera_info_topic&quot;, camera_info_topic_name, &quot;/camera/camera_info&quot;);

  //get camera ID
  camera_id_str = camera_info_topic_name;
  camera_id_str.erase(camera_id_str.find(&quot;/camera/camera_info&quot;));
  if (camera_id_str == &quot;/&quot;) {
    camera_id_str = &quot;camera&quot;;
  }

  ros::Subscriber obj_pos_xyz = n.subscribe(&quot;image_obj_tracked&quot;, 1, obj_pos_xyzCallback);

  pub = n.advertise&lt;cv_tracker::obj_label&gt;(&quot;obj_label&quot;,1);
  marker_pub = n.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;obj_label_marker&quot;, 1);

#ifdef HAVE_JSK_PLUGIN
  jsk_bounding_box_pub = n.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(&quot;obj_label_bounding_box&quot;, 1);
#endif

  ros::Subscriber projection = n.subscribe(projectionMat_topic_name, 1, projection_callback);
  ros::Subscriber camera_info = n.subscribe(camera_info_topic_name, 1, camera_info_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/range_fusion/range_fusion.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/range_fusion/range_fusion.cpp">
				<diff>@@ -29,7 +29,7 @@
 */
 
 #include &lt;ros/ros.h&gt;
-#include &lt;cv_tracker/image_obj_ranged.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
 #include &lt;std_msgs/Header.h&gt;
 #include &lt;fusion_func.h&gt;
 #include &lt;runtime_manager/ConfigCarFusion.h&gt;
@@ -40,7 +40,7 @@ static std_msgs::Header sensor_header;
 
 bool ready_ = false;
 
-static void DetectedObjectsCallback(const cv_tracker::image_obj&amp; image_object)
+static void DetectedObjectsCallback(const cv_tracker_msgs::image_obj&amp; image_object)
 {
     sensor_header = image_object.header;
     setDetectedObjects(image_object);
@@ -80,7 +80,7 @@ static void publishTopic()
 	/*
 	 * Publish topic(obj position ranged).
 	 */
-	cv_tracker::image_obj_ranged fused_objects_msg;
+	cv_tracker_msgs::image_obj_ranged fused_objects_msg;
 	fused_objects_msg.header = sensor_header;
 
 	fused_objects_msg.type = getObjectsType();
@@ -133,7 +133,7 @@ int main(int argc, char **argv)
 #if _DEBUG
 	ros::Subscriber image_sub = n.subscribe(IMAGE_TOPIC, 1, IMAGE_CALLBACK);
 #endif
-	fused_objects = n.advertise&lt;cv_tracker::image_obj_ranged&gt;(&quot;image_obj_ranged&quot;, 1);
+	fused_objects = n.advertise&lt;cv_tracker_msgs::image_obj_ranged&gt;(&quot;image_obj_ranged&quot;, 1);
 
 	ros::Subscriber config_subscriber;
 	std::string config_topic(&quot;/config&quot;);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;cv_tracker/image_obj_ranged.h&gt;
#include &lt;std_msgs/Header.h&gt;
#include &lt;fusion_func.h&gt;
#include &lt;runtime_manager/ConfigCarFusion.h&gt;

static void publishTopic();
static ros::Publisher fused_objects;
static std_msgs::Header sensor_header;

bool ready_ = false;

static void DetectedObjectsCallback(const cv_tracker::image_obj&amp; image_object)
{
    sensor_header = image_object.header;
    setDetectedObjects(image_object);
    if (ready_) {
        fuse();
        publishTopic();
        ready_ = false;
        return;
    }
    ready_ = true;
}

/*static void ScanImageCallback(const scan2image::ScanImage&amp; scan_image)
{
	setScanImage(scan_image);
	sensor_header = scan_image.header;

	calcDistance();
	publishTopic();
}*/

static void PointsImageCallback(const points2image::PointsImage&amp; points_image)
{
    sensor_header = points_image.header;
    setPointsImage(points_image);
    if (ready_) {
		fuse();
		publishTopic();
        ready_ = false;
        return;
    }
    ready_ = true;
}

static void publishTopic()
{
	/*
	 * Publish topic(obj position ranged).
	 */
	cv_tracker::image_obj_ranged fused_objects_msg;
	fused_objects_msg.header = sensor_header;

	fused_objects_msg.type = getObjectsType();
	fused_objects_msg.obj = getObjectsRectRanged();
	fused_objects.publish(fused_objects_msg);
}

static void config_cb(const runtime_manager::ConfigCarFusion::ConstPtr&amp; param)
{
	setParams(param-&gt;min_low_height,
			param-&gt;max_low_height,
			param-&gt;max_height,
			param-&gt;min_points,
			param-&gt;dispersion);
}

int main(int argc, char **argv)
{
	init();
	ros::init(argc, argv, &quot;range_fusion&quot;);

	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	std::string image_topic;
	std::string points_topic;
	if (private_nh.getParam(&quot;image_node&quot;, image_topic))
	{
		ROS_INFO(&quot;Setting image node to %s&quot;, image_topic.c_str());
	}
	else
	{
		ROS_INFO(&quot;No image node received, defaulting to image_obj, you can use _image_node:=YOUR_TOPIC&quot;);
		image_topic = &quot;image_obj&quot;;
	}
	if (private_nh.getParam(&quot;points_node&quot;, points_topic))
	{
		ROS_INFO(&quot;Setting points node to %s&quot;, points_topic.c_str());
	}
	else
	{
		ROS_INFO(&quot;No points node received, defaulting to vscan_image, you can use _points_node:=YOUR_TOPIC&quot;);
		points_topic = &quot;/vscan_image&quot;;
	}

//	ros::Subscriber image_obj_sub = n.subscribe(&quot;/obj_car/image_obj&quot;, 1, DetectedObjectsCallback);
	ros::Subscriber image_obj_sub = n.subscribe(image_topic, 1, DetectedObjectsCallback);
	//ros::Subscriber scan_image_sub = n.subscribe(&quot;scan_image&quot;, 1, ScanImageCallback);
	ros::Subscriber points_image_sub =n.subscribe(points_topic, 1, PointsImageCallback);
#if _DEBUG
	ros::Subscriber image_sub = n.subscribe(IMAGE_TOPIC, 1, IMAGE_CALLBACK);
#endif
	fused_objects = n.advertise&lt;cv_tracker::image_obj_ranged&gt;(&quot;image_obj_ranged&quot;, 1);

	ros::Subscriber config_subscriber;
	std::string config_topic(&quot;/config&quot;);
	config_topic += ros::this_node::getNamespace() + &quot;/fusion&quot;;
	config_subscriber = n.subscribe(config_topic, 1, config_cb);

	ros::spin();
	destroy();

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/rcnn/rcnn_node.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/rcnn/rcnn_node.cpp">
				<diff>@@ -33,7 +33,7 @@
 #include &lt;runtime_manager/ConfigRcnn.h&gt;
 #include &lt;sensor_msgs/Image.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;cv_tracker/image_obj.h&gt;
+#include &lt;cv_tracker_msgs/image_obj.h&gt;
 
 #include &lt;rcnn_detector.h&gt;
 #include &lt;rect_class_score.h&gt;
@@ -73,7 +73,7 @@ class RosRcnnApp
 	//vector of indices of the classes to search for
 	std::vector&lt;unsigned int&gt; detect_classes_;
 
-	void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, cv_tracker::image_obj&amp; out_message, cv::Mat&amp; in_image, std::string in_class)
+	void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, cv_tracker_msgs::image_obj&amp; out_message, cv::Mat&amp; in_image, std::string in_class)
 	{
 		for (unsigned int i = 0; i &lt; in_objects.size(); ++i)
 		{
@@ -85,7 +85,7 @@ class RosRcnnApp
 				)//check if the score is larger than minimum required
 			{
 				//std::cout &lt;&lt; in_objects[i].toString() &lt;&lt; std::endl;
-				cv_tracker::image_rect rect;
+				cv_tracker_msgs::image_rect rect;
 
 				rect.x = in_objects[i].x;
 				rect.y = in_objects[i].y;
@@ -124,8 +124,8 @@ class RosRcnnApp
 		//std::cout &lt;&lt; &quot;Detection took: &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; std::endl;
 
 		//Prepare Output message
-		cv_tracker::image_obj output_car_message;
-		cv_tracker::image_obj output_person_message;
+		cv_tracker_msgs::image_obj output_car_message;
+		cv_tracker_msgs::image_obj output_person_message;
 		output_car_message.header = image_source.header;
 		output_car_message.type = &quot;car&quot;;
 
@@ -216,8 +216,8 @@ public:
 			return;
 		}
 
-		publisher_car_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
-		publisher_person_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);
+		publisher_car_objects_ = node_handle_.advertise&lt;cv_tracker_msgs::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
+		publisher_person_objects_ = node_handle_.advertise&lt;cv_tracker_msgs::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);
 
 		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str());
 		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str, 1, &amp;RosRcnnApp::image_callback, this);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
#include &lt;string&gt;
#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;runtime_manager/ConfigRcnn.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_tracker/image_obj.h&gt;

#include &lt;rcnn_detector.h&gt;
#include &lt;rect_class_score.h&gt;

#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;

class RosRcnnApp
{
	ros::Subscriber subscriber_image_raw_;
	ros::Subscriber subscriber_rcnn_config_;
	ros::Publisher publisher_car_objects_;
	ros::Publisher publisher_person_objects_;
	ros::NodeHandle node_handle_;

	//Caffe based Object Detection ConvNet
	RcnnDetector* rcnn_detector_;

	//The minimum score required to filter the detected objects by the ConvNet
	float score_threshold_;

	//The percentage area to group bounding boxes obtained by the ConvNet
	float group_threshold_;

	//Number of slices to use for the creation of proposals for the ConvNet
	float image_slices_;

	//percentage of overlapping between the slices
	float slices_overlap_;

	//If GPU is enabled, stores the GPU Device to use
	unsigned int gpu_device_id_;

	//Sets whether or not use GPU acceleration
	bool use_gpu_;

	//vector of indices of the classes to search for
	std::vector&lt;unsigned int&gt; detect_classes_;

	void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, cv_tracker::image_obj&amp; out_message, cv::Mat&amp; in_image, std::string in_class)
	{
		for (unsigned int i = 0; i &lt; in_objects.size(); ++i)
		{
			if ( (in_objects[i].score &gt; score_threshold_)
				&amp;&amp; (	(in_class == &quot;car&quot; &amp;&amp; (in_objects[i].class_type == Rcnn::CAR || in_objects[i].class_type == Rcnn::BUS))
						|| (in_class == &quot;person&quot; &amp;&amp; (in_objects[i].class_type == Rcnn::PERSON || in_objects[i].class_type == Rcnn::BICYCLE))
					)

				)//check if the score is larger than minimum required
			{
				//std::cout &lt;&lt; in_objects[i].toString() &lt;&lt; std::endl;
				cv_tracker::image_rect rect;

				rect.x = in_objects[i].x;
				rect.y = in_objects[i].y;
				rect.width = in_objects[i].w;
				rect.height = in_objects[i].h;
				if (in_objects[i].x &lt; 0)
					rect.x = 0;
				if (in_objects[i].y &lt; 0)
					rect.y = 0;
				if (in_objects[i].w &lt; 0)
					rect.width = 0;
				if (in_objects[i].h &lt; 0)
					rect.height = 0;

				rect.score = in_objects[i].score;

				out_message.obj.push_back(rect);

			}
		}
	}

	void image_callback(const sensor_msgs::Image&amp; image_source)
	{
		//Receive Image, convert it to OpenCV Mat
		cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, &quot;bgr8&quot;);//toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
		cv::Mat image = cv_image-&gt;image;

		//Detect Object in image
		std::vector&lt; RectClassScore&lt;float&gt; &gt; detections;
		//cv::TickMeter timer; timer.start();
		//std::cout &lt;&lt; &quot;score:&quot; &lt;&lt; score_threshold_ &lt;&lt; &quot; slices:&quot; &lt;&lt; image_slices_ &lt;&lt; &quot; slices overlap:&quot; &lt;&lt; slices_overlap_ &lt;&lt; &quot;nms&quot; &lt;&lt; group_threshold_ &lt;&lt; std::endl;
		detections = rcnn_detector_-&gt;Detect(image, detect_classes_, score_threshold_, image_slices_, slices_overlap_, group_threshold_);

		//timer.stop();
		//std::cout &lt;&lt; &quot;Detection took: &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; std::endl;

		//Prepare Output message
		cv_tracker::image_obj output_car_message;
		cv_tracker::image_obj output_person_message;
		output_car_message.header = image_source.header;
		output_car_message.type = &quot;car&quot;;

		output_person_message.header = image_source.header;
		output_person_message.type = &quot;person&quot;;

		//Convert Objects to Message type
		//timer.reset(); timer.start();
		convert_rect_to_image_obj(detections, output_car_message, image, &quot;car&quot;);
		convert_rect_to_image_obj(detections, output_person_message, image, &quot;person&quot;);

		publisher_car_objects_.publish(output_car_message);
		publisher_person_objects_.publish(output_person_message);
	}

	void config_cb(const runtime_manager::ConfigRcnn::ConstPtr&amp; param)
	{
		rcnn_detector_-&gt;SetPixelMean(cv::Scalar(param-&gt;b_mean, param-&gt;g_mean, param-&gt;r_mean));

		score_threshold_ 	= param-&gt;score_threshold;
		group_threshold_ 	= param-&gt;group_threshold;
		image_slices_		= param-&gt;image_slices;
		slices_overlap_		= param-&gt;slices_overlap;

		/*use_gpu_			= param-&gt;use_gpu;
		gpu_device_id_		= param-&gt;gpu_device_id;*/
	}
public:
	void Run()
	{
		//ROS STUFF
		ros::NodeHandle private_node_handle(&quot;~&quot;);//to receive args

		//RECEIVE IMAGE TOPIC NAME
		std::string image_raw_topic_str;
		if (private_node_handle.getParam(&quot;image_raw_node&quot;, image_raw_topic_str))
		{
			ROS_INFO(&quot;Setting image node to %s&quot;, image_raw_topic_str.c_str());
		}
		else
		{
			ROS_INFO(&quot;No image node received, defaulting to /image_raw, you can use _image_raw_node:=YOUR_TOPIC&quot;);
			image_raw_topic_str = &quot;/image_raw&quot;;
		}

		//RECEIVE CONVNET FILENAMES
		std::string network_definition_file;
		std::string pretrained_model_file;
		if (private_node_handle.getParam(&quot;network_definition_file&quot;, network_definition_file))
		{
			ROS_INFO(&quot;Network Definition File: %s&quot;, network_definition_file.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Network Definition File was received. Finishing execution.&quot;);
			return;
		}
		if (private_node_handle.getParam(&quot;pretrained_model_file&quot;, pretrained_model_file))
		{
			ROS_INFO(&quot;Pretrained Model File: %s&quot;, pretrained_model_file.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Pretrained Model File was received. Finishing execution.&quot;);
			return;
		}

		if (private_node_handle.getParam(&quot;use_gpu&quot;, use_gpu_))
		{
			ROS_INFO(&quot;GPU Mode: %d&quot;, use_gpu_);
		}
		int gpu_id;
		if (private_node_handle.getParam(&quot;gpu_device_id&quot;, gpu_id ))
		{
			ROS_INFO(&quot;GPU Device ID: %d&quot;, gpu_id);
			gpu_device_id_ = (unsigned int) gpu_id;
		}

		detect_classes_.push_back(Rcnn::CAR);
		detect_classes_.push_back(Rcnn::PERSON);
		detect_classes_.push_back(Rcnn::BUS);
		//RCNN STUFF
		rcnn_detector_ = new RcnnDetector(network_definition_file, pretrained_model_file, use_gpu_, gpu_device_id_);

		if (NULL == rcnn_detector_)
		{
			ROS_INFO(&quot;Error while creating RCNN Object&quot;);
			return;
		}

		publisher_car_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
		publisher_person_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);

		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str());
		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str, 1, &amp;RosRcnnApp::image_callback, this);

		std::string config_topic(&quot;/config&quot;);	config_topic += ros::this_node::getNamespace() + &quot;/rcnn&quot;;
		subscriber_rcnn_config_ =node_handle_.subscribe(config_topic, 1, &amp;RosRcnnApp::config_cb, this);

		ros::spin();
		ROS_INFO(&quot;END rcnn&quot;);

	}

	~RosRcnnApp()
	{
		if (NULL != rcnn_detector_)
			delete rcnn_detector_;
	}

	RosRcnnApp()
	{
		rcnn_detector_ 	= NULL;
		score_threshold_= 0.6;
		group_threshold_= 0.8;
		image_slices_ 	= 16;
		use_gpu_ 		= false;
		gpu_device_id_ 	= 0;
		slices_overlap_ = 0.7;
	}
};

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;rcnn_msr&quot;);

	RosRcnnApp app;

	app.Run();

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/draw_rects.cpp" new_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/draw_rects.cpp">
				<diff>@@ -18,7 +18,7 @@ namespace integrated_viewer
   } // DrawRects::DrawRects()
 
 
-  void DrawRects::DrawImageObj(const cv_tracker::image_obj::ConstPtr&amp; rect_data,
+  void DrawRects::DrawImageObj(const cv_tracker_msgs::image_obj::ConstPtr&amp; rect_data,
                                cv::Mat &amp;image) {
     if (rect_data == NULL) {
       return;
@@ -52,7 +52,7 @@ namespace integrated_viewer
   } // DrawRects::DrawImageObj()
 
 
-  void DrawRects::DrawImageObjRanged(const cv_tracker::image_obj_ranged::ConstPtr&amp; rect_data,
+  void DrawRects::DrawImageObjRanged(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; rect_data,
                                      cv::Mat &amp;image) {
     if (rect_data == NULL) {
       return;
@@ -86,7 +86,7 @@ namespace integrated_viewer
   } // DrawRects::DrawImageObjRanged()
 
 
-  void DrawRects::DrawImageObjTracked(const cv_tracker::image_obj_tracked::ConstPtr&amp; rect_data,
+  void DrawRects::DrawImageObjTracked(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; rect_data,
                                       cv::Mat &amp;image) {
     if (rect_data == NULL) {
       return;
</diff>
				<old_file>#include &quot;draw_rects.h&quot;
#include &lt;string&gt;
#include &lt;vector&gt;
//#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &quot;gencolors.cpp&quot;


namespace integrated_viewer
{
  const int        DrawRects::kRectangleThickness = 3;
  const cv::Scalar DrawRects::kBlue               = CV_RGB(0, 0, 255);
  const cv::Scalar DrawRects::kGreen              = CV_RGB(0, 255, 0);
  
  DrawRects::DrawRects(void) {
    // Generate color map to represent tracked object
    generateColors(color_map_, 25);

  } // DrawRects::DrawRects()


  void DrawRects::DrawImageObj(const cv_tracker::image_obj::ConstPtr&amp; rect_data,
                               cv::Mat &amp;image) {
    if (rect_data == NULL) {
      return;
    }

    cv::Scalar rectangle_color;
    if (rect_data-&gt;type == &quot;car&quot;) {
      rectangle_color = kBlue;
    } else {
      rectangle_color = kGreen;
    }
    
    // Draw rectangles for each objects
    for (const auto&amp; rectangle : rect_data-&gt;obj) {
      // Make label shown on a rectangle
      std::ostringstream label;
      label &lt;&lt; rect_data-&gt;type &lt;&lt; &quot;:&quot; &lt;&lt; std::setprecision(2) &lt;&lt; rectangle.score;

      // Draw object information label
      DrawLabel(label.str(), cv::Point(rectangle.x, rectangle.y), image);

      // Draw rectangle
      cv::rectangle(image,
                    cv::Point(rectangle.x, rectangle.y),
                    cv::Point(rectangle.x + rectangle.width, rectangle.y + rectangle.height),
                    rectangle_color,
                    kRectangleThickness,
                    CV_AA,
                    0);
    }
  } // DrawRects::DrawImageObj()


  void DrawRects::DrawImageObjRanged(const cv_tracker::image_obj_ranged::ConstPtr&amp; rect_data,
                                     cv::Mat &amp;image) {
    if (rect_data == NULL) {
      return;
    }

    cv::Scalar rectangle_color;
    if (rect_data-&gt;type == &quot;car&quot;) {
      rectangle_color = kBlue;
    } else {
      rectangle_color = kGreen;
    }
    
    // Draw rectangles for each objects
    for (const auto&amp; ojbect : rect_data-&gt;obj) {
      // Make label shown on a rectangle
      std::ostringstream label;
      label &lt;&lt; rect_data-&gt;type &lt;&lt; &quot; : &quot; &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; ojbect.range / 100 &lt;&lt; &quot; m&quot;;

      // Draw object information label
      DrawLabel(label.str(), cv::Point(ojbect.rect.x, ojbect.rect.y), image);

      // Draw rectangle
      cv::rectangle(image,
                    cv::Point(ojbect.rect.x, ojbect.rect.y),
                    cv::Point(ojbect.rect.x + ojbect.rect.width, ojbect.rect.y + ojbect.rect.height),
                    rectangle_color,
                    kRectangleThickness,
                    CV_AA,
                    0);
    }
  } // DrawRects::DrawImageObjRanged()


  void DrawRects::DrawImageObjTracked(const cv_tracker::image_obj_tracked::ConstPtr&amp; rect_data,
                                      cv::Mat &amp;image) {
    if (rect_data == NULL) {
      return;
    }

    for (const auto&amp; object : rect_data-&gt;rect_ranged) {
      int index = &amp;object - &amp;(rect_data-&gt;rect_ranged[0]);
      int object_id = rect_data-&gt;obj_id[index];

      // Make label shown on a rectangle
      std::ostringstream label;
      label &lt;&lt; rect_data-&gt;type &lt;&lt; &quot;_&quot; &lt;&lt; object_id &lt;&lt; &quot; : &quot; &lt;&lt; std::setprecision(2) &lt;&lt; rect_data-&gt;lifespan[index];

      // Draw object information label
      DrawLabel(label.str(), cv::Point(object.rect.x, object.rect.y), image);
      
      // Draw rectangle
      cv::rectangle(image,
                    cv::Point(object.rect.x, object.rect.y),
                    cv::Point(object.rect.x + object.rect.width, object.rect.y + object.rect.height),
                    color_map_[object_id],
                    kRectangleThickness,
                    CV_AA,
                    0);
    }
  } // DrawRects::DrawImageObjTracked()


  void DrawRects::DrawLabel(const std::string&amp; label,
                            const cv::Point&amp; rectangle_origin,
                            cv::Mat &amp;image) {
    // label's property
    const int    font_face      = cv::FONT_HERSHEY_COMPLEX;
    const double font_scale     = 0.5;
    const int    font_thickness = 1;
    int          font_baseline  = 0;

    cv::Size label_size = cv::getTextSize(label,
                                          font_face,
                                          font_scale,
                                          font_thickness,
                                          &amp;font_baseline);

    cv::Point label_origin = cv::Point(rectangle_origin.x - kRectangleThickness,
                                       rectangle_origin.y - font_baseline - kRectangleThickness);

    // Fill label's background by black
    cv::rectangle(image,
                  cv::Point(label_origin.x, label_origin.y + font_baseline),
                  cv::Point(label_origin.x + label_size.width, label_origin.y - label_size.height),
                  CV_RGB(0, 0, 0),
                  CV_FILLED);

    // Draw label text by white
    cv::putText(image,
                label,
                label_origin,
                font_face,
                font_scale,
                CV_RGB(255, 255, 255));
        
  } // DrawRects::DrawLabel()
} // end namespace integrated_viewer
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/draw_rects.h" new_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/draw_rects.h">
				<diff>@@ -2,18 +2,18 @@
 #define DRAW_RECTS_H
 
 #include &lt;opencv/cv.h&gt;
-#include &lt;cv_tracker/image_obj.h&gt;
-#include &lt;cv_tracker/image_obj_ranged.h&gt;
-#include &lt;cv_tracker/image_obj_tracked.h&gt;
+#include &lt;cv_tracker_msgs/image_obj.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
 
 namespace integrated_viewer {
   // helper class to draw detection result rectangle
   class DrawRects{
   public:
     explicit DrawRects(void);
-    void DrawImageObj(const cv_tracker::image_obj::ConstPtr&amp; rect_data, cv::Mat&amp; image);
-    void DrawImageObjRanged(const cv_tracker::image_obj_ranged::ConstPtr&amp; rect_data, cv::Mat&amp; image);
-    void DrawImageObjTracked(const cv_tracker::image_obj_tracked::ConstPtr&amp; rect_data, cv::Mat&amp; image);
+    void DrawImageObj(const cv_tracker_msgs::image_obj::ConstPtr&amp; rect_data, cv::Mat&amp; image);
+    void DrawImageObjRanged(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; rect_data, cv::Mat&amp; image);
+    void DrawImageObjTracked(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; rect_data, cv::Mat&amp; image);
 
   protected:
     static const int kRectangleThickness;
</diff>
				<old_file>#ifndef DRAW_RECTS_H
#define DRAW_RECTS_H

#include &lt;opencv/cv.h&gt;
#include &lt;cv_tracker/image_obj.h&gt;
#include &lt;cv_tracker/image_obj_ranged.h&gt;
#include &lt;cv_tracker/image_obj_tracked.h&gt;

namespace integrated_viewer {
  // helper class to draw detection result rectangle
  class DrawRects{
  public:
    explicit DrawRects(void);
    void DrawImageObj(const cv_tracker::image_obj::ConstPtr&amp; rect_data, cv::Mat&amp; image);
    void DrawImageObjRanged(const cv_tracker::image_obj_ranged::ConstPtr&amp; rect_data, cv::Mat&amp; image);
    void DrawImageObjTracked(const cv_tracker::image_obj_tracked::ConstPtr&amp; rect_data, cv::Mat&amp; image);

  protected:
    static const int kRectangleThickness;
  
  private:
    void DrawLabel(const std::string&amp; label, const cv::Point&amp; rectangle_origin, cv::Mat&amp; image);
    std::vector&lt;cv::Scalar&gt; color_map_;
    static const cv::Scalar kBlue;
    static const cv::Scalar kGreen;
  };
}
#endif // DRAW_RECTS_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/image_viewer_plugin.cpp" new_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/image_viewer_plugin.cpp">
				<diff>@@ -15,11 +15,11 @@
 namespace integrated_viewer
 {
   const QString     ImageViewerPlugin::kImageDataType               = &quot;sensor_msgs/Image&quot;;
-  const QString     ImageViewerPlugin::kRectDataTypeBase            = &quot;cv_tracker/image_obj&quot;;
+  const QString     ImageViewerPlugin::kRectDataTypeBase            = &quot;cv_tracker_msgs/image_obj&quot;;
   const QString     ImageViewerPlugin::kPointDataType               = &quot;points2image/PointsImage&quot;;
   const QString     ImageViewerPlugin::kBlankTopic                  = &quot;-----&quot;;
-  const std::string ImageViewerPlugin::kRectDataTypeImageObjRanged  = &quot;cv_tracker/image_obj_ranged&quot;;
-  const std::string ImageViewerPlugin::kRectDataTypeImageObjTracked = &quot;cv_tracker/image_obj_tracked&quot;;
+  const std::string ImageViewerPlugin::kRectDataTypeImageObjRanged  = &quot;cv_tracker_msgs/image_obj_ranged&quot;;
+  const std::string ImageViewerPlugin::kRectDataTypeImageObjTracked = &quot;cv_tracker_msgs/image_obj_tracked&quot;;
 
   ImageViewerPlugin::ImageViewerPlugin(QWidget* parent)
     : rviz::Panel(parent) {
@@ -200,7 +200,7 @@ namespace integrated_viewer
       image_obj_ranged_msg_  = NULL;
       image_obj_tracked_msg_ = NULL;
       // this topic type is image_obj_ranged
-      rect_sub_ = node_handle_.subscribe&lt;cv_tracker::image_obj_ranged&gt;(selected_topic,
+      rect_sub_ = node_handle_.subscribe&lt;cv_tracker_msgs::image_obj_ranged&gt;(selected_topic,
                                                                        1,
                                                                        &amp;ImageViewerPlugin::ImageObjRangedCallback,
                                                                        this);
@@ -210,7 +210,7 @@ namespace integrated_viewer
       image_obj_ranged_msg_  = NULL;
       image_obj_tracked_msg_ = NULL;
       // this topic type is image_obj_tracked
-      rect_sub_ = node_handle_.subscribe&lt;cv_tracker::image_obj_tracked&gt;(selected_topic,
+      rect_sub_ = node_handle_.subscribe&lt;cv_tracker_msgs::image_obj_tracked&gt;(selected_topic,
                                                                        1,
                                                                        &amp;ImageViewerPlugin::ImageObjTrackedCallback,
                                                                        this);
@@ -219,7 +219,7 @@ namespace integrated_viewer
       image_obj_ranged_msg_  = NULL;
       image_obj_tracked_msg_ = NULL;
       // this topic type is image_obj
-      rect_sub_ = node_handle_.subscribe&lt;cv_tracker::image_obj&gt;(selected_topic,
+      rect_sub_ = node_handle_.subscribe&lt;cv_tracker_msgs::image_obj&gt;(selected_topic,
                                                                 1,
                                                                 &amp;ImageViewerPlugin::ImageObjCallback,
                                                                 this);
@@ -229,15 +229,15 @@ namespace integrated_viewer
   } // ImageViewerPlugin::on_rect_topic_combo_box__activated()
   
 
-  void ImageViewerPlugin::ImageObjCallback(const cv_tracker::image_obj::ConstPtr&amp; msg) {
+  void ImageViewerPlugin::ImageObjCallback(const cv_tracker_msgs::image_obj::ConstPtr&amp; msg) {
     image_obj_msg_ = msg;
   } // ImageViewerPlugin::ImageObjCallback()
 
-  void ImageViewerPlugin::ImageObjRangedCallback(const cv_tracker::image_obj_ranged::ConstPtr &amp;msg) {
+  void ImageViewerPlugin::ImageObjRangedCallback(const cv_tracker_msgs::image_obj_ranged::ConstPtr &amp;msg) {
     image_obj_ranged_msg_ = msg;
   } // ImageViewerPlugin::ImageObjRangedCallback()
 
-  void ImageViewerPlugin::ImageObjTrackedCallback(const cv_tracker::image_obj_tracked::ConstPtr &amp;msg) {
+  void ImageViewerPlugin::ImageObjTrackedCallback(const cv_tracker_msgs::image_obj_tracked::ConstPtr &amp;msg) {
     image_obj_tracked_msg_ = msg;
   } // ImageViewerPlugin::ImageObjTrackedCallback()
 
</diff>
				<old_file>#include &lt;ros/ros.h&gt;
#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/imgcodecs/imgcodecs.hpp&gt;
#include &lt;QString&gt;
#include &lt;QImage&gt;

#include &quot;image_viewer_plugin.h&quot;
#include &quot;draw_rects.h&quot;
#include &quot;draw_points.h&quot;

#define XSTR(x) #x
#define STR(x) XSTR(x)

namespace integrated_viewer
{
  const QString     ImageViewerPlugin::kImageDataType               = &quot;sensor_msgs/Image&quot;;
  const QString     ImageViewerPlugin::kRectDataTypeBase            = &quot;cv_tracker/image_obj&quot;;
  const QString     ImageViewerPlugin::kPointDataType               = &quot;points2image/PointsImage&quot;;
  const QString     ImageViewerPlugin::kBlankTopic                  = &quot;-----&quot;;
  const std::string ImageViewerPlugin::kRectDataTypeImageObjRanged  = &quot;cv_tracker/image_obj_ranged&quot;;
  const std::string ImageViewerPlugin::kRectDataTypeImageObjTracked = &quot;cv_tracker/image_obj_tracked&quot;;

  ImageViewerPlugin::ImageViewerPlugin(QWidget* parent)
    : rviz::Panel(parent) {

    // Initialize Form
    ui_.setupUi(this);

    // Load default image
    default_image_ = cv::imread(STR(IMAGE_VIEWER_DEFAULT_IMAGE));

    points_msg_ = NULL;
    image_obj_msg_ = NULL;
    image_obj_ranged_msg_ = NULL;
    image_obj_tracked_msg_ = NULL;

    UpdateTopicList();

    viewed_image_ = default_image_.clone();
    default_image_shown_ = true;
    ShowImageOnUi();

    // If combobox is clicked, topic list will be update
    ui_.image_topic_combo_box_-&gt;installEventFilter(this);
    ui_.rect_topic_combo_box_-&gt;installEventFilter(this);
    ui_.point_topic_combo_box_-&gt;installEventFilter(this);

  } // ImageViewerPlugin::ImageViewerPlugin()


  void ImageViewerPlugin::UpdateTopicList(void) {
    // The topic list that can be selected from the UI
    QStringList image_topic_list;
    QStringList rect_topic_list;
    QStringList point_topic_list;

    // The topic name currently chosen
    QString image_topic_current = ui_.image_topic_combo_box_-&gt;currentText();
    QString rect_topic_current = ui_.rect_topic_combo_box_-&gt;currentText();
    QString point_topic_current = ui_.point_topic_combo_box_-&gt;currentText();

    if (image_topic_current == &quot;&quot;) {
      image_topic_current = kBlankTopic;
    }

    if (rect_topic_current == &quot;&quot;) {
      rect_topic_current = kBlankTopic;
    }

    if (point_topic_current == &quot;&quot;) {
      point_topic_current = kBlankTopic;
    }

    // reset topic information list for detection result
    rect_topic_info_.clear();

    // Insert blank topic name to the top of the lists
    image_topic_list &lt;&lt; kBlankTopic;
    rect_topic_list  &lt;&lt; kBlankTopic;
    point_topic_list &lt;&lt; kBlankTopic;

    // Get all available topic 
    ros::master::V_TopicInfo master_topics;
    ros::master::getTopics(master_topics);

    // Analyse topics
    for (ros::master::V_TopicInfo::iterator it = master_topics.begin(); it != master_topics.end(); it++) {
      const ros::master::TopicInfo&amp; info = *it;
      const QString topic_name = QString::fromStdString(info.name);
      const QString topic_type = QString::fromStdString(info.datatype);
      
      // Check whether this topic is image
      if (topic_type.contains(kImageDataType) == true) {
        image_topic_list &lt;&lt; topic_name;
        continue;
      }

      // Check whether this topic is rectangle
      if (topic_type.contains(kRectDataTypeBase) == true) { 
        // This condition will also be true for &quot;image_obj_ranged&quot;and &quot;image_obj_tracked&quot;
        rect_topic_list &lt;&lt; topic_name;
        // Insert topic name and data type to a list
        rect_topic_info_[info.name] = info.datatype;
        continue;
      }

      // Check whether this topic is point cloud
      if (topic_type.contains(kPointDataType) == true) {
        point_topic_list &lt;&lt; topic_name;
        continue;
      }
    }

    // remove all list items from combo box
    ui_.image_topic_combo_box_-&gt;clear();
    ui_.rect_topic_combo_box_-&gt;clear();
    ui_.point_topic_combo_box_-&gt;clear();

    // set new items to combo box
    ui_.image_topic_combo_box_-&gt;addItems(image_topic_list);
    ui_.rect_topic_combo_box_-&gt;addItems(rect_topic_list);
    ui_.point_topic_combo_box_-&gt;addItems(point_topic_list);
   
    ui_.image_topic_combo_box_-&gt;insertSeparator(1);
    ui_.rect_topic_combo_box_-&gt;insertSeparator(1);
    ui_.point_topic_combo_box_-&gt;insertSeparator(1);

    // set last topic as current
    int image_topic_index = ui_.image_topic_combo_box_-&gt;findText(image_topic_current);
    int rect_topic_index = ui_.rect_topic_combo_box_-&gt;findText(rect_topic_current);
    int point_topic_index = ui_.point_topic_combo_box_-&gt;findText(point_topic_current);

    if (image_topic_index != -1) {
      ui_.image_topic_combo_box_-&gt;setCurrentIndex(image_topic_index);
    }

    if (rect_topic_index != -1) {
      ui_.rect_topic_combo_box_-&gt;setCurrentIndex(rect_topic_index);
    }

    if (point_topic_index != -1) {
      ui_.point_topic_combo_box_-&gt;setCurrentIndex(point_topic_index);
    }

  } // ImageViewerPlugin::UpdateTopicList()





  // The behavior of combo box for image
  void ImageViewerPlugin::on_image_topic_combo_box__activated(int index) {
    // Extract selected topic name from combo box
    std::string selected_topic = ui_.image_topic_combo_box_-&gt;itemText(index).toStdString();
    if (selected_topic == kBlankTopic.toStdString() || selected_topic == &quot;&quot;) {
      image_sub_.shutdown();
      // If blank name is selected as image topic, show default image
      viewed_image_ = default_image_.clone();
      default_image_shown_ = true;
      ShowImageOnUi();
      return;
    }
    
    // if selected topic is not blank or empty, start callback function
    default_image_shown_ = false;
    image_sub_ = node_handle_.subscribe&lt;sensor_msgs::Image&gt;(selected_topic,
                                                            1,
                                                            &amp;ImageViewerPlugin::ImageCallback,
                                                            this);

  } // ImageViewerPlugin::on_image_topic_combo_box__activated()


  void ImageViewerPlugin::ImageCallback(const sensor_msgs::Image::ConstPtr&amp; msg) {
    // Get image from topic
    const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
    viewed_image_ = cv_bridge::toCvCopy(msg, encoding)-&gt;image;

    ShowImageOnUi();
  } // ImageViewerPlugin::ImageCallback()


  // The behavior of combo box for detection result rectangle
  void ImageViewerPlugin::on_rect_topic_combo_box__activated(int index) {
    // Extract selected topic name from combo box
    std::string selected_topic = ui_.rect_topic_combo_box_-&gt;itemText(index).toStdString();
    if (selected_topic == kBlankTopic.toStdString() || selected_topic == &quot;&quot;) {
      rect_sub_.shutdown();
      image_obj_msg_         = NULL;
      image_obj_ranged_msg_  = NULL;
      image_obj_tracked_msg_ = NULL;
      return;
    }

    // Switch booted callback function by topic name 
    std::string topic_type = rect_topic_info_[selected_topic];
    if (topic_type.find(kRectDataTypeImageObjRanged) != std::string::npos) {
      image_obj_msg_         = NULL;
      image_obj_ranged_msg_  = NULL;
      image_obj_tracked_msg_ = NULL;
      // this topic type is image_obj_ranged
      rect_sub_ = node_handle_.subscribe&lt;cv_tracker::image_obj_ranged&gt;(selected_topic,
                                                                       1,
                                                                       &amp;ImageViewerPlugin::ImageObjRangedCallback,
                                                                       this);

    } else if (topic_type.find(kRectDataTypeImageObjTracked) != std::string::npos) {
      image_obj_msg_         = NULL;
      image_obj_ranged_msg_  = NULL;
      image_obj_tracked_msg_ = NULL;
      // this topic type is image_obj_tracked
      rect_sub_ = node_handle_.subscribe&lt;cv_tracker::image_obj_tracked&gt;(selected_topic,
                                                                       1,
                                                                       &amp;ImageViewerPlugin::ImageObjTrackedCallback,
                                                                       this);
    } else {
      image_obj_msg_         = NULL;
      image_obj_ranged_msg_  = NULL;
      image_obj_tracked_msg_ = NULL;
      // this topic type is image_obj
      rect_sub_ = node_handle_.subscribe&lt;cv_tracker::image_obj&gt;(selected_topic,
                                                                1,
                                                                &amp;ImageViewerPlugin::ImageObjCallback,
                                                                this);
    }


  } // ImageViewerPlugin::on_rect_topic_combo_box__activated()
  

  void ImageViewerPlugin::ImageObjCallback(const cv_tracker::image_obj::ConstPtr&amp; msg) {
    image_obj_msg_ = msg;
  } // ImageViewerPlugin::ImageObjCallback()

  void ImageViewerPlugin::ImageObjRangedCallback(const cv_tracker::image_obj_ranged::ConstPtr &amp;msg) {
    image_obj_ranged_msg_ = msg;
  } // ImageViewerPlugin::ImageObjRangedCallback()

  void ImageViewerPlugin::ImageObjTrackedCallback(const cv_tracker::image_obj_tracked::ConstPtr &amp;msg) {
    image_obj_tracked_msg_ = msg;
  } // ImageViewerPlugin::ImageObjTrackedCallback()


  // The behavior of combo box for points image
  void ImageViewerPlugin::on_point_topic_combo_box__activated(int index) {
    // Extract selected topic name from combo box
    std::string selected_topic = ui_.point_topic_combo_box_-&gt;itemText(index).toStdString();
    if (selected_topic == kBlankTopic.toStdString() || selected_topic == &quot;&quot;) {
      point_sub_.shutdown();
      points_msg_ = NULL;
      return;
    }

    // if selected topic is not blank or empty , start callback function
    point_sub_ = node_handle_.subscribe&lt;points2image::PointsImage&gt;(selected_topic,
                                                                   1,
                                                                   &amp;ImageViewerPlugin::PointCallback,
                                                                   this);

  } // ImageViewerPlugin::on_point_topic_combo_box__activated()


  void ImageViewerPlugin::PointCallback(const points2image::PointsImage::ConstPtr &amp;msg) {
    points_msg_ = msg;
  } // ImageViewerPlugin::PointCallback()


  void ImageViewerPlugin::ShowImageOnUi(void) {
    // Additional things will be drawn if shown image is not default one
    if (!default_image_shown_) {
      // Draw detection result rectangles on the image
      rects_drawer_.DrawImageObj(image_obj_msg_, viewed_image_);
      rects_drawer_.DrawImageObjRanged(image_obj_ranged_msg_, viewed_image_);
      rects_drawer_.DrawImageObjTracked(image_obj_tracked_msg_, viewed_image_);

      // Draw points on the image
      points_drawer_.Draw(points_msg_, viewed_image_);
    }
    // Convert cv::Mat to QPixmap to show modified image on the UI
    QPixmap view_on_ui = convert_image::CvMatToQPixmap(viewed_image_);

    // Reflect image on UI
    int height = ui_.view_-&gt;height();
    int width  = ui_.view_-&gt;width();
    ui_.view_-&gt;setPixmap(view_on_ui.scaled(width,
                                           height,
                                           Qt::KeepAspectRatio,
                                           Qt::SmoothTransformation));
  } // ImageViewerPlugin::ShowImageOnUi()


  void ImageViewerPlugin::resizeEvent(QResizeEvent *) {
    ShowImageOnUi();
  } // ImageViewerPlugin::resizeEvent()


  bool ImageViewerPlugin::eventFilter(QObject* object, QEvent* event) {
    if (event-&gt;type() == QEvent::MouseButtonPress) {
      // combo box will update its contents if this filter is applied
      UpdateTopicList();
    }

    return QObject::eventFilter(object, event);
  }


} // end namespace integrated_viewer


// Tell pluginlib about this class.  Every class which should be
// loadable by pluginlib::ClassLoader must have these two lines
// compiled in its .cpp file, outside of any namespace scope.
#include &lt;pluginlib/class_list_macros.h&gt;
PLUGINLIB_EXPORT_CLASS(integrated_viewer::ImageViewerPlugin, rviz::Panel)
// END_TUTORIAL
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/image_viewer_plugin.h" new_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/image_viewer_plugin.h">
				<diff>@@ -6,9 +6,9 @@
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
 #include &lt;rviz/panel.h&gt;
-#include &lt;cv_tracker/image_obj.h&gt;
-#include &lt;cv_tracker/image_obj_ranged.h&gt;
-#include &lt;cv_tracker/image_obj_tracked.h&gt;
+#include &lt;cv_tracker_msgs/image_obj.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
 #include &lt;points2image/PointsImage.h&gt;
 
 #include &lt;string&gt;
@@ -47,9 +47,9 @@ namespace integrated_viewer
     
     // The Callback functions
     void ImageCallback(const sensor_msgs::Image::ConstPtr&amp; msg);
-    void ImageObjCallback(const cv_tracker::image_obj::ConstPtr&amp; msg);
-    void ImageObjRangedCallback(const cv_tracker::image_obj_ranged::ConstPtr&amp; msg);
-    void ImageObjTrackedCallback(const cv_tracker::image_obj_tracked::ConstPtr&amp; msg);
+    void ImageObjCallback(const cv_tracker_msgs::image_obj::ConstPtr&amp; msg);
+    void ImageObjRangedCallback(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; msg);
+    void ImageObjTrackedCallback(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; msg);
     void PointCallback(const points2image::PointsImage::ConstPtr &amp;msg);
 
    // The function to refrect modified image on UI
@@ -85,9 +85,9 @@ namespace integrated_viewer
 
     // Data pointer to hold subscribed data
     points2image::PointsImage::ConstPtr points_msg_;
-    cv_tracker::image_obj::ConstPtr image_obj_msg_;
-    cv_tracker::image_obj_ranged::ConstPtr image_obj_ranged_msg_;
-    cv_tracker::image_obj_tracked::ConstPtr image_obj_tracked_msg_;
+    cv_tracker_msgs::image_obj::ConstPtr image_obj_msg_;
+    cv_tracker_msgs::image_obj_ranged::ConstPtr image_obj_ranged_msg_;
+    cv_tracker_msgs::image_obj_tracked::ConstPtr image_obj_tracked_msg_;
 
     // data structure to hold topic information for detection result
     std::map&lt;std::string, std::string&gt; rect_topic_info_;
</diff>
				<old_file>#ifndef IMAGE_VIEWER_PLUGIN_H
#define IMAGE_VIEWER_PLUGIN_H

#ifndef Q_MOC_RUN
#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;rviz/panel.h&gt;
#include &lt;cv_tracker/image_obj.h&gt;
#include &lt;cv_tracker/image_obj_ranged.h&gt;
#include &lt;cv_tracker/image_obj_tracked.h&gt;
#include &lt;points2image/PointsImage.h&gt;

#include &lt;string&gt;
#include &lt;map&gt;

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;

#include &lt;QStringList&gt;
#include &lt;QWidget&gt;
#include &lt;QEvent&gt;

#include &quot;convert_image.h&quot;
#include &quot;ui_image_viewer_form.h&quot;
#include &quot;draw_rects.h&quot;
#include &quot;draw_points.h&quot;
#endif

namespace integrated_viewer
{

  class ImageViewerPlugin: public rviz::Panel {
  Q_OBJECT
  public:
    explicit ImageViewerPlugin(QWidget* parent = 0);

    // override resize event
    virtual void resizeEvent(QResizeEvent *);
    
  protected:
    // The function to update topic list that can be selected from the UI
    void UpdateTopicList(void);

    // The event filter to catch clicking on combo box
    bool eventFilter(QObject* object, QEvent* event);
    
    // The Callback functions
    void ImageCallback(const sensor_msgs::Image::ConstPtr&amp; msg);
    void ImageObjCallback(const cv_tracker::image_obj::ConstPtr&amp; msg);
    void ImageObjRangedCallback(const cv_tracker::image_obj_ranged::ConstPtr&amp; msg);
    void ImageObjTrackedCallback(const cv_tracker::image_obj_tracked::ConstPtr&amp; msg);
    void PointCallback(const points2image::PointsImage::ConstPtr &amp;msg);

   // The function to refrect modified image on UI
   void ShowImageOnUi(void);

    // The data type of the topic that will be shown in each combo box
    static const QString kImageDataType;
    static const QString kRectDataTypeBase;
    static const QString kPointDataType;

    // The blank topic name
    static const QString kBlankTopic;

    // The base topic name of detection result rectangles
    static const std::string  kRectDataTypeImageObjRanged;
    static const std::string  kRectDataTypeImageObjTracked;

    // The ROS node handle.
    ros::NodeHandle node_handle_;

    // The ROS subscriber
    ros::Subscriber image_sub_;
    ros::Subscriber rect_sub_;
    ros::Subscriber point_sub_;

  private:
    // The UI components
    Ui::image_viewer_form ui_;

    // The image displayed on viewer
    cv::Mat viewed_image_;
    cv::Mat default_image_;

    // Data pointer to hold subscribed data
    points2image::PointsImage::ConstPtr points_msg_;
    cv_tracker::image_obj::ConstPtr image_obj_msg_;
    cv_tracker::image_obj_ranged::ConstPtr image_obj_ranged_msg_;
    cv_tracker::image_obj_tracked::ConstPtr image_obj_tracked_msg_;

    // data structure to hold topic information for detection result
    std::map&lt;std::string, std::string&gt; rect_topic_info_;

    // The helper-class constructor for drawing
    DrawRects rects_drawer_;
    DrawPoints points_drawer_;

    // The flag to represent whether default image should be shown or not
    bool default_image_shown_;

    // The behavior definition of the UI
    private Q_SLOTS:
      // We can skip &quot;connect&quot; process by defining naming
      // of slot function like on_&quot;widget_name&quot;_&quot;signal_name&quot;
      void on_image_topic_combo_box__activated(int index);
      void on_rect_topic_combo_box__activated(int index);
      void on_point_topic_combo_box__activated(int index);

  }; // end class ImageViewerPlugin

} // end namespace integrated_viewer

#endif // IMAGE_VIEWER_PLUGIN_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/obj_fusion/obj_fusion.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/obj_fusion/obj_fusion.cpp">
				<diff>@@ -1,4 +1,4 @@
-#include &lt;cv_tracker/obj_label.h&gt;
+#include &lt;cv_tracker_msgs/obj_label.h&gt;
 #include &lt;float.h&gt;
 #include &lt;geometry_msgs/Point.h&gt;
 #include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
@@ -154,7 +154,7 @@ static void fusion_objects(void) {
   obj_pose_timestamp_pub.publish(time);
 }
 
-void obj_label_cb(const cv_tracker::obj_label &amp;obj_label_msg) {
+void obj_label_cb(const cv_tracker_msgs::obj_label &amp;obj_label_msg) {
   object_type = obj_label_msg.type;
   obj_pose_timestamp = obj_label_msg.header.stamp;
 
</diff>
				<old_file>#include &lt;cv_tracker/obj_label.h&gt;
#include &lt;float.h&gt;
#include &lt;geometry_msgs/Point.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;
#include &lt;lidar_tracker/CloudCluster.h&gt;
#include &lt;lidar_tracker/CloudClusterArray.h&gt;
#include &lt;math.h&gt;
#include &lt;mutex&gt;
#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/Time.h&gt;
#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_listener.h&gt;

/* flag for comfirming whether multiple topics are received */
static bool isReady_obj_label;
static bool isReady_cluster_centroids;

static constexpr uint32_t SUBSCRIBE_QUEUE_SIZE = 100;
static constexpr uint32_t ADVERTISE_QUEUE_SIZE = 10;
static constexpr bool ADVERTISE_LATCH = false;
static constexpr double LOOP_RATE = 15.0;

ros::Publisher obj_pose_pub;
ros::Publisher obj_pose_timestamp_pub;
ros::Publisher cluster_class_pub;

static std::string object_type;
static std::vector&lt;geometry_msgs::Point&gt; centroids;
static std_msgs::Header sensor_header;
static std::vector&lt;lidar_tracker::CloudCluster&gt; v_cloud_cluster;
static ros::Time obj_pose_timestamp;
static double threshold_min_dist;
static tf::StampedTransform transform;

struct obj_label_t {
  std::vector&lt;geometry_msgs::Point&gt; reprojected_positions;
  std::vector&lt;int&gt; obj_id;
};

obj_label_t obj_label;

/* mutex to handle objects from within multi thread safely */
std::mutex mtx_flag_obj_label;
std::mutex mtx_flag_cluster_centroids;
std::mutex mtx_reprojected_positions;
std::mutex mtx_centroids;
#define LOCK(mtx) (mtx).lock()
#define UNLOCK(mtx) (mtx).unlock()

static double euclid_distance(const geometry_msgs::Point pos1,
                              const geometry_msgs::Point pos2) {
  return sqrt(pow(pos1.x - pos2.x, 2) + pow(pos1.y - pos2.y, 2) +
              pow(pos1.z - pos2.z, 2));

} /* static double distance() */

/* fusion reprojected position and pointcloud centroids */
static void fusion_objects(void) {
  obj_label_t obj_label_current;
  std::vector&lt;lidar_tracker::CloudCluster&gt; v_cloud_cluster_current;
  std_msgs::Header header = sensor_header;
  std::vector&lt;geometry_msgs::Point&gt; centroids_current;

  LOCK(mtx_reprojected_positions);
  copy(obj_label.reprojected_positions.begin(),
       obj_label.reprojected_positions.end(),
       back_inserter(obj_label_current.reprojected_positions));
  copy(obj_label.obj_id.begin(), obj_label.obj_id.end(),
       back_inserter(obj_label_current.obj_id));
  UNLOCK(mtx_reprojected_positions);

  LOCK(mtx_centroids);
  copy(centroids.begin(), centroids.end(), back_inserter(centroids_current));
  copy(v_cloud_cluster.begin(), v_cloud_cluster.end(),
       back_inserter(v_cloud_cluster_current));
  UNLOCK(mtx_centroids);

  if (centroids_current.empty() ||
      obj_label_current.reprojected_positions.empty() ||
      obj_label_current.obj_id.empty()) {
    jsk_recognition_msgs::BoundingBoxArray pub_msg;
    pub_msg.header = header;
    std_msgs::Time time;
    obj_pose_pub.publish(pub_msg);
    lidar_tracker::CloudClusterArray cloud_clusters_msg;
    cloud_clusters_msg.header = header;
    cluster_class_pub.publish(cloud_clusters_msg);

    time.data = obj_pose_timestamp;
    obj_pose_timestamp_pub.publish(time);
    return;
  }

  std::vector&lt;int&gt; obj_indices;

  for (unsigned int i = 0; i &lt; obj_label_current.obj_id.size(); ++i) {
    unsigned int min_idx = 0;
    double min_distance = DBL_MAX;

    /* calculate each euclid distance between reprojected position and centroids
     */
    for (unsigned int j = 0; j &lt; centroids_current.size(); j++) {
      double distance =
          euclid_distance(obj_label_current.reprojected_positions.at(i),
                          centroids_current.at(j));

      /* Nearest centroid correspond to this reprojected object */
      if (distance &lt; min_distance) {
        min_distance = distance;
        min_idx = j;
      }
    }
    if (min_distance &lt; threshold_min_dist) {
      obj_indices.push_back(min_idx);
    } else {
      obj_indices.push_back(-1);
    }
  }

  /* Publish marker with centroids coordinates */
  jsk_recognition_msgs::BoundingBoxArray pub_msg;
  pub_msg.header = header;
  lidar_tracker::CloudClusterArray cloud_clusters_msg;
  cloud_clusters_msg.header = header;

  for (unsigned int i = 0; i &lt; obj_label_current.obj_id.size(); ++i) {
    jsk_recognition_msgs::BoundingBox bounding_box;
    if (obj_indices.at(i) == -1)
      continue;

    v_cloud_cluster_current.at(obj_indices.at(i)).label = object_type;

    if (object_type == &quot;car&quot;) {
      v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 0;
    } else if (object_type == &quot;person&quot;) {
      v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 1;
    } else {
      v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.label = 2;
      v_cloud_cluster_current.at(obj_indices.at(i)).label = &quot;unknown&quot;;
    }
    v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box.value =
        obj_label_current.obj_id.at(i);
    bounding_box = v_cloud_cluster_current.at(obj_indices.at(i)).bounding_box;
    pub_msg.boxes.push_back(bounding_box);
    cloud_clusters_msg.clusters.push_back(
        v_cloud_cluster_current.at(obj_indices.at(i)));
  }

  obj_pose_pub.publish(pub_msg);
  cluster_class_pub.publish(cloud_clusters_msg);
  std_msgs::Time time;
  time.data = obj_pose_timestamp;
  obj_pose_timestamp_pub.publish(time);
}

void obj_label_cb(const cv_tracker::obj_label &amp;obj_label_msg) {
  object_type = obj_label_msg.type;
  obj_pose_timestamp = obj_label_msg.header.stamp;

  LOCK(mtx_reprojected_positions);
  obj_label.reprojected_positions.clear();
  obj_label.obj_id.clear();
  UNLOCK(mtx_reprojected_positions);

  LOCK(mtx_reprojected_positions);
  for (unsigned int i = 0; i &lt; obj_label_msg.obj_id.size(); ++i) {
    obj_label.reprojected_positions.push_back(
        obj_label_msg.reprojected_pos.at(i));
    obj_label.obj_id.push_back(obj_label_msg.obj_id.at(i));
  }
  UNLOCK(mtx_reprojected_positions);

  /* confirm obj_label is subscribed */
  LOCK(mtx_flag_obj_label);
  isReady_obj_label = true;
  UNLOCK(mtx_flag_obj_label);

  /* Publish fusion result if both of topics are ready */
  if (isReady_obj_label &amp;&amp; isReady_cluster_centroids) {
    fusion_objects();

    LOCK(mtx_flag_obj_label);
    isReady_obj_label = false;
    UNLOCK(mtx_flag_obj_label);

    LOCK(mtx_flag_cluster_centroids);
    isReady_cluster_centroids = false;
    UNLOCK(mtx_flag_cluster_centroids);
  }

} /* void obj_label_cb() */

void cluster_centroids_cb(
    const lidar_tracker::CloudClusterArray::Ptr &amp;in_cloud_cluster_array_ptr) {
  LOCK(mtx_centroids);
  centroids.clear();
  v_cloud_cluster.clear();
  UNLOCK(mtx_centroids);

  LOCK(mtx_centroids);
  static tf::TransformListener trf_listener;
  try {
    trf_listener.lookupTransform(&quot;map&quot;, &quot;velodyne&quot;, ros::Time(0), transform);
    for (int i(0); i &lt; (int)in_cloud_cluster_array_ptr-&gt;clusters.size(); ++i) {
      lidar_tracker::CloudCluster cloud_cluster =
          in_cloud_cluster_array_ptr-&gt;clusters.at(i);
      /* convert centroids coodinate from velodyne frame to map frame */
      tf::Vector3 pt(cloud_cluster.centroid_point.point.x,
                     cloud_cluster.centroid_point.point.y,
                     cloud_cluster.centroid_point.point.z);
      tf::Vector3 converted = transform * pt;
      sensor_header = cloud_cluster.header;
      v_cloud_cluster.push_back(cloud_cluster);
      geometry_msgs::Point point_in_map;
      point_in_map.x = converted.x();
      point_in_map.y = converted.y();
      point_in_map.z = converted.z();

      centroids.push_back(point_in_map);
    }
  } catch (tf::TransformException ex) {
    ROS_INFO(&quot;%s&quot;, ex.what());
    ros::Duration(1.0).sleep();
  }
  UNLOCK(mtx_centroids);

  LOCK(mtx_flag_cluster_centroids);
  isReady_cluster_centroids = true;
  UNLOCK(mtx_flag_cluster_centroids);

  /* Publish fusion result if both of topics are ready */
  if (isReady_obj_label &amp;&amp; isReady_cluster_centroids) {
    fusion_objects();

    LOCK(mtx_flag_obj_label);
    isReady_obj_label = false;
    UNLOCK(mtx_flag_obj_label);

    LOCK(mtx_flag_cluster_centroids);
    isReady_cluster_centroids = false;
    UNLOCK(mtx_flag_cluster_centroids);
  }

} /* void cluster_centroids_cb() */

int main(int argc, char *argv[]) {
  /* ROS initialization */
  ros::init(argc, argv, &quot;obj_fusion&quot;);

  ros::NodeHandle n;
  ros::NodeHandle private_n(&quot;~&quot;);

  if (!private_n.getParam(&quot;min_dist&quot;, threshold_min_dist)) {
    threshold_min_dist = 2.0;
  }
  /* Initialize flags */
  isReady_obj_label = false;
  isReady_cluster_centroids = false;

  ros::Subscriber obj_label_sub =
      n.subscribe(&quot;obj_label&quot;, SUBSCRIBE_QUEUE_SIZE, obj_label_cb);
  ros::Subscriber cluster_centroids_sub = n.subscribe(
      &quot;/cloud_clusters&quot;, SUBSCRIBE_QUEUE_SIZE, cluster_centroids_cb);
  obj_pose_pub = n.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(
      &quot;obj_pose&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
  cluster_class_pub = n.advertise&lt;lidar_tracker::CloudClusterArray&gt;(
      &quot;/cloud_clusters_class&quot;, ADVERTISE_QUEUE_SIZE);
  obj_pose_timestamp_pub =
      n.advertise&lt;std_msgs::Time&gt;(&quot;obj_pose_timestamp&quot;, ADVERTISE_QUEUE_SIZE);
  ros::spin();

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/vscan_lidar_track/mainwindow.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/vscan_lidar_track/mainwindow.cpp">
				<diff>@@ -269,7 +269,7 @@ MainWindow::MainWindow(QWidget *parent) :
     ui-&gt;setupUi(this);
 
     scansub=new ROSSub&lt;sensor_msgs::LaserScanConstPtr&gt;(&quot;/scan&quot;,1000,10,this);
-    //detectionsub=new ROSSub&lt;cv_tracker::obj_label::ConstPtr&gt;(&quot;obj_label&quot;,1000,10,this);
+    //detectionsub=new ROSSub&lt;cv_tracker_msgs::obj_label::ConstPtr&gt;(&quot;obj_label&quot;,1000,10,this);
     boxessub=new ROSSub&lt;jsk_recognition_msgs::BoundingBoxArray::ConstPtr&gt;(&quot;bounding_boxes&quot;,1000,10,this);
     tfsub=new ROSTFSub(&quot;/world&quot;,&quot;/velodyne&quot;,10,this);
     tfMap2Lidarsub=new ROSTFSub(&quot;/velodyne&quot;,&quot;/map&quot;,10,this); // obj_pose is published into &quot;map&quot; frame
@@ -333,7 +333,7 @@ void MainWindow::slotReceive()
 
 void MainWindow::slotReceiveDetection()
 {
-    cv_tracker::obj_label::ConstPtr msg=detectionsub-&gt;getMessage();
+    cv_tracker_msgs::obj_label::ConstPtr msg=detectionsub-&gt;getMessage();
 
     for (const auto&amp; point : msg-&gt;reprojected_pos) {
         int msec=(msg-&gt;header.stamp.sec)%(24*60*60)*1000+(msg-&gt;header.stamp.nsec)/1000000;
</diff>
				<old_file>#include &quot;mainwindow.h&quot;
#include &quot;ui_mainwindow.h&quot;
#include &quot;moc_mainwindow.cpp&quot;

InitTrackerView::InitTrackerView(QWidget * parent)
    : QGraphicsView(parent)
{
    scene=new QGraphicsScene;
    scene-&gt;setSceneRect(-5000,-5000,10000,10000);
    this-&gt;setScene(scene);
    sx=sy=15;
    this-&gt;scale(sx,sy);
}

void InitTrackerView::showLaserScan(LaserScan &amp; scan)
{
    scene-&gt;clear();
    state.clear();
    double density=2*PI/scan.beamnum;
    for(int i=0;i&lt;scan.beamnum;i++)
    {
        double theta=i*density-PI;
        double x=scan.length[i]*cos(theta);
        double y=scan.length[i]*sin(theta);
        scene-&gt;addEllipse(-y-0.05,-x-0.05,0.1,0.1,QPen(Qt::blue,0.1))-&gt;setZValue(1);
    }
    for(int i=10;i&lt;=100;i+=10)
    {
        scene-&gt;addEllipse(-i/2,-i/2,i,i,QPen(Qt::gray,0.2,Qt::DotLine))-&gt;setZValue(0);
    }
    scene-&gt;addLine(0,0,0,-5,QPen(Qt::red,0.2,Qt::DotLine))-&gt;setZValue(0);
    scene-&gt;addLine(0,0,-5,0,QPen(Qt::green,0.2,Qt::DotLine))-&gt;setZValue(0);
}

void InitTrackerView::getInitState(QVector&lt;VehicleState&gt; &amp;initState)
{
    int statenum=state.size();
    initState.resize(statenum);
    for(int i=0;i&lt;statenum;i++)
    {
        initState[i].x=-state[i]-&gt;line().p1().y();
        initState[i].y=-state[i]-&gt;line().p1().x();
        initState[i].theta=atan2(state[i]-&gt;line().p1().x()-state[i]-&gt;line().p2().x(),state[i]-&gt;line().p1().y()-state[i]-&gt;line().p2().y());
        initState[i].wl=1.5;initState[i].wr=1.5;initState[i].lf=2.5;initState[i].lb=2.5;
        initState[i].a=0;initState[i].v=10;initState[i].k=0;initState[i].omega=0;
    }
}

void InitTrackerView::mousePressEvent(QMouseEvent * event)
{
    switch(event-&gt;button())
    {
    case Qt::LeftButton:
        if(pressflag)
        {
            point2=this-&gt;mapToScene(event-&gt;pos());
            lineitem=scene-&gt;addLine(point1.x(),point1.y(),point2.x(),point2.y(),QPen(Qt::red,0.2));
            lineitem-&gt;setZValue(2);
            state.push_back(lineitem);
            scene-&gt;removeItem(point1item);
            delete point1item;
            pressflag=0;
        }
        else
        {
            point1=this-&gt;mapToScene(event-&gt;pos());
            point1item=scene-&gt;addEllipse(point1.x()-0.05,point1.y()-0.05,0.1,0.1,QPen(Qt::red,0.2));
            point1item-&gt;setZValue(2);
            pressflag=1;
        }
        break;
    case Qt::RightButton:
        if(pressflag)
        {
            scene-&gt;removeItem(point1item);
            delete point1item;
            pressflag=0;
        }
        else
        {
            QGraphicsLineItem * item=(QGraphicsLineItem *)(this-&gt;itemAt(event-&gt;pos()));
            if(state.contains(item))
            {
                scene-&gt;removeItem(item);
                delete item;
            }
        }
        break;
    default:
        QGraphicsView::mousePressEvent(event);
        break;
    }
}

void InitTrackerView::wheelEvent(QWheelEvent *event)
{
    if(ctrlflag)
    {
        if(event-&gt;delta()&gt;0)
        {
            sx*=1.1;sy*=1.1;
            this-&gt;scale(1.1,1.1);
        }
        else
        {
            sx*=0.9;sy*=0.9;
            this-&gt;scale(0.9,0.9);
        }
    }
    else
    {
        QGraphicsView::wheelEvent(event);
    }
}

void InitTrackerView::keyPressEvent(QKeyEvent *event)
{
    switch(event-&gt;key())
    {
    case Qt::Key_Control:
        ctrlflag=1;
        break;
    default:
        QGraphicsView::keyPressEvent(event);
        break;
    }
}

void InitTrackerView::keyReleaseEvent(QKeyEvent *event)
{
    switch(event-&gt;key())
    {
    case Qt::Key_Control:
        ctrlflag=0;
        break;
    default:
        QGraphicsView::keyReleaseEvent(event);
        break;
    }
}

UpdateTrackerView::UpdateTrackerView(QWidget *parent)
    : QGraphicsView(parent)
{
    scene=new QGraphicsScene;
    scene-&gt;setSceneRect(-5000,-5000,10000,10000);
    this-&gt;setScene(scene);
    sx=sy=15;
    this-&gt;scale(sx,sy);
}

//function to handle final tracking result stored in trackerresultmap [vehicleID, tracking result]
void UpdateTrackerView::slotUpdateTrackerFinish(LaserScan scan, QMap&lt;int, TrackerResultContainer&gt; trackerresultmap)
{
    scene-&gt;clear();

    QTransform transform;
    transform.rotateRadians(-scan.theta);
    transform.translate(-scan.y,-scan.x);
    transform.scale(sx,sy);
    setTransform(transform);

    centerOn(0,0);

    double density=2*PI/scan.beamnum;
    for(int i=0;i&lt;scan.beamnum;i++)
    {
        double theta=i*density-PI;
        double x=scan.length[i]*cos(theta);
        double y=scan.length[i]*sin(theta);
        scene-&gt;addEllipse(-y-0.05,-x-0.05,0.1,0.1,QPen(Qt::blue,0.1))-&gt;setZValue(1);
    }
    for(int i=10;i&lt;=100;i+=10)
    {
        scene-&gt;addEllipse(-i/2,-i/2,i,i,QPen(Qt::gray,0.2,Qt::DotLine))-&gt;setZValue(0);
    }
    scene-&gt;addLine(0,0,0,-5,QPen(Qt::red,0.2,Qt::DotLine))-&gt;setZValue(0);
    scene-&gt;addLine(0,0,-5,0,QPen(Qt::green,0.2,Qt::DotLine))-&gt;setZValue(0);

    QList&lt;int&gt; curidlist=pathmap.keys();
    QList&lt;int&gt; trackidlist=trackerresultmap.keys();
    //for loop to get all tracking results
    for(int i=0;i&lt;trackidlist.size();i++)
    {
        //get one tracking result stored in trackerresult
        TrackerResultContainer trackerresult=trackerresultmap[trackidlist[i]];
        //for loop to draw rectangle of vehicle. the corner is represented as (cx[i],cy[i]) (0&lt;=i&lt;=3)
        for(int j=0;j&lt;4;j++)
        {
            scene-&gt;addLine(-trackerresult.estimate.cy[j],-trackerresult.estimate.cx[j],-trackerresult.estimate.cy[(j+1)%4],-trackerresult.estimate.cx[(j+1)%4],QPen(Qt::red,0.1,Qt::DotLine));
        }
        scene-&gt;addLine(-trackerresult.estimate.cy[0],-trackerresult.estimate.cx[0],-trackerresult.estimate.cy[2],-trackerresult.estimate.cx[2],QPen(Qt::red,0.1,Qt::DotLine));
        scene-&gt;addLine(-trackerresult.estimate.cy[1],-trackerresult.estimate.cx[1],-trackerresult.estimate.cy[3],-trackerresult.estimate.cx[3],QPen(Qt::red,0.1,Qt::DotLine));

        for(int j=0;j&lt;2;j++)
        {
            for(int k=0;k&lt;trackerresult.edgepointnum[j];k++)
            {
                int id=trackerresult.edgepointid[j][k];
                double theta=id*density-PI;
                double x=scan.length[id]*cos(theta);
                double y=scan.length[id]*sin(theta);
                scene-&gt;addEllipse(-y-0.05,-x-0.05,0.1,0.1,QPen(Qt::green,0.1))-&gt;setZValue(2);
            }
        }
    }

    for(int i=0;i&lt;curidlist.size();i++)
    {
        bool flag=trackidlist.contains(curidlist[i]);
        if(!flag)
        {            
            pathmap.remove(curidlist[i]);
        }
    }
}

void UpdateTrackerView::wheelEvent(QWheelEvent *event)
{
    if(ctrlflag)
    {
        if(event-&gt;delta()&gt;0)
        {
            sx*=1.1;sy*=1.1;
            this-&gt;scale(1.1,1.1);
        }
        else
        {
            sx*=0.9;sy*=0.9;
            this-&gt;scale(0.9,0.9);
        }
    }
    else
    {
        QGraphicsView::wheelEvent(event);
    }
}

void UpdateTrackerView::keyPressEvent(QKeyEvent *event)
{
    switch(event-&gt;key())
    {
    case Qt::Key_Control:
        ctrlflag=1;
        break;
    default:
        QGraphicsView::keyPressEvent(event);
        break;
    }
}

void UpdateTrackerView::keyReleaseEvent(QKeyEvent *event)
{
    switch(event-&gt;key())
    {
    case Qt::Key_Control:
        ctrlflag=0;
        break;
    default:
        QGraphicsView::keyReleaseEvent(event);
        break;
    }
}

MainWindow::MainWindow(QWidget *parent) :
    QMainWindow(parent),
    ui(new Ui::MainWindow)
{
    ui-&gt;setupUi(this);

    scansub=new ROSSub&lt;sensor_msgs::LaserScanConstPtr&gt;(&quot;/scan&quot;,1000,10,this);
    //detectionsub=new ROSSub&lt;cv_tracker::obj_label::ConstPtr&gt;(&quot;obj_label&quot;,1000,10,this);
    boxessub=new ROSSub&lt;jsk_recognition_msgs::BoundingBoxArray::ConstPtr&gt;(&quot;bounding_boxes&quot;,1000,10,this);
    tfsub=new ROSTFSub(&quot;/world&quot;,&quot;/velodyne&quot;,10,this);
    tfMap2Lidarsub=new ROSTFSub(&quot;/velodyne&quot;,&quot;/map&quot;,10,this); // obj_pose is published into &quot;map&quot; frame


    //subscribe vehicle detection results (array of [x,y,theta])

    connect(scansub,SIGNAL(receiveMessageSignal()),this,SLOT(slotReceive()));
    //connect(detectionsub,SIGNAL(receiveMessageSignal()), this, SLOT(slotReceiveDetection()));
    connect(boxessub,SIGNAL(receiveMessageSignal()), this, SLOT(slotReceiveBoxes()));
    connect(tfsub,SIGNAL(receiveTFSignal()),this,SLOT(slotReceiveTF()));
    connect(tfMap2Lidarsub,SIGNAL(receiveTFSignal()),this,SLOT(slotReceiveTFMap2Lidar()));

    QSplitter * splitter=new QSplitter(Qt::Horizontal);
    ui-&gt;layout-&gt;addWidget(splitter);

    initview=new InitTrackerView;
    splitter-&gt;addWidget(initview);

    updateview=new UpdateTrackerView;
    splitter-&gt;addWidget(updateview);

    vehicletracker=new RBSSPFVehicleTracker;
    connect(vehicletracker,SIGNAL(signalUpdateTrackerFinish(LaserScan,QMap&lt;int,TrackerResultContainer&gt;)),updateview,SLOT(slotUpdateTrackerFinish(LaserScan,QMap&lt;int,TrackerResultContainer&gt;)));

    scansub-&gt;startReceiveSlot();
    //detectionsub-&gt;startReceiveSlot();
    boxessub-&gt;startReceiveSlot();
    tfsub-&gt;startReceiveSlot();
    tfMap2Lidarsub-&gt;startReceiveSlot();
}

MainWindow::~MainWindow()
{
    scansub-&gt;stopReceiveSlot();
    //detectionsub-&gt;stopReceiveSlot();
    boxessub-&gt;stopReceiveSlot();
    tfsub-&gt;stopReceiveSlot();
    tfMap2Lidarsub-&gt;stopReceiveSlot();
    delete ui;
}

void MainWindow::slotReceive()
{
    sensor_msgs::LaserScanConstPtr msg=scansub-&gt;getMessage();
    int msec=(msg-&gt;header.stamp.sec)%(24*60*60)*1000+(msg-&gt;header.stamp.nsec)/1000000;
    QTime timestamp=QTime::fromMSecsSinceStartOfDay(msec);
    LaserScan scan;
    scan.timestamp=timestamp.msecsSinceStartOfDay();
    scan.beamnum=msg-&gt;ranges.size();
    for(int i=0;i&lt;scan.beamnum;i++)
    {
        scan.length[i]=msg-&gt;ranges[i];
    }
    scanlist.push_back(QPair&lt;QTime, LaserScan &gt;(timestamp,scan));
    if(ui-&gt;trigger-&gt;isChecked())
    {
        slotShowScan();
    }
}

void MainWindow::slotReceiveDetection()
{
    cv_tracker::obj_label::ConstPtr msg=detectionsub-&gt;getMessage();

    for (const auto&amp; point : msg-&gt;reprojected_pos) {
        int msec=(msg-&gt;header.stamp.sec)%(24*60*60)*1000+(msg-&gt;header.stamp.nsec)/1000000;
        QTime timestamp=QTime::fromMSecsSinceStartOfDay(msec);
        VehicleState state;
        //fill state from msg;
        // convert object position from map coordinate to sensor coordinate
        tf::Vector3 pt(point.x, point.y, point.z);
        tf::Vector3 converted = transformMap2Lidar * pt;
        state.x = converted.x();
        state.y = converted.y();

        detectionlist.push_back(QPair&lt;QTime, VehicleState &gt;(timestamp,state));
        if(ui-&gt;trigger-&gt;isChecked())
            {
                slotShowScan();
            }
    }
}

void MainWindow::slotReceiveBoxes()
{
	jsk_recognition_msgs::BoundingBoxArray::ConstPtr msg=boxessub-&gt;getMessage();
    for (const auto&amp; box : msg-&gt;boxes) {
        int msec=(msg-&gt;header.stamp.sec)%(24*60*60)*1000+(msg-&gt;header.stamp.nsec)/1000000;
        QTime timestamp=QTime::fromMSecsSinceStartOfDay(msec);
        VehicleState vstate;
        //fill state from msg;
        // convert object position from map coordinate to sensor coordinate
        tf::Vector3 pt(box.pose.position.x, box.pose.position.y, box.pose.position.z);
        //tf::Vector3 converted = transformMap2Lidar * pt;
        vstate.x = pt.x();
        vstate.y = pt.y();
        tf::Quaternion quat;
        tf::quaternionMsgToTF(box.pose.orientation, quat);
        vstate.theta = tf::getYaw(quat);

        detectionlist.push_back(QPair&lt;QTime, VehicleState &gt;(timestamp,vstate));
        if(ui-&gt;trigger-&gt;isChecked())
            {
                slotShowScan();
            }
    }
}

void MainWindow::slotReceiveTF()
{
    tf::StampedTransform tf;
    tfsub-&gt;getTF(tf);
    int msec=(tf.stamp_.sec)%(24*60*60)*1000+(tf.stamp_.nsec)/1000000;
    QTime timestamp=QTime::fromMSecsSinceStartOfDay(msec);

    tf::Vector3 pos=tf.getOrigin();
    tf::Matrix3x3 rot=tf.getBasis();
    Eigen::Vector3d head;
    head(0)=1;head(1)=0;head(2)=0;
    Eigen::Matrix3d rotmat;
    for(int i=0;i&lt;3;i++)
    {
        rotmat(i,0)=(double)(rot.getRow(i).x());
        rotmat(i,1)=(double)(rot.getRow(i).y());
        rotmat(i,2)=(double)(rot.getRow(i).z());
    }
    head=rotmat*head;
    EGOMOTION ego={pos.x(),pos.y(),atan2(head(1),head(0))};

    tflist.push_back(QPair&lt;QTime,EGOMOTION&gt;(timestamp,ego));

    if(ui-&gt;trigger-&gt;isChecked())
    {
        slotShowScan();
    }
}


void MainWindow::slotReceiveTFMap2Lidar()
{
    tfMap2Lidarsub-&gt;getTF(transformMap2Lidar);
}


void MainWindow::getInitStateFromTopic(QVector&lt;VehicleState&gt; &amp;initState)
{
    for (auto&amp; detected : detectionlist)
    {
        initState.push_back(detected.second);
    }
    detectionlist.clear();
}

void MainWindow::slotShowScan()
{
    //synchronization between vscan and tf
    bool flag=1;
    while(flag&amp;&amp;!scanlist.isEmpty()&amp;&amp;!tflist.isEmpty())
    {
        QTime scantime=scanlist[0].first;
        QTime tftime=tflist[0].first;
        if(scantime==tftime)
        {
            flag=0;
        }
        else if(scantime&gt;tftime)
        {
            tflist.pop_front();
        }
        else
        {
            scanlist.pop_front();
        }
    }

    int scannum=scanlist.size();
    int tfnum=tflist.size();
    //it's better to synchronize detection with them


    if(scannum&gt;=1&amp;&amp;tfnum&gt;=1)
    {
        if(initflag)
        {
            //=====================================
            //fill initstate from subscribed detection topic
            //=====================================
            QVector&lt;VehicleState&gt; initstate;
            //initview-&gt;getInitState(initstate);
            getInitStateFromTopic(initstate);
            vehicletracker-&gt;addTrackerData(curscan,initstate);
        }
        curscan=scanlist[0].second;
        curscan.x=tflist[0].second.x;
        curscan.y=tflist[0].second.y;
        curscan.theta=tflist[0].second.theta;
        initview-&gt;showLaserScan(curscan);
        initflag=1;

        scanlist.pop_front();
        //detectionlist.pop_front();
        tflist.pop_front();

        if(ui-&gt;local-&gt;isChecked())
        {
            QTransform transform;
            transform.scale(initview-&gt;sx,initview-&gt;sy);
            initview-&gt;setTransform(transform);
        }
        else
        {
            QTransform transform;
            transform.rotateRadians(-curscan.theta);
            transform.translate(-curscan.y,-curscan.x);
            transform.scale(initview-&gt;sx,initview-&gt;sy);
            initview-&gt;setTransform(transform);
        }
        initview-&gt;centerOn(0,0);
    }
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/vscan_lidar_track/mainwindow.h" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/vscan_lidar_track/mainwindow.h">
				<diff>@@ -6,7 +6,7 @@
 #include&lt;sensor_msgs/LaserScan.h&gt;
 #include&lt;sensor_msgs/PointCloud2.h&gt;
 #include&lt;visualization_msgs/MarkerArray.h&gt;
-#include &quot;cv_tracker/obj_label.h&quot;
+#include &quot;cv_tracker_msgs/obj_label.h&quot;
 
 #include&lt;QGraphicsView&gt;
 #include&lt;QGraphicsScene&gt;
@@ -100,7 +100,7 @@ private:
     Ui::MainWindow *ui;
 public:
     ROSSub&lt;sensor_msgs::LaserScanConstPtr&gt; * scansub;
-    ROSSub&lt;cv_tracker::obj_label::ConstPtr&gt; * detectionsub;
+    ROSSub&lt;cv_tracker_msgs::obj_label::ConstPtr&gt; * detectionsub;
     ROSSub&lt;jsk_recognition_msgs::BoundingBoxArray::ConstPtr&gt; * boxessub;
     ROSTFSub * tfsub;
     ROSTFSub * tfMap2Lidarsub;
</diff>
				<old_file>#ifndef MAINWINDOW_H
#define MAINWINDOW_H

#include&lt;QMainWindow&gt;
#include&lt;rosinterface.h&gt;
#include&lt;sensor_msgs/LaserScan.h&gt;
#include&lt;sensor_msgs/PointCloud2.h&gt;
#include&lt;visualization_msgs/MarkerArray.h&gt;
#include &quot;cv_tracker/obj_label.h&quot;

#include&lt;QGraphicsView&gt;
#include&lt;QGraphicsScene&gt;
#include&lt;QGraphicsLineItem&gt;
#include&lt;QGraphicsEllipseItem&gt;
#include&lt;QGraphicsPathItem&gt;
#include&lt;QPainterPath&gt;
#include&lt;QLayout&gt;
#include&lt;QMouseEvent&gt;
#include&lt;QKeyEvent&gt;
#include&lt;QWheelEvent&gt;
#include&lt;QPointF&gt;
#include&lt;QListWidget&gt;
#include&lt;QMap&gt;
#include&lt;QTime&gt;
#include&lt;QList&gt;
#include&lt;QPair&gt;
#include&lt;QSplitter&gt;
#include&lt;Eigen/Dense&gt;

#include&lt;rbsspfvehicletracker.h&gt;


#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;

namespace Ui {
class MainWindow;
}

// using namespace RobotSDK;

class InitTrackerView : public QGraphicsView
{
    Q_OBJECT
public:
    InitTrackerView(QWidget * parent=NULL);
public:
    void showLaserScan(LaserScan &amp; scan);
    void getInitState(QVector&lt;VehicleState&gt; &amp; initState);
protected:
    void mousePressEvent(QMouseEvent *event);
    void wheelEvent(QWheelEvent *event);
    void keyPressEvent(QKeyEvent *event);
    void keyReleaseEvent(QKeyEvent *event);
protected:
    bool pressflag=0;
    bool ctrlflag=0;
    QPointF point1,point2;
    QGraphicsEllipseItem * point1item;
    QGraphicsLineItem * lineitem;
public:
    double sx=1,sy=1;
    QGraphicsScene * scene=NULL;
    LaserScan scan;
    QVector&lt;QGraphicsLineItem *&gt; state;
};

class UpdateTrackerView : public QGraphicsView
{
    Q_OBJECT
public:
    UpdateTrackerView(QWidget * parent=NULL);
public slots:
    void slotUpdateTrackerFinish(LaserScan scan, QMap&lt;int, TrackerResultContainer&gt; trackerresultmap);
protected:
    void wheelEvent(QWheelEvent *event);
    void keyPressEvent(QKeyEvent *event);
    void keyReleaseEvent(QKeyEvent *event);
protected:
    bool ctrlflag=0;
    QMap&lt;int, QGraphicsPathItem *&gt; pathmap;
public:
    double sx=1,sy=1;
    QGraphicsScene * scene=NULL;
};

struct EGOMOTION
{
    double x,y,theta;
};

class MainWindow : public QMainWindow
{
    Q_OBJECT
public:
    explicit MainWindow(QWidget *parent = 0);
    ~MainWindow();
    void getInitStateFromTopic(QVector&lt;VehicleState&gt; &amp; initState);
private:
    Ui::MainWindow *ui;
public:
    ROSSub&lt;sensor_msgs::LaserScanConstPtr&gt; * scansub;
    ROSSub&lt;cv_tracker::obj_label::ConstPtr&gt; * detectionsub;
    ROSSub&lt;jsk_recognition_msgs::BoundingBoxArray::ConstPtr&gt; * boxessub;
    ROSTFSub * tfsub;
    ROSTFSub * tfMap2Lidarsub;
    QList&lt; QPair&lt;QTime,LaserScan&gt; &gt; scanlist;
    QList&lt; QPair&lt;QTime,VehicleState&gt; &gt; detectionlist;
    QList&lt; QPair&lt;QTime,EGOMOTION&gt; &gt; tflist;
public:
    RBSSPFVehicleTracker * vehicletracker;
    LaserScan curscan;
public:
    InitTrackerView * initview;
    UpdateTrackerView * updateview;
    bool initflag=0;
public slots:
    void slotReceive();
    void slotReceiveDetection();
    void slotReceiveBoxes();
    void slotReceiveTF();
    void slotReceiveTFMap2Lidar();
    void slotShowScan();
private:
    tf::StampedTransform transformMap2Lidar;
};

#endif // MAINWINDOW_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_d_viewer/image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_d_viewer/image_d_viewer.cpp">
				<diff>@@ -36,7 +36,7 @@
 #include &quot;ros/ros.h&quot;
 #include &lt;sensor_msgs/image_encodings.h&gt;
 #include &lt;sensor_msgs/CompressedImage.h&gt;
-#include &quot;cv_tracker/image_obj_ranged.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
 #include &lt;math.h&gt;
 #include &lt;float.h&gt;
 #define NO_DATA 0
@@ -49,8 +49,8 @@ static IplImage temp;
 static IplImage *image;
 static double ratio = 1;	//resize ratio
 
-static cv_tracker::image_obj_ranged car_fused_objects;
-static cv_tracker::image_obj_ranged pedestrian_fused_objects;
+static cv_tracker_msgs::image_obj_ranged car_fused_objects;
+static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
 
 static const int OBJ_RECT_THICKNESS = 3;
 static void showImage();
@@ -64,7 +64,7 @@ static inline bool isNearlyNODATA(float x)
 }
 
 void showRects(IplImage *Image,
-               std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
+               std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                double ratio,
                CvScalar col)
 {
@@ -80,7 +80,7 @@ void showRects(IplImage *Image,
     }
 }
 
-static void obj_carCallback(const cv_tracker::image_obj_ranged&amp; fused_objects)
+static void obj_carCallback(const cv_tracker_msgs::image_obj_ranged&amp; fused_objects)
 {
     if(image == NULL){
       return;
@@ -89,7 +89,7 @@ static void obj_carCallback(const cv_tracker::image_obj_ranged&amp; fused_objects)
     showImage();
 }
 
-static void obj_personCallback(const cv_tracker::image_obj_ranged&amp; fused_objects)
+static void obj_personCallback(const cv_tracker_msgs::image_obj_ranged&amp; fused_objects)
 {
     if(image == NULL){
       return;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;

#include &quot;ros/ros.h&quot;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;sensor_msgs/CompressedImage.h&gt;
#include &quot;cv_tracker/image_obj_ranged.h&quot;
#include &lt;math.h&gt;
#include &lt;float.h&gt;
#define NO_DATA 0

static char window_name_base[] = &quot;image_d_viewer&quot;;
static std::string window_name;
//for imageCallback
static cv_bridge::CvImagePtr cv_image;
static IplImage temp;
static IplImage *image;
static double ratio = 1;	//resize ratio

static cv_tracker::image_obj_ranged car_fused_objects;
static cv_tracker::image_obj_ranged pedestrian_fused_objects;

static const int OBJ_RECT_THICKNESS = 3;
static void showImage();

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
  float abs_x  = (float)fabs(x);
  const int rangeScale = 100;
  return(abs_x &lt; FLT_MIN*rangeScale);
}

void showRects(IplImage *Image,
               std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
               double ratio,
               CvScalar col)
{
    unsigned int object_num = objects.size();
    for(unsigned int i = 0; i &lt; object_num; i++)
    {
        if (!isNearlyNODATA(objects.at(i).range))
        {
            CvPoint p1=cvPoint(objects.at(i).rect.x, objects.at(i).rect.y);
            CvPoint p2=cvPoint(objects.at(i).rect.x + objects.at(i).rect.width, objects.at(i).rect.y + objects.at(i).rect.height);
            cvRectangle(Image,p1,p2,col,OBJ_RECT_THICKNESS);
        }
    }
}

static void obj_carCallback(const cv_tracker::image_obj_ranged&amp; fused_objects)
{
    if(image == NULL){
      return;
    }
    car_fused_objects = fused_objects;
    showImage();
}

static void obj_personCallback(const cv_tracker::image_obj_ranged&amp; fused_objects)
{
    if(image == NULL){
      return;
    }
    pedestrian_fused_objects = fused_objects;
    showImage();
}

static void imageCallback(const sensor_msgs::Image&amp; image_source)
{
    cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
    temp = cv_image-&gt;image;
    image = &amp;temp;
    showImage();
}

static void showImage()
{
    IplImage* image_clone = cvCloneImage(image);
    char distance_string[32];
    CvFont dfont;
    float hscale      = 0.7f;
    float vscale      = 0.7f;
    float italicscale = 0.0f;
    int  thickness    = 1;

    std::string objectLabel;
    CvFont      dfont_label;
    float       hscale_label = 0.5f;
    float       vscale_label = 0.5f;
    CvSize      text_size;
    int         baseline     = 0;

    cvInitFont(&amp;dfont_label, CV_FONT_HERSHEY_COMPLEX, hscale_label, vscale_label, italicscale, thickness, CV_AA);
    objectLabel = car_fused_objects.type;
    cvGetTextSize(objectLabel.data(),
                  &amp;dfont_label,
                  &amp;text_size,
                  &amp;baseline);

    /*
     * Plot obstacle frame
     */
    showRects(image_clone,
              car_fused_objects.obj,
              ratio,
              cvScalar(255.0,255.0,0.0));
    showRects(image_clone,
              pedestrian_fused_objects.obj,
              ratio,
              cvScalar(0.0,255.0,0.0));


    /*
     * Plot car distance data on image
     */
    for (unsigned int i = 0; i &lt; car_fused_objects.obj.size(); i++) {
      if(!isNearlyNODATA(car_fused_objects.obj.at(i).range)) {
          int rect_x      = car_fused_objects.obj.at(i).rect.x;
          int rect_y      = car_fused_objects.obj.at(i).rect.y;
          int rect_width  = car_fused_objects.obj.at(i).rect.width;
          int rect_height = car_fused_objects.obj.at(i).rect.height;
          float range     = car_fused_objects.obj.at(i).range;

          /* put label */
          CvPoint labelOrg = cvPoint(rect_x - OBJ_RECT_THICKNESS,
                                     rect_y - baseline - OBJ_RECT_THICKNESS);
          cvRectangle(image_clone,
                      cvPoint(labelOrg.x + 0, labelOrg.y + baseline),
                      cvPoint(labelOrg.x + text_size.width, labelOrg.y - text_size.height),
                      CV_RGB(0, 0, 0), // label background color is black
                      -1, 8, 0
                      );
          cvPutText(image_clone,
                    objectLabel.data(),
                    labelOrg,
                    &amp;dfont_label,
                    CV_RGB(255, 255, 255) // label text color is white
                    );

          /* put distance data */
            cvRectangle(image_clone,
                        cv::Point(rect_x + (rect_width/2) - (((int)log10(range/100)+1) * 5 + 45),
                                  rect_y + rect_height + 5),
                        cv::Point(rect_x + (rect_width/2) + (((int)log10(range/100)+1) * 8 + 38),
                                  rect_y + rect_height + 30),
                        cv::Scalar(255,255,255), -1);
            cvInitFont (&amp;dfont, CV_FONT_HERSHEY_COMPLEX , hscale, vscale, italicscale, thickness, CV_AA);
            sprintf(distance_string, &quot;%.2f m&quot;, range / 100); //unit of length is meter
            cvPutText(image_clone,
                      distance_string,
                      cvPoint(rect_x + (rect_width/2) - (((int)log10(range/100)+1) * 5 + 40),
                              rect_y + rect_height + 25),
                      &amp;dfont,
                      CV_RGB(255, 0, 0));
        }
    }

    objectLabel = pedestrian_fused_objects.type;
    cvGetTextSize(objectLabel.data(),
                  &amp;dfont_label,
                  &amp;text_size,
                  &amp;baseline);

    /*
     * Plot pedestrian distance data on image
     */
    for (unsigned int i = 0; i &lt; pedestrian_fused_objects.obj.size(); i++) {
      if(!isNearlyNODATA(pedestrian_fused_objects.obj.at(i).range)) {
          int rect_x      = pedestrian_fused_objects.obj.at(i).rect.x;
          int rect_y      = pedestrian_fused_objects.obj.at(i).rect.y;
          int rect_width  = pedestrian_fused_objects.obj.at(i).rect.width;
          int rect_height = pedestrian_fused_objects.obj.at(i).rect.height;
          float range     = pedestrian_fused_objects.obj.at(i).range;

          /* put label */
          CvPoint labelOrg = cvPoint(rect_x - OBJ_RECT_THICKNESS,
                                     rect_y - baseline - OBJ_RECT_THICKNESS);
          cvRectangle(image_clone,
                      cvPoint(labelOrg.x + 0, labelOrg.y + baseline),
                      cvPoint(labelOrg.x + text_size.width, labelOrg.y - text_size.height),
                      CV_RGB(0, 0, 0), // label background color is black
                      -1, 8, 0
                      );
          cvPutText(image_clone,
                    objectLabel.data(),
                    labelOrg,
                    &amp;dfont_label,
                    CV_RGB(255, 255, 255) // label text color is white
                    );

          /* put distance data */
            cvRectangle(image_clone,
                        cv::Point(rect_x + (rect_width/2) - (((int)log10(range/100)+1) * 5 + 45),
                                  rect_y + rect_height + 5),
                        cv::Point(rect_x + (rect_width/2) + (((int)log10(range/100)+1) * 8 + 38),
                                  rect_y + rect_height + 30),
                        cv::Scalar(255,255,255), -1);
            cvInitFont (&amp;dfont, CV_FONT_HERSHEY_COMPLEX , hscale, vscale, italicscale, thickness, CV_AA);
            sprintf(distance_string, &quot;%.2f m&quot;, range / 100); //unit of length is meter
            cvPutText(image_clone,
                      distance_string,
                      cvPoint(rect_x + (rect_width/2) - (((int)log10(range/100)+1) * 5 + 40),
                              rect_y + rect_height + 25),
                      &amp;dfont,
                      CV_RGB(255, 0, 0));
        }
    }

    /*
     * Show image
     */
    if (cvGetWindowHandle(window_name.c_str()) != NULL) // Guard not to write destroyed window by using close button on the window
      {
        cvShowImage(window_name.c_str(), image_clone);
        cvWaitKey(2);
      }
    cvReleaseImage(&amp;image_clone);
}

int main(int argc, char **argv)
{
   /**
    * The ros::init() function needs to see argc and argv so that it can perform
    * any ROS arguments and name remapping that were provided at the command line. For programmatic
    * remappings you can use a different version of init() which takes remappings
    * directly, but for most command-line programs, passing argc and argv is the easiest
    * way to do it.  The third argument to init() is the name of the node.
    *
    * You must call one of the versions of ros::init() before using any other
    * part of the ROS system.
    */


    ros::init(argc, argv, &quot;image_d_viewer&quot;);

    /**
     * NodeHandle is the main access point to communications with the ROS system.
     * The first NodeHandle constructed will fully initialize this node, and the last
     * NodeHandle destructed will close down the node.
     */
    ros::NodeHandle n;
    ros::NodeHandle private_nh(&quot;~&quot;);

    /**
     * The subscribe() call is how you tell ROS that you want to receive messages
     * on a given topic.  This invokes a call to the ROS
     * master node, which keeps a registry of who is publishing and who
     * is subscribing.  Messages are passed to a callback function, here
     * called Callback.  subscribe() returns a Subscriber object that you
     * must hold on to until you want to unsubscribe.  When all copies of the Subscriber
     * object go out of scope, this callback will automatically be unsubscribed from
     * this topic.
     *
     * The second parameter to the subscribe() function is the size of the message
     * queue.  If messages are arriving faster than they are being processed, this
     * is the number of messages that will be buffered up before beginning to throw
     * away the oldest ones.
     */
    std::string image_topic;
    std::string car_topic;
    std::string person_topic;

    if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic)) {
      ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic.c_str());
    } else {
      ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
      image_topic = &quot;/image_raw&quot;;
    }

    if (!private_nh.getParam(&quot;car_topic&quot;, car_topic)) {
      car_topic = &quot;/obj_car/image_obj_ranged&quot;;
    }

    if (!private_nh.getParam(&quot;person_topic&quot;, person_topic)) {
      person_topic = &quot;/obj_person/image_obj_ranged&quot;;
    }

    std::string name_space_str = ros::this_node::getNamespace();
    if (name_space_str != &quot;/&quot;) {
      window_name = std::string(window_name_base) + &quot; (&quot; + ros::this_node::getNamespace() + &quot;)&quot;;
    }
    else {
      window_name = std::string(window_name_base);
    }
    cvNamedWindow(window_name.c_str(), 2);
    cvStartWindowThread();
    image = NULL;
    car_fused_objects.obj.clear();
    pedestrian_fused_objects.obj.clear();

    ros::Subscriber image_sub = n.subscribe(image_topic, 1, imageCallback);
    ros::Subscriber obj_car_sub = n.subscribe(car_topic, 1, obj_carCallback);
    ros::Subscriber obj_person_sub = n.subscribe(person_topic, 1, obj_personCallback);

    /**
     * ros::spin() will enter a loop, pumping callbacks.  With this version, all
     * callbacks will be called from within this thread (the main one).  ros::spin()
     * will exit when Ctrl-C is pressed, or the node is shutdown by the master.
     */
    ros::spin();
    cvDestroyWindow(window_name.c_str());

    return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_viewer/image_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_viewer/image_viewer.cpp">
				<diff>@@ -38,8 +38,8 @@
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
 
-#include &lt;cv_tracker/image_obj_tracked.h&gt;
-#include &lt;cv_tracker/image_obj.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
+#include &lt;cv_tracker_msgs/image_obj.h&gt;
 
 //DPM related
 static std::vector&lt;cv::Rect&gt; cars;		//objects detected
@@ -209,7 +209,7 @@ static void image_viewer_callback(const sensor_msgs::Image&amp; image_source)
 	_drawing = false;
 }
 
-static void image_obj_update_cb(const cv_tracker::image_obj&amp; image_objs)
+static void image_obj_update_cb(const cv_tracker_msgs::image_obj&amp; image_objs)
 {
 	if(_drawing)
 		return;
@@ -239,7 +239,7 @@ static void image_obj_update_cb(const cv_tracker::image_obj&amp; image_objs)
 	}
 }
 
-static void image_obj_updater_cb_tracked(const cv_tracker::image_obj_tracked&amp; image_objs_tracked_msg)
+static void image_obj_updater_cb_tracked(const cv_tracker_msgs::image_obj_tracked&amp; image_objs_tracked_msg)
 {
 	if(_drawing)
 		return;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *	list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *	this list of conditions and the following disclaimer in the documentation
 *	and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *	contributors may be used to endorse or promote products derived from
 *	this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;string&gt;
#include &lt;vector&gt;

//#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &quot;gencolors.cpp&quot;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;

#include &lt;cv_tracker/image_obj_tracked.h&gt;
#include &lt;cv_tracker/image_obj.h&gt;

//DPM related
static std::vector&lt;cv::Rect&gt; cars;		//objects detected
static std::vector&lt;float&gt; cars_score;		//score of each object
//KF related
static std::vector&lt;cv::Rect&gt; cars_tracked;	//objects tracked for current frame
static std::vector&lt;int&gt; cars_tracked_lifespan;	//remaining lifespan
static std::vector&lt;int&gt; cars_tracked_id;	//objects' id
static std::vector&lt;int&gt; cars_tracked_real_data;	//states if the data contained in the index is real or prediction

//DPM related
static std::vector&lt;cv::Rect&gt; peds;
static std::vector&lt;float&gt; peds_score;
//KF related
static std::vector&lt;cv::Rect&gt; peds_tracked;
static std::vector&lt;int&gt; peds_tracked_lifespan;
static std::vector&lt;int&gt; peds_tracked_id;
static std::vector&lt;int&gt; peds_tracked_real_data;

static std::vector&lt;cv::Scalar&gt; _colors;

static const int OBJ_RECT_THICKNESS = 3;

static bool _drawing = false;
static bool car_track_ready = false;
static bool car_dpm_ready = false;
static bool ped_track_ready = false;
static bool ped_dpm_ready = false;

static bool car_image_obj_ready = false;
static bool pedestrian_image_obj_ready = false;

static const std::string window_name = &quot;Image Viewer&quot;;

/*static void dashed_rectangle(cv::Mat&amp; img, const cv::Rect&amp; r, const cv::Scalar&amp; color,
			     int thickness = 2, int dash_length = 10)
{
	//draw horizontal dashed lines
	for (int i = 0; i &lt; r.width; i+=dash_length) {
		cv::line(img, cv::Point(r.x+i, r.y),  cv::Point(r.x+i+(dash_length/2), r.y), color, thickness);
		cv::line(img, cv::Point(r.x+i, r.y + r.height), cv::Point(r.x+i+(dash_length/2), r.y + r.height), color, thickness);
	}

	//draw vertical dashes lines
	for (int i = 0; i &lt; r.height; i+=dash_length) {
		cv::line(img, cv::Point(r.x, r.y+i), cv::Point(r.x, r.y+i+(dash_length/2)), color, thickness);
		cv::line(img, cv::Point(r.x +r.width, r.y+i), cv::Point(r.x+ r.width, r.y+i+(dash_length/2)), color, thickness);
	}
}*/

static void drawDetections(std::vector&lt;cv::Rect&gt; dets, std::vector&lt;float&gt; scores, std::string objectLabel, IplImage frame)
{
	/* variables for object label */
	CvFont font;
	const float hscale = 0.5f;
	const float vscale = 0.5f;
	const float italicScale = 0.0f;
	const int thickness = 1;
	CvSize text_size;
	int baseline = 0;

	cvInitFont(&amp;font, CV_FONT_HERSHEY_COMPLEX, hscale, vscale, italicScale, thickness, CV_AA);

	//UNTRACKED
	for(std::size_t i = 0; i &lt; dets.size(); ++i) {
#ifdef TEMP_DISABLED
		//temporal way to avoid drawing detections in the sky
		if (dets[i].y &lt;= frame.height * 0.3)
			continue;
#endif
		std::ostringstream label;
		label &lt;&lt; objectLabel &lt;&lt; &quot;:&quot; &lt;&lt; std::setprecision(2) &lt;&lt; scores[i];
		std::string text = label.str();

		//get text size
		cvGetTextSize(text.data(),
			&amp;font,
			&amp;text_size,
			&amp;baseline);

		//cvRectangle( &amp;frame,
			//cvPoint(dets[i].x, dets[i].y),
			//cvPoint(dets[i].x+dets[i].width, dets[i].y+dets[i].height),
			//CV_RGB(0, 0, 255), OBJ_RECT_THICKNESS, CV_AA, 0);
		cvCircle(&amp;frame, cvPoint(dets[i].x+dets[i].width/2, dets[i].y+dets[i].height/2), 30, cvScalar(0,255,0),3);		/* draw object label */
		CvPoint textOrg = cvPoint(dets[i].x - OBJ_RECT_THICKNESS, dets[i].y - baseline - OBJ_RECT_THICKNESS);

		cvRectangle(&amp;frame,
			cvPoint(textOrg.x + 0 , textOrg.y + baseline),
			cvPoint(textOrg.x + text_size.width, textOrg.y - text_size.height),
			CV_RGB(0, 0, 0), // text background is black
			-1, 8, 0);
		cvPutText(&amp;frame,
			text.data(),
			textOrg,
			&amp;font,
			CV_RGB(255, 255, 255) // text color is white
			);
	}
}

static void drawTracked(std::vector&lt;cv::Rect&gt; dets, std::vector&lt;int&gt; lifespan, std::vector&lt;int&gt; obj_id,
			std::vector&lt;int&gt; real_data, std::string objectLabel, cv::Mat imageTrack)
{
	for(std::size_t i=0; i&lt;dets.size();i++) {
#ifdef TEMP_DISABLED
		//temporal way to avoid drawing detections in the sky
		if (dets[i].y &lt;= imageTrack.rows * 0.3)
			continue;
#endif

		std::ostringstream label;
		label &lt;&lt; objectLabel &lt;&lt; &quot;_&quot; &lt;&lt; obj_id[i] &lt;&lt; &quot;:&quot; &lt;&lt; std::setprecision(2) &lt;&lt; lifespan[i];
		std::string text = label.str();

		//if (real_data[i])
			//rectangle(imageTrack, dets[i], _colors[obj_id[i]], 3);
	//	else
			//dashed_rectangle(imageTrack, dets[i], _colors[obj_id[i]], 3, 10);

		putText(imageTrack, text.c_str(), cv::Point(dets[i].x + 4, dets[i].y + 15),
			cv::FONT_HERSHEY_SIMPLEX, 0.55, _colors[obj_id[i]], 2);
		cv::circle(imageTrack, cv::Point(dets[i].x+dets[i].width/2, dets[i].y+dets[i].height/2), 30, _colors[obj_id[i]],3);
	}
}

static void image_viewer_callback(const sensor_msgs::Image&amp; image_source)
{
	_drawing = true;

	const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source,
							     encoding);
	IplImage frame = cv_image-&gt;image;

	cv::Mat matImage(cv_image-&gt;image);
	cv::Mat imageTrack = matImage.clone();

	//UNTRACKED
	putText(matImage, &quot;PIXEL_XY&quot;, cv::Point(10,10), cv::FONT_HERSHEY_SIMPLEX, 0.55, cv::Scalar(0, 0, 255), 2);
	if (car_dpm_ready)
		drawDetections(cars, cars_score, &quot;car&quot;, frame);
	if (ped_dpm_ready)
		drawDetections(peds, peds_score, &quot;pedestrian&quot;, frame);

	if (car_image_obj_ready)
		drawDetections(cars, cars_score, &quot;car&quot;, frame);
	if (pedestrian_image_obj_ready)
		drawDetections(peds, peds_score, &quot;pedestrian&quot;, frame);

	//TRACKED
	putText(imageTrack, &quot;PIXEL_XY_TRACKED&quot;, cv::Point(10,10), cv::FONT_HERSHEY_SIMPLEX, 0.55, cv::Scalar(0, 255, 0), 2);
	if(car_track_ready)
		drawTracked(cars_tracked, cars_tracked_lifespan, cars_tracked_id, cars_tracked_real_data, &quot;car&quot;, imageTrack);
	if(ped_track_ready)
		drawTracked(peds_tracked, peds_tracked_lifespan, peds_tracked_id, peds_tracked_real_data, &quot;pedestrian&quot;, imageTrack);

	cv::Mat merged;
	hconcat(matImage, imageTrack, merged);

	if (cvGetWindowHandle(window_name.c_str()) != NULL) // Guard not to write destroyed window by using close button on the window
		{
			imshow(window_name, merged);
			cvWaitKey(2);
		}

	_drawing = false;
}

static void image_obj_update_cb(const cv_tracker::image_obj&amp; image_objs)
{
	if(_drawing)
		return;

	bool is_car = (image_objs.type == &quot;car&quot;);
	std::vector&lt;cv::Rect&gt;&amp; objs = is_car ? cars : peds;
	std::vector&lt;float&gt;&amp; scores = is_car ? cars_score : peds_score;
	
	objs.clear();
	scores.clear();

	for (const auto&amp; obj : image_objs.obj) {
		cv::Rect tmp;
		tmp.x = obj.x;
		tmp.y = obj.y;
		tmp.width = obj.width;
		tmp.height = obj.height;

		objs.push_back(tmp);
		scores.push_back(obj.score);
	}

	if (is_car) {
		car_image_obj_ready = true;
	} else {
		pedestrian_image_obj_ready = true;
	}
}

static void image_obj_updater_cb_tracked(const cv_tracker::image_obj_tracked&amp; image_objs_tracked_msg)
{
	if(_drawing)
		return;
	bool is_car = (image_objs_tracked_msg.type == &quot;car&quot;);
	std::vector&lt;cv::Rect&gt;&amp; objs_tracked = is_car ? cars_tracked : peds_tracked;
	std::vector&lt;int&gt;&amp; objs_tracked_lifespan = is_car ? cars_tracked_lifespan : peds_tracked_lifespan;
	std::vector&lt;int&gt;&amp; objs_tracked_id = is_car ? cars_tracked_id : peds_tracked_id;
	std::vector&lt;int&gt;&amp; objs_tracked_real_data = is_car ? cars_tracked_real_data : peds_tracked_real_data;

	objs_tracked_lifespan = image_objs_tracked_msg.lifespan;
	objs_tracked_id = image_objs_tracked_msg.obj_id;
	objs_tracked_real_data = image_objs_tracked_msg.real_data;

	objs_tracked.clear();
	for (const auto&amp; rect_ranged : image_objs_tracked_msg.rect_ranged)
		{
			cv::Rect tmp;
			tmp.x = rect_ranged.rect.x;
			tmp.y = rect_ranged.rect.y;
			tmp.width = rect_ranged.rect.width;
			tmp.height = rect_ranged.rect.height;

			objs_tracked.push_back(tmp);
		}

	if(is_car) {
		car_track_ready = true;
	} else {
		ped_track_ready = true;
	}
}

int main(int argc, char **argv)
{

	/* create resizable window */
	cv::namedWindow(window_name, cv::WINDOW_NORMAL);
	cv::startWindowThread();

	ros::init(argc, argv, &quot;image_viewer&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	std::string image_topic_name;

	if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
		ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
	} else {
		ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
		image_topic_name = &quot;/image_raw&quot;;
	}

	generateColors(_colors, 25);

	ros::Subscriber scriber = n.subscribe(image_topic_name, 1, image_viewer_callback);

	ros::Subscriber scriber_car = n.subscribe(&quot;/obj_car/image_obj&quot;, 1,
						image_obj_update_cb);
	ros::Subscriber scriber_ped = n.subscribe(&quot;/obj_person/image_obj&quot;, 1,
						image_obj_update_cb);

	ros::Subscriber scriber_ped_tracked = n.subscribe(&quot;/obj_person/image_obj_tracked&quot;, 1,
						image_obj_updater_cb_tracked);
	ros::Subscriber scriber_car_tracked = n.subscribe(&quot;/obj_car/image_obj_tracked&quot;, 1,
						image_obj_updater_cb_tracked);

	ros::spin();

	/* destroy window */
	cv::destroyWindow(window_name);

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/points_image_d_viewer/points_image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/points_image_d_viewer/points_image_d_viewer.cpp">
				<diff>@@ -39,7 +39,7 @@
 #include &lt;sensor_msgs/image_encodings.h&gt;
 #include &lt;points2image/PointsImage.h&gt;
 
-#include &quot;cv_tracker/image_obj_ranged.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
 #include &lt;vector&gt;
 #include &lt;iostream&gt;
 #include &lt;math.h&gt;
@@ -58,8 +58,8 @@ static cv::Mat colormap;
 static std::vector&lt;cv::Rect&gt; cars;
 static std::vector&lt;cv::Rect&gt; peds;
 #else
-static cv_tracker::image_obj_ranged car_fused_objects;
-static cv_tracker::image_obj_ranged pedestrian_fused_objects;
+static cv_tracker_msgs::image_obj_ranged car_fused_objects;
+static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
 #endif
 
 /* check whether floating value x is nearly 0 or not */
@@ -78,7 +78,7 @@ static std::vector&lt;cv::Scalar&gt; _colors;
 static const int OBJ_RECT_THICKNESS = 3;
 
 static void drawRects(IplImage *Image,
-                      std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
+                      std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                       CvScalar color,
                       int threshold_height)
 {
@@ -93,7 +93,7 @@ static void drawRects(IplImage *Image,
 }
 
 static void putDistance(IplImage *Image,
-                        std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
+                        std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                         int threshold_height,
                         const char* objectLabel)
 {
@@ -278,7 +278,7 @@ static void car_updater_callback(dpm::ImageObjects image_objects_msg)
   }
 }
 #else
-static void car_updater_callback(const cv_tracker::image_obj_ranged&amp; fused_car_msg)
+static void car_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
 {
   car_fused_objects = fused_car_msg;
   //  show();
@@ -303,7 +303,7 @@ static void ped_updater_callback(dpm::ImageObjects image_objects_msg)
   }
 }
 #else
-static void ped_updater_callback(const cv_tracker::image_obj_ranged&amp; fused_pds_msg)
+static void ped_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
 {
   pedestrian_fused_objects = fused_pds_msg;
   //  show();
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/opencv.hpp&gt;
//#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &quot;gencolors.cpp&quot;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;points2image/PointsImage.h&gt;

#include &quot;cv_tracker/image_obj_ranged.h&quot;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
#include &lt;float.h&gt;

#define NO_DATA 0
static char window_name[] = &quot;points_image_d_viewer&quot;;

static bool existImage = false;
static bool existPoints = false;
static sensor_msgs::Image image_msg;
static points2image::PointsImageConstPtr points_msg;
static cv::Mat colormap;

#if 0
static std::vector&lt;cv::Rect&gt; cars;
static std::vector&lt;cv::Rect&gt; peds;
#else
static cv_tracker::image_obj_ranged car_fused_objects;
static cv_tracker::image_obj_ranged pedestrian_fused_objects;
#endif

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
  float abs_x  = (float)fabs(x);
  const int rangeScale = 100;
  return(abs_x &lt; FLT_MIN*rangeScale);
}

static std::vector&lt;cv::Scalar&gt; _colors;

#define	IMAGE_WIDTH	800
#define	IMAGE_HEIGHT	600

static const int OBJ_RECT_THICKNESS = 3;

static void drawRects(IplImage *Image,
                      std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
                      CvScalar color,
                      int threshold_height)
{
  unsigned int object_num = objects.size();
  for(unsigned int i = 0; i &lt; object_num; i++) {
    if (objects.at(i).rect.y &gt; threshold_height &amp;&amp; !isNearlyNODATA(objects.at(i).range)) {  // temporal way to avoid drawing detections in the sky
      CvPoint p1=cvPoint(objects.at(i).rect.x, objects.at(i).rect.y);
      CvPoint p2=cvPoint(objects.at(i).rect.x + objects.at(i).rect.width, objects.at(i).rect.y + objects.at(i).rect.height);
      cvRectangle(Image,p1,p2,color,OBJ_RECT_THICKNESS);
    }
  }
}

static void putDistance(IplImage *Image,
                        std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
                        int threshold_height,
                        const char* objectLabel)
{
  char distance_string[32];
  CvFont dfont;
  float hscale	    = 0.7f;
  float vscale	    = 0.7f;
  float italicscale = 0.0f;
  int	thickness   = 1;

  CvFont      dfont_label;
  float       hscale_label = 0.5f;
  float       vscale_label = 0.5f;
  CvSize      text_size;
  int         baseline     = 0;

  cvInitFont(&amp;dfont_label, CV_FONT_HERSHEY_COMPLEX, hscale_label, vscale_label, italicscale, thickness, CV_AA);
  cvGetTextSize(objectLabel,
                &amp;dfont_label,
                &amp;text_size,
                &amp;baseline);

  for (unsigned int i=0; i&lt;objects.size(); i++)
    {
      if (objects.at(i).rect.y &gt; threshold_height) // temporal way to avoid drawing detections in the sky
        {
          if (!isNearlyNODATA(objects.at(i).range))
            {

              /*put label */
              CvPoint labelOrg = cvPoint(objects.at(i).rect.x - OBJ_RECT_THICKNESS,
                                         objects.at(i).rect.y - baseline - OBJ_RECT_THICKNESS);

              cvRectangle(Image,
                          cvPoint(labelOrg.x + 0, labelOrg.y + baseline),
                          cvPoint(labelOrg.x + text_size.width, labelOrg.y - text_size.height),
                          CV_RGB(0, 0, 0), // label background is black
                          -1, 8, 0
                          );
              cvPutText(Image,
                        objectLabel,
                        labelOrg,
                        &amp;dfont_label,
                        CV_RGB(255, 255, 255) // label text color is white
                        );

              /* put distance data */
              cvRectangle(Image,
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 45),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 5),
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) + (((int)log10(objects.at(i).range/100)+1) * 8 + 38),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 30),
                          cv::Scalar(255,255,255),
                          -1);

              cvInitFont (&amp;dfont,
                          CV_FONT_HERSHEY_COMPLEX,
                          hscale,
                          vscale,
                          italicscale,
                          thickness,
                          CV_AA);

              sprintf(distance_string, &quot;%.2f m&quot;, objects.at(i).range / 100); //unit of length is meter
              cvPutText(Image,
                        distance_string,
                        cvPoint(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 40),
                                objects.at(i).rect.y + objects.at(i).rect.height + 25),
                        &amp;dfont,
                        CV_RGB(255, 0, 0));
            }

        }
    }
}

void show(void)
{
  if(!existImage || !existPoints){
    return;
  }
  const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, encoding);
  IplImage frame = cv_image-&gt;image;

  cv::Mat matImage = cv::cvarrToMat(&amp;frame);//(&amp;frame, false);

  /* DRAW RECTANGLES of detected objects */
#if 0
  for(std::size_t i=0; i&lt;cars.size();i++) {
      if(cars[i].y &gt; matImage.rows*.3) { //temporal way to avoid drawing detections in the sky
          cvRectangle( &amp;frame,
                       cvPoint(cars[i].x, cars[i].y),
                       cvPoint(cars[i].x+cars[i].width, cars[i].y+cars[i].height),
                       _colors[0], 3, 8,0 );
    }
  }
  for(std::size_t i=0; i&lt;peds.size();i++) {
    if(peds[i].y &gt; matImage.rows*.3) {
      cvRectangle( &amp;frame,
                   cvPoint(peds[i].x, peds[i].y),
                   cvPoint(peds[i].x+peds[i].width, peds[i].y+peds[i].height),
                   _colors[1], 3, 8,0 );
    }
  }
#else
  drawRects(&amp;frame,
            car_fused_objects.obj,
            cvScalar(255.0, 255.0, 0,0),
            matImage.rows*.10);

  drawRects(&amp;frame,
            pedestrian_fused_objects.obj,
            cvScalar(0.0, 255.0, 0,0),
            matImage.rows*.10);
#endif
  /* PUT DISTANCE text on image */
  putDistance(&amp;frame,
              car_fused_objects.obj,
              matImage.rows*.10,
              car_fused_objects.type.c_str());
  putDistance(&amp;frame,
              pedestrian_fused_objects.obj,
              matImage.rows*.10,
              pedestrian_fused_objects.type.c_str());

  /* DRAW POINTS of lidar scanning */
  int w = matImage.size().width;
  int h = matImage.size().height;

  int n = w * h;
  float min_d = 1&lt;&lt;16, max_d = -1;
  //	int min_i = 1&lt;&lt;8, max_i = -1;
  for(int i=0; i&lt;n; i++){
    int di = points_msg-&gt;distance[i];
    max_d = di &gt; max_d ? di : max_d;
    min_d = di &lt; min_d ? di : min_d;
    // int it = points_msg-&gt;intensity[i];
    // max_i = it &gt; max_i ? it : max_i;
    // min_i = it &lt; min_i ? it : min_i;
  }
  float wid_d = max_d - min_d;

  for(int y=0; y&lt;h; y++){
    for(int x=0; x&lt;w; x++){
      int j = y * w + x;
      double distance = points_msg-&gt;distance[j];
      if(distance == 0){
        continue;
      }
      int colorid= wid_d ? ( (distance - min_d) * 255 / wid_d ) : 128;
      cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
      int g = color[1];
      int b = color[2];
      int r = color[0];
      cvRectangle(&amp;frame, cvPoint(x, y), cvPoint(x+1, y+1), CV_RGB(r, g, b));
    }
  }

  if (cvGetWindowHandle(window_name) != NULL) // Guard not to write destroyed window by using close button on the window
    {
      cvShowImage(window_name, &amp;frame);
      cvWaitKey(2);
    }
}

#if 0
static void car_updater_callback(dpm::ImageObjects image_objects_msg)
{
  int num = image_objects_msg.car_num;
  std::vector&lt;int&gt; points = image_objects_msg.corner_point;
  //points are X,Y,W,H and repeat for each instance
  cars.clear();

  for (int i=0; i&lt;num;i++) {
    cv::Rect tmp;
    tmp.x = points[i*4 + 0];
    tmp.y = points[i*4 + 1];
    tmp.width = points[i*4 + 2];
    tmp.height = points[i*4 + 3];
    cars.push_back(tmp);
  }
}
#else
static void car_updater_callback(const cv_tracker::image_obj_ranged&amp; fused_car_msg)
{
  car_fused_objects = fused_car_msg;
  //  show();
}
#endif

#if 0
static void ped_updater_callback(dpm::ImageObjects image_objects_msg)
{
  int num = image_objects_msg.car_num;
  std::vector&lt;int&gt; points = image_objects_msg.corner_point;
  //points are X,Y,W,H and repeat for each instance
  peds.clear();

  for (int i=0; i&lt;num;i++) {
    cv::Rect tmp;
    tmp.x = points[i*4 + 0];
    tmp.y = points[i*4 + 1];
    tmp.width = points[i*4 + 2];
    tmp.height = points[i*4 + 3];
    peds.push_back(tmp);
  }
}
#else
static void ped_updater_callback(const cv_tracker::image_obj_ranged&amp; fused_pds_msg)
{
  pedestrian_fused_objects = fused_pds_msg;
  //  show();
}
#endif

static void image_cb(const sensor_msgs::Image&amp; msg)
{
  image_msg = msg;
  existImage = true;
  show();
}

static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
{
  points_msg = msg;
  existPoints = true;
  show();
}

int main(int argc, char **argv)
{
  /* create resizable window */
  cvNamedWindow(window_name, CV_WINDOW_NORMAL);
  cvStartWindowThread();

  ros::init(argc, argv, &quot;points_image_d_viewer&quot;);
  ros::NodeHandle n;
  ros::NodeHandle private_nh(&quot;~&quot;);

  std::string image_topic_name;
  std::string car_node;
  std::string pedestrian_node;
  std::string points_node;

  if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
    ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
  } else {
    ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
    image_topic_name = &quot;/image_raw&quot;;
  }

  if (private_nh.getParam(&quot;car_node&quot;, car_node)) {
    ROS_INFO(&quot;Setting car positions node to %s&quot;, car_node.c_str());
  } else {
    ROS_INFO(&quot;No car positions node received, defaulting to car_pixel_xyz, you can use _car_node:=YOUR_TOPIC&quot;);
    car_node = &quot;/obj_car/image_obj_ranged&quot;;
  }

  if (private_nh.getParam(&quot;pedestrian_node&quot;, pedestrian_node)) {
    ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, pedestrian_node.c_str());
  } else {
    ROS_INFO(&quot;No pedestrian positions node received, defaulting to pedestrian_pixel_xyz, you can use _pedestrian_node:=YOUR_TOPIC&quot;);
    pedestrian_node = &quot;/obj_person/image_obj_ranged&quot;;
  }

  if (private_nh.getParam(&quot;points_node&quot;, points_node)) {
    ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, points_node.c_str());
  } else {
    ROS_INFO(&quot;No points node received, defaulting to points_image, you can use _points_node:=YOUR_TOPIC&quot;);
    points_node = &quot;/points_image&quot;;
  }

  generateColors(_colors, 25);

  ros::Subscriber scriber = n.subscribe(image_topic_name, 1,
                                        image_cb);
  ros::Subscriber scriber_car = n.subscribe(car_node, 1,
                                            car_updater_callback);
  ros::Subscriber scriber_ped = n.subscribe(pedestrian_node, 1,
                                            ped_updater_callback);
  ros::Subscriber scriber_points = n.subscribe(points_node, 1,
                                               points_cb);

  cv::Mat grayscale(256,1,CV_8UC1);
  for(int i=0;i&lt;256;i++) {
    grayscale.at&lt;uchar&gt;(i)=i;
  }
  cv::applyColorMap(grayscale,colormap,cv::COLORMAP_JET);

  ros::spin();

  cvDestroyWindow(window_name);

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/scan_image_d_viewer/scan_image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/scan_image_d_viewer/scan_image_d_viewer.cpp">
				<diff>@@ -42,7 +42,7 @@
 #include &lt;iostream&gt;
 #include &lt;math.h&gt;
 #include &lt;float.h&gt;
-#include &quot;cv_tracker/image_obj_ranged.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
 #include &quot;scan2image/ScanImage.h&quot;
 
 #define IMAGE_WIDTH 800
@@ -58,8 +58,8 @@ bool exist_image = false;
 bool exist_scan = false;
 cv::Mat colormap;
 
-cv_tracker::image_obj_ranged car_fused_objects;
-cv_tracker::image_obj_ranged pedestrian_fused_objects;
+cv_tracker_msgs::image_obj_ranged car_fused_objects;
+cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
 static const int OBJ_RECT_THICKNESS = 3;
 
 /* check whether floating value x is nearly 0 or not */
@@ -71,7 +71,7 @@ static inline bool isNearlyNODATA(float x)
 }
 
 static void putDistance(IplImage *Image,
-                        std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
+                        std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                         int threshold_height,
                         const char* objectLabel)
 {
@@ -147,7 +147,7 @@ static void putDistance(IplImage *Image,
 }
 
 static void drawRects(IplImage *Image,
-                      std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
+                      std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                       CvScalar color,
                       int threshold_height)
 {
@@ -236,13 +236,13 @@ static void scan_image_callback(const scan2image::ScanImage&amp; scan_image_msg)
     show();
 }
 
-static void car_fusion_callback(const cv_tracker::image_obj_ranged&amp; fused_car_msg)
+static void car_fusion_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
 {
   car_fused_objects = fused_car_msg;
 //  show();
 }
 
-static void ped_fusion_callback(const cv_tracker::image_obj_ranged&amp; fused_pds_msg)
+static void ped_fusion_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
 {
   pedestrian_fused_objects = fused_pds_msg;
 //  show();
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

//openCV library
#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv/cxcore.h&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &quot;ros/ros.h&quot;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
#include &lt;float.h&gt;
#include &quot;cv_tracker/image_obj_ranged.h&quot;
#include &quot;scan2image/ScanImage.h&quot;

#define IMAGE_WIDTH 800
#define IMAGE_HEIGHT 600
#define NO_DATA 0

char window_name[] = &quot;SCAN_IMAGE_VIEWER&quot;;
//for imageCallback
cv_bridge::CvImagePtr cv_image;
IplImage image;
scan2image::ScanImage scan_image;
bool exist_image = false;
bool exist_scan = false;
cv::Mat colormap;

cv_tracker::image_obj_ranged car_fused_objects;
cv_tracker::image_obj_ranged pedestrian_fused_objects;
static const int OBJ_RECT_THICKNESS = 3;

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
    float abs_x  = (float)fabs(x);
    const int rangeScale = 100;
    return(abs_x &lt; FLT_MIN*rangeScale);
}

static void putDistance(IplImage *Image,
                        std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
                        int threshold_height,
                        const char* objectLabel)
{
  char distance_string[32];
  CvFont dfont;
  float hscale	    = 0.7f;
  float vscale	    = 0.7f;
  float italicscale = 0.0f;
  int	thickness   = 1;

  CvFont      dfont_label;
  float       hscale_label = 0.5f;
  float       vscale_label = 0.5f;
  CvSize      text_size;
  int         baseline     = 0;

  cvInitFont(&amp;dfont_label, CV_FONT_HERSHEY_COMPLEX, hscale_label, vscale_label, italicscale, thickness, CV_AA);
  cvGetTextSize(objectLabel,
                &amp;dfont_label,
                &amp;text_size,
                &amp;baseline);

  for (unsigned int i=0; i&lt;objects.size(); i++)
    {
      if (objects.at(i).rect.y &gt; threshold_height) // temporal way to avoid drawing detections in the sky
        {
          if (!isNearlyNODATA(objects.at(i).range))
            {
              /* put label */
              CvPoint labelOrg = cvPoint(objects.at(i).rect.x - OBJ_RECT_THICKNESS,
                                         objects.at(i).rect.y - baseline - OBJ_RECT_THICKNESS);

              cvRectangle(Image,
                          cvPoint(labelOrg.x + 0, labelOrg.y + baseline),
                          cvPoint(labelOrg.x + text_size.width, labelOrg.y - text_size.height),
                          CV_RGB(0, 0, 0), // label background is black
                          -1, 8, 0
                          );
              cvPutText(Image,
                        objectLabel,
                        labelOrg,
                        &amp;dfont_label,
                        CV_RGB(255, 255, 255) // label text color is white
                        );

              /* put distance data */
              cvRectangle(Image,
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 45),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 5),
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) + (((int)log10(objects.at(i).range/100)+1) * 8 + 38),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 30),
                          cv::Scalar(255,255,255),
                          -1);

              cvInitFont (&amp;dfont,
                          CV_FONT_HERSHEY_COMPLEX,
                          hscale,
                          vscale,
                          italicscale,
                          thickness,
                          CV_AA);

              sprintf(distance_string, &quot;%.2f m&quot;, objects.at(i).range / 100); //unit of length is meter
              cvPutText(Image,
                        distance_string,
                        cvPoint(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 40),
                                objects.at(i).rect.y + objects.at(i).rect.height + 25),
                        &amp;dfont,
                        CV_RGB(255, 0, 0));
            }
        }
    }
}

static void drawRects(IplImage *Image,
                      std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
                      CvScalar color,
                      int threshold_height)
{
    unsigned int object_num = objects.size();
    for(unsigned int i = 0; i &lt; object_num; i++)
    {
        if (objects.at(i).rect.y &gt; threshold_height &amp;&amp; !isNearlyNODATA(objects.at(i).range)) // temporal way to avoid drawing detections in the sky
        {
            CvPoint p1=cvPoint(objects.at(i).rect.x, objects.at(i).rect.y);
            CvPoint p2=cvPoint(objects.at(i).rect.x + objects.at(i).rect.width, objects.at(i).rect.y + objects.at(i).rect.height);
            cvRectangle(Image,p1,p2,color,OBJ_RECT_THICKNESS);
        }
    }
}

static void show()
{
    if(!exist_image || !exist_scan){
        return;
    }

    IplImage* image_view = cvCreateImage(cvGetSize(&amp;image), image.depth, image.nChannels);
    cvCopy(&amp;image, image_view);

	float min_d, max_d;
	min_d = max_d = scan_image.distance.at(0);
	for(int i = 1; i &lt; IMAGE_WIDTH * IMAGE_HEIGHT; i++){
		float di = scan_image.distance.at(i);
		max_d = di &gt; max_d ? di : max_d;
		min_d = di &lt; min_d ? di : min_d;
	}
	float wid_d = max_d - min_d;

    /*
     * Plot depth points on an image
     */
    CvPoint pt;
    int height, width;
    for(int i = 0; i &lt; (int)scan_image.distance.size(); i++) {
        height = (int)(i % IMAGE_HEIGHT);
        width = (int)(i / IMAGE_HEIGHT);
        if(scan_image.distance.at(i) != 0.0) {
            pt.x = width;
            pt.y = height;
			int colorid= wid_d ? ( (scan_image.distance.at(i) - min_d) * 255 / wid_d ) : 128;
			cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
			int g = color[1];
			int b = color[2];
			int r = color[0];
            cvCircle(image_view, pt, 2, CV_RGB (r, g, b), CV_FILLED, 8, 0);
        }
    }


  drawRects(image_view,
            car_fused_objects.obj,
            cvScalar(255.0, 255.0, 0,0),
            (image_view-&gt;height)*.3);

  drawRects(image_view,
            pedestrian_fused_objects.obj,
            cvScalar(0.0, 255.0, 0,0),
            (image_view-&gt;height)*.3);
  /* PUT DISTANCE text on image */
  putDistance(image_view,
              car_fused_objects.obj,
              (image_view-&gt;height)*.3,
              car_fused_objects.type.c_str());
  putDistance(image_view,
              pedestrian_fused_objects.obj,
              (image_view-&gt;height)*.3,
              pedestrian_fused_objects.type.c_str());

    /*
     * Show image
     */
    cvShowImage(window_name, image_view);
    cvWaitKey(2);
    cvReleaseImage(&amp;image_view);
}

static void scan_image_callback(const scan2image::ScanImage&amp; scan_image_msg)
{
    scan_image = scan_image_msg;
    exist_scan = true;
    show();
}

static void car_fusion_callback(const cv_tracker::image_obj_ranged&amp; fused_car_msg)
{
  car_fused_objects = fused_car_msg;
//  show();
}

static void ped_fusion_callback(const cv_tracker::image_obj_ranged&amp; fused_pds_msg)
{
  pedestrian_fused_objects = fused_pds_msg;
//  show();
}

static void image_callback(const sensor_msgs::Image&amp; image_msg)
{
    cv_image = cv_bridge::toCvCopy(image_msg, sensor_msgs::image_encodings::BGR8);
    image = cv_image-&gt;image;
    exist_image = true;
    show();
}

int main(int argc, char **argv)
{
    ros::init(argc, argv, &quot;sca_image_d_viewer&quot;);
    ros::NodeHandle n;
    ros::NodeHandle private_nh(&quot;~&quot;);
    std::string image_topic_name;
    if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
      ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
    } else {
      ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
      image_topic_name = &quot;/image_raw&quot;;
    }

    ros::Subscriber scan_image_sub = n.subscribe(&quot;/scan_image&quot;, 1, scan_image_callback);
    ros::Subscriber image_sub = n.subscribe(image_topic_name, 1, image_callback);
    ros::Subscriber car_fusion_sub = n.subscribe(&quot;/obj_car/image_obj_ranged&quot;, 1, car_fusion_callback);
    ros::Subscriber pedestrian_fusion_sub = n.subscribe(&quot;/obj_person/image_obj_ranged&quot;, 1, ped_fusion_callback);

    cv::Mat grayscale(256,1,CV_8UC1);
    for(int i = 0; i &lt; 256; i++) {
        grayscale.at&lt;uchar&gt;(i)=i;
    }
    cv::applyColorMap(grayscale, colormap, cv::COLORMAP_JET);
    cvNamedWindow(window_name, 2);

    ros::spin();

    cvDestroyWindow(window_name);
    return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/vscan_image_d_viewer/vscan_image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/vscan_image_d_viewer/vscan_image_d_viewer.cpp">
				<diff>@@ -35,7 +35,7 @@
 #include &lt;sensor_msgs/image_encodings.h&gt;
 #include &lt;points2image/PointsImage.h&gt;
 
-#include &lt;cv_tracker/image_obj_ranged.h&gt;
+#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
 #include &lt;vector&gt;
 #include &lt;iostream&gt;
 #include &lt;math.h&gt;
@@ -58,8 +58,8 @@ static cv::Mat colormap;
 static std::vector&lt;cv::Rect&gt; cars;
 static std::vector&lt;cv::Rect&gt; peds;
 #else
-static cv_tracker::image_obj_ranged car_fused_objects;
-static cv_tracker::image_obj_ranged pedestrian_fused_objects;
+static cv_tracker_msgs::image_obj_ranged car_fused_objects;
+static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
 #endif
 
 /* check whether floating value x is nearly 0 or not */
@@ -80,7 +80,7 @@ static std::vector&lt;cv::Scalar&gt; _colors;
 static const int OBJ_RECT_THICKNESS = 3;
 
 static void drawRects(cv::Mat image,
-                    std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
+                    std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
 					CvScalar color,
 					int threshold_height,
 					std::string objectClass)
@@ -176,13 +176,13 @@ static void show(void)
 		cvWaitKey(2);
 	}
 }
-static void car_updater_callback(const cv_tracker::image_obj_ranged&amp; fused_car_msg)
+static void car_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
 {
 	car_fused_objects = fused_car_msg;
 	//  show();
 }
 
-static void ped_updater_callback(const cv_tracker::image_obj_ranged&amp; fused_pds_msg)
+static void ped_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
 {
   pedestrian_fused_objects = fused_pds_msg;
   //  show();
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv2/opencv.hpp&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;points2image/PointsImage.h&gt;

#include &lt;cv_tracker/image_obj_ranged.h&gt;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
#include &lt;float.h&gt;

#include &lt;opencv2/core/core.hpp&gt;

#include &quot;gencolors.cpp&quot;

#define NO_DATA 0
static char window_name[] = &quot;vscan_image_d_viewer&quot;;

static bool existImage = false;
static bool existPoints = false;
static sensor_msgs::Image image_msg;
static points2image::PointsImageConstPtr points_msg;
static cv::Mat colormap;

#if 0
static std::vector&lt;cv::Rect&gt; cars;
static std::vector&lt;cv::Rect&gt; peds;
#else
static cv_tracker::image_obj_ranged car_fused_objects;
static cv_tracker::image_obj_ranged pedestrian_fused_objects;
#endif

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
	float abs_x  = (float)fabs(x);
	const int rangeScale = 100;
	return(abs_x &lt; FLT_MIN*rangeScale);
}

static std::vector&lt;cv::Scalar&gt; _colors;

#define	IMAGE_WIDTH		800
#define	IMAGE_HEIGHT 	600

#define POINTS_THRESHOLD 0.1

static const int OBJ_RECT_THICKNESS = 3;

static void drawRects(cv::Mat image,
                    std::vector&lt;cv_tracker::image_rect_ranged&gt; objects,
					CvScalar color,
					int threshold_height,
					std::string objectClass)
{
	int object_num = objects.size();
	char distance_string[32];
	int fontFace = cv::FONT_HERSHEY_SIMPLEX; double fontScale = 0.55; int fontThick = 2;
	std::vector&lt;int&gt; pointsInBoundingBox;
	for(int i = 0; i &lt; object_num; i++)
	{
		//corner_point[0]=&gt;X1		corner_point[1]=&gt;Y1
		//corner_point[2]=&gt;width	corner_point[3]=&gt;height
		cv::Rect detection = cv::Rect(objects.at(i).rect.x, objects.at(i).rect.y, objects.at(i).rect.width, objects.at(i).rect.height);

		rectangle(image, detection, color, OBJ_RECT_THICKNESS);//draw bounding box
		putText(image, objectClass, cv::Point(detection.x + 4, detection.y + 10), fontFace, fontScale, color, fontThick);//draw label text

		sprintf(distance_string, &quot;D:%.2f m H:%.1f,%.1f&quot;, objects.at(i).range / 100, objects.at(i).min_height, objects.at(i).max_height);
		//Size textSize = getTextSize(string(distance_string), fontFace, fontScale, fontThick, 0);
		//rectangle(image, cv::Rect( detection.x, detection.y, textSize.width + 4, textSize.height + 10), Scalar::all(0), CV_FILLED);//draw fill distance rectangle
		putText(image, std::string(distance_string), cv::Point(detection.x + 4, detection.y - 10), fontFace, fontScale, color, fontThick);//draw distance text
	}
}

static void drawVScanPoints(cv::Mat image)
{
	/* DRAW POINTS of lidar scanning */
    int w = image.size().width;
	int h = image.size().height;

	int i, n = w * h;
	float min_d = 1&lt;&lt;16, max_d = -1;
	//	int min_i = 1&lt;&lt;8, max_i = -1;
	for(i=0; i&lt;n; i++){
		int di = points_msg-&gt;distance[i];
		max_d = di &gt; max_d ? di : max_d;
		min_d = di &lt; min_d ? di : min_d;
		// int it = points_msg-&gt;intensity[i];
		// max_i = it &gt; max_i ? it : max_i;
		// min_i = it &lt; min_i ? it : min_i;
	}
	float wid_d = max_d - min_d;

	int x, y;
	for(y=0; y&lt;h; y++){
		for(x=0; x&lt;w; x++){
			int i = y * w + x;
			double distance = points_msg-&gt;distance[i];

			if(distance == 0){
				continue;
			}
			int colorid= wid_d ? ( (distance - min_d) * 255 / wid_d ) : 128;
			cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
			int g = color[1];
			int b = color[2];
			int r = color[0];
			rectangle(image, cv::Rect(x, y,1, 1), cv::Scalar(r, g, b), OBJ_RECT_THICKNESS);
		}
	}
}

static void show(void)
{
	if(!existImage || !existPoints){
		return;
	}
	const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, encoding);
	IplImage frame = cv_image-&gt;image;

	cv::Mat matImage=cv::cvarrToMat(&amp;frame);//(&amp;frame, false);

	//Draw VScan Points
	drawVScanPoints(matImage);

	/* DRAW RECTANGLES of detected objects */
	drawRects(matImage,
		  car_fused_objects.obj,
		  cv::Scalar(255.0, 255.0, 0,0),
		  matImage.rows*.25,
		  car_fused_objects.type);

	drawRects(matImage,
		  pedestrian_fused_objects.obj,
		  cv::Scalar(0.0, 255.0, 0,0),
		  matImage.rows*.25,
		  pedestrian_fused_objects.type);

	if (cvGetWindowHandle(window_name) != NULL) // Guard not to write destroyed window by using close button on the window
	{
		cvShowImage(window_name, &amp;frame);
		cvWaitKey(2);
	}
}
static void car_updater_callback(const cv_tracker::image_obj_ranged&amp; fused_car_msg)
{
	car_fused_objects = fused_car_msg;
	//  show();
}

static void ped_updater_callback(const cv_tracker::image_obj_ranged&amp; fused_pds_msg)
{
  pedestrian_fused_objects = fused_pds_msg;
  //  show();
}

static void image_cb(const sensor_msgs::Image&amp; msg)
{
	image_msg = msg;
	existImage = true;
	show();
}

static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
{
	points_msg = msg;
	existPoints = true;
	show();
}

int main(int argc, char **argv)
{
	/* create resizable window */
	cvNamedWindow(window_name, CV_WINDOW_NORMAL);
	cvStartWindowThread();

	ros::init(argc, argv, &quot;vscan_image_d_viewer&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	std::string image_topic_name;
	std::string car_node;
	std::string pedestrian_node;
	std::string points_node;

	if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name))
	{
		ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
	}
	else
	{
		ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
		image_topic_name = &quot;/image_raw&quot;;
	}

	if (private_nh.getParam(&quot;car_node&quot;, car_node))
	{
		ROS_INFO(&quot;Setting car positions node to %s&quot;, car_node.c_str());
	}
	else
	{
		ROS_INFO(&quot;No car positions node received, defaulting to car_pixel_xyz, you can use _car_node:=YOUR_TOPIC&quot;);
		car_node = &quot;/obj_car/image_obj_ranged&quot;;
	}

	if (private_nh.getParam(&quot;pedestrian_node&quot;, pedestrian_node))
	{
		ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, pedestrian_node.c_str());
	}
	else
	{
		ROS_INFO(&quot;No pedestrian positions node received, defaulting to pedestrian_pixel_xyz, you can use _pedestrian_node:=YOUR_TOPIC&quot;);
		pedestrian_node = &quot;/obj_person/image_obj_ranged&quot;;
	}

	if (private_nh.getParam(&quot;points_node&quot;, points_node))
	{
		ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, points_node.c_str());
	}
	else
	{
		ROS_INFO(&quot;No points node received, defaulting to points_image, you can use _points_node:=YOUR_TOPIC&quot;);
		points_node = &quot;/vscan_image&quot;;
	}

	generateColors(_colors, 25);

	ros::Subscriber scriber = n.subscribe(image_topic_name, 1,
					    image_cb);
	ros::Subscriber scriber_car = n.subscribe(car_node, 1,
						car_updater_callback);
	ros::Subscriber scriber_ped = n.subscribe(pedestrian_node, 1,
						ped_updater_callback);
	ros::Subscriber scriber_points = n.subscribe(points_node, 1,
						points_cb);

	cv::Mat grayscale(256,1,CV_8UC1);
	for(int i=0;i&lt;256;i++)
	{
		grayscale.at&lt;uchar&gt;(i)=i;
	}
	cv::applyColorMap(grayscale,colormap,cv::COLORMAP_JET);

	ros::spin();

	cvDestroyWindow(window_name);

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/freespace_planner/nodes/astar_navi/astar_navi.cpp" new_path="ros/src/computing/planning/mission/packages/freespace_planner/nodes/astar_navi/astar_navi.cpp">
				<diff>@@ -1,25 +1,25 @@
 #include &quot;astar_search.h&quot;
 #include &quot;search_info_ros.h&quot;
-#include &quot;waypoint_follower/LaneArray.h&quot;
+#include &quot;waypoint_follower_msgs/LaneArray.h&quot;
 
 namespace
 {
 
 void publishPathAsWaypoints(const ros::Publisher&amp; pub, const nav_msgs::Path&amp; path, const double waypoint_velocity_kmph)
 {
-  waypoint_follower::lane lane;
+  waypoint_follower_msgs::lane lane;
 
   lane.header = path.header;
   lane.increment = 0;
   for (const auto&amp; pose : path.poses) {
-    waypoint_follower::waypoint wp;
+    waypoint_follower_msgs::waypoint wp;
     wp.pose = pose;
     wp.twist.twist.linear.x = waypoint_velocity_kmph / 3.6;
 
     lane.waypoints.push_back(wp);
   }
 
-  waypoint_follower::LaneArray lane_array;
+  waypoint_follower_msgs::LaneArray lane_array;
   lane_array.lanes.push_back(lane);
   pub.publish(lane_array);
 
@@ -49,7 +49,7 @@ int main(int argc, char **argv)
 
   // ROS publishers
   ros::Publisher path_pub       = n.advertise&lt;nav_msgs::Path&gt;(&quot;astar_path&quot;, 1, true);
-  ros::Publisher waypoints_pub  = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;lane_waypoints_array&quot;, 1, true);
+  ros::Publisher waypoints_pub  = n.advertise&lt;waypoint_follower_msgs::LaneArray&gt;(&quot;lane_waypoints_array&quot;, 1, true);
   ros::Publisher debug_pose_pub = n.advertise&lt;geometry_msgs::PoseArray&gt;(&quot;debug_pose_array&quot;, 1, true);
 
   ros::Rate loop_rate(10);
</diff>
				<old_file>#include &quot;astar_search.h&quot;
#include &quot;search_info_ros.h&quot;
#include &quot;waypoint_follower/LaneArray.h&quot;

namespace
{

void publishPathAsWaypoints(const ros::Publisher&amp; pub, const nav_msgs::Path&amp; path, const double waypoint_velocity_kmph)
{
  waypoint_follower::lane lane;

  lane.header = path.header;
  lane.increment = 0;
  for (const auto&amp; pose : path.poses) {
    waypoint_follower::waypoint wp;
    wp.pose = pose;
    wp.twist.twist.linear.x = waypoint_velocity_kmph / 3.6;

    lane.waypoints.push_back(wp);
  }

  waypoint_follower::LaneArray lane_array;
  lane_array.lanes.push_back(lane);
  pub.publish(lane_array);

  return;
}

}

int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;astar_navi&quot;);
  ros::NodeHandle n;
  ros::NodeHandle private_nh_(&quot;~&quot;);

  double waypoint_velocity_kmph;
  std::string map_topic;
  private_nh_.param&lt;double&gt;(&quot;waypoint_velocity_kmph&quot;, waypoint_velocity_kmph, 5.0);
  private_nh_.param&lt;std::string&gt;(&quot;map_topic&quot;, map_topic, &quot;ring_ogm&quot;);

  AstarSearch astar;
  SearchInfo search_info;

  // ROS subscribers
  ros::Subscriber map_sub = n.subscribe(map_topic, 1, &amp;SearchInfo::mapCallback, &amp;search_info);
  ros::Subscriber start_sub = n.subscribe(&quot;/current_pose&quot;, 1, &amp;SearchInfo::currentPoseCallback, &amp;search_info);
  ros::Subscriber goal_sub  = n.subscribe(&quot;/move_base_simple/goal&quot;, 1, &amp;SearchInfo::goalCallback, &amp;search_info);

  // ROS publishers
  ros::Publisher path_pub       = n.advertise&lt;nav_msgs::Path&gt;(&quot;astar_path&quot;, 1, true);
  ros::Publisher waypoints_pub  = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;lane_waypoints_array&quot;, 1, true);
  ros::Publisher debug_pose_pub = n.advertise&lt;geometry_msgs::PoseArray&gt;(&quot;debug_pose_array&quot;, 1, true);

  ros::Rate loop_rate(10);
  while (ros::ok()) {
    ros::spinOnce();

    if (!search_info.getMapSet() || !search_info.getStartSet() || !search_info.getGoalSet()) {
      loop_rate.sleep();
      continue;
    }

    // Reset flag
    search_info.reset();

    auto start = std::chrono::system_clock::now();

    // Execute astar search
    bool result = astar.makePlan(search_info.getStartPose().pose, search_info.getGoalPose().pose, search_info.getMap());

    auto end = std::chrono::system_clock::now();
    auto usec = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(end - start).count();
    //std::cout &lt;&lt; &quot;astar msec: &quot; &lt;&lt; usec / 1000.0 &lt;&lt; std::endl;
    ROS_INFO(&quot;astar msec: %lf&quot;, usec / 1000.0);

    if(result) {
      ROS_INFO(&quot;Found GOAL!&quot;);
      publishPathAsWaypoints(waypoints_pub, astar.getPath(), waypoint_velocity_kmph);

#if DEBUG
      astar.publishPoseArray(debug_pose_pub, &quot;/map&quot;);
      path_pub.publish(astar.getPath());
      astar.broadcastPathTF();
#endif

    } else {
      ROS_INFO(&quot;can't find goal...&quot;);

#if DEBUG
      astar.publishPoseArray(debug_pose_pub, &quot;/map&quot;); // debug
      path_pub.publish(astar.getPath());
#endif

    }

    astar.reset();

    loop_rate.sleep();
  }

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/include/lane_planner/vmap.hpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/include/lane_planner/vmap.hpp">
				<diff>@@ -39,9 +39,9 @@
 #include &lt;visualization_msgs/Marker.h&gt;
 
 #include &lt;vector_map/vector_map.h&gt;
-#include &lt;tablet_socket/route_cmd.h&gt;
-#include &lt;waypoint_follower/dtlane.h&gt;
-#include &lt;waypoint_follower/lane.h&gt;
+#include &lt;tablet_socket_msgs/route_cmd.h&gt;
+#include &lt;waypoint_follower_msgs/dtlane.h&gt;
+#include &lt;waypoint_follower_msgs/lane.h&gt;
 
 namespace lane_planner {
 
@@ -77,12 +77,12 @@ bool is_connection_dtlane(const VectorMap&amp; fine_vmap, int index);
 
 geometry_msgs::Point create_geometry_msgs_point(const vector_map::Point&amp; vp);
 vector_map::Point create_vector_map_point(const geometry_msgs::Point&amp; gp);
-waypoint_follower::dtlane create_waypoint_follower_dtlane(const vector_map::DTLane&amp; vd);
-vector_map::DTLane create_vector_map_dtlane(const waypoint_follower::dtlane&amp; wd);
+waypoint_follower_msgs::dtlane create_waypoint_follower_dtlane(const vector_map::DTLane&amp; vd);
+vector_map::DTLane create_vector_map_dtlane(const waypoint_follower_msgs::dtlane&amp; wd);
 
 VectorMap create_lane_vmap(const VectorMap&amp; vmap, int lno);
-VectorMap create_coarse_vmap_from_lane(const waypoint_follower::lane&amp; lane);
-VectorMap create_coarse_vmap_from_route(const tablet_socket::route_cmd&amp; route);
+VectorMap create_coarse_vmap_from_lane(const waypoint_follower_msgs::lane&amp; lane);
+VectorMap create_coarse_vmap_from_route(const tablet_socket_msgs::route_cmd&amp; route);
 VectorMap create_fine_vmap(const VectorMap&amp; lane_vmap, int lno, const VectorMap&amp; coarse_vmap, double search_radius,
 			   int waypoint_max);
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef LANE_PLANNER_VMAP_HPP
#define LANE_PLANNER_VMAP_HPP

#include &lt;string&gt;
#include &lt;vector&gt;

#include &lt;geometry_msgs/Point.h&gt;
#include &lt;ros/ros.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;

#include &lt;vector_map/vector_map.h&gt;
#include &lt;tablet_socket/route_cmd.h&gt;
#include &lt;waypoint_follower/dtlane.h&gt;
#include &lt;waypoint_follower/lane.h&gt;

namespace lane_planner {

namespace vmap {

constexpr int LNO_ALL = -1;
constexpr int LNO_CROSSING = 0;
constexpr int LNO_MOSTLEFT = 1;

constexpr int TRAFFIC_LIGHT_RED = 0;
constexpr int TRAFFIC_LIGHT_GREEN = 1;
constexpr int TRAFFIC_LIGHT_UNKNOWN = 2;

constexpr double RADIUS_MAX = 90000000000;

struct VectorMap {
	std::vector&lt;vector_map::Point&gt; points;
	std::vector&lt;vector_map::Lane&gt; lanes;
	std::vector&lt;vector_map::Node&gt; nodes;
	std::vector&lt;vector_map::StopLine&gt; stoplines;
	std::vector&lt;vector_map::DTLane&gt; dtlanes;
};

void write_waypoints(const std::vector&lt;vector_map::Point&gt;&amp; points, double velocity, const std::string&amp; path);

double compute_reduction(const vector_map::DTLane&amp; d, double w);

bool is_straight_dtlane(const vector_map::DTLane&amp; dtlane);
bool is_curve_dtlane(const vector_map::DTLane&amp; dtlane);
bool is_crossroad_dtlane(const vector_map::DTLane&amp; dtlane);
bool is_clothoid_dtlane(const vector_map::DTLane&amp; dtlane);
bool is_connection_dtlane(const VectorMap&amp; fine_vmap, int index);

geometry_msgs::Point create_geometry_msgs_point(const vector_map::Point&amp; vp);
vector_map::Point create_vector_map_point(const geometry_msgs::Point&amp; gp);
waypoint_follower::dtlane create_waypoint_follower_dtlane(const vector_map::DTLane&amp; vd);
vector_map::DTLane create_vector_map_dtlane(const waypoint_follower::dtlane&amp; wd);

VectorMap create_lane_vmap(const VectorMap&amp; vmap, int lno);
VectorMap create_coarse_vmap_from_lane(const waypoint_follower::lane&amp; lane);
VectorMap create_coarse_vmap_from_route(const tablet_socket::route_cmd&amp; route);
VectorMap create_fine_vmap(const VectorMap&amp; lane_vmap, int lno, const VectorMap&amp; coarse_vmap, double search_radius,
			   int waypoint_max);

std::vector&lt;vector_map::Point&gt; create_branching_points(const VectorMap&amp; vmap);
std::vector&lt;vector_map::Point&gt; create_merging_points(const VectorMap&amp; vmap);

void publish_add_marker(const ros::Publisher&amp; pub, const visualization_msgs::Marker&amp; marker,
			const std::vector&lt;vector_map::Point&gt;&amp; points);
void publish_delete_marker(const ros::Publisher&amp; pub, const visualization_msgs::Marker&amp; marker);

} // namespace vmap

} // namespace lane_planner

#endif // LANE_PLANNER_VMAP_HPP
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/lib/lane_planner/vmap.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/lib/lane_planner/vmap.cpp">
				<diff>@@ -33,7 +33,7 @@
 
 #include &lt;ros/console.h&gt;
 
-#include &lt;tablet_socket/Waypoint.h&gt;
+#include &lt;tablet_socket_msgs/Waypoint.h&gt;
 
 #include &lt;geo_pos_conv.hh&gt;
 #include &lt;lane_planner/vmap.hpp&gt;
@@ -506,9 +506,9 @@ vector_map::Point create_vector_map_point(const geometry_msgs::Point&amp; gp)
 	return vp;
 }
 
-waypoint_follower::dtlane create_waypoint_follower_dtlane(const vector_map::DTLane&amp; vd)
+waypoint_follower_msgs::dtlane create_waypoint_follower_dtlane(const vector_map::DTLane&amp; vd)
 {
-	waypoint_follower::dtlane wd;
+	waypoint_follower_msgs::dtlane wd;
 	wd.dist = vd.dist;
 	wd.dir = vd.dir;
 	wd.apara = vd.apara;
@@ -521,7 +521,7 @@ waypoint_follower::dtlane create_waypoint_follower_dtlane(const vector_map::DTLa
 	return wd;
 }
 
-vector_map::DTLane create_vector_map_dtlane(const waypoint_follower::dtlane&amp; wd)
+vector_map::DTLane create_vector_map_dtlane(const waypoint_follower_msgs::dtlane&amp; wd)
 {
 	vector_map::DTLane vd;
 	vd.dist = wd.dist;
@@ -572,22 +572,22 @@ VectorMap create_lane_vmap(const VectorMap&amp; vmap, int lno)
 	return lane_vmap;
 }
 
-VectorMap create_coarse_vmap_from_lane(const waypoint_follower::lane&amp; lane)
+VectorMap create_coarse_vmap_from_lane(const waypoint_follower_msgs::lane&amp; lane)
 {
 	VectorMap coarse_vmap;
-	for (const waypoint_follower::waypoint&amp; w : lane.waypoints)
+	for (const waypoint_follower_msgs::waypoint&amp; w : lane.waypoints)
 		coarse_vmap.points.push_back(create_vector_map_point(w.pose.pose.position));
 
 	return coarse_vmap;
 }
 
-VectorMap create_coarse_vmap_from_route(const tablet_socket::route_cmd&amp; route)
+VectorMap create_coarse_vmap_from_route(const tablet_socket_msgs::route_cmd&amp; route)
 {
 	geo_pos_conv geo;
 	geo.set_plane(7);
 
 	VectorMap coarse_vmap;
-	for (const tablet_socket::Waypoint&amp; w : route.point) {
+	for (const tablet_socket_msgs::Waypoint&amp; w : route.point) {
 		geo.llh_to_xyz(w.lat, w.lon, 0);
 
 		vector_map::Point p;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;fstream&gt;
#include &lt;tuple&gt;

#include &lt;ros/console.h&gt;

#include &lt;tablet_socket/Waypoint.h&gt;

#include &lt;geo_pos_conv.hh&gt;
#include &lt;lane_planner/vmap.hpp&gt;

namespace lane_planner {

namespace vmap {

namespace {

void write_waypoint(const vector_map::Point&amp; point, double yaw, double velocity, const std::string&amp; path,
		    bool first);

double compute_direction_angle(const vector_map::Point&amp; p1, const vector_map::Point&amp; p2);

bool is_branching_point(const VectorMap&amp; vmap, const vector_map::Point&amp; point);
bool is_merging_point(const VectorMap&amp; vmap, const vector_map::Point&amp; point);
bool is_branching_lane(const vector_map::Lane&amp; lane);
bool is_merging_lane(const vector_map::Lane&amp; lane);

vector_map::Point find_start_point(const VectorMap&amp; vmap, const vector_map::Lane&amp; lane);
vector_map::Point find_end_point(const VectorMap&amp; vmap, const vector_map::Lane&amp; lane);
vector_map::Point find_departure_point(const VectorMap&amp; lane_vmap, int lno,
				       const std::vector&lt;vector_map::Point&gt;&amp; coarse_points,
				       double search_radius);
vector_map::Point find_arrival_point(const VectorMap&amp; lane_vmap, int lno,
				     const std::vector&lt;vector_map::Point&gt;&amp; coarse_points,
				     double search_radius);
vector_map::Point find_nearest_point(const VectorMap&amp; vmap, const vector_map::Point&amp; point);
std::vector&lt;vector_map::Point&gt; find_near_points(const VectorMap&amp; vmap, const vector_map::Point&amp; point,
						double search_radius);

vector_map::Lane find_lane(const VectorMap&amp; vmap, int lno, const vector_map::Point&amp; point);
vector_map::Lane find_prev_lane(const VectorMap&amp; vmap, int lno, const vector_map::Lane&amp; lane);
vector_map::Lane find_next_lane(const VectorMap&amp; vmap, int lno, const vector_map::Lane&amp; lane);
vector_map::Lane find_next_branching_lane(const VectorMap&amp; vmap, int lno, const vector_map::Lane&amp; lane,
					  double coarse_angle, double search_radius);

void write_waypoint(const vector_map::Point&amp; point, double yaw, double velocity, const std::string&amp; path,
		    bool first)
{
	// reverse X-Y axis
	if (first) {
		std::ofstream ofs(path.c_str());
		ofs &lt;&lt; std::fixed &lt;&lt; point.ly &lt;&lt; &quot;,&quot;
		    &lt;&lt; std::fixed &lt;&lt; point.bx &lt;&lt; &quot;,&quot;
		    &lt;&lt; std::fixed &lt;&lt; point.h &lt;&lt; &quot;,&quot;
		    &lt;&lt; std::fixed &lt;&lt; yaw &lt;&lt; std::endl;
	} else {
		std::ofstream ofs(path.c_str(), std::ios_base::app);
		ofs &lt;&lt; std::fixed &lt;&lt; point.ly &lt;&lt; &quot;,&quot;
		    &lt;&lt; std::fixed &lt;&lt; point.bx &lt;&lt; &quot;,&quot;
		    &lt;&lt; std::fixed &lt;&lt; point.h &lt;&lt; &quot;,&quot;
		    &lt;&lt; std::fixed &lt;&lt; yaw &lt;&lt; &quot;,&quot;
		    &lt;&lt; std::fixed &lt;&lt; velocity &lt;&lt; std::endl;
	}
}

double compute_direction_angle(const vector_map::Point&amp; p1, const vector_map::Point&amp; p2)
{
	return (atan2(p2.ly - p1.ly, p2.bx - p1.bx) * (180 / M_PI)); // -180 to 180 degrees
}

bool is_branching_point(const VectorMap&amp; vmap, const vector_map::Point&amp; point)
{
	vector_map::Lane lane = find_lane(vmap, LNO_ALL, point);
	if (lane.lnid &lt; 0)
		return false;

	lane = find_prev_lane(vmap, LNO_ALL, lane);
	if (lane.lnid &lt; 0)
		return false;

	return is_branching_lane(lane);
}

bool is_merging_point(const VectorMap&amp; vmap, const vector_map::Point&amp; point)
{
	vector_map::Lane lane = find_lane(vmap, LNO_ALL, point);
	if (lane.lnid &lt; 0)
		return false;

	return is_merging_lane(lane);
}

bool is_branching_lane(const vector_map::Lane&amp; lane)
{
	return (lane.jct == 1 || lane.jct == 2 || lane.jct == 5);
}

bool is_merging_lane(const vector_map::Lane&amp; lane)
{
	return (lane.jct == 3 || lane.jct == 4 || lane.jct == 5);
}

vector_map::Point find_start_point(const VectorMap&amp; vmap, const vector_map::Lane&amp; lane)
{
	vector_map::Point error;
	error.pid = -1;

	for (const vector_map::Node&amp; n : vmap.nodes) {
		if (n.nid != lane.bnid)
			continue;
		for (const vector_map::Point&amp; p : vmap.points) {
			if (p.pid != n.pid)
				continue;
			return p;
		}
	}

	return error;
}

vector_map::Point find_end_point(const VectorMap&amp; vmap, const vector_map::Lane&amp; lane)
{
	vector_map::Point error;
	error.pid = -1;

	for (const vector_map::Node&amp; n : vmap.nodes) {
		if (n.nid != lane.fnid)
			continue;
		for (const vector_map::Point&amp; p : vmap.points) {
			if (p.pid != n.pid)
				continue;
			return p;
		}
	}

	return error;
}

vector_map::Point find_departure_point(const VectorMap&amp; lane_vmap, int lno,
				       const std::vector&lt;vector_map::Point&gt;&amp; coarse_points,
				       double search_radius)
{
	vector_map::Point coarse_p1 = coarse_points[0];
	vector_map::Point coarse_p2 = coarse_points[1];

	vector_map::Point nearest_point = find_nearest_point(lane_vmap, coarse_p1);
	if (nearest_point.pid &lt; 0)
		return nearest_point;

	std::vector&lt;vector_map::Point&gt; near_points = find_near_points(lane_vmap, coarse_p1, search_radius);
	double coarse_angle = compute_direction_angle(coarse_p1, coarse_p2);
	double score = 180 + search_radius; // XXX better way?
	for (const vector_map::Point&amp; p1 : near_points) {
		vector_map::Lane l = find_lane(lane_vmap, lno, p1);
		if (l.lnid &lt; 0)
			continue;

		vector_map::Point p2 = find_end_point(lane_vmap, l);
		if (p2.pid &lt; 0)
			continue;

		double a = compute_direction_angle(p1, p2);
		a = fabs(a - coarse_angle);
		if (a &gt; 180)
			a = fabs(a - 360);
		double d = hypot(p1.bx - coarse_p1.bx, p1.ly - coarse_p1.ly);
		double s = a + d;
		if (s &lt;= score) {
			nearest_point = p1;
			score = s;
		}
	}

	return nearest_point;
}

vector_map::Point find_arrival_point(const VectorMap&amp; lane_vmap, int lno,
				     const std::vector&lt;vector_map::Point&gt;&amp; coarse_points,
				     double search_radius)
{
	vector_map::Point coarse_p1 = coarse_points[coarse_points.size() - 1];
	vector_map::Point coarse_p2 = coarse_points[coarse_points.size() - 2];

	vector_map::Point nearest_point = find_nearest_point(lane_vmap, coarse_p1);
	if (nearest_point.pid &lt; 0)
		return nearest_point;

	std::vector&lt;vector_map::Point&gt; near_points = find_near_points(lane_vmap, coarse_p1, search_radius);
	double coarse_angle = compute_direction_angle(coarse_p1, coarse_p2);
	double score = 180 + search_radius; // XXX better way?
	for (const vector_map::Point&amp; p1 : near_points) {
		vector_map::Lane l = find_lane(lane_vmap, lno, p1);
		if (l.lnid &lt; 0)
			continue;

		l = find_prev_lane(lane_vmap, lno, l);
		if (l.lnid &lt; 0)
			continue;

		vector_map::Point p2 = find_start_point(lane_vmap, l);
		if (p2.pid &lt; 0)
			continue;

		double a = compute_direction_angle(p1, p2);
		a = fabs(a - coarse_angle);
		if (a &gt; 180)
			a = fabs(a - 360);
		double d = hypot(p1.bx - coarse_p1.bx, p1.ly - coarse_p1.ly);
		double s = a + d;
		if (s &lt;= score) {
			nearest_point = p1;
			score = s;
		}
	}

	return nearest_point;
}

vector_map::Point find_nearest_point(const VectorMap&amp; vmap, const vector_map::Point&amp; point)
{
	vector_map::Point nearest_point;
	nearest_point.pid = -1;

	double distance = DBL_MAX;
	for (const vector_map::Point&amp; p : vmap.points) {
		double d = hypot(p.bx - point.bx, p.ly - point.ly);
		if (d &lt;= distance) {
			nearest_point = p;
			distance = d;
		}
	}

	return nearest_point;
}

std::vector&lt;vector_map::Point&gt; find_near_points(const VectorMap&amp; vmap, const vector_map::Point&amp; point,
						double search_radius)
{
	std::vector&lt;vector_map::Point&gt; near_points;
	for (const vector_map::Point&amp; p : vmap.points) {
		double d = hypot(p.bx - point.bx, p.ly - point.ly);
		if (d &lt;= search_radius)
			near_points.push_back(p);
	}

	return near_points;
}

vector_map::Lane find_lane(const VectorMap&amp; vmap, int lno, const vector_map::Point&amp; point)
{
	vector_map::Lane error;
	error.lnid = -1;

	for (const vector_map::Node&amp; n : vmap.nodes) {
		if (n.pid != point.pid)
			continue;
		for (const vector_map::Lane&amp; l : vmap.lanes) {
			if (lno != LNO_ALL &amp;&amp; l.lno != lno)
				continue;
			if (l.bnid != n.nid)
				continue;
			return l;
		}
	}

	return error;
}

vector_map::Lane find_prev_lane(const VectorMap&amp; vmap, int lno, const vector_map::Lane&amp; lane)
{
	vector_map::Lane error;
	error.lnid = -1;

	if (is_merging_lane(lane)) {
		for (const vector_map::Lane&amp; l : vmap.lanes) {
			if (lno != LNO_ALL &amp;&amp; l.lno != lno)
				continue;
			if (l.lnid != lane.blid &amp;&amp; l.lnid != lane.blid2 &amp;&amp; l.lnid != lane.blid3 &amp;&amp;
			    l.lnid != lane.blid4)
				continue;
			return l;
		}
	} else {
		for (const vector_map::Lane&amp; l : vmap.lanes) {
			if (l.lnid != lane.blid)
				continue;
			return l;
		}
	}

	return error;
}

vector_map::Lane find_next_lane(const VectorMap&amp; vmap, int lno, const vector_map::Lane&amp; lane)
{
	vector_map::Lane error;
	error.lnid = -1;

	if (is_branching_lane(lane)) {
		for (const vector_map::Lane&amp; l : vmap.lanes) {
			if (lno != LNO_ALL &amp;&amp; l.lno != lno)
				continue;
			if (l.lnid != lane.flid &amp;&amp; l.lnid != lane.flid2 &amp;&amp; l.lnid != lane.flid3 &amp;&amp;
			    l.lnid != lane.flid4)
				continue;
			return l;
		}
	} else {
		for (const vector_map::Lane&amp; l : vmap.lanes) {
			if (l.lnid != lane.flid)
				continue;
			return l;
		}
	}

	return error;
}

vector_map::Lane find_next_branching_lane(const VectorMap&amp; vmap, int lno, const vector_map::Lane&amp; lane,
					  double coarse_angle, double search_radius)
{
	vector_map::Lane error;
	error.lnid = -1;

	vector_map::Point p1 = find_end_point(vmap, lane);
	if (p1.pid &lt; 0)
		return error;

	std::vector&lt;std::tuple&lt;vector_map::Point, vector_map::Lane&gt;&gt; candidates;
	for (const vector_map::Lane&amp; l1 : vmap.lanes) {
		if (lno != LNO_ALL &amp;&amp; l1.lno != lno)
			continue;
		if (l1.lnid == lane.flid || l1.lnid == lane.flid2 || l1.lnid == lane.flid3 || l1.lnid == lane.flid4) {
			vector_map::Lane l2 = l1;
			vector_map::Point p = find_end_point(vmap, l2);
			if (p.pid &lt; 0)
				continue;
			vector_map::Point p2 = p;
			double d = hypot(p2.bx - p1.bx, p2.ly - p1.ly);
			while (d &lt;= search_radius &amp;&amp; l2.flid != 0 &amp;&amp; !is_branching_lane(l2)) {
				l2 = find_next_lane(vmap, LNO_ALL, l2);
				if (l2.lnid &lt; 0)
					break;
				p = find_end_point(vmap, l2);
				if (p.pid &lt; 0)
					break;
				p2 = p;
				d = hypot(p2.bx - p1.bx, p2.ly - p1.ly);
			}
			candidates.push_back(std::make_tuple(p2, l1));
		}
	}

	if (candidates.empty())
		return error;

	vector_map::Lane branching_lane;
	double angle = 180;
	for (const std::tuple&lt;vector_map::Point, vector_map::Lane&gt;&amp; c : candidates) {
		vector_map::Point p2 = std::get&lt;0&gt;(c);
		double a = compute_direction_angle(p1, p2);
		a = fabs(a - coarse_angle);
		if (a &gt; 180)
			a = fabs(a - 360);
		if (a &lt;= angle) {
			branching_lane = std::get&lt;1&gt;(c);
			angle = a;
		}
	}

	return branching_lane;
}

} // namespace

void write_waypoints(const std::vector&lt;vector_map::Point&gt;&amp; points, double velocity, const std::string&amp; path)
{
	if (points.size() &lt; 2)
		return;

	size_t last_index = points.size() - 1;
	for (size_t i = 0; i &lt; points.size(); ++i) {
		double yaw;
		if (i == last_index) {
			geometry_msgs::Point p1 = create_geometry_msgs_point(points[i]);
			geometry_msgs::Point p2 = create_geometry_msgs_point(points[i - 1]);
			yaw = atan2(p2.y - p1.y, p2.x - p1.x);
			yaw -= M_PI;
		} else {
			geometry_msgs::Point p1 = create_geometry_msgs_point(points[i]);
			geometry_msgs::Point p2 = create_geometry_msgs_point(points[i + 1]);
			yaw = atan2(p2.y - p1.y, p2.x - p1.x);
		}

		write_waypoint(points[i], yaw, velocity, path, (i == 0));
	}
}

double compute_reduction(const vector_map::DTLane&amp; d, double w)
{
	return (1 - fabs(1 / d.r) * w); // 0 to 1 rates
}

bool is_straight_dtlane(const vector_map::DTLane&amp; dtlane)
{
	return (dtlane.apara == 0 &amp;&amp; dtlane.r == RADIUS_MAX);
}

bool is_curve_dtlane(const vector_map::DTLane&amp; dtlane)
{
	return (dtlane.apara == 0 &amp;&amp; dtlane.r != RADIUS_MAX);
}

// XXX better way?
bool is_crossroad_dtlane(const vector_map::DTLane&amp; dtlane)
{
	// take crossroad for 10 radius or less
	return (fabs(dtlane.r) &lt;= 10);
}

bool is_clothoid_dtlane(const vector_map::DTLane&amp; dtlane)
{
	return (dtlane.apara != 0);
}

// XXX better way?
bool is_connection_dtlane(const VectorMap&amp; fine_vmap, int index)
{
	const vector_map::DTLane&amp; dtlane = fine_vmap.dtlanes[index];
	int size = fine_vmap.dtlanes.size();

	int change = 0;
	int straight = 0;
	for (int i = index - 1; i &gt;= 0; --i) {
		if (dtlane.r != fine_vmap.dtlanes[i].r) {
			++change;
			if (is_straight_dtlane(fine_vmap.dtlanes[i]))
				++straight;
			break;
		}
	}
	for (int i = index + 1; i &lt; size; ++i) {
		if (dtlane.r != fine_vmap.dtlanes[i].r) {
			++change;
			if (is_straight_dtlane(fine_vmap.dtlanes[i]))
				++straight;
			break;
		}
	}
	if (change == 1 &amp;&amp; straight == 1)
		return true;
	if (straight == 2)
		return true;

	return false;
}

geometry_msgs::Point create_geometry_msgs_point(const vector_map::Point&amp; vp)
{
	// reverse X-Y axis
	geometry_msgs::Point gp;
	gp.x = vp.ly;
	gp.y = vp.bx;
	gp.z = vp.h;

	return gp;
}

vector_map::Point create_vector_map_point(const geometry_msgs::Point&amp; gp)
{
	// reverse X-Y axis
	vector_map::Point vp;
	vp.bx = gp.y;
	vp.ly = gp.x;
	vp.h = gp.z;

	return vp;
}

waypoint_follower::dtlane create_waypoint_follower_dtlane(const vector_map::DTLane&amp; vd)
{
	waypoint_follower::dtlane wd;
	wd.dist = vd.dist;
	wd.dir = vd.dir;
	wd.apara = vd.apara;
	wd.r = vd.r;
	wd.slope = vd.slope;
	wd.cant = vd.cant;
	wd.lw = vd.lw;
	wd.rw = vd.rw;

	return wd;
}

vector_map::DTLane create_vector_map_dtlane(const waypoint_follower::dtlane&amp; wd)
{
	vector_map::DTLane vd;
	vd.dist = wd.dist;
	vd.dir = wd.dir;
	vd.apara = wd.apara;
	vd.r = wd.r;
	vd.slope = wd.slope;
	vd.cant = wd.cant;
	vd.lw = wd.lw;
	vd.rw = wd.rw;

	return vd;
}

VectorMap create_lane_vmap(const VectorMap&amp; vmap, int lno)
{
	VectorMap lane_vmap;
	for (const vector_map::Lane&amp; l : vmap.lanes) {
		if (lno != LNO_ALL &amp;&amp; l.lno != lno)
			continue;
		lane_vmap.lanes.push_back(l);

		for (const vector_map::Node&amp; n : vmap.nodes) {
			if (n.nid != l.bnid &amp;&amp; n.nid != l.fnid)
				continue;
			lane_vmap.nodes.push_back(n);

			for (const vector_map::Point&amp; p : vmap.points) {
				if (p.pid != n.pid)
					continue;
				lane_vmap.points.push_back(p);
			}
		}

		for (const vector_map::StopLine&amp; s : vmap.stoplines) {
			if (s.linkid != l.lnid)
				continue;
			lane_vmap.stoplines.push_back(s);
		}

		for (const vector_map::DTLane&amp; d : vmap.dtlanes) {
			if (d.did != l.did)
				continue;
			lane_vmap.dtlanes.push_back(d);
		}
	}

	return lane_vmap;
}

VectorMap create_coarse_vmap_from_lane(const waypoint_follower::lane&amp; lane)
{
	VectorMap coarse_vmap;
	for (const waypoint_follower::waypoint&amp; w : lane.waypoints)
		coarse_vmap.points.push_back(create_vector_map_point(w.pose.pose.position));

	return coarse_vmap;
}

VectorMap create_coarse_vmap_from_route(const tablet_socket::route_cmd&amp; route)
{
	geo_pos_conv geo;
	geo.set_plane(7);

	VectorMap coarse_vmap;
	for (const tablet_socket::Waypoint&amp; w : route.point) {
		geo.llh_to_xyz(w.lat, w.lon, 0);

		vector_map::Point p;
		p.bx = geo.x();
		p.ly = geo.y();
		coarse_vmap.points.push_back(p);
	}

	return coarse_vmap;
}

VectorMap create_fine_vmap(const VectorMap&amp; lane_vmap, int lno, const VectorMap&amp; coarse_vmap, double search_radius,
			   int waypoint_max)
{
	VectorMap fine_vmap;
	VectorMap null_vmap;

	vector_map::Point departure_point;
	departure_point.pid = -1;
	if (lno == LNO_ALL)
		departure_point = find_nearest_point(lane_vmap, coarse_vmap.points.front());
	else {
		for (int i = lno; i &gt;= LNO_CROSSING; --i) {
			departure_point = find_departure_point(lane_vmap, i, coarse_vmap.points, search_radius);
			if (departure_point.pid &gt;= 0)
				break;
		}
	}
	if (departure_point.pid &lt; 0)
		return null_vmap;

	vector_map::Point arrival_point;
	arrival_point.pid = -1;
	if (lno == LNO_ALL)
		arrival_point = find_nearest_point(lane_vmap, coarse_vmap.points.back());
	else {
		for (int i = lno; i &gt;= LNO_CROSSING; --i) {
			arrival_point = find_arrival_point(lane_vmap, i, coarse_vmap.points, search_radius);
			if (arrival_point.pid &gt;= 0)
				break;
		}
	}
	if (arrival_point.pid &lt; 0)
		return null_vmap;

	vector_map::Point point = departure_point;
	vector_map::Lane lane = find_lane(lane_vmap, LNO_ALL, point);
	if (lane.lnid &lt; 0)
		return null_vmap;

	bool finish = false;
	for (int i = 0; i &lt; waypoint_max; ++i) {
		fine_vmap.points.push_back(point);

		// last is equal to previous dtlane
		vector_map::DTLane dtlane;
		dtlane.did = -1;
		for (const vector_map::DTLane&amp; d : lane_vmap.dtlanes) {
			if (d.did == lane.did) {
				dtlane = d;
				break;
			}
		}
		fine_vmap.dtlanes.push_back(dtlane);

		// last is equal to previous stopline
		vector_map::StopLine stopline;
		stopline.id = -1;
		for (const vector_map::StopLine&amp; s : lane_vmap.stoplines) {
			if (s.linkid == lane.lnid) {
				stopline = s;
				break;
			}
		}
		fine_vmap.stoplines.push_back(stopline);

		if (finish)
			break;

		fine_vmap.lanes.push_back(lane);

		point = find_end_point(lane_vmap, lane);
		if (point.pid &lt; 0)
			return null_vmap;
		if (point.bx == arrival_point.bx &amp;&amp; point.ly == arrival_point.ly) {
			finish = true;
			continue;
		}

		if (is_branching_lane(lane)) {
			vector_map::Point coarse_p1 = find_end_point(lane_vmap, lane);
			if (coarse_p1.pid &lt; 0)
				return null_vmap;

			coarse_p1 = find_nearest_point(coarse_vmap, coarse_p1);
			if (coarse_p1.pid &lt; 0)
				return null_vmap;

			vector_map::Point coarse_p2;
			double distance = -1;
			for (const vector_map::Point&amp; p : coarse_vmap.points) {
				if (distance == -1) {
					if (p.bx == coarse_p1.bx &amp;&amp; p.ly == coarse_p1.ly)
						distance = 0;
					continue;
				}
				coarse_p2 = p;
				distance = hypot(coarse_p2.bx - coarse_p1.bx, coarse_p2.ly - coarse_p1.ly);
				if (distance &gt; search_radius)
					break;
			}
			if (distance &lt;= 0)
				return null_vmap;

			double coarse_angle = compute_direction_angle(coarse_p1, coarse_p2);
			if (lno == LNO_ALL) {
				lane = find_next_branching_lane(lane_vmap, LNO_ALL, lane, coarse_angle, search_radius);
			} else {
				vector_map::Lane l;
				l.lnid = -1;
				for (int j = lno; j &gt;= LNO_CROSSING; --j) {
					l = find_next_branching_lane(lane_vmap, j, lane, coarse_angle, search_radius);
					if (l.lnid &gt;= 0)
						break;
				}
				lane = l;
			}
		} else {
			lane = find_next_lane(lane_vmap, LNO_ALL, lane);
		}
		if (lane.lnid &lt; 0)
			return null_vmap;
	}

	if (!finish) {
		ROS_ERROR_STREAM(&quot;lane is too long&quot;);
		return null_vmap;
	}

	return fine_vmap;
}

std::vector&lt;vector_map::Point&gt; create_branching_points(const VectorMap&amp; vmap)
{
	std::vector&lt;vector_map::Point&gt; branching_points;
	for (const vector_map::Point&amp; p : vmap.points) {
		if (!is_branching_point(vmap, p))
			continue;
		branching_points.push_back(p);
	}

	return branching_points;
}

std::vector&lt;vector_map::Point&gt; create_merging_points(const VectorMap&amp; vmap)
{
	std::vector&lt;vector_map::Point&gt; merging_points;
	for (const vector_map::Point&amp; p : vmap.points) {
		if (!is_merging_point(vmap, p))
			continue;
		merging_points.push_back(p);
	}

	return merging_points;
}

void publish_add_marker(const ros::Publisher&amp; pub, const visualization_msgs::Marker&amp; marker,
			const std::vector&lt;vector_map::Point&gt;&amp; points)
{
	visualization_msgs::Marker m;
	m.header.frame_id = marker.header.frame_id;
	m.ns = marker.ns;
	m.id = marker.id;
	m.type = marker.type;
	m.scale = marker.scale;
	m.color = marker.color;
	m.frame_locked = marker.frame_locked;
	for (const vector_map::Point&amp; p : points)
		m.points.push_back(create_geometry_msgs_point(p));

	m.header.stamp = ros::Time::now();
	m.action = visualization_msgs::Marker::ADD;

	pub.publish(m);
}

void publish_delete_marker(const ros::Publisher&amp; pub, const visualization_msgs::Marker&amp; marker)
{
	visualization_msgs::Marker m;
	m.header.frame_id = marker.header.frame_id;
	m.ns = marker.ns;
	m.id = marker.id;

	m.header.stamp = ros::Time::now();
	m.action = visualization_msgs::Marker::DELETE;

	pub.publish(m);
}

} // namespace vmap

} // namespace lane_planner
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_navi/lane_navi.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_navi/lane_navi.cpp">
				<diff>@@ -34,7 +34,7 @@
 #include &lt;tf/transform_datatypes.h&gt;
 
 #include &lt;vector_map/vector_map.h&gt;
-#include &lt;waypoint_follower/LaneArray.h&gt;
+#include &lt;waypoint_follower_msgs/LaneArray.h&gt;
 
 #include &lt;lane_planner/vmap.hpp&gt;
 
@@ -50,7 +50,7 @@ ros::Publisher waypoint_pub;
 
 lane_planner::vmap::VectorMap all_vmap;
 lane_planner::vmap::VectorMap lane_vmap;
-tablet_socket::route_cmd cached_route;
+tablet_socket_msgs::route_cmd cached_route;
 
 std::vector&lt;std::string&gt; split(const std::string&amp; str, char delim)
 {
@@ -90,7 +90,7 @@ int count_lane(const lane_planner::vmap::VectorMap&amp; vmap)
 	return lcnt;
 }
 
-void create_waypoint(const tablet_socket::route_cmd&amp; msg)
+void create_waypoint(const tablet_socket_msgs::route_cmd&amp; msg)
 {
 	std_msgs::Header header;
 	header.stamp = ros::Time::now();
@@ -123,9 +123,9 @@ void create_waypoint(const tablet_socket::route_cmd&amp; msg)
 		fine_vmaps.push_back(v);
 	}
 
-	waypoint_follower::LaneArray lane_waypoint;
+	waypoint_follower_msgs::LaneArray lane_waypoint;
 	for (const lane_planner::vmap::VectorMap&amp; v : fine_vmaps) {
-		waypoint_follower::lane l;
+		waypoint_follower_msgs::lane l;
 		l.header = header;
 		l.increment = 1;
 
@@ -147,7 +147,7 @@ void create_waypoint(const tablet_socket::route_cmd&amp; msg)
 				yaw = atan2(p2.y - p1.y, p2.x - p1.x);
 			}
 
-			waypoint_follower::waypoint w;
+			waypoint_follower_msgs::waypoint w;
 			w.pose.header = header;
 			w.pose.pose.position = lane_planner::vmap::create_geometry_msgs_point(v.points[i]);
 			w.pose.pose.orientation = tf::createQuaternionMsgFromYaw(yaw);
@@ -237,7 +237,7 @@ int main(int argc, char **argv)
 		return EXIT_FAILURE;
 	}
 
-	waypoint_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/lane_waypoints_array&quot;, pub_waypoint_queue_size,
+	waypoint_pub = n.advertise&lt;waypoint_follower_msgs::LaneArray&gt;(&quot;/lane_waypoints_array&quot;, pub_waypoint_queue_size,
 								 pub_waypoint_latch);
 
 	ros::Subscriber route_sub = n.subscribe(&quot;/route_cmd&quot;, sub_route_queue_size, create_waypoint);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;sstream&gt;

#include &lt;ros/console.h&gt;
#include &lt;tf/transform_datatypes.h&gt;

#include &lt;vector_map/vector_map.h&gt;
#include &lt;waypoint_follower/LaneArray.h&gt;

#include &lt;lane_planner/vmap.hpp&gt;

namespace {

int waypoint_max;
double search_radius; // meter
double velocity; // km/h
std::string frame_id;
std::string output_file;

ros::Publisher waypoint_pub;

lane_planner::vmap::VectorMap all_vmap;
lane_planner::vmap::VectorMap lane_vmap;
tablet_socket::route_cmd cached_route;

std::vector&lt;std::string&gt; split(const std::string&amp; str, char delim)
{
	std::stringstream ss(str);
	std::string s;
	std::vector&lt;std::string&gt; vec;
	while (std::getline(ss, s, delim))
		vec.push_back(s);

	if (!str.empty() &amp;&amp; str.back() == delim)
		vec.push_back(std::string());

	return vec;
}

std::string join(const std::vector&lt;std::string&gt;&amp; vec, char delim)
{
	std::string str;
	for (size_t i = 0; i &lt; vec.size(); ++i) {
		str += vec[i];
		if (i != (vec.size() - 1))
			str += delim;
	}

	return str;
}

int count_lane(const lane_planner::vmap::VectorMap&amp; vmap)
{
	int lcnt = -1;

	for (const vector_map::Lane&amp; l : vmap.lanes) {
		if (l.lcnt &gt; lcnt)
			lcnt = l.lcnt;
	}

	return lcnt;
}

void create_waypoint(const tablet_socket::route_cmd&amp; msg)
{
	std_msgs::Header header;
	header.stamp = ros::Time::now();
	header.frame_id = frame_id;

	if (all_vmap.points.empty() || all_vmap.lanes.empty() || all_vmap.nodes.empty()) {
		cached_route.header = header;
		cached_route.point = msg.point;
		return;
	}

	lane_planner::vmap::VectorMap coarse_vmap = lane_planner::vmap::create_coarse_vmap_from_route(msg);
	if (coarse_vmap.points.size() &lt; 2)
		return;

	std::vector&lt;lane_planner::vmap::VectorMap&gt; fine_vmaps;
	lane_planner::vmap::VectorMap fine_mostleft_vmap =
		lane_planner::vmap::create_fine_vmap(lane_vmap, lane_planner::vmap::LNO_MOSTLEFT, coarse_vmap,
						     search_radius, waypoint_max);
	if (fine_mostleft_vmap.points.size() &lt; 2)
		return;
	fine_vmaps.push_back(fine_mostleft_vmap);

	int lcnt = count_lane(fine_mostleft_vmap);
	for (int i = lane_planner::vmap::LNO_MOSTLEFT + 1; i &lt;= lcnt; ++i) {
		lane_planner::vmap::VectorMap v =
			lane_planner::vmap::create_fine_vmap(lane_vmap, i, coarse_vmap, search_radius, waypoint_max);
		if (v.points.size() &lt; 2)
			continue;
		fine_vmaps.push_back(v);
	}

	waypoint_follower::LaneArray lane_waypoint;
	for (const lane_planner::vmap::VectorMap&amp; v : fine_vmaps) {
		waypoint_follower::lane l;
		l.header = header;
		l.increment = 1;

		size_t last_index = v.points.size() - 1;
		for (size_t i = 0; i &lt; v.points.size(); ++i) {
			double yaw;
			if (i == last_index) {
				geometry_msgs::Point p1 =
					lane_planner::vmap::create_geometry_msgs_point(v.points[i]);
				geometry_msgs::Point p2 =
					lane_planner::vmap::create_geometry_msgs_point(v.points[i - 1]);
				yaw = atan2(p2.y - p1.y, p2.x - p1.x);
				yaw -= M_PI;
			} else {
				geometry_msgs::Point p1 =
					lane_planner::vmap::create_geometry_msgs_point(v.points[i]);
				geometry_msgs::Point p2 =
					lane_planner::vmap::create_geometry_msgs_point(v.points[i + 1]);
				yaw = atan2(p2.y - p1.y, p2.x - p1.x);
			}

			waypoint_follower::waypoint w;
			w.pose.header = header;
			w.pose.pose.position = lane_planner::vmap::create_geometry_msgs_point(v.points[i]);
			w.pose.pose.orientation = tf::createQuaternionMsgFromYaw(yaw);
			w.twist.header = header;
			w.twist.twist.linear.x = velocity / 3.6; // to m/s
			l.waypoints.push_back(w);
		}
		lane_waypoint.lanes.push_back(l);
	}
	waypoint_pub.publish(lane_waypoint);

	for (size_t i = 0; i &lt; fine_vmaps.size(); ++i) {
		std::stringstream ss;
		ss &lt;&lt; &quot;_&quot; &lt;&lt; i;

		std::vector&lt;std::string&gt; v1 = split(output_file, '/');
		std::vector&lt;std::string&gt; v2 = split(v1.back(), '.');
		v2[0] = v2.front() + ss.str();
		v1[v1.size() - 1] = join(v2, '.');
		std::string path = join(v1, '/');

		lane_planner::vmap::write_waypoints(fine_vmaps[i].points, velocity, path);
	}
}

void update_values()
{
	if (all_vmap.points.empty() || all_vmap.lanes.empty() || all_vmap.nodes.empty())
		return;

	lane_vmap = lane_planner::vmap::create_lane_vmap(all_vmap, lane_planner::vmap::LNO_ALL);

	if (!cached_route.point.empty()) {
		create_waypoint(cached_route);
		cached_route.point.clear();
		cached_route.point.shrink_to_fit();
	}
}

void cache_point(const vector_map::PointArray&amp; msg)
{
	all_vmap.points = msg.data;
	update_values();
}

void cache_lane(const vector_map::LaneArray&amp; msg)
{
	all_vmap.lanes = msg.data;
	update_values();
}

void cache_node(const vector_map::NodeArray&amp; msg)
{
	all_vmap.nodes = msg.data;
	update_values();
}

} // namespace

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;lane_navi&quot;);

	ros::NodeHandle n;

	int sub_vmap_queue_size;
	n.param&lt;int&gt;(&quot;/lane_navi/sub_vmap_queue_size&quot;, sub_vmap_queue_size, 1);
	int sub_route_queue_size;
	n.param&lt;int&gt;(&quot;/lane_navi/sub_route_queue_size&quot;, sub_route_queue_size, 1);
	int pub_waypoint_queue_size;
	n.param&lt;int&gt;(&quot;/lane_navi/pub_waypoint_queue_size&quot;, pub_waypoint_queue_size, 1);
	bool pub_waypoint_latch;
	n.param&lt;bool&gt;(&quot;/lane_navi/pub_waypoint_latch&quot;, pub_waypoint_latch, true);

	n.param&lt;int&gt;(&quot;/lane_navi/waypoint_max&quot;, waypoint_max, 10000);
	n.param&lt;double&gt;(&quot;/lane_navi/search_radius&quot;, search_radius, 10);
	n.param&lt;double&gt;(&quot;/lane_navi/velocity&quot;, velocity, 40);
	n.param&lt;std::string&gt;(&quot;/lane_navi/frame_id&quot;, frame_id, &quot;map&quot;);
	n.param&lt;std::string&gt;(&quot;/lane_navi/output_file&quot;, output_file, &quot;/tmp/lane_waypoint.csv&quot;);

	if (output_file.empty()) {
		ROS_ERROR_STREAM(&quot;output filename is empty&quot;);
		return EXIT_FAILURE;
	}
	if (output_file.back() == '/') {
		ROS_ERROR_STREAM(output_file &lt;&lt; &quot; is directory&quot;);
		return EXIT_FAILURE;
	}

	waypoint_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/lane_waypoints_array&quot;, pub_waypoint_queue_size,
								 pub_waypoint_latch);

	ros::Subscriber route_sub = n.subscribe(&quot;/route_cmd&quot;, sub_route_queue_size, create_waypoint);
	ros::Subscriber point_sub = n.subscribe(&quot;/vector_map_info/point&quot;, sub_vmap_queue_size, cache_point);
	ros::Subscriber lane_sub = n.subscribe(&quot;/vector_map_info/lane&quot;, sub_vmap_queue_size, cache_lane);
	ros::Subscriber node_sub = n.subscribe(&quot;/vector_map_info/node&quot;, sub_vmap_queue_size, cache_node);

	ros::spin();

	return EXIT_SUCCESS;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_rule/lane_rule.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_rule/lane_rule.cpp">
				<diff>@@ -38,7 +38,7 @@
 
 #include &lt;vector_map/vector_map.h&gt;
 #include &lt;runtime_manager/ConfigLaneRule.h&gt;
-#include &lt;waypoint_follower/LaneArray.h&gt;
+#include &lt;waypoint_follower_msgs/LaneArray.h&gt;
 
 #include &lt;lane_planner/vmap.hpp&gt;
 
@@ -65,7 +65,7 @@ lane_planner::vmap::VectorMap lane_vmap;
 double curve_radius_min;
 double crossroad_radius_min;
 double clothoid_radius_min;
-waypoint_follower::LaneArray cached_waypoint;
+waypoint_follower_msgs::LaneArray cached_waypoint;
 
 #ifdef DEBUG
 visualization_msgs::Marker debug_marker;
@@ -73,12 +73,12 @@ ros::Publisher marker_pub;
 int marker_cnt;
 #endif // DEBUG
 
-waypoint_follower::lane create_new_lane(const waypoint_follower::lane&amp; lane, const std_msgs::Header&amp; header)
+waypoint_follower_msgs::lane create_new_lane(const waypoint_follower_msgs::lane&amp; lane, const std_msgs::Header&amp; header)
 {
-	waypoint_follower::lane l = lane;
+	waypoint_follower_msgs::lane l = lane;
 	l.header = header;
 
-	for (waypoint_follower::waypoint&amp; w : l.waypoints) {
+	for (waypoint_follower_msgs::waypoint&amp; w : l.waypoints) {
 		w.pose.header = header;
 		w.twist.header = header;
 	}
@@ -86,10 +86,10 @@ waypoint_follower::lane create_new_lane(const waypoint_follower::lane&amp; lane, con
 	return l;
 }
 
-waypoint_follower::lane apply_acceleration(const waypoint_follower::lane&amp; lane, double acceleration,
+waypoint_follower_msgs::lane apply_acceleration(const waypoint_follower_msgs::lane&amp; lane, double acceleration,
 					   size_t start_index, size_t fixed_cnt, double fixed_vel)
 {
-	waypoint_follower::lane l = lane;
+	waypoint_follower_msgs::lane l = lane;
 
 	if (fixed_cnt == 0)
 		return l;
@@ -116,9 +116,9 @@ waypoint_follower::lane apply_acceleration(const waypoint_follower::lane&amp; lane,
 	return l;
 }
 
-waypoint_follower::lane apply_crossroad_acceleration(const waypoint_follower::lane&amp; lane, double acceleration)
+waypoint_follower_msgs::lane apply_crossroad_acceleration(const waypoint_follower_msgs::lane&amp; lane, double acceleration)
 {
-	waypoint_follower::lane l = lane;
+	waypoint_follower_msgs::lane l = lane;
 
 	bool crossroad = false;
 	std::vector&lt;size_t&gt; start_indexes;
@@ -162,11 +162,11 @@ waypoint_follower::lane apply_crossroad_acceleration(const waypoint_follower::la
 	return l;
 }
 
-waypoint_follower::lane apply_stopline_acceleration(const waypoint_follower::lane&amp; lane, double acceleration,
+waypoint_follower_msgs::lane apply_stopline_acceleration(const waypoint_follower_msgs::lane&amp; lane, double acceleration,
 						    const lane_planner::vmap::VectorMap&amp; fine_vmap, size_t ahead_cnt,
 						    size_t behind_cnt)
 {
-	waypoint_follower::lane l = lane;
+	waypoint_follower_msgs::lane l = lane;
 
 	std::vector&lt;size_t&gt; indexes;
 	for (size_t i = 0; i &lt; fine_vmap.stoplines.size(); ++i) {
@@ -225,7 +225,7 @@ std::vector&lt;vector_map::Point&gt; create_stop_points(const lane_planner::vmap::Vect
 }
 
 std::vector&lt;size_t&gt; create_stop_indexes(const lane_planner::vmap::VectorMap&amp; vmap,
-					const waypoint_follower::lane&amp; lane, double stopline_search_radius)
+					const waypoint_follower_msgs::lane&amp; lane, double stopline_search_radius)
 {
 	std::vector&lt;size_t&gt; stop_indexes;
 	for (const vector_map::Point&amp; p : create_stop_points(vmap)) {
@@ -249,10 +249,10 @@ std::vector&lt;size_t&gt; create_stop_indexes(const lane_planner::vmap::VectorMap&amp; vma
 	return stop_indexes;
 }
 
-waypoint_follower::lane apply_stopline_acceleration(const waypoint_follower::lane&amp; lane, double acceleration,
+waypoint_follower_msgs::lane apply_stopline_acceleration(const waypoint_follower_msgs::lane&amp; lane, double acceleration,
 						    double stopline_search_radius, size_t ahead_cnt, size_t behind_cnt)
 {
-	waypoint_follower::lane l = lane;
+	waypoint_follower_msgs::lane l = lane;
 
 	std::vector&lt;size_t&gt; indexes = create_stop_indexes(lane_vmap, l, stopline_search_radius);
 	if (indexes.empty())
@@ -276,7 +276,7 @@ waypoint_follower::lane apply_stopline_acceleration(const waypoint_follower::lan
 	return l;
 }
 
-bool is_fine_vmap(const lane_planner::vmap::VectorMap&amp; fine_vmap, const waypoint_follower::lane&amp; lane)
+bool is_fine_vmap(const lane_planner::vmap::VectorMap&amp; fine_vmap, const waypoint_follower_msgs::lane&amp; lane)
 {
 	if (fine_vmap.points.size() != lane.waypoints.size())
 		return false;
@@ -366,7 +366,7 @@ std_msgs::ColorRGBA create_color(int index)
 }
 #endif // DEBUG
 
-void create_waypoint(const waypoint_follower::LaneArray&amp; msg)
+void create_waypoint(const waypoint_follower_msgs::LaneArray&amp; msg)
 {
 	std_msgs::Header header;
 	header.stamp = ros::Time::now();
@@ -374,7 +374,7 @@ void create_waypoint(const waypoint_follower::LaneArray&amp; msg)
 
 	cached_waypoint.lanes.clear();
 	cached_waypoint.lanes.shrink_to_fit();
-	for (const waypoint_follower::lane&amp; l : msg.lanes)
+	for (const waypoint_follower_msgs::lane&amp; l : msg.lanes)
 		cached_waypoint.lanes.push_back(create_new_lane(l, header));
 	if (all_vmap.points.empty() || all_vmap.lanes.empty() || all_vmap.nodes.empty() ||
 	    all_vmap.stoplines.empty() || all_vmap.dtlanes.empty()) {
@@ -386,11 +386,11 @@ void create_waypoint(const waypoint_follower::LaneArray&amp; msg)
 	marker_cnt = msg.lanes.size();
 #endif // DEBUG
 
-	waypoint_follower::LaneArray traffic_waypoint;
-	waypoint_follower::LaneArray red_waypoint;
-	waypoint_follower::LaneArray green_waypoint;
+	waypoint_follower_msgs::LaneArray traffic_waypoint;
+	waypoint_follower_msgs::LaneArray red_waypoint;
+	waypoint_follower_msgs::LaneArray green_waypoint;
 	for (size_t i = 0; i &lt; msg.lanes.size(); ++i) {
-		waypoint_follower::lane lane = create_new_lane(msg.lanes[i], header);
+		waypoint_follower_msgs::lane lane = create_new_lane(msg.lanes[i], header);
 
 		lane_planner::vmap::VectorMap coarse_vmap =
 			lane_planner::vmap::create_coarse_vmap_from_lane(lane);
@@ -488,7 +488,7 @@ void update_values()
 #endif // DEBUG
 
 	if (!cached_waypoint.lanes.empty()) {
-		waypoint_follower::LaneArray update_waypoint = cached_waypoint;
+		waypoint_follower_msgs::LaneArray update_waypoint = cached_waypoint;
 		create_waypoint(update_waypoint);
 	}
 }
@@ -531,7 +531,7 @@ void config_parameter(const runtime_manager::ConfigLaneRule&amp; msg)
 	config_number_of_zeros_behind = msg.number_of_zeros_behind;
 
 	if (!cached_waypoint.lanes.empty()) {
-		waypoint_follower::LaneArray update_waypoint = cached_waypoint;
+		waypoint_follower_msgs::LaneArray update_waypoint = cached_waypoint;
 		create_waypoint(update_waypoint);
 	}
 }
@@ -568,11 +568,11 @@ int main(int argc, char **argv)
 	n.param&lt;double&gt;(&quot;/lane_rule/clothoid_weight&quot;, clothoid_weight, 0.215);
 	n.param&lt;std::string&gt;(&quot;/lane_rule/frame_id&quot;, frame_id, &quot;map&quot;);
 
-	traffic_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/traffic_waypoints_array&quot;, pub_waypoint_queue_size,
+	traffic_pub = n.advertise&lt;waypoint_follower_msgs::LaneArray&gt;(&quot;/traffic_waypoints_array&quot;, pub_waypoint_queue_size,
 								pub_waypoint_latch);
-	red_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/red_waypoints_array&quot;, pub_waypoint_queue_size,
+	red_pub = n.advertise&lt;waypoint_follower_msgs::LaneArray&gt;(&quot;/red_waypoints_array&quot;, pub_waypoint_queue_size,
 							    pub_waypoint_latch);
-	green_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/green_waypoints_array&quot;, pub_waypoint_queue_size,
+	green_pub = n.advertise&lt;waypoint_follower_msgs::LaneArray&gt;(&quot;/green_waypoints_array&quot;, pub_waypoint_queue_size,
 							      pub_waypoint_latch);
 
 #ifdef DEBUG
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

// #define DEBUG

#ifdef DEBUG
#include &lt;sstream&gt;
#endif // DEBUG

#include &lt;ros/console.h&gt;

#include &lt;vector_map/vector_map.h&gt;
#include &lt;runtime_manager/ConfigLaneRule.h&gt;
#include &lt;waypoint_follower/LaneArray.h&gt;

#include &lt;lane_planner/vmap.hpp&gt;

namespace {

double config_acceleration = 1; // m/s^2
double config_stopline_search_radius = 1; // meter
int config_number_of_zeros_ahead = 0;
int config_number_of_zeros_behind = 0;

int waypoint_max;
double search_radius; // meter
double curve_weight;
double crossroad_weight;
double clothoid_weight;
std::string frame_id;

ros::Publisher traffic_pub;
ros::Publisher red_pub;
ros::Publisher green_pub;

lane_planner::vmap::VectorMap all_vmap;
lane_planner::vmap::VectorMap lane_vmap;
double curve_radius_min;
double crossroad_radius_min;
double clothoid_radius_min;
waypoint_follower::LaneArray cached_waypoint;

#ifdef DEBUG
visualization_msgs::Marker debug_marker;
ros::Publisher marker_pub;
int marker_cnt;
#endif // DEBUG

waypoint_follower::lane create_new_lane(const waypoint_follower::lane&amp; lane, const std_msgs::Header&amp; header)
{
	waypoint_follower::lane l = lane;
	l.header = header;

	for (waypoint_follower::waypoint&amp; w : l.waypoints) {
		w.pose.header = header;
		w.twist.header = header;
	}

	return l;
}

waypoint_follower::lane apply_acceleration(const waypoint_follower::lane&amp; lane, double acceleration,
					   size_t start_index, size_t fixed_cnt, double fixed_vel)
{
	waypoint_follower::lane l = lane;

	if (fixed_cnt == 0)
		return l;

	double square_vel = fixed_vel * fixed_vel;
	double distance = 0;
	for (size_t i = start_index; i &lt; l.waypoints.size(); ++i) {
		if (i - start_index &lt; fixed_cnt) {
			l.waypoints[i].twist.twist.linear.x = fixed_vel;
			continue;
		}

		geometry_msgs::Point a = l.waypoints[i - 1].pose.pose.position;
		geometry_msgs::Point b = l.waypoints[i].pose.pose.position;
		distance += hypot(b.x - a.x, b.y - a.y);

		double v = sqrt(square_vel + 2 * acceleration * distance);
		if (v &lt; l.waypoints[i].twist.twist.linear.x)
			l.waypoints[i].twist.twist.linear.x = v;
		else
			break;
	}

	return l;
}

waypoint_follower::lane apply_crossroad_acceleration(const waypoint_follower::lane&amp; lane, double acceleration)
{
	waypoint_follower::lane l = lane;

	bool crossroad = false;
	std::vector&lt;size_t&gt; start_indexes;
	std::vector&lt;size_t&gt; end_indexes;
	for (size_t i = 0; i &lt; l.waypoints.size(); ++i) {
		vector_map::DTLane dtlane = lane_planner::vmap::create_vector_map_dtlane(l.waypoints[i].dtlane);
		if (i == 0) {
			crossroad = lane_planner::vmap::is_crossroad_dtlane(dtlane);
			continue;
		}
		if (crossroad) {
			if (!lane_planner::vmap::is_crossroad_dtlane(dtlane)) {
				end_indexes.push_back(i - 1);
				crossroad = false;
			}
		} else {
			if (lane_planner::vmap::is_crossroad_dtlane(dtlane)) {
				start_indexes.push_back(i);
				crossroad = true;
			}
		}
	}
	if (start_indexes.empty() &amp;&amp; end_indexes.empty())
		return l;

	for (const size_t i : end_indexes)
		l = apply_acceleration(l, acceleration, i, 1, l.waypoints[i].twist.twist.linear.x);

	std::reverse(l.waypoints.begin(), l.waypoints.end());

	std::vector&lt;size_t&gt; reverse_start_indexes;
	for (const size_t i : start_indexes)
		reverse_start_indexes.push_back(l.waypoints.size() - i - 1);
	std::reverse(reverse_start_indexes.begin(), reverse_start_indexes.end());

	for (const size_t i : reverse_start_indexes)
		l = apply_acceleration(l, acceleration, i, 1, l.waypoints[i].twist.twist.linear.x);

	std::reverse(l.waypoints.begin(), l.waypoints.end());

	return l;
}

waypoint_follower::lane apply_stopline_acceleration(const waypoint_follower::lane&amp; lane, double acceleration,
						    const lane_planner::vmap::VectorMap&amp; fine_vmap, size_t ahead_cnt,
						    size_t behind_cnt)
{
	waypoint_follower::lane l = lane;

	std::vector&lt;size_t&gt; indexes;
	for (size_t i = 0; i &lt; fine_vmap.stoplines.size(); ++i) {
		if (fine_vmap.stoplines[i].id &gt;= 0)
			indexes.push_back(i);
	}
	if (indexes.empty())
		return l;

	for (const size_t i : indexes)
		l = apply_acceleration(l, acceleration, i, behind_cnt + 1, 0);

	std::reverse(l.waypoints.begin(), l.waypoints.end());

	std::vector&lt;size_t&gt; reverse_indexes;
	for (const size_t i : indexes)
		reverse_indexes.push_back(l.waypoints.size() - i - 1);
	std::reverse(reverse_indexes.begin(), reverse_indexes.end());

	for (const size_t i : reverse_indexes)
		l = apply_acceleration(l, acceleration, i, ahead_cnt + 1, 0);

	std::reverse(l.waypoints.begin(), l.waypoints.end());

	return l;
}

std::vector&lt;vector_map::Point&gt; create_stop_points(const lane_planner::vmap::VectorMap&amp; vmap)
{
	std::vector&lt;vector_map::Point&gt; stop_points;
	for (const vector_map::StopLine&amp; s : vmap.stoplines) {
		for (const vector_map::Lane&amp; l : vmap.lanes) {
			if (l.lnid != s.linkid)
				continue;
			for (const vector_map::Node&amp; n : vmap.nodes) {
				if (n.nid != l.bnid)
					continue;
				for (const vector_map::Point&amp; p : vmap.points) {
					if (p.pid != n.pid)
						continue;
					bool hit = false;
					for (const vector_map::Point&amp; sp : stop_points) {
						if (sp.pid == p.pid) {
							hit = true;
							break;
						}
					}
					if (!hit)
						stop_points.push_back(p);
				}
			}
		}
	}

	return stop_points;
}

std::vector&lt;size_t&gt; create_stop_indexes(const lane_planner::vmap::VectorMap&amp; vmap,
					const waypoint_follower::lane&amp; lane, double stopline_search_radius)
{
	std::vector&lt;size_t&gt; stop_indexes;
	for (const vector_map::Point&amp; p : create_stop_points(vmap)) {
		size_t index = SIZE_MAX;
		double distance = DBL_MAX;
		for (size_t i = 0; i &lt; lane.waypoints.size(); ++i) {
			vector_map::Point point =
				lane_planner::vmap::create_vector_map_point(lane.waypoints[i].pose.pose.position);
			double d = hypot(p.bx - point.bx, p.ly - point.ly);
			if (d &lt;= distance) {
				index = i;
				distance = d;
			}
		}
		if (index != SIZE_MAX &amp;&amp; distance &lt;= stopline_search_radius) {
			stop_indexes.push_back(index);
		}
	}
	std::sort(stop_indexes.begin(), stop_indexes.end());

	return stop_indexes;
}

waypoint_follower::lane apply_stopline_acceleration(const waypoint_follower::lane&amp; lane, double acceleration,
						    double stopline_search_radius, size_t ahead_cnt, size_t behind_cnt)
{
	waypoint_follower::lane l = lane;

	std::vector&lt;size_t&gt; indexes = create_stop_indexes(lane_vmap, l, stopline_search_radius);
	if (indexes.empty())
		return l;

	for (const size_t i : indexes)
		l = apply_acceleration(l, acceleration, i, behind_cnt + 1, 0);

	std::reverse(l.waypoints.begin(), l.waypoints.end());

	std::vector&lt;size_t&gt; reverse_indexes;
	for (const size_t i : indexes)
		reverse_indexes.push_back(l.waypoints.size() - i - 1);
	std::reverse(reverse_indexes.begin(), reverse_indexes.end());

	for (const size_t i : reverse_indexes)
		l = apply_acceleration(l, acceleration, i, ahead_cnt + 1, 0);

	std::reverse(l.waypoints.begin(), l.waypoints.end());

	return l;
}

bool is_fine_vmap(const lane_planner::vmap::VectorMap&amp; fine_vmap, const waypoint_follower::lane&amp; lane)
{
	if (fine_vmap.points.size() != lane.waypoints.size())
		return false;

	for (size_t i = 0; i &lt; fine_vmap.points.size(); ++i) {
		vector_map::Point point =
			lane_planner::vmap::create_vector_map_point(lane.waypoints[i].pose.pose.position);
		double distance = hypot(fine_vmap.points[i].bx - point.bx, fine_vmap.points[i].ly - point.ly);
		if (distance &gt; 0.1)
			return false;
	}

	return true;
}

double create_reduction(const lane_planner::vmap::VectorMap&amp; fine_vmap, int index)
{
	const vector_map::DTLane&amp; dtlane = fine_vmap.dtlanes[index];

	if (lane_planner::vmap::is_straight_dtlane(dtlane))
		return 1;

	if (lane_planner::vmap::is_curve_dtlane(dtlane)) {
		if (lane_planner::vmap::is_crossroad_dtlane(dtlane))
			return lane_planner::vmap::compute_reduction(dtlane, crossroad_radius_min * crossroad_weight);

		if (lane_planner::vmap::is_connection_dtlane(fine_vmap, index))
			return 1;

		return lane_planner::vmap::compute_reduction(dtlane, curve_radius_min * curve_weight);
	}

	if (lane_planner::vmap::is_clothoid_dtlane(dtlane))
		return lane_planner::vmap::compute_reduction(dtlane, clothoid_radius_min * clothoid_weight);

	return 1;
}

#ifdef DEBUG
std_msgs::ColorRGBA create_color(int index)
{
	std_msgs::ColorRGBA color;
	switch (index) {
	case 0:
		color.r = 0;
		color.g = 0;
		color.b = 0;
		break;
	case 1:
		color.r = 0;
		color.g = 0;
		color.b = 1;
		break;
	case 2:
		color.r = 0;
		color.g = 1;
		color.b = 0;
		break;
	case 3:
		color.r = 0;
		color.g = 1;
		color.b = 1;
		break;
	case 4:
		color.r = 1;
		color.g = 0;
		color.b = 0;
		break;
	case 5:
		color.r = 1;
		color.g = 0;
		color.b = 1;
		break;
	case 6:
		color.r = 1;
		color.g = 1;
		color.b = 0;
		break;
	default:
		color.r = 1;
		color.g = 1;
		color.b = 1;
	}
	color.a = 1;

	return color;
}
#endif // DEBUG

void create_waypoint(const waypoint_follower::LaneArray&amp; msg)
{
	std_msgs::Header header;
	header.stamp = ros::Time::now();
	header.frame_id = frame_id;

	cached_waypoint.lanes.clear();
	cached_waypoint.lanes.shrink_to_fit();
	for (const waypoint_follower::lane&amp; l : msg.lanes)
		cached_waypoint.lanes.push_back(create_new_lane(l, header));
	if (all_vmap.points.empty() || all_vmap.lanes.empty() || all_vmap.nodes.empty() ||
	    all_vmap.stoplines.empty() || all_vmap.dtlanes.empty()) {
		traffic_pub.publish(cached_waypoint);
		return;
	}

#ifdef DEBUG
	marker_cnt = msg.lanes.size();
#endif // DEBUG

	waypoint_follower::LaneArray traffic_waypoint;
	waypoint_follower::LaneArray red_waypoint;
	waypoint_follower::LaneArray green_waypoint;
	for (size_t i = 0; i &lt; msg.lanes.size(); ++i) {
		waypoint_follower::lane lane = create_new_lane(msg.lanes[i], header);

		lane_planner::vmap::VectorMap coarse_vmap =
			lane_planner::vmap::create_coarse_vmap_from_lane(lane);
		if (coarse_vmap.points.size() &lt; 2) {
			traffic_waypoint.lanes.push_back(lane);
			continue;
		}

		lane_planner::vmap::VectorMap fine_vmap =
			lane_planner::vmap::create_fine_vmap(lane_vmap, lane_planner::vmap::LNO_ALL, coarse_vmap,
							     search_radius, waypoint_max);
		if (fine_vmap.points.size() &lt; 2 || !is_fine_vmap(fine_vmap, lane)) {
			traffic_waypoint.lanes.push_back(lane);
			green_waypoint.lanes.push_back(lane);
			lane = apply_stopline_acceleration(lane, config_acceleration, config_stopline_search_radius,
							   config_number_of_zeros_ahead,
							   config_number_of_zeros_behind);
			red_waypoint.lanes.push_back(lane);
			continue;
		}

		for (size_t j = 0; j &lt; lane.waypoints.size(); ++j) {
			lane.waypoints[j].twist.twist.linear.x *= create_reduction(fine_vmap, j);
			if (fine_vmap.dtlanes[j].did &gt;= 0) {
				lane.waypoints[j].dtlane =
					lane_planner::vmap::create_waypoint_follower_dtlane(fine_vmap.dtlanes[j]);
			}
		}

		lane = apply_crossroad_acceleration(lane, config_acceleration);

		traffic_waypoint.lanes.push_back(lane);
		green_waypoint.lanes.push_back(lane);

		lane = apply_stopline_acceleration(lane, config_acceleration, fine_vmap, config_number_of_zeros_ahead,
						   config_number_of_zeros_behind);

		red_waypoint.lanes.push_back(lane);

#ifdef DEBUG
		std::stringstream ss;
		ss &lt;&lt; &quot;_&quot; &lt;&lt; i;

		visualization_msgs::Marker m = debug_marker;
		m.ns = &quot;lane&quot; + ss.str();
		m.color = create_color(i);

		lane_planner::vmap::publish_add_marker(marker_pub, m, fine_vmap.points);
#endif // DEBUG
	}

	traffic_pub.publish(traffic_waypoint);
	red_pub.publish(red_waypoint);
	green_pub.publish(green_waypoint);
}

void update_values()
{
	if (all_vmap.points.empty() || all_vmap.lanes.empty() || all_vmap.nodes.empty() ||
	    all_vmap.stoplines.empty() || all_vmap.dtlanes.empty())
		return;

	lane_vmap = lane_planner::vmap::create_lane_vmap(all_vmap, lane_planner::vmap::LNO_ALL);

	curve_radius_min = lane_planner::vmap::RADIUS_MAX;
	crossroad_radius_min = lane_planner::vmap::RADIUS_MAX;
	clothoid_radius_min = lane_planner::vmap::RADIUS_MAX;
	for (const vector_map::DTLane&amp; d : lane_vmap.dtlanes) {
		double radius_min = fabs(d.r);
		if (lane_planner::vmap::is_curve_dtlane(d)) {
			if (lane_planner::vmap::is_crossroad_dtlane(d)) {
				if (radius_min &lt; crossroad_radius_min)
					crossroad_radius_min = radius_min;
			} else {
				if (radius_min &lt; curve_radius_min)
					curve_radius_min = radius_min;
			}
		} else if (lane_planner::vmap::is_clothoid_dtlane(d)) {
			if (radius_min &lt; clothoid_radius_min)
				clothoid_radius_min = radius_min;
		}
	}

#ifdef DEBUG
	for (int i = 0; i &lt; marker_cnt; ++i) {
		std::stringstream ss;
		ss &lt;&lt; &quot;_&quot; &lt;&lt; i;

		visualization_msgs::Marker m = debug_marker;
		m.ns = &quot;lane&quot; + ss.str();

		lane_planner::vmap::publish_delete_marker(marker_pub, m);
	}
	marker_cnt = 0;
#endif // DEBUG

	if (!cached_waypoint.lanes.empty()) {
		waypoint_follower::LaneArray update_waypoint = cached_waypoint;
		create_waypoint(update_waypoint);
	}
}

void cache_point(const vector_map::PointArray&amp; msg)
{
	all_vmap.points = msg.data;
	update_values();
}

void cache_lane(const vector_map::LaneArray&amp; msg)
{
	all_vmap.lanes = msg.data;
	update_values();
}

void cache_node(const vector_map::NodeArray&amp; msg)
{
	all_vmap.nodes = msg.data;
	update_values();
}

void cache_stopline(const vector_map::StopLineArray&amp; msg)
{
	all_vmap.stoplines = msg.data;
	update_values();
}

void cache_dtlane(const vector_map::DTLaneArray&amp; msg)
{
	all_vmap.dtlanes = msg.data;
	update_values();
}

void config_parameter(const runtime_manager::ConfigLaneRule&amp; msg)
{
	config_acceleration = msg.acceleration;
	config_stopline_search_radius = msg.stopline_search_radius;
	config_number_of_zeros_ahead = msg.number_of_zeros_ahead;
	config_number_of_zeros_behind = msg.number_of_zeros_behind;

	if (!cached_waypoint.lanes.empty()) {
		waypoint_follower::LaneArray update_waypoint = cached_waypoint;
		create_waypoint(update_waypoint);
	}
}

} // namespace

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;lane_rule&quot;);

	ros::NodeHandle n;

	int sub_vmap_queue_size;
	n.param&lt;int&gt;(&quot;/lane_rule/sub_vmap_queue_size&quot;, sub_vmap_queue_size, 1);
	int sub_waypoint_queue_size;
	n.param&lt;int&gt;(&quot;/lane_rule/sub_waypoint_queue_size&quot;, sub_waypoint_queue_size, 1);
	int sub_config_queue_size;
	n.param&lt;int&gt;(&quot;/lane_rule/sub_config_queue_size&quot;, sub_config_queue_size, 1);
	int pub_waypoint_queue_size;
	n.param&lt;int&gt;(&quot;/lane_rule/pub_waypoint_queue_size&quot;, pub_waypoint_queue_size, 1);
	bool pub_waypoint_latch;
	n.param&lt;bool&gt;(&quot;/lane_rule/pub_waypoint_latch&quot;, pub_waypoint_latch, true);
#ifdef DEBUG
	int pub_marker_queue_size;
	n.param&lt;int&gt;(&quot;/lane_rule/pub_marker_queue_size&quot;, pub_marker_queue_size, 10);
	bool pub_marker_latch;
	n.param&lt;bool&gt;(&quot;/lane_rule/pub_marker_latch&quot;, pub_marker_latch, true);
#endif // DEBUG

	n.param&lt;int&gt;(&quot;/lane_rule/waypoint_max&quot;, waypoint_max, 10000);
	n.param&lt;double&gt;(&quot;/lane_rule/search_radius&quot;, search_radius, 10);
	n.param&lt;double&gt;(&quot;/lane_rule/curve_weight&quot;, curve_weight, 0.6);
	n.param&lt;double&gt;(&quot;/lane_rule/crossroad_weight&quot;, crossroad_weight, 0.9);
	n.param&lt;double&gt;(&quot;/lane_rule/clothoid_weight&quot;, clothoid_weight, 0.215);
	n.param&lt;std::string&gt;(&quot;/lane_rule/frame_id&quot;, frame_id, &quot;map&quot;);

	traffic_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/traffic_waypoints_array&quot;, pub_waypoint_queue_size,
								pub_waypoint_latch);
	red_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/red_waypoints_array&quot;, pub_waypoint_queue_size,
							    pub_waypoint_latch);
	green_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/green_waypoints_array&quot;, pub_waypoint_queue_size,
							      pub_waypoint_latch);

#ifdef DEBUG
	debug_marker.header.frame_id = frame_id;
	debug_marker.id = 0;
	debug_marker.type = visualization_msgs::Marker::LINE_STRIP;
	debug_marker.scale.x = 0.2;
	debug_marker.scale.y = 0.2;
	debug_marker.frame_locked = true;

	marker_pub = n.advertise&lt;visualization_msgs::Marker&gt;(&quot;/waypoint_debug&quot;, pub_marker_queue_size,
							     pub_marker_latch);
#endif // DEBUG

	ros::Subscriber waypoint_sub = n.subscribe(&quot;/lane_waypoints_array&quot;, sub_waypoint_queue_size, create_waypoint);
	ros::Subscriber point_sub = n.subscribe(&quot;/vector_map_info/point&quot;, sub_vmap_queue_size, cache_point);
	ros::Subscriber lane_sub = n.subscribe(&quot;/vector_map_info/lane&quot;, sub_vmap_queue_size, cache_lane);
	ros::Subscriber node_sub = n.subscribe(&quot;/vector_map_info/node&quot;, sub_vmap_queue_size, cache_node);
	ros::Subscriber stopline_sub = n.subscribe(&quot;/vector_map_info/stop_line&quot;, sub_vmap_queue_size, cache_stopline);
	ros::Subscriber dtlane_sub = n.subscribe(&quot;/vector_map_info/dtlane&quot;, sub_vmap_queue_size, cache_dtlane);
	ros::Subscriber config_sub = n.subscribe(&quot;/config/lane_rule&quot;, sub_config_queue_size, config_parameter);

	ros::spin();

	return EXIT_SUCCESS;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.cpp">
				<diff>@@ -50,11 +50,11 @@ void getPointAndVectorFromPose(const geometry_msgs::Pose &amp;pose, Element2D *point
   vector-&gt;set(tmp_tf_vevtor.getX(), tmp_tf_vevtor.getY());
 }
 
-std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start,
+std::vector&lt;waypoint_follower_msgs::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start,
                                                                     const geometry_msgs::Pose &amp;end,
                                                                     const double velocity_mps, const double vlength)
 {
-  std::vector&lt;waypoint_follower::waypoint&gt; wps;
+  std::vector&lt;waypoint_follower_msgs::waypoint&gt; wps;
   Element2D p0(0, 0), v0(0, 0), p1(0, 0), v1(0, 0);
   getPointAndVectorFromPose(start, &amp;p0, &amp;v0);
   getPointAndVectorFromPose(end, &amp;p1, &amp;v1);
@@ -64,7 +64,7 @@ std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geomet
   double height_d = fabs(start.position.z - end.position.z);
   for (uint32_t i = 0; i &lt; result.size(); i++)
   {
-    waypoint_follower::waypoint wp;
+    waypoint_follower_msgs::waypoint wp;
     wp.pose.pose.position.x = result.at(i).x;
     wp.pose.pose.position.y = result.at(i).y;
     wp.twist.twist.linear.x = velocity_mps;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;hermite_curve.h&quot;

namespace lane_planner
{
void createVectorFromPose(const geometry_msgs::Pose &amp;p, tf::Vector3 *v)
{
  tf::Transform pose;
  tf::poseMsgToTF(p, pose);
  tf::Vector3 x_axis(1, 0, 0);
  *v = pose.getBasis() * x_axis;
}

void getPointAndVectorFromPose(const geometry_msgs::Pose &amp;pose, Element2D *point, Element2D *vector)
{
  point-&gt;set(pose.position.x, pose.position.y);

  tf::Vector3 tmp_tf_vevtor;
  createVectorFromPose(pose, &amp;tmp_tf_vevtor);
  vector-&gt;set(tmp_tf_vevtor.getX(), tmp_tf_vevtor.getY());
}

std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start,
                                                                    const geometry_msgs::Pose &amp;end,
                                                                    const double velocity_mps, const double vlength)
{
  std::vector&lt;waypoint_follower::waypoint&gt; wps;
  Element2D p0(0, 0), v0(0, 0), p1(0, 0), v1(0, 0);
  getPointAndVectorFromPose(start, &amp;p0, &amp;v0);
  getPointAndVectorFromPose(end, &amp;p1, &amp;v1);

  std::vector&lt;Element2D&gt; result = generateHermiteCurve(p0, v0, p1, v1, vlength);

  double height_d = fabs(start.position.z - end.position.z);
  for (uint32_t i = 0; i &lt; result.size(); i++)
  {
    waypoint_follower::waypoint wp;
    wp.pose.pose.position.x = result.at(i).x;
    wp.pose.pose.position.y = result.at(i).y;
    wp.twist.twist.linear.x = velocity_mps;

    // height
    wp.pose.pose.position.z = (i == 0) ? start.position.z : (i == result.size() - 1)
                                       ? end.position.z : start.position.z &lt; end.position.z
                                       ? start.position.z + height_d * i / result.size()
                                       : start.position.z - height_d * i / result.size();

    // orientation
    if (i != result.size() - 1)
    {
      double radian = atan2(result.at(i + 1).y - result.at(i).y, result.at(i + 1).x - result.at(i).x);
      wp.pose.pose.orientation = tf::createQuaternionMsgFromYaw(radian);
    }
    else
    {
      wp.pose.pose.orientation = wps.at(wps.size() - 1).pose.pose.orientation;
    }

    wps.push_back(wp);
  }
  return wps;
}

std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1,
                                            const Element2D &amp;v1, const double vlength)
{
  std::vector&lt;Element2D&gt; result;
  const double interval = 1.0;
  int32_t divide = 2;
  const int32_t loop = 100;
  while (divide &lt; loop)
  {
    result.reserve(divide);
    for (int32_t i = 0; i &lt; divide; i++)
    {
      double u = i * 1.0 / (divide - 1);
      double u_square = pow(u, 2);
      double u_cube = pow(u, 3);
      double coeff_p0 = 2 * u_cube - 3 * u_square + 1;
      double coeff_v0 = u_cube - 2 * u_square + u;
      double coeff_p1 = (-1) * 2 * u_cube + 3 * u_square;
      double coeff_v1 = u_cube - u_square;
      // printf(&quot;u: %lf, u^2: %lf, u^3: %lf, coeff_p0: %lf, coeff_v0: %lf, coeff_p1: %lf, coeff_v1: %lf\n&quot;, u, u_square,
      // u_cube, coeff_p0, coeff_p1, coeff_v0, coeff_v1);
      result.push_back(
          Element2D((p0.x * coeff_p0 + vlength * v0.x * coeff_v0 + p1.x * coeff_p1 + vlength * v1.x * coeff_v1),
                    (p0.y * coeff_p0 + vlength * v0.y * coeff_v0 + p1.y * coeff_p1 + vlength * v1.y * coeff_v1)));
    }

    double dt = sqrt(pow((result.at(divide / 2 - 1).x - result.at(divide / 2).x), 2) +
                     pow((result.at(divide / 2 - 1).y - result.at(divide / 2).y), 2));
    std::cout &lt;&lt; &quot;interval : &quot; &lt;&lt; dt &lt;&lt; std::endl;
    if (interval &gt; dt || divide == loop - 1)
      return result;
    else
    {
      result.clear();
      result.shrink_to_fit();
      divide++;
    }
  }
  return result;
}
}  // namespace
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.h" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/hermite_curve.h">
				<diff>@@ -43,7 +43,8 @@
 #include &lt;tf/transform_datatypes.h&gt;
 #include &lt;geometry_msgs/Pose.h&gt;
 
-#include &quot;waypoint_follower/lane.h&quot;
+#include &quot;waypoint_follower_msgs/lane.h&quot;
+#include &quot;waypoint_follower_msgs/waypoint.h&quot;
 
 namespace lane_planner
 {
@@ -65,7 +66,7 @@ struct Element2D
 
 std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1,
                                             const Element2D &amp;v1, const double vlength = 20);
-std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start,
+std::vector&lt;waypoint_follower_msgs::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start,
                                                                     const geometry_msgs::Pose &amp;end,
                                                                     const double velocity, const double vlength);
 void createVectorFromPose(const geometry_msgs::Pose &amp;p, tf::Vector3 *v);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef HERMITE_CURVE_H
#define HERMITE_CURVE_H

// C++ includes
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;cmath&gt;
#include &lt;cstdio&gt;

// ROS includes
#include &lt;ros/ros.h&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;geometry_msgs/Pose.h&gt;

#include &quot;waypoint_follower/lane.h&quot;

namespace lane_planner
{
struct Element2D
{
  Element2D(double x, double y)
  {
    this-&gt;x = x;
    this-&gt;y = y;
  }
  void set(double x, double y)
  {
    this-&gt;x = x;
    this-&gt;y = y;
  }
  double x;
  double y;
};

std::vector&lt;Element2D&gt; generateHermiteCurve(const Element2D &amp;p0, const Element2D &amp;v0, const Element2D &amp;p1,
                                            const Element2D &amp;v1, const double vlength = 20);
std::vector&lt;waypoint_follower::waypoint&gt; generateHermiteCurveForROS(const geometry_msgs::Pose &amp;start,
                                                                    const geometry_msgs::Pose &amp;end,
                                                                    const double velocity, const double vlength);
void createVectorFromPose(const geometry_msgs::Pose &amp;p, tf::Vector3 *v);
}  // namespace
#endif  // HERMITE_CURVE_H
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.cpp">
				<diff>@@ -69,7 +69,7 @@ void LaneSelectNode::initForROS()
   sub5_ = nh_.subscribe(&quot;/config/lane_select&quot;, 1, &amp;LaneSelectNode::callbackFromConfig, this);
 
   // setup publisher
-  pub1_ = nh_.advertise&lt;waypoint_follower::lane&gt;(&quot;base_waypoints&quot;, 1);
+  pub1_ = nh_.advertise&lt;waypoint_follower_msgs::lane&gt;(&quot;base_waypoints&quot;, 1);
   pub2_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 1);
   pub3_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;change_flag&quot;, 1);
   vis_pub1_ = nh_.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;lane_select_marker&quot;, 1);
@@ -183,7 +183,7 @@ void LaneSelectNode::processing()
   resetSubscriptionFlag();
 }
 
-int32_t LaneSelectNode::getClosestLaneChangeWaypointNumber(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, int32_t cl_wp)
+int32_t LaneSelectNode::getClosestLaneChangeWaypointNumber(const std::vector&lt;waypoint_follower_msgs::waypoint&gt; &amp;wps, int32_t cl_wp)
 {
 
   for (uint32_t i = cl_wp; i &lt; wps.size(); i++)
@@ -203,7 +203,7 @@ void LaneSelectNode::createLaneForChange()
   std::get&lt;0&gt;(lane_for_change_).waypoints.shrink_to_fit();
   std::get&lt;1&gt;(lane_for_change_) = -1;
 
-  const waypoint_follower::lane &amp;cur_lane = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_));
+  const waypoint_follower_msgs::lane &amp;cur_lane = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_));
   const int32_t &amp;clst_wp = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
 
   int32_t num_lane_change = getClosestLaneChangeWaypointNumber(cur_lane.waypoints, clst_wp);
@@ -229,7 +229,7 @@ void LaneSelectNode::createLaneForChange()
                          ? current_velocity_.twist.linear.x * lane_change_target_ratio_
                          : lane_change_target_minimum_;
   ROS_INFO(&quot;dt : %lf, dt_by_vel : %lf&quot;, dt, dt_by_vel);
-  waypoint_follower::lane &amp;nghbr_lane =
+  waypoint_follower_msgs::lane &amp;nghbr_lane =
       static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
           ? std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_))
           : std::get&lt;0&gt;(tuple_vec_.at(left_lane_idx_));
@@ -255,7 +255,7 @@ void LaneSelectNode::createLaneForChange()
     return;
 
   std::get&lt;0&gt;(lane_for_change_).header.stamp = nghbr_lane.header.stamp;
-  std::vector&lt;waypoint_follower::waypoint&gt; hermite_wps = generateHermiteCurveForROS(
+  std::vector&lt;waypoint_follower_msgs::waypoint&gt; hermite_wps = generateHermiteCurveForROS(
       cur_lane.waypoints.at(num_lane_change).pose.pose, nghbr_lane.waypoints.at(target_num).pose.pose,
       cur_lane.waypoints.at(num_lane_change).twist.twist.linear.x, vlength_hermite_curve_);
 
@@ -582,7 +582,7 @@ void LaneSelectNode::publishVisualizer()
   vis_pub1_.publish(marker_array);
 }
 
-void LaneSelectNode::publishLane(const waypoint_follower::lane &amp;lane)
+void LaneSelectNode::publishLane(const waypoint_follower_msgs::lane &amp;lane)
 {
   // publish global lane
   pub1_.publish(lane);
@@ -603,7 +603,7 @@ void LaneSelectNode::publishChangeFlag(const ChangeFlag flag)
   pub3_.publish(change_flag);
 }
 
-void LaneSelectNode::callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg)
+void LaneSelectNode::callbackFromLaneArray(const waypoint_follower_msgs::LaneArrayConstPtr &amp;msg)
 {
   tuple_vec_.clear();
   tuple_vec_.shrink_to_fit();
@@ -728,7 +728,7 @@ double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry
 }
 
 // get closest waypoint from current pose
-int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
+int32_t getClosestWaypointNumber(const waypoint_follower_msgs::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                  const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number,
                                  const double distance_threshold)
 {
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;lane_select_core.h&quot;

namespace lane_planner
{
// Constructor
LaneSelectNode::LaneSelectNode()
  : private_nh_(&quot;~&quot;)
  , current_lane_idx_(-1)
  , right_lane_idx_(-1)
  , left_lane_idx_(-1)
  , is_lane_array_subscribed_(false)
  , is_current_pose_subscribed_(false)
  , is_current_velocity_subscribed_(false)
  , is_current_state_subscribed_(false)
  , is_config_subscribed_(false)
  , distance_threshold_(3.0)
  , lane_change_interval_(10.0)
  , lane_change_target_ratio_(2.0)
  , lane_change_target_minimum_(5.0)
  , vlength_hermite_curve_(10)
  , current_state_(&quot;UNKNOWN&quot;)
{
  initForROS();
}

// Destructor
LaneSelectNode::~LaneSelectNode()
{
}

void LaneSelectNode::initForROS()
{
  // setup subscriber
  sub1_ = nh_.subscribe(&quot;traffic_waypoints_array&quot;, 1, &amp;LaneSelectNode::callbackFromLaneArray, this);
  sub2_ = nh_.subscribe(&quot;current_pose&quot;, 1, &amp;LaneSelectNode::callbackFromPoseStamped, this);
  sub3_ = nh_.subscribe(&quot;current_velocity&quot;, 1, &amp;LaneSelectNode::callbackFromTwistStamped, this);
  sub4_ = nh_.subscribe(&quot;state&quot;, 1, &amp;LaneSelectNode::callbackFromState, this);
  sub5_ = nh_.subscribe(&quot;/config/lane_select&quot;, 1, &amp;LaneSelectNode::callbackFromConfig, this);

  // setup publisher
  pub1_ = nh_.advertise&lt;waypoint_follower::lane&gt;(&quot;base_waypoints&quot;, 1);
  pub2_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 1);
  pub3_ = nh_.advertise&lt;std_msgs::Int32&gt;(&quot;change_flag&quot;, 1);
  vis_pub1_ = nh_.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;lane_select_marker&quot;, 1);

  // get from rosparam
  private_nh_.param&lt;double&gt;(&quot;lane_change_interval&quot;, lane_change_interval_, double(2));
  private_nh_.param&lt;double&gt;(&quot;distance_threshold&quot;, distance_threshold_, double(3.0));
}

bool LaneSelectNode::isAllTopicsSubscribed()
{
  if (!is_current_pose_subscribed_ || !is_lane_array_subscribed_ || !is_current_velocity_subscribed_)
  {
    ROS_WARN(&quot;Necessary topics are not subscribed yet. Waiting...&quot;);
    return false;
  }
  return true;
}

void LaneSelectNode::initForLaneSelect()
{
  if(!isAllTopicsSubscribed())
    return;

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    publishClosestWaypoint(-1);
    resetLaneIdx();
    return;
  }

  findCurrentLane();
  findNeighborLanes();
  updateChangeFlag();
  createLaneForChange();

  publishLane(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)));
  publishClosestWaypoint(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)));
  publishChangeFlag(std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)));
  publishVisualizer();

  resetSubscriptionFlag();
  return;
}

void LaneSelectNode::resetLaneIdx()
{
  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  publishVisualizer();
}

void LaneSelectNode::resetSubscriptionFlag()
{
  is_current_pose_subscribed_ = false;
  is_current_velocity_subscribed_ = false;
  is_current_state_subscribed_ = false;
}

void LaneSelectNode::processing()
{
  if(!isAllTopicsSubscribed())
    return;

  // search closest waypoint number for each lanes
  if (!getClosestWaypointNumberForEachLanes())
  {
    publishClosestWaypoint(-1);
    resetLaneIdx();
    return;
  }

  // if closest waypoint on current lane is -1,
  if (std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)) == -1)
  {
    publishClosestWaypoint(-1);
    resetLaneIdx();
    return;
  }

  findNeighborLanes();
  ROS_INFO(&quot;current_lane_idx: %d&quot;, current_lane_idx_);
  ROS_INFO(&quot;right_lane_idx: %d&quot;, right_lane_idx_);
  ROS_INFO(&quot;left_lane_idx: %d&quot;, left_lane_idx_);

  if (current_state_ == &quot;LANE_CHANGE&quot;)
  {
    changeLane();
    std::get&lt;1&gt;(lane_for_change_) =
        getClosestWaypointNumber(std::get&lt;0&gt;(lane_for_change_), current_pose_.pose, current_velocity_.twist,
                                 std::get&lt;1&gt;(lane_for_change_), distance_threshold_);
    std::get&lt;2&gt;(lane_for_change_) =
        static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(lane_for_change_).waypoints.at(std::get&lt;1&gt;(lane_for_change_)).change_flag);
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(lane_for_change_));
    publishLane(std::get&lt;0&gt;(lane_for_change_));
    publishClosestWaypoint(std::get&lt;1&gt;(lane_for_change_));
    publishChangeFlag(std::get&lt;2&gt;(lane_for_change_));
  }
  else
  {
    updateChangeFlag();
    createLaneForChange();

    publishLane(std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)));
    publishClosestWaypoint(std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_)));
    publishChangeFlag(std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)));
  }
  publishVisualizer();
  resetSubscriptionFlag();
}

int32_t LaneSelectNode::getClosestLaneChangeWaypointNumber(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, int32_t cl_wp)
{

  for (uint32_t i = cl_wp; i &lt; wps.size(); i++)
  {
    if (static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::right ||
      static_cast&lt;ChangeFlag&gt;(wps.at(i).change_flag) == ChangeFlag::left)
    {
      return i;
    }
  }
  return -1;
}

void LaneSelectNode::createLaneForChange()
{
  std::get&lt;0&gt;(lane_for_change_).waypoints.clear();
  std::get&lt;0&gt;(lane_for_change_).waypoints.shrink_to_fit();
  std::get&lt;1&gt;(lane_for_change_) = -1;

  const waypoint_follower::lane &amp;cur_lane = std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_));
  const int32_t &amp;clst_wp = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));

  int32_t num_lane_change = getClosestLaneChangeWaypointNumber(cur_lane.waypoints, clst_wp);
  ROS_INFO(&quot;num_lane_change: %d&quot;, num_lane_change);
  if (num_lane_change &lt; 0 || num_lane_change &gt;= static_cast&lt;int32_t&gt;(cur_lane.waypoints.size()))
  {
    ROS_WARN(&quot;current lane doesn't have change flag&quot;);
    return;
  }

  if ((static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right &amp;&amp;
       right_lane_idx_ &lt; 0) ||
      (static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::left &amp;&amp;
       left_lane_idx_ &lt; 0))
  {
    ROS_WARN(&quot;current lane doesn't have the lane for lane change&quot;);
    return;
  }

  double dt = getTwoDimensionalDistance(cur_lane.waypoints.at(num_lane_change).pose.pose.position,
                                        cur_lane.waypoints.at(clst_wp).pose.pose.position);
  double dt_by_vel = current_velocity_.twist.linear.x * lane_change_target_ratio_ &gt; lane_change_target_minimum_
                         ? current_velocity_.twist.linear.x * lane_change_target_ratio_
                         : lane_change_target_minimum_;
  ROS_INFO(&quot;dt : %lf, dt_by_vel : %lf&quot;, dt, dt_by_vel);
  waypoint_follower::lane &amp;nghbr_lane =
      static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
          ? std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_))
          : std::get&lt;0&gt;(tuple_vec_.at(left_lane_idx_));
  const int32_t &amp;nghbr_clst_wp =
      static_cast&lt;ChangeFlag&gt;(cur_lane.waypoints.at(num_lane_change).change_flag) == ChangeFlag::right
          ? std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_))
          : std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_));

  int32_t target_num = -1;
  for (uint32_t i = nghbr_clst_wp; i &lt; nghbr_lane.waypoints.size(); i++)
  {
    if (i == nghbr_lane.waypoints.size() - 1 ||
        dt + dt_by_vel &lt; getTwoDimensionalDistance(nghbr_lane.waypoints.at(nghbr_clst_wp).pose.pose.position,
                                                   nghbr_lane.waypoints.at(i).pose.pose.position))
    {
      target_num = i;
      break;
    }
  }

  ROS_INFO(&quot;target_num : %d&quot;, target_num);
  if (target_num &lt; 0)
    return;

  std::get&lt;0&gt;(lane_for_change_).header.stamp = nghbr_lane.header.stamp;
  std::vector&lt;waypoint_follower::waypoint&gt; hermite_wps = generateHermiteCurveForROS(
      cur_lane.waypoints.at(num_lane_change).pose.pose, nghbr_lane.waypoints.at(target_num).pose.pose,
      cur_lane.waypoints.at(num_lane_change).twist.twist.linear.x, vlength_hermite_curve_);

  for (auto &amp;&amp;el : hermite_wps)
    el.change_flag = cur_lane.waypoints.at(num_lane_change).change_flag;

  std::get&lt;0&gt;(lane_for_change_).waypoints.reserve(nghbr_lane.waypoints.size() + hermite_wps.size());
  std::move(hermite_wps.begin(), hermite_wps.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
  auto itr = nghbr_lane.waypoints.begin();
  std::advance(itr, target_num);
  for (auto i = itr; i != nghbr_lane.waypoints.end(); i++)
  {
    if (getTwoDimensionalDistance(itr-&gt;pose.pose.position, i-&gt;pose.pose.position) &lt; lane_change_interval_)
      i-&gt;change_flag = enumToInteger(ChangeFlag::straight);
    else
      break;
  }
  std::copy(itr, nghbr_lane.waypoints.end(), std::back_inserter(std::get&lt;0&gt;(lane_for_change_).waypoints));
}

void LaneSelectNode::updateChangeFlag()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;2&gt;(el) = (std::get&lt;1&gt;(el) != -1)
                          ? static_cast&lt;ChangeFlag&gt;(std::get&lt;0&gt;(el).waypoints.at(std::get&lt;1&gt;(el)).change_flag)
                          : ChangeFlag::unknown;

    if(std::get&lt;2&gt;(el) == ChangeFlag::right &amp;&amp; right_lane_idx_ == -1)
      std::get&lt;2&gt;(el) = ChangeFlag::unknown;
    else if(std::get&lt;2&gt;(el) == ChangeFlag::left &amp;&amp; left_lane_idx_ == -1)
      std::get&lt;2&gt;(el) = ChangeFlag::unknown;

    ROS_INFO(&quot;change_flag: %d&quot;, enumToInteger(std::get&lt;2&gt;(el)));
  }
}

void LaneSelectNode::changeLane()
{
  if (std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)) == ChangeFlag::right &amp;&amp; right_lane_idx_ != -1 &amp;&amp;
      std::get&lt;1&gt;(tuple_vec_.at(right_lane_idx_)) != -1)
  {
    current_lane_idx_ = right_lane_idx_;
  }
  else if (std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_)) == ChangeFlag::left &amp;&amp; left_lane_idx_ != -1 &amp;&amp;
           std::get&lt;1&gt;(tuple_vec_.at(left_lane_idx_)) != -1)
  {
    current_lane_idx_ = left_lane_idx_;
  }

  findNeighborLanes();
  return;
}

bool LaneSelectNode::getClosestWaypointNumberForEachLanes()
{
  for (auto &amp;el : tuple_vec_)
  {
    std::get&lt;1&gt;(el) = getClosestWaypointNumber(std::get&lt;0&gt;(el), current_pose_.pose, current_velocity_.twist,
                                               std::get&lt;1&gt;(el), distance_threshold_);
    ROS_INFO(&quot;closest: %d&quot;, std::get&lt;1&gt;(el));
  }

  // confirm if all closest waypoint numbers are -1. If so, output warning
  int32_t accum = 0;
  for (const auto &amp;el : tuple_vec_)
  {
    accum += std::get&lt;1&gt;(el);
  }
  if (accum == (-1) * static_cast&lt;int32_t&gt;(tuple_vec_.size()))
  {
    ROS_WARN(&quot;Cannot get closest waypoints. All closest waypoints are changed to -1...&quot;);
    return false;
  }

  return true;
}

void LaneSelectNode::findCurrentLane()
{
  std::vector&lt;uint32_t&gt; idx_vec;
  idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;
    idx_vec.push_back(i);
  }
  current_lane_idx_ = findMostClosestLane(idx_vec, current_pose_.pose.position);
}

int32_t LaneSelectNode::findMostClosestLane(const std::vector&lt;uint32_t&gt; idx_vec, const geometry_msgs::Point p)
{
  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    int32_t closest_number = std::get&lt;1&gt;(tuple_vec_.at(el));
    dist_vec.push_back(
        getTwoDimensionalDistance(p, std::get&lt;0&gt;(tuple_vec_.at(el)).waypoints.at(closest_number).pose.pose.position));
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  return idx_vec.at(std::distance(dist_vec.begin(), itr));
}

void LaneSelectNode::findNeighborLanes()
{
  int32_t current_closest_num = std::get&lt;1&gt;(tuple_vec_.at(current_lane_idx_));
  const geometry_msgs::Pose &amp;current_closest_pose =
      std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.at(current_closest_num).pose.pose;

  std::vector&lt;uint32_t&gt; left_lane_idx_vec;
  left_lane_idx_vec.reserve(tuple_vec_.size());
  std::vector&lt;uint32_t&gt; right_lane_idx_vec;
  right_lane_idx_vec.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (i == static_cast&lt;uint32_t&gt;(current_lane_idx_) || std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    int32_t target_num = std::get&lt;1&gt;(tuple_vec_.at(i));
    const geometry_msgs::Point &amp;target_p = std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(target_num).pose.pose.position;

    geometry_msgs::Point converted_p = convertPointIntoRelativeCoordinate(target_p, current_closest_pose);

    ROS_INFO(&quot;distance: %lf&quot;, converted_p.y);
    if (fabs(converted_p.y) &gt; distance_threshold_)
    {
      ROS_INFO(&quot;%d lane is far from current lane...&quot;, i);
      continue;
    }

    if (converted_p.y &gt; 0)
      left_lane_idx_vec.push_back(i);
    else
      right_lane_idx_vec.push_back(i);
  }

  if (!left_lane_idx_vec.empty())
    left_lane_idx_ = findMostClosestLane(left_lane_idx_vec, current_closest_pose.position);
  else
    left_lane_idx_ = -1;

  if (!right_lane_idx_vec.empty())
    right_lane_idx_ = findMostClosestLane(right_lane_idx_vec, current_closest_pose.position);
  else
    right_lane_idx_ = -1;
}
visualization_msgs::Marker LaneSelectNode::createCurrentLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;current_lane_marker&quot;;

  if (current_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;
  marker.color = color_current;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createRightLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;right_lane_marker&quot;;

  if (right_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker.color = change_flag == ChangeFlag::right ? color_neighbor_change : color_neighbor;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at(right_lane_idx_)).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createLeftLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;left_lane_marker&quot;;

  if (left_lane_idx_ == -1 || std::get&lt;0&gt;(tuple_vec_.at(current_lane_idx_)).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color_neighbor;
  color_neighbor.r = 0.5;
  color_neighbor.b = 0.5;
  color_neighbor.g = 0.5;
  color_neighbor.a = 1.0;

  std_msgs::ColorRGBA color_neighbor_change;
  color_neighbor_change.b = 0.7;
  color_neighbor_change.g = 1.0;
  color_neighbor_change.a = 1.0;

  const ChangeFlag &amp;change_flag = std::get&lt;2&gt;(tuple_vec_.at(current_lane_idx_));
  marker.color = change_flag == ChangeFlag::left ? color_neighbor_change : color_neighbor;

  for(const auto &amp;em : std::get&lt;0&gt;(tuple_vec_.at((left_lane_idx_))).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createChangeLaneMarker()
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;change_lane_marker&quot;;

  if (std::get&lt;0&gt;(lane_for_change_).waypoints.empty())
  {
    marker.action = visualization_msgs::Marker::DELETE;
    return marker;
  }

  marker.type = visualization_msgs::Marker::LINE_STRIP;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.05;

  std_msgs::ColorRGBA color;
  color.r = 1.0;
  color.a = 1.0;

  std_msgs::ColorRGBA color_current;
  color_current.b = 1.0;
  color_current.g = 0.7;
  color_current.a = 1.0;

  marker.color = current_state_ == &quot;LANE_CHANGE&quot; ? color_current : color;
  for(const auto &amp;em : std::get&lt;0&gt;(lane_for_change_).waypoints)
    marker.points.push_back(em.pose.pose.position);

  return marker;
}

visualization_msgs::Marker LaneSelectNode::createClosestWaypointsMarker()
{
  visualization_msgs::Marker marker;
  std_msgs::ColorRGBA color_closest_wp;
  color_closest_wp.r = 1.0;
  color_closest_wp.b = 1.0;
  color_closest_wp.g = 1.0;
  color_closest_wp.a = 1.0;

  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;closest_waypoints_marker&quot;;
  marker.type = visualization_msgs::Marker::POINTS;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.x = 0.5;
  marker.color = color_closest_wp;

  marker.points.reserve(tuple_vec_.size());
  for (uint32_t i = 0; i &lt; tuple_vec_.size(); i++)
  {
    if (std::get&lt;1&gt;(tuple_vec_.at(i)) == -1)
      continue;

    marker.points.push_back(
        std::get&lt;0&gt;(tuple_vec_.at(i)).waypoints.at(std::get&lt;1&gt;(tuple_vec_.at(i))).pose.pose.position);
  }

  return marker;
}

void LaneSelectNode::publishVisualizer()
{
  visualization_msgs::MarkerArray marker_array;
  marker_array.markers.push_back(createChangeLaneMarker());
  marker_array.markers.push_back(createCurrentLaneMarker());
  marker_array.markers.push_back(createRightLaneMarker());
  marker_array.markers.push_back(createLeftLaneMarker());
  marker_array.markers.push_back(createClosestWaypointsMarker());

  vis_pub1_.publish(marker_array);
}

void LaneSelectNode::publishLane(const waypoint_follower::lane &amp;lane)
{
  // publish global lane
  pub1_.publish(lane);
}

void LaneSelectNode::publishClosestWaypoint(const int32_t clst_wp)
{
  // publish closest waypoint
  std_msgs::Int32 closest_waypoint;
  closest_waypoint.data = clst_wp;
  pub2_.publish(closest_waypoint);
}

void LaneSelectNode::publishChangeFlag(const ChangeFlag flag)
{
  std_msgs::Int32 change_flag;
  change_flag.data = enumToInteger(flag);
  pub3_.publish(change_flag);
}

void LaneSelectNode::callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg)
{
  tuple_vec_.clear();
  tuple_vec_.shrink_to_fit();
  tuple_vec_.reserve(msg-&gt;lanes.size());
  for (const auto &amp;el : msg-&gt;lanes)
  {
    auto t = std::make_tuple(el, -1, ChangeFlag::unknown);
    tuple_vec_.push_back(t);
  }

  current_lane_idx_ = -1;
  right_lane_idx_ = -1;
  left_lane_idx_ = -1;
  is_lane_array_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  current_pose_ = *msg;
  is_current_pose_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromTwistStamped(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  current_velocity_ = *msg;
  is_current_velocity_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromState(const std_msgs::StringConstPtr &amp;msg)
{
  current_state_ = msg-&gt;data;
  is_current_state_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::callbackFromConfig(const runtime_manager::ConfigLaneSelectConstPtr &amp;msg)
{
  distance_threshold_ = msg-&gt; distance_threshold_neighbor_lanes;
  lane_change_interval_= msg-&gt;lane_change_interval;
    lane_change_target_ratio_ = msg-&gt;lane_change_target_ratio;
  lane_change_target_minimum_ = msg-&gt;lane_change_target_minimum;
    vlength_hermite_curve_= msg-&gt;vector_length_hermite_curve;
  is_config_subscribed_ = true;

  if(current_lane_idx_ == -1)
    initForLaneSelect();
  else
    processing();
}

void LaneSelectNode::run()
{
  ros::spin();
}

// distance between target 1 and target2 in 2-D
double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2)
{
  double distance = sqrt(pow(target1.x - target2.x, 2) + pow(target1.y - target2.y, 2));
  return distance;
}

geometry_msgs::Point convertPointIntoRelativeCoordinate(const geometry_msgs::Point &amp;input_point, const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);
  tf::Transform transform = inverse.inverse();

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = transform * p;
  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);
  return tf_point_msg;
}

geometry_msgs::Point convertPointIntoWorldCoordinate(const geometry_msgs::Point &amp;input_point,
                                                                      const geometry_msgs::Pose &amp;pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(pose, inverse);

  tf::Point p;
  pointMsgToTF(input_point, p);
  tf::Point tf_p = inverse * p;

  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);
  return tf_point_msg;
}

double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry_msgs::Pose &amp;current_pose)
{
  tf::Vector3 x_axis(1, 0, 0);
  tf::Transform waypoint_tfpose;
  tf::poseMsgToTF(waypoint_pose, waypoint_tfpose);
  tf::Vector3 waypoint_v = waypoint_tfpose.getBasis() * x_axis;
  tf::Transform current_tfpose;
  tf::poseMsgToTF(current_pose, current_tfpose);
  tf::Vector3 current_v = current_tfpose.getBasis() * x_axis;

  return current_v.angle(waypoint_v) * 180 / M_PI;
}

// get closest waypoint from current pose
int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number,
                                 const double distance_threshold)
{
  if (current_lane.waypoints.empty())
    return -1;

  std::vector&lt;uint32_t&gt; idx_vec;
  // if previous number is -1, search closest waypoint from waypoints in front of current pose
  if (previous_number == -1)
  {
    idx_vec.reserve(current_lane.waypoints.size());
    for (uint32_t i = 0; i &lt; current_lane.waypoints.size(); i++)
    {
      geometry_msgs::Point converted_p =
          convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
        idx_vec.push_back(i);
    }
  }
  else
  {
    if (distance_threshold &lt;
        getTwoDimensionalDistance(current_lane.waypoints.at(previous_number).pose.pose.position, current_pose.position))
    {
      ROS_WARN(&quot;Current_pose is far away from previous closest waypoint. Initilized...&quot;);
      return -1;
    }

    double ratio = 3;
    double minimum_dt = 2.0;
    double dt = current_velocity.linear.x * ratio &gt; minimum_dt ? current_velocity.linear.x * ratio : minimum_dt;

    auto range_max = static_cast&lt;uint32_t&gt;(previous_number + dt) &lt; current_lane.waypoints.size()
                         ? static_cast&lt;uint32_t&gt;(previous_number + dt)
                         : current_lane.waypoints.size();
    for (uint32_t i = static_cast&lt;uint32_t&gt;(previous_number); i &lt; range_max; i++)
    {
      geometry_msgs::Point converted_p =
          convertPointIntoRelativeCoordinate(current_lane.waypoints.at(i).pose.pose.position, current_pose);
      double angle = getRelativeAngle(current_lane.waypoints.at(i).pose.pose, current_pose);
      if (converted_p.x &gt; 0 &amp;&amp; angle &lt; 90)
        idx_vec.push_back(i);
    }
  }

  if (idx_vec.empty())
    return -1;

  std::vector&lt;double&gt; dist_vec;
  dist_vec.reserve(idx_vec.size());
  for (const auto &amp;el : idx_vec)
  {
    double dt = getTwoDimensionalDistance(current_pose.position, current_lane.waypoints.at(el).pose.pose.position);
    dist_vec.push_back(dt);
  }
  std::vector&lt;double&gt;::iterator itr = std::min_element(dist_vec.begin(), dist_vec.end());
  int32_t found_number = idx_vec.at(static_cast&lt;uint32_t&gt;(std::distance(dist_vec.begin(), itr)));
  return found_number;
}

// let the linear equation be &quot;ax + by + c = 0&quot;
// if there are two points (x1,y1) , (x2,y2), a = &quot;y2-y1, b = &quot;(-1) * x2 - x1&quot; ,c = &quot;(-1) * (y2-y1)x1 + (x2-x1)y1&quot;
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c)
{
  //(x1, y1) = (start.x, star.y), (x2, y2) = (end.x, end.y)
  double sub_x = fabs(start.x - end.x);
  double sub_y = fabs(start.y - end.y);
  double error = pow(10, -5);  // 0.00001

  if (sub_x &lt; error &amp;&amp; sub_y &lt; error)
  {
    ROS_INFO(&quot;two points are the same point!!&quot;);
    return false;
  }

  *a = end.y - start.y;
  *b = (-1) * (end.x - start.x);
  *c = (-1) * (end.y - start.y) * start.x + (end.x - start.x) * start.y;

  return true;
}
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double a, double b, double c)
{
  double d = fabs(a * point.x + b * point.y + c) / sqrt(pow(a, 2) + pow(b, 2));

  return d;
}

}  // lane_planner
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.h" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_select/lane_select_core.h">
				<diff>@@ -45,7 +45,7 @@
 #include &lt;tuple&gt;
 
 // User defined includes
-#include &quot;waypoint_follower/LaneArray.h&quot;
+#include &quot;waypoint_follower_msgs/LaneArray.h&quot;
 #include &quot;waypoint_follower/libwaypoint_follower.h&quot;
 #include &quot;runtime_manager/ConfigLaneSelect.h&quot;
 #include &quot;hermite_curve.h&quot;
@@ -91,9 +91,9 @@ private:
   int32_t current_lane_idx_;  // the index of the lane we are driving
   int32_t right_lane_idx_;
   int32_t left_lane_idx_;
-  std::vector&lt;std::tuple&lt;waypoint_follower::lane, int32_t, ChangeFlag&gt;&gt; tuple_vec_;  // lane, closest_waypoint,
+  std::vector&lt;std::tuple&lt;waypoint_follower_msgs::lane, int32_t, ChangeFlag&gt;&gt; tuple_vec_;  // lane, closest_waypoint,
                                                                                      // change_flag
-  std::tuple&lt;waypoint_follower::lane, int32_t, ChangeFlag&gt; lane_for_change_;
+  std::tuple&lt;waypoint_follower_msgs::lane, int32_t, ChangeFlag&gt; lane_for_change_;
   bool is_lane_array_subscribed_, is_current_pose_subscribed_, is_current_velocity_subscribed_, is_current_state_subscribed_, is_config_subscribed_;
 
   // parameter from runtime manager
@@ -105,7 +105,7 @@ private:
   std::string current_state_;
 
   // callbacks
-  void callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg);
+  void callbackFromLaneArray(const waypoint_follower_msgs::LaneArrayConstPtr &amp;msg);
   void callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg);
   void callbackFromTwistStamped(const geometry_msgs::TwistStampedConstPtr &amp;msg);
   void callbackFromState(const std_msgs::StringConstPtr &amp;msg);
@@ -128,7 +128,7 @@ private:
   void resetSubscriptionFlag();
   bool isAllTopicsSubscribed();
   void processing();
-  void publishLane(const waypoint_follower::lane &amp;lane);
+  void publishLane(const waypoint_follower_msgs::lane &amp;lane);
   void publishClosestWaypoint(const int32_t clst_wp);
   void publishChangeFlag(const ChangeFlag flag);
   bool getClosestWaypointNumberForEachLanes();
@@ -138,10 +138,10 @@ private:
   void changeLane();
   void updateChangeFlag();
   void createLaneForChange();
-  int32_t getClosestLaneChangeWaypointNumber(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, int32_t cl_wp);
+  int32_t getClosestLaneChangeWaypointNumber(const std::vector&lt;waypoint_follower_msgs::waypoint&gt; &amp;wps, int32_t cl_wp);
 };
 
-int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
+int32_t getClosestWaypointNumber(const waypoint_follower_msgs::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                  const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number, const double distance_threshold);
 
 double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef LANE_SELECT_CORE_H
#define LANE_SELECT_CORE_H

// ROS includes
#include &lt;ros/ros.h&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;std_msgs/Int32.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;std_msgs/String.h&gt;

// C++ includes
#include &lt;iostream&gt;
#include &lt;numeric&gt;
#include &lt;tuple&gt;

// User defined includes
#include &quot;waypoint_follower/LaneArray.h&quot;
#include &quot;waypoint_follower/libwaypoint_follower.h&quot;
#include &quot;runtime_manager/ConfigLaneSelect.h&quot;
#include &quot;hermite_curve.h&quot;

namespace lane_planner
{
enum class ChangeFlag : int32_t
{
  straight,
  right,
  left,

  unknown = -1,
};

template &lt;class T&gt;
typename std::underlying_type&lt;T&gt;::type enumToInteger(T t)
{
  return static_cast&lt;typename std::underlying_type&lt;T&gt;::type&gt;(t);
}

class LaneSelectNode
{
public:
  LaneSelectNode();
  ~LaneSelectNode();

  void run();

private:
  // handle
  ros::NodeHandle nh_;
  ros::NodeHandle private_nh_;

  // publisher
  ros::Publisher pub1_, pub2_, pub3_;
  ros::Publisher vis_pub1_;

  // subscriber
  ros::Subscriber sub1_, sub2_, sub3_, sub4_, sub5_;

  // variables
  int32_t current_lane_idx_;  // the index of the lane we are driving
  int32_t right_lane_idx_;
  int32_t left_lane_idx_;
  std::vector&lt;std::tuple&lt;waypoint_follower::lane, int32_t, ChangeFlag&gt;&gt; tuple_vec_;  // lane, closest_waypoint,
                                                                                     // change_flag
  std::tuple&lt;waypoint_follower::lane, int32_t, ChangeFlag&gt; lane_for_change_;
  bool is_lane_array_subscribed_, is_current_pose_subscribed_, is_current_velocity_subscribed_, is_current_state_subscribed_, is_config_subscribed_;

  // parameter from runtime manager
  double distance_threshold_, lane_change_interval_, lane_change_target_ratio_, lane_change_target_minimum_, vlength_hermite_curve_;

  // topics
  geometry_msgs::PoseStamped current_pose_;
  geometry_msgs::TwistStamped current_velocity_;
  std::string current_state_;

  // callbacks
  void callbackFromLaneArray(const waypoint_follower::LaneArrayConstPtr &amp;msg);
  void callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg);
  void callbackFromTwistStamped(const geometry_msgs::TwistStampedConstPtr &amp;msg);
  void callbackFromState(const std_msgs::StringConstPtr &amp;msg);
  void callbackFromConfig(const runtime_manager::ConfigLaneSelectConstPtr &amp;msg);

  // initializer
  void initForROS();
  void initForLaneSelect();

  // visualizer
  void publishVisualizer();
  visualization_msgs::Marker createCurrentLaneMarker();
  visualization_msgs::Marker createRightLaneMarker();
  visualization_msgs::Marker createLeftLaneMarker();
  visualization_msgs::Marker createClosestWaypointsMarker();
  visualization_msgs::Marker createChangeLaneMarker();

  // functions
  void resetLaneIdx();
  void resetSubscriptionFlag();
  bool isAllTopicsSubscribed();
  void processing();
  void publishLane(const waypoint_follower::lane &amp;lane);
  void publishClosestWaypoint(const int32_t clst_wp);
  void publishChangeFlag(const ChangeFlag flag);
  bool getClosestWaypointNumberForEachLanes();
  int32_t findMostClosestLane(const std::vector&lt;uint32_t&gt; idx_vec, const geometry_msgs::Point p);
  void findCurrentLane();
  void findNeighborLanes();
  void changeLane();
  void updateChangeFlag();
  void createLaneForChange();
  int32_t getClosestLaneChangeWaypointNumber(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps, int32_t cl_wp);
};

int32_t getClosestWaypointNumber(const waypoint_follower::lane &amp;current_lane, const geometry_msgs::Pose &amp;current_pose,
                                 const geometry_msgs::Twist &amp;current_velocity, const int32_t previous_number, const double distance_threshold);

double getTwoDimensionalDistance(const geometry_msgs::Point &amp;target1, const geometry_msgs::Point &amp;target2);

geometry_msgs::Point convertPointIntoRelativeCoordinate(const geometry_msgs::Point &amp;input_point, const geometry_msgs::Pose &amp;pose);

geometry_msgs::Point convertPointIntoWorldCoordinate(const geometry_msgs::Point &amp;input_point,
                                                                      const geometry_msgs::Pose &amp;pose);
double getRelativeAngle(const geometry_msgs::Pose &amp;waypoint_pose, const geometry_msgs::Pose &amp;current_pose);
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c);
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double sa, double b, double c);
}
#endif  // LANE_SELECT_CORE_H
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_stop/lane_stop.cpp" new_path="ros/src/computing/planning/mission/packages/lane_planner/nodes/lane_stop/lane_stop.cpp">
				<diff>@@ -32,7 +32,7 @@
 
 #include &lt;runtime_manager/ConfigLaneStop.h&gt;
 #include &lt;runtime_manager/traffic_light.h&gt;
-#include &lt;waypoint_follower/LaneArray.h&gt;
+#include &lt;waypoint_follower_msgs/LaneArray.h&gt;
 
 #include &lt;lane_planner/vmap.hpp&gt;
 
@@ -42,14 +42,14 @@ bool config_manual_detection = true;
 
 ros::Publisher traffic_pub;
 
-waypoint_follower::LaneArray current_red_lane;
-waypoint_follower::LaneArray current_green_lane;
+waypoint_follower_msgs::LaneArray current_red_lane;
+waypoint_follower_msgs::LaneArray current_green_lane;
 
-const waypoint_follower::LaneArray *previous_lane = &amp;current_red_lane;
+const waypoint_follower_msgs::LaneArray *previous_lane = &amp;current_red_lane;
 
 void select_current_lane(const runtime_manager::traffic_light&amp; msg)
 {
-	const waypoint_follower::LaneArray *current;
+	const waypoint_follower_msgs::LaneArray *current;
 	switch (msg.traffic_light) {
 	case lane_planner::vmap::TRAFFIC_LIGHT_RED:
 		current = &amp;current_red_lane;
@@ -87,12 +87,12 @@ void receive_manual_detection(const runtime_manager::traffic_light&amp; msg)
 		select_current_lane(msg);
 }
 
-void cache_red_lane(const waypoint_follower::LaneArray&amp; msg)
+void cache_red_lane(const waypoint_follower_msgs::LaneArray&amp; msg)
 {
 	current_red_lane = msg;
 }
 
-void cache_green_lane(const waypoint_follower::LaneArray&amp; msg)
+void cache_green_lane(const waypoint_follower_msgs::LaneArray&amp; msg)
 {
 	current_green_lane = msg;
 }
@@ -121,7 +121,7 @@ int main(int argc, char **argv)
 	bool pub_waypoint_latch;
 	n.param&lt;bool&gt;(&quot;/lane_stop/pub_waypoint_latch&quot;, pub_waypoint_latch, true);
 
-	traffic_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/traffic_waypoints_array&quot;, pub_waypoint_queue_size,
+	traffic_pub = n.advertise&lt;waypoint_follower_msgs::LaneArray&gt;(&quot;/traffic_waypoints_array&quot;, pub_waypoint_queue_size,
 								pub_waypoint_latch);
 
 	ros::Subscriber light_sub = n.subscribe(&quot;/light_color&quot;, sub_light_queue_size, receive_auto_detection);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/console.h&gt;

#include &lt;runtime_manager/ConfigLaneStop.h&gt;
#include &lt;runtime_manager/traffic_light.h&gt;
#include &lt;waypoint_follower/LaneArray.h&gt;

#include &lt;lane_planner/vmap.hpp&gt;

namespace {

bool config_manual_detection = true;

ros::Publisher traffic_pub;

waypoint_follower::LaneArray current_red_lane;
waypoint_follower::LaneArray current_green_lane;

const waypoint_follower::LaneArray *previous_lane = &amp;current_red_lane;

void select_current_lane(const runtime_manager::traffic_light&amp; msg)
{
	const waypoint_follower::LaneArray *current;
	switch (msg.traffic_light) {
	case lane_planner::vmap::TRAFFIC_LIGHT_RED:
		current = &amp;current_red_lane;
		break;
	case lane_planner::vmap::TRAFFIC_LIGHT_GREEN:
		current = &amp;current_green_lane;
		break;
	case lane_planner::vmap::TRAFFIC_LIGHT_UNKNOWN:
		current = previous_lane; // if traffic light state is unknown, keep previous state
		break;
	default:
		ROS_ERROR_STREAM(&quot;undefined traffic light&quot;);
		return;
	}

	if (current-&gt;lanes.empty()) {
		ROS_ERROR_STREAM(&quot;empty lanes&quot;);
		return;
	}

	traffic_pub.publish(*current);

	previous_lane = current;
}

void receive_auto_detection(const runtime_manager::traffic_light&amp; msg)
{
	if (!config_manual_detection)
		select_current_lane(msg);
}

void receive_manual_detection(const runtime_manager::traffic_light&amp; msg)
{
	if (config_manual_detection)
		select_current_lane(msg);
}

void cache_red_lane(const waypoint_follower::LaneArray&amp; msg)
{
	current_red_lane = msg;
}

void cache_green_lane(const waypoint_follower::LaneArray&amp; msg)
{
	current_green_lane = msg;
}

void config_parameter(const runtime_manager::ConfigLaneStop&amp; msg)
{
	config_manual_detection = msg.manual_detection;
}

} // namespace

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;lane_stop&quot;);

	ros::NodeHandle n;

	int sub_light_queue_size;
	n.param&lt;int&gt;(&quot;/lane_stop/sub_light_queue_size&quot;, sub_light_queue_size, 1);
	int sub_waypoint_queue_size;
	n.param&lt;int&gt;(&quot;/lane_stop/sub_waypoint_queue_size&quot;, sub_waypoint_queue_size, 1);
	int sub_config_queue_size;
	n.param&lt;int&gt;(&quot;/lane_rule/sub_config_queue_size&quot;, sub_config_queue_size, 1);
	int pub_waypoint_queue_size;
	n.param&lt;int&gt;(&quot;/lane_stop/pub_waypoint_queue_size&quot;, pub_waypoint_queue_size, 1);
	bool pub_waypoint_latch;
	n.param&lt;bool&gt;(&quot;/lane_stop/pub_waypoint_latch&quot;, pub_waypoint_latch, true);

	traffic_pub = n.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;/traffic_waypoints_array&quot;, pub_waypoint_queue_size,
								pub_waypoint_latch);

	ros::Subscriber light_sub = n.subscribe(&quot;/light_color&quot;, sub_light_queue_size, receive_auto_detection);
	ros::Subscriber light_managed_sub = n.subscribe(&quot;/light_color_managed&quot;, sub_light_queue_size,
							receive_manual_detection);
	ros::Subscriber red_sub = n.subscribe(&quot;/red_waypoints_array&quot;, sub_waypoint_queue_size, cache_red_lane);
	ros::Subscriber green_sub = n.subscribe(&quot;/green_waypoints_array&quot;, sub_waypoint_queue_size, cache_green_lane);
	ros::Subscriber config_sub = n.subscribe(&quot;/config/lane_stop&quot;, sub_config_queue_size, config_parameter);

	ros::spin();

	return EXIT_SUCCESS;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/obstacle_avoid/obstacle_avoid.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/obstacle_avoid/obstacle_avoid.cpp">
				<diff>@@ -29,12 +29,12 @@
  */
 
 #include &lt;ros/ros.h&gt;
-#include &lt;waypoint_follower/lane.h&gt;
+#include &lt;waypoint_follower_msgs/lane.h&gt;
 #include &lt;iostream&gt;
 
 static ros::Publisher _pub;
 
-void callback(const waypoint_follower::lane &amp;msg)
+void callback(const waypoint_follower_msgs::lane &amp;msg)
 {
     _pub.publish(msg);
 }
@@ -46,7 +46,7 @@ int main(int argc, char **argv)
 
     ros::NodeHandle nh;
     ros::Subscriber twist_sub = nh.subscribe(&quot;temporal_waypoints&quot;, 1, callback);
-    _pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;final_waypoints&quot;, 1000,true);
+    _pub = nh.advertise&lt;waypoint_follower_msgs::lane&gt;(&quot;final_waypoints&quot;, 1000,true);
 
     ros::spin();
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &lt;ros/ros.h&gt;
#include &lt;waypoint_follower/lane.h&gt;
#include &lt;iostream&gt;

static ros::Publisher _pub;

void callback(const waypoint_follower::lane &amp;msg)
{
    _pub.publish(msg);
}


int main(int argc, char **argv)
{
    ros::init(argc, argv, &quot;obstacle_avoid&quot;);

    ros::NodeHandle nh;
    ros::Subscriber twist_sub = nh.subscribe(&quot;temporal_waypoints&quot;, 1, callback);
    _pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;final_waypoints&quot;, 1000,true);

    ros::spin();



    return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/libvelocity_set.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/libvelocity_set.cpp">
				<diff>@@ -248,7 +248,7 @@ void CrossWalk::setCrossWalkPoints()
   set_points = true;
 }
 
-int CrossWalk::findClosestCrosswalk(const int closest_waypoint, const waypoint_follower::lane&amp; lane, const int search_distance)
+int CrossWalk::findClosestCrosswalk(const int closest_waypoint, const waypoint_follower_msgs::lane&amp; lane, const int search_distance)
 {
   if (!set_points || closest_waypoint &lt; 0)
     return -1;
</diff>
				<old_file>#include &quot;libvelocity_set.h&quot;

// extract edge points from zebra zone
std::vector&lt;geometry_msgs::Point&gt; removeNeedlessPoints(std::vector&lt;geometry_msgs::Point&gt; &amp;area_points)
{
  area_points.push_back(area_points.front());
  std::map&lt;double, int&gt; length_index;
  for (unsigned int i = 0; i &lt; area_points.size() - 1; i++)
    length_index[calcSquareOfLength(area_points[i], area_points[i + 1])] = i;

  std::vector&lt;geometry_msgs::Point&gt; new_points;
  auto it = length_index.end();
  int first = (--it)-&gt;second;
  int second = (--it)-&gt;second;
  new_points.push_back(area_points[first]);
  new_points.push_back(area_points[first + 1]);
  new_points.push_back(area_points[second]);
  new_points.push_back(area_points[second + 1]);

  return new_points;
}

void CrossWalk::crossWalkCallback(const vector_map::CrossWalkArray &amp;msg)
{
  crosswalk_ = msg;

  loaded_crosswalk = true;
  if (loaded_crosswalk &amp;&amp; loaded_area &amp;&amp; loaded_line &amp;&amp; loaded_point)
  {
    loaded_all = true;
    ROS_INFO(&quot;All VectorMap loaded&quot;);
  }
}

void CrossWalk::areaCallback(const vector_map::AreaArray &amp;msg)
{
  area_ = msg;

  loaded_area = true;
  if (loaded_crosswalk &amp;&amp; loaded_area &amp;&amp; loaded_line &amp;&amp; loaded_point)
  {
    loaded_all = true;
    ROS_INFO(&quot;All VectorMap loaded&quot;);
  }
}

void CrossWalk::lineCallback(const vector_map::LineArray &amp;msg)
{
  line_ = msg;

  loaded_line = true;
  if (loaded_crosswalk &amp;&amp; loaded_area &amp;&amp; loaded_line &amp;&amp; loaded_point)
  {
    loaded_all = true;
    ROS_INFO(&quot;All VectorMap loaded&quot;);
  }
}

void CrossWalk::pointCallback(const vector_map::PointArray &amp;msg)
{
  point_ = msg;

  loaded_point = true;
  if (loaded_crosswalk &amp;&amp; loaded_area &amp;&amp; loaded_line &amp;&amp; loaded_point)
  {
    loaded_all = true;
    ROS_INFO(&quot;All VectorMap loaded&quot;);
  }
}

geometry_msgs::Point CrossWalk::getPoint(const int &amp;pid) const
{
  geometry_msgs::Point point;
  for (const auto &amp;p : point_.data)
  {
    if (p.pid == pid)
    {
      point.x = p.ly;
      point.y = p.bx;
      point.z = p.h;
      return point;
    }
  }

  ROS_ERROR(&quot;can't find a point of pid %d&quot;, pid);
  return point;
}

geometry_msgs::Point CrossWalk::calcCenterofGravity(const int &amp;aid) const
{
  int search_lid = -1;
  for (const auto &amp;area : area_.data)
    if (area.aid == aid)
    {
      search_lid = area.slid;
      break;
    }

  std::vector&lt;geometry_msgs::Point&gt; area_points;
  while (search_lid)
  {
    for (const auto &amp;line : line_.data)
    {
      if (line.lid == search_lid)
      {
        area_points.push_back(getPoint(line.bpid));
        search_lid = line.flid;
      }
    }
  }

  geometry_msgs::Point point;
  point.x = 0.0;
  point.y = 0.0;
  point.z = 0.0;
  if (area_points.size() &gt; 4)
  {
    std::vector&lt;geometry_msgs::Point&gt; filterd_points = removeNeedlessPoints(area_points);
    for (const auto &amp;p : filterd_points)
    {
      point.x += p.x;
      point.y += p.y;
      point.z += p.z;
    }
  }
  else
  {
    for (const auto &amp;p : area_points)
    {
      point.x += p.x;
      point.y += p.y;
      point.z += p.z;
    }
  }

  point.x /= 4;
  point.y /= 4;
  point.z /= 4;
  return point;
}

double CrossWalk::calcCrossWalkWidth(const int &amp;aid) const
{
  int search_lid = -1;
  for (const auto &amp;area : area_.data)
    if (area.aid == aid)
    {
      search_lid = area.slid;
      break;
    }

  std::vector&lt;geometry_msgs::Point&gt; area_points;
  while (search_lid)
  {
    for (const auto &amp;line : line_.data)
    {
      if (line.lid == search_lid)
      {
        area_points.push_back(getPoint(line.bpid));
        //_points.push_back(area_points.back());///
        search_lid = line.flid;
      }
    }
  }

  area_points.push_back(area_points.front());
  double max_length = calcSquareOfLength(area_points[0], area_points[1]);
  for (unsigned int i = 1; i &lt; area_points.size() - 1; i++)
  {
    if (calcSquareOfLength(area_points[i], area_points[i + 1]) &gt; max_length)
      max_length = calcSquareOfLength(area_points[i], area_points[i + 1]);
  }

  return sqrt(max_length);
}

// count the number of crosswalks
int CrossWalk::countAreaSize() const
{
  int count = 0;
  for (const auto &amp;x : crosswalk_.data)
    if (x.type == 0)  // type:0 -&gt; outer frame of crosswalks
      count++;

  return count;
}

void CrossWalk::getAID(std::unordered_map&lt;int, std::vector&lt;int&gt;&gt; &amp;bdid2aid_map) const
{
  for (const auto &amp;x : crosswalk_.data)
    if (x.type == 1)
    {                                         // if it is zebra
      bdid2aid_map[x.bdid].push_back(x.aid);  // save area id
    }
}

void CrossWalk::calcDetectionArea(const std::unordered_map&lt;int, std::vector&lt;int&gt;&gt; &amp;bdid2aid_map)
{
  for (const auto &amp;crosswalk_aids : bdid2aid_map)
  {
    int bdid = crosswalk_aids.first;
    double width = 0.0;
    for (const auto &amp;aid : crosswalk_aids.second)
    {
      detection_points_[bdid].points.push_back(calcCenterofGravity(aid));
      width += calcCrossWalkWidth(aid);
    }
    width /= crosswalk_aids.second.size();
    detection_points_[bdid].width = width;
  }
}

void CrossWalk::calcCenterPoints()
{
  for (const auto &amp;i : bdID_)
  {
    geometry_msgs::Point center;
    center.x = 0.0;
    center.y = 0.0;
    center.z = 0.0;
    for (const auto &amp;p : detection_points_[i].points)
    {
      center.x += p.x;
      center.y += p.y;
      center.z += p.z;
    }
    center.x /= detection_points_[i].points.size();
    center.y /= detection_points_[i].points.size();
    center.z /= detection_points_[i].points.size();
    detection_points_[i].center = center;
  }
}

void CrossWalk::setCrossWalkPoints()
{
  // bdid2aid_map[BDID] has AIDs of its zebra zone
  std::unordered_map&lt;int, std::vector&lt;int&gt;&gt; bdid2aid_map;
  getAID(bdid2aid_map);

  // Save key values
  for (const auto &amp;bdid2aid : bdid2aid_map)
    bdID_.push_back(bdid2aid.first);

  calcDetectionArea(bdid2aid_map);
  calcCenterPoints();

  ROS_INFO(&quot;Set cross walk detection points&quot;);
  set_points = true;
}

int CrossWalk::findClosestCrosswalk(const int closest_waypoint, const waypoint_follower::lane&amp; lane, const int search_distance)
{
  if (!set_points || closest_waypoint &lt; 0)
    return -1;

  double find_distance = 2.0 * 2.0;      // meter
  double ignore_distance = 20.0 * 20.0;  // meter
  static std::vector&lt;int&gt; bdid = getBDID();
  // Find near cross walk
  for (int num = closest_waypoint; num &lt; closest_waypoint + search_distance; num++)
  {
    geometry_msgs::Point waypoint = lane.waypoints[num].pose.pose.position;
    waypoint.z = 0.0;  // ignore Z axis
    for (const auto &amp;i : bdid)
    {
      // ignore far crosswalk
      geometry_msgs::Point crosswalk_center = getDetectionPoints(i).center;
      crosswalk_center.z = 0.0;
      if (calcSquareOfLength(crosswalk_center, waypoint) &gt; ignore_distance)
        continue;

      for (auto p : getDetectionPoints(i).points)
      {
        p.z = waypoint.z;
        if (calcSquareOfLength(p, waypoint) &lt; find_distance)
        {
          setDetectionCrossWalkID(i);
          return num;
        }
      }
    }
  }

  setDetectionCrossWalkID(-1);
  return -1;  // no near crosswalk

}

geometry_msgs::Point ObstaclePoints::getObstaclePoint(const EControl &amp;kind) const
{
  geometry_msgs::Point point;

  if (kind == EControl::STOP)
  {
    for (const auto &amp;p : stop_points_)
    {
      point.x += p.x;
      point.y += p.y;
      point.z += p.z;
    }
    point.x /= stop_points_.size();
    point.y /= stop_points_.size();
    point.z /= stop_points_.size();

    return point;
  }
  else // kind == DECELERATE
  {
    for (const auto &amp;p : decelerate_points_)
    {
      point.x += p.x;
      point.y += p.y;
      point.z += p.z;
    }
    point.x /= decelerate_points_.size();
    point.y /= decelerate_points_.size();
    point.z /= decelerate_points_.size();

    return point;
  }
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/libvelocity_set.h" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/libvelocity_set.h">
				<diff>@@ -63,7 +63,7 @@ public:
   geometry_msgs::Point getPoint(const int &amp;pid) const;
   void calcCenterPoints();
   void setCrossWalkPoints();
-  int findClosestCrosswalk(const int closest_waypoint, const waypoint_follower::lane&amp; lane, const int search_distance);
+  int findClosestCrosswalk(const int closest_waypoint, const waypoint_follower_msgs::lane&amp; lane, const int search_distance);
   int getSize() const
   {
     return detection_points_.size();
</diff>
				<old_file>#ifndef _VELOCITY_SET_H
#define _VELOCITY_SET_H

#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;map&gt;
#include &lt;unordered_map&gt;
#include &lt;math.h&gt;

#include &lt;ros/ros.h&gt;
#include &lt;geometry_msgs/Point.h&gt;
#include &lt;vector_map/vector_map.h&gt;

#include &quot;waypoint_follower/libwaypoint_follower.h&quot;

enum class EControl
{
  KEEP = -1,
  STOP = 1,
  DECELERATE = 2,
  OTHERS = 3,
};

struct CrossWalkPoints
{
  std::vector&lt;geometry_msgs::Point&gt; points;
  geometry_msgs::Point center;
  double width;
};

class CrossWalk
{
private:
  // detection_points_[bdID] has information of each crosswalk
  std::unordered_map&lt;int, CrossWalkPoints&gt; detection_points_;
  int detection_waypoint_;
  int detection_crosswalk_id_;
  std::vector&lt;geometry_msgs::Point&gt; obstacle_points_;
  std::vector&lt;int&gt; bdID_;

public:
  bool loaded_crosswalk;
  bool loaded_area;
  bool loaded_line;
  bool loaded_point;
  bool loaded_all;
  bool set_points;
  vector_map::CrossWalkArray crosswalk_;
  vector_map::AreaArray area_;
  vector_map::LineArray line_;
  vector_map::PointArray point_;

  void crossWalkCallback(const vector_map::CrossWalkArray &amp;msg);
  void areaCallback(const vector_map::AreaArray &amp;msg);
  void lineCallback(const vector_map::LineArray &amp;msg);
  void pointCallback(const vector_map::PointArray &amp;msg);

  int countAreaSize() const;
  void getAID(std::unordered_map&lt;int, std::vector&lt;int&gt;&gt; &amp;aid_crosswalk) const;
  void calcDetectionArea(const std::unordered_map&lt;int, std::vector&lt;int&gt;&gt; &amp;bdid2aid_map);
  geometry_msgs::Point calcCenterofGravity(const int &amp;aid) const;
  double calcCrossWalkWidth(const int &amp;aid) const;
  geometry_msgs::Point getPoint(const int &amp;pid) const;
  void calcCenterPoints();
  void setCrossWalkPoints();
  int findClosestCrosswalk(const int closest_waypoint, const waypoint_follower::lane&amp; lane, const int search_distance);
  int getSize() const
  {
    return detection_points_.size();
  }
  std::vector&lt;int&gt; getBDID() const
  {
    return bdID_;
  }
  CrossWalkPoints getDetectionPoints(const int &amp;id) const
  {
    return detection_points_.at(id);
  }
  void setDetectionWaypoint(const int &amp;num)
  {
    detection_waypoint_ = num;
  }
  int getDetectionWaypoint() const
  {
    return detection_waypoint_;
  }
  void setDetectionCrossWalkID(const int &amp;id)
  {
    detection_crosswalk_id_ = id;
  }
  int getDetectionCrossWalkID() const
  {
    return detection_crosswalk_id_;
  }

  CrossWalk()
    : detection_waypoint_(-1)
    , detection_crosswalk_id_(-1)
    , loaded_crosswalk(false)
    , loaded_area(false)
    , loaded_line(false)
    , loaded_point(false)
    , loaded_all(false)
    , set_points(false)
  {
  }
};

//////////////////////////////////////
// for visualization of obstacles
//////////////////////////////////////
class ObstaclePoints
{
private:
  std::vector&lt;geometry_msgs::Point&gt; stop_points_;
  std::vector&lt;geometry_msgs::Point&gt; decelerate_points_;
  geometry_msgs::Point previous_detection_;

public:
  void setStopPoint(const geometry_msgs::Point &amp;p)
  {
    stop_points_.push_back(p);
  }
  void setDeceleratePoint(const geometry_msgs::Point &amp;p)
  {
    decelerate_points_.push_back(p);
  }
  geometry_msgs::Point getObstaclePoint(const EControl &amp;kind) const;
  void clearStopPoints()
  {
    stop_points_.clear();
  }
  void clearDeceleratePoints()
  {
    decelerate_points_.clear();
  }

  ObstaclePoints() : stop_points_(0), decelerate_points_(0)
  {
  }
};

inline double calcSquareOfLength(const geometry_msgs::Point &amp;p1, const geometry_msgs::Point &amp;p2)
{
  return (p1.x - p2.x) * (p1.x - p2.x) + (p1.y - p2.y) * (p1.y - p2.y) + (p1.z - p2.z) * (p1.z - p2.z);
}

#endif /* _VELOCITY_SET_H */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set.cpp">
				<diff>@@ -89,7 +89,7 @@ void displayObstacle(const EControl &amp;kind, const ObstaclePoints&amp; obstacle_points
   //obstacle_pub.publish(marker);
 }
 
-void displayDetectionRange(const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, const int closest_waypoint, const EControl &amp;kind, const int obstacle_waypoint, const double stop_range, const double deceleration_range, const ros::Publisher&amp; detection_range_pub)
+void displayDetectionRange(const waypoint_follower_msgs::lane&amp; lane, const CrossWalk&amp; crosswalk, const int closest_waypoint, const EControl &amp;kind, const int obstacle_waypoint, const double stop_range, const double deceleration_range, const ros::Publisher&amp; detection_range_pub)
 {
   // set up for marker array
   visualization_msgs::MarkerArray marker_array;
@@ -231,7 +231,7 @@ EControl crossWalkDetection(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const
   return EControl::KEEP;  // find no obstacles
 }
 
-int detectStopObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, double stop_range, double points_threshold, const geometry_msgs::PoseStamped&amp; localizer_pose, ObstaclePoints* obstacle_points)
+int detectStopObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower_msgs::lane&amp; lane, const CrossWalk&amp; crosswalk, double stop_range, double points_threshold, const geometry_msgs::PoseStamped&amp; localizer_pose, ObstaclePoints* obstacle_points)
 {
   int stop_obstacle_waypoint = -1;
   // start search from the closest waypoint
@@ -290,7 +290,7 @@ int detectStopObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int c
   return stop_obstacle_waypoint;
 }
 
-int detectDecelerateObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower::lane&amp; lane, const double stop_range, const double deceleration_range, const double points_threshold, const geometry_msgs::PoseStamped&amp; localizer_pose, ObstaclePoints* obstacle_points)
+int detectDecelerateObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower_msgs::lane&amp; lane, const double stop_range, const double deceleration_range, const double points_threshold, const geometry_msgs::PoseStamped&amp; localizer_pose, ObstaclePoints* obstacle_points)
 {
   int decelerate_obstacle_waypoint = -1;
   // start search from the closest waypoint
@@ -340,7 +340,7 @@ int detectDecelerateObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const
 
 
 // Detect an obstacle by using pointcloud
-EControl pointsDetection(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo&amp; vs_info, int* obstacle_waypoint, ObstaclePoints* obstacle_points)
+EControl pointsDetection(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower_msgs::lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo&amp; vs_info, int* obstacle_waypoint, ObstaclePoints* obstacle_points)
 {
   if (points.empty() == true || closest_waypoint &lt; 0)
     return EControl::KEEP;
@@ -388,7 +388,7 @@ EControl pointsDetection(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int
 
 }
 
-EControl obstacleDetection(int closest_waypoint, const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo vs_info, const ros::Publisher&amp; detection_range_pub, const ros::Publisher&amp; obstacle_pub, int* obstacle_waypoint)
+EControl obstacleDetection(int closest_waypoint, const waypoint_follower_msgs::lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo vs_info, const ros::Publisher&amp; detection_range_pub, const ros::Publisher&amp; obstacle_pub, int* obstacle_waypoint)
 {
   ObstaclePoints obstacle_points;
   EControl detection_result = pointsDetection(vs_info.getPoints(), closest_waypoint, lane, crosswalk, vs_info, obstacle_waypoint, &amp;obstacle_points);
@@ -500,7 +500,7 @@ int main(int argc, char **argv)
 
   // publisher
   ros::Publisher detection_range_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;detection_range&quot;, 0);
-  ros::Publisher temporal_waypoints_pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;temporal_waypoints&quot;, 1000, true);
+  ros::Publisher temporal_waypoints_pub = nh.advertise&lt;waypoint_follower_msgs::lane&gt;(&quot;temporal_waypoints&quot;, 1000, true);
   ros::Publisher obstacle_pub = nh.advertise&lt;visualization_msgs::Marker&gt;(&quot;obstacle&quot;, 0);
 
   ros::Rate loop_rate(LOOP_RATE);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &lt;ros/ros.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;iostream&gt;

#include &quot;libvelocity_set.h&quot;
#include &quot;velocity_set_path.h&quot;
#include &quot;velocity_set_info.h&quot;

namespace
{
constexpr int LOOP_RATE = 10;
constexpr double DECELERATION_SEARCH_DISTANCE = 30;
constexpr double STOP_SEARCH_DISTANCE = 60;


// Display a detected obstacle
void displayObstacle(const EControl &amp;kind, const ObstaclePoints&amp; obstacle_points, const ros::Publisher&amp; obstacle_pub)
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;/map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;my_namespace&quot;;
  marker.id = 0;
  marker.type = visualization_msgs::Marker::CUBE;
  marker.action = visualization_msgs::Marker::ADD;

  static geometry_msgs::Point prev_obstacle_point;
  if (kind == EControl::STOP || kind == EControl::DECELERATE)
  {
    marker.pose.position = obstacle_points.getObstaclePoint(kind);
    prev_obstacle_point = marker.pose.position;
  }
  else // kind == OTHERS
  {
    marker.pose.position = prev_obstacle_point;
  }
  geometry_msgs::Quaternion quat;
  marker.pose.orientation = quat;

  marker.scale.x = 1.0;
  marker.scale.y = 1.0;
  marker.scale.z = 2.0;
  marker.color.a = 0.7;
  if (kind == EControl::STOP)
  {
    marker.color.r = 1.0;
    marker.color.g = 0.0;
    marker.color.b = 0.0;
  }
  else
  {
    marker.color.r = 1.0;
    marker.color.g = 1.0;
    marker.color.b = 0.0;
  }
  marker.lifetime = ros::Duration(0.1);
  marker.frame_locked = true;

  //obstacle_pub.publish(marker);
}

void displayDetectionRange(const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, const int closest_waypoint, const EControl &amp;kind, const int obstacle_waypoint, const double stop_range, const double deceleration_range, const ros::Publisher&amp; detection_range_pub)
{
  // set up for marker array
  visualization_msgs::MarkerArray marker_array;
  visualization_msgs::Marker crosswalk_marker;
  visualization_msgs::Marker waypoint_marker_stop;
  visualization_msgs::Marker waypoint_marker_decelerate;
  visualization_msgs::Marker stop_line;
  crosswalk_marker.header.frame_id = &quot;/map&quot;;
  crosswalk_marker.header.stamp = ros::Time();
  crosswalk_marker.id = 0;
  crosswalk_marker.type = visualization_msgs::Marker::SPHERE_LIST;
  crosswalk_marker.action = visualization_msgs::Marker::ADD;
  waypoint_marker_stop = crosswalk_marker;
  waypoint_marker_decelerate = crosswalk_marker;
  stop_line = crosswalk_marker;
  stop_line.type = visualization_msgs::Marker::CUBE;

  // set each namespace
  crosswalk_marker.ns = &quot;Crosswalk Detection&quot;;
  waypoint_marker_stop.ns = &quot;Stop Detection&quot;;
  waypoint_marker_decelerate.ns = &quot;Decelerate Detection&quot;;
  stop_line.ns = &quot;Stop Line&quot;;

  // set scale and color
  double scale = 2 * stop_range;
  waypoint_marker_stop.scale.x = scale;
  waypoint_marker_stop.scale.y = scale;
  waypoint_marker_stop.scale.z = scale;
  waypoint_marker_stop.color.a = 0.2;
  waypoint_marker_stop.color.r = 0.0;
  waypoint_marker_stop.color.g = 1.0;
  waypoint_marker_stop.color.b = 0.0;
  waypoint_marker_stop.frame_locked = true;

  scale = 2 * (stop_range + deceleration_range);
  waypoint_marker_decelerate.scale.x = scale;
  waypoint_marker_decelerate.scale.y = scale;
  waypoint_marker_decelerate.scale.z = scale;
  waypoint_marker_decelerate.color.a = 0.15;
  waypoint_marker_decelerate.color.r = 1.0;
  waypoint_marker_decelerate.color.g = 1.0;
  waypoint_marker_decelerate.color.b = 0.0;
  waypoint_marker_decelerate.frame_locked = true;

  if (obstacle_waypoint &gt; -1)
  {
    stop_line.pose.position = lane.waypoints[obstacle_waypoint].pose.pose.position;
    stop_line.pose.orientation = lane.waypoints[obstacle_waypoint].pose.pose.orientation;
  }
  stop_line.pose.position.z += 1.0;
  stop_line.scale.x = 0.1;
  stop_line.scale.y = 15.0;
  stop_line.scale.z = 2.0;
  stop_line.color.a = 0.3;
  stop_line.color.r = 1.0;
  stop_line.color.g = 0.0;
  stop_line.color.b = 0.0;
  stop_line.lifetime = ros::Duration(0.1);
  stop_line.frame_locked = true;

  int crosswalk_id = crosswalk.getDetectionCrossWalkID();
  if (crosswalk_id &gt; 0)
    scale = crosswalk.getDetectionPoints(crosswalk_id).width;
  crosswalk_marker.scale.x = scale;
  crosswalk_marker.scale.y = scale;
  crosswalk_marker.scale.z = scale;
  crosswalk_marker.color.a = 0.5;
  crosswalk_marker.color.r = 0.0;
  crosswalk_marker.color.g = 1.0;
  crosswalk_marker.color.b = 0.0;
  crosswalk_marker.frame_locked = true;

  // set marker points coordinate
  for (int i = 0; i &lt; STOP_SEARCH_DISTANCE; i++)
  {
    if (closest_waypoint &lt; 0 || i + closest_waypoint &gt; static_cast&lt;int&gt;(lane.waypoints.size()) - 1)
      break;

    geometry_msgs::Point point;
    point = lane.waypoints[closest_waypoint + i].pose.pose.position;

    waypoint_marker_stop.points.push_back(point);

    if (i &gt; DECELERATION_SEARCH_DISTANCE)
      continue;
    waypoint_marker_decelerate.points.push_back(point);
  }

  if (crosswalk_id &gt; 0)
  {
    for (const auto &amp;p : crosswalk.getDetectionPoints(crosswalk_id).points)
      crosswalk_marker.points.push_back(p);
  }

  // publish marker
  marker_array.markers.push_back(crosswalk_marker);
  marker_array.markers.push_back(waypoint_marker_stop);
  marker_array.markers.push_back(waypoint_marker_decelerate);
  if (kind == EControl::STOP)
    marker_array.markers.push_back(stop_line);
  detection_range_pub.publish(marker_array);
  marker_array.markers.clear();
}

// obstacle detection for crosswalk
EControl crossWalkDetection(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const CrossWalk&amp; crosswalk, const geometry_msgs::PoseStamped&amp; localizer_pose, const int points_threshold, ObstaclePoints* obstacle_points)
{
  int crosswalk_id = crosswalk.getDetectionCrossWalkID();
  double search_radius = crosswalk.getDetectionPoints(crosswalk_id).width / 2;

  // Search each calculated points in the crosswalk
  for (const auto &amp;p : crosswalk.getDetectionPoints(crosswalk_id).points)
  {
    geometry_msgs::Point detection_point = calcRelativeCoordinate(p, localizer_pose.pose);
    tf::Vector3 detection_vector = point2vector(detection_point);
    detection_vector.setZ(0.0);

    int stop_count = 0;  // the number of points in the detection area
    for (const auto &amp;p : points)
    {
      tf::Vector3 point_vector(p.x, p.y, 0.0);
      double distance = tf::tfDistance(point_vector, detection_vector);
      if (distance &lt; search_radius)
      {
        stop_count++;
        geometry_msgs::Point point_temp;
        point_temp.x = p.x;
        point_temp.y = p.y;
        point_temp.z = p.z;
	obstacle_points-&gt;setStopPoint(calcAbsoluteCoordinate(point_temp, localizer_pose.pose));
      }
      if (stop_count &gt; points_threshold)
        return EControl::STOP;
    }

    obstacle_points-&gt;clearStopPoints();
  }

  return EControl::KEEP;  // find no obstacles
}

int detectStopObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, double stop_range, double points_threshold, const geometry_msgs::PoseStamped&amp; localizer_pose, ObstaclePoints* obstacle_points)
{
  int stop_obstacle_waypoint = -1;
  // start search from the closest waypoint
  for (int i = closest_waypoint; i &lt; closest_waypoint + STOP_SEARCH_DISTANCE; i++)
  {
    // reach the end of waypoints
    if (i &gt;= static_cast&lt;int&gt;(lane.waypoints.size()))
      break;

    // Detection for cross walk
    if (i == crosswalk.getDetectionWaypoint())
    {
      // found an obstacle in the cross walk
      if (crossWalkDetection(points, crosswalk, localizer_pose, points_threshold, obstacle_points) == EControl::STOP)
      {
        stop_obstacle_waypoint = i;
        break;
      }
    }

    // waypoint seen by localizer
    geometry_msgs::Point waypoint = calcRelativeCoordinate(lane.waypoints[i].pose.pose.position, localizer_pose.pose);
    tf::Vector3 tf_waypoint = point2vector(waypoint);
    tf_waypoint.setZ(0);

    int stop_point_count = 0;
    for (const auto&amp; p : points)
    {
      tf::Vector3 point_vector(p.x, p.y, 0);

      // 2D distance between waypoint and points (obstacle)
      double dt = tf::tfDistance(point_vector, tf_waypoint);
      if (dt &lt; stop_range)
      {
        stop_point_count++;
        geometry_msgs::Point point_temp;
        point_temp.x = p.x;
        point_temp.y = p.y;
        point_temp.z = p.z;
	obstacle_points-&gt;setStopPoint(calcAbsoluteCoordinate(point_temp, localizer_pose.pose));
      }
    }

    // there is an obstacle if the number of points exceeded the threshold
    if (stop_point_count &gt; points_threshold)
    {
      stop_obstacle_waypoint = i;
      break;
    }

    obstacle_points-&gt;clearStopPoints();

    // check next waypoint...
  }

  return stop_obstacle_waypoint;
}

int detectDecelerateObstacle(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower::lane&amp; lane, const double stop_range, const double deceleration_range, const double points_threshold, const geometry_msgs::PoseStamped&amp; localizer_pose, ObstaclePoints* obstacle_points)
{
  int decelerate_obstacle_waypoint = -1;
  // start search from the closest waypoint
  for (int i = closest_waypoint; i &lt; closest_waypoint + DECELERATION_SEARCH_DISTANCE; i++)
  {
    // reach the end of waypoints
    if (i &gt;= static_cast&lt;int&gt;(lane.waypoints.size()))
      break;

    // waypoint seen by localizer
    geometry_msgs::Point waypoint = calcRelativeCoordinate(lane.waypoints[i].pose.pose.position, localizer_pose.pose);
    tf::Vector3 tf_waypoint = point2vector(waypoint);
    tf_waypoint.setZ(0);

    int decelerate_point_count = 0;
    for (const auto&amp; p : points)
    {
      tf::Vector3 point_vector(p.x, p.y, 0);

      // 2D distance between waypoint and points (obstacle)
      double dt = tf::tfDistance(point_vector, tf_waypoint);
      if (dt &gt; stop_range &amp;&amp; dt &lt; stop_range + deceleration_range)
      {
        decelerate_point_count++;
        geometry_msgs::Point point_temp;
        point_temp.x = p.x;
        point_temp.y = p.y;
        point_temp.z = p.z;
	obstacle_points-&gt;setDeceleratePoint(calcAbsoluteCoordinate(point_temp, localizer_pose.pose));
      }
    }

    // there is an obstacle if the number of points exceeded the threshold
    if (decelerate_point_count &gt; points_threshold)
    {
      decelerate_obstacle_waypoint = i;
      break;
    }

    obstacle_points-&gt;clearDeceleratePoints();

    // check next waypoint...
  }

  return decelerate_obstacle_waypoint;
}


// Detect an obstacle by using pointcloud
EControl pointsDetection(const pcl::PointCloud&lt;pcl::PointXYZ&gt;&amp; points, const int closest_waypoint, const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo&amp; vs_info, int* obstacle_waypoint, ObstaclePoints* obstacle_points)
{
  if (points.empty() == true || closest_waypoint &lt; 0)
    return EControl::KEEP;

  int stop_obstacle_waypoint = detectStopObstacle(points, closest_waypoint, lane, crosswalk, vs_info.getStopRange(), vs_info.getPointsThreshold(), vs_info.getLocalizerPose(), obstacle_points);

  // skip searching deceleration range
  if (vs_info.getDecelerationRange() &lt; 0.01)
  {
    *obstacle_waypoint = stop_obstacle_waypoint;
    return stop_obstacle_waypoint &lt; 0 ? EControl::KEEP : EControl::STOP;
  }

  int decelerate_obstacle_waypoint = detectDecelerateObstacle(points, closest_waypoint, lane, vs_info.getStopRange(), vs_info.getDecelerationRange(), vs_info.getPointsThreshold(), vs_info.getLocalizerPose(), obstacle_points);

  // stop obstacle was not found
  if (stop_obstacle_waypoint &lt; 0)
  {
    *obstacle_waypoint  = decelerate_obstacle_waypoint;
    return decelerate_obstacle_waypoint &lt; 0 ? EControl::KEEP : EControl::DECELERATE;
  }

  // stop obstacle was found but decelerate obstacle was not found
  if (decelerate_obstacle_waypoint &lt; 0)
  {
    *obstacle_waypoint = stop_obstacle_waypoint;
    return EControl::STOP;
  }

  // about 5.0 meter
  double waypoint_interval = getPlaneDistance(lane.waypoints[0].pose.pose.position, lane.waypoints[1].pose.pose.position);
  int stop_decelerate_threshold = 5 / waypoint_interval;

  // both were found
  if (stop_obstacle_waypoint - decelerate_obstacle_waypoint &gt; stop_decelerate_threshold)
  {
    *obstacle_waypoint = decelerate_obstacle_waypoint;
    return EControl::DECELERATE;
  }
  else
  {
    *obstacle_waypoint = stop_obstacle_waypoint;
    return EControl::STOP;
  }

}

EControl obstacleDetection(int closest_waypoint, const waypoint_follower::lane&amp; lane, const CrossWalk&amp; crosswalk, const VelocitySetInfo vs_info, const ros::Publisher&amp; detection_range_pub, const ros::Publisher&amp; obstacle_pub, int* obstacle_waypoint)
{
  ObstaclePoints obstacle_points;
  EControl detection_result = pointsDetection(vs_info.getPoints(), closest_waypoint, lane, crosswalk, vs_info, obstacle_waypoint, &amp;obstacle_points);
  displayDetectionRange(lane, crosswalk, closest_waypoint, detection_result, *obstacle_waypoint, vs_info.getStopRange(), vs_info.getDecelerationRange(), detection_range_pub);

  static int false_count = 0;
  static EControl prev_detection = EControl::KEEP;
  static int prev_obstacle_waypoint = -1;

  // stop or decelerate because we found obstacles
  if (detection_result == EControl::STOP || detection_result == EControl::DECELERATE)
  {
    displayObstacle(detection_result, obstacle_points, obstacle_pub);
      prev_detection = detection_result;
      false_count = 0;
      prev_obstacle_waypoint = *obstacle_waypoint;
      return detection_result;
  }

  // there are no obstacles, but wait a little for safety
  if (prev_detection == EControl::STOP || prev_detection == EControl::DECELERATE)
  {
    false_count++;

    if (false_count &lt; LOOP_RATE / 2)
    {
      *obstacle_waypoint = prev_obstacle_waypoint;
      displayObstacle(EControl::OTHERS, obstacle_points, obstacle_pub);
      return prev_detection;
    }
  }

  // there are no obstacles, so we move forward
  *obstacle_waypoint = -1;
  false_count = 0;
  prev_detection = EControl::KEEP;
  return detection_result;
}

void changeWaypoints(const VelocitySetInfo&amp; vs_info, const EControl&amp; detection_result, int closest_waypoint, int obstacle_waypoint, const ros::Publisher&amp; temporal_waypoints_pub, VelocitySetPath* vs_path)
{
  if (detection_result == EControl::STOP)
  {  // STOP for obstacle
    // stop_waypoint is about g_stop_distance meter away from obstacles
    int stop_waypoint = obstacle_waypoint - vs_info.getStopDistance() / vs_path-&gt;calcInterval(0, 1);

    // change waypoints to stop by the stop_waypoint
    vs_path-&gt;changeWaypointsForStopping(stop_waypoint, obstacle_waypoint, closest_waypoint, vs_info.getDeceleration());
    vs_path-&gt;avoidSuddenAcceleration(vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;avoidSuddenDeceleration(vs_info.getVelocityChangeLimit(), vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;setTemporalWaypoints(vs_info.getTemporalWaypointsSize(), closest_waypoint, vs_info.getControlPose());
    temporal_waypoints_pub.publish(vs_path-&gt;getTemporalWaypoints());
  }
  else if (detection_result == EControl::DECELERATE)
  {  // DECELERATE for obstacles
    vs_path-&gt;initializeNewWaypoints();
    vs_path-&gt;changeWaypointsForDeceleration(vs_info.getDeceleration(), closest_waypoint, obstacle_waypoint);
    vs_path-&gt;avoidSuddenDeceleration(vs_info.getVelocityChangeLimit(), vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;avoidSuddenAcceleration(vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;setTemporalWaypoints(vs_info.getTemporalWaypointsSize(), closest_waypoint, vs_info.getControlPose());
    temporal_waypoints_pub.publish(vs_path-&gt;getTemporalWaypoints());
  }
  else
  {  // ACCELERATE or KEEP
    vs_path-&gt;initializeNewWaypoints();
    vs_path-&gt;avoidSuddenAcceleration(vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;avoidSuddenDeceleration(vs_info.getVelocityChangeLimit(), vs_info.getDeceleration(), closest_waypoint);
    vs_path-&gt;setTemporalWaypoints(vs_info.getTemporalWaypointsSize(), closest_waypoint, vs_info.getControlPose());
    temporal_waypoints_pub.publish(vs_path-&gt;getTemporalWaypoints());
  }
}

} // end namespace


int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;velocity_set&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  bool use_crosswalk_detection;
  std::string points_topic;
  private_nh.param&lt;bool&gt;(&quot;use_crosswalk_detection&quot;, use_crosswalk_detection, true);
  private_nh.param&lt;std::string&gt;(&quot;points_topic&quot;, points_topic, &quot;points_lanes&quot;);

  // class
  CrossWalk crosswalk;
  VelocitySetPath vs_path;
  VelocitySetInfo vs_info;

  // velocity set subscriber
  ros::Subscriber waypoints_sub = nh.subscribe(&quot;base_waypoints&quot;, 1, &amp;VelocitySetPath::waypointsCallback, &amp;vs_path);
  ros::Subscriber current_vel_sub = nh.subscribe(&quot;current_velocity&quot;, 1, &amp;VelocitySetPath::currentVelocityCallback, &amp;vs_path);

  // velocity set info subscriber
  ros::Subscriber config_sub = nh.subscribe(&quot;config/velocity_set&quot;, 1, &amp;VelocitySetInfo::configCallback, &amp;vs_info);
  ros::Subscriber points_sub = nh.subscribe(points_topic, 1, &amp;VelocitySetInfo::pointsCallback, &amp;vs_info);
  ros::Subscriber localizer_sub = nh.subscribe(&quot;localizer_pose&quot;, 1, &amp;VelocitySetInfo::localizerPoseCallback, &amp;vs_info);
  ros::Subscriber control_pose_sub = nh.subscribe(&quot;current_pose&quot;, 1, &amp;VelocitySetInfo::controlPoseCallback, &amp;vs_info);
  ros::Subscriber closest_waypoint_sub = nh.subscribe(&quot;closest_waypoint&quot;, 1, &amp;VelocitySetInfo::closestWaypointCallback, &amp;vs_info);

  // vector map subscriber
  ros::Subscriber sub_dtlane = nh.subscribe(&quot;vector_map_info/cross_walk&quot;, 1, &amp;CrossWalk::crossWalkCallback, &amp;crosswalk);
  ros::Subscriber sub_area = nh.subscribe(&quot;vector_map_info/area&quot;, 1, &amp;CrossWalk::areaCallback, &amp;crosswalk);
  ros::Subscriber sub_line = nh.subscribe(&quot;vector_map_info/line&quot;, 1, &amp;CrossWalk::lineCallback, &amp;crosswalk);
  ros::Subscriber sub_point = nh.subscribe(&quot;vector_map_info/point&quot;, 1, &amp;CrossWalk::pointCallback, &amp;crosswalk);

  // publisher
  ros::Publisher detection_range_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;detection_range&quot;, 0);
  ros::Publisher temporal_waypoints_pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;temporal_waypoints&quot;, 1000, true);
  ros::Publisher obstacle_pub = nh.advertise&lt;visualization_msgs::Marker&gt;(&quot;obstacle&quot;, 0);

  ros::Rate loop_rate(LOOP_RATE);
  while (ros::ok())
  {
    ros::spinOnce();

    if (crosswalk.loaded_all &amp;&amp; !crosswalk.set_points)
      crosswalk.setCrossWalkPoints();

    if (!vs_info.getSetPose() || !vs_path.getSetPath())
    {
      loop_rate.sleep();
      continue;
    }

    if (use_crosswalk_detection)
      crosswalk.setDetectionWaypoint(crosswalk.findClosestCrosswalk(vs_info.getClosestWaypoint(), vs_path.getPrevWaypoints(), STOP_SEARCH_DISTANCE));

    int obstacle_waypoint = -1;
    EControl detection_result = obstacleDetection(vs_info.getClosestWaypoint(), vs_path.getPrevWaypoints(), crosswalk, vs_info, detection_range_pub, obstacle_pub, &amp;obstacle_waypoint);

    changeWaypoints(vs_info, detection_result, vs_info.getClosestWaypoint(), obstacle_waypoint, temporal_waypoints_pub, &amp;vs_path);

    vs_info.clearPoints();

    loop_rate.sleep();
  }

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.cpp">
				<diff>@@ -63,7 +63,7 @@ void VelocitySetPath::setTemporalWaypoints(int temporal_waypoints_size, int clos
   temporal_waypoints_.header = new_waypoints_.header;
   temporal_waypoints_.increment = new_waypoints_.increment;
   // push current pose
-  waypoint_follower::waypoint current_point;
+  waypoint_follower_msgs::waypoint current_point;
 
   current_point.pose = control_pose;
   current_point.twist = new_waypoints_.waypoints[closest_waypoint].twist;
@@ -222,7 +222,7 @@ double VelocitySetPath::calcInterval(const int begin, const int end) const
 }
 
 
-void VelocitySetPath::waypointsCallback(const waypoint_follower::laneConstPtr&amp; msg)
+void VelocitySetPath::waypointsCallback(const waypoint_follower_msgs::laneConstPtr&amp; msg)
 {
   prev_waypoints_ = *msg;
   new_waypoints_ = *msg;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &quot;velocity_set_path.h&quot;

VelocitySetPath::VelocitySetPath()
  : set_path_(false),
    current_vel_(0)
{
  ros::NodeHandle private_nh_(&quot;~&quot;);
  private_nh_.param&lt;double&gt;(&quot;velocity_offset&quot;, velocity_offset_, 1.2);
  private_nh_.param&lt;double&gt;(&quot;decelerate_vel_min&quot;, decelerate_vel_min_, 1.3);
}

VelocitySetPath::~VelocitySetPath()
{
}

// check if waypoint number is valid
bool VelocitySetPath::checkWaypoint(int num, const char *name) const
{
  if (num &lt; 0 || num &gt;= getPrevWaypointsSize())
  {
    return false;
  }
  return true;
}

// set about '_temporal_waypoints_size' meter waypoints from closest waypoint
void VelocitySetPath::setTemporalWaypoints(int temporal_waypoints_size, int closest_waypoint, geometry_msgs::PoseStamped control_pose)
{
  if (closest_waypoint &lt; 0)
    return;

  temporal_waypoints_.waypoints.clear();
  temporal_waypoints_.header = new_waypoints_.header;
  temporal_waypoints_.increment = new_waypoints_.increment;
  // push current pose
  waypoint_follower::waypoint current_point;

  current_point.pose = control_pose;
  current_point.twist = new_waypoints_.waypoints[closest_waypoint].twist;
  current_point.dtlane = new_waypoints_.waypoints[closest_waypoint].dtlane;
  temporal_waypoints_.waypoints.push_back(current_point);
  for (int i = 0; i &lt; temporal_waypoints_size; i++)
  {
    if (closest_waypoint + i &gt;= getNewWaypointsSize())
      return;

    temporal_waypoints_.waypoints.push_back(new_waypoints_.waypoints[closest_waypoint + i]);
  }

  return;
}

void VelocitySetPath::changeWaypointsForDeceleration(double deceleration, int closest_waypoint, int obstacle_waypoint)
{
  double square_vel_min = decelerate_vel_min_ * decelerate_vel_min_;
  int extra = 4; // for safety

  // decelerate with constant deceleration
  for (int index = obstacle_waypoint + extra; index &gt;= closest_waypoint; index--)
  {
    if (!checkWaypoint(index, __FUNCTION__))
      continue;

    // v = sqrt( (v0)^2 + 2ax )
    double changed_vel = std::sqrt(square_vel_min + 2.0 * deceleration * calcInterval(index, obstacle_waypoint));

    double prev_vel = prev_waypoints_.waypoints[index].twist.twist.linear.x;
    if (changed_vel &gt; prev_vel)
    {
      new_waypoints_.waypoints[index].twist.twist.linear.x = prev_vel;
    }
    else
    {
      new_waypoints_.waypoints[index].twist.twist.linear.x = changed_vel;
    }
  }

}

void VelocitySetPath::avoidSuddenAcceleration(double deceleration, int closest_waypoint)
{
  double square_current_vel = current_vel_ * current_vel_;

  for (int i = 0;; i++)
  {
    if (!checkWaypoint(closest_waypoint + i, __FUNCTION__))
      return;

    // accelerate with constant acceleration
    // v = root((v0)^2 + 2ax)
    double changed_vel = std::sqrt(square_current_vel + 2 * deceleration * calcInterval(closest_waypoint, closest_waypoint + i)) + velocity_offset_;

    // Don't exceed original velocity
    if (changed_vel &gt; new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x)
      return;

    new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x = changed_vel;
  }

  return;
}

void VelocitySetPath::avoidSuddenDeceleration(double velocity_change_limit, double deceleration, int closest_waypoint)
{
  if (closest_waypoint &lt; 0)
    return;

  // not avoid braking
  if (current_vel_ - new_waypoints_.waypoints[closest_waypoint].twist.twist.linear.x &lt; velocity_change_limit)
    return;

  //std::cout &lt;&lt; &quot;avoid sudden braking!&quot; &lt;&lt; std::endl;

  double square_vel = (current_vel_ - velocity_change_limit) * (current_vel_ - velocity_change_limit);
  for (int i = 0;; i++)
  {
    if (!checkWaypoint(closest_waypoint + i, __FUNCTION__))
      return;

    // sqrt(v^2 - 2ax)
    double changed_vel = square_vel - 2 * deceleration * calcInterval(closest_waypoint, closest_waypoint + i);

    if (changed_vel &lt; 0)
      break;

    new_waypoints_.waypoints[closest_waypoint + i].twist.twist.linear.x = std::sqrt(changed_vel);
  }

}

void VelocitySetPath::changeWaypointsForStopping(int stop_waypoint, int obstacle_waypoint, int closest_waypoint, double deceleration)
{
  if (closest_waypoint &lt; 0)
    return;

  // decelerate with constant deceleration
  for (int index = stop_waypoint; index &gt;= closest_waypoint; index--)
  {
    if (!checkWaypoint(index, __FUNCTION__))
      continue;

    // v = (v0)^2 + 2ax, and v0 = 0
    double changed_vel = std::sqrt(2.0 * deceleration * calcInterval(index, stop_waypoint));

    double prev_vel = prev_waypoints_.waypoints[index].twist.twist.linear.x;
    if (changed_vel &gt; prev_vel)
    {
      new_waypoints_.waypoints[index].twist.twist.linear.x = prev_vel;
    }
    else
    {
      new_waypoints_.waypoints[index].twist.twist.linear.x = changed_vel;
    }
  }

  // fill velocity with 0 for stopping
  for (int i = stop_waypoint; i &lt;= obstacle_waypoint; i++)
  {
    new_waypoints_.waypoints[i].twist.twist.linear.x = 0;
  }

}

void VelocitySetPath::initializeNewWaypoints()
{
  new_waypoints_ = prev_waypoints_;
}

double VelocitySetPath::calcInterval(const int begin, const int end) const
{
  // check index
  if (begin &lt; 0 || begin &gt;= getPrevWaypointsSize() || end &lt; 0 || end &gt;= getPrevWaypointsSize())
  {
    ROS_WARN(&quot;Invalid index&quot;);
    return -1;
  }

  // Calculate the inteval of waypoints
  double dist_sum = 0;
  for (int i = begin; i &lt; end; i++)
  {
    tf::Vector3 v1(prev_waypoints_.waypoints[i].pose.pose.position.x,
                   prev_waypoints_.waypoints[i].pose.pose.position.y, 0);

    tf::Vector3 v2(prev_waypoints_.waypoints[i + 1].pose.pose.position.x,
                   prev_waypoints_.waypoints[i + 1].pose.pose.position.y, 0);

    dist_sum += tf::tfDistance(v1, v2);
  }

  return dist_sum;
}


void VelocitySetPath::waypointsCallback(const waypoint_follower::laneConstPtr&amp; msg)
{
  prev_waypoints_ = *msg;
  new_waypoints_ = *msg;

  if (!set_path_)
    set_path_ = true;
}

void VelocitySetPath::currentVelocityCallback(const geometry_msgs::TwistStampedConstPtr&amp; msg)
{
  current_vel_ = msg-&gt;twist.linear.x;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.h" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_path.h">
				<diff>@@ -31,13 +31,14 @@
 #ifndef VELOCITY_SET_PATH_H
 #define VELOCITY_SET_PATH_H
 
+#include &lt;waypoint_follower_msgs/lane.h&gt;
 #include &quot;waypoint_follower/libwaypoint_follower.h&quot;
 class VelocitySetPath
 {
  private:
-  waypoint_follower::lane prev_waypoints_;
-  waypoint_follower::lane new_waypoints_;
-  waypoint_follower::lane temporal_waypoints_;
+  waypoint_follower_msgs::lane prev_waypoints_;
+  waypoint_follower_msgs::lane new_waypoints_;
+  waypoint_follower_msgs::lane temporal_waypoints_;
   bool set_path_;
   double current_vel_;
 
@@ -59,22 +60,22 @@ class VelocitySetPath
   void initializeNewWaypoints();
 
   // ROS Callbacks
-  void waypointsCallback(const waypoint_follower::laneConstPtr&amp; msg);
+  void waypointsCallback(const waypoint_follower_msgs::laneConstPtr&amp; msg);
   void currentVelocityCallback(const geometry_msgs::TwistStampedConstPtr&amp; msg);
 
   double calcInterval(const int begin, const int end) const;
 
-  waypoint_follower::lane getPrevWaypoints() const
+  waypoint_follower_msgs::lane getPrevWaypoints() const
   {
     return prev_waypoints_;
   }
 
-  waypoint_follower::lane getNewWaypoints() const
+  waypoint_follower_msgs::lane getNewWaypoints() const
   {
     return new_waypoints_;
   }
 
-  waypoint_follower::lane getTemporalWaypoints() const
+  waypoint_follower_msgs::lane getTemporalWaypoints() const
   {
     return temporal_waypoints_;
   }
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#ifndef VELOCITY_SET_PATH_H
#define VELOCITY_SET_PATH_H

#include &quot;waypoint_follower/libwaypoint_follower.h&quot;
class VelocitySetPath
{
 private:
  waypoint_follower::lane prev_waypoints_;
  waypoint_follower::lane new_waypoints_;
  waypoint_follower::lane temporal_waypoints_;
  bool set_path_;
  double current_vel_;

  // ROS param
  double velocity_offset_; // m/s
  double decelerate_vel_min_; // m/s

  bool checkWaypoint(int num, const char *name) const;

 public:
  VelocitySetPath();
  ~VelocitySetPath();

  void changeWaypointsForStopping(int stop_waypoint, int obstacle_waypoint, int closest_waypoint, double deceleration);
  void avoidSuddenDeceleration(double velocity_change_limit, double deceleration, int closest_waypoint);
  void avoidSuddenAcceleration(double decelerationint, int closest_waypoint);
  void changeWaypointsForDeceleration(double deceleration, int closest_waypoint, int obstacle_waypoint);
  void setTemporalWaypoints(int temporal_waypoints_size, int closest_waypoint, geometry_msgs::PoseStamped control_pose);
  void initializeNewWaypoints();

  // ROS Callbacks
  void waypointsCallback(const waypoint_follower::laneConstPtr&amp; msg);
  void currentVelocityCallback(const geometry_msgs::TwistStampedConstPtr&amp; msg);

  double calcInterval(const int begin, const int end) const;

  waypoint_follower::lane getPrevWaypoints() const
  {
    return prev_waypoints_;
  }

  waypoint_follower::lane getNewWaypoints() const
  {
    return new_waypoints_;
  }

  waypoint_follower::lane getTemporalWaypoints() const
  {
    return temporal_waypoints_;
  }

  bool getSetPath() const
  {
    return set_path_;
  }

  double getCurrentVelocity() const
  {
    return current_vel_;
  }

  int getPrevWaypointsSize() const
  {
    return prev_waypoints_.waypoints.size();
  }  

  int getNewWaypointsSize() const
  {
    return new_waypoints_.waypoints.size();
  }
};

#endif // VELOCITY_SET_PATH_H
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/lattice_planner/nodes/lattice_trajectory_gen/lattice_trajectory_gen.cpp" new_path="ros/src/computing/planning/motion/packages/lattice_planner/nodes/lattice_trajectory_gen/lattice_trajectory_gen.cpp">
				<diff>@@ -124,7 +124,7 @@ static void currentVelCallback(const geometry_msgs::TwistStampedConstPtr &amp;msg)
   g_current_velocity = msg-&gt;twist.linear.x;
 }
 
-static void WayPointCallback(const waypoint_follower::laneConstPtr &amp;msg)
+static void WayPointCallback(const waypoint_follower_msgs::laneConstPtr &amp;msg)
 {
   g_current_waypoints.setPath(*msg);
   g_waypoint_set = true;
</diff>
				<old_file>/*
 *  trajectory_generator.cpp
 *  Navigation via Cubic Spline Generation 
 *
 *  Created by Matthew O'Kelly on 7/17/15.
 *  Copyright (c) 2015 Matthew O'Kelly. All rights reserved.
 *  mokelly@seas.upenn.edu
 *  
*/

/*
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
*/

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;geometry_msgs/Twist.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;
#include &lt;nav_msgs/Odometry.h&gt;
#include &lt;nav_msgs/Path.h&gt;
#include &lt;sensor_msgs/NavSatFix.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;std_msgs/Bool.h&gt;
#include &lt;std_msgs/Float32.h&gt;
#include &lt;std_msgs/Float64MultiArray.h&gt;
#include &quot;runtime_manager/ConfigWaypointFollower.h&quot;
#include &quot;waypoint_follower/libwaypoint_follower.h&quot;
#include &quot;libtraj_gen.h&quot;
#include &quot;vehicle_socket/CanInfo.h&quot;
//#include &lt;dbw_mkz_msgs/SteeringReport.h&gt;


#define DEBUG_TRAJECTORY_GEN

#define WHEEL_ANGLE_MAX (31.28067)
#define STEERING_ANGLE_MAX (666.00000)
#define WHEEL_TO_STEERING (STEERING_ANGLE_MAX/WHEEL_ANGLE_MAX)
#define WHEEL_BASE (2.70)

#define WHEEL_BASE_MKZ (2.84988)
#define WHEEL_TO_STEERING_MKZ (22.00)

static const int LOOP_RATE = 10; //Hz

static const std::string MAP_FRAME = &quot;map&quot;;
static const std::string SIM_BASE_FRAME = &quot;sim_base_link&quot;;
static const std::string BASE_FRAME = &quot;base_link&quot;;

static ros::Publisher g_marker_pub;
static ros::Publisher g_vis_pub;
static ros::Publisher g_stat_pub;

static bool g_prius_mode = FALSE;
static bool g_mkz_mode = FALSE;
static bool g_sim_mode = false;
static geometry_msgs::PoseStamped g_current_pose; // current pose by the global plane.
static double g_current_velocity;
static double g_can_info_curvature;
static double g_prev_velocity = 0;
static ros::Publisher _traj_pub;
static ros::Publisher _stat_pub;
static bool g_waypoint_set = false;
static bool g_pose_set = false;

static double g_current_angular_velocity;
static double g_mkz_info_curvature;

static int SPLINE_INDEX=0;

//config topic
static int g_param_flag = 0; //0 = waypoint, 1 = Dialog
static double g_lookahead_threshold = 4.0; //meter
static double g_initial_velocity = 5.0; //km/h
static double g_look_ahead_threshold_calc_ratio = 2.0;
static double g_minimum_look_ahead_threshold = 6.0; // the next waypoint must be outside of this threshold.

static WayPoints g_current_waypoints;

static void ConfigCallback(const runtime_manager::ConfigWaypointFollowerConstPtr &amp;config)
{
  g_param_flag = config-&gt;param_flag;
  g_lookahead_threshold = config-&gt;lookahead_distance;
  g_initial_velocity = config-&gt;velocity;
  g_look_ahead_threshold_calc_ratio = config-&gt;lookahead_ratio;
  g_minimum_look_ahead_threshold = config-&gt;minimum_lookahead_distance;
}



static void currentPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  g_current_pose = *msg;
  g_pose_set = true;
}

static void currentVelCallback(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  g_current_velocity = msg-&gt;twist.linear.x;
}

static void WayPointCallback(const waypoint_follower::laneConstPtr &amp;msg)
{
  g_current_waypoints.setPath(*msg);
  g_waypoint_set = true;
  ROS_INFO_STREAM(&quot;waypoint subscribed&quot;);
}

/*static double getCmdVelocity(int waypoint)
{

  if (g_param_flag)
  {
    ROS_INFO_STREAM(&quot;dialog : &quot; &lt;&lt; g_initial_velocity &lt;&lt; &quot; km/h (&quot; &lt;&lt; kmph2mps(g_initial_velocity) &lt;&lt; &quot; m/s )&quot;);
    return kmph2mps(g_initial_velocity);
  }

  if (g_current_waypoints.isEmpty())
  {
    ROS_INFO_STREAM(&quot;waypoint : not loaded path&quot;);
    return 0;
  }

  double velocity = g_current_waypoints.getWaypointVelocityMPS(waypoint);
  ROS_INFO_STREAM(&quot;waypoint : &quot; &lt;&lt; mps2kmph(velocity) &lt;&lt; &quot; km/h ( &quot; &lt;&lt; velocity &lt;&lt; &quot;m/s )&quot;);
  return velocity;
}
*/
static double getLookAheadThreshold(int waypoint)
{
  if (g_param_flag)
    return g_lookahead_threshold;

  // double current_velocity_mps = _current_waypoints.getWaypointVelocityMPS(waypoint);
  double current_velocity_mps = g_current_velocity;

  if (current_velocity_mps * g_look_ahead_threshold_calc_ratio &lt; g_minimum_look_ahead_threshold)
    return g_minimum_look_ahead_threshold;
  else
    return current_velocity_mps * g_look_ahead_threshold_calc_ratio;
}

static void canInfoCallback(const vehicle_socket::CanInfoConstPtr &amp;msg)
{
  double steering_wheel_angle = msg-&gt;angle;
  //g_current_velocity = (msg-&gt;speed)*(1000.00/3600);
  steering_wheel_angle = steering_wheel_angle*(3.1496/180.00);
  g_can_info_curvature = (steering_wheel_angle / (double) WHEEL_TO_STEERING) / WHEEL_BASE;
  ROS_INFO_STREAM(&quot;Steering Wheel Angle: &quot;&lt;&lt;steering_wheel_angle);
  ROS_INFO_STREAM(&quot;Curvature from CAN: &quot;&lt;&lt;g_can_info_curvature);
}

/*static void mkzInfoCallback(const dbw_mkz_msgs::SteeringReport::ConstPtr&amp; msg)
{
  double steering_wheel_angle = msg-&gt;steering_wheel_angle;
  _current_velocity = (msg-&gt;speed);
  _can_info_curvature = (steering_wheel_angle / (double) WHEEL_TO_STEERING_MKZ) / WHEEL_BASE_MKZ;
  ROS_INFO_STREAM(&quot;Steering Wheel Angle: &quot;&lt;&lt;steering_wheel_angle);
  ROS_INFO_STREAM(&quot;Curvature from CAN: &quot;&lt;&lt;_mkz_info_curvature);
}
*/

static int getNextWaypoint(int closest_waypoint)
{
  // if waypoints are not given, do nothing.
  if (g_current_waypoints.getSize() == 0)
    return -1;

  double lookahead_threshold = getLookAheadThreshold(closest_waypoint);

  //ROS_INFO_STREAM(&quot;threshold = &quot; &lt;&lt; lookahead_threshold);
  // look for the next waypoint.
  for (int i = closest_waypoint; i &lt; g_current_waypoints.getSize(); i++)
  {
    //skip waypoint behind vehicle
    if (calcRelativeCoordinate(g_current_waypoints.getCurrentWaypoints().waypoints[i].pose.pose.position,
        g_current_pose.pose).x &lt; 0)
      continue;

    // if there exists an effective waypoint
    if (getPlaneDistance(g_current_waypoints.getCurrentWaypoints().waypoints[i].pose.pose.position,
        g_current_pose.pose.position) &gt; lookahead_threshold)
      return i;
  }

  // if the program reaches here, it means we lost the waypoint.
  return -1;
}

// display the next waypoint by markers.
static void displayNextWaypoint(int i)
{

  visualization_msgs::Marker marker;
  marker.header.frame_id = MAP_FRAME;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;next_waypoint_marker&quot;;
  marker.id = 0;
  marker.type = visualization_msgs::Marker::SPHERE;
  marker.action = visualization_msgs::Marker::ADD;
  marker.pose.position = g_current_waypoints.getWaypointPosition(i);
  marker.pose.orientation = g_current_waypoints.getWaypointOrientation(i);
  marker.scale.x = 1.0;
  marker.scale.y = 1.0;
  marker.scale.z = 1.0;
  marker.color.a = 1.0;
  marker.color.r = 0.0;
  marker.color.g = 0.0;
  marker.color.b = 1.0;
  marker.frame_locked = true;
  g_vis_pub.publish(marker);
}

//////////////////////////////////////////////////////////////////////////////////////////////////
// M. O'Kelly code begins here, 
// Suggested: need to clean up unused functions above... don't have time.
/////////////////////////////////////////////////////////////////////////////////////////////////

/////////////////////////////////////////////////////////////////
// Compute the goal state of the vehicle
/////////////////////////////////////////////////////////////////
static union State computeWaypointGoal(int next_waypoint)
{
    union State l_goal;

    // Get the next waypoint position with respect to the vehicles frame
    //l_goal.sx = _path_pp.transformWaypoint(next_waypoint).getX();
    //l_goal.sy = _path_pp.transformWaypoint(next_waypoint).getY();

    l_goal.sx = calcRelativeCoordinate(g_current_waypoints.getWaypointPosition(next_waypoint),g_current_pose.pose).x;
    l_goal.sy = calcRelativeCoordinate(g_current_waypoints.getWaypointPosition(next_waypoint),g_current_pose.pose).y;

    // Get the next next waypoint position
    //double waypoint_lookahead_1_x = _path_pp.transformWaypoint(next_waypoint+1).getX();
   // double waypoint_lookahead_1_y = _path_pp.transformWaypoint(next_waypoint+1).getY();
    double waypoint_lookahead_1_x = calcRelativeCoordinate(g_current_waypoints.getWaypointPosition(next_waypoint+1),g_current_pose.pose).x;
    double waypoint_lookahead_1_y = calcRelativeCoordinate(g_current_waypoints.getWaypointPosition(next_waypoint+1),g_current_pose.pose).y;

    // Get the next next next waypoint
   // double waypoint_lookahead_2_x = _path_pp.transformWaypoint(next_waypoint+2).getX();
    //double waypoint_lookahead_2_y = _path_pp.transformWaypoint(next_waypoint+2).getY();
    double waypoint_lookahead_2_x = calcRelativeCoordinate(g_current_waypoints.getWaypointPosition(next_waypoint+2),g_current_pose.pose).x;
    double waypoint_lookahead_2_y = calcRelativeCoordinate(g_current_waypoints.getWaypointPosition(next_waypoint+2),g_current_pose.pose).y;

    // Compute dX and dY relative to lookahead
    double dX_1 =  waypoint_lookahead_1_x - l_goal.sx;
    double dY_1 =  waypoint_lookahead_1_y - l_goal.sy;

    // Compute dX and dY relative to lookahead and next lookahead
    double dX_2 =  waypoint_lookahead_2_x - waypoint_lookahead_1_x;
    double dY_2 =  waypoint_lookahead_2_y - waypoint_lookahead_1_y;

    // Estimate desired orientation of the vehicle at next waypoint
    l_goal.theta = atan(dY_1/dX_1);

    // Estimate the desired orientation at the next next waypoint
    double theta_lookahead = atan(dY_2/dX_2);

    // Estimate the arc length
    double ds = sqrt(pow(waypoint_lookahead_1_x - waypoint_lookahead_2_x, 2) + pow(waypoint_lookahead_1_x - waypoint_lookahead_2_y, 2));
    
    // Angle
    double angle = (theta_lookahead-l_goal.theta)/2.00;

    // Estimate Kappa
    double estimate = 2.00*sin(angle)/ds;
    
    l_goal.kappa = estimate;

    // Note we limit kappa from being too extreme
    // 10.0 was arbitrary, we really need a better curvature estimate
    l_goal.kappa = min((double)kmax/10.0, l_goal.kappa);

    l_goal.kappa = max ((double)kmin/10.0, l_goal.kappa); 
  
    // Get the desired velocity at the closest waypoint
    l_goal.v = g_current_waypoints.getWaypointVelocityMPS(next_waypoint);

    return l_goal;
}

/////////////////////////////////////////////////////////////////
// Compute current state of the vehicle
/////////////////////////////////////////////////////////////////
static union State computeVeh(int old_time, double old_theta, int next_waypoint)
{
    union State l_veh;

    // Goal is computed relative to vehicle coordinate frame
    l_veh.sx=0.0;
    l_veh.sy=0.0;

    // Compute yaw (orientation) relative to the world coordinate frame
    // Necessary to compute curvature, but note that in the local coordinate frame yaw is still 0.0
    tf::Quaternion q(g_current_pose.pose.orientation.x,g_current_pose.pose.orientation.y,g_current_pose.pose.orientation.z,g_current_pose.pose.orientation.w);
    tf::Matrix3x3 m(q);
    double roll,pitch,yaw;
    m.getRPY(roll,pitch,yaw);

    // Because we are on the coordinate system of the base frame
    l_veh.theta = 0.0;

    // Get the current velocity of the vehicle
    l_veh.v = g_current_velocity;

    // Get the desired velocity
    l_veh.vdes = g_current_waypoints.getWaypointVelocityMPS(next_waypoint);
    ROS_INFO_STREAM(&quot;Desired Velocity: &quot;&lt;&lt; l_veh.vdes);

    // Not using timing related stuff for now...
    double w = g_current_angular_velocity;
    ROS_INFO_STREAM(&quot;Current omega: &quot; &lt;&lt;w);
    l_veh.kappa = w/l_veh.vdes;


    if (!g_sim_mode &amp;&amp; g_prius_mode)
    {
     l_veh.kappa = g_can_info_curvature;
     ROS_INFO_STREAM(&quot;Current kappa (prius): &quot; &lt;&lt;l_veh.kappa);
    }

    else if(!g_sim_mode &amp;&amp; g_mkz_mode)
    {
      l_veh.kappa = g_mkz_info_curvature;
      ROS_INFO_STREAM(&quot;Current kappa (mkz): &quot; &lt;&lt;l_veh.kappa);
    }

    else
    {
      double w = g_current_angular_velocity;
      l_veh.kappa = w/l_veh.vdes;
      ROS_INFO_STREAM(&quot;Current kappa (sim): &quot; &lt;&lt;l_veh.kappa);
    }

    return l_veh;
}

/////////////////////////////////////////////////////////////////
// Compute trajectory
/////////////////////////////////////////////////////////////////
static union Spline waypointTrajectory(union State veh, union State goal, union Spline curvature, int next_waypoint)
{
    curvature.success=TRUE;  
    bool convergence=FALSE;
    int iteration = 0;
    union State veh_next;
    double dt = step_size;
    veh.v=goal.v;

    // While loop for computing trajectory parameters
    while(convergence == FALSE &amp;&amp; iteration&lt;4)
    {
        // Set time horizon
        double horizon = curvature.s/veh.vdes;
        ROS_INFO_STREAM(&quot;vdes: &quot; &lt;&lt; veh.vdes);
        ROS_INFO_STREAM(&quot;horizon: &quot; &lt;&lt; horizon);

        // Run motion model
        veh_next = motionModel(veh, goal, curvature, dt, horizon, 0);
        
        // Determine convergence criteria
        convergence = checkConvergence(veh_next, goal);

        // If the motion model doesn't get us to the goal compute new parameters
        if(convergence==FALSE)
        {
            // Update parameters
            curvature = generateCorrection(veh, veh_next, goal, curvature, dt, horizon);
            iteration++;

            // Escape route for poorly conditioned Jacobian
            if(curvature.success==FALSE)
            {
                ROS_INFO_STREAM(&quot;Init State: sx &quot;&lt;&lt;veh.sx&lt;&lt;&quot; sy &quot; &lt;&lt;veh.sy&lt;&lt;&quot; theta &quot;&lt;&lt;veh.theta&lt;&lt;&quot; kappa &quot;&lt;&lt;veh.kappa&lt;&lt;&quot; v &quot;&lt;&lt;veh.v);
                ROS_INFO_STREAM(&quot;Goal State: sx &quot;&lt;&lt;goal.sx&lt;&lt;&quot; sy &quot; &lt;&lt;goal.sy&lt;&lt;&quot; theta &quot;&lt;&lt;goal.theta&lt;&lt;&quot; kappa &quot;&lt;&lt;goal.kappa&lt;&lt;&quot; v&quot;&lt;&lt;goal.v);
                break;
            }
        }    
    }

    if(convergence==FALSE)
    {
      ROS_INFO_STREAM(&quot;Next State: sx &quot;&lt;&lt;veh_next.sx&lt;&lt;&quot; sy &quot; &lt;&lt;veh_next.sy&lt;&lt;&quot; theta &quot;&lt;&lt;veh_next.theta&lt;&lt;&quot; kappa &quot;&lt;&lt;veh_next.kappa&lt;&lt;&quot; v &quot;&lt;&lt;veh_next.v);
      ROS_INFO_STREAM(&quot;Init State: sx &quot;&lt;&lt;veh.sx&lt;&lt;&quot; sy &quot; &lt;&lt;veh.sy&lt;&lt;&quot; theta &quot;&lt;&lt;veh.theta&lt;&lt;&quot; kappa &quot;&lt;&lt;veh.kappa);
      ROS_INFO_STREAM(&quot;Goal State: sx &quot;&lt;&lt;goal.sx&lt;&lt;&quot; sy &quot; &lt;&lt;goal.sy&lt;&lt;&quot; theta &quot;&lt;&lt;goal.theta&lt;&lt;&quot; kappa &quot;&lt;&lt;goal.kappa);
      curvature.success= FALSE;
    }

    else
    {
        ROS_INFO_STREAM(&quot;Converged in &quot;&lt;&lt;iteration&lt;&lt;&quot; iterations&quot;);

        #ifdef LOG_OUTPUT
        // Set time horizon
         double horizon = curvature.s/v_0;
        // Run motion model and log data for plotting
        veh_next = motionModel(veh, goal, curvature, 0.1, horizon, 1);
        fmm_sx&lt;&lt;&quot;0.0 \n&quot;;
        fmm_sy&lt;&lt;&quot;0.0 \n&quot;;
        #endif
    }

    return curvature;
}

/////////////////////////////////////////////////////////////////
// Draw Spline
/////////////////////////////////////////////////////////////////
static void drawSpline(union Spline curvature, union State veh, int flag, int selected)
{
  static double vdes=veh.vdes;
  // Setup up line strips
  visualization_msgs:: Marker line_strip;
  if (!g_sim_mode)
  {
    line_strip.header.frame_id = BASE_FRAME;
  }
  else
  {
    line_strip.header.frame_id = SIM_BASE_FRAME;
  }
  line_strip.header.stamp = ros::Time();
  line_strip.action = visualization_msgs::Marker::ADD;


  // Define message id and scale (thickness)
  line_strip.id = flag;
  line_strip.type = visualization_msgs::Marker::LINE_STRIP;
  

  // Set the color and transparency (blue and solid) if not selected
  if(selected&gt;0)
  {
    line_strip.scale.x = 0.08;
    line_strip.color.r = 1.0;
    line_strip.color.a = 1.0;
  }

  // Set the color and transparency (green and solid) if selected  
  else
  {
    line_strip.scale.x = 0.1;
    line_strip.color.g= 1.0;
    line_strip.color.a = 1.0;
  }


  // Init temp state for storing results of genLineStrip
  union State temp;

  // Init time
  double sim_time = 0.0;

  // Figure out sim time horizon
  double horizon = curvature.s/veh.vdes;

  // Init points
  geometry_msgs::Point p;

  // Create veritices
  while(sim_time&lt;horizon &amp;&amp; curvature.success==TRUE)
  {
    temp = genLineStrip(veh, curvature, vdes, sim_time);
    p.x = temp.sx;
    p.y = temp.sy;
    p.z = 0.0;
    line_strip.points.push_back(p);
    veh= temp;
    sim_time = sim_time+ plot_step_size;
  }

  // Publish trajectory line strip (to RViz)
  g_marker_pub.publish(line_strip);

}

/////////////////////////////////////////////////////////////////
// MAIN
/////////////////////////////////////////////////////////////////

int main(int argc, char **argv)
{
  // These are local variables for keeping track of the previous
  // timestamp and orientation. Used in the estimate of curvature...
  int old_time=0;
  double old_theta=0.0;

  // Write to console that we are starting trajectory generation
  ROS_INFO_STREAM(&quot;Trajectory Generation Begins: &quot;);

  // Set up ROS, TO DO: change to proper name (same with rest of the file)
  ros::init(argc, argv, &quot;lattice_trajectory_gen&quot;);

  // Create node handles 
  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  // Set the parameters for the node
  private_nh.getParam(&quot;sim_mode&quot;, g_sim_mode);
  private_nh.getParam(&quot;prius_mode&quot;, g_prius_mode);
  private_nh.getParam(&quot;mkz_mode&quot;, g_mkz_mode);
  ROS_INFO_STREAM(&quot;sim_mode : &quot; &lt;&lt; g_sim_mode);
  ROS_INFO_STREAM(&quot;prius_mode : &quot; &lt;&lt; g_prius_mode);
  ROS_INFO_STREAM(&quot;mkz_mode : &quot; &lt;&lt; g_mkz_mode);

  // Publish the following topics: 
  g_vis_pub = nh.advertise&lt;visualization_msgs::Marker&gt;(&quot;next_waypoint_mark&quot;, 1);
  g_stat_pub = nh.advertise&lt;std_msgs::Bool&gt;(&quot;wf_stat&quot;, 0);
  // Publish the curvature information:
  ros::Publisher spline_parameters_pub = nh.advertise&lt;std_msgs::Float64MultiArray&gt;(&quot;spline&quot;, 10);
  ros::Publisher state_parameters_pub = nh.advertise&lt;std_msgs::Float64MultiArray&gt;(&quot;state&quot;, 10);
  // Publish the trajectory visualization
  g_marker_pub = nh.advertise&lt;visualization_msgs::Marker&gt;(&quot;cubic_splines_viz&quot;, 10);

  // Subscribe to the following topics: 
  ros::Subscriber waypoint_subcscriber = nh.subscribe(&quot;final_waypoints&quot;, 1, WayPointCallback);
  ros::Subscriber current_pose_subscriber = nh.subscribe(&quot;current_pose&quot;, 1, currentPoseCallback);
  ros::Subscriber current_vel_subscriber = nh.subscribe(&quot;current_velocity&quot;, 1, currentVelCallback);
  ros::Subscriber config_subscriber = nh.subscribe(&quot;config/waypoint_follower&quot;, 1, ConfigCallback);
  ros::Subscriber sub_steering;
  ros::Subscriber can_info;

  if(g_prius_mode)
  {
    can_info = nh.subscribe(&quot;can_info&quot;, 1, canInfoCallback);
  }

  
/*  else if(_mkz_mode)
    {
    ROS_INFO_STREAM(&quot;********************mkz_mode ON&quot;);
    sub_steering = nh.subscribe(&quot;/vehicle/steering_report&quot;, 1, mkzInfoCallback);
    }
  */

  // Local variable for geometry messages
  geometry_msgs::TwistStamped twist;

  // Set the loop rate unit is Hz
  ros::Rate loop_rate(LOOP_RATE); 

  // Set up arrays for perturb and flag to enable easy parallelization via OpenMP pragma
  double perturb[30];
  perturb[0]=-3.00;

  int flag[30];
  flag[0]=1;

  for(int i=1; i&lt;30; i++)
  {
    perturb[i] = perturb[i-1] + 0.2;
    flag[i-1] = flag[i]+1;
  }
  bool initFlag = FALSE;
  union Spline prev_curvature;
  union State veh_fmm;

  // Here we go....
  while (ros::ok())
  {
    std_msgs::Bool _lf_stat;

    ros::spinOnce();

    // Wait for waypoints (in Runtime Manager) and pose to be set (in RViz)
    if (g_waypoint_set == false || g_pose_set == false)
    {
      ROS_INFO_STREAM(&quot;topic waiting...&quot;);
      loop_rate.sleep();
      continue;
    }

    // Get the closest waypoinmt
    int closest_waypoint = getClosestWaypoint(g_current_waypoints.getCurrentWaypoints(), g_current_pose.pose);
    ROS_INFO_STREAM(&quot;closest waypoint = &quot; &lt;&lt; closest_waypoint);

      // If the current  waypoint has a valid index
      if (closest_waypoint &gt; 0)
      {
        // Return the next waypoint
        int next_waypoint = getNextWaypoint(closest_waypoint);
        ROS_INFO_STREAM(&quot;Next waypoint: &quot;&lt;&lt;next_waypoint);

        // If the next waypoiont also has a valid index
        if (next_waypoint &gt; 0)
        {
          // Display and publish waypoint information 
          displayNextWaypoint(next_waypoint);
          _lf_stat.data = true;
          _stat_pub.publish(_lf_stat);

          // Determine the desired state of the vehicle at the next waypoint 
          union State goal = computeWaypointGoal(next_waypoint);
          
          // Estimate the current state of the vehicle
          union State veh = computeVeh(old_time, old_theta, next_waypoint);

          if(initFlag==TRUE &amp;&amp; prev_curvature.success==TRUE)
          {
            veh_fmm = nextState(veh, prev_curvature, veh.vdes, 0.2, 0);
            ROS_INFO_STREAM(&quot;est kappa: &quot; &lt;&lt;veh_fmm.kappa);
          }
        
          // Initialize the estimate for the curvature
          union Spline curvature = initParams(veh, goal);

          // Generate a cubic spline (trajectory) for the vehicle to follow
          curvature = waypointTrajectory(veh, goal, curvature, next_waypoint);
          prev_curvature = curvature;
          initFlag=TRUE;

          // Check that we got a result and publish it or stream expletive to screen
          if(curvature.success==TRUE)
          { 
            std_msgs::Float64MultiArray spline;
  	        spline.data.clear();

            for(int i = 0; i &lt; 6;i++)
            {
              spline.data.push_back(curvature.spline_value[i]);
            }

          spline_parameters_pub.publish(spline);
          }
          else 
          {
            ROS_INFO_STREAM(&quot;SPLINE FAIL&quot;);
          }

          // Also publish the state at the time of the result for curvature...
          std_msgs::Float64MultiArray state;
          state.data.clear();
          for(int i = 0; i &lt; 7; i++)
          {
            state.data.push_back(veh.state_value[i]);
          }

          state_parameters_pub.publish(state);

          // Need to hold back on extra trajectories until CPU utilization is figured out...
          // Need cost map etc...
          if(g_sim_mode)
          {
              // If the velocity is nonzero (would preclude horizon calc) publish trajectory viz
              if(veh.v&gt;0)
              {
                drawSpline(curvature, veh, 0,0);
                SPLINE_INDEX++;
                ROS_INFO_STREAM(&quot;Spline published to RVIZ&quot;);
              }
              
                // This is a messy for loop which generates extra trajectories for visualization
                // Likely will change when valid cost map arrives.
                // Note: pragma indicates parallelization for OpenMP

                // Setup variables
                union State tempGoal= goal;
                int i;
                union Spline extra;
                
                // Tell OpenMP how to parallelize (keep i private because it is a counter)
                #pragma omp parallel for private(i)

                // Index through all the predefined perturbations from waypoint
                for(i=1; i&lt;31; i++)
                {
                  // Shift the y-coordinate of the goal
                  tempGoal.sy = tempGoal.sy + perturb[i-1];

                  // Compute new spline 
                  extra= waypointTrajectory(veh, tempGoal, curvature, next_waypoint);

                  // Display trajectory
                  if(veh.v&gt;5.00)
                  {
                    drawSpline(extra, veh, i,1);
                  }
                }
          }

          // Update previous time and orientation measurements
          old_time= veh.timestamp;
          old_theta=veh.theta;
        }
        // If the next way point is not available 
        else 
        {
          ROS_INFO_STREAM(&quot;Lost waypoint!&quot;);
          _lf_stat.data = false;
          _stat_pub.publish(_lf_stat);
          twist.twist.linear.x = 0;
          twist.twist.angular.z = 0;
        }

      }

    g_prev_velocity = twist.twist.linear.x;
    loop_rate.sleep();
  }

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/lattice_planner/nodes/lattice_velocity_set/lattice_velocity_set.cpp" new_path="ros/src/computing/planning/motion/packages/lattice_planner/nodes/lattice_velocity_set/lattice_velocity_set.cpp">
				<diff>@@ -46,7 +46,7 @@
 #include &lt;runtime_manager/ConfigLatticeVelocitySet.h&gt;
 #include &lt;iostream&gt;
 
-#include &quot;waypoint_follower/lane.h&quot;
+#include &quot;waypoint_follower_msgs/lane.h&quot;
 #include &quot;waypoint_follower/libwaypoint_follower.h&quot;
 #include &quot;libvelocity_set.h&quot;
 
@@ -97,7 +97,7 @@ WayPoints g_path_dk;
 class PathVset : public WayPoints
 {
 private:
-  waypoint_follower::lane temporal_waypoints_;
+  waypoint_follower_msgs::lane temporal_waypoints_;
 
 public:
   void changeWaypoints(int stop_waypoint);
@@ -106,7 +106,7 @@ public:
   void setDeceleration();
   bool checkWaypoint(int num, const char *name) const;
   void setTemporalWaypoints();
-  waypoint_follower::lane getTemporalWaypoints() const
+  waypoint_follower_msgs::lane getTemporalWaypoints() const
   {
     return temporal_waypoints_;
   }
@@ -138,7 +138,7 @@ void PathVset::setTemporalWaypoints()
   temporal_waypoints_.header = current_waypoints_.header;
   temporal_waypoints_.increment = current_waypoints_.increment;
   // push current pose
-  waypoint_follower::waypoint current_point;
+  waypoint_follower_msgs::waypoint current_point;
 
   current_point.pose = g_control_pose;
   current_point.twist = current_waypoints_.waypoints[g_closest_waypoint].twist;
@@ -279,7 +279,7 @@ void PathVset::changeWaypoints(int stop_waypoint)
 
     changed_vel = sqrt(2.0 * g_decel * (interval * i));  // sqrt(2*a*x)
 
-    waypoint_follower::waypoint initial_waypoint = g_path_dk.getCurrentWaypoints().waypoints[num];
+    waypoint_follower_msgs::waypoint initial_waypoint = g_path_dk.getCurrentWaypoints().waypoints[num];
     if (changed_vel &gt; initial_waypoint.twist.twist.linear.x)
     {  // avoid acceleration
       current_waypoints_.waypoints[num].twist.twist.linear.x = initial_waypoint.twist.twist.linear.x;
@@ -330,7 +330,7 @@ void currentVelCallback(const geometry_msgs::TwistStampedConstPtr &amp;msg)
   g_current_vel = msg-&gt;twist.linear.x;
 }
 
-void baseWaypointCallback(const waypoint_follower::laneConstPtr &amp;msg)
+void baseWaypointCallback(const waypoint_follower_msgs::laneConstPtr &amp;msg)
 {
   g_path_dk.setPath(*msg);
   g_path_change.setPath(*msg);
@@ -838,7 +838,7 @@ int main(int argc, char **argv)
 
   g_range_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;detection_range&quot;, 0);
   g_sound_pub = nh.advertise&lt;std_msgs::String&gt;(&quot;sound_player&quot;, 10);
-  g_temporal_waypoints_pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;temporal_waypoints&quot;, 1000, true);
+  g_temporal_waypoints_pub = nh.advertise&lt;waypoint_follower_msgs::lane&gt;(&quot;temporal_waypoints&quot;, 1000, true);
   ros::Publisher closest_waypoint_pub;
   closest_waypoint_pub = nh.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 1000);
   g_obstacle_pub = nh.advertise&lt;visualization_msgs::Marker&gt;(&quot;obstacle&quot;, 0);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &lt;ros/ros.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/PoseArray.h&gt;
#include &lt;geometry_msgs/Point.h&gt;
#include &lt;nav_msgs/Odometry.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/io/io.h&gt;
#include &lt;pcl/io/pcd_io.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;std_msgs/Float32.h&gt;
#include &lt;std_msgs/Int32.h&gt;
#include &lt;runtime_manager/ConfigLatticeVelocitySet.h&gt;
#include &lt;iostream&gt;

#include &quot;waypoint_follower/lane.h&quot;
#include &quot;waypoint_follower/libwaypoint_follower.h&quot;
#include &quot;libvelocity_set.h&quot;

namespace
{

const int LOOP_RATE = 10;

geometry_msgs::TwistStamped g_current_twist;
geometry_msgs::PoseStamped g_localizer_pose;  // pose of sensor
geometry_msgs::PoseStamped g_control_pose;  // pose of base_link
pcl::PointCloud&lt;pcl::PointXYZ&gt; g_vscan;

const std::string pedestrian_sound = &quot;pedestrian&quot;;
bool g_pose_flag = false;
bool g_path_flag = false;
bool g_vscan_flag = false;
int g_obstacle_waypoint = -1;
double g_deceleration_search_distance = 30;
double g_search_distance = 60;
int g_closest_waypoint = -1;
double g_current_vel = 0.0;  // (m/s) subscribe estimated_vel
CrossWalk vmap;
ObstaclePoints g_obstacle;

/* Config Parameter */
double g_detection_range = 0;                   // if obstacle is in this range, stop
double g_deceleration_range = 1.8;              // if obstacle is in this range, decelerate
int g_threshold_points = 15;
double g_detection_height_top = 2.0;  // actually +2.0m
double g_detection_height_bottom = -2.0;
double g_others_distance = 8.0;            // meter: stopping distance from obstacles (using VSCAN)
double g_decel = 1.5;                      // (m/s) deceleration
double g_velocity_change_limit = 2.778;    // (m/s) about 10 km/h
double g_temporal_waypoints_size = 100.0;  // meter

// Publisher
ros::Publisher g_range_pub;
ros::Publisher g_deceleration_range_pub;
ros::Publisher g_sound_pub;
ros::Publisher g_safety_waypoint_pub;
ros::Publisher g_temporal_waypoints_pub;
ros::Publisher g_crosswalk_points_pub;
ros::Publisher g_obstacle_pub;

WayPoints g_path_dk;

class PathVset : public WayPoints
{
private:
  waypoint_follower::lane temporal_waypoints_;

public:
  void changeWaypoints(int stop_waypoint);
  void avoidSuddenBraking();
  void avoidSuddenAceleration();
  void setDeceleration();
  bool checkWaypoint(int num, const char *name) const;
  void setTemporalWaypoints();
  waypoint_follower::lane getTemporalWaypoints() const
  {
    return temporal_waypoints_;
  }
};
PathVset g_path_change;

//===============================
//       class function
//===============================

// check if waypoint number is valid
bool PathVset::checkWaypoint(int num, const char *name) const
{
  if (num &lt; 0 || num &gt;= getSize())
  {
    return false;
  }
  return true;
}

// set about '_temporal_waypoints_size' meter waypoints from closest waypoint
void PathVset::setTemporalWaypoints()
{
  if (g_closest_waypoint &lt; 0)
    return;
  int size = (int)(g_temporal_waypoints_size / getInterval()) + 1;

  temporal_waypoints_.waypoints.clear();
  temporal_waypoints_.header = current_waypoints_.header;
  temporal_waypoints_.increment = current_waypoints_.increment;
  // push current pose
  waypoint_follower::waypoint current_point;

  current_point.pose = g_control_pose;
  current_point.twist = current_waypoints_.waypoints[g_closest_waypoint].twist;
  current_point.dtlane = current_waypoints_.waypoints[g_closest_waypoint].dtlane;
  temporal_waypoints_.waypoints.push_back(current_point);
  for (int i = 0; i &lt; size; i++)
  {
    if (g_closest_waypoint + i &gt;= getSize())
      return;
    temporal_waypoints_.waypoints.push_back(current_waypoints_.waypoints[g_closest_waypoint + i]);
  }

  return;
}

void PathVset::setDeceleration()
{
  int velocity_change_range = 5;
  double intervel = getInterval();
  double temp1 = g_current_vel * g_current_vel;
  double temp2 = 2 * g_decel * intervel;
  double deceleration_minimum = kmph2mps(4.0);

  for (int i = 0; i &lt; velocity_change_range; i++)
  {
    if (!checkWaypoint(g_closest_waypoint + i, &quot;setDeceleration&quot;))
      continue;
    double waypoint_velocity = current_waypoints_.waypoints[g_closest_waypoint + i].twist.twist.linear.x;
    double changed_vel = temp1 - temp2;
    if (changed_vel &lt; 0)
    {
      changed_vel = deceleration_minimum * deceleration_minimum;
    }
    if (sqrt(changed_vel) &gt; waypoint_velocity || deceleration_minimum &gt; waypoint_velocity)
      continue;
    if (sqrt(changed_vel) &lt; deceleration_minimum)
    {
      current_waypoints_.waypoints[g_closest_waypoint + i].twist.twist.linear.x = deceleration_minimum;
      continue;
    }
    current_waypoints_.waypoints[g_closest_waypoint + i].twist.twist.linear.x = sqrt(changed_vel);
  }

  return;
}

void PathVset::avoidSuddenAceleration()
{
  double changed_vel;
  double interval = getInterval();
  double temp1 = g_current_vel * g_current_vel;
  double temp2 = 2 * g_decel * interval;
  double velocity_offset = 1.389; // m/s

  for (int i = 0;; i++)
  {
    if (!checkWaypoint(g_closest_waypoint + i, &quot;avoidSuddenAceleration&quot;))
      return;
    changed_vel = sqrt(temp1 + temp2 * (double)(i + 1)) + velocity_offset;
    if (changed_vel &gt; current_waypoints_.waypoints[g_closest_waypoint + i].twist.twist.linear.x)
      return;
    current_waypoints_.waypoints[g_closest_waypoint + i].twist.twist.linear.x = changed_vel;
  }

  return;
}

void PathVset::avoidSuddenBraking()
{
  int i = 0;
  int fill_in_zero = 20;
  int fill_in_vel = 15;
  int examin_range = 1;  // need to change according to waypoint interval?
  int num;
  double interval = getInterval();
  double changed_vel;

  for (int j = -1; j &lt; examin_range; j++)
  {
    if (!checkWaypoint(g_closest_waypoint + j, &quot;avoidSuddenBraking&quot;))
      return;
    if (getWaypointVelocityMPS(g_closest_waypoint + j) &lt;
        g_current_vel - g_velocity_change_limit)  // we must change waypoints
      break;
    if (j == examin_range - 1)  // we don't have to change waypoints
      return;
  }

  // fill in waypoints velocity behind vehicle
  for (num = g_closest_waypoint - 1; fill_in_vel &gt; 0; fill_in_vel--)
  {
    if (!checkWaypoint(num - fill_in_vel, &quot;avoidSuddenBraking&quot;))
      continue;
    current_waypoints_.waypoints[num - fill_in_vel].twist.twist.linear.x = g_current_vel;
  }

  // decelerate gradually
  double temp1 = (g_current_vel - g_velocity_change_limit + 1.389) * (g_current_vel - g_velocity_change_limit + 1.389);
  double temp2 = 2 * g_decel * interval;
  for (num = g_closest_waypoint - 1;; num++)
  {
    if (num &gt;= getSize())
      return;
    if (!checkWaypoint(num, &quot;avoidSuddenBraking&quot;))
      continue;
    changed_vel = temp1 - temp2 * (double)i;  // sqrt(v^2 - 2*a*x)
    if (changed_vel &lt;= 0)
      break;
    current_waypoints_.waypoints[num].twist.twist.linear.x = sqrt(changed_vel);

    i++;
  }

  for (int j = 0; j &lt; fill_in_zero; j++)
  {
    if (!checkWaypoint(num + j, &quot;avoidSuddenBraking&quot;))
      continue;
    current_waypoints_.waypoints[num + j].twist.twist.linear.x = 0.0;
  }


  return;
}

void PathVset::changeWaypoints(int stop_waypoint)
{
  int i = 0;
  int close_waypoint_threshold = 4;
  int fill_in_zero = 20;
  double changed_vel;
  double interval = getInterval();

  // change waypoints to decelerate
  for (int num = stop_waypoint; num &gt; g_closest_waypoint - close_waypoint_threshold; num--)
  {
    if (!checkWaypoint(num, &quot;changeWaypoints&quot;))
      continue;

    changed_vel = sqrt(2.0 * g_decel * (interval * i));  // sqrt(2*a*x)

    waypoint_follower::waypoint initial_waypoint = g_path_dk.getCurrentWaypoints().waypoints[num];
    if (changed_vel &gt; initial_waypoint.twist.twist.linear.x)
    {  // avoid acceleration
      current_waypoints_.waypoints[num].twist.twist.linear.x = initial_waypoint.twist.twist.linear.x;
    }
    else
    {
      current_waypoints_.waypoints[num].twist.twist.linear.x = changed_vel;
    }

    i++;
  }

  // fill in 0
  for (int j = 1; j &lt; fill_in_zero; j++)
  {
    if (!checkWaypoint(stop_waypoint + j, &quot;changeWaypoints&quot;))
      continue;
    current_waypoints_.waypoints[stop_waypoint + j].twist.twist.linear.x = 0.0;
  }


  return;
}

//===============================
//       class function
//===============================

//===============================
//          Callback
//===============================

void configCallback(const runtime_manager::ConfigLatticeVelocitySetConstPtr &amp;config)
{
  g_others_distance = config-&gt;others_distance;
  g_detection_range = config-&gt;detection_range;
  g_threshold_points = config-&gt;threshold_points;
  g_detection_height_top = config-&gt;detection_height_top;
  g_detection_height_bottom = config-&gt;detection_height_bottom;
  g_decel = config-&gt;deceleration;
  g_velocity_change_limit = kmph2mps(config-&gt;velocity_change_limit);
  g_deceleration_range = config-&gt;deceleration_range;
  g_temporal_waypoints_size = config-&gt;temporal_waypoints_size;
}

void currentVelCallback(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  g_current_vel = msg-&gt;twist.linear.x;
}

void baseWaypointCallback(const waypoint_follower::laneConstPtr &amp;msg)
{
  g_path_dk.setPath(*msg);
  g_path_change.setPath(*msg);
  if (g_path_flag == false)
  {
    g_path_flag = true;
  }
}

void objPoseCallback(const visualization_msgs::MarkerConstPtr &amp;msg)
{
  //ROS_INFO(&quot;subscribed obj_pose\n&quot;);
}

void vscanCallback(const sensor_msgs::PointCloud2ConstPtr &amp;msg)
{
  pcl::PointCloud&lt;pcl::PointXYZ&gt; vscan_raw;
  pcl::fromROSMsg(*msg, vscan_raw);

  g_vscan.clear();
  for (const auto &amp;v : vscan_raw)
  {
    if (v.x == 0 &amp;&amp; v.y == 0)
      continue;
    if (v.z &gt; g_detection_height_top || v.z &lt; g_detection_height_bottom)
      continue;
    g_vscan.push_back(v);
  }

  if (g_vscan_flag == false)
  {
    g_vscan_flag = true;
  }
}

void controlCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  if (!g_pose_flag)
    g_pose_flag = true;

  g_control_pose.header = msg-&gt;header;
  g_control_pose.pose = msg-&gt;pose;
}

void localizerCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  g_localizer_pose.header = msg-&gt;header;
  g_localizer_pose.pose = msg-&gt;pose;
}


//===============================
//          Callback
//===============================

void displayObstacle(const EControl &amp;kind)
{
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;/map&quot;;
  marker.header.stamp = ros::Time();
  marker.ns = &quot;my_namespace&quot;;
  marker.id = 0;
  marker.type = visualization_msgs::Marker::CUBE;
  marker.action = visualization_msgs::Marker::ADD;
  marker.pose.position = g_obstacle.getObstaclePoint(kind);
  if (kind == OTHERS)
    marker.pose.position = g_obstacle.getPreviousDetection();
  marker.pose.orientation = g_localizer_pose.pose.orientation;
  marker.scale.x = 1.0;
  marker.scale.y = 1.0;
  marker.scale.z = 2.0;
  marker.color.a = 0.7;
  if (kind == STOP)
  {
    marker.color.r = 1.0;
    marker.color.g = 0.0;
    marker.color.b = 0.0;
  }
  else
  {
    marker.color.r = 1.0;
    marker.color.g = 1.0;
    marker.color.b = 0.0;
  }
  marker.lifetime = ros::Duration(0.1);
  marker.frame_locked = true;

  g_obstacle_pub.publish(marker);
}

void displayDetectionRange(const int &amp;crosswalk_id, const int &amp;num, const EControl &amp;kind)
{
  // set up for marker array
  visualization_msgs::MarkerArray marker_array;
  visualization_msgs::Marker crosswalk_marker;
  visualization_msgs::Marker waypoint_marker_stop;
  visualization_msgs::Marker waypoint_marker_decelerate;
  visualization_msgs::Marker stop_line;
  crosswalk_marker.header.frame_id = &quot;/map&quot;;
  crosswalk_marker.header.stamp = ros::Time();
  crosswalk_marker.id = 0;
  crosswalk_marker.type = visualization_msgs::Marker::SPHERE_LIST;
  crosswalk_marker.action = visualization_msgs::Marker::ADD;
  waypoint_marker_stop = crosswalk_marker;
  waypoint_marker_decelerate = crosswalk_marker;
  stop_line = crosswalk_marker;
  stop_line.type = visualization_msgs::Marker::CUBE;

  // set each namespace
  crosswalk_marker.ns = &quot;Crosswalk Detection&quot;;
  waypoint_marker_stop.ns = &quot;Stop Detection&quot;;
  waypoint_marker_decelerate.ns = &quot;Decelerate Detection&quot;;
  stop_line.ns = &quot;Stop Line&quot;;

  // set scale and color
  double scale = 2 * g_detection_range;
  waypoint_marker_stop.scale.x = scale;
  waypoint_marker_stop.scale.y = scale;
  waypoint_marker_stop.scale.z = scale;
  waypoint_marker_stop.color.a = 0.2;
  waypoint_marker_stop.color.r = 0.0;
  waypoint_marker_stop.color.g = 1.0;
  waypoint_marker_stop.color.b = 0.0;
  waypoint_marker_stop.frame_locked = true;

  scale = 2 * (g_detection_range + g_deceleration_range);
  waypoint_marker_decelerate.scale.x = scale;
  waypoint_marker_decelerate.scale.y = scale;
  waypoint_marker_decelerate.scale.z = scale;
  waypoint_marker_decelerate.color.a = 0.15;
  waypoint_marker_decelerate.color.r = 1.0;
  waypoint_marker_decelerate.color.g = 1.0;
  waypoint_marker_decelerate.color.b = 0.0;
  waypoint_marker_decelerate.frame_locked = true;

  if (g_obstacle_waypoint &gt; -1)
  {
    stop_line.pose.position = g_path_dk.getWaypointPosition(g_obstacle_waypoint);
    stop_line.pose.orientation = g_path_dk.getWaypointOrientation(g_obstacle_waypoint);
  }
  stop_line.pose.position.z += 1.0;
  stop_line.scale.x = 0.1;
  stop_line.scale.y = 15.0;
  stop_line.scale.z = 2.0;
  stop_line.color.a = 0.3;
  stop_line.color.r = 1.0;
  stop_line.color.g = 0.0;
  stop_line.color.b = 0.0;
  stop_line.lifetime = ros::Duration(0.1);
  stop_line.frame_locked = true;

  if (crosswalk_id &gt; 0)
    scale = vmap.getDetectionPoints(crosswalk_id).width;
  crosswalk_marker.scale.x = scale;
  crosswalk_marker.scale.y = scale;
  crosswalk_marker.scale.z = scale;
  crosswalk_marker.color.a = 0.5;
  crosswalk_marker.color.r = 0.0;
  crosswalk_marker.color.g = 1.0;
  crosswalk_marker.color.b = 0.0;
  crosswalk_marker.frame_locked = true;

  // set marker points coordinate
  for (int i = 0; i &lt; g_search_distance; i++)
  {
    if (num &lt; 0 || i + num &gt; g_path_dk.getSize() - 1)
      break;

    geometry_msgs::Point point;
    point = g_path_dk.getWaypointPosition(num + i);

    waypoint_marker_stop.points.push_back(point);

    if (i &gt; g_deceleration_search_distance)
      continue;
    waypoint_marker_decelerate.points.push_back(point);
  }

  if (crosswalk_id &gt; 0)
  {
    for (const auto &amp;p : vmap.getDetectionPoints(crosswalk_id).points)
      crosswalk_marker.points.push_back(p);
  }

  // publish marker
  marker_array.markers.push_back(crosswalk_marker);
  marker_array.markers.push_back(waypoint_marker_stop);
  marker_array.markers.push_back(waypoint_marker_decelerate);
  if (kind == STOP)
    marker_array.markers.push_back(stop_line);
  g_range_pub.publish(marker_array);
  marker_array.markers.clear();
}

int findCrossWalk()
{
  if (!vmap.set_points || g_closest_waypoint &lt; 0)
    return -1;

  double find_distance = 2.0 * 2.0;      // meter
  double ignore_distance = 20.0 * 20.0;  // meter
  static std::vector&lt;int&gt; bdid = vmap.getBDID();
  // Find near cross walk
  for (int num = g_closest_waypoint; num &lt; g_closest_waypoint + g_search_distance; num++)
  {
    geometry_msgs::Point waypoint = g_path_dk.getWaypointPosition(num);
    waypoint.z = 0.0;  // ignore Z axis
    for (const auto &amp;i : bdid)
    {
      // ignore far crosswalk
      geometry_msgs::Point crosswalk_center = vmap.getDetectionPoints(i).center;
      crosswalk_center.z = 0.0;
      if (calcSquareOfLength(crosswalk_center, waypoint) &gt; ignore_distance)
        continue;

      for (auto p : vmap.getDetectionPoints(i).points)
      {
        p.z = waypoint.z;
        if (calcSquareOfLength(p, waypoint) &lt; find_distance)
        {
          vmap.setDetectionCrossWalkID(i);
          return num;
        }
      }
    }
  }

  vmap.setDetectionCrossWalkID(-1);
  return -1;  // no near crosswalk
}

EControl crossWalkDetection(const int &amp;crosswalk_id)
{
  double search_radius = vmap.getDetectionPoints(crosswalk_id).width / 2;

  // Search each calculated points in the crosswalk
  for (const auto &amp;p : vmap.getDetectionPoints(crosswalk_id).points)
  {
    geometry_msgs::Point detection_point = calcRelativeCoordinate(p, g_localizer_pose.pose);
    tf::Vector3 detection_vector = point2vector(detection_point);
    detection_vector.setZ(0.0);

    int stop_count = 0;  // the number of points in the detection area
    for (const auto &amp;vscan : g_vscan)
    {
      tf::Vector3 vscan_vector(vscan.x, vscan.y, 0.0);
      double distance = tf::tfDistance(vscan_vector, detection_vector);
      if (distance &lt; search_radius)
      {
        stop_count++;
        geometry_msgs::Point vscan_temp;
        vscan_temp.x = vscan.x;
        vscan_temp.y = vscan.y;
        vscan_temp.z = vscan.z;
	g_obstacle.setStopPoint(calcAbsoluteCoordinate(vscan_temp, g_localizer_pose.pose));
      }
      if (stop_count &gt; g_threshold_points)
        return STOP;
    }

    g_obstacle.clearStopPoints();
  }

  return KEEP;  // find no obstacles
}

EControl vscanDetection()
{
  if (g_vscan.empty() == true || g_closest_waypoint &lt; 0)
    return KEEP;

  int decelerate_or_stop = -10000;
  int decelerate2stop_waypoints = 15;

  for (int i = g_closest_waypoint; i &lt; g_closest_waypoint + g_search_distance; i++)
  {
    g_obstacle.clearStopPoints();
    if (!g_obstacle.isDecided())
      g_obstacle.clearDeceleratePoints();

    decelerate_or_stop++;
    if (decelerate_or_stop &gt; decelerate2stop_waypoints || (decelerate_or_stop &gt;= 0 &amp;&amp; i &gt;= g_path_dk.getSize() - 1) ||
        (decelerate_or_stop &gt;= 0 &amp;&amp; i == g_closest_waypoint + g_search_distance - 1))
      return DECELERATE;
    if (i &gt; g_path_dk.getSize() - 1)
      return KEEP;

    // Detection for cross walk
    if (i == vmap.getDetectionWaypoint())
    {
      if (crossWalkDetection(vmap.getDetectionCrossWalkID()) == STOP)
      {
        g_obstacle_waypoint = i;
        return STOP;
      }
    }

    // waypoint seen by vehicle
    geometry_msgs::Point waypoint = calcRelativeCoordinate(g_path_dk.getWaypointPosition(i), g_localizer_pose.pose);
    tf::Vector3 tf_waypoint = point2vector(waypoint);
    tf_waypoint.setZ(0);

    int stop_point_count = 0;
    int decelerate_point_count = 0;
    for (pcl::PointCloud&lt;pcl::PointXYZ&gt;::const_iterator item = g_vscan.begin(); item != g_vscan.end(); item++)
    {
      tf::Vector3 vscan_vector((double)item-&gt;x, (double)item-&gt;y, 0);

      // 2D distance between waypoint and vscan points(obstacle)
      // ---STOP OBSTACLE DETECTION---
      double dt = tf::tfDistance(vscan_vector, tf_waypoint);
      if (dt &lt; g_detection_range)
      {
        stop_point_count++;
        geometry_msgs::Point vscan_temp;
        vscan_temp.x = item-&gt;x;
        vscan_temp.y = item-&gt;y;
        vscan_temp.z = item-&gt;z;
	g_obstacle.setStopPoint(calcAbsoluteCoordinate(vscan_temp, g_localizer_pose.pose));
      }
      if (stop_point_count &gt; g_threshold_points)
      {
        g_obstacle_waypoint = i;
        return STOP;
      }

      // without deceleration range
      if (g_deceleration_range &lt; 0.01)
        continue;
      // deceleration search runs &quot;decelerate_search_distance&quot; waypoints from closest
      if (i &gt; g_closest_waypoint + g_deceleration_search_distance || decelerate_or_stop &gt;= 0)
        continue;

      // ---DECELERATE OBSTACLE DETECTION---
      if (dt &gt; g_detection_range &amp;&amp; dt &lt; g_detection_range + g_deceleration_range)
      {
        bool count_flag = true;

        // search overlaps between DETECTION range and DECELERATION range
        for (int waypoint_search = -5; waypoint_search &lt;= 5; waypoint_search++)
        {
          if (i + waypoint_search &lt; 0 || i + waypoint_search &gt;= g_path_dk.getSize() || !waypoint_search)
            continue;
          geometry_msgs::Point temp_waypoint =
              calcRelativeCoordinate(g_path_dk.getWaypointPosition(i + waypoint_search), g_localizer_pose.pose);
          tf::Vector3 waypoint_vector = point2vector(temp_waypoint);
          waypoint_vector.setZ(0);
          // if there is a overlap, give priority to DETECTION range
          if (tf::tfDistance(vscan_vector, waypoint_vector) &lt; g_detection_range)
          {
            count_flag = false;
            break;
          }
        }
        if (count_flag)
        {
          decelerate_point_count++;
          geometry_msgs::Point vscan_temp;
          vscan_temp.x = item-&gt;x;
          vscan_temp.y = item-&gt;y;
          vscan_temp.z = item-&gt;z;
	  g_obstacle.setDeceleratePoint(calcAbsoluteCoordinate(vscan_temp, g_localizer_pose.pose));
        }
      }

      // found obstacle to DECELERATE
      if (decelerate_point_count &gt; g_threshold_points)
      {
        g_obstacle_waypoint = i;
        decelerate_or_stop = 0;  // for searching near STOP obstacle
        g_obstacle.setDecided(true);
      }
    }
  }

  return KEEP;  // no obstacles
}

  /*
void soundPlay()
{
  std_msgs::String string;
  string.data = pedestrian_sound;
  g_sound_pub.publish(string);
}
  */

EControl obstacleDetection()
{
  static int false_count = 0;
  static EControl prev_detection = KEEP;

  EControl vscan_result = vscanDetection();
  displayDetectionRange(vmap.getDetectionCrossWalkID(), g_closest_waypoint, vscan_result);

  if (prev_detection == KEEP)
  {
    if (vscan_result != KEEP)
    {  // found obstacle
      displayObstacle(vscan_result);
      prev_detection = vscan_result;
      // SoundPlay();
      false_count = 0;
      return vscan_result;
    }
    else
    {  // no obstacle
      prev_detection = KEEP;
      return vscan_result;
    }
  }
  else
  {  // prev_detection = STOP or DECELERATE
    if (vscan_result != KEEP)
    {  // found obstacle
      displayObstacle(vscan_result);
      prev_detection = vscan_result;
      false_count = 0;
      return vscan_result;
    }
    else
    {  // no obstacle
      false_count++;

      // fail-safe
      if (false_count &gt;= LOOP_RATE / 2)
      {
        g_obstacle_waypoint = -1;
        false_count = 0;
        prev_detection = KEEP;
        return vscan_result;
      }
      else
      {
        displayObstacle(OTHERS);
        return prev_detection;
      }
    }
  }
}

void changeWaypoint(EControl detection_result)
{
  int obs = g_obstacle_waypoint;

  if (detection_result == STOP)
  {  // STOP for obstacle
    // stop_waypoint is about g_others_distance meter away from obstacles
    int stop_waypoint = obs - ((int)(g_others_distance / g_path_change.getInterval()));
    // change waypoints to stop by the stop_waypoint
    g_path_change.changeWaypoints(stop_waypoint);
    g_path_change.avoidSuddenBraking();
    g_path_change.setTemporalWaypoints();
    g_temporal_waypoints_pub.publish(g_path_change.getTemporalWaypoints());
  }
  else if (detection_result == DECELERATE)
  {  // DECELERATE for obstacles
    g_path_change.setPath(g_path_dk.getCurrentWaypoints());
    g_path_change.setDeceleration();
    g_path_change.setTemporalWaypoints();
    g_temporal_waypoints_pub.publish(g_path_change.getTemporalWaypoints());
  }
  else
  {  // ACELERATE or KEEP
    g_path_change.setPath(g_path_dk.getCurrentWaypoints());
    g_path_change.avoidSuddenAceleration();
    g_path_change.avoidSuddenBraking();
    g_path_change.setTemporalWaypoints();
    g_temporal_waypoints_pub.publish(g_path_change.getTemporalWaypoints());
  }

  return;
}

} // end namespace

//======================================
//                 main
//======================================

int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;lattice_velocity_set&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  bool use_crosswalk_detection;
  private_nh.param&lt;bool&gt;(&quot;use_crosswalk_detection&quot;, use_crosswalk_detection, true);

  ros::Subscriber localizer_sub = nh.subscribe(&quot;localizer_pose&quot;, 1, localizerCallback);
  ros::Subscriber control_pose_sub = nh.subscribe(&quot;current_pose&quot;, 1, controlCallback);
  ros::Subscriber vscan_sub = nh.subscribe(&quot;vscan_points&quot;, 1, vscanCallback);
  ros::Subscriber base_waypoint_sub = nh.subscribe(&quot;base_waypoints&quot;, 1, baseWaypointCallback);
  ros::Subscriber obj_pose_sub = nh.subscribe(&quot;obj_pose&quot;, 1, objPoseCallback);
  ros::Subscriber current_vel_sub = nh.subscribe(&quot;current_velocity&quot;, 1, currentVelCallback);
  ros::Subscriber config_sub = nh.subscribe(&quot;config/lattice_velocity_set&quot;, 10, configCallback);

  //------------------ Vector Map ----------------------//
  ros::Subscriber sub_dtlane = nh.subscribe(&quot;vector_map_info/cross_walk&quot;, 1, &amp;CrossWalk::crossWalkCallback, &amp;vmap);
  ros::Subscriber sub_area = nh.subscribe(&quot;vector_map_info/area&quot;, 1, &amp;CrossWalk::areaCallback, &amp;vmap);
  ros::Subscriber sub_line = nh.subscribe(&quot;vector_map_info/line&quot;, 1, &amp;CrossWalk::lineCallback, &amp;vmap);
  ros::Subscriber sub_point = nh.subscribe(&quot;vector_map_info/point&quot;, 1, &amp;CrossWalk::pointCallback, &amp;vmap);
  //----------------------------------------------------//

  g_range_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;detection_range&quot;, 0);
  g_sound_pub = nh.advertise&lt;std_msgs::String&gt;(&quot;sound_player&quot;, 10);
  g_temporal_waypoints_pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;temporal_waypoints&quot;, 1000, true);
  ros::Publisher closest_waypoint_pub;
  closest_waypoint_pub = nh.advertise&lt;std_msgs::Int32&gt;(&quot;closest_waypoint&quot;, 1000);
  g_obstacle_pub = nh.advertise&lt;visualization_msgs::Marker&gt;(&quot;obstacle&quot;, 0);

  ros::Rate loop_rate(LOOP_RATE);
  while (ros::ok())
  {
    ros::spinOnce();

    if (vmap.loaded_all &amp;&amp; !vmap.set_points)
      vmap.setCrossWalkPoints();

    if (g_pose_flag == false || g_path_flag == false)
    {
      loop_rate.sleep();
      continue;
    }

    g_closest_waypoint = getClosestWaypoint(g_path_change.getCurrentWaypoints(), g_control_pose.pose);

    std_msgs::Int32 closest_waypoint;
    closest_waypoint.data = g_closest_waypoint;
    closest_waypoint_pub.publish(closest_waypoint);

    if (use_crosswalk_detection)
      vmap.setDetectionWaypoint(findCrossWalk());

    EControl detection_result = obstacleDetection();

    changeWaypoint(detection_result);

    g_vscan.clear();

    loop_rate.sleep();
  }

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/lattice_planner/nodes/path_select/path_select.cpp" new_path="ros/src/computing/planning/motion/packages/lattice_planner/nodes/path_select/path_select.cpp">
				<diff>@@ -29,12 +29,12 @@
  */
 
 #include &lt;ros/ros.h&gt;
-#include &lt;waypoint_follower/lane.h&gt;
+#include &lt;waypoint_follower_msgs/lane.h&gt;
 #include &lt;iostream&gt;
 
 static ros::Publisher _pub;
 
-void callback(const waypoint_follower::lane &amp;msg)
+void callback(const waypoint_follower_msgs::lane &amp;msg)
 {
     _pub.publish(msg);
 }
@@ -46,7 +46,7 @@ int main(int argc, char **argv)
 
     ros::NodeHandle nh;
     ros::Subscriber twist_sub = nh.subscribe(&quot;temporal_waypoints&quot;, 1, callback);
-    _pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;final_waypoints&quot;, 1000,true);
+    _pub = nh.advertise&lt;waypoint_follower_msgs::lane&gt;(&quot;final_waypoints&quot;, 1000,true);
 
     ros::spin();
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &lt;ros/ros.h&gt;
#include &lt;waypoint_follower/lane.h&gt;
#include &lt;iostream&gt;

static ros::Publisher _pub;

void callback(const waypoint_follower::lane &amp;msg)
{
    _pub.publish(msg);
}


int main(int argc, char **argv)
{
    ros::init(argc, argv, &quot;path_select&quot;);

    ros::NodeHandle nh;
    ros::Subscriber twist_sub = nh.subscribe(&quot;temporal_waypoints&quot;, 1, callback);
    _pub = nh.advertise&lt;waypoint_follower::lane&gt;(&quot;final_waypoints&quot;, 1000,true);

    ros::spin();



    return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_follower/include/waypoint_follower/libwaypoint_follower.h" new_path="ros/src/computing/planning/motion/packages/waypoint_follower/include/waypoint_follower/libwaypoint_follower.h">
				<diff>@@ -39,15 +39,15 @@
 // ROS header
 #include &lt;tf/transform_broadcaster.h&gt;
 #include &lt;tf/transform_listener.h&gt;
-#include &quot;waypoint_follower/lane.h&quot;
+#include &quot;waypoint_follower_msgs/lane.h&quot;
 
 class WayPoints
 {
 protected:
-  waypoint_follower::lane current_waypoints_;
+  waypoint_follower_msgs::lane current_waypoints_;
 
 public:
-  void setPath(const waypoint_follower::lane &amp;waypoints)
+  void setPath(const waypoint_follower_msgs::lane &amp;waypoints)
   {
     current_waypoints_ = waypoints;
   }
@@ -61,7 +61,7 @@ public:
   geometry_msgs::Quaternion getWaypointOrientation(int waypoint) const;
   geometry_msgs::Pose getWaypointPose(int waypoint) const;
   double getWaypointVelocityMPS(int waypoint) const;
-  waypoint_follower::lane getCurrentWaypoints() const
+  waypoint_follower_msgs::lane getCurrentWaypoints() const
   {
     return current_waypoints_;
   }
@@ -96,7 +96,7 @@ geometry_msgs::Point calcAbsoluteCoordinate(geometry_msgs::Point point,
                                                                                 // coordinate
 double getPlaneDistance(geometry_msgs::Point target1,
                         geometry_msgs::Point target2);  // get 2 dimentional distance between target 1 and target 2
-int getClosestWaypoint(const waypoint_follower::lane &amp;current_path, geometry_msgs::Pose current_pose);
+int getClosestWaypoint(const waypoint_follower_msgs::lane &amp;current_path, geometry_msgs::Pose current_pose);
 bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c);
 double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double sa, double b, double c);
 double getRelativeAngle(geometry_msgs::Pose waypoint_pose, geometry_msgs::Pose vehicle_pose);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef _LIB_WAYPOINT_FOLLOWER_H_
#define _LIB_WAYPOINT_FOLLOWER_H_

// C++ header
#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;fstream&gt;

// ROS header
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &quot;waypoint_follower/lane.h&quot;

class WayPoints
{
protected:
  waypoint_follower::lane current_waypoints_;

public:
  void setPath(const waypoint_follower::lane &amp;waypoints)
  {
    current_waypoints_ = waypoints;
  }
  int getSize() const;
  bool isEmpty() const
  {
    return current_waypoints_.waypoints.empty();
  };
  double getInterval() const;
  geometry_msgs::Point getWaypointPosition(int waypoint) const;
  geometry_msgs::Quaternion getWaypointOrientation(int waypoint) const;
  geometry_msgs::Pose getWaypointPose(int waypoint) const;
  double getWaypointVelocityMPS(int waypoint) const;
  waypoint_follower::lane getCurrentWaypoints() const
  {
    return current_waypoints_;
  }
  bool isFront(int waypoint, geometry_msgs::Pose current_pose) const;
};

// inline function (less than 10 lines )
inline double kmph2mps(double velocity_kmph)
{
  return (velocity_kmph * 1000) / (60 * 60);
}
inline double mps2kmph(double velocity_mps)
{
  return (velocity_mps * 60 * 60) / 1000;
}
inline double deg2rad(double deg)
{
  return deg * M_PI / 180;
}  // convert degree to radian

tf::Vector3 point2vector(geometry_msgs::Point point);  // convert point to vector
geometry_msgs::Point vector2point(tf::Vector3 vector);  // convert vector to point
tf::Vector3 rotateUnitVector(tf::Vector3 unit_vector, double degree);  // rotate unit vector by degree
geometry_msgs::Point rotatePoint(geometry_msgs::Point point, double degree);  // rotate point vector by degree

double DecelerateVelocity(double distance, double prev_velocity);
geometry_msgs::Point calcRelativeCoordinate(geometry_msgs::Point point,
                                            geometry_msgs::Pose current_pose);  // transform point into the coordinate
                                                                                // of current_pose
geometry_msgs::Point calcAbsoluteCoordinate(geometry_msgs::Point point,
                                            geometry_msgs::Pose current_pose);  // transform point into the global
                                                                                // coordinate
double getPlaneDistance(geometry_msgs::Point target1,
                        geometry_msgs::Point target2);  // get 2 dimentional distance between target 1 and target 2
int getClosestWaypoint(const waypoint_follower::lane &amp;current_path, geometry_msgs::Pose current_pose);
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c);
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double sa, double b, double c);
double getRelativeAngle(geometry_msgs::Pose waypoint_pose, geometry_msgs::Pose vehicle_pose);
#endif
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_follower/lib/libwaypoint_follower.cpp" new_path="ros/src/computing/planning/motion/packages/waypoint_follower/lib/libwaypoint_follower.cpp">
				<diff>@@ -172,7 +172,7 @@ double getRelativeAngle(geometry_msgs::Pose waypoint_pose, geometry_msgs::Pose v
 }
 
 // get closest waypoint from current pose
-int getClosestWaypoint(const waypoint_follower::lane &amp;current_path, geometry_msgs::Pose current_pose)
+int getClosestWaypoint(const waypoint_follower_msgs::lane &amp;current_path, geometry_msgs::Pose current_pose)
 {
   WayPoints wp;
   wp.setPath(current_path);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &quot;waypoint_follower/libwaypoint_follower.h&quot;

int WayPoints::getSize() const
{
  if (current_waypoints_.waypoints.empty())
    return 0;
  else
    return current_waypoints_.waypoints.size();
}

double WayPoints::getInterval() const
{
  if (current_waypoints_.waypoints.empty())
    return 0;

  // interval between 2 waypoints
  tf::Vector3 v1(current_waypoints_.waypoints[0].pose.pose.position.x,
                 current_waypoints_.waypoints[0].pose.pose.position.y, 0);

  tf::Vector3 v2(current_waypoints_.waypoints[1].pose.pose.position.x,
                 current_waypoints_.waypoints[1].pose.pose.position.y, 0);
  return tf::tfDistance(v1, v2);
}

geometry_msgs::Point WayPoints::getWaypointPosition(int waypoint) const
{
  geometry_msgs::Point p;
  if (waypoint &gt; getSize() - 1 || waypoint &lt; 0)
    return p;

  p = current_waypoints_.waypoints[waypoint].pose.pose.position;
  return p;
}

geometry_msgs::Quaternion WayPoints::getWaypointOrientation(int waypoint) const
{
  geometry_msgs::Quaternion q;
  if (waypoint &gt; getSize() - 1 || waypoint &lt; 0)
    return q;

  q = current_waypoints_.waypoints[waypoint].pose.pose.orientation;
  return q;
}

geometry_msgs::Pose WayPoints::getWaypointPose(int waypoint) const
{
  geometry_msgs::Pose pose;
  if (waypoint &gt; getSize() - 1 || waypoint &lt; 0)
    return pose;

  pose = current_waypoints_.waypoints[waypoint].pose.pose;
  return pose;
}

double WayPoints::getWaypointVelocityMPS(int waypoint) const
{
  if (waypoint &gt; getSize() - 1 || waypoint &lt; 0)
    return 0;

  return current_waypoints_.waypoints[waypoint].twist.twist.linear.x;
}

bool WayPoints::isFront(int waypoint, geometry_msgs::Pose current_pose) const
{
  double x = calcRelativeCoordinate(current_waypoints_.waypoints[waypoint].pose.pose.position, current_pose).x;
  if (x &lt; 0)
    return false;
  else
    return true;
}

double DecelerateVelocity(double distance, double prev_velocity)
{
  double decel_ms = 1.0;  // m/s
  double decel_velocity_ms = sqrt(2 * decel_ms * distance);

  std::cout &lt;&lt; &quot;velocity/prev_velocity :&quot; &lt;&lt; decel_velocity_ms &lt;&lt; &quot;/&quot; &lt;&lt; prev_velocity &lt;&lt; std::endl;
  if (decel_velocity_ms &lt; prev_velocity)
  {
    return decel_velocity_ms;
  }
  else
  {
    return prev_velocity;
  }
}

// calculation relative coordinate of point from current_pose frame
geometry_msgs::Point calcRelativeCoordinate(geometry_msgs::Point point_msg, geometry_msgs::Pose current_pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(current_pose, inverse);
  tf::Transform transform = inverse.inverse();

  tf::Point p;
  pointMsgToTF(point_msg, p);
  tf::Point tf_p = transform * p;
  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);

  return tf_point_msg;
}

// calculation absolute coordinate of point on current_pose frame
geometry_msgs::Point calcAbsoluteCoordinate(geometry_msgs::Point point_msg, geometry_msgs::Pose current_pose)
{
  tf::Transform inverse;
  tf::poseMsgToTF(current_pose, inverse);

  tf::Point p;
  pointMsgToTF(point_msg, p);
  tf::Point tf_p = inverse * p;
  geometry_msgs::Point tf_point_msg;
  pointTFToMsg(tf_p, tf_point_msg);
  return tf_point_msg;
}

// distance between target 1 and target2 in 2-D
double getPlaneDistance(geometry_msgs::Point target1, geometry_msgs::Point target2)
{
  tf::Vector3 v1 = point2vector(target1);
  v1.setZ(0);
  tf::Vector3 v2 = point2vector(target2);
  v2.setZ(0);
  return tf::tfDistance(v1, v2);
}

double getRelativeAngle(geometry_msgs::Pose waypoint_pose, geometry_msgs::Pose vehicle_pose)
{
  geometry_msgs::Point relative_p1 = calcRelativeCoordinate(waypoint_pose.position, vehicle_pose);
  geometry_msgs::Point p2;
  p2.x = 1.0;
  geometry_msgs::Point relative_p2 = calcRelativeCoordinate(calcAbsoluteCoordinate(p2, waypoint_pose), vehicle_pose);
  tf::Vector3 relative_waypoint_v(relative_p2.x - relative_p1.x, relative_p2.y - relative_p1.y,
                                  relative_p2.z - relative_p1.z);
  relative_waypoint_v.normalize();
  tf::Vector3 relative_pose_v(1, 0, 0);
  double angle = relative_pose_v.angle(relative_waypoint_v) * 180 / M_PI;
  // ROS_INFO(&quot;angle : %lf&quot;,angle);

  return angle;
}

// get closest waypoint from current pose
int getClosestWaypoint(const waypoint_follower::lane &amp;current_path, geometry_msgs::Pose current_pose)
{
  WayPoints wp;
  wp.setPath(current_path);

  if (wp.isEmpty())
    return -1;

  // search closest candidate within a certain meter
  double search_distance = 5.0;
  std::vector&lt;int&gt; waypoint_candidates;
  for (int i = 1; i &lt; wp.getSize(); i++)
  {
    if (getPlaneDistance(wp.getWaypointPosition(i), current_pose.position) &gt; search_distance)
      continue;

    if (!wp.isFront(i, current_pose))
      continue;

    double angle_threshold = 90;
    if (getRelativeAngle(wp.getWaypointPose(i), current_pose) &gt; angle_threshold)
      continue;

    waypoint_candidates.push_back(i);
  }

  // get closest waypoint from candidates
  if (!waypoint_candidates.empty())
  {
    int waypoint_min = -1;
    double distance_min = DBL_MAX;
    for (auto el : waypoint_candidates)
    {
      // ROS_INFO(&quot;closest_candidates : %d&quot;,el);
      double d = getPlaneDistance(wp.getWaypointPosition(el), current_pose.position);
      if (d &lt; distance_min)
      {
        waypoint_min = el;
        distance_min = d;
      }
    }
    return waypoint_min;
  }
  else
  {
    ROS_INFO(&quot;no candidate. search closest waypoint from all waypoints...&quot;);
    // if there is no candidate...
    int waypoint_min = -1;
    double distance_min = DBL_MAX;
    for (int i = 1; i &lt; wp.getSize(); i++)
    {
      if (!wp.isFront(i, current_pose))
        continue;

      // if (!wp.isValid(i, current_pose))
      //  continue;

      double d = getPlaneDistance(wp.getWaypointPosition(i), current_pose.position);
      if (d &lt; distance_min)
      {
        waypoint_min = i;
        distance_min = d;
      }
    }
    return waypoint_min;
  }
}

// let the linear equation be &quot;ax + by + c = 0&quot;
// if there are two points (x1,y1) , (x2,y2), a = &quot;y2-y1, b = &quot;(-1) * x2 - x1&quot; ,c = &quot;(-1) * (y2-y1)x1 + (x2-x1)y1&quot;
bool getLinearEquation(geometry_msgs::Point start, geometry_msgs::Point end, double *a, double *b, double *c)
{
  //(x1, y1) = (start.x, star.y), (x2, y2) = (end.x, end.y)
  double sub_x = fabs(start.x - end.x);
  double sub_y = fabs(start.y - end.y);
  double error = pow(10, -5);  // 0.00001

  if (sub_x &lt; error &amp;&amp; sub_y &lt; error)
  {
    ROS_INFO(&quot;two points are the same point!!&quot;);
    return false;
  }

  *a = end.y - start.y;
  *b = (-1) * (end.x - start.x);
  *c = (-1) * (end.y - start.y) * start.x + (end.x - start.x) * start.y;

  return true;
}
double getDistanceBetweenLineAndPoint(geometry_msgs::Point point, double a, double b, double c)
{
  double d = fabs(a * point.x + b * point.y + c) / sqrt(pow(a, 2) + pow(b, 2));

  return d;
}

tf::Vector3 point2vector(geometry_msgs::Point point)
{
  tf::Vector3 vector(point.x, point.y, point.z);
  return vector;
}

geometry_msgs::Point vector2point(tf::Vector3 vector)
{
  geometry_msgs::Point point;
  point.x = vector.getX();
  point.y = vector.getY();
  point.z = vector.getZ();
  return point;
}

tf::Vector3 rotateUnitVector(tf::Vector3 unit_vector, double degree)
{
  tf::Vector3 w1(cos(deg2rad(degree)) * unit_vector.getX() - sin(deg2rad(degree)) * unit_vector.getY(),
                 sin(deg2rad(degree)) * unit_vector.getX() + cos(deg2rad(degree)) * unit_vector.getY(), 0);
  tf::Vector3 unit_w1 = w1.normalize();

  return unit_w1;
}

geometry_msgs::Point rotatePoint(geometry_msgs::Point point, double degree)
{
  geometry_msgs::Point rotate;
  rotate.x = cos(deg2rad(degree)) * point.x - sin(deg2rad(degree)) * point.y;
  rotate.y = sin(deg2rad(degree)) * point.x + cos(deg2rad(degree)) * point.y;

  return rotate;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit.h" new_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit.h">
				<diff>@@ -37,7 +37,7 @@
 #include &lt;geometry_msgs/TwistStamped.h&gt;
 
 // User defined includes
-#include &quot;waypoint_follower/lane.h&quot;
+#include &quot;waypoint_follower_msgs/lane.h&quot;
 #include &quot;waypoint_follower/libwaypoint_follower.h&quot;
 
 namespace waypoint_follower
@@ -57,7 +57,7 @@ public:
   {
     current_linear_velocity_ = cur_vel;
   }
-  void setCurrentWaypoints(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps)
+  void setCurrentWaypoints(const std::vector&lt;waypoint_follower_msgs::waypoint&gt; &amp;wps)
   {
     current_waypoints_ = wps;
   }
@@ -102,7 +102,7 @@ private:
   double lookahead_distance_;
   geometry_msgs::Pose current_pose_;
   double current_linear_velocity_;
-  std::vector&lt;waypoint_follower::waypoint&gt; current_waypoints_;
+  std::vector&lt;waypoint_follower_msgs::waypoint&gt; current_waypoints_;
 
   // functions
   double calcCurvature(geometry_msgs::Point target) const;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef PURE_PURSUIT_H
#define PURE_PURSUIT_H

// ROS includes
#include &lt;ros/ros.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;

// User defined includes
#include &quot;waypoint_follower/lane.h&quot;
#include &quot;waypoint_follower/libwaypoint_follower.h&quot;

namespace waypoint_follower
{
class PurePursuit
{
public:
  PurePursuit();
  ~PurePursuit();

  // for setting data
  void setLookaheadDistance(const double &amp;ld)
  {
    lookahead_distance_ = ld;
  }
  void setCurrentVelocity(const double &amp;cur_vel)
  {
    current_linear_velocity_ = cur_vel;
  }
  void setCurrentWaypoints(const std::vector&lt;waypoint_follower::waypoint&gt; &amp;wps)
  {
    current_waypoints_ = wps;
  }
  void setCurrentPose(const geometry_msgs::PoseStampedConstPtr &amp;msg)
  {
    current_pose_ = msg-&gt;pose;
  }
  void setLinearInterpolationParameter(const bool &amp;param)
  {
    is_linear_interpolation_ = param;
  }

  // for debug on ROS
  geometry_msgs::Point getPoseOfNextWaypoint() const
  {
    return current_waypoints_.at(next_waypoint_number_).pose.pose.position;
  }
  geometry_msgs::Point getPoseOfNextTarget() const
  {
    return next_target_position_;
  }
  geometry_msgs::Pose getCurrentPose() const
  {
    return current_pose_;
  }
  double getLookaheadDistance() const
  {
    return lookahead_distance_;
  }
  // processing
  bool canGetCurvature(double *output_kappa);

private:
  // constant
  const double RADIUS_MAX_;
  const double KAPPA_MIN_;

  // variables
  bool is_linear_interpolation_;
  int next_waypoint_number_;
  geometry_msgs::Point next_target_position_;
  double lookahead_distance_;
  geometry_msgs::Pose current_pose_;
  double current_linear_velocity_;
  std::vector&lt;waypoint_follower::waypoint&gt; current_waypoints_;

  // functions
  double calcCurvature(geometry_msgs::Point target) const;
  bool interpolateNextTarget(int next_waypoint, geometry_msgs::Point *next_target) const;
  void getNextWaypoint();
};
}  // waypoint_follower

#endif  // PURE_PURSUIT_H
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit_core.cpp" new_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit_core.cpp">
				<diff>@@ -76,7 +76,7 @@ void PurePursuitNode::initForROS()
 
   // setup publisher
   pub1_ = nh_.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;twist_raw&quot;, 10);
-  pub2_ = nh_.advertise&lt;waypoint_follower::ControlCommandStamped&gt;(&quot;ctrl_cmd&quot;, 10);
+  pub2_ = nh_.advertise&lt;waypoint_follower_msgs::ControlCommandStamped&gt;(&quot;ctrl_cmd&quot;, 10);
   pub11_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;next_waypoint_mark&quot;, 0);
   pub12_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;next_target_mark&quot;, 0);
   pub13_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;search_circle_mark&quot;, 0);
@@ -134,7 +134,7 @@ void PurePursuitNode::publishControlCommandStamped(const bool &amp;can_get_curvature
   if (!publishes_for_steering_robot_)
     return;
 
-  waypoint_follower::ControlCommandStamped ccs;
+  waypoint_follower_msgs::ControlCommandStamped ccs;
   ccs.header.stamp = ros::Time::now();
   ccs.cmd.linear_velocity = can_get_curvature ? computeCommandVelocity() : 0;
   ccs.cmd.steering_angle = can_get_curvature ? convertCurvatureToSteeringAngle(wheel_base_, kappa) : 0;
@@ -186,7 +186,7 @@ void PurePursuitNode::callbackFromCurrentVelocity(const geometry_msgs::TwistStam
   is_velocity_set_ = true;
 }
 
-void PurePursuitNode::callbackFromWayPoints(const waypoint_follower::laneConstPtr &amp;msg)
+void PurePursuitNode::callbackFromWayPoints(const waypoint_follower_msgs::laneConstPtr &amp;msg)
 {
   if (!msg-&gt;waypoints.empty())
     command_linear_velocity_ = msg-&gt;waypoints.at(0).twist.twist.linear.x;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;pure_pursuit_core.h&quot;

namespace waypoint_follower
{
// Constructor
PurePursuitNode::PurePursuitNode()
  : private_nh_(&quot;~&quot;)
  , pp_()
  , LOOP_RATE_(30)
  , is_waypoint_set_(false)
  , is_pose_set_(false)
  , is_velocity_set_(false)
  , is_config_set_(false)
  , current_linear_velocity_(0)
  , command_linear_velocity_(0)
  , param_flag_(-1)
  , const_lookahead_distance_(4.0)
  , const_velocity_(5.0)
  , lookahead_distance_ratio_(2.0)
  , minimum_lookahead_distance_(6.0)
{
  initForROS();

  // initialize for PurePursuit
  pp_.setLinearInterpolationParameter(is_linear_interpolation_);
}

// Destructor
PurePursuitNode::~PurePursuitNode()
{
}

void PurePursuitNode::initForROS()
{
  // ros parameter settings
  private_nh_.param(&quot;is_linear_interpolation&quot;, is_linear_interpolation_, bool(true));
  // ROS_INFO_STREAM(&quot;is_linear_interpolation : &quot; &lt;&lt; is_linear_interpolation_);
  private_nh_.param(&quot;publishes_for_steering_robot&quot;, publishes_for_steering_robot_, bool(false));
  private_nh_.param(&quot;vehicle_info/wheel_base&quot;, wheel_base_, double(2.7));

  // setup subscriber
  sub1_ = nh_.subscribe(&quot;final_waypoints&quot;, 10, &amp;PurePursuitNode::callbackFromWayPoints, this);
  sub2_ = nh_.subscribe(&quot;current_pose&quot;, 10, &amp;PurePursuitNode::callbackFromCurrentPose, this);
  sub3_ = nh_.subscribe(&quot;config/waypoint_follower&quot;, 10, &amp;PurePursuitNode::callbackFromConfig, this);
  sub4_ = nh_.subscribe(&quot;current_velocity&quot;, 10, &amp;PurePursuitNode::callbackFromCurrentVelocity, this);

  // setup publisher
  pub1_ = nh_.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;twist_raw&quot;, 10);
  pub2_ = nh_.advertise&lt;waypoint_follower::ControlCommandStamped&gt;(&quot;ctrl_cmd&quot;, 10);
  pub11_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;next_waypoint_mark&quot;, 0);
  pub12_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;next_target_mark&quot;, 0);
  pub13_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;search_circle_mark&quot;, 0);
  pub14_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;line_point_mark&quot;, 0);  // debug tool
  pub15_ = nh_.advertise&lt;visualization_msgs::Marker&gt;(&quot;trajectory_circle_mark&quot;, 0);
  // pub7_ = nh.advertise&lt;std_msgs::Bool&gt;(&quot;wf_stat&quot;, 0);
}

void PurePursuitNode::run()
{
  ROS_INFO_STREAM(&quot;pure pursuit start&quot;);
  ros::Rate loop_rate(LOOP_RATE_);
  while (ros::ok())
  {
    ros::spinOnce();
    if (!is_pose_set_ || !is_waypoint_set_ || !is_velocity_set_ || !is_config_set_)
    {
      ROS_WARN(&quot;Necessary topics are not subscribed yet ... &quot;);
      loop_rate.sleep();
      continue;
    }

    pp_.setLookaheadDistance(computeLookaheadDistance());

    double kappa = 0;
    bool can_get_curvature = pp_.canGetCurvature(&amp;kappa);
    publishTwistStamped(can_get_curvature, kappa);
    publishControlCommandStamped(can_get_curvature, kappa);

    // for visualization with Rviz
    pub11_.publish(displayNextWaypoint(pp_.getPoseOfNextWaypoint()));
    pub13_.publish(displaySearchRadius(pp_.getCurrentPose().position, pp_.getLookaheadDistance()));
    pub12_.publish(displayNextTarget(pp_.getPoseOfNextTarget()));
    pub15_.publish(displayTrajectoryCircle(
        waypoint_follower::generateTrajectoryCircle(pp_.getPoseOfNextTarget(), pp_.getCurrentPose())));

    is_pose_set_ = false;
    is_velocity_set_ = false;
    is_waypoint_set_ = false;
    loop_rate.sleep();
  }
}

void PurePursuitNode::publishTwistStamped(const bool &amp;can_get_curvature, const double &amp;kappa) const
{
  geometry_msgs::TwistStamped ts;
  ts.header.stamp = ros::Time::now();
  ts.twist.linear.x = can_get_curvature ? computeCommandVelocity() : 0;
  ts.twist.angular.z = can_get_curvature ? kappa * ts.twist.linear.x : 0;
  pub1_.publish(ts);
}

void PurePursuitNode::publishControlCommandStamped(const bool &amp;can_get_curvature, const double &amp;kappa) const
{
  if (!publishes_for_steering_robot_)
    return;

  waypoint_follower::ControlCommandStamped ccs;
  ccs.header.stamp = ros::Time::now();
  ccs.cmd.linear_velocity = can_get_curvature ? computeCommandVelocity() : 0;
  ccs.cmd.steering_angle = can_get_curvature ? convertCurvatureToSteeringAngle(wheel_base_, kappa) : 0;

  pub2_.publish(ccs);
}

double PurePursuitNode::computeLookaheadDistance() const
{
  if (param_flag_ == enumToInteger(Mode::dialog))
    return const_lookahead_distance_;

  double maximum_lookahead_distance = current_linear_velocity_ * 10;
  double ld = current_linear_velocity_ * lookahead_distance_ratio_;

  return ld &lt; minimum_lookahead_distance_ ? minimum_lookahead_distance_
        : ld &gt; maximum_lookahead_distance ? maximum_lookahead_distance
        : ld;
}

double PurePursuitNode::computeCommandVelocity() const
{
  if (param_flag_ == enumToInteger(Mode::dialog))
    return kmph2mps(const_velocity_);

  return command_linear_velocity_;
}

void PurePursuitNode::callbackFromConfig(const runtime_manager::ConfigWaypointFollowerConstPtr &amp;config)
{
  param_flag_ = config-&gt;param_flag;
  const_lookahead_distance_ = config-&gt;lookahead_distance;
  const_velocity_ = config-&gt;velocity;
  lookahead_distance_ratio_ = config-&gt;lookahead_ratio;
  minimum_lookahead_distance_ = config-&gt;minimum_lookahead_distance;
  is_config_set_ = true;
}

void PurePursuitNode::callbackFromCurrentPose(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  pp_.setCurrentPose(msg);
  is_pose_set_ = true;
}

void PurePursuitNode::callbackFromCurrentVelocity(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  current_linear_velocity_ = msg-&gt;twist.linear.x;
  pp_.setCurrentVelocity(current_linear_velocity_);
  is_velocity_set_ = true;
}

void PurePursuitNode::callbackFromWayPoints(const waypoint_follower::laneConstPtr &amp;msg)
{
  if (!msg-&gt;waypoints.empty())
    command_linear_velocity_ = msg-&gt;waypoints.at(0).twist.twist.linear.x;
  else
    command_linear_velocity_ = 0;

  pp_.setCurrentWaypoints(msg-&gt;waypoints);
  is_waypoint_set_ = true;
}

double convertCurvatureToSteeringAngle(const double &amp;wheel_base, const double &amp;kappa)
{
  return atan(wheel_base * kappa);
}

}  // waypoint_follower
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit_core.h" new_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/pure_pursuit/pure_pursuit_core.h">
				<diff>@@ -39,8 +39,8 @@
 
 // User defined includes
 #include &quot;runtime_manager/ConfigWaypointFollower.h&quot;
-#include &quot;waypoint_follower/lane.h&quot;
-#include &quot;waypoint_follower/ControlCommandStamped.h&quot;
+#include &quot;waypoint_follower_msgs/lane.h&quot;
+#include &quot;waypoint_follower_msgs/ControlCommandStamped.h&quot;
 #include &quot;pure_pursuit_viz.h&quot;
 #include &quot;pure_pursuit.h&quot;
 
@@ -101,7 +101,7 @@ private:
   void callbackFromConfig(const runtime_manager::ConfigWaypointFollowerConstPtr &amp;config);
   void callbackFromCurrentPose(const geometry_msgs::PoseStampedConstPtr &amp;msg);
   void callbackFromCurrentVelocity(const geometry_msgs::TwistStampedConstPtr &amp;msg);
-  void callbackFromWayPoints(const waypoint_follower::laneConstPtr &amp;msg);
+  void callbackFromWayPoints(const waypoint_follower_msgs::laneConstPtr &amp;msg);
 
   // initializer
   void initForROS();
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef PURE_PURSUIT_CORE_H
#define PURE_PURSUIT_CORE_H

// ROS includes
#include &lt;ros/ros.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;

// User defined includes
#include &quot;runtime_manager/ConfigWaypointFollower.h&quot;
#include &quot;waypoint_follower/lane.h&quot;
#include &quot;waypoint_follower/ControlCommandStamped.h&quot;
#include &quot;pure_pursuit_viz.h&quot;
#include &quot;pure_pursuit.h&quot;

namespace waypoint_follower
{
enum class Mode : int32_t
{
  waypoint,
  dialog,

  unknown = -1,
};

template &lt;class T&gt;
typename std::underlying_type&lt;T&gt;::type enumToInteger(T t)
{
  return static_cast&lt;typename std::underlying_type&lt;T&gt;::type&gt;(t);
}

class PurePursuitNode
{
public:
  PurePursuitNode();
  ~PurePursuitNode();

  void run();

private:
  // handle
  ros::NodeHandle nh_;
  ros::NodeHandle private_nh_;

  // class
  PurePursuit pp_;

  // publisher
  ros::Publisher pub1_, pub2_, pub11_, pub12_, pub13_, pub14_, pub15_;

  // subscriber
  ros::Subscriber sub1_, sub2_, sub3_, sub4_;

  // constant
  const int LOOP_RATE_;  // processing frequency

  // variables
  bool is_linear_interpolation_, publishes_for_steering_robot_;
  bool is_waypoint_set_, is_pose_set_, is_velocity_set_, is_config_set_;
  double current_linear_velocity_, command_linear_velocity_;
  double wheel_base_;

  int32_t param_flag_;               // 0 = waypoint, 1 = Dialog
  double const_lookahead_distance_;  // meter
  double const_velocity_;            // km/h
  double lookahead_distance_ratio_;
  double minimum_lookahead_distance_;  // the next waypoint must be outside of this threshold.

  // callbacks
  void callbackFromConfig(const runtime_manager::ConfigWaypointFollowerConstPtr &amp;config);
  void callbackFromCurrentPose(const geometry_msgs::PoseStampedConstPtr &amp;msg);
  void callbackFromCurrentVelocity(const geometry_msgs::TwistStampedConstPtr &amp;msg);
  void callbackFromWayPoints(const waypoint_follower::laneConstPtr &amp;msg);

  // initializer
  void initForROS();

  // functions
  void publishTwistStamped(const bool &amp;can_get_curvature, const double &amp;kappa) const;
  void publishControlCommandStamped(const bool &amp;can_get_curvature, const double &amp;kappa) const;

  double computeLookaheadDistance() const;
  double computeCommandVelocity() const;
};

double convertCurvatureToSteeringAngle(const double &amp;wheel_base, const double &amp;kappa);

inline double kmph2mps(double velocity_kmph)
{
  return (velocity_kmph * 1000) / (60 * 60);
}

}  // waypoint_follower

#endif  // PURE_PURSUIT_CORE_H
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/wf_simulator/wf_simulator.cpp" new_path="ros/src/computing/planning/motion/packages/waypoint_follower/nodes/wf_simulator/wf_simulator.cpp">
				<diff>@@ -133,7 +133,7 @@ void callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg)
   _initial_set = true;
 }
 
-void waypointCallback(const waypoint_follower::laneConstPtr &amp;msg)
+void waypointCallback(const waypoint_follower_msgs::laneConstPtr &amp;msg)
 {
   // _path_og.setPath(msg);
   _current_waypoints.setPath(*msg);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;tf/tf.h&gt;
#include &lt;iostream&gt;
#include &lt;std_msgs/Int32.h&gt;
#include &lt;random&gt;

#include &quot;waypoint_follower/libwaypoint_follower.h&quot;

namespace
{
geometry_msgs::Twist _current_velocity;

const std::string SIMULATION_FRAME = &quot;sim_base_link&quot;;
const std::string MAP_FRAME = &quot;map&quot;;

geometry_msgs::Pose _initial_pose;
bool _initial_set = false;
bool _pose_set = false;
bool _waypoint_set = false;
bool g_is_closest_waypoint_subscribed = false;
WayPoints _current_waypoints;
ros::Publisher g_odometry_publisher;
ros::Publisher g_velocity_publisher;
int32_t g_closest_waypoint = -1;
double g_position_error;
double g_angle_error;

constexpr int LOOP_RATE = 50; // 50Hz

void CmdCallBack(const geometry_msgs::TwistStampedConstPtr &amp;msg, double accel_rate)
{

  static double previous_linear_velocity = 0;

  if(_current_velocity.linear.x &lt; msg-&gt;twist.linear.x)
  {
    _current_velocity.linear.x = previous_linear_velocity + accel_rate / (double)LOOP_RATE;

    if(_current_velocity.linear.x &gt; msg-&gt;twist.linear.x)
    {
      _current_velocity.linear.x = msg-&gt;twist.linear.x;
    }
  }
  else
  {
    _current_velocity.linear.x = previous_linear_velocity - accel_rate / (double)LOOP_RATE;

    if(_current_velocity.linear.x &lt; msg-&gt;twist.linear.x)
    {
      _current_velocity.linear.x = msg-&gt;twist.linear.x;
    }
  }

  previous_linear_velocity = _current_velocity.linear.x;

  _current_velocity.angular.z = msg-&gt;twist.angular.z;


  //_current_velocity = msg-&gt;twist;
}

void getTransformFromTF(const std::string parent_frame, const std::string child_frame, tf::StampedTransform &amp;transform)
{
  static tf::TransformListener listener;

  while (1)
  {
    try
    {
      listener.lookupTransform(parent_frame, child_frame, ros::Time(0), transform);
      break;
    }
    catch (tf::TransformException ex)
    {
      ROS_ERROR(&quot;%s&quot;, ex.what());
      ros::Duration(1.0).sleep();
    }
  }
}

void initialposeCallback(const geometry_msgs::PoseWithCovarianceStampedConstPtr &amp;input)
{
  tf::StampedTransform transform;
  getTransformFromTF(MAP_FRAME, &quot;world&quot;, transform);

  _initial_pose.position.x = input-&gt;pose.pose.position.x + transform.getOrigin().x();
  _initial_pose.position.y = input-&gt;pose.pose.position.y + transform.getOrigin().y();
  _initial_pose.position.z = input-&gt;pose.pose.position.z + transform.getOrigin().z();
  _initial_pose.orientation = input-&gt;pose.pose.orientation;

  _initial_set = true;
  _pose_set = false;
}

void callbackFromPoseStamped(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  _initial_pose = msg-&gt;pose;
  _initial_set = true;
}

void waypointCallback(const waypoint_follower::laneConstPtr &amp;msg)
{
  // _path_og.setPath(msg);
  _current_waypoints.setPath(*msg);
  _waypoint_set = true;
  //ROS_INFO_STREAM(&quot;waypoint subscribed&quot;);
}

void callbackFromClosestWaypoint(const std_msgs::Int32ConstPtr &amp;msg)
{
  g_closest_waypoint = msg-&gt;data;
  g_is_closest_waypoint_subscribed = true;
}

void publishOdometry()
{
  static ros::Time current_time = ros::Time::now();
  static ros::Time last_time = ros::Time::now();
  static geometry_msgs::Pose pose;
  static double th = 0;
  static tf::TransformBroadcaster odom_broadcaster;

  if (!_pose_set)
  {
    pose.position = _initial_pose.position;
    pose.orientation = _initial_pose.orientation;
    th = tf::getYaw(pose.orientation);
    ROS_INFO_STREAM(&quot;pose set : (&quot; &lt;&lt; pose.position.x &lt;&lt; &quot; &quot; &lt;&lt; pose.position.y &lt;&lt; &quot; &quot; &lt;&lt; pose.position.z &lt;&lt; &quot; &quot; &lt;&lt; th
                                   &lt;&lt; &quot;)&quot;);
    _pose_set = true;
  }

  /*int closest_waypoint = getClosestWaypoint(_current_waypoints.getCurrentWaypoints(), pose);
  if (closest_waypoint == -1)
  {
    ROS_INFO(&quot;cannot publish odometry because closest waypoint is -1.&quot;);
    return;
  }
  else
  {
    pose.position.z = _current_waypoints.getWaypointPosition(closest_waypoint).z;
  }
*/if(_waypoint_set &amp;&amp; g_is_closest_waypoint_subscribed)
    pose.position.z = _current_waypoints.getWaypointPosition(g_closest_waypoint).z;

  double vx = _current_velocity.linear.x;
  double vth = _current_velocity.angular.z;
  current_time = ros::Time::now();

  // compute odometry in a typical way given the velocities of the robot
  std::random_device rnd;
  std::mt19937 mt(rnd());
  std::uniform_real_distribution&lt;double&gt; rnd_dist(0.0, 2.0);
  double rnd_value_x = rnd_dist(mt) - 1.0;
  double rnd_value_y = rnd_dist(mt) - 1.0;
  double rnd_value_th = rnd_dist(mt) - 1.0;

  double dt = (current_time - last_time).toSec();
  double delta_x = (vx * cos(th)) * dt + rnd_value_x * g_position_error;
  double delta_y = (vx * sin(th)) * dt + rnd_value_y * g_position_error;
  double delta_th = vth * dt + rnd_value_th * g_angle_error * M_PI / 180;

  pose.position.x += delta_x;
  pose.position.y += delta_y;
  th += delta_th;
  pose.orientation = tf::createQuaternionMsgFromYaw(th);

  // std::cout &lt;&lt; &quot;delta (x y th) : (&quot; &lt;&lt; delta_x &lt;&lt; &quot; &quot; &lt;&lt; delta_y &lt;&lt; &quot; &quot; &lt;&lt; delta_th &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
  // std::cout &lt;&lt; &quot;current_velocity(linear.x angular.z) : (&quot; &lt;&lt; _current_velocity.linear.x &lt;&lt; &quot; &quot; &lt;&lt;
  // _current_velocity.angular.z &lt;&lt; &quot;)&quot;&lt;&lt; std::endl;
  //    std::cout &lt;&lt; &quot;current_pose : (&quot; &lt;&lt; pose.position.x &lt;&lt; &quot; &quot; &lt;&lt; pose.position.y&lt;&lt; &quot; &quot; &lt;&lt; pose.position.z &lt;&lt; &quot; &quot; &lt;&lt;
  //    th &lt;&lt; &quot;)&quot; &lt;&lt; std::endl &lt;&lt; std::endl;

  // first, we'll publish the transform over tf
  geometry_msgs::TransformStamped odom_trans;
  odom_trans.header.stamp = current_time;
  odom_trans.header.frame_id = MAP_FRAME;
  odom_trans.child_frame_id = SIMULATION_FRAME;

  odom_trans.transform.translation.x = pose.position.x;
  odom_trans.transform.translation.y = pose.position.y;
  odom_trans.transform.translation.z = pose.position.z;
  odom_trans.transform.rotation = pose.orientation;

  // send the transform
  odom_broadcaster.sendTransform(odom_trans);

  // next, we'll publish the odometry message over ROS
  std_msgs::Header h;
  h.stamp = current_time;
  h.frame_id = MAP_FRAME;

  geometry_msgs::PoseStamped ps;
  ps.header = h;
  ps.pose = pose;

  geometry_msgs::TwistStamped ts;
  ts.header = h;
  ts.twist.linear.x = vx;
  ts.twist.angular.z = vth;

  // publish the message
  g_odometry_publisher.publish(ps);
  g_velocity_publisher.publish(ts);

  last_time = current_time;
}
}
int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;wf_simulator&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  std::string initialize_source;
  private_nh.getParam(&quot;initialize_source&quot;, initialize_source);
  ROS_INFO_STREAM(&quot;initialize_source : &quot; &lt;&lt; initialize_source);

  double accel_rate;
  private_nh.param(&quot;accel_rate&quot;,accel_rate,double(1.0));
  ROS_INFO_STREAM(&quot;accel_rate : &quot; &lt;&lt; accel_rate);


  private_nh.param(&quot;position_error&quot;, g_position_error, double(0.0));
  private_nh.param(&quot;angle_error&quot;, g_angle_error, double(0.0));
  // publish topic
  g_odometry_publisher = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;sim_pose&quot;, 10);
  g_velocity_publisher = nh.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;sim_velocity&quot;, 10);

  // subscribe topic
  ros::Subscriber cmd_subscriber = nh.subscribe&lt;geometry_msgs::TwistStamped&gt;(&quot;twist_cmd&quot;, 10, boost::bind(CmdCallBack, _1, accel_rate));
  ros::Subscriber waypoint_subcscriber = nh.subscribe(&quot;base_waypoints&quot;, 10, waypointCallback);
  ros::Subscriber closest_sub = nh.subscribe(&quot;closest_waypoint&quot;, 10, callbackFromClosestWaypoint);
  ros::Subscriber initialpose_subscriber;

  if (initialize_source == &quot;Rviz&quot;)
  {
    initialpose_subscriber = nh.subscribe(&quot;initialpose&quot;, 10, initialposeCallback);
  }
  else if (initialize_source == &quot;ndt_localizer&quot;)
  {
    initialpose_subscriber = nh.subscribe(&quot;ndt_pose&quot;, 10, callbackFromPoseStamped);
  }
  else if (initialize_source == &quot;GNSS&quot;)
  {
    initialpose_subscriber = nh.subscribe(&quot;gnss_pose&quot;, 10, callbackFromPoseStamped);
  }
  else
  {
    ROS_INFO(&quot;Set pose initializer!!&quot;);
  }

  ros::Rate loop_rate(LOOP_RATE);
  while (ros::ok())
  {
    ros::spinOnce();  // check subscribe topic

    /*if (!_waypoint_set)
    {
      loop_rate.sleep();
      continue;
    }*/

    if (!_initial_set)
    {
      loop_rate.sleep();
      continue;
    }

    publishOdometry();

    loop_rate.sleep();
  }

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_maker/nodes/waypoint_loader/waypoint_loader_core.cpp" new_path="ros/src/computing/planning/motion/packages/waypoint_maker/nodes/waypoint_loader/waypoint_loader_core.cpp">
				<diff>@@ -48,7 +48,7 @@ WaypointLoaderNode::~WaypointLoaderNode()
 void WaypointLoaderNode::initPublisher()
 {
   // setup publisher
-  lane_pub_ = nh_.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;lane_waypoints_array&quot;, 10, true);
+  lane_pub_ = nh_.advertise&lt;waypoint_follower_msgs::LaneArray&gt;(&quot;lane_waypoints_array&quot;, 10, true);
 }
 
 void WaypointLoaderNode::initParameter()
@@ -64,23 +64,23 @@ void WaypointLoaderNode::publishLaneArray()
   // extract file paths
   std::vector&lt;std::string&gt; multi_file_path;
   parseColumns(multi_lane_csv_, &amp;multi_file_path);
-  waypoint_follower::LaneArray lane_array;
+  waypoint_follower_msgs::LaneArray lane_array;
   createLaneArray(multi_file_path, &amp;lane_array);
   lane_pub_.publish(lane_array);
 }
 
 void WaypointLoaderNode::createLaneArray(const std::vector&lt;std::string&gt; &amp;paths,
-                                         waypoint_follower::LaneArray *lane_array)
+                                         waypoint_follower_msgs::LaneArray *lane_array)
 {
   for (auto el : paths)
   {
-    waypoint_follower::lane lane;
+    waypoint_follower_msgs::lane lane;
     createLaneWaypoint(el, &amp;lane);
     lane_array-&gt;lanes.push_back(lane);
   }
 }
 
-void WaypointLoaderNode::createLaneWaypoint(const std::string &amp;file_path, waypoint_follower::lane *lane)
+void WaypointLoaderNode::createLaneWaypoint(const std::string &amp;file_path, waypoint_follower_msgs::lane *lane)
 {
   if (!verifyFileConsistency(file_path.c_str()))
   {
@@ -90,7 +90,7 @@ void WaypointLoaderNode::createLaneWaypoint(const std::string &amp;file_path, waypoi
 
   ROS_INFO(&quot;lane data is valid. publishing...&quot;);
   FileFormat format = checkFileFormat(file_path.c_str());
-  std::vector&lt;waypoint_follower::waypoint&gt; wps;
+  std::vector&lt;waypoint_follower_msgs::waypoint&gt; wps;
   if (format == FileFormat::ver1)
     loadWaypointsForVer1(file_path.c_str(), &amp;wps);
   else if (format == FileFormat::ver2)
@@ -103,7 +103,7 @@ void WaypointLoaderNode::createLaneWaypoint(const std::string &amp;file_path, waypoi
   lane-&gt;waypoints = wps;
 }
 
-void WaypointLoaderNode::loadWaypointsForVer1(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps)
+void WaypointLoaderNode::loadWaypointsForVer1(const char *filename, std::vector&lt;waypoint_follower_msgs::waypoint&gt; *wps)
 {
   std::ifstream ifs(filename);
 
@@ -115,7 +115,7 @@ void WaypointLoaderNode::loadWaypointsForVer1(const char *filename, std::vector&lt;
 
   while (std::getline(ifs, line))
   {
-    waypoint_follower::waypoint wp;
+    waypoint_follower_msgs::waypoint wp;
     parseWaypointForVer1(line, &amp;wp);
     wps-&gt;push_back(wp);
   }
@@ -139,7 +139,7 @@ void WaypointLoaderNode::loadWaypointsForVer1(const char *filename, std::vector&lt;
   }
 }
 
-void WaypointLoaderNode::parseWaypointForVer1(const std::string &amp;line, waypoint_follower::waypoint *wp)
+void WaypointLoaderNode::parseWaypointForVer1(const std::string &amp;line, waypoint_follower_msgs::waypoint *wp)
 {
   std::vector&lt;std::string&gt; columns;
   parseColumns(line, &amp;columns);
@@ -150,7 +150,7 @@ void WaypointLoaderNode::parseWaypointForVer1(const std::string &amp;line, waypoint_
   wp-&gt;twist.twist.linear.x = kmph2mps(std::stod(columns[3]));
 }
 
-void WaypointLoaderNode::loadWaypointsForVer2(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps)
+void WaypointLoaderNode::loadWaypointsForVer2(const char *filename, std::vector&lt;waypoint_follower_msgs::waypoint&gt; *wps)
 {
   std::ifstream ifs(filename);
 
@@ -162,14 +162,14 @@ void WaypointLoaderNode::loadWaypointsForVer2(const char *filename, std::vector&lt;
 
   while (std::getline(ifs, line))
   {
-    waypoint_follower::waypoint wp;
+    waypoint_follower_msgs::waypoint wp;
     parseWaypointForVer2(line, &amp;wp);
     wps-&gt;push_back(wp);
   }
   planningVelocity(&amp;*wps);
 }
 
-void WaypointLoaderNode::parseWaypointForVer2(const std::string &amp;line, waypoint_follower::waypoint *wp)
+void WaypointLoaderNode::parseWaypointForVer2(const std::string &amp;line, waypoint_follower_msgs::waypoint *wp)
 {
   std::vector&lt;std::string&gt; columns;
   parseColumns(line, &amp;columns);
@@ -181,7 +181,7 @@ void WaypointLoaderNode::parseWaypointForVer2(const std::string &amp;line, waypoint_
   wp-&gt;twist.twist.linear.x = kmph2mps(std::stod(columns[4]));
 }
 
-void WaypointLoaderNode::loadWaypoints(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps)
+void WaypointLoaderNode::loadWaypoints(const char *filename, std::vector&lt;waypoint_follower_msgs::waypoint&gt; *wps)
 {
   std::ifstream ifs(filename);
 
@@ -196,7 +196,7 @@ void WaypointLoaderNode::loadWaypoints(const char *filename, std::vector&lt;waypoin
   std::getline(ifs, line);  // remove second line
   while (std::getline(ifs, line))
   {
-    waypoint_follower::waypoint wp;
+    waypoint_follower_msgs::waypoint wp;
     parseWaypoint(line, contents, &amp;wp);
     wps-&gt;push_back(wp);
   }
@@ -204,7 +204,7 @@ void WaypointLoaderNode::loadWaypoints(const char *filename, std::vector&lt;waypoin
 }
 
 void WaypointLoaderNode::parseWaypoint(const std::string &amp;line, const std::vector&lt;std::string&gt; &amp;contents,
-                                       waypoint_follower::waypoint *wp)
+                                       waypoint_follower_msgs::waypoint *wp)
 {
   std::vector&lt;std::string&gt; columns;
   parseColumns(line, &amp;columns);
@@ -255,7 +255,7 @@ FileFormat WaypointLoaderNode::checkFileFormat(const char *filename)
           );
 }
 
-void WaypointLoaderNode::planningVelocity(std::vector&lt;waypoint_follower::waypoint&gt; *wps)
+void WaypointLoaderNode::planningVelocity(std::vector&lt;waypoint_follower_msgs::waypoint&gt; *wps)
 {
   for (size_t i = 0; i &lt; wps-&gt;size(); ++i)
   {
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University

 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;waypoint_loader_core.h&quot;

namespace waypoint_maker
{
// Constructor
WaypointLoaderNode::WaypointLoaderNode() : private_nh_(&quot;~&quot;)
{
  initParameter();
  initPublisher();
}

// Destructor
WaypointLoaderNode::~WaypointLoaderNode()
{
}

void WaypointLoaderNode::initPublisher()
{
  // setup publisher
  lane_pub_ = nh_.advertise&lt;waypoint_follower::LaneArray&gt;(&quot;lane_waypoints_array&quot;, 10, true);
}

void WaypointLoaderNode::initParameter()
{
  // parameter settings
  private_nh_.param&lt;double&gt;(&quot;decelerate&quot;, decelerate_, double(0));
  ROS_INFO_STREAM(&quot;decelerate :&quot; &lt;&lt; decelerate_);
  private_nh_.param&lt;std::string&gt;(&quot;multi_lane_csv&quot;, multi_lane_csv_, MULTI_LANE_CSV);
}

void WaypointLoaderNode::publishLaneArray()
{
  // extract file paths
  std::vector&lt;std::string&gt; multi_file_path;
  parseColumns(multi_lane_csv_, &amp;multi_file_path);
  waypoint_follower::LaneArray lane_array;
  createLaneArray(multi_file_path, &amp;lane_array);
  lane_pub_.publish(lane_array);
}

void WaypointLoaderNode::createLaneArray(const std::vector&lt;std::string&gt; &amp;paths,
                                         waypoint_follower::LaneArray *lane_array)
{
  for (auto el : paths)
  {
    waypoint_follower::lane lane;
    createLaneWaypoint(el, &amp;lane);
    lane_array-&gt;lanes.push_back(lane);
  }
}

void WaypointLoaderNode::createLaneWaypoint(const std::string &amp;file_path, waypoint_follower::lane *lane)
{
  if (!verifyFileConsistency(file_path.c_str()))
  {
    ROS_ERROR(&quot;lane data is something wrong...&quot;);
    return;
  }

  ROS_INFO(&quot;lane data is valid. publishing...&quot;);
  FileFormat format = checkFileFormat(file_path.c_str());
  std::vector&lt;waypoint_follower::waypoint&gt; wps;
  if (format == FileFormat::ver1)
    loadWaypointsForVer1(file_path.c_str(), &amp;wps);
  else if (format == FileFormat::ver2)
    loadWaypointsForVer2(file_path.c_str(), &amp;wps);
  else
    loadWaypoints(file_path.c_str(), &amp;wps);

  lane-&gt;header.frame_id = &quot;/map&quot;;
  lane-&gt;header.stamp = ros::Time(0);
  lane-&gt;waypoints = wps;
}

void WaypointLoaderNode::loadWaypointsForVer1(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps)
{
  std::ifstream ifs(filename);

  if (!ifs)
    return;

  std::string line;
  std::getline(ifs, line);  // Remove first line

  while (std::getline(ifs, line))
  {
    waypoint_follower::waypoint wp;
    parseWaypointForVer1(line, &amp;wp);
    wps-&gt;push_back(wp);
  }

  size_t last = wps-&gt;size() - 1;
  for (size_t i = 0; i &lt; wps-&gt;size(); ++i)
  {
    if (i != last)
    {
      double yaw = atan2(wps-&gt;at(i + 1).pose.pose.position.y - wps-&gt;at(i).pose.pose.position.y,
                         wps-&gt;at(i + 1).pose.pose.position.x - wps-&gt;at(i).pose.pose.position.x);
      wps-&gt;at(i).pose.pose.orientation = tf::createQuaternionMsgFromYaw(yaw);
    }
    else
    {
      wps-&gt;at(i).pose.pose.orientation = wps-&gt;at(i - 1).pose.pose.orientation;
    }

    wps-&gt;at(i).twist.twist.linear.x = decelerate(
        wps-&gt;at(i).pose.pose.position, wps-&gt;at(wps-&gt;size() - 1).pose.pose.position, wps-&gt;at(i).twist.twist.linear.x);
  }
}

void WaypointLoaderNode::parseWaypointForVer1(const std::string &amp;line, waypoint_follower::waypoint *wp)
{
  std::vector&lt;std::string&gt; columns;
  parseColumns(line, &amp;columns);

  wp-&gt;pose.pose.position.x = std::stod(columns[0]);
  wp-&gt;pose.pose.position.y = std::stod(columns[1]);
  wp-&gt;pose.pose.position.z = std::stod(columns[2]);
  wp-&gt;twist.twist.linear.x = kmph2mps(std::stod(columns[3]));
}

void WaypointLoaderNode::loadWaypointsForVer2(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps)
{
  std::ifstream ifs(filename);

  if (!ifs)
    return;

  std::string line;
  std::getline(ifs, line);  // Remove first line

  while (std::getline(ifs, line))
  {
    waypoint_follower::waypoint wp;
    parseWaypointForVer2(line, &amp;wp);
    wps-&gt;push_back(wp);
  }
  planningVelocity(&amp;*wps);
}

void WaypointLoaderNode::parseWaypointForVer2(const std::string &amp;line, waypoint_follower::waypoint *wp)
{
  std::vector&lt;std::string&gt; columns;
  parseColumns(line, &amp;columns);

  wp-&gt;pose.pose.position.x = std::stod(columns[0]);
  wp-&gt;pose.pose.position.y = std::stod(columns[1]);
  wp-&gt;pose.pose.position.z = std::stod(columns[2]);
  wp-&gt;pose.pose.orientation = tf::createQuaternionMsgFromYaw(std::stod(columns[3]));
  wp-&gt;twist.twist.linear.x = kmph2mps(std::stod(columns[4]));
}

void WaypointLoaderNode::loadWaypoints(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps)
{
  std::ifstream ifs(filename);

  if (!ifs)
    return;

  std::string line;
  std::getline(ifs, line);  // get first line
  std::vector&lt;std::string&gt; contents;
  parseColumns(line, &amp;contents);

  std::getline(ifs, line);  // remove second line
  while (std::getline(ifs, line))
  {
    waypoint_follower::waypoint wp;
    parseWaypoint(line, contents, &amp;wp);
    wps-&gt;push_back(wp);
  }
  planningVelocity(&amp;*wps);
}

void WaypointLoaderNode::parseWaypoint(const std::string &amp;line, const std::vector&lt;std::string&gt; &amp;contents,
                                       waypoint_follower::waypoint *wp)
{
  std::vector&lt;std::string&gt; columns;
  parseColumns(line, &amp;columns);
  std::unordered_map&lt;std::string, std::string&gt; map;
  for (size_t i = 0; i &lt; contents.size(); i++)
  {
    map[contents.at(i)] = columns.at(i);
  }

  wp-&gt;pose.pose.position.x = std::stod(map[&quot;x&quot;]);
  wp-&gt;pose.pose.position.y = std::stod(map[&quot;y&quot;]);
  wp-&gt;pose.pose.position.z = std::stod(map[&quot;z&quot;]);
  wp-&gt;pose.pose.orientation = tf::createQuaternionMsgFromYaw(std::stod(map[&quot;yaw&quot;]));
  wp-&gt;twist.twist.linear.x = kmph2mps(std::stod(map[&quot;velocity&quot;]));
  wp-&gt;change_flag = std::stoi(map[&quot;change_flag&quot;]);
}

FileFormat WaypointLoaderNode::checkFileFormat(const char *filename)
{
  std::ifstream ifs(filename);

  if (!ifs)
  {
    return FileFormat::unknown;
  }

  // get first line
  std::string line;
  std::getline(ifs, line);

  // parse first line
  std::vector&lt;std::string&gt; parsed_columns;
  parseColumns(line, &amp;parsed_columns);

  // check if first element in the first column does not include digit
  if (!std::any_of(parsed_columns.at(0).cbegin(), parsed_columns.at(0).cend(), isdigit))
  {
    return FileFormat::ver3;
  }

  // if element consists only digit
  int num_of_columns = countColumns(line);
  ROS_INFO(&quot;columns size: %d&quot;, num_of_columns);

  return ( num_of_columns == 3 ? FileFormat::ver1  // if data consists &quot;x y z (velocity)&quot;
         : num_of_columns == 4 ? FileFormat::ver2  // if data consists &quot;x y z yaw (velocity)
                               : FileFormat::unknown
          );
}

void WaypointLoaderNode::planningVelocity(std::vector&lt;waypoint_follower::waypoint&gt; *wps)
{
  for (size_t i = 0; i &lt; wps-&gt;size(); ++i)
  {
    wps-&gt;at(i).twist.twist.linear.x = decelerate(
      wps-&gt;at(i).pose.pose.position, wps-&gt;at(wps-&gt;size() - 1).pose.pose.position, wps-&gt;at(i).twist.twist.linear.x);
  }
}

double WaypointLoaderNode::decelerate(geometry_msgs::Point p1, geometry_msgs::Point p2, double original_velocity_mps)
{
  double distance = sqrt(pow(p2.x - p1.x, 2) + pow(p2.y - p1.y, 2) + pow(p2.z - p1.z, 2));
  double vel = sqrt(2 * decelerate_ * distance);  // km/h

  if (mps2kmph(vel) &lt; 1.0)
    vel = 0;

  if (vel &gt; original_velocity_mps)
    vel = original_velocity_mps;

  return vel;
}

bool WaypointLoaderNode::verifyFileConsistency(const char *filename)
{
  ROS_INFO(&quot;verify...&quot;);
  std::ifstream ifs(filename);

  if (!ifs)
    return false;

  FileFormat format = checkFileFormat(filename);
  ROS_INFO(&quot;format: %d&quot;, static_cast&lt;FileFormat&gt;(format));
  if (format == FileFormat::unknown)
  {
    ROS_ERROR(&quot;unknown file format&quot;);
    return false;
  }

  std::string line;
  std::getline(ifs, line);  // remove first line

  size_t ncol = format == FileFormat::ver1 ? 4 //x,y,z,velocity
              : format == FileFormat::ver2 ? 5 //x,y,z,yaw,velocity
              : countColumns(line);

  while (std::getline(ifs, line))  // search from second line
  {
    if (countColumns(line) != ncol)
      return false;
  }
  return true;
}

void parseColumns(const std::string &amp;line, std::vector&lt;std::string&gt; *columns)
{
  std::istringstream ss(line);
  std::string column;
  while (std::getline(ss, column, ','))
  {
    columns-&gt;push_back(column);
  }
}

size_t countColumns(const std::string &amp;line)
{
  std::istringstream ss(line);
  size_t ncol = 0;

  std::string column;
  while (std::getline(ss, column, ','))
  {
    ++ncol;
  }

  return ncol;
}

}  // waypoint_maker
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_maker/nodes/waypoint_loader/waypoint_loader_core.h" new_path="ros/src/computing/planning/motion/packages/waypoint_maker/nodes/waypoint_loader/waypoint_loader_core.h">
				<diff>@@ -41,7 +41,7 @@
 #include &lt;tf/transform_datatypes.h&gt;
 #include &lt;unordered_map&gt;
 
-#include &quot;waypoint_follower/LaneArray.h&quot;
+#include &quot;waypoint_follower_msgs/LaneArray.h&quot;
 
 namespace waypoint_maker
 {
@@ -96,19 +96,19 @@ private:
 
   // functions
 
-  void createLaneWaypoint(const std::string &amp;file_path, waypoint_follower::lane *lane);
-  void createLaneArray(const std::vector&lt;std::string&gt; &amp;paths, waypoint_follower::LaneArray *lane_array);
+  void createLaneWaypoint(const std::string &amp;file_path, waypoint_follower_msgs::lane *lane);
+  void createLaneArray(const std::vector&lt;std::string&gt; &amp;paths, waypoint_follower_msgs::LaneArray *lane_array);
 
   FileFormat checkFileFormat(const char *filename);
   bool verifyFileConsistency(const char *filename);
-  void loadWaypointsForVer1(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps);
-  void parseWaypointForVer1(const std::string &amp;line, waypoint_follower::waypoint *wp);
-  void loadWaypointsForVer2(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps);
-  void parseWaypointForVer2(const std::string &amp;line, waypoint_follower::waypoint *wp);
-  void loadWaypoints(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps);
+  void loadWaypointsForVer1(const char *filename, std::vector&lt;waypoint_follower_msgs::waypoint&gt; *wps);
+  void parseWaypointForVer1(const std::string &amp;line, waypoint_follower_msgs::waypoint *wp);
+  void loadWaypointsForVer2(const char *filename, std::vector&lt;waypoint_follower_msgs::waypoint&gt; *wps);
+  void parseWaypointForVer2(const std::string &amp;line, waypoint_follower_msgs::waypoint *wp);
+  void loadWaypoints(const char *filename, std::vector&lt;waypoint_follower_msgs::waypoint&gt; *wps);
   void parseWaypoint(const std::string &amp;line, const std::vector&lt;std::string&gt; &amp;contents,
-                            waypoint_follower::waypoint *wp);
-  void planningVelocity(std::vector&lt;waypoint_follower::waypoint&gt; *wps);
+                            waypoint_follower_msgs::waypoint *wp);
+  void planningVelocity(std::vector&lt;waypoint_follower_msgs::waypoint&gt; *wps);
   double decelerate(geometry_msgs::Point p1, geometry_msgs::Point p2, double original_velocity_mps);
 
 };
</diff>
				<old_file>/*
// *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef WAYPOINT_LOADER_CORE_H
#define WAYPOINT_LOADER_CORE_H

// ROS includes
#include &lt;ros/ros.h&gt;

// C++ includes
#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;vector&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;unordered_map&gt;

#include &quot;waypoint_follower/LaneArray.h&quot;

namespace waypoint_maker
{

const std::string MULTI_LANE_CSV = &quot;/tmp/driving_lane.csv&quot;;

enum class FileFormat : int32_t
{
  ver1,  //x,y,z,(velocity)
  ver2,  //x,y,z,yaw,(velocity)
  ver3,  //first line consists on explanation of values

  unknown = -1,
};

typedef std::underlying_type&lt;FileFormat&gt;::type FileFormatInteger;

inline double kmph2mps(double velocity_kmph)
{
  return (velocity_kmph * 1000) / (60 * 60);
}
inline double mps2kmph(double velocity_mps)
{
  return (velocity_mps * 60 * 60) / 1000;
}

class WaypointLoaderNode
{
public:

  WaypointLoaderNode();
  ~WaypointLoaderNode();

  void publishLaneArray();

private:

  // handle
  ros::NodeHandle nh_;
  ros::NodeHandle private_nh_;

  // publisher
  ros::Publisher lane_pub_;

  // variables
  std::string multi_lane_csv_;
  double decelerate_;

  // initializer
  void initPublisher();
  void initParameter();

  // functions

  void createLaneWaypoint(const std::string &amp;file_path, waypoint_follower::lane *lane);
  void createLaneArray(const std::vector&lt;std::string&gt; &amp;paths, waypoint_follower::LaneArray *lane_array);

  FileFormat checkFileFormat(const char *filename);
  bool verifyFileConsistency(const char *filename);
  void loadWaypointsForVer1(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps);
  void parseWaypointForVer1(const std::string &amp;line, waypoint_follower::waypoint *wp);
  void loadWaypointsForVer2(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps);
  void parseWaypointForVer2(const std::string &amp;line, waypoint_follower::waypoint *wp);
  void loadWaypoints(const char *filename, std::vector&lt;waypoint_follower::waypoint&gt; *wps);
  void parseWaypoint(const std::string &amp;line, const std::vector&lt;std::string&gt; &amp;contents,
                            waypoint_follower::waypoint *wp);
  void planningVelocity(std::vector&lt;waypoint_follower::waypoint&gt; *wps);
  double decelerate(geometry_msgs::Point p1, geometry_msgs::Point p2, double original_velocity_mps);

};

void parseColumns(const std::string &amp;line, std::vector&lt;std::string&gt; *columns);
size_t countColumns(const std::string&amp; line);

}
#endif  // WAYPOINT_LOADER_CORE_H
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/waypoint_maker/nodes/waypoint_marker_publisher/waypoint_marker_publisher.cpp" new_path="ros/src/computing/planning/motion/packages/waypoint_maker/nodes/waypoint_marker_publisher/waypoint_marker_publisher.cpp">
				<diff>@@ -38,7 +38,7 @@
 #include &lt;vector&gt;
 #include &lt;string&gt;
 
-#include &quot;waypoint_follower/LaneArray.h&quot;
+#include &quot;waypoint_follower_msgs/LaneArray.h&quot;
 #include &quot;waypoint_follower/libwaypoint_follower.h&quot;
 #include &lt;runtime_manager/ConfigLaneStop.h&gt;
 #include &quot;runtime_manager/traffic_light.h&quot;
@@ -96,7 +96,7 @@ void publishGlobalMarker()
   g_global_mark_pub.publish(marker_array);
 }
 
-void createGlobalLaneArrayVelocityMarker(const waypoint_follower::LaneArray &amp;lane_waypoints_array)
+void createGlobalLaneArrayVelocityMarker(const waypoint_follower_msgs::LaneArray &amp;lane_waypoints_array)
 {
   visualization_msgs::MarkerArray tmp_marker_array;
   // display by markers the velocity of each waypoint.
@@ -138,7 +138,7 @@ void createGlobalLaneArrayVelocityMarker(const waypoint_follower::LaneArray &amp;lan
                                        tmp_marker_array.markers.end());
 }
 
-void createGlobalLaneArrayChangeFlagMarker(const waypoint_follower::LaneArray &amp;lane_waypoints_array)
+void createGlobalLaneArrayChangeFlagMarker(const waypoint_follower_msgs::LaneArray &amp;lane_waypoints_array)
 {
   visualization_msgs::MarkerArray tmp_marker_array;
   // display by markers the velocity of each waypoint.
@@ -198,7 +198,7 @@ void createGlobalLaneArrayChangeFlagMarker(const waypoint_follower::LaneArray &amp;l
 }
 
 void createLocalWaypointVelocityMarker(std_msgs::ColorRGBA color, int closest_waypoint,
-                                       const waypoint_follower::lane &amp;lane_waypoint)
+                                       const waypoint_follower_msgs::lane &amp;lane_waypoint)
 {
 
   // display by markers the velocity of each waypoint.
@@ -231,7 +231,7 @@ void createLocalWaypointVelocityMarker(std_msgs::ColorRGBA color, int closest_wa
 
 }
 
-void createGlobalLaneArrayMarker(std_msgs::ColorRGBA color, const waypoint_follower::LaneArray &amp;lane_waypoints_array)
+void createGlobalLaneArrayMarker(std_msgs::ColorRGBA color, const waypoint_follower_msgs::LaneArray &amp;lane_waypoints_array)
 {
   visualization_msgs::Marker lane_waypoint_marker;
   lane_waypoint_marker.header.frame_id = &quot;map&quot;;
@@ -261,7 +261,7 @@ void createGlobalLaneArrayMarker(std_msgs::ColorRGBA color, const waypoint_follo
 
 }
 
-void createGlobalLaneArrayOrientationMarker(const waypoint_follower::LaneArray &amp;lane_waypoints_array)
+void createGlobalLaneArrayOrientationMarker(const waypoint_follower_msgs::LaneArray &amp;lane_waypoints_array)
 {
   visualization_msgs::MarkerArray tmp_marker_array;
   visualization_msgs::Marker lane_waypoint_marker;
@@ -294,7 +294,7 @@ void createGlobalLaneArrayOrientationMarker(const waypoint_follower::LaneArray &amp;
                                        tmp_marker_array.markers.end());
 }
 
-void createLocalPathMarker(std_msgs::ColorRGBA color, const waypoint_follower::lane &amp;lane_waypoint)
+void createLocalPathMarker(std_msgs::ColorRGBA color, const waypoint_follower_msgs::lane &amp;lane_waypoint)
 {
   visualization_msgs::Marker lane_waypoint_marker;
   lane_waypoint_marker.header.frame_id = &quot;map&quot;;
@@ -317,7 +317,7 @@ void createLocalPathMarker(std_msgs::ColorRGBA color, const waypoint_follower::l
   g_local_waypoints_marker_array.markers.push_back(lane_waypoint_marker);
 }
 
-void createLocalPointMarker(const waypoint_follower::lane &amp;lane_waypoint)
+void createLocalPointMarker(const waypoint_follower_msgs::lane &amp;lane_waypoint)
 {
   visualization_msgs::Marker lane_waypoint_marker;
   lane_waypoint_marker.header.frame_id = &quot;map&quot;;
@@ -396,7 +396,7 @@ void configParameter(const runtime_manager::ConfigLaneStopConstPtr&amp; msg)
   g_config_manual_detection = msg-&gt;manual_detection;
 }
 
-void laneArrayCallback(const waypoint_follower::LaneArrayConstPtr &amp;msg)
+void laneArrayCallback(const waypoint_follower_msgs::LaneArrayConstPtr &amp;msg)
 {
   g_global_marker_array.markers.clear();
   createGlobalLaneArrayVelocityMarker(*msg);
@@ -406,7 +406,7 @@ void laneArrayCallback(const waypoint_follower::LaneArrayConstPtr &amp;msg)
   publishGlobalMarker();
 }
 
-void temporalCallback(const waypoint_follower::laneConstPtr &amp;msg)
+void temporalCallback(const waypoint_follower_msgs::laneConstPtr &amp;msg)
 {
   g_local_waypoints_marker_array.markers.clear();
   if (_closest_waypoint != -1)
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &lt;ros/ros.h&gt;
#include &lt;ros/console.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;std_msgs/Int32.h&gt;
#include &lt;tf/transform_datatypes.h&gt;

#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;

#include &quot;waypoint_follower/LaneArray.h&quot;
#include &quot;waypoint_follower/libwaypoint_follower.h&quot;
#include &lt;runtime_manager/ConfigLaneStop.h&gt;
#include &quot;runtime_manager/traffic_light.h&quot;

namespace
{

ros::Publisher g_local_mark_pub;
ros::Publisher g_global_mark_pub;

constexpr int32_t TRAFFIC_LIGHT_RED = 0;
constexpr int32_t TRAFFIC_LIGHT_GREEN = 1;
constexpr int32_t TRAFFIC_LIGHT_UNKNOWN = 2;

std_msgs::ColorRGBA _initial_color;
std_msgs::ColorRGBA _global_color;
std_msgs::ColorRGBA g_local_color;
const double g_global_alpha = 0.2;
const double g_local_alpha = 1.0;
int _closest_waypoint = -1;
visualization_msgs::MarkerArray g_global_marker_array;
visualization_msgs::MarkerArray g_local_waypoints_marker_array;
bool g_config_manual_detection = true;

enum class ChangeFlag : int32_t
{
  straight,
  right,
  left,

  unknown = -1,
};

typedef std::underlying_type&lt;ChangeFlag&gt;::type ChangeFlagInteger;

void publishLocalMarker()
{
  visualization_msgs::MarkerArray marker_array;

  //insert local marker
  marker_array.markers.insert(marker_array.markers.end(), g_local_waypoints_marker_array.markers.begin(),
                              g_local_waypoints_marker_array.markers.end());

  g_local_mark_pub.publish(marker_array);
}

void publishGlobalMarker()
{
  visualization_msgs::MarkerArray marker_array;

  //insert global marker
  marker_array.markers.insert(marker_array.markers.end(), g_global_marker_array.markers.begin(),
                              g_global_marker_array.markers.end());

  g_global_mark_pub.publish(marker_array);
}

void createGlobalLaneArrayVelocityMarker(const waypoint_follower::LaneArray &amp;lane_waypoints_array)
{
  visualization_msgs::MarkerArray tmp_marker_array;
  // display by markers the velocity of each waypoint.
  visualization_msgs::Marker velocity_marker;
  velocity_marker.header.frame_id = &quot;map&quot;;
  velocity_marker.header.stamp = ros::Time();
  velocity_marker.type = visualization_msgs::Marker::TEXT_VIEW_FACING;
  velocity_marker.action = visualization_msgs::Marker::ADD;
  velocity_marker.scale.z = 0.4;
  velocity_marker.color.a = 1.0;
  velocity_marker.color.r = 1;
  velocity_marker.color.g = 1;
  velocity_marker.color.b = 1;
  velocity_marker.frame_locked = true;

  int count = 1;
  for (auto lane : lane_waypoints_array.lanes)
  {
    velocity_marker.ns = &quot;global_velocity_lane_&quot; + std::to_string(count);
    for (int i = 0; i &lt; static_cast&lt;int&gt;(lane.waypoints.size()); i++)
    {
      //std::cout &lt;&lt; _waypoints[i].GetX() &lt;&lt; &quot; &quot; &lt;&lt; _waypoints[i].GetY() &lt;&lt; &quot; &quot; &lt;&lt; _waypoints[i].GetZ() &lt;&lt; &quot; &quot; &lt;&lt; _waypoints[i].GetVelocity_kmh() &lt;&lt; std::endl;
      velocity_marker.id = i;
      geometry_msgs::Point relative_p;
      relative_p.y = 0.5;
      velocity_marker.pose.position = calcAbsoluteCoordinate(relative_p, lane.waypoints[i].pose.pose);
      velocity_marker.pose.position.z += 0.2;

      // double to string
      std::string vel = std::to_string(mps2kmph(lane.waypoints[i].twist.twist.linear.x));
      velocity_marker.text = vel.erase(vel.find_first_of(&quot;.&quot;) + 2);

      tmp_marker_array.markers.push_back(velocity_marker);
    }
    count++;
  }

  g_global_marker_array.markers.insert(g_global_marker_array.markers.end(), tmp_marker_array.markers.begin(),
                                       tmp_marker_array.markers.end());
}

void createGlobalLaneArrayChangeFlagMarker(const waypoint_follower::LaneArray &amp;lane_waypoints_array)
{
  visualization_msgs::MarkerArray tmp_marker_array;
  // display by markers the velocity of each waypoint.
  visualization_msgs::Marker marker;
  marker.header.frame_id = &quot;map&quot;;
  marker.header.stamp = ros::Time();
  marker.type = visualization_msgs::Marker::TEXT_VIEW_FACING;
  marker.action = visualization_msgs::Marker::ADD;
  marker.scale.z = 0.4;
  marker.color.a = 1.0;
  marker.color.r = 1;
  marker.color.g = 1;
  marker.color.b = 1;
  marker.frame_locked = true;

  int count = 1;
  for (auto lane : lane_waypoints_array.lanes)
  {
    marker.ns = &quot;global_change_flag_lane_&quot; + std::to_string(count);
    for (int i = 0; i &lt; static_cast&lt;int&gt;(lane.waypoints.size()); i++)
    {
      //std::cout &lt;&lt; _waypoints[i].GetX() &lt;&lt; &quot; &quot; &lt;&lt; _waypoints[i].GetY() &lt;&lt; &quot; &quot; &lt;&lt; _waypoints[i].GetZ() &lt;&lt; &quot; &quot; &lt;&lt; _waypoints[i].GetVelocity_kmh() &lt;&lt; std::endl;
      marker.id = i;
      geometry_msgs::Point relative_p;
      relative_p.x = -0.1;
      marker.pose.position = calcAbsoluteCoordinate(relative_p, lane.waypoints[i].pose.pose);
      marker.pose.position.z += 0.2;

      // double to string
      std::string str = &quot;&quot;;
      if(lane.waypoints[i].change_flag == static_cast&lt;ChangeFlagInteger&gt;(ChangeFlag::straight))
      {
        str = &quot;S&quot;;
      }
      else if(lane.waypoints[i].change_flag == static_cast&lt;ChangeFlagInteger&gt;(ChangeFlag::right))
      {
        str = &quot;R&quot;;
      }
      else if(lane.waypoints[i].change_flag == static_cast&lt;ChangeFlagInteger&gt;(ChangeFlag::left))
      {
        str = &quot;L&quot;;
      }
      else if(lane.waypoints[i].change_flag == static_cast&lt;ChangeFlagInteger&gt;(ChangeFlag::unknown))
      {
        str = &quot;U&quot;;
      }

      marker.text = str;

      tmp_marker_array.markers.push_back(marker);
    }
    count++;
  }

  g_global_marker_array.markers.insert(g_global_marker_array.markers.end(), tmp_marker_array.markers.begin(),
                                       tmp_marker_array.markers.end());
}

void createLocalWaypointVelocityMarker(std_msgs::ColorRGBA color, int closest_waypoint,
                                       const waypoint_follower::lane &amp;lane_waypoint)
{

  // display by markers the velocity of each waypoint.
  visualization_msgs::Marker velocity;
  velocity.header.frame_id = &quot;map&quot;;
  velocity.header.stamp = ros::Time();
  velocity.ns = &quot;local_waypoint_velocity&quot;;
  velocity.type = visualization_msgs::Marker::TEXT_VIEW_FACING;
  velocity.action = visualization_msgs::Marker::ADD;
  velocity.scale.z = 0.4;
  velocity.color = color;
  velocity.frame_locked = true;

  for (int i = 0; i &lt; static_cast&lt;int&gt;(lane_waypoint.waypoints.size()); i++)
  {
    velocity.id = i;
    geometry_msgs::Point relative_p;
    relative_p.y = -0.65;
    velocity.pose.position = calcAbsoluteCoordinate(relative_p, lane_waypoint.waypoints[i].pose.pose);
    velocity.pose.position.z += 0.2;

    // double to string
    std::ostringstream oss;
    // oss &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; mps2kmph(lane_waypoint.waypoints[i].twist.twist.linear.x) &lt;&lt; &quot; km/h&quot;;
    oss &lt;&lt; std::fixed &lt;&lt; std::setprecision(1) &lt;&lt; mps2kmph(lane_waypoint.waypoints[i].twist.twist.linear.x);
    velocity.text = oss.str();

    g_local_waypoints_marker_array.markers.push_back(velocity);
  }

}

void createGlobalLaneArrayMarker(std_msgs::ColorRGBA color, const waypoint_follower::LaneArray &amp;lane_waypoints_array)
{
  visualization_msgs::Marker lane_waypoint_marker;
  lane_waypoint_marker.header.frame_id = &quot;map&quot;;
  lane_waypoint_marker.header.stamp = ros::Time();
  lane_waypoint_marker.ns = &quot;global_lane_array_marker&quot;;
  lane_waypoint_marker.type = visualization_msgs::Marker::LINE_STRIP;
  lane_waypoint_marker.action = visualization_msgs::Marker::ADD;
  lane_waypoint_marker.scale.x = 1.0;
  lane_waypoint_marker.color = color;
  lane_waypoint_marker.frame_locked = true;

  int count = 0;
  for (auto lane : lane_waypoints_array.lanes)
  {
    lane_waypoint_marker.points.clear();
    lane_waypoint_marker.id = count;

    for (auto el : lane.waypoints)
    {
      geometry_msgs::Point point;
      point = el.pose.pose.position;
      lane_waypoint_marker.points.push_back(point);
    }
    g_global_marker_array.markers.push_back(lane_waypoint_marker);
    count++;
  }

}

void createGlobalLaneArrayOrientationMarker(const waypoint_follower::LaneArray &amp;lane_waypoints_array)
{
  visualization_msgs::MarkerArray tmp_marker_array;
  visualization_msgs::Marker lane_waypoint_marker;
  lane_waypoint_marker.header.frame_id = &quot;map&quot;;
  lane_waypoint_marker.header.stamp = ros::Time();
  lane_waypoint_marker.type = visualization_msgs::Marker::ARROW;
  lane_waypoint_marker.action = visualization_msgs::Marker::ADD;
  lane_waypoint_marker.scale.x = 0.25;
  lane_waypoint_marker.scale.y = 0.05;
  lane_waypoint_marker.scale.z = 0.05;
  lane_waypoint_marker.color.r = 1.0;
  lane_waypoint_marker.color.a = 1.0;
  lane_waypoint_marker.frame_locked = true;

  int count = 1;
  for (auto lane : lane_waypoints_array.lanes)
  {
    lane_waypoint_marker.ns = &quot;global_lane_waypoint_orientation_marker_&quot; + std::to_string(count);

    for (int i = 0; i &lt; static_cast&lt;int&gt;(lane.waypoints.size()); i++)
    {
      lane_waypoint_marker.id = i;
      lane_waypoint_marker.pose = lane.waypoints[i].pose.pose;
      tmp_marker_array.markers.push_back(lane_waypoint_marker);
    }
    count++;
  }

  g_global_marker_array.markers.insert(g_global_marker_array.markers.end(), tmp_marker_array.markers.begin(),
                                       tmp_marker_array.markers.end());
}

void createLocalPathMarker(std_msgs::ColorRGBA color, const waypoint_follower::lane &amp;lane_waypoint)
{
  visualization_msgs::Marker lane_waypoint_marker;
  lane_waypoint_marker.header.frame_id = &quot;map&quot;;
  lane_waypoint_marker.header.stamp = ros::Time();
  lane_waypoint_marker.ns = &quot;local_path_marker&quot;;
  lane_waypoint_marker.id = 0;
  lane_waypoint_marker.type = visualization_msgs::Marker::LINE_STRIP;
  lane_waypoint_marker.action = visualization_msgs::Marker::ADD;
  lane_waypoint_marker.scale.x = 0.2;
  lane_waypoint_marker.color = color;
  lane_waypoint_marker.frame_locked = true;

  for (unsigned int i = 0; i &lt; lane_waypoint.waypoints.size(); i++)
  {
    geometry_msgs::Point point;
    point = lane_waypoint.waypoints[i].pose.pose.position;
    lane_waypoint_marker.points.push_back(point);

  }
  g_local_waypoints_marker_array.markers.push_back(lane_waypoint_marker);
}

void createLocalPointMarker(const waypoint_follower::lane &amp;lane_waypoint)
{
  visualization_msgs::Marker lane_waypoint_marker;
  lane_waypoint_marker.header.frame_id = &quot;map&quot;;
  lane_waypoint_marker.header.stamp = ros::Time();
  lane_waypoint_marker.ns = &quot;local_point_marker&quot;;
  lane_waypoint_marker.id = 0;
  lane_waypoint_marker.type = visualization_msgs::Marker::CUBE_LIST;
  lane_waypoint_marker.action = visualization_msgs::Marker::ADD;
  lane_waypoint_marker.scale.x = 0.2;
  lane_waypoint_marker.scale.y = 0.2;
  lane_waypoint_marker.scale.z = 0.2;
  lane_waypoint_marker.color.r = 1.0;
   lane_waypoint_marker.color.a = 1.0;
  lane_waypoint_marker.frame_locked = true;

  for (unsigned int i = 0; i &lt; lane_waypoint.waypoints.size(); i++)
  {
    geometry_msgs::Point point;
    point = lane_waypoint.waypoints[i].pose.pose.position;
    lane_waypoint_marker.points.push_back(point);

  }
  g_local_waypoints_marker_array.markers.push_back(lane_waypoint_marker);
}

void lightCallback(const runtime_manager::traffic_lightConstPtr&amp; msg)
{
  std_msgs::ColorRGBA global_color;
  global_color.a = g_global_alpha;

  std_msgs::ColorRGBA local_color;
  local_color.a = g_local_alpha;

  switch (msg-&gt;traffic_light)
  {
    case TRAFFIC_LIGHT_RED:
      global_color.r = 1.0;
      _global_color = global_color;
      local_color.r = 1.0;
      g_local_color = local_color;
      break;
    case TRAFFIC_LIGHT_GREEN:
      global_color.g = 1.0;
      _global_color = global_color;
      local_color.g = 1.0;
      g_local_color = local_color;
      break;
    case TRAFFIC_LIGHT_UNKNOWN:
      global_color.b = 1.0;
      global_color.g = 0.7;
      _global_color = global_color;
      local_color.b = 1.0;
      local_color.g = 0.7;
      g_local_color = local_color;
      break;
    default:
      ROS_ERROR(&quot;unknown traffic_light&quot;);
      return;
  }
}

void receiveAutoDetection(const runtime_manager::traffic_lightConstPtr&amp; msg)
{
  if (!g_config_manual_detection)
    lightCallback(msg);
}

void receiveManualDetection(const runtime_manager::traffic_lightConstPtr&amp; msg)
{
  if (g_config_manual_detection)
    lightCallback(msg);
}

void configParameter(const runtime_manager::ConfigLaneStopConstPtr&amp; msg)
{
  g_config_manual_detection = msg-&gt;manual_detection;
}

void laneArrayCallback(const waypoint_follower::LaneArrayConstPtr &amp;msg)
{
  g_global_marker_array.markers.clear();
  createGlobalLaneArrayVelocityMarker(*msg);
  //createGlobalLaneArrayMarker(_global_color, *msg);
  createGlobalLaneArrayOrientationMarker(*msg);
  createGlobalLaneArrayChangeFlagMarker(*msg);
  publishGlobalMarker();
}

void temporalCallback(const waypoint_follower::laneConstPtr &amp;msg)
{
  g_local_waypoints_marker_array.markers.clear();
  if (_closest_waypoint != -1)
    createLocalWaypointVelocityMarker(g_local_color, _closest_waypoint, *msg);
  createLocalPathMarker(g_local_color, *msg);
  createLocalPointMarker(*msg);
  publishLocalMarker();

}

void closestCallback(const std_msgs::Int32ConstPtr &amp;msg)
{
  _closest_waypoint = msg-&gt;data;
}
}

int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;waypoints_marker_publisher&quot;);
  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  //subscribe traffic light
  ros::Subscriber light_sub = nh.subscribe(&quot;light_color&quot;, 10, receiveAutoDetection);
  ros::Subscriber light_managed_sub = nh.subscribe(&quot;light_color_managed&quot;, 10, receiveManualDetection);

  //subscribe global waypoints
  ros::Subscriber lane_array_sub = nh.subscribe(&quot;lane_waypoints_array&quot;, 10, laneArrayCallback);
  ros::Subscriber traffic_array_sub = nh.subscribe(&quot;traffic_waypoints_array&quot;, 10, laneArrayCallback);

  //subscribe local waypoints
  ros::Subscriber temporal_sub = nh.subscribe(&quot;temporal_waypoints&quot;, 10, temporalCallback);
  ros::Subscriber closest_sub = nh.subscribe(&quot;closest_waypoint&quot;, 10, closestCallback);

  //subscribe config
  ros::Subscriber config_sub = nh.subscribe(&quot;config/lane_stop&quot;, 10, configParameter);

  g_local_mark_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;local_waypoints_mark&quot;, 10, true);
  g_global_mark_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;global_waypoints_mark&quot;, 10, true);

  //initialize path color
  _initial_color.b = 1.0;
  _initial_color.g = 0.7;
  _global_color = _initial_color;
  _global_color.a = g_global_alpha;
  g_local_color = _initial_color;
  g_local_color.a = g_local_alpha;

  ros::spin();

}
</old_file>
			</file>
			<file old_path="ros/src/data/packages/map_file/nodes/points_map_loader/points_map_loader.cpp" new_path="ros/src/data/packages/map_file/nodes/points_map_loader/points_map_loader.cpp">
				<diff>@@ -37,7 +37,7 @@
 #include &lt;std_msgs/Bool.h&gt;
 #include &lt;tf/transform_listener.h&gt;
 
-#include &lt;waypoint_follower/LaneArray.h&gt;
+#include &lt;waypoint_follower_msgs/LaneArray.h&gt;
 
 #include &lt;map_file/get_file.h&gt;
 
@@ -419,11 +419,11 @@ void publish_dragged_pcd(const geometry_msgs::PoseWithCovarianceStamped&amp; msg)
 	publish_pcd(create_pcd(p));
 }
 
-void request_lookahead_download(const waypoint_follower::LaneArray&amp; msg)
+void request_lookahead_download(const waypoint_follower_msgs::LaneArray&amp; msg)
 {
 	request_queue.clear_look_ahead();
 
-	for (const waypoint_follower::lane&amp; l : msg.lanes) {
+	for (const waypoint_follower_msgs::lane&amp; l : msg.lanes) {
 		size_t end = l.waypoints.size() - 1;
 		double distance = 0;
 		double threshold = (MARGIN_UNIT / 2) + margin; // XXX better way?
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;condition_variable&gt;
#include &lt;queue&gt;
#include &lt;thread&gt;

#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;std_msgs/Bool.h&gt;
#include &lt;tf/transform_listener.h&gt;

#include &lt;waypoint_follower/LaneArray.h&gt;

#include &lt;map_file/get_file.h&gt;

namespace {

class RequestQueue {
private:
	std::queue&lt;geometry_msgs::Point&gt; queue_; // takes priority over look_ahead_queue_
	std::queue&lt;geometry_msgs::Point&gt; look_ahead_queue_;
	std::mutex mtx_;
	std::condition_variable cv_;

public:
	void enqueue(const geometry_msgs::Point&amp; p);
	void enqueue_look_ahead(const geometry_msgs::Point&amp; p);
	void clear();
	void clear_look_ahead();
	geometry_msgs::Point dequeue();
};

void RequestQueue::enqueue(const geometry_msgs::Point&amp; p)
{
	std::unique_lock&lt;std::mutex&gt; lock(mtx_);
	queue_.push(p);
	cv_.notify_all();
}

void RequestQueue::enqueue_look_ahead(const geometry_msgs::Point&amp; p)
{
	std::unique_lock&lt;std::mutex&gt; lock(mtx_);
	look_ahead_queue_.push(p);
	cv_.notify_all();
}

void RequestQueue::clear()
{
	std::unique_lock&lt;std::mutex&gt; lock(mtx_);
	while (!queue_.empty())
		queue_.pop();
}

void RequestQueue::clear_look_ahead()
{
	std::unique_lock&lt;std::mutex&gt; lock(mtx_);
	while (!look_ahead_queue_.empty())
		look_ahead_queue_.pop();
}

geometry_msgs::Point RequestQueue::dequeue()
{
	std::unique_lock&lt;std::mutex&gt; lock(mtx_);
	while (queue_.empty() &amp;&amp; look_ahead_queue_.empty())
		cv_.wait(lock);
	if (!queue_.empty()) {
		geometry_msgs::Point p = queue_.front();
		queue_.pop();
		return p;
	} else {
		geometry_msgs::Point p = look_ahead_queue_.front();
		look_ahead_queue_.pop();
		return p;
	}
}

struct Area {
	std::string path;
	double x_min;
	double y_min;
	double z_min;
	double x_max;
	double y_max;
	double z_max;
};

typedef std::vector&lt;Area&gt; AreaList;
typedef std::vector&lt;std::vector&lt;std::string&gt;&gt; Tbl;

constexpr int DEFAULT_UPDATE_RATE = 1000; // ms
constexpr double MARGIN_UNIT = 100; // meter
constexpr int ROUNDING_UNIT = 1000; // meter
const std::string AREALIST_FILENAME = &quot;arealist.txt&quot;;
const std::string TEMPORARY_DIRNAME = &quot;/tmp/&quot;;

int update_rate;
int fallback_rate;
double margin;
bool can_download;

ros::Time gnss_time;
ros::Time current_time;

ros::Publisher pcd_pub;
ros::Publisher stat_pub;
std_msgs::Bool stat_msg;

AreaList all_areas;
AreaList downloaded_areas;
std::mutex downloaded_areas_mtx;
std::vector&lt;std::string&gt; cached_arealist_paths;

GetFile gf;
RequestQueue request_queue;

Tbl read_csv(const std::string&amp; path)
{
	std::ifstream ifs(path.c_str());
	std::string line;
	Tbl ret;
	while (std::getline(ifs, line)) {
		std::istringstream iss(line);
		std::string col;
		std::vector&lt;std::string&gt; cols;
		while (std::getline(iss, col, ','))
			cols.push_back(col);
		ret.push_back(cols);
	}
	return ret;
}

void write_csv(const std::string&amp; path, const Tbl&amp; tbl)
{
	std::ofstream ofs(path.c_str());
	for (const std::vector&lt;std::string&gt;&amp; cols : tbl) {
		std::string line;
		for (size_t i = 0; i &lt; cols.size(); ++i) {
			if (i == 0)
				line += cols[i];
			else
				line += &quot;,&quot; + cols[i];
		}
		ofs &lt;&lt; line &lt;&lt; std::endl;
	}
}

AreaList read_arealist(const std::string&amp; path)
{
	Tbl tbl = read_csv(path);
	AreaList ret;
	for (const std::vector&lt;std::string&gt;&amp; cols : tbl) {
		Area area;
		area.path = cols[0];
		area.x_min = std::stod(cols[1]);
		area.y_min = std::stod(cols[2]);
		area.z_min = std::stod(cols[3]);
		area.x_max = std::stod(cols[4]);
		area.y_max = std::stod(cols[5]);
		area.z_max = std::stod(cols[6]);
		ret.push_back(area);
	}
	return ret;
}

void write_arealist(const std::string&amp; path, const AreaList&amp; areas)
{
	Tbl tbl;
	for (const Area&amp; area : areas) {
		std::vector&lt;std::string&gt; cols;
		cols.push_back(area.path);
		cols.push_back(std::to_string(area.x_min));
		cols.push_back(std::to_string(area.y_min));
		cols.push_back(std::to_string(area.z_min));
		cols.push_back(std::to_string(area.x_max));
		cols.push_back(std::to_string(area.y_max));
		cols.push_back(std::to_string(area.z_max));
		tbl.push_back(cols);
	}
	write_csv(path, tbl);
}

bool is_downloaded(const std::string&amp; path)
{
	struct stat st;
	return (stat(path.c_str(), &amp;st) == 0);
}

bool is_in_area(double x, double y, const Area&amp; area, double m)
{
	return ((area.x_min - m) &lt;= x &amp;&amp; x &lt;= (area.x_max + m) &amp;&amp; (area.y_min - m) &lt;= y &amp;&amp; y &lt;= (area.y_max + m));
}

std::string create_location(int x, int y)
{
	x -= x % ROUNDING_UNIT;
	y -= y % ROUNDING_UNIT;
	return (&quot;data/map/&quot; + std::to_string(y) + &quot;/&quot; + std::to_string(x) + &quot;/pointcloud/&quot;);
}

void cache_arealist(const Area&amp; area, AreaList&amp; areas)
{
	for (const Area&amp; a : areas) {
		if (a.path == area.path)
			return;
	}
	areas.push_back(area);
}

int download(GetFile gf, const std::string&amp; tmp, const std::string&amp; loc, const std::string&amp; filename)
{
	std::string pathname;
	pathname += tmp;
	std::istringstream iss(loc);
	std::string col;
	while (std::getline(iss, col, '/')) {
		pathname += col + &quot;/&quot;;
		mkdir(pathname.c_str(), 0755);
	}

	return gf.GetHTTPFile(loc + filename);
}

void download_map()
{
	while (true) {
		geometry_msgs::Point p = request_queue.dequeue();

		int x = static_cast&lt;int&gt;(p.x);
		int y = static_cast&lt;int&gt;(p.y);
		int x_min = static_cast&lt;int&gt;(p.x - margin);
		int y_min = static_cast&lt;int&gt;(p.y - margin);
		int x_max = static_cast&lt;int&gt;(p.x + margin);
		int y_max = static_cast&lt;int&gt;(p.y + margin);

		std::vector&lt;std::string&gt; locs;
		locs.push_back(create_location(x, y));
		locs.push_back(create_location(x_min, y_min));
		locs.push_back(create_location(x_min, y_max));
		locs.push_back(create_location(x_max, y_min));
		locs.push_back(create_location(x_max, y_max));
		for (const std::string&amp; loc : locs) { // XXX better way?
			std::string arealist_path = TEMPORARY_DIRNAME + loc + AREALIST_FILENAME;

			bool cached = false;
			for (const std::string&amp; path : cached_arealist_paths) {
				if (path == arealist_path) {
					cached = true;
					break;
				}
			}
			if (cached)
				continue;

			AreaList areas;
			if (is_downloaded(arealist_path))
				areas = read_arealist(arealist_path);
			else {
				if (download(gf, TEMPORARY_DIRNAME, loc, AREALIST_FILENAME) != 0)
					continue;
				areas = read_arealist(arealist_path);
				for (Area&amp; area : areas)
					area.path = TEMPORARY_DIRNAME + loc + basename(area.path.c_str());
				write_arealist(arealist_path, areas);
			}
			for (const Area&amp; area : areas)
				cache_arealist(area, all_areas);
			cached_arealist_paths.push_back(arealist_path);
		}

		for (const Area&amp; area : all_areas) {
			if (is_in_area(p.x, p.y, area, margin)) {
				int x_area = static_cast&lt;int&gt;(area.x_max - MARGIN_UNIT);
				int y_area = static_cast&lt;int&gt;(area.y_max - MARGIN_UNIT);
				std::string loc = create_location(x_area, y_area);
				if (is_downloaded(area.path) ||
				    download(gf, TEMPORARY_DIRNAME, loc, basename(area.path.c_str())) == 0) {
					std::unique_lock&lt;std::mutex&gt; lock(downloaded_areas_mtx);
					cache_arealist(area, downloaded_areas);
				}
			}
		}
	}
}

sensor_msgs::PointCloud2 create_pcd(const geometry_msgs::Point&amp; p)
{
	sensor_msgs::PointCloud2 pcd, part;
	std::unique_lock&lt;std::mutex&gt; lock(downloaded_areas_mtx);
	for (const Area&amp; area : downloaded_areas) {
		if (is_in_area(p.x, p.y, area, margin)) {
			if (pcd.width == 0)
				pcl::io::loadPCDFile(area.path.c_str(), pcd);
			else {
				pcl::io::loadPCDFile(area.path.c_str(), part);
				pcd.width += part.width;
				pcd.row_step += part.row_step;
				pcd.data.insert(pcd.data.end(), part.data.begin(), part.data.end());
			}
		}
	}

	return pcd;
}

sensor_msgs::PointCloud2 create_pcd(const std::vector&lt;std::string&gt;&amp; pcd_paths, int* ret_err = NULL)
{
	sensor_msgs::PointCloud2 pcd, part;
	for (const std::string&amp; path : pcd_paths) {
		// Following outputs are used for progress bar of Runtime Manager.
		if (pcd.width == 0) {
			if (pcl::io::loadPCDFile(path.c_str(), pcd) == -1) {
				std::cerr &lt;&lt; &quot;load failed &quot; &lt;&lt; path &lt;&lt; std::endl;
				if (ret_err) *ret_err = 1;
			}
		} else {
			if (pcl::io::loadPCDFile(path.c_str(), part) == -1) {
				std::cerr &lt;&lt; &quot;load failed &quot; &lt;&lt; path &lt;&lt; std::endl;
				if (ret_err) *ret_err = 1;
			}
			pcd.width += part.width;
			pcd.row_step += part.row_step;
			pcd.data.insert(pcd.data.end(), part.data.begin(), part.data.end());
		}
		std::cerr &lt;&lt; &quot;load &quot; &lt;&lt; path &lt;&lt; std::endl;
		if (!ros::ok()) break;
	}

	return pcd;
}

void publish_pcd(sensor_msgs::PointCloud2 pcd, const int* errp = NULL)
{
	if (pcd.width != 0) {
		pcd.header.frame_id = &quot;map&quot;;
		pcd_pub.publish(pcd);

		if (errp == NULL || *errp == 0) {
			stat_msg.data = true;
			stat_pub.publish(stat_msg);
		}
	}
}

void publish_gnss_pcd(const geometry_msgs::PoseStamped&amp; msg)
{
	ros::Time now = ros::Time::now();
	if (((now - current_time).toSec() * 1000) &lt; fallback_rate)
		return;
	if (((now - gnss_time).toSec() * 1000) &lt; update_rate)
		return;
	gnss_time = now;

	if (can_download)
		request_queue.enqueue(msg.pose.position);

	publish_pcd(create_pcd(msg.pose.position));
}

void publish_current_pcd(const geometry_msgs::PoseStamped&amp; msg)
{
	ros::Time now = ros::Time::now();
	if (((now - current_time).toSec() * 1000) &lt; update_rate)
		return;
	current_time = now;

	if (can_download)
		request_queue.enqueue(msg.pose.position);

	publish_pcd(create_pcd(msg.pose.position));
}

void publish_dragged_pcd(const geometry_msgs::PoseWithCovarianceStamped&amp; msg)
{
	tf::TransformListener listener;
	tf::StampedTransform transform;
	try {
		ros::Time zero = ros::Time(0);
		listener.waitForTransform(&quot;map&quot;, &quot;world&quot;, zero, ros::Duration(10));
		listener.lookupTransform(&quot;map&quot;, &quot;world&quot;, zero, transform);
	} catch (tf::TransformException &amp;ex) {
		ROS_ERROR_STREAM(&quot;failed to create transform from &quot; &lt;&lt; ex.what());
	}

	geometry_msgs::Point p;
	p.x = msg.pose.pose.position.x + transform.getOrigin().x();
	p.y = msg.pose.pose.position.y + transform.getOrigin().y();

	if (can_download)
		request_queue.enqueue(p);

	publish_pcd(create_pcd(p));
}

void request_lookahead_download(const waypoint_follower::LaneArray&amp; msg)
{
	request_queue.clear_look_ahead();

	for (const waypoint_follower::lane&amp; l : msg.lanes) {
		size_t end = l.waypoints.size() - 1;
		double distance = 0;
		double threshold = (MARGIN_UNIT / 2) + margin; // XXX better way?
		for (size_t i = 0; i &lt;= end; ++i) {
			if (i == 0 || i == end) {
				geometry_msgs::Point p;
				p.x = l.waypoints[i].pose.pose.position.x;
				p.y = l.waypoints[i].pose.pose.position.y;
				request_queue.enqueue_look_ahead(p);
			} else {
				geometry_msgs::Point p1, p2;
				p1.x = l.waypoints[i].pose.pose.position.x;
				p1.y = l.waypoints[i].pose.pose.position.y;
				p2.x = l.waypoints[i - 1].pose.pose.position.x;
				p2.y = l.waypoints[i - 1].pose.pose.position.y;
				distance += hypot(p2.x - p1.x, p2.y - p1.y);
				if (distance &gt; threshold) {
					request_queue.enqueue_look_ahead(p1);
					distance = 0;
				}
			}
		}
	}
}

void print_usage()
{
	ROS_ERROR_STREAM(&quot;Usage:&quot;);
	ROS_ERROR_STREAM(&quot;rosrun map_file points_map_loader noupdate [PCD]...&quot;);
	ROS_ERROR_STREAM(&quot;rosrun map_file points_map_loader {1x1|3x3|5x5|7x7|9x9} AREALIST [PCD]...&quot;);
	ROS_ERROR_STREAM(&quot;rosrun map_file points_map_loader {1x1|3x3|5x5|7x7|9x9} download&quot;);
}

} // namespace

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;points_map_loader&quot;);

	ros::NodeHandle n;

	if (argc &lt; 3) {
		print_usage();
		return EXIT_FAILURE;
	}

	std::string area(argv[1]);
	if (area == &quot;noupdate&quot;)
		margin = -1;
	else if (area == &quot;1x1&quot;)
		margin = 0;
	else if (area == &quot;3x3&quot;)
		margin = MARGIN_UNIT * 1;
	else if (area == &quot;5x5&quot;)
		margin = MARGIN_UNIT * 2;
	else if (area == &quot;7x7&quot;)
		margin = MARGIN_UNIT * 3;
	else if (area == &quot;9x9&quot;)
		margin = MARGIN_UNIT * 4;
	else {
		print_usage();
		return EXIT_FAILURE;
	}

	std::string arealist_path;
	std::vector&lt;std::string&gt; pcd_paths;
	if (margin &lt; 0) {
		can_download = false;
		for (int i = 2; i &lt; argc; ++i) {
			std::string path(argv[i]);
			pcd_paths.push_back(path);
		}
	} else {
		std::string mode(argv[2]);
		if (mode == &quot;download&quot;) {
			can_download = true;
			std::string host_name;
			n.param&lt;std::string&gt;(&quot;points_map_loader/host_name&quot;, host_name, HTTP_HOSTNAME);
			int port;
			n.param&lt;int&gt;(&quot;points_map_loader/port&quot;, port, HTTP_PORT);
			std::string user;
			n.param&lt;std::string&gt;(&quot;points_map_loader/user&quot;, user, HTTP_USER);
			std::string password;
			n.param&lt;std::string&gt;(&quot;points_map_loader/password&quot;, password, HTTP_PASSWORD);
			gf = GetFile(host_name, port, user, password);
		} else {
			can_download = false;
			arealist_path += argv[2];
			for (int i = 3; i &lt; argc; ++i) {
				std::string path(argv[i]);
				pcd_paths.push_back(path);
			}
		}
	}

	pcd_pub = n.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;points_map&quot;, 1, true);
	stat_pub = n.advertise&lt;std_msgs::Bool&gt;(&quot;pmap_stat&quot;, 1, true);

	stat_msg.data = false;
	stat_pub.publish(stat_msg);

	ros::Subscriber gnss_sub;
	ros::Subscriber current_sub;
	ros::Subscriber initial_sub;
	ros::Subscriber waypoints_sub;
	if (margin &lt; 0) {
		int err = 0;
		publish_pcd(create_pcd(pcd_paths, &amp;err), &amp;err);
	} else {
		n.param&lt;int&gt;(&quot;points_map_loader/update_rate&quot;, update_rate, DEFAULT_UPDATE_RATE);
		fallback_rate = update_rate * 2; // XXX better way?

		gnss_sub = n.subscribe(&quot;gnss_pose&quot;, 1000, publish_gnss_pcd);
		current_sub = n.subscribe(&quot;current_pose&quot;, 1000, publish_current_pcd);
		initial_sub = n.subscribe(&quot;initialpose&quot;, 1, publish_dragged_pcd);

		if (can_download) {
			waypoints_sub = n.subscribe(&quot;traffic_waypoints_array&quot;, 1, request_lookahead_download);
			try {
				std::thread downloader(download_map);
				downloader.detach();
			} catch (std::exception &amp;ex) {
				ROS_ERROR_STREAM(&quot;failed to create thread from &quot; &lt;&lt; ex.what());
			}
		} else {
			AreaList areas = read_arealist(arealist_path);
			for (const Area&amp; area : areas) {
				for (const std::string&amp; path : pcd_paths) {
					if (path == area.path)
						cache_arealist(area, downloaded_areas);
				}
			}
		}

		gnss_time = current_time = ros::Time::now();
	}

	ros::spin();

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/data/packages/pos_db/nodes/pos_uploader/pos_uploader.cpp" new_path="ros/src/data/packages/pos_db/nodes/pos_uploader/pos_uploader.cpp">
				<diff>@@ -48,7 +48,7 @@
 
 
 #include &lt;pos_db.h&gt;
-#include &lt;cv_tracker/obj_label.h&gt;
+#include &lt;cv_tracker_msgs/obj_label.h&gt;
 
 #define MYNAME		&quot;pos_uploader&quot;
 #define OWN_TOPIC_NAME	&quot;current_pose&quot;
@@ -58,8 +58,8 @@
 using namespace std;
 
 //store subscribed value
-static std::vector &lt;cv_tracker::obj_label&gt; car_positions_array;
-static std::vector &lt;cv_tracker::obj_label&gt; person_positions_array;
+static std::vector &lt;cv_tracker_msgs::obj_label&gt; car_positions_array;
+static std::vector &lt;cv_tracker_msgs::obj_label&gt; person_positions_array;
 //flag for comfirming whether updating position or not
 static size_t car_num = 0;
 static size_t person_num = 0;
@@ -156,7 +156,7 @@ static std::string point_to_insert_statement(const geometry_msgs::Point&amp; point,
   return oss.str();
 }
 
-static std::string makeSendDataDetectedObj(const cv_tracker::obj_label&amp; cp_array, const char *name)
+static std::string makeSendDataDetectedObj(const cv_tracker_msgs::obj_label&amp; cp_array, const char *name)
 {
   std::string timestamp;
   if(use_current_time  || cp_array.header.stamp.sec == 0) {
@@ -259,7 +259,7 @@ static void car_locate_cb(const visualization_msgs::MarkerArray&amp; obj_pose_msg)
 {
 	if (obj_pose_msg.markers.size() &gt; 0) {
 		geometry_msgs::Point tmpPoint;
-		cv_tracker::obj_label tmpLabel;
+		cv_tracker_msgs::obj_label tmpLabel;
 
 		pthread_mutex_lock(&amp;pose_lock_);
 
@@ -282,7 +282,7 @@ static void person_locate_cb(const visualization_msgs::MarkerArray &amp;obj_pose_msg
 {
 	if (obj_pose_msg.markers.size() &gt; 0) {
 		geometry_msgs::Point tmpPoint;
-		cv_tracker::obj_label tmpLabel;
+		cv_tracker_msgs::obj_label tmpLabel;
 
 		pthread_mutex_lock(&amp;pose_lock_);
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;cstdio&gt;
#include &lt;time.h&gt;
#include &lt;pthread.h&gt;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;sstream&gt;
#include &lt;sys/time.h&gt;

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/String.h&gt;

#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;geometry_msgs/PoseArray.h&gt;
#include &lt;geometry_msgs/Point.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;


#include &lt;pos_db.h&gt;
#include &lt;cv_tracker/obj_label.h&gt;

#define MYNAME		&quot;pos_uploader&quot;
#define OWN_TOPIC_NAME	&quot;current_pose&quot;
#define CAR_TOPIC_NAME	&quot;obj_car/obj_pose&quot;
#define PERSON_TOPIC_NAME	&quot;obj_person/obj_pose&quot;

using namespace std;

//store subscribed value
static std::vector &lt;cv_tracker::obj_label&gt; car_positions_array;
static std::vector &lt;cv_tracker::obj_label&gt; person_positions_array;
//flag for comfirming whether updating position or not
static size_t car_num = 0;
static size_t person_num = 0;

static int sleep_msec = 250;		// period
static int use_current_time = 0;

static string db_host_name;
static int db_port;
static string sshpubkey;
static string sshprivatekey;
static int ssh_port;
static string sshtunnelhost;

//send to server class
static SendData sd;

//store own position and direction now.updated by position_getter
static std::vector &lt;geometry_msgs::PoseStamped&gt; current_pose_position;
pthread_mutex_t pose_lock_;

static char mac_addr[MAC_ADDRBUFSIZ];

static std::string getTimeStamp(time_t sec, time_t nsec)
{
  char buf[30];
  int msec = static_cast&lt;int&gt;(nsec / (1000 * 1000));

  tm *t = gmtime(&amp;sec);
  sprintf(buf, &quot;%04d-%02d-%02d %02d:%02d:%02d.%03d&quot;,
          t-&gt;tm_year + 1900, t-&gt;tm_mon + 1, t-&gt;tm_mday,
          t-&gt;tm_hour, t-&gt;tm_min, t-&gt;tm_sec, msec);

  return std::string(static_cast&lt;const char*&gt;(buf));
}

static int get_type_from_name(const char *name)
{
  if (strcmp(name, OWN_TOPIC_NAME) == 0) {
    return 1;
  } else if (strcmp(name, CAR_TOPIC_NAME) == 0) {
    return 2;
  } else if (strcmp(name, PERSON_TOPIC_NAME) == 0) {
    return 3;
  } else {
    std::cerr &lt;&lt; &quot;Cannot convert name \&quot;&quot; &lt;&lt; name &lt;&lt; &quot;\&quot; to type&quot; &lt;&lt; std::endl;
    return 0;
  }
}

static std::string pose_to_insert_statement(const geometry_msgs::Pose&amp; pose, const std::string&amp; timestamp, const char *name)
{
  std::ostringstream oss;
  constexpr int AREA = 7;

  oss &lt;&lt; &quot;INSERT INTO POS(id,x,y,z,area,or_x,or_y,or_z,or_w,type,tm) &quot;
      &lt;&lt; &quot;VALUES(&quot;
      &lt;&lt; &quot;'&quot; &lt;&lt; mac_addr &lt;&lt; &quot;',&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; pose.position.y &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; pose.position.x &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; pose.position.z &lt;&lt; &quot;,&quot;
      &lt;&lt; AREA &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; pose.orientation.y &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; pose.orientation.x &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; pose.orientation.z &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; pose.orientation.w &lt;&lt; &quot;,&quot;
      &lt;&lt; get_type_from_name(name) &lt;&lt; &quot;,&quot;
      &lt;&lt; &quot;'&quot; &lt;&lt; timestamp &lt;&lt; &quot;'&quot;
      &lt;&lt; &quot;);&quot;;

  return oss.str();
}

static std::string point_to_insert_statement(const geometry_msgs::Point&amp; point, const std::string&amp; timestamp, const char *name)
{
  std::ostringstream oss;
  constexpr int AREA = 7;

  oss &lt;&lt; &quot;INSERT INTO POS(id,x,y,z,area,or_x,or_y,or_z,or_w,type,tm) &quot;
      &lt;&lt; &quot;VALUES(&quot;
      &lt;&lt; &quot;'&quot; &lt;&lt; mac_addr &lt;&lt; &quot;',&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; point.y &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; point.x &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; point.z &lt;&lt; &quot;,&quot;
      &lt;&lt; AREA &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; 0 &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; 0 &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; 0 &lt;&lt; &quot;,&quot;
      &lt;&lt; std::fixed &lt;&lt; std::setprecision(6) &lt;&lt; 0 &lt;&lt; &quot;,&quot;
      &lt;&lt; get_type_from_name(name) &lt;&lt; &quot;,&quot;
      &lt;&lt; &quot;'&quot; &lt;&lt; timestamp &lt;&lt; &quot;'&quot;
      &lt;&lt; &quot;);&quot;;

  return oss.str();
}

static std::string makeSendDataDetectedObj(const cv_tracker::obj_label&amp; cp_array, const char *name)
{
  std::string timestamp;
  if(use_current_time  || cp_array.header.stamp.sec == 0) {
    ros::Time t = ros::Time::now();
    timestamp = getTimeStamp(t.sec, t.nsec);
  } else {
    timestamp = getTimeStamp(cp_array.header.stamp.sec, cp_array.header.stamp.nsec);
  }

  std::string ret;
  for (const auto&amp; point : cp_array.reprojected_pos) {
    //create sql
    ret += point_to_insert_statement(point, timestamp, name);
    ret += &quot;\n&quot;;
  }

  return ret;
}

//wrap SendData class
static void send_sql()
{
  int sql_num = car_num + person_num + current_pose_position.size();
  std::cout &lt;&lt; &quot;sqlnum : &quot; &lt;&lt; sql_num &lt;&lt; std::endl;

  //create header
  std::string value = make_header(2, sql_num);

  std::cout &lt;&lt; &quot;current_num=&quot; &lt;&lt; current_pose_position.size()
    &lt;&lt; &quot;, car_num=&quot; &lt;&lt; car_num &lt;&lt; &quot;(&quot; &lt;&lt; car_positions_array.size() &lt;&lt; &quot;)&quot;
    &lt;&lt; &quot;,person_num=&quot; &lt;&lt; person_num &lt;&lt; &quot;(&quot; &lt;&lt; person_positions_array.size() &lt;&lt; &quot;)&quot;
    &lt;&lt; std::endl;

  //get data of car and person recognizing
  pthread_mutex_lock(&amp;pose_lock_);
  if(car_positions_array.size() &gt; 0){
    for(size_t i = 0; i &lt; car_positions_array.size(); i++) {
      value += makeSendDataDetectedObj(car_positions_array[i], CAR_TOPIC_NAME);
    }
  }
  car_positions_array.clear();
  car_num = 0;

  if(person_positions_array.size() &gt; 0){
    for(size_t i = 0; i &lt; person_positions_array.size(); i++) {
      value += makeSendDataDetectedObj(person_positions_array[i], PERSON_TOPIC_NAME);
    }
  }
  person_positions_array.clear();
  person_num = 0;


  // my_location
  for(size_t i = 0; i &lt; current_pose_position.size(); i++) {
    std::string timestamp;
    timestamp = getTimeStamp(current_pose_position[i].header.stamp.sec,current_pose_position[i].header.stamp.nsec);
    value += pose_to_insert_statement(current_pose_position[i].pose, timestamp, OWN_TOPIC_NAME);
    value += &quot;\n&quot;;
  }
  current_pose_position.clear();
  pthread_mutex_unlock(&amp;pose_lock_);

#ifdef POS_DB_VERBOSE
  std::cout &lt;&lt; &quot;val=&quot; &lt;&lt; value.substr(POS_DB_HEAD_LEN) &lt;&lt; std::endl;
#endif /* POS_DB_VERBOSE */

  std::string res;
  int ret = sd.Sender(value, res, sql_num);
  if (ret &lt; 0) {
    std::cerr &lt;&lt; &quot;Failed: sd.Sender&quot; &lt;&lt; std::endl;
    return;
  }

#ifdef POS_DB_VERBOSE
  std::cout &lt;&lt; &quot;retrun message from DBserver : &quot; &lt;&lt; res &lt;&lt; std::endl;
#endif /* POS_DB_VERBOSE */

  return;
}

static void* intervalCall(void *unused)
{
  while(1){
    //If angle and position data is not updated from previous data send,
    //data is not sent
    if((car_num + person_num + current_pose_position.size()) &lt;= 0) {
      usleep(sleep_msec*1000);
      continue;
    }

    send_sql();
    usleep(sleep_msec*1000);
  }

  return nullptr;
}


static void car_locate_cb(const visualization_msgs::MarkerArray&amp; obj_pose_msg)
{
	if (obj_pose_msg.markers.size() &gt; 0) {
		geometry_msgs::Point tmpPoint;
		cv_tracker::obj_label tmpLabel;

		pthread_mutex_lock(&amp;pose_lock_);

		for (visualization_msgs::Marker tmpMarker : obj_pose_msg.markers) {
			tmpPoint.x = tmpMarker.pose.position.x;
			tmpPoint.y = tmpMarker.pose.position.y;
			tmpPoint.z = tmpMarker.pose.position.z;

			tmpLabel.reprojected_pos.push_back(tmpPoint);
		}

		car_positions_array.push_back(tmpLabel);
		car_num += obj_pose_msg.markers.size();

		pthread_mutex_unlock(&amp;pose_lock_);
	}
}

static void person_locate_cb(const visualization_msgs::MarkerArray &amp;obj_pose_msg)
{
	if (obj_pose_msg.markers.size() &gt; 0) {
		geometry_msgs::Point tmpPoint;
		cv_tracker::obj_label tmpLabel;

		pthread_mutex_lock(&amp;pose_lock_);

		for (visualization_msgs::Marker tmpMarker : obj_pose_msg.markers) {
			tmpPoint.x = tmpMarker.pose.position.x;
			tmpPoint.y = tmpMarker.pose.position.y;
			tmpPoint.z = tmpMarker.pose.position.z;

			tmpLabel.reprojected_pos.push_back(tmpPoint);
		}

		person_positions_array.push_back(tmpLabel);
		person_num += obj_pose_msg.markers.size();

		pthread_mutex_unlock(&amp;pose_lock_);
	}
}

static void current_pose_cb(const geometry_msgs::PoseStamped &amp;pose)
{
  pthread_mutex_lock(&amp;pose_lock_);
  if(use_current_time) {
    geometry_msgs::PoseStamped n = pose;
    ros::Time t = ros::Time::now();
    n.header.stamp = t;
    current_pose_position.push_back(n);
  } else {
    current_pose_position.push_back(pose);
  }
  pthread_mutex_unlock(&amp;pose_lock_);
}

int main(int argc, char **argv)
{
  ros::init(argc ,argv, MYNAME);
  std::cout &lt;&lt; MYNAME &lt;&lt; std::endl;

  if(argc &lt; 2) {
    std::cerr &lt;&lt; &quot;usage : \n\trosrun &quot; &lt;&lt; MYNAME &lt;&lt; &quot; &lt;user name&gt; [now]&quot; &lt;&lt; std::endl;
    return -1;
  }
  if(argc &gt; 2) {
    if(strncmp(argv[2], &quot;now&quot;, 3) == 0) use_current_time = 1;
  }
  std::cerr &lt;&lt; &quot;use_current_time=&quot; &lt;&lt; use_current_time &lt;&lt; std::endl;

  pose_lock_ = PTHREAD_MUTEX_INITIALIZER;

  probe_mac_addr(mac_addr);
  std::cerr &lt;&lt;  &quot;mac_addr=&quot; &lt;&lt; mac_addr &lt;&lt; std::endl;

  /**
   * NodeHandle is the main access point to communications with the ROS system.
   * The first NodeHandle constructed will fully initialize this node, and the last
   * NodeHandle destructed will close down the node.
   */
  ros::NodeHandle nh;

  ros::Subscriber car_locate = nh.subscribe(&quot;/&quot; CAR_TOPIC_NAME, 1, car_locate_cb);
  ros::Subscriber person_locate = nh.subscribe(&quot;/&quot; PERSON_TOPIC_NAME, 1, person_locate_cb);
  ros::Subscriber gnss_pose = nh.subscribe(&quot;/&quot; OWN_TOPIC_NAME, 1, current_pose_cb);

  string home_dir = getenv(&quot;HOME&quot;);

  nh.param&lt;string&gt;(&quot;pos_db/db_host_name&quot;, db_host_name, DB_HOSTNAME);
  cout &lt;&lt; &quot;db_host_name=&quot; &lt;&lt; db_host_name &lt;&lt; endl;
  nh.param&lt;int&gt;(&quot;pos_db/db_port&quot;, db_port, DB_PORT);
  cout &lt;&lt; &quot;db_port=&quot; &lt;&lt; db_port &lt;&lt; endl;
  nh.param&lt;string&gt;(&quot;pos_db/sshpubkey&quot;, sshpubkey, home_dir+SSHPUBKEY);
  cout &lt;&lt; &quot;sshpubkey=&quot; &lt;&lt; sshpubkey &lt;&lt; endl;
  nh.param&lt;string&gt;(&quot;pos_db/sshprivatekey&quot;, sshprivatekey, home_dir+SSHPRIVATEKEY);
  cout &lt;&lt; &quot;sshprivatekey=&quot; &lt;&lt; sshprivatekey &lt;&lt; endl;
  nh.param&lt;int&gt;(&quot;pos_db/ssh_port&quot;, ssh_port, SSHPORT);
  cout &lt;&lt; &quot;ssh_port=&quot; &lt;&lt; ssh_port &lt;&lt; endl;
  nh.param&lt;string&gt;(&quot;pos_db/sshtunnelhost&quot;, sshtunnelhost, SSHTUNNELHOST);
  cout &lt;&lt; &quot;sshtunnelhost=&quot; &lt;&lt; sshtunnelhost &lt;&lt; endl;

  //set server name and port
  sd = SendData(db_host_name, db_port, argv[1], sshpubkey, sshprivatekey, ssh_port, sshtunnelhost);

  pthread_t th;
  if(pthread_create(&amp;th, nullptr, intervalCall, nullptr)){
    printf(&quot;thread create error\n&quot;);
  }
  pthread_detach(th);

  ros::spin();
  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/data/packages/vector_map_server/nodes/vector_map_client/vector_map_client.cpp" new_path="ros/src/data/packages/vector_map_server/nodes/vector_map_client/vector_map_client.cpp">
				<diff>@@ -29,7 +29,7 @@
 */
 
 #include &lt;geometry_msgs/PoseStamped.h&gt;
-#include &lt;waypoint_follower/lane.h&gt;
+#include &lt;waypoint_follower_msgs/lane.h&gt;
 #include &lt;visualization_msgs/MarkerArray.h&gt;
 #include &lt;vector_map/vector_map.h&gt;
 
@@ -61,7 +61,7 @@ class VectorMapClient
 {
 private:
   geometry_msgs::PoseStamped pose_;
-  waypoint_follower::lane waypoints_;
+  waypoint_follower_msgs::lane waypoints_;
 
 public:
   VectorMapClient()
@@ -73,7 +73,7 @@ public:
     return pose_;
   }
 
-  waypoint_follower::lane getWaypoints() const
+  waypoint_follower_msgs::lane getWaypoints() const
   {
     return waypoints_;
   }
@@ -83,7 +83,7 @@ public:
     pose_ = pose;
   }
 
-  void setWaypoints(const waypoint_follower::lane&amp; waypoints)
+  void setWaypoints(const waypoint_follower_msgs::lane&amp; waypoints)
   {
     waypoints_ = waypoints;
   }
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;waypoint_follower/lane.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;vector_map/vector_map.h&gt;

#include &lt;vector_map_server/GetWhiteLine.h&gt;
#include &lt;vector_map_server/GetStopLine.h&gt;
#include &lt;vector_map_server/GetCrossWalk.h&gt;
#include &lt;vector_map_server/GetSignal.h&gt;

using vector_map::VectorMap;
using vector_map::Category;
using vector_map::Color;
using vector_map::Key;

using vector_map::Vector;
using vector_map::Line;
using vector_map::Area;
using vector_map::Pole;
using vector_map::Signal;

using vector_map::isValidMarker;
using vector_map::createVectorMarker;
using vector_map::createLineMarker;
using vector_map::createAreaMarker;
using vector_map::createPoleMarker;

namespace
{
class VectorMapClient
{
private:
  geometry_msgs::PoseStamped pose_;
  waypoint_follower::lane waypoints_;

public:
  VectorMapClient()
  {
  }

  geometry_msgs::PoseStamped getPose() const
  {
    return pose_;
  }

  waypoint_follower::lane getWaypoints() const
  {
    return waypoints_;
  }

  void setPose(const geometry_msgs::PoseStamped&amp; pose)
  {
    pose_ = pose;
  }

  void setWaypoints(const waypoint_follower::lane&amp; waypoints)
  {
    waypoints_ = waypoints;
  }
};
} // namespace

int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;vector_map_client&quot;);

  ros::NodeHandle nh;
  VectorMapClient vmc;

  ros::Publisher marker_array_pub = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;vector_map_client&quot;, 10, true);

  VectorMap vmap;
  vmap.subscribe(nh,
                 Category::POINT | Category::VECTOR | Category::LINE | Category::AREA | Category::POLE |
                 Category::WHITE_LINE | Category::STOP_LINE | Category::CROSS_WALK | Category::SIGNAL,
                 ros::Duration(0)); // non-blocking

  ros::Subscriber pose_sub = nh.subscribe(&quot;current_pose&quot;, 1, &amp;VectorMapClient::setPose, &amp;vmc);
  ros::Subscriber waypoints_sub = nh.subscribe(&quot;final_waypoints&quot;, 1, &amp;VectorMapClient::setWaypoints, &amp;vmc);

  visualization_msgs::MarkerArray marker_array;
  ros::ServiceClient white_line_cli =
    nh.serviceClient&lt;vector_map_server::GetWhiteLine&gt;(&quot;vector_map_server/get_white_line&quot;);
  ros::ServiceClient stop_line_cli =
    nh.serviceClient&lt;vector_map_server::GetStopLine&gt;(&quot;vector_map_server/get_stop_line&quot;);
  ros::ServiceClient cross_walk_cli =
    nh.serviceClient&lt;vector_map_server::GetCrossWalk&gt;(&quot;vector_map_server/get_cross_walk&quot;);
  ros::ServiceClient signal_cli =
    nh.serviceClient&lt;vector_map_server::GetSignal&gt;(&quot;vector_map_server/get_signal&quot;);
  ros::Rate rate(1);
  while (ros::ok())
  {
    ros::spinOnce();

    visualization_msgs::MarkerArray marker_array_buffer;
    int id = 0;

    vector_map_server::GetWhiteLine white_line_srv;
    white_line_srv.request.pose = vmc.getPose();
    white_line_srv.request.waypoints = vmc.getWaypoints();
    if (white_line_cli.call(white_line_srv))
    {
      for (const auto&amp; white_line : white_line_srv.response.objects.data)
      {
        if (white_line.lid == 0)
          continue;

        Line line = vmap.findByKey(Key&lt;Line&gt;(white_line.lid));
        if (line.lid == 0)
          continue;

        visualization_msgs::Marker marker = createLineMarker(&quot;white_line&quot;, id++, Color::GREEN, vmap, line);
        if (isValidMarker(marker))
        {
          marker.scale.x = 0.4;
          marker.color.a = 0.4;
          marker_array_buffer.markers.push_back(marker);
        }
      }
    }

    vector_map_server::GetStopLine stop_line_srv;
    stop_line_srv.request.pose = vmc.getPose();
    stop_line_srv.request.waypoints = vmc.getWaypoints();
    if (stop_line_cli.call(stop_line_srv))
    {
      for (const auto&amp; stop_line : stop_line_srv.response.objects.data)
      {
        if (stop_line.lid == 0)
          continue;

        Line line = vmap.findByKey(Key&lt;Line&gt;(stop_line.lid));
        if (line.lid == 0)
          continue;

        visualization_msgs::Marker marker = createLineMarker(&quot;stop_line&quot;, id++, Color::RED, vmap, line);
        if (isValidMarker(marker))
        {
          marker.scale.x = 0.4;
          marker.color.a = 0.4;
          marker_array_buffer.markers.push_back(marker);
        }
      }
    }

    vector_map_server::GetCrossWalk cross_walk_srv;
    cross_walk_srv.request.pose = vmc.getPose();
    cross_walk_srv.request.waypoints = vmc.getWaypoints();
    if (cross_walk_cli.call(cross_walk_srv))
    {
      for (const auto&amp; cross_walk : cross_walk_srv.response.objects.data)
      {
        if (cross_walk.aid == 0)
          continue;

        Area area = vmap.findByKey(Key&lt;Area&gt;(cross_walk.aid));
        if (area.aid == 0)
          continue;

        visualization_msgs::Marker marker = createAreaMarker(&quot;cross_walk&quot;, id++, Color::BLUE, vmap, area);
        if (isValidMarker(marker))
        {
          marker.scale.x = 0.4;
          marker.color.a = 0.4;
          marker_array_buffer.markers.push_back(marker);
        }
      }
    }

    vector_map_server::GetSignal signal_srv;
    signal_srv.request.pose = vmc.getPose();
    signal_srv.request.waypoints = vmc.getWaypoints();
    if (signal_cli.call(signal_srv))
    {
      for (const auto&amp; signal : signal_srv.response.objects.data)
      {
        if (signal.vid == 0)
          continue;

        Vector vector = vmap.findByKey(Key&lt;Vector&gt;(signal.vid));
        if (vector.vid == 0)
          continue;

        Pole pole;
        if (signal.plid != 0)
        {
          pole = vmap.findByKey(Key&lt;Pole&gt;(signal.plid));
          if (pole.plid == 0)
            continue;
        }

        visualization_msgs::Marker vector_marker;
        switch (signal.type)
        {
        case Signal::RED:
        case Signal::PEDESTRIAN_RED:
          vector_marker = createVectorMarker(&quot;signal&quot;, id++, Color::RED, vmap, vector);
          break;
        case Signal::BLUE:
        case Signal::PEDESTRIAN_BLUE:
          vector_marker = createVectorMarker(&quot;signal&quot;, id++, Color::BLUE, vmap, vector);
          break;
        case Signal::YELLOW:
          vector_marker = createVectorMarker(&quot;signal&quot;, id++, Color::YELLOW, vmap, vector);
          break;
        case Signal::OTHER:
          vector_marker = createVectorMarker(&quot;signal&quot;, id++, Color::CYAN, vmap, vector);
          break;
        default:
          continue;
        }
        if (isValidMarker(vector_marker))
        {
          vector_marker.type = visualization_msgs::Marker::CUBE;
          vector_marker.scale.x = 0.4;
          vector_marker.scale.y = 0.4;
          vector_marker.scale.z = 0.4;
          vector_marker.color.a = 0.4;
          marker_array_buffer.markers.push_back(vector_marker);
        }

        if (signal.plid != 0)
        {
          visualization_msgs::Marker pole_marker = createPoleMarker(&quot;signal&quot;, id++, Color::MAGENTA, vmap, pole);
          if (isValidMarker(pole_marker))
          {
            pole_marker.type = visualization_msgs::Marker::CUBE;
            pole_marker.scale.x += 0.4;
            pole_marker.scale.y += 0.4;
            pole_marker.color.a = 0.4;
            marker_array_buffer.markers.push_back(pole_marker);
          }
        }
      }
    }

    if (!marker_array.markers.empty())
    {
      for (auto&amp; marker : marker_array.markers)
        marker.action = visualization_msgs::Marker::DELETE;
      marker_array_pub.publish(marker_array); // clear previous marker
    }
    marker_array = marker_array_buffer;
    marker_array_pub.publish(marker_array);

    rate.sleep();
  }

  return EXIT_SUCCESS;
}
</old_file>
			</file>
			<file old_path="ros/src/data/packages/vector_map_server/nodes/vector_map_server/vector_map_server.cpp" new_path="ros/src/data/packages/vector_map_server/nodes/vector_map_server/vector_map_server.cpp">
				<diff>@@ -29,7 +29,7 @@
 */
 
 #include &lt;geometry_msgs/PoseStamped.h&gt;
-#include &lt;waypoint_follower/lane.h&gt;
+#include &lt;waypoint_follower_msgs/lane.h&gt;
 #include &lt;visualization_msgs/MarkerArray.h&gt;
 #include &lt;vector_map/vector_map.h&gt;
 
@@ -345,7 +345,7 @@ std::vector&lt;Lane&gt; findNearLanes(const VectorMap&amp; vmap, const std::vector&lt;Lane&gt;&amp;
   return near_lanes;
 }
 
-std::vector&lt;Lane&gt; createFineLanes(const VectorMap&amp; vmap, const waypoint_follower::lane&amp; waypoints, double radius,
+std::vector&lt;Lane&gt; createFineLanes(const VectorMap&amp; vmap, const waypoint_follower_msgs::lane&amp; waypoints, double radius,
                                   int loops)
 {
   std::vector&lt;Lane&gt; null_lanes;
@@ -532,7 +532,7 @@ private:
   ros::Publisher marker_array_pub_;
 
   std::vector&lt;Lane&gt; createTravelingRoute(const geometry_msgs::PoseStamped&amp; pose,
-                                         const waypoint_follower::lane&amp; waypoints)
+                                         const waypoint_follower_msgs::lane&amp; waypoints)
   {
     std::vector&lt;Lane&gt; null_lanes;
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;waypoint_follower/lane.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;vector_map/vector_map.h&gt;

#include &lt;vector_map_server/GetDTLane.h&gt;
#include &lt;vector_map_server/GetNode.h&gt;
#include &lt;vector_map_server/GetLane.h&gt;
#include &lt;vector_map_server/GetWayArea.h&gt;
#include &lt;vector_map_server/GetRoadEdge.h&gt;
#include &lt;vector_map_server/GetGutter.h&gt;
#include &lt;vector_map_server/GetCurb.h&gt;
#include &lt;vector_map_server/GetWhiteLine.h&gt;
#include &lt;vector_map_server/GetStopLine.h&gt;
#include &lt;vector_map_server/GetZebraZone.h&gt;
#include &lt;vector_map_server/GetCrossWalk.h&gt;
#include &lt;vector_map_server/GetRoadMark.h&gt;
#include &lt;vector_map_server/GetRoadPole.h&gt;
#include &lt;vector_map_server/GetRoadSign.h&gt;
#include &lt;vector_map_server/GetSignal.h&gt;
#include &lt;vector_map_server/GetStreetLight.h&gt;
#include &lt;vector_map_server/GetUtilityPole.h&gt;
#include &lt;vector_map_server/GetGuardRail.h&gt;
#include &lt;vector_map_server/GetSideWalk.h&gt;
#include &lt;vector_map_server/GetDriveOnPortion.h&gt;
#include &lt;vector_map_server/GetCrossRoad.h&gt;
#include &lt;vector_map_server/GetSideStrip.h&gt;
#include &lt;vector_map_server/GetCurveMirror.h&gt;
#include &lt;vector_map_server/GetWall.h&gt;
#include &lt;vector_map_server/GetFence.h&gt;
#include &lt;vector_map_server/GetRailCrossing.h&gt;
#include &lt;vector_map_server/PositionState.h&gt;

using vector_map::VectorMap;
using vector_map::Category;
using vector_map::Color;
using vector_map::Filter;
using vector_map::Key;

using vector_map::Point;
using vector_map::Vector;
using vector_map::Line;
using vector_map::Area;
using vector_map::Pole;
using vector_map::Box;
using vector_map::DTLane;
using vector_map::Node;
using vector_map::Lane;
using vector_map::WayArea;
using vector_map::RoadEdge;
using vector_map::Gutter;
using vector_map::Curb;
using vector_map::WhiteLine;
using vector_map::StopLine;
using vector_map::ZebraZone;
using vector_map::CrossWalk;
using vector_map::RoadMark;
using vector_map::RoadPole;
using vector_map::RoadSign;
using vector_map::Signal;
using vector_map::StreetLight;
using vector_map::UtilityPole;
using vector_map::GuardRail;
using vector_map::SideWalk;
using vector_map::DriveOnPortion;
using vector_map::CrossRoad;
using vector_map::SideStrip;
using vector_map::CurveMirror;
using vector_map::Wall;
using vector_map::Fence;
using vector_map::RailCrossing;

using vector_map::isValidMarker;
using vector_map::convertPointToGeomPoint;
using vector_map::convertGeomPointToPoint;

using Polygon = std::vector&lt;geometry_msgs::Point&gt;;

namespace
{
bool isBranchingLane(const Lane&amp; lane)
{
  return lane.jct == Lane::LEFT_BRANCHING || lane.jct == Lane::RIGHT_BRANCHING || lane.jct == Lane::COMPOSITION;
}

bool isMergingLane(const Lane&amp; lane)
{
  return lane.jct == Lane::LEFT_MERGING || lane.jct == Lane::RIGHT_MERGING || lane.jct == Lane::COMPOSITION;
}

double computeDistance(const Point&amp; p1, const Point&amp; p2)
{
  return std::hypot(p2.bx - p1.bx, p2.ly - p1.ly); // XXX: don't consider z axis
}

double computeAngle(const Point&amp; p1, const Point&amp; p2)
{
  return std::atan2(p2.ly - p1.ly, p2.bx - p1.bx); // XXX: don't consider z axis
}

double computeScore(const Point&amp; bp1, const Point&amp; bp2, const Point&amp; p1, const Point&amp; p2, double radius)
{
  double distance_score = computeDistance(bp1, p1);
  distance_score = 50 * (radius - distance_score) / radius;
  double angle_score = computeAngle(p1, p2) - computeAngle(bp1, bp2);
  angle_score = 50 * (M_PI - std::fabs(angle_score)) / M_PI;
  return distance_score + angle_score;
}

Point findStartPoint(const VectorMap&amp; vmap, const Lane&amp; lane)
{
  Point start_point;
  Node node = vmap.findByKey(Key&lt;Node&gt;(lane.bnid));
  if (node.nid == 0)
    return start_point;
  return vmap.findByKey(Key&lt;Point&gt;(node.pid));
}

Point findEndPoint(const VectorMap&amp; vmap, const Lane&amp; lane)
{
  Point end_point;
  Node node = vmap.findByKey(Key&lt;Node&gt;(lane.fnid));
  if (node.nid == 0)
    return end_point;
  return vmap.findByKey(Key&lt;Point&gt;(node.pid));
}

Point createMedianPoint(const Point&amp; p1, const Point&amp; p2)
{
  Point point;
  point.bx = (p1.bx + p2.bx) / 2;
  point.ly = (p1.ly + p2.ly) / 2;
  point.h = (p1.h + p2.h) / 2;
  return point;
}

std::vector&lt;Point&gt; findStartPoints(const VectorMap&amp; vmap)
{
  std::vector&lt;Point&gt; start_points;
  for (const auto&amp; lane : vmap.findByFilter([](const Lane&amp; lane){return true;}))
  {
    Node node = vmap.findByKey(Key&lt;Node&gt;(lane.bnid));
    if (node.nid == 0)
      continue;
    Point point = vmap.findByKey(Key&lt;Point&gt;(node.pid));
    if (point.pid == 0)
      continue;
    start_points.push_back(point);
  }
  return start_points;
}

std::vector&lt;Point&gt; findEndPoints(const VectorMap&amp; vmap)
{
  std::vector&lt;Point&gt; end_points;
  for (const auto&amp; lane : vmap.findByFilter([](const Lane&amp; lane){return true;}))
  {
    Node node = vmap.findByKey(Key&lt;Node&gt;(lane.fnid));
    if (node.nid == 0)
      continue;
    Point point = vmap.findByKey(Key&lt;Point&gt;(node.pid));
    if (point.pid == 0)
      continue;
    end_points.push_back(point);
  }
  return end_points;
}

Point findNearestPoint(const std::vector&lt;Point&gt;&amp; points, const Point&amp; base_point)
{
  Point nearest_point;
  double min_distance = DBL_MAX;
  for (const auto&amp; point : points)
  {
    double distance = computeDistance(base_point, point);
    if (distance &lt;= min_distance)
    {
      nearest_point = point;
      min_distance = distance;
    }
  }
  return nearest_point;
}

std::vector&lt;Point&gt; findNearPoints(const std::vector&lt;Point&gt;&amp; points, const Point&amp; base_point, double radius)
{
  std::vector&lt;Point&gt; near_points;
  for (const auto&amp; point : points)
  {
    if (computeDistance(base_point, point) &lt;= radius)
      near_points.push_back(point);
  }
  return near_points;
}

std::vector&lt;Lane&gt; findLanesByStartPoint(const VectorMap&amp; vmap, const Point&amp; start_point)
{
  std::vector&lt;Lane&gt; lanes;
  for (const auto&amp; node : vmap.findByFilter([&amp;start_point](const Node&amp; node){return node.pid == start_point.pid;}))
  {
    for (const auto&amp; lane : vmap.findByFilter([&amp;node](const Lane&amp; lane){return lane.bnid == node.nid;}))
      lanes.push_back(lane);
  }
  return lanes;
}

std::vector&lt;Lane&gt; findLanesByEndPoint(const VectorMap&amp; vmap, const Point&amp; end_point)
{
  std::vector&lt;Lane&gt; lanes;
  for (const auto&amp; node : vmap.findByFilter([&amp;end_point](const Node&amp; node){return node.pid == end_point.pid;}))
  {
    for (const auto&amp; lane : vmap.findByFilter([&amp;node](const Lane&amp; lane){return lane.fnid == node.nid;}))
      lanes.push_back(lane);
  }
  return lanes;
}

Lane findStartLane(const VectorMap&amp; vmap, const std::vector&lt;Point&gt;&amp; points, double radius)
{
  Lane start_lane;
  if (points.size() &lt; 2)
    return start_lane;

  Point bp1 = points[0];
  Point bp2 = points[1];
  double max_score = -DBL_MAX;
  for (const auto&amp; p1 : findNearPoints(findStartPoints(vmap), bp1, radius))
  {
    for (const auto&amp; lane : findLanesByStartPoint(vmap, p1))
    {
      if (lane.lnid == 0)
        continue;
      Point p2 = findEndPoint(vmap, lane);
      if (p2.pid == 0)
        continue;
      double score = computeScore(bp1, bp2, p1, p2, radius);
      if (score &gt;= max_score)
      {
        start_lane = lane;
        max_score = score;
      }
    }
  }
  return start_lane;
}

Lane findEndLane(const VectorMap&amp; vmap, const std::vector&lt;Point&gt;&amp; points, double radius)
{
  Lane end_lane;
  if (points.size() &lt; 2)
    return end_lane;

  Point bp1 = points[points.size() - 2];
  Point bp2 = points[points.size() - 1];
  double max_score = -DBL_MAX;
  for (const auto&amp; p2 : findNearPoints(findEndPoints(vmap), bp2, radius))
  {
    for (const auto&amp; lane : findLanesByEndPoint(vmap, p2))
    {
      if (lane.lnid == 0)
        continue;
      Point p1 = findStartPoint(vmap, lane);
      if (p1.pid == 0)
        continue;
      double score = computeScore(bp2, bp1, p2, p1, radius);
      if (score &gt;= max_score)
      {
        end_lane = lane;
        max_score = score;
      }
    }
  }
  return end_lane;
}

Lane findNearestLane(const VectorMap&amp; vmap, const std::vector&lt;Lane&gt;&amp; lanes, const Point&amp; base_point)
{
  Lane nearest_lane;
  double min_distance = DBL_MAX;
  for (const auto&amp; lane : lanes)
  {
    Point start_point = findStartPoint(vmap, lane);
    if (start_point.pid == 0)
      continue;
    Point end_point = findEndPoint(vmap, lane);
    if (end_point.pid == 0)
      continue;
    Point median_point = createMedianPoint(start_point, end_point);
    double distance = computeDistance(base_point, median_point);
    if (distance &lt;= min_distance)
    {
      nearest_lane = lane;
      min_distance = distance;
    }
  }
  return nearest_lane;
}

std::vector&lt;Lane&gt; findNearLanes(const VectorMap&amp; vmap, const std::vector&lt;Lane&gt;&amp; lanes, const Point&amp; base_point,
                                double radius)
{
  std::vector&lt;Lane&gt; near_lanes;
  for (const auto&amp; lane : lanes)
  {
    Point start_point = findStartPoint(vmap, lane);
    if (start_point.pid == 0)
      continue;
    Point end_point = findEndPoint(vmap, lane);
    if (end_point.pid == 0)
      continue;
    Point median_point = createMedianPoint(start_point, end_point);
    if (computeDistance(base_point, median_point) &lt;= radius)
      near_lanes.push_back(lane);
  }
  return near_lanes;
}

std::vector&lt;Lane&gt; createFineLanes(const VectorMap&amp; vmap, const waypoint_follower::lane&amp; waypoints, double radius,
                                  int loops)
{
  std::vector&lt;Lane&gt; null_lanes;

  std::vector&lt;Point&gt; coarse_points;
  for (const auto&amp; waypoint : waypoints.waypoints)
    coarse_points.push_back(convertGeomPointToPoint(waypoint.pose.pose.position));

  Lane start_lane = findStartLane(vmap, coarse_points, radius);
  if (start_lane.lnid == 0)
    return null_lanes;

  Lane end_lane = findEndLane(vmap, coarse_points, radius);
  if (end_lane.lnid == 0)
    return null_lanes;

  std::vector&lt;Lane&gt; fine_lanes;
  Lane current_lane = start_lane;
  for (int i = 0; i &lt; loops; ++i)
  {
    fine_lanes.push_back(current_lane);
    if (current_lane.lnid == end_lane.lnid)
      return fine_lanes;

    if (isBranchingLane(current_lane))
    {
      Point fine_p1 = findEndPoint(vmap, current_lane);
      if (fine_p1.pid == 0)
        return null_lanes;

      Point coarse_p1 = findNearestPoint(coarse_points, fine_p1); // certainly succeed

      if (computeDistance(fine_p1, coarse_p1) &gt; radius)
        return null_lanes;

      Point coarse_p2;
      double distance = -DBL_MAX;
      for (const auto&amp; coarse_point : coarse_points)
      {
        if (distance == -DBL_MAX)
        {
          if (coarse_point.bx == coarse_p1.bx &amp;&amp; coarse_point.ly == coarse_p1.ly) // XXX: don't consider z axis
            distance = 0;
          continue;
        }
        coarse_p2 = coarse_point;
        distance = computeDistance(coarse_p2, coarse_p1);
        if (distance &gt; radius)
          break;
      }
      if (distance &lt;= 0)
        return null_lanes;

      double max_score = -DBL_MAX;
      Filter&lt;Lane&gt; is_next_lane = [&amp;current_lane](const Lane&amp; lane)
        {
          return lane.lnid == current_lane.flid || lane.lnid == current_lane.flid2 ||
                 lane.lnid == current_lane.flid3 || lane.lnid == current_lane.flid4;
        };
      for (const auto&amp; lane : vmap.findByFilter(is_next_lane))
      {
        Lane next_lane = lane;
        Point next_point = findEndPoint(vmap, next_lane);
        if (next_point.pid == 0)
          continue;
        Point fine_p2 = next_point;
        while (computeDistance(fine_p2, fine_p1) &lt;= radius &amp;&amp; !isBranchingLane(next_lane) &amp;&amp; next_lane.flid != 0)
        {
          next_lane = vmap.findByKey(Key&lt;Lane&gt;(next_lane.flid));;
          if (next_lane.lnid == 0)
            break;
          next_point = findEndPoint(vmap, next_lane);
          if (next_point.pid == 0)
            break;
          fine_p2 = next_point;
        }
        double score = computeScore(fine_p1, fine_p2, coarse_p1, coarse_p2, radius);
        if (score &gt;= max_score)
        {
          current_lane = lane;
          max_score = score;
        }
      }
      if (max_score == -DBL_MAX)
        return null_lanes;
    }
    else
      current_lane = vmap.findByKey(Key&lt;Lane&gt;(current_lane.flid));;
    if (current_lane.lnid == 0)
      return null_lanes;
  }

  return null_lanes;
}

bool isValidPolygon(const Polygon&amp; polygon)
{
  return polygon.size() &gt; 3;
}

Polygon createPolygon(const VectorMap&amp; vmap, const Area&amp; area)
{
  Polygon null_polygon;
  if (area.aid == 0)
    return null_polygon;

  Line line = vmap.findByKey(Key&lt;Line&gt;(area.slid));
  if (line.lid == 0)
    return null_polygon;
  if (line.blid != 0)
    return null_polygon;

  Polygon polygon;
  Line start_line = line;
  while (true)
  {
    Point point = vmap.findByKey(Key&lt;Point&gt;(line.bpid));
    if (point.pid == 0)
      return null_polygon;
    polygon.push_back(convertPointToGeomPoint(point));

    if (line.flid == 0)
      break;

    line = vmap.findByKey(Key&lt;Line&gt;(line.flid));
    if (line.lid == 0)
      return null_polygon;
  }
  Point point = vmap.findByKey(Key&lt;Point&gt;(line.fpid));
  if (point.pid == 0)
    return null_polygon;
  polygon.push_back(convertPointToGeomPoint(point));

  Line end_line = line;
  if (start_line.bpid != end_line.fpid)
    return null_polygon;

  if (!isValidPolygon(polygon))
    return null_polygon;

  return polygon;
}

bool isWinding(const Polygon&amp; polygon, const geometry_msgs::Point&amp; geom_point, size_t i)
{
  double variation_x = polygon[i + 1].x - polygon[i].x;
  variation_x *= (geom_point.y - polygon[i].y) / (polygon[i + 1].y - polygon[i].y);
  return geom_point.x &lt; polygon[i].x + variation_x;
}

bool isInPolygon(const Polygon&amp; polygon, const geometry_msgs::Point&amp; geom_point)
{
  if (!isValidPolygon(polygon))
    return false;

  // Winding Number Algorithm
  int winding_number = 0;
  for (size_t i = 0; i &lt; polygon.size() - 1; ++i)
  {
    if (polygon[i].y &lt;= geom_point.y &amp;&amp; polygon[i + 1].y &gt; geom_point.y)
    {
      if (isWinding(polygon, geom_point, i))
        ++winding_number;
    }
    else if (polygon[i].y &gt; geom_point.y &amp;&amp; polygon[i + 1].y &lt;= geom_point.y)
    {
      if (isWinding(polygon, geom_point, i))
        --winding_number;
    }
  }

  return winding_number != 0;
}

class VectorMapServer
{
private:
  VectorMap vmap_;
  double radius_;
  int loops_;

  bool debug_;
  visualization_msgs::MarkerArray marker_array_;
  ros::Publisher marker_array_pub_;

  std::vector&lt;Lane&gt; createTravelingRoute(const geometry_msgs::PoseStamped&amp; pose,
                                         const waypoint_follower::lane&amp; waypoints)
  {
    std::vector&lt;Lane&gt; null_lanes;

    std::vector&lt;Lane&gt; fine_lanes;
    if (waypoints.waypoints.empty())
      fine_lanes = vmap_.findByFilter([](const Lane&amp; lane){return true;});
    else
      fine_lanes = createFineLanes(vmap_, waypoints, radius_, loops_);
    if (fine_lanes.empty())
      return null_lanes;

    Lane nearest_lane = findNearestLane(vmap_, fine_lanes, convertGeomPointToPoint(pose.pose.position));
    if (nearest_lane.lnid == 0)
      return null_lanes;

    std::vector&lt;Lane&gt; traveling_route;
    if (waypoints.waypoints.empty())
      traveling_route.push_back(nearest_lane);
    else
    {
      bool future = false;
      for (const auto&amp; fine_lane : fine_lanes)
      {
        if (fine_lane.lnid == nearest_lane.lnid)
          future = true;
        if (future)
          traveling_route.push_back(fine_lane);
      }
    }

    if (debug_)
    {
      visualization_msgs::MarkerArray marker_array_buffer;
      int id = 0;
      for (const auto&amp; lane : traveling_route)
      {
        Point start_point = findStartPoint(vmap_, lane);
        if (start_point.pid != 0)
        {
          visualization_msgs::Marker marker = createPointMarker(&quot;traveling_route&quot;, id++, Color::YELLOW, start_point);
          if (isValidMarker(marker))
            marker_array_buffer.markers.push_back(marker);
        }
        Point end_point = findEndPoint(vmap_, lane);
        if (end_point.pid != 0)
        {
          visualization_msgs::Marker marker = createPointMarker(&quot;traveling_route&quot;, id++, Color::YELLOW, end_point);
          if (isValidMarker(marker))
            marker_array_buffer.markers.push_back(marker);
        }
      }
      if (!marker_array_.markers.empty())
      {
        for (auto&amp; marker : marker_array_.markers)
          marker.action = visualization_msgs::Marker::DELETE;
        marker_array_pub_.publish(marker_array_); // clear previous marker
      }
      marker_array_ = marker_array_buffer;
      marker_array_pub_.publish(marker_array_);
    }

    return traveling_route;
  }

public:
  explicit VectorMapServer(ros::NodeHandle&amp; nh)
  {
    vmap_.subscribe(nh, Category::ALL, ros::Duration(0));
    nh.param&lt;double&gt;(&quot;vector_map_server/radius&quot;, radius_, 10);
    nh.param&lt;int&gt;(&quot;vector_map_server/loops&quot;, loops_, 10000);
    nh.param&lt;bool&gt;(&quot;vector_map_server/debug&quot;, debug_, false);
    if (debug_)
      marker_array_pub_ = nh.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;vector_map_server&quot;, 10, true);
  }

  bool getDTLane(vector_map_server::GetDTLane::Request&amp; request,
                 vector_map_server::GetDTLane::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      DTLane dtlane = vmap_.findByKey(Key&lt;DTLane&gt;(lane.did));
      if (dtlane.did == 0)
        return false;
      response.objects.data.push_back(dtlane);
    }
    return true;
  }

  bool getNode(vector_map_server::GetNode::Request&amp; request,
               vector_map_server::GetNode::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      Node node = vmap_.findByKey(Key&lt;Node&gt;(lane.bnid));
      if (node.nid == 0)
        return false;
      response.objects.data.push_back(node);
    }
    Lane end_lane = traveling_route[traveling_route.size() - 1];
    Node end_node = vmap_.findByKey(Key&lt;Node&gt;(end_lane.fnid));
    if (end_node.nid == 0)
      return false;
    response.objects.data.push_back(end_node);
    return true;
  }

  bool getLane(vector_map_server::GetLane::Request&amp; request,
               vector_map_server::GetLane::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
      response.objects.data.push_back(lane);
    return true;
  }

  bool getWayArea(vector_map_server::GetWayArea::Request&amp; request,
                  vector_map_server::GetWayArea::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      WayArea way_area = vmap_.findByKey(Key&lt;WayArea&gt;(lane.linkwaid));
      if (way_area.waid == 0)
        return false;
      response.objects.data.push_back(way_area);
    }
    return true;
  }

  bool getRoadEdge(vector_map_server::GetRoadEdge::Request&amp; request,
                   vector_map_server::GetRoadEdge::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; road_edge : vmap_.findByFilter(
           [&amp;lane](const RoadEdge&amp; road_edge){return road_edge.linkid == lane.lnid;}))
        response.objects.data.push_back(road_edge);
    }
    return true;
  }

  bool getGutter(vector_map_server::GetGutter::Request&amp; request,
                 vector_map_server::GetGutter::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; gutter : vmap_.findByFilter(
           [&amp;lane](const Gutter&amp; gutter){return gutter.linkid == lane.lnid;}))
        response.objects.data.push_back(gutter);
    }
    return true;
  }

  bool getCurb(vector_map_server::GetCurb::Request&amp; request,
               vector_map_server::GetCurb::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; curb : vmap_.findByFilter(
           [&amp;lane](const Curb&amp; curb){return curb.linkid == lane.lnid;}))
        response.objects.data.push_back(curb);
    }
    return true;
  }

  bool getWhiteLine(vector_map_server::GetWhiteLine::Request&amp; request,
                    vector_map_server::GetWhiteLine::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; white_line : vmap_.findByFilter(
           [&amp;lane](const WhiteLine&amp; white_line){return white_line.linkid == lane.lnid;}))
        response.objects.data.push_back(white_line);
    }
    return true;
  }

  bool getStopLine(vector_map_server::GetStopLine::Request&amp; request,
                   vector_map_server::GetStopLine::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; stop_line : vmap_.findByFilter(
           [&amp;lane](const StopLine&amp; stop_line){return stop_line.linkid == lane.lnid;}))
        response.objects.data.push_back(stop_line);
    }
    return true;
  }

  bool getZebraZone(vector_map_server::GetZebraZone::Request&amp; request,
                    vector_map_server::GetZebraZone::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; zebra_zone : vmap_.findByFilter(
           [&amp;lane](const ZebraZone&amp; zebra_zone){return zebra_zone.linkid == lane.lnid;}))
        response.objects.data.push_back(zebra_zone);
    }
    return true;
  }

  bool getCrossWalk(vector_map_server::GetCrossWalk::Request&amp; request,
                    vector_map_server::GetCrossWalk::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; cross_walk : vmap_.findByFilter(
           [&amp;lane](const CrossWalk&amp; cross_walk){return cross_walk.linkid == lane.lnid;}))
        response.objects.data.push_back(cross_walk);
    }
    return true;
  }

  bool getRoadMark(vector_map_server::GetRoadMark::Request&amp; request,
                   vector_map_server::GetRoadMark::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; road_mark : vmap_.findByFilter(
           [&amp;lane](const RoadMark&amp; road_mark){return road_mark.linkid == lane.lnid;}))
        response.objects.data.push_back(road_mark);
    }
    return true;
  }

  bool getRoadPole(vector_map_server::GetRoadPole::Request&amp; request,
                   vector_map_server::GetRoadPole::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; road_pole : vmap_.findByFilter(
           [&amp;lane](const RoadPole&amp; road_pole){return road_pole.linkid == lane.lnid;}))
        response.objects.data.push_back(road_pole);
    }
    return true;
  }

  bool getRoadSign(vector_map_server::GetRoadSign::Request&amp; request,
                   vector_map_server::GetRoadSign::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; road_sign : vmap_.findByFilter(
           [&amp;lane](const RoadSign&amp; road_sign){return road_sign.linkid == lane.lnid;}))
        response.objects.data.push_back(road_sign);
    }
    return true;
  }

  bool getSignal(vector_map_server::GetSignal::Request&amp; request,
                 vector_map_server::GetSignal::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; signal : vmap_.findByFilter(
           [&amp;lane](const Signal&amp; signal){return signal.linkid == lane.lnid;}))
        response.objects.data.push_back(signal);
    }
    return true;
  }

  bool getStreetLight(vector_map_server::GetStreetLight::Request&amp; request,
                      vector_map_server::GetStreetLight::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; street_light : vmap_.findByFilter(
           [&amp;lane](const StreetLight&amp; street_light){return street_light.linkid == lane.lnid;}))
        response.objects.data.push_back(street_light);
    }
    return true;
  }

  bool getUtilityPole(vector_map_server::GetUtilityPole::Request&amp; request,
                      vector_map_server::GetUtilityPole::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; utility_pole : vmap_.findByFilter(
           [&amp;lane](const UtilityPole&amp; utility_pole){return utility_pole.linkid == lane.lnid;}))
        response.objects.data.push_back(utility_pole);
    }
    return true;
  }

  bool getGuardRail(vector_map_server::GetGuardRail::Request&amp; request,
                    vector_map_server::GetGuardRail::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; guard_rail : vmap_.findByFilter(
           [&amp;lane](const GuardRail&amp; guard_rail){return guard_rail.linkid == lane.lnid;}))
        response.objects.data.push_back(guard_rail);
    }
    return true;
  }

  bool getSideWalk(vector_map_server::GetSideWalk::Request&amp; request,
                   vector_map_server::GetSideWalk::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; side_walk : vmap_.findByFilter(
           [&amp;lane](const SideWalk&amp; side_walk){return side_walk.linkid == lane.lnid;}))
        response.objects.data.push_back(side_walk);
    }
    return true;
  }

  bool getDriveOnPortion(vector_map_server::GetDriveOnPortion::Request&amp; request,
                         vector_map_server::GetDriveOnPortion::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; drive_on_portion : vmap_.findByFilter(
           [&amp;lane](const DriveOnPortion&amp; drive_on_portion){return drive_on_portion.linkid == lane.lnid;}))
        response.objects.data.push_back(drive_on_portion);
    }
    return true;
  }

  bool getCrossRoad(vector_map_server::GetCrossRoad::Request&amp; request,
                    vector_map_server::GetCrossRoad::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; cross_road : vmap_.findByFilter(
           [&amp;lane](const CrossRoad&amp; cross_road){return cross_road.linkid == lane.lnid;}))
        response.objects.data.push_back(cross_road);
    }
    return true;
  }

  bool getSideStrip(vector_map_server::GetSideStrip::Request&amp; request,
                    vector_map_server::GetSideStrip::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; side_strip : vmap_.findByFilter(
           [&amp;lane](const SideStrip&amp; side_strip){return side_strip.linkid == lane.lnid;}))
        response.objects.data.push_back(side_strip);
    }
    return true;
  }

  bool getCurveMirror(vector_map_server::GetCurveMirror::Request&amp; request,
                      vector_map_server::GetCurveMirror::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; curve_mirror : vmap_.findByFilter(
           [&amp;lane](const CurveMirror&amp; curve_mirror){return curve_mirror.linkid == lane.lnid;}))
        response.objects.data.push_back(curve_mirror);
    }
    return true;
  }

  bool getWall(vector_map_server::GetWall::Request&amp; request,
               vector_map_server::GetWall::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; wall : vmap_.findByFilter(
           [&amp;lane](const Wall&amp; wall){return wall.linkid == lane.lnid;}))
        response.objects.data.push_back(wall);
    }
    return true;
  }

  bool getFence(vector_map_server::GetFence::Request&amp; request,
                vector_map_server::GetFence::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; fence : vmap_.findByFilter(
           [&amp;lane](const Fence&amp; fence){return fence.linkid == lane.lnid;}))
        response.objects.data.push_back(fence);
    }
    return true;
  }

  bool getRailCrossing(vector_map_server::GetRailCrossing::Request&amp; request,
                       vector_map_server::GetRailCrossing::Response&amp; response)
  {
    std::vector&lt;Lane&gt; traveling_route = createTravelingRoute(request.pose, request.waypoints);
    if (traveling_route.empty())
      return false;
    response.objects.header.frame_id = &quot;map&quot;;
    for (const auto&amp; lane : traveling_route)
    {
      for (const auto&amp; rail_crossing : vmap_.findByFilter(
           [&amp;lane](const RailCrossing&amp; rail_crossing){return rail_crossing.linkid == lane.lnid;}))
        response.objects.data.push_back(rail_crossing);
    }
    return true;
  }

  bool isWayArea(vector_map_server::PositionState::Request&amp; request,
                 vector_map_server::PositionState::Response&amp; response)
  {
    response.state = false;
    for (const auto&amp; way_area : vmap_.findByFilter([](const WayArea&amp; way_area){return true;}))
    {
      Area area = vmap_.findByKey(Key&lt;Area&gt;(way_area.aid));
      if (area.aid == 0)
        continue;
      Polygon polygon = createPolygon(vmap_, area);
      if (isInPolygon(polygon, request.position))
      {
        response.state = true;
        break;
      }
    }
    return true;
  }
};
} // namespace

int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;vector_map_server&quot;);

  ros::NodeHandle nh;
  VectorMapServer vms(nh);

  ros::ServiceServer get_dtlane_srv = nh.advertiseService(&quot;vector_map_server/get_dtlane&quot;,
                                                          &amp;VectorMapServer::getDTLane, &amp;vms);
  ros::ServiceServer get_node_srv = nh.advertiseService(&quot;vector_map_server/get_node&quot;,
                                                        &amp;VectorMapServer::getNode, &amp;vms);
  ros::ServiceServer get_lane_srv = nh.advertiseService(&quot;vector_map_server/get_lane&quot;,
                                                        &amp;VectorMapServer::getLane, &amp;vms);
  ros::ServiceServer get_way_area_srv = nh.advertiseService(&quot;vector_map_server/get_way_area&quot;,
                                                            &amp;VectorMapServer::getWayArea, &amp;vms);
  ros::ServiceServer get_road_edge_srv = nh.advertiseService(&quot;vector_map_server/get_road_edge&quot;,
                                                             &amp;VectorMapServer::getRoadEdge, &amp;vms);
  ros::ServiceServer get_gutter_srv = nh.advertiseService(&quot;vector_map_server/get_gutter&quot;,
                                                          &amp;VectorMapServer::getGutter, &amp;vms);
  ros::ServiceServer get_curb_srv = nh.advertiseService(&quot;vector_map_server/get_curb&quot;,
                                                        &amp;VectorMapServer::getCurb, &amp;vms);
  ros::ServiceServer get_white_line_srv = nh.advertiseService(&quot;vector_map_server/get_white_line&quot;,
                                                              &amp;VectorMapServer::getWhiteLine, &amp;vms);
  ros::ServiceServer get_stop_line_srv = nh.advertiseService(&quot;vector_map_server/get_stop_line&quot;,
                                                             &amp;VectorMapServer::getStopLine, &amp;vms);
  ros::ServiceServer get_zebra_zone_srv = nh.advertiseService(&quot;vector_map_server/get_zebra_zone&quot;,
                                                              &amp;VectorMapServer::getZebraZone, &amp;vms);
  ros::ServiceServer get_cross_walk_srv = nh.advertiseService(&quot;vector_map_server/get_cross_walk&quot;,
                                                              &amp;VectorMapServer::getCrossWalk, &amp;vms);
  ros::ServiceServer get_road_mark_srv = nh.advertiseService(&quot;vector_map_server/get_road_mark&quot;,
                                                             &amp;VectorMapServer::getRoadMark, &amp;vms);
  ros::ServiceServer get_road_pole_srv = nh.advertiseService(&quot;vector_map_server/get_road_pole&quot;,
                                                             &amp;VectorMapServer::getRoadPole, &amp;vms);
  ros::ServiceServer get_road_sign_srv = nh.advertiseService(&quot;vector_map_server/get_road_sign&quot;,
                                                             &amp;VectorMapServer::getRoadSign, &amp;vms);
  ros::ServiceServer get_signal_srv = nh.advertiseService(&quot;vector_map_server/get_signal&quot;,
                                                          &amp;VectorMapServer::getSignal, &amp;vms);
  ros::ServiceServer get_street_light_srv = nh.advertiseService(&quot;vector_map_server/get_street_light&quot;,
                                                                &amp;VectorMapServer::getStreetLight, &amp;vms);
  ros::ServiceServer get_utility_pole_srv = nh.advertiseService(&quot;vector_map_server/get_utility_pole&quot;,
                                                                &amp;VectorMapServer::getUtilityPole, &amp;vms);
  ros::ServiceServer get_guard_rail_srv = nh.advertiseService(&quot;vector_map_server/get_guard_rail&quot;,
                                                              &amp;VectorMapServer::getGuardRail, &amp;vms);
  ros::ServiceServer get_side_walk_srv = nh.advertiseService(&quot;vector_map_server/get_side_walk&quot;,
                                                             &amp;VectorMapServer::getSideWalk, &amp;vms);
  ros::ServiceServer get_drive_on_portion_srv = nh.advertiseService(&quot;vector_map_server/get_drive_on_portion&quot;,
                                                                    &amp;VectorMapServer::getDriveOnPortion, &amp;vms);
  ros::ServiceServer get_cross_road_srv = nh.advertiseService(&quot;vector_map_server/get_cross_road&quot;,
                                                              &amp;VectorMapServer::getCrossRoad, &amp;vms);
  ros::ServiceServer get_side_strip_srv = nh.advertiseService(&quot;vector_map_server/get_side_strip&quot;,
                                                              &amp;VectorMapServer::getSideStrip, &amp;vms);
  ros::ServiceServer get_curve_mirror_srv = nh.advertiseService(&quot;vector_map_server/get_curve_mirror&quot;,
                                                                &amp;VectorMapServer::getCurveMirror, &amp;vms);
  ros::ServiceServer get_wall_srv = nh.advertiseService(&quot;vector_map_server/get_wall&quot;,
                                                        &amp;VectorMapServer::getWall, &amp;vms);
  ros::ServiceServer get_fence_srv = nh.advertiseService(&quot;vector_map_server/get_fence&quot;,
                                                         &amp;VectorMapServer::getFence, &amp;vms);
  ros::ServiceServer get_rail_crossing_srv = nh.advertiseService(&quot;vector_map_server/get_rail_crossing&quot;,
                                                                 &amp;VectorMapServer::getRailCrossing, &amp;vms);
  ros::ServiceServer is_way_area_srv = nh.advertiseService(&quot;vector_map_server/is_way_area&quot;,
                                                           &amp;VectorMapServer::isWayArea, &amp;vms);

  ros::spin();

  return EXIT_SUCCESS;
}
</old_file>
			</file>
			<file old_path="ros/src/socket/packages/tablet_socket/nodes/tablet_receiver/tablet_receiver.cpp" new_path="ros/src/socket/packages/tablet_socket/nodes/tablet_receiver/tablet_receiver.cpp">
				<diff>@@ -48,9 +48,9 @@
 #include &lt;geo_pos_conv.hh&gt;
 
 #include &quot;ros/ros.h&quot;
-#include &quot;tablet_socket/gear_cmd.h&quot;
-#include &quot;tablet_socket/mode_cmd.h&quot;
-#include &quot;tablet_socket/route_cmd.h&quot;
+#include &quot;tablet_socket_msgs/gear_cmd.h&quot;
+#include &quot;tablet_socket_msgs/mode_cmd.h&quot;
+#include &quot;tablet_socket_msgs/route_cmd.h&quot;
 
 #define NODE_NAME	&quot;tablet_receiver&quot;
 #define TOPIC_NR	(5)
@@ -139,9 +139,9 @@ int main(int argc, char *argv[])
 
 	ros::init(argc, argv, NODE_NAME);
 	ros::NodeHandle node;
-	pub[0] = node.advertise&lt;tablet_socket::gear_cmd&gt;(&quot;gear_cmd&quot;, 1);
-	pub[1] = node.advertise&lt;tablet_socket::mode_cmd&gt;(&quot;mode_cmd&quot;, 1);
-	pub[2] = node.advertise&lt;tablet_socket::route_cmd&gt;(&quot;route_cmd&quot;, 1);
+	pub[0] = node.advertise&lt;tablet_socket_msgs::gear_cmd&gt;(&quot;gear_cmd&quot;, 1);
+	pub[1] = node.advertise&lt;tablet_socket_msgs::mode_cmd&gt;(&quot;mode_cmd&quot;, 1);
+	pub[2] = node.advertise&lt;tablet_socket_msgs::route_cmd&gt;(&quot;route_cmd&quot;, 1);
 	pub[3] = node.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;gnss_pose&quot;, 1);
 	pub[4] = node.advertise&lt;std_msgs::Bool&gt;(&quot;gnss_stat&quot;, 1);
 	node.param&lt;int&gt;(&quot;tablet_receiver/port&quot;, port, DEFAULT_PORT);
@@ -245,13 +245,13 @@ static int getSensorValue(int sock, ros::Publisher pub[TOPIC_NR])
 
 	switch(info[0]) {
 	case 1: { // GEAR
-		tablet_socket::gear_cmd msg;
+		tablet_socket_msgs::gear_cmd msg;
 		msg.gear = info[1];
 		pub[0].publish(msg);
 		break;
 	}
 	case 2: { // MODE
-		tablet_socket::mode_cmd msg;
+		tablet_socket_msgs::mode_cmd msg;
 		msg.mode = info[1];
 		pub[1].publish(msg);
 		break;
@@ -284,8 +284,8 @@ static int getSensorValue(int sock, ros::Publisher pub[TOPIC_NR])
 			}
 		}
 
-		tablet_socket::route_cmd msg;
-		tablet_socket::Waypoint point;
+		tablet_socket_msgs::route_cmd msg;
+		tablet_socket_msgs::Waypoint point;
 		for (int i = 0; i &lt; points_nr; i++) {
 			if (i % 2) {
 				point.lon = points[i];
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/time.h&gt;
#include &lt;signal.h&gt;
#include &lt;wait.h&gt;

//#undef NDEBUG
#include &lt;assert.h&gt;

#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;std_msgs/Bool.h&gt;

#include &lt;geo_pos_conv.hh&gt;

#include &quot;ros/ros.h&quot;
#include &quot;tablet_socket/gear_cmd.h&quot;
#include &quot;tablet_socket/mode_cmd.h&quot;
#include &quot;tablet_socket/route_cmd.h&quot;

#define NODE_NAME	&quot;tablet_receiver&quot;
#define TOPIC_NR	(5)

#define DEFAULT_PORT	(5666)
#define DEFAULT_PLANE	(7)

static int getConnect(int, int *, int *);
static int getSensorValue(int, ros::Publisher[TOPIC_NR]);
static int sendSignal(int);

class Launch {
private:
	std::string launch_;
	bool running_;
	pid_t pid_;

public:
	explicit Launch(const char *launch);

	void start();
	void stop();
};

Launch::Launch(const char *launch)
{
	launch_ = launch;
	running_ = false;
}

void Launch::start()
{
	if (running_)
		return;

	running_ = true;

	pid_t pid = fork();
	if (pid &gt; 0)
		pid_ = pid;
	else if (pid == 0) {
		execlp(&quot;roslaunch&quot;, &quot;roslaunch&quot;, &quot;runtime_manager&quot;,
		       launch_.c_str(), NULL);
		running_ = false;
		exit(EXIT_FAILURE);
	}
	else
		running_ = false;
}

void Launch::stop()
{
	if (!running_)
		return;

	kill(pid_, SIGTERM);
	waitpid(pid_, NULL, 0);

	running_ = false;
}

static Launch s1(&quot;check.launch&quot;), s2(&quot;set.launch&quot;);

static geo_pos_conv geo;

void stopChildProcess(int signo)
{
	s1.stop();
	s2.stop();
	_exit(EXIT_SUCCESS);
}

int main(int argc, char *argv[])
{
	ros::Publisher pub[TOPIC_NR];
	int port, plane;
	int sock, asock;

	struct sigaction act;
	memset(&amp;act, 0, sizeof(act));
	act.sa_handler = stopChildProcess;
	if (sigaction(SIGTERM, &amp;act, NULL) == -1) {
		perror(&quot;sigaction&quot;);
		return -1;
	}

	ros::init(argc, argv, NODE_NAME);
	ros::NodeHandle node;
	pub[0] = node.advertise&lt;tablet_socket::gear_cmd&gt;(&quot;gear_cmd&quot;, 1);
	pub[1] = node.advertise&lt;tablet_socket::mode_cmd&gt;(&quot;mode_cmd&quot;, 1);
	pub[2] = node.advertise&lt;tablet_socket::route_cmd&gt;(&quot;route_cmd&quot;, 1);
	pub[3] = node.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;gnss_pose&quot;, 1);
	pub[4] = node.advertise&lt;std_msgs::Bool&gt;(&quot;gnss_stat&quot;, 1);
	node.param&lt;int&gt;(&quot;tablet_receiver/port&quot;, port, DEFAULT_PORT);
	node.param&lt;int&gt;(&quot;tablet_receiver/plane&quot;, plane, DEFAULT_PLANE);
	fprintf(stderr, &quot;listen port=%d\n&quot;, port);

	geo.set_plane(plane);

	//get connect to android
	sock = -1;

	sigaction(SIGINT, NULL, &amp;act);
	act.sa_flags &amp;= ~SA_RESTART;
	sigaction(SIGINT, &amp;act, NULL);

	while (getConnect(port, &amp;sock, &amp;asock) != -1) {
		struct timeval tv[2];
		double sec;
		int count;

		fprintf(stderr, &quot;get connect.\n&quot;);
		gettimeofday(tv, NULL);
		for (count = 0; ; count++) {
			if(getSensorValue(asock, pub) == -1)
				break;
			if(sendSignal(asock) == -1)
				break;
		}
		close(asock);
		gettimeofday(tv+1, NULL);
		sec = (tv[1].tv_sec - tv[0].tv_sec) +
			(tv[1].tv_usec - tv[0].tv_usec) / 1000000.0;
		fprintf(stderr, &quot;done, %f sec\n&quot;,sec);
	}

	return 0;
}

static int getConnect(int port, int *sock, int *asock)
{
	struct sockaddr_in addr;
	struct sockaddr_in client;
	socklen_t len;
	int yes = 1;

	assert(sock != NULL);
	assert(asock != NULL);

	if (*sock &lt; 0) {
		*sock = socket(AF_INET, SOCK_STREAM, 0);
		if (*sock == -1) {
			perror(&quot;socket&quot;);
			return -1;
		}

		std::memset(&amp;addr, 0, sizeof(sockaddr_in));
		addr.sin_family = AF_INET;
		addr.sin_port = htons(port);
		addr.sin_addr.s_addr = htonl(INADDR_ANY);
		//make it available immediately to connect
		setsockopt(*sock, SOL_SOCKET, SO_REUSEADDR,
			(const char *)&amp;yes, sizeof(yes));
		if (bind(*sock, (struct sockaddr *)&amp;addr, sizeof(addr)) == -1) {
			perror(&quot;bind&quot;);
			return -1;
		}
		if (listen(*sock, 5) == -1) {
			perror(&quot;listen&quot;);
			return -1;
		}
	}

	len = sizeof(client);
	*asock = accept(*sock, (struct sockaddr *)&amp;client, &amp;len);
	if(*asock == -1) {
		perror(&quot;accept&quot;);
		return -1;
	}

	return 0;
}

static int getSensorValue(int sock, ros::Publisher pub[TOPIC_NR])
{
	int info[2];
	size_t size = sizeof(info);
	ssize_t nbytes;

	for (char *p = (char *)info; size; size -= nbytes, p += nbytes) {
		nbytes = recv(sock, info, size, 0);
		if (nbytes == -1) {
			perror(&quot;recv&quot;);
			return -1;
		}
		if (nbytes == 0) {
			fprintf(stderr, &quot;peer is shutdown\n&quot;);
			return -1;
		}
	}
	fprintf(stderr, &quot;info=%d value=%d\n&quot;, info[0], info[1]);

	switch(info[0]) {
	case 1: { // GEAR
		tablet_socket::gear_cmd msg;
		msg.gear = info[1];
		pub[0].publish(msg);
		break;
	}
	case 2: { // MODE
		tablet_socket::mode_cmd msg;
		msg.mode = info[1];
		pub[1].publish(msg);
		break;
	}
	case 3: { // ROUTE
		size = info[1];
		if (!size)
			break;

		double *points = (double *)malloc(size);
		if (points == NULL) {
			perror(&quot;malloc&quot;);
			return -1;
		}

		int points_nr = size / sizeof(double);

		for (char *p = (char *)points; size;
		     size -= nbytes, p += nbytes) {
			nbytes = recv(sock, p, size, 0);
			if (nbytes == -1) {
				perror(&quot;recv&quot;);
				free(points);
				return -1;
			}
			if (nbytes == 0) {
				fprintf(stderr, &quot;peer is shutdown\n&quot;);
				free(points);
				return -1;
			}
		}

		tablet_socket::route_cmd msg;
		tablet_socket::Waypoint point;
		for (int i = 0; i &lt; points_nr; i++) {
			if (i % 2) {
				point.lon = points[i];
				msg.point.push_back(point);
			} else
				point.lat = points[i];
		}

		free(points);

		pub[2].publish(msg);
		break;
	}
	case 4: { // S1
		if (info[1] &gt;= 0)
			s1.start();
		else
			s1.stop();
		break;
	}
	case 5: { // S2
		if (info[1] &gt;= 0)
			s2.start();
		else
			s2.stop();
		break;
	}
	case 6: { // POSE
		size = info[1];
		if (!size)
			break;

		double *buf = (double *)malloc(size);
		if (buf == NULL) {
			perror(&quot;malloc&quot;);
			return -1;
		}

		for (char *p = (char *)buf; size;
		     size -= nbytes, p += nbytes) {
			nbytes = recv(sock, p, size, 0);
			if (nbytes == -1) {
				perror(&quot;recv&quot;);
				free(buf);
				return -1;
			}
			if (nbytes == 0) {
				fprintf(stderr, &quot;peer is shutdown\n&quot;);
				free(buf);
				return -1;
			}
		}

		geo.llh_to_xyz(buf[0], buf[1], buf[2]);

		tf::Transform transform;
		tf::Quaternion q;
		transform.setOrigin(tf::Vector3(geo.y(), geo.x(), geo.z()));
		q.setRPY(buf[4], buf[5], buf[3]);
		transform.setRotation(q);

		free(buf);

		ros::Time now = ros::Time::now();

		tf::TransformBroadcaster br;
		br.sendTransform(tf::StampedTransform(transform, now, &quot;map&quot;,
						      &quot;gps&quot;));

		geometry_msgs::PoseStamped pose;
		pose.header.stamp = now;
		pose.header.frame_id = &quot;map&quot;;
		pose.pose.position.x = geo.y();
		pose.pose.position.y = geo.x();
		pose.pose.position.z = geo.z();
		pose.pose.orientation.x = q.x();
		pose.pose.orientation.y = q.y();
		pose.pose.orientation.z = q.z();
		pose.pose.orientation.w = q.w();

		std_msgs::Bool stat;
		if (pose.pose.position.x == 0 || pose.pose.position.y == 0 ||
		    pose.pose.position.z == 0)
			stat.data = false;
		else
			stat.data = true;

		pub[3].publish(pose);
		pub[4].publish(stat);
		break;
	}
	default: // TERMINATOR
		fprintf(stderr, &quot;receive %d, terminated.\n&quot;, info[0]);
		sendSignal(sock);
		return -1;
	}

	return 0;
}

static int sendSignal(int sock)
{
	int signal = 0;

	if(send(sock, &amp;signal, sizeof(signal), 0) == -1) {
		perror(&quot;send&quot;);
		return -1;
	}
	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/socket/packages/tablet_socket/nodes/tablet_sender/tablet_sender.cpp" new_path="ros/src/socket/packages/tablet_socket/nodes/tablet_sender/tablet_sender.cpp">
				<diff>@@ -37,8 +37,8 @@
 #include &lt;signal.h&gt;
 
 #include &lt;std_msgs/Bool.h&gt;
-#include &lt;tablet_socket/error_info.h&gt;
-#include &lt;tablet_socket/mode_info.h&gt;
+#include &lt;tablet_socket_msgs/error_info.h&gt;
+#include &lt;tablet_socket_msgs/mode_info.h&gt;
 #include &lt;vehicle_socket/CanInfo.h&gt;
 #include &lt;ndt_localizer/ndt_stat.h&gt;
 
@@ -62,7 +62,7 @@ struct error_request {
 	int32_t type;
 	int32_t error;
 
-	error_request(const tablet_socket::error_info&amp; msg)
+	error_request(const tablet_socket_msgs::error_info&amp; msg)
 	: type(ERROR_INFO_TYPE), error(msg.error) {
 	}
 };
@@ -80,7 +80,7 @@ struct mode_request {
 	int32_t type;
 	int32_t mode;
 
-	mode_request(const tablet_socket::mode_info&amp; msg)
+	mode_request(const tablet_socket_msgs::mode_info&amp; msg)
 	: type(MODE_INFO_TYPE), mode(msg.mode) {
 	}
 };
@@ -115,7 +115,7 @@ struct lf_request {
 	}
 };
 
-static void subscribe_error_info(const tablet_socket::error_info&amp; msg)
+static void subscribe_error_info(const tablet_socket_msgs::error_info&amp; msg)
 {
 	error_request request(msg);
 	int response;
@@ -181,7 +181,7 @@ static void subscribe_can_info(const vehicle_socket::CanInfo&amp; msg)
 	}
 }
 
-static void subscribe_mode_info(const tablet_socket::mode_info&amp; msg)
+static void subscribe_mode_info(const tablet_socket_msgs::mode_info&amp; msg)
 {
 	mode_request request(msg);
 	int response;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;mutex&gt;

#include &lt;netinet/in.h&gt;

#include &lt;ros/ros.h&gt;
#include &lt;ros/console.h&gt;
#include &lt;signal.h&gt;

#include &lt;std_msgs/Bool.h&gt;
#include &lt;tablet_socket/error_info.h&gt;
#include &lt;tablet_socket/mode_info.h&gt;
#include &lt;vehicle_socket/CanInfo.h&gt;
#include &lt;ndt_localizer/ndt_stat.h&gt;

static constexpr int DEFAULT_PORT = 5777;
static constexpr int LISTEN_BACKLOG = 10;
static constexpr uint32_t QUEUE_SIZE = 1;
static constexpr double SUBSCRIBE_HZ = 1;

static constexpr int32_t ERROR_INFO_TYPE = 1;
static constexpr int32_t CAN_INFO_TYPE = 2;
static constexpr int32_t MODE_INFO_TYPE = 3;
static constexpr int32_t NDT_STAT_TYPE = 4;
static constexpr int32_t LF_STAT_TYPE = 5;

static int port;
static int connfd;
static volatile bool socket_ok;
static std::mutex mtx;

struct error_request {
	int32_t type;
	int32_t error;

	error_request(const tablet_socket::error_info&amp; msg)
	: type(ERROR_INFO_TYPE), error(msg.error) {
	}
};

struct can_request {
	int32_t type;
	int32_t driveshift;

	can_request(const vehicle_socket::CanInfo&amp; msg)
	: type(CAN_INFO_TYPE), driveshift(msg.driveshift) {
	}
};

struct mode_request {
	int32_t type;
	int32_t mode;

	mode_request(const tablet_socket::mode_info&amp; msg)
	: type(MODE_INFO_TYPE), mode(msg.mode) {
	}
};

struct ndt_request {
	int32_t type;
	float exe_time;
	int32_t iteration;
	float score;
	float velocity;
	float acceleration;
	int32_t use_predict_pose;

	ndt_request(const ndt_localizer::ndt_stat&amp; msg) {
		type = NDT_STAT_TYPE;
		exe_time = msg.exe_time;
		iteration = msg.iteration;
		score = msg.score;
		velocity = msg.velocity;
		acceleration = msg.acceleration;
		use_predict_pose = msg.use_predict_pose;
	}
};

struct lf_request {
	int32_t type;
	int32_t data;

	lf_request(const std_msgs::Bool&amp; msg) {
		type = LF_STAT_TYPE;
		data = msg.data ? 1 : 0;
	}
};

static void subscribe_error_info(const tablet_socket::error_info&amp; msg)
{
	error_request request(msg);
	int response;
	ssize_t nbytes;

	std::lock_guard&lt;std::mutex&gt; lock(mtx);

	nbytes = send(connfd, &amp;request, sizeof(request), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;send: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(request)) {
		ROS_WARN(&quot;send: %zd bytes remaining&quot;,
			 sizeof(request) - nbytes);
		return;
	}

	nbytes = recv(connfd, &amp;response, sizeof(response), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;recv: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(response)) {
		ROS_WARN(&quot;recv: %zd bytes remaining&quot;,
			 sizeof(response) - nbytes);
		return;
	}
}

static void subscribe_can_info(const vehicle_socket::CanInfo&amp; msg)
{
	can_request request(msg);
	int response;
	ssize_t nbytes;

	std::lock_guard&lt;std::mutex&gt; lock(mtx);

	nbytes = send(connfd, &amp;request, sizeof(request), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;send: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(request)) {
		ROS_WARN(&quot;send: %zd bytes remaining&quot;,
			 sizeof(request) - nbytes);
		return;
	}

	nbytes = recv(connfd, &amp;response, sizeof(response), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;recv: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(response)) {
		ROS_WARN(&quot;recv: %zd bytes remaining&quot;,
			 sizeof(response) - nbytes);
		return;
	}
}

static void subscribe_mode_info(const tablet_socket::mode_info&amp; msg)
{
	mode_request request(msg);
	int response;
	ssize_t nbytes;

	std::lock_guard&lt;std::mutex&gt; lock(mtx);

	nbytes = send(connfd, &amp;request, sizeof(request), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;send: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(request)) {
		ROS_WARN(&quot;send: %zd bytes remaining&quot;,
			 sizeof(request) - nbytes);
		return;
	}

	nbytes = recv(connfd, &amp;response, sizeof(response), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;recv: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(response)) {
		ROS_WARN(&quot;recv: %zd bytes remaining&quot;,
			 sizeof(response) - nbytes);
		return;
	}
}

static void subscribe_ndt_stat(const ndt_localizer::ndt_stat&amp; msg)
{
	ndt_request request(msg);
	int response;
	ssize_t nbytes;

	std::lock_guard&lt;std::mutex&gt; lock(mtx);

	nbytes = send(connfd, &amp;request, sizeof(request), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;send: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(request)) {
		ROS_WARN(&quot;send: %zd bytes remaining&quot;,
			 sizeof(request) - nbytes);
		return;
	}

	nbytes = recv(connfd, &amp;response, sizeof(response), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;recv: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(response)) {
		ROS_WARN(&quot;recv: %zd bytes remaining&quot;,
			 sizeof(response) - nbytes);
		return;
	}
}

static void subscribe_lf_stat(const std_msgs::Bool&amp; msg)
{
	lf_request request(msg);
	int response;
	ssize_t nbytes;

	std::lock_guard&lt;std::mutex&gt; lock(mtx);

	nbytes = send(connfd, &amp;request, sizeof(request), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;send: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(request)) {
		ROS_WARN(&quot;send: %zd bytes remaining&quot;,
			 sizeof(request) - nbytes);
		return;
	}

	nbytes = recv(connfd, &amp;response, sizeof(response), 0);
	if (nbytes &lt; 0) {
		ROS_ERROR(&quot;recv: %s&quot;, strerror(errno));
		socket_ok = false;
		return;
	}
	if ((size_t)nbytes &lt; sizeof(response)) {
		ROS_WARN(&quot;recv: %zd bytes remaining&quot;,
			 sizeof(response) - nbytes);
		return;
	}
}

static bool send_beacon(void)
{
	int request[2];
	int response;
	ssize_t nbytes;

	memset(request, 0, sizeof(request));

	std::lock_guard&lt;std::mutex&gt; lock(mtx);

	nbytes = send(connfd, request, sizeof(request), 0);
	if (nbytes &lt; 0) {
		socket_ok = false;
		return false;
	}

	nbytes = recv(connfd, &amp;response, sizeof(response), 0);
	if (nbytes &lt; 0) {
		socket_ok = false;
		return false;
	}

	return true;
}

int main(int argc, char **argv)
{
	int listenfd, on;
	sockaddr_in addr;

	ros::init(argc, argv, &quot;tablet_sender&quot;);

	ros::NodeHandle n;
	n.param&lt;int&gt;(&quot;tablet_sender/port&quot;, port, DEFAULT_PORT);
	if (!(port &gt;= 0 &amp;&amp; port &lt; 65536)) {
		ROS_ERROR(&quot;Invalid port value %d\n&quot;, port);
		return -1;
	}

	listenfd = socket(AF_INET, SOCK_STREAM, IPPROTO_IP);
	if (listenfd &lt; 0) {
		ROS_ERROR(&quot;socket: %s&quot;, strerror(errno));
		return -1;
	}

	on = 1;
	if (setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on))
	    &lt; 0) {
		ROS_ERROR(&quot;setsockopt: %s&quot;, strerror(errno));
		close(listenfd);
		return -1;
	}

	memset(&amp;addr, 0, sizeof(addr));
	addr.sin_family = AF_INET;
	addr.sin_port = htons(port);
	addr.sin_addr.s_addr = htonl(INADDR_ANY);

	if (bind(listenfd, (const struct sockaddr *)&amp;addr, sizeof(addr)) &lt; 0) {
		ROS_ERROR(&quot;bind: %s&quot;, strerror(errno));
		close(listenfd);
		return -1;
	}

	if (listen(listenfd, LISTEN_BACKLOG) &lt; 0) {
		ROS_ERROR(&quot;listen: %s&quot;, strerror(errno));
		close(listenfd);
		return -1;
	}

	ros::Subscriber sub_error_info = n.subscribe(&quot;error_info&quot;, QUEUE_SIZE,
						     subscribe_error_info);
	ros::Subscriber sub_can_info = n.subscribe(&quot;can_info&quot;, QUEUE_SIZE,
						   subscribe_can_info);
	ros::Subscriber sub_mode_info = n.subscribe(&quot;mode_info&quot;, QUEUE_SIZE,
						    subscribe_mode_info);
	ros::Subscriber sub_ndt_stat = n.subscribe(&quot;ndt_stat&quot;, QUEUE_SIZE,
						   subscribe_ndt_stat);
	ros::Subscriber sub_lf_stat = n.subscribe(&quot;wf_stat&quot;, QUEUE_SIZE,
						  subscribe_lf_stat);

	ros::Rate loop_rate(SUBSCRIBE_HZ);

	struct sigaction act;
	sigaction(SIGINT, NULL, &amp;act);
	act.sa_flags &amp;= ~SA_RESTART;
	sigaction(SIGINT, &amp;act, NULL);

	while (true) {
		connfd = accept(listenfd, (struct sockaddr *)nullptr,
				nullptr);
		if (connfd &lt; 0) {
			ROS_ERROR(&quot;accept: %s&quot;, strerror(errno));
			close(listenfd);
			return -1;
		}

		socket_ok = true;
		while (socket_ok &amp;&amp; send_beacon()) {
			ros::spinOnce();
			loop_rate.sleep();
		}

		close(connfd);
	}

	close(listenfd);

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/socket/packages/udon_socket/nodes/udon_sender/udon_sender.cpp" new_path="ros/src/socket/packages/udon_socket/nodes/udon_sender/udon_sender.cpp">
				<diff>@@ -41,7 +41,7 @@
 #include &lt;geometry_msgs/PoseStamped.h&gt;
 #include &lt;tf/transform_datatypes.h&gt;
 
-#include &lt;tablet_socket/mode_info.h&gt;
+#include &lt;tablet_socket_msgs/mode_info.h&gt;
 
 #include &lt;udon_socket/udon.hpp&gt;
 
@@ -55,7 +55,7 @@ struct Vehicle {
 Vehicle vehicle;
 boost::shared_mutex vehicle_mtx;
 
-void cache_mode(const tablet_socket::mode_info&amp; msg)
+void cache_mode(const tablet_socket_msgs::mode_info&amp; msg)
 {
 	boost::upgrade_lock&lt;boost::shared_mutex&gt; up_lock(vehicle_mtx);
 	boost::upgrade_to_unique_lock&lt;boost::shared_mutex&gt; write_lock(up_lock);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;arpa/inet.h&gt;
#include &lt;netinet/in.h&gt;

#include &lt;thread&gt;

#include &lt;boost/thread.hpp&gt;

#include &lt;ros/ros.h&gt;
#include &lt;ros/console.h&gt;

#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;tf/transform_datatypes.h&gt;

#include &lt;tablet_socket/mode_info.h&gt;

#include &lt;udon_socket/udon.hpp&gt;

namespace {

struct Vehicle {
	std::int32_t mode;
	udon_socket::udon::Location location;
};

Vehicle vehicle;
boost::shared_mutex vehicle_mtx;

void cache_mode(const tablet_socket::mode_info&amp; msg)
{
	boost::upgrade_lock&lt;boost::shared_mutex&gt; up_lock(vehicle_mtx);
	boost::upgrade_to_unique_lock&lt;boost::shared_mutex&gt; write_lock(up_lock);

	vehicle.mode = msg.mode;
}

void cache_pose(const geometry_msgs::PoseStamped&amp; msg)
{
	boost::upgrade_lock&lt;boost::shared_mutex&gt; up_lock(vehicle_mtx);
	boost::upgrade_to_unique_lock&lt;boost::shared_mutex&gt; write_lock(up_lock);

	// msg's X-Y axis is reversed
	vehicle.location.x = msg.pose.position.y;
	vehicle.location.y = msg.pose.position.x;
	vehicle.location.z = msg.pose.position.z;
	vehicle.location.d = tf::getYaw(msg.pose.orientation);
	vehicle.location.d = (-1 * vehicle.location.d) + (M_PI / 2);
	vehicle.location.d = fmod(vehicle.location.d, (2 * M_PI));
	if (vehicle.location.d &lt; 0)
		vehicle.location.d += (2 * M_PI);
}

void send_info(const sockaddr_in client_addr, int connect_fd, std::size_t bufsize, int period)
{
	std::uint8_t *buf;
	bool first;

	char astr[INET_ADDRSTRLEN];
	if (inet_ntop(AF_INET, &amp;client_addr.sin_addr, astr, sizeof(astr)) == nullptr) {
		ROS_ERROR_STREAM(&quot;inet_ntop: &quot; &lt;&lt; std::strerror(errno));
		goto close_connect_fd;
	}

	buf = new std::uint8_t[bufsize];
	first = true;

	Vehicle curr, prev;
	while (true) {
		boost::shared_lock&lt;boost::shared_mutex&gt; read_lock(vehicle_mtx);
		curr = vehicle;
		read_lock.unlock();

		if (first) {
			ssize_t nbytes = udon_socket::udon::send_request(connect_fd);
			if (nbytes &lt; 0) {
				ROS_ERROR_STREAM(&quot;udon_socket::udon::send_request: &quot; &lt;&lt; std::strerror(errno));
				goto delete_buf;
			}
			nbytes = recv(connect_fd, buf, bufsize, 0);
			if (nbytes &lt; 0) {
				ROS_ERROR_STREAM(&quot;recv: &quot; &lt;&lt; std::strerror(errno));
				goto delete_buf;
			} else if (nbytes == 0) {
				ROS_INFO_STREAM(&quot;disconnect &quot; &lt;&lt; astr &lt;&lt; &quot;:&quot; &lt;&lt; ntohs(client_addr.sin_port));
				goto delete_buf;
			}

			nbytes = udon_socket::udon::send_mode(connect_fd, curr.mode);
			if (nbytes &lt; 0) {
				ROS_ERROR_STREAM(&quot;udon_socket::udon::send_mode: &quot; &lt;&lt; std::strerror(errno));
				goto delete_buf;
			}
			nbytes = recv(connect_fd, buf, bufsize, 0);
			if (nbytes &lt; 0) {
				ROS_ERROR_STREAM(&quot;recv: &quot; &lt;&lt; std::strerror(errno));
				goto delete_buf;
			} else if (nbytes == 0) {
				ROS_INFO_STREAM(&quot;disconnect &quot; &lt;&lt; astr &lt;&lt; &quot;:&quot; &lt;&lt; ntohs(client_addr.sin_port));
				goto delete_buf;
			}

			if (curr.mode == udon_socket::udon::MODE_AUTO) {
				nbytes = udon_socket::udon::send_location(connect_fd, curr.location);
				if (nbytes &lt; 0) {
					ROS_ERROR_STREAM(&quot;udon_socket::udon::send_location: &quot; &lt;&lt; std::strerror(errno));
					goto delete_buf;
				}
				nbytes = recv(connect_fd, buf, bufsize, 0);
				if (nbytes &lt; 0) {
					ROS_ERROR_STREAM(&quot;recv: &quot; &lt;&lt; std::strerror(errno));
					goto delete_buf;
				} else if (nbytes == 0) {
					ROS_INFO_STREAM(&quot;disconnect &quot; &lt;&lt; astr &lt;&lt; &quot;:&quot; &lt;&lt; ntohs(client_addr.sin_port));
					goto delete_buf;
				}
			}

			first = false;
		} else {
			if (curr.mode != prev.mode) {
				ssize_t nbytes = udon_socket::udon::send_mode(connect_fd, curr.mode);
				if (nbytes &lt; 0) {
					ROS_ERROR_STREAM(&quot;udon_socket::udon::send_mode: &quot; &lt;&lt; std::strerror(errno));
					goto delete_buf;
				}
				nbytes = recv(connect_fd, buf, bufsize, 0);
				if (nbytes &lt; 0) {
					ROS_ERROR_STREAM(&quot;recv: &quot; &lt;&lt; std::strerror(errno));
					goto delete_buf;
				} else if (nbytes == 0) {
					ROS_INFO_STREAM(&quot;disconnect &quot; &lt;&lt; astr &lt;&lt; &quot;:&quot; &lt;&lt; ntohs(client_addr.sin_port));
					goto delete_buf;
				}
			}

			if (curr.mode == udon_socket::udon::MODE_AUTO &amp;&amp; curr.location != prev.location) {
				ssize_t nbytes = udon_socket::udon::send_location(connect_fd, curr.location);
				if (nbytes &lt; 0) {
					ROS_ERROR_STREAM(&quot;udon_socket::udon::send_location: &quot; &lt;&lt; std::strerror(errno));
					goto delete_buf;
				}
				nbytes = recv(connect_fd, buf, bufsize, 0);
				if (nbytes &lt; 0) {
					ROS_ERROR_STREAM(&quot;recv: &quot; &lt;&lt; std::strerror(errno));
					goto delete_buf;
				} else if (nbytes == 0) {
					ROS_INFO_STREAM(&quot;disconnect &quot; &lt;&lt; astr &lt;&lt; &quot;:&quot; &lt;&lt; ntohs(client_addr.sin_port));
					goto delete_buf;
				}
			}
		}

		prev = curr;

		std::this_thread::sleep_for(std::chrono::milliseconds(period));
	}

delete_buf:
	delete[] buf;
close_connect_fd:
	close(connect_fd);
}

void accept_sock(int backlog, std::size_t bufsize, int period, std::uint16_t port)
{
	int listen_fd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
	if (listen_fd &lt; 0) {
		ROS_ERROR_STREAM(&quot;socket: &quot; &lt;&lt; std::strerror(errno));
		return;
	}

	const int on = 1;
	if (setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on)) &lt; 0) {
		ROS_ERROR_STREAM(&quot;setsockopt: &quot; &lt;&lt; std::strerror(errno));
		goto close_listen_fd;
	}

	sockaddr_in server_addr;
	std::memset(&amp;server_addr, 0, sizeof(server_addr));
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(port);
	server_addr.sin_addr.s_addr = htonl(INADDR_ANY);
	if (bind(listen_fd, reinterpret_cast&lt;const sockaddr *&gt;(&amp;server_addr), sizeof(server_addr)) &lt; 0) {
		ROS_ERROR_STREAM(&quot;bind: &quot; &lt;&lt; std::strerror(errno));
		goto close_listen_fd;
	}

	if (listen(listen_fd, backlog) &lt; 0) {
		ROS_ERROR_STREAM(&quot;listen: &quot; &lt;&lt; std::strerror(errno));
		goto close_listen_fd;
	}

	char astr[INET_ADDRSTRLEN];
	if (inet_ntop(AF_INET, &amp;server_addr.sin_addr, astr, sizeof(astr)) == nullptr) {
		ROS_ERROR_STREAM(&quot;inet_ntop: &quot; &lt;&lt; std::strerror(errno));
		goto close_listen_fd;
	}
	ROS_INFO_STREAM(&quot;listen &quot; &lt;&lt; astr &lt;&lt; &quot;:&quot; &lt;&lt; ntohs(server_addr.sin_port));

	int connect_fd;
	while (true) {
		sockaddr_in client_addr;
		socklen_t len = sizeof(client_addr);
		connect_fd = accept(listen_fd, reinterpret_cast&lt;sockaddr *&gt;(&amp;client_addr), &amp;len);
		if (connect_fd &lt; 0) {
			ROS_ERROR_STREAM(&quot;accept: &quot; &lt;&lt; std::strerror(errno));
			goto close_listen_fd;
		}

		if (inet_ntop(AF_INET, &amp;client_addr.sin_addr, astr, sizeof(astr)) == nullptr) {
			ROS_ERROR_STREAM(&quot;inet_ntop: &quot; &lt;&lt; std::strerror(errno));
			goto close_connect_fd;
		}
		ROS_INFO_STREAM(&quot;connect &quot; &lt;&lt; astr &lt;&lt; &quot;:&quot; &lt;&lt; ntohs(client_addr.sin_port));

		try {
			std::thread sender(send_info, client_addr, connect_fd, bufsize, period);
			sender.detach();
		} catch (std::exception &amp;ex) {
			ROS_ERROR_STREAM(&quot;std::thread::thread: &quot; &lt;&lt; ex.what());
			goto close_connect_fd;
		}
	}

close_connect_fd:
	close(connect_fd);
close_listen_fd:
	close(listen_fd);
}

} // namespace

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;udon_sender&quot;);

	ros::NodeHandle n;

	int backlog;
	n.param&lt;int&gt;(&quot;/udon_sender/backlog&quot;, backlog, 128);
	int bufsize;
	n.param&lt;int&gt;(&quot;/udon_sender/bufsize&quot;, bufsize, 4096);
	int period;
	n.param&lt;int&gt;(&quot;/udon_sender/period&quot;, period, 200);
	int port;
	n.param&lt;int&gt;(&quot;/udon_sender/port&quot;, port, 5999);
	int sub_mode_queue_size;
	n.param&lt;int&gt;(&quot;/udon_sender/sub_mode_queue_size&quot;, sub_mode_queue_size, 1);
	int sub_pose_queue_size;
	n.param&lt;int&gt;(&quot;/udon_sender/sub_pose_queue_size&quot;, sub_pose_queue_size, 1);
	ROS_INFO_STREAM(&quot;backlog = &quot; &lt;&lt; backlog);
	ROS_INFO_STREAM(&quot;bufsize = &quot; &lt;&lt; bufsize);
	ROS_INFO_STREAM(&quot;period = &quot; &lt;&lt; period);
	ROS_INFO_STREAM(&quot;port = &quot; &lt;&lt; port);
	ROS_INFO_STREAM(&quot;sub_mode_queue_size = &quot; &lt;&lt; sub_mode_queue_size);
	ROS_INFO_STREAM(&quot;sub_pose_queue_size = &quot; &lt;&lt; sub_pose_queue_size);

	ros::Subscriber mode_sub = n.subscribe(&quot;/mode_info&quot;, sub_mode_queue_size, cache_mode);
	ros::Subscriber pose_sub = n.subscribe(&quot;/current_pose&quot;, sub_pose_queue_size, cache_pose);

	try {
		std::thread server(accept_sock, backlog, bufsize, period, port);
		server.detach();
	} catch (std::exception &amp;ex) {
		ROS_ERROR_STREAM(&quot;std::thread::thread: &quot; &lt;&lt; ex.what());
		return EXIT_FAILURE;
	}

	ros::spin();

	return EXIT_SUCCESS;
}
</old_file>
			</file>
			<file old_path="ros/src/socket/packages/vehicle_socket/nodes/vehicle_receiver/vehicle_receiver.cpp" new_path="ros/src/socket/packages/vehicle_socket/nodes/vehicle_receiver/vehicle_receiver.cpp">
				<diff>@@ -30,7 +30,7 @@
 
 #include &lt;ros/ros.h&gt;
 #include &lt;vehicle_socket/CanInfo.h&gt;
-#include &lt;tablet_socket/mode_info.h&gt;
+#include &lt;tablet_socket_msgs/mode_info.h&gt;
 
 #include &lt;iostream&gt;
 #include &lt;string&gt;
@@ -150,7 +150,7 @@ static void* getCanValue(void *arg)
   can_msg.header.stamp = ros::Time::now();
   can_pub.publish(can_msg);
 
-  tablet_socket::mode_info mode_msg;
+  tablet_socket_msgs::mode_info mode_msg;
   mode_msg.header.frame_id = &quot;/mode&quot;;
   mode_msg.header.stamp = ros::Time::now();
   mode_msg.mode = mode;
@@ -229,7 +229,7 @@ int main(int argc, char **argv)
   std::cout &lt;&lt; &quot;vehicle receiver&quot; &lt;&lt; std::endl;
 
   can_pub = nh.advertise&lt;vehicle_socket::CanInfo&gt;(&quot;can_info&quot;, 100);
-  mode_pub = nh.advertise&lt;tablet_socket::mode_info&gt;(&quot;mode_info&quot;, 100);
+  mode_pub = nh.advertise&lt;tablet_socket_msgs::mode_info&gt;(&quot;mode_info&quot;, 100);
 
   pthread_t th;
   int ret = pthread_create(&amp;th, nullptr, receiverCaller, nullptr);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;vehicle_socket/CanInfo.h&gt;
#include &lt;tablet_socket/mode_info.h&gt;

#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;vector&gt;
#include &lt;cstdio&gt;
#include &lt;cstring&gt;
#include &lt;cstdlib&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;

#define CAN_KEY_MODE	(0)
#define CAN_KEY_TIME	(1)
#define CAN_KEY_VELOC	(2)
#define CAN_KEY_ANGLE	(3)
#define CAN_KEY_TORQUE	(4)
#define CAN_KEY_ACCEL	(5)
#define CAN_KEY_BRAKE	(6)
#define CAN_KEY_SHIFT	(7)

static ros::Publisher can_pub;
static ros::Publisher mode_pub;
static int mode;

static bool parseCanValue(const std::string&amp; can_data, vehicle_socket::CanInfo&amp; msg)
{
  std::istringstream ss(can_data);
  std::vector&lt;std::string&gt; columns;

  std::string column;
  while(std::getline(ss, column, ',')){
    columns.push_back(column);
  }

  for (std::size_t i = 0; i &lt; columns.size(); i += 2) {
    int key = std::stoi(columns[i]);
    switch (key) {
    case CAN_KEY_MODE:
      mode = std::stoi(columns[i+1]);
      break;
    case CAN_KEY_TIME:
      msg.tm = columns[i+1].substr(1, columns[i+1].length() - 2); // skip '
      break;
    case CAN_KEY_VELOC:
      msg.speed = std::stod(columns[i+1]);
      break;
    case CAN_KEY_ANGLE:
      msg.angle = std::stod(columns[i+1]);
      break;
    case CAN_KEY_TORQUE:
      msg.torque = std::stoi(columns[i+1]);
      break;
    case CAN_KEY_ACCEL:
      msg.drivepedal = std::stoi(columns[i+1]);
      break;
    case CAN_KEY_BRAKE:
      msg.brakepedal = std::stoi(columns[i+1]);
      break;
    case CAN_KEY_SHIFT:
      msg.driveshift = std::stoi(columns[i+1]);
      break;
    default:
      std::cout &lt;&lt; &quot;Warning: unknown key : &quot; &lt;&lt; key &lt;&lt; std::endl;
    }
  }

  return true;
}

static void* getCanValue(void *arg)
{
  int *client_sockp = static_cast&lt;int*&gt;(arg);
  int sock = *client_sockp;
  delete client_sockp;

  char recvdata[1024];
  std::string can_data(&quot;&quot;);
  constexpr int LIMIT = 1024 * 1024;

  while(true){
    ssize_t n = recv(sock, recvdata, sizeof(recvdata), 0);

    if(n&lt;0){
      std::perror(&quot;recv&quot;);
      can_data = &quot;&quot;;
      break;
    }else if(n == 0){
      break;
    }
    can_data.append(recvdata,n);

    //recv data is bigger than 1M,return error
    if(can_data.size() &gt; LIMIT){
      std::cerr &lt;&lt; &quot;recv data is too big.&quot; &lt;&lt; std::endl;
      can_data = &quot;&quot;;
      break;
    }
  }

  if(close(sock)&lt;0){
    std::perror(&quot;close&quot;);
    return nullptr;
  }

  if(can_data.empty())
    return nullptr;

  vehicle_socket::CanInfo can_msg;
  bool ret = parseCanValue(can_data, can_msg);
  if(!ret)
    return nullptr;

  can_msg.header.frame_id = &quot;/can&quot;;
  can_msg.header.stamp = ros::Time::now();
  can_pub.publish(can_msg);

  tablet_socket::mode_info mode_msg;
  mode_msg.header.frame_id = &quot;/mode&quot;;
  mode_msg.header.stamp = ros::Time::now();
  mode_msg.mode = mode;
  mode_pub.publish(mode_msg);

  return nullptr;
}

static void* receiverCaller(void *unused)
{
  constexpr int listen_port = 10000;

  int sock = socket(AF_INET, SOCK_STREAM, 0);
  if(sock == -1){
    std::perror(&quot;socket&quot;);
    return nullptr;
  }

  sockaddr_in client;
  socklen_t len = sizeof(client);
  sockaddr_in addr;

  std::memset(&amp;addr, 0, sizeof(sockaddr_in));
  addr.sin_family = PF_INET;
  addr.sin_port = htons(listen_port);
  addr.sin_addr.s_addr = INADDR_ANY;
  //make it available immediately to connect
  //setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, (const char *)&amp;yes, sizeof(yes));
  int ret = bind(sock, (sockaddr*)&amp;addr, sizeof(addr));
  if(ret == -1){
    std::perror(&quot;bind&quot;);
    goto error;
  }

  ret = listen(sock, 5);
  if(ret == -1) {
    std::perror(&quot;listen&quot;);
    goto error;
  }

  while(true){
    //get connect to android
    std::cout &lt;&lt; &quot;Waiting access...&quot; &lt;&lt; std::endl;
    int *client_sock = new int();
    *client_sock = accept(sock, reinterpret_cast&lt;sockaddr*&gt;(&amp;client), &amp;len);
    if(*client_sock == -1){
      std::perror(&quot;accept&quot;);
      break;
    }

    std::cout &lt;&lt; &quot;Get connect&quot; &lt;&lt; std::endl;

    pthread_t th;
    if(pthread_create(&amp;th, nullptr, getCanValue, static_cast&lt;void*&gt;(client_sock))){
      std::perror(&quot;pthread_create&quot;);
      break;
    }

    ret = pthread_detach(th);
    if(ret != 0){
      std::perror(&quot;pthread_detach&quot;);
      break;
    }
  }

error:
  close(sock);
  return nullptr;
}

int main(int argc, char **argv)
{
  ros::init(argc ,argv, &quot;vehicle_receiver&quot;);
  ros::NodeHandle nh;

  std::cout &lt;&lt; &quot;vehicle receiver&quot; &lt;&lt; std::endl;

  can_pub = nh.advertise&lt;vehicle_socket::CanInfo&gt;(&quot;can_info&quot;, 100);
  mode_pub = nh.advertise&lt;tablet_socket::mode_info&gt;(&quot;mode_info&quot;, 100);

  pthread_t th;
  int ret = pthread_create(&amp;th, nullptr, receiverCaller, nullptr);
  if (ret != 0) {
    std::perror(&quot;pthread_create&quot;);
    std::exit(1);
  }

  ret = pthread_detach(th);
  if(ret != 0){
    std::perror(&quot;pthread_detach&quot;);
    std::exit(1);
  }

  ros::spin();

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/socket/packages/vehicle_socket/nodes/vehicle_sender/vehicle_sender.cpp" new_path="ros/src/socket/packages/vehicle_socket/nodes/vehicle_sender/vehicle_sender.cpp">
				<diff>@@ -30,12 +30,12 @@
 
 #include &lt;ros/ros.h&gt;
 #include &lt;geometry_msgs/TwistStamped.h&gt;
-#include &lt;tablet_socket/mode_cmd.h&gt;
-#include &lt;tablet_socket/gear_cmd.h&gt;
+#include &lt;tablet_socket_msgs/mode_cmd.h&gt;
+#include &lt;tablet_socket_msgs/gear_cmd.h&gt;
 #include &lt;runtime_manager/accel_cmd.h&gt;
 #include &lt;runtime_manager/brake_cmd.h&gt;
 #include &lt;runtime_manager/steer_cmd.h&gt;
-#include &lt;waypoint_follower/ControlCommandStamped.h&gt;
+#include &lt;waypoint_follower_msgs/ControlCommandStamped.h&gt;
 
 #include &lt;iostream&gt;
 #include &lt;string&gt;
@@ -82,7 +82,7 @@ static void twistCMDCallback(const geometry_msgs::TwistStamped&amp; msg)
   command_data.angular_z = msg.twist.angular.z;
 }
 
-static void modeCMDCallback(const tablet_socket::mode_cmd&amp; mode)
+static void modeCMDCallback(const tablet_socket_msgs::mode_cmd&amp; mode)
 {
   if(mode.mode == -1 || mode.mode == 0){
     command_data.reset();
@@ -91,7 +91,7 @@ static void modeCMDCallback(const tablet_socket::mode_cmd&amp; mode)
   command_data.modeValue = mode.mode;
 }
 
-static void gearCMDCallback(const tablet_socket::gear_cmd&amp; gear)
+static void gearCMDCallback(const tablet_socket_msgs::gear_cmd&amp; gear)
 {
   command_data.gearValue = gear.gear;
 }
@@ -111,7 +111,7 @@ static void brakeCMDCallback(const runtime_manager::brake_cmd &amp;brake)
   command_data.brakeValue = brake.brake;
 }
 
-static void ctrlCMDCallback(const waypoint_follower::ControlCommandStamped&amp; msg)
+static void ctrlCMDCallback(const waypoint_follower_msgs::ControlCommandStamped&amp; msg)
 {
   command_data.linear_velocity = msg.cmd.linear_velocity;
   command_data.steering_angle = msg.cmd.steering_angle;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;tablet_socket/mode_cmd.h&gt;
#include &lt;tablet_socket/gear_cmd.h&gt;
#include &lt;runtime_manager/accel_cmd.h&gt;
#include &lt;runtime_manager/brake_cmd.h&gt;
#include &lt;runtime_manager/steer_cmd.h&gt;
#include &lt;waypoint_follower/ControlCommandStamped.h&gt;

#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;cstdio&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;

struct CommandData {
  double linear_x;
  double angular_z;
  int modeValue;
  int gearValue;
  int accellValue;
  int brakeValue;
  int steerValue;
  double linear_velocity;
  double steering_angle;

  void reset();
};

void CommandData::reset()
{
  linear_x    = 0;
  angular_z   = 0;
  modeValue   = 0;
  gearValue   = 0;
  accellValue = 0;
  brakeValue  = 0;
  steerValue  = 0;
  linear_velocity = -1;
  steering_angle = 0;
}

static CommandData command_data;

static void twistCMDCallback(const geometry_msgs::TwistStamped&amp; msg)
{
  command_data.linear_x = msg.twist.linear.x;
  command_data.angular_z = msg.twist.angular.z;
}

static void modeCMDCallback(const tablet_socket::mode_cmd&amp; mode)
{
  if(mode.mode == -1 || mode.mode == 0){
    command_data.reset();
  }

  command_data.modeValue = mode.mode;
}

static void gearCMDCallback(const tablet_socket::gear_cmd&amp; gear)
{
  command_data.gearValue = gear.gear;
}

static void accellCMDCallback(const runtime_manager::accel_cmd&amp; accell)
{
  command_data.accellValue = accell.accel;
}

static void steerCMDCallback(const runtime_manager::steer_cmd&amp; steer)
{
  command_data.steerValue = steer.steer;
}

static void brakeCMDCallback(const runtime_manager::brake_cmd &amp;brake)
{
  command_data.brakeValue = brake.brake;
}

static void ctrlCMDCallback(const waypoint_follower::ControlCommandStamped&amp; msg)
{
  command_data.linear_velocity = msg.cmd.linear_velocity;
  command_data.steering_angle = msg.cmd.steering_angle;
}

static void *sendCommand(void *arg)
{
  int *client_sockp = static_cast&lt;int*&gt;(arg);
  int client_sock = *client_sockp;
  delete client_sockp;

  std::ostringstream oss;
  oss &lt;&lt; command_data.linear_x &lt;&lt; &quot;,&quot;;
  oss &lt;&lt; command_data.angular_z &lt;&lt; &quot;,&quot;;
  oss &lt;&lt; command_data.modeValue &lt;&lt; &quot;,&quot;;
  oss &lt;&lt; command_data.gearValue &lt;&lt; &quot;,&quot;;
  oss &lt;&lt; command_data.accellValue &lt;&lt; &quot;,&quot;;
  oss &lt;&lt; command_data.brakeValue &lt;&lt; &quot;,&quot;;
  oss &lt;&lt; command_data.steerValue &lt;&lt; &quot;,&quot;;
  oss &lt;&lt; command_data.linear_velocity &lt;&lt; &quot;,&quot;;
  oss &lt;&lt; command_data.steering_angle;

  std::string cmd(oss.str());
  ssize_t n = write(client_sock, cmd.c_str(), cmd.size());
  if(n &lt; 0){
    std::perror(&quot;write&quot;);
    return nullptr;
  }
  
  if(close(client_sock) == -1){
    std::perror(&quot;close&quot;);
    return nullptr;
  }

  std::cout &lt;&lt; &quot;cmd: &quot; &lt;&lt; cmd &lt;&lt; &quot;, size: &quot; &lt;&lt; cmd.size() &lt;&lt; std::endl;
  return nullptr;
}

static void* receiverCaller(void *unused)
{
  constexpr int listen_port = 10001;

  int sock = socket(AF_INET, SOCK_STREAM, 0);
  if(sock == -1){
    std::perror(&quot;socket&quot;);
    return nullptr;
  }

  sockaddr_in addr;
  sockaddr_in client;
  socklen_t len = sizeof(client);

  std::memset(&amp;addr, 0, sizeof(sockaddr_in));
  addr.sin_family = PF_INET;
  addr.sin_port = htons(listen_port);
  addr.sin_addr.s_addr = INADDR_ANY;

  int ret = bind(sock, (struct sockaddr *)&amp;addr, sizeof(addr));
  if(ret == -1){
    std::perror(&quot;bind&quot;);
    goto error;
  }

  ret = listen(sock, 20);
  if(ret == -1){
    std::perror(&quot;listen&quot;);
    goto error;
  }

  while(true){
    //get connect to android
    std::cout &lt;&lt; &quot;Waiting access...&quot; &lt;&lt; std::endl;

    int *client_sock = new int();
    *client_sock = accept(sock, reinterpret_cast&lt;sockaddr*&gt;(&amp;client), &amp;len);
    if(*client_sock == -1){
      std::perror(&quot;accept&quot;);
      break;
    }

    std::cout &lt;&lt; &quot;get connect.&quot; &lt;&lt; std::endl;

    pthread_t th;
    if(pthread_create(&amp;th, nullptr, sendCommand, static_cast&lt;void*&gt;(client_sock)) != 0){
      std::perror(&quot;pthread_create&quot;);
      break;
    }

    if(pthread_detach(th) != 0){
      std::perror(&quot;pthread_detach&quot;);
      break;
    }
  }

error:
  close(sock);
  return nullptr;
}

int main(int argc, char **argv)
{
  ros::init(argc ,argv, &quot;vehicle_sender&quot;) ;
  ros::NodeHandle nh;

  std::cout &lt;&lt; &quot;vehicle sender&quot; &lt;&lt; std::endl;
  ros::Subscriber sub[7];
  sub[0] = nh.subscribe(&quot;/twist_cmd&quot;, 1, twistCMDCallback);
  sub[1] = nh.subscribe(&quot;/mode_cmd&quot;,  1, modeCMDCallback);
  sub[2] = nh.subscribe(&quot;/gear_cmd&quot;,  1, gearCMDCallback);
  sub[3] = nh.subscribe(&quot;/accel_cmd&quot;, 1, accellCMDCallback);
  sub[4] = nh.subscribe(&quot;/steer_cmd&quot;, 1, steerCMDCallback);
  sub[5] = nh.subscribe(&quot;/brake_cmd&quot;, 1, brakeCMDCallback);
  sub[6] = nh.subscribe(&quot;/ctrl_cmd&quot;, 1, ctrlCMDCallback);

  command_data.reset();

  pthread_t th;
  if(pthread_create(&amp;th, nullptr, receiverCaller, nullptr) != 0){
    std::perror(&quot;pthread_create&quot;);
    std::exit(1);
  }

  if (pthread_detach(th) != 0){
    std::perror(&quot;pthread_detach&quot;);
    std::exit(1);
  }

  ros::spin();
  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/system/sync/computing/perception/detection/packages/cv_tracker/nodes/kf_track/sync_track.cpp" new_path="ros/src/system/sync/computing/perception/detection/packages/cv_tracker/nodes/kf_track/sync_track.cpp">
				<diff>@@ -1,7 +1,7 @@
 #include &quot;ros/ros.h&quot;
 #include &quot;sensor_msgs/Image.h&quot;
-#include &quot;cv_tracker/image_obj_tracked.h&quot;
-#include &quot;cv_tracker/image_obj_ranged.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_tracked.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
 #include &quot;sync.hpp&quot;
 
 int main(int argc, char **argv) {
@@ -13,7 +13,7 @@ int main(int argc, char **argv) {
     std::string pub1(&quot;/image_obj_ranged&quot;);
     std::string pub2(&quot;/image_raw&quot;);
 
-    Synchronizer&lt;cv_tracker::image_obj_ranged, sensor_msgs::Image, cv_tracker::image_obj_tracked&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
+    Synchronizer&lt;cv_tracker_msgs::image_obj_ranged, sensor_msgs::Image, cv_tracker_msgs::image_obj_tracked&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
     synchronizer.run();
 
     return 0;
@@ -40,8 +40,8 @@ int main(int argc, char **argv) {
 #include &quot;t_sync_message.h&quot;
 /* user header */
 #include &quot;sensor_msgs/Image.h&quot;
-#include &quot;cv_tracker/image_obj_tracked.h&quot;
-#include &quot;cv_tracker/image_obj_ranged.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_tracked.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
 
 /* ----mode---- */
 #define _REQ_PUB 1
@@ -51,7 +51,7 @@ int main(int argc, char **argv) {
 bool buf_flag;
 pthread_mutex_t mutex;
 /* user var */
-boost::circular_buffer&lt;cv_tracker::image_obj_ranged&gt; image_obj_ranged_ringbuf(10);
+boost::circular_buffer&lt;cv_tracker_msgs::image_obj_ranged&gt; image_obj_ranged_ringbuf(10);
 boost::circular_buffer&lt;sensor_msgs::Image&gt; image_raw_ringbuf(10);
 ros::Publisher image_obj_ranged__pub;
 ros::Publisher image_raw__pub;
@@ -71,10 +71,10 @@ double get_time(const std_msgs::Header *timespec) {
 
 
 #if _REQ_PUB
-cv_tracker::image_obj_ranged* p_image_obj_ranged_buf;
+cv_tracker_msgs::image_obj_ranged* p_image_obj_ranged_buf;
 sensor_msgs::Image* p_image_raw_buf;
 
-void publish_msg(cv_tracker::image_obj_ranged* p_image_obj_ranged_buf, sensor_msgs::Image* p_image_raw_buf) {
+void publish_msg(cv_tracker_msgs::image_obj_ranged* p_image_obj_ranged_buf, sensor_msgs::Image* p_image_raw_buf) {
     ROS_INFO(&quot;publish&quot;);
     image_obj_ranged__pub.publish(*p_image_obj_ranged_buf);
     image_raw__pub.publish(*p_image_raw_buf);
@@ -97,7 +97,7 @@ bool publish() {
         // image_obj_ranged &gt; image_raw
         if (get_time(&amp;(image_obj_ranged_ringbuf.front().header)) &gt;= get_time(&amp;(image_raw_ringbuf.front().header))) {
             p_image_raw_buf = &amp;(image_raw_ringbuf.front());
-            boost::circular_buffer&lt;cv_tracker::image_obj_ranged&gt;::iterator it = image_obj_ranged_ringbuf.begin();
+            boost::circular_buffer&lt;cv_tracker_msgs::image_obj_ranged&gt;::iterator it = image_obj_ranged_ringbuf.begin();
             if (image_obj_ranged_ringbuf.size() == 1) {
                 p_image_obj_ranged_buf = &amp;*it;
                 publish_msg(p_image_obj_ranged_buf, p_image_raw_buf);
@@ -163,7 +163,7 @@ bool publish() {
     }
 }
 
-void image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
+void image_obj_ranged_callback(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
     pthread_mutex_lock(&amp;mutex);
     image_obj_ranged_ringbuf.push_front(*image_obj_ranged_msg);
     //image_raw is empty
@@ -203,7 +203,7 @@ void image_raw_callback(const sensor_msgs::Image::ConstPtr&amp; image_raw_msg) {
 #else
 #endif
 
-void image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
+void image_obj_tracked_callback(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
     pthread_mutex_lock(&amp;mutex);
     image_obj_tracked_flag = true;
     ROS_INFO(&quot;catch publish request&quot;);
@@ -252,7 +252,7 @@ int main(int argc, char **argv) {
 
     ros::Subscriber image_obj_ranged_sub = nh.subscribe(&quot;/image_obj_ranged&quot;, 1, image_obj_ranged_callback);
     ros::Subscriber image_raw_sub = nh.subscribe(&quot;/sync_drivers/image_raw&quot;, 1, image_raw_callback);
-    image_obj_ranged__pub = nh.advertise&lt;cv_tracker::image_obj_ranged&gt;(&quot;/sync_tracking/image_obj_ranged&quot;, 5);
+    image_obj_ranged__pub = nh.advertise&lt;cv_tracker_msgs::image_obj_ranged&gt;(&quot;/sync_tracking/image_obj_ranged&quot;, 5);
     image_raw__pub = nh.advertise&lt;sensor_msgs::Image&gt;(&quot;/sync_tracking/image_raw&quot;, 5);
 
     while ((!buf_flag) &amp;&amp; ros::ok()) {
@@ -284,10 +284,10 @@ int main(int argc, char **argv) {
 
 
 #if 0
-cv_tracker::image_obj_ranged image_obj_ranged_buf;
+cv_tracker_msgs::image_obj_ranged image_obj_ranged_buf;
 sensor_msgs::Image image_raw_buf;
 
-void image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
+void image_obj_ranged_callback(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
     pthread_mutex_lock(&amp;mutex);
     image_obj_ranged_ringbuf.push_front(*image_obj_ranged_msg);
 
@@ -303,7 +303,7 @@ void image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; ima
     // image_obj_ranged &gt; image_raw
     if (get_time(&amp;(image_obj_ranged_ringbuf.front().header)) &gt;= get_time(&amp;(image_raw_ringbuf.front().header))) {
         image_raw_buf = image_raw_ringbuf.front();
-        boost::circular_buffer&lt;cv_tracker::image_obj_ranged&gt;::iterator it = image_obj_ranged_ringbuf.begin();
+        boost::circular_buffer&lt;cv_tracker_msgs::image_obj_ranged&gt;::iterator it = image_obj_ranged_ringbuf.begin();
         if (image_obj_ranged_ringbuf.size() == 1) {
             image_obj_ranged_buf = *it;
             pthread_mutex_unlock(&amp;mutex);
@@ -360,7 +360,7 @@ void image_raw_callback(const sensor_msgs::Image::ConstPtr&amp; image_raw_msg) {
     // image_obj_ranged &gt; image_raw
     if (get_time(&amp;(image_obj_ranged_ringbuf.front().header)) &gt;= get_time(&amp;(image_raw_ringbuf.front().header))) {
         image_raw_buf = image_raw_ringbuf.front();
-        boost::circular_buffer&lt;cv_tracker::image_obj_ranged&gt;::iterator it = image_obj_ranged_ringbuf.begin();
+        boost::circular_buffer&lt;cv_tracker_msgs::image_obj_ranged&gt;::iterator it = image_obj_ranged_ringbuf.begin();
         if (image_obj_ranged_ringbuf.size() == 1) {
             image_obj_ranged_buf = *it;
             pthread_mutex_unlock(&amp;mutex);
</diff>
				<old_file>#include &quot;ros/ros.h&quot;
#include &quot;sensor_msgs/Image.h&quot;
#include &quot;cv_tracker/image_obj_tracked.h&quot;
#include &quot;cv_tracker/image_obj_ranged.h&quot;
#include &quot;sync.hpp&quot;

int main(int argc, char **argv) {
    ros::init(argc, argv, &quot;sync_tracking&quot;);
    std::string ns(ros::this_node::getNamespace());
    std::string sub1(&quot;/image_obj_ranged&quot;);
    std::string sub2(&quot;/sync_drivers/image_raw&quot;);
    std::string req(&quot;/image_obj_tracked&quot;);
    std::string pub1(&quot;/image_obj_ranged&quot;);
    std::string pub2(&quot;/image_raw&quot;);

    Synchronizer&lt;cv_tracker::image_obj_ranged, sensor_msgs::Image, cv_tracker::image_obj_tracked&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
    synchronizer.run();

    return 0;
}

#if 0
/* ----header---- */
/* common header */
#include &quot;ros/ros.h&quot;
#include &lt;ros/callback_queue.h&gt;
#include &lt;boost/circular_buffer.hpp&gt;
#include &lt;vector&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;signal.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;sys/select.h&gt;
#include &lt;mqueue.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;errno.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;
#include &quot;t_sync_message.h&quot;
/* user header */
#include &quot;sensor_msgs/Image.h&quot;
#include &quot;cv_tracker/image_obj_tracked.h&quot;
#include &quot;cv_tracker/image_obj_ranged.h&quot;

/* ----mode---- */
#define _REQ_PUB 1

/* ----var---- */
/* common var */
bool buf_flag;
pthread_mutex_t mutex;
/* user var */
boost::circular_buffer&lt;cv_tracker::image_obj_ranged&gt; image_obj_ranged_ringbuf(10);
boost::circular_buffer&lt;sensor_msgs::Image&gt; image_raw_ringbuf(10);
ros::Publisher image_obj_ranged__pub;
ros::Publisher image_raw__pub;
bool image_obj_tracked_flag;

/* ----function---- */
double fabs_time_diff(std_msgs::Header *timespec1, std_msgs::Header *timespec2) {
    double time1 = (double)timespec1-&gt;stamp.sec + (double)timespec1-&gt;stamp.nsec/1000000000L;
    double time2 = (double)timespec2-&gt;stamp.sec + (double)timespec2-&gt;stamp.nsec/1000000000L;

    return fabs(time1 - time2);
}

double get_time(const std_msgs::Header *timespec) {
    return (double)timespec-&gt;stamp.sec + (double)timespec-&gt;stamp.nsec/1000000000L;
}


#if _REQ_PUB
cv_tracker::image_obj_ranged* p_image_obj_ranged_buf;
sensor_msgs::Image* p_image_raw_buf;

void publish_msg(cv_tracker::image_obj_ranged* p_image_obj_ranged_buf, sensor_msgs::Image* p_image_raw_buf) {
    ROS_INFO(&quot;publish&quot;);
    image_obj_ranged__pub.publish(*p_image_obj_ranged_buf);
    image_raw__pub.publish(*p_image_raw_buf);
}

bool publish() {
    if (buf_flag) {
        //image_obj_ranged is empty
        if (image_obj_ranged_ringbuf.begin() == image_obj_ranged_ringbuf.end()) {
            ROS_INFO(&quot;image_obj_ranged ring buffer is empty&quot;);
            return false;
        }

        //image_raw is empty
        if (image_raw_ringbuf.begin() == image_raw_ringbuf.end()) {
            ROS_INFO(&quot;image_raw ring buffer is empty&quot;);
            return false;
        }

        // image_obj_ranged &gt; image_raw
        if (get_time(&amp;(image_obj_ranged_ringbuf.front().header)) &gt;= get_time(&amp;(image_raw_ringbuf.front().header))) {
            p_image_raw_buf = &amp;(image_raw_ringbuf.front());
            boost::circular_buffer&lt;cv_tracker::image_obj_ranged&gt;::iterator it = image_obj_ranged_ringbuf.begin();
            if (image_obj_ranged_ringbuf.size() == 1) {
                p_image_obj_ranged_buf = &amp;*it;
                publish_msg(p_image_obj_ranged_buf, p_image_raw_buf);
                if (image_obj_tracked_flag == true){
                    buf_flag = false;
                    image_obj_tracked_flag = false;
                    image_obj_ranged_ringbuf.clear();
                    image_raw_ringbuf.clear();
                }
                return true;
            } else {
                for (it++; it != image_obj_ranged_ringbuf.end(); it++) {
                    if (fabs_time_diff(&amp;(image_raw_ringbuf.front().header), &amp;((it-1)-&gt;header))
                        &lt; fabs_time_diff(&amp;(image_raw_ringbuf.front().header), &amp;(it-&gt;header))) {
                        p_image_obj_ranged_buf = &amp;*(it-1);
                        break;
                    }
                }
                if (it == image_obj_ranged_ringbuf.end()) {
                    p_image_obj_ranged_buf = &amp;(image_obj_ranged_ringbuf.back());
                }
            }
        }
        // image_obj_ranged &lt; image_raw
        else {
            p_image_obj_ranged_buf = &amp;(image_obj_ranged_ringbuf.front());
            boost::circular_buffer&lt;sensor_msgs::Image&gt;::iterator it = image_raw_ringbuf.begin();
            if (image_raw_ringbuf.size() == 1) {
                p_image_raw_buf = &amp;*it;
                publish_msg(p_image_obj_ranged_buf, p_image_raw_buf);
                if (image_obj_tracked_flag == true){
                    buf_flag = false;
                    image_obj_tracked_flag = false;
                    image_obj_ranged_ringbuf.clear();
                    image_raw_ringbuf.clear();
                }
                return true;
            }

            for (it++; it != image_raw_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(image_obj_ranged_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(image_obj_ranged_ringbuf.front().header), &amp;(it-&gt;header))) {
                    p_image_raw_buf = &amp;*(it-1);
                    break;
                }
            }

            if (it == image_raw_ringbuf.end()) {
                p_image_raw_buf = &amp;(image_raw_ringbuf.back());
            }
        }
        publish_msg(p_image_obj_ranged_buf, p_image_raw_buf);
        if (image_obj_tracked_flag == true){
            buf_flag = false;
            image_obj_tracked_flag = false;
            image_obj_ranged_ringbuf.clear();
            image_raw_ringbuf.clear();
        }

        return true;
    } else {
        return false;
    }
}

void image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_obj_ranged_ringbuf.push_front(*image_obj_ranged_msg);
    //image_raw is empty
    if (image_raw_ringbuf.begin() == image_raw_ringbuf.end()) {
        ROS_INFO(&quot;image_raw ring buffer is empty&quot;);
        buf_flag = false;
        pthread_mutex_unlock(&amp;mutex);
        return;
    }
    buf_flag = true;
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (image_obj_tracked_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}

void image_raw_callback(const sensor_msgs::Image::ConstPtr&amp; image_raw_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_raw_ringbuf.push_front(*image_raw_msg);
    //image_obj_ranged is empty
    if (image_obj_ranged_ringbuf.begin() == image_obj_ranged_ringbuf.end()) {
        ROS_INFO(&quot;image_obj_ranged ring buffer is empty&quot;);
        buf_flag = false;
        pthread_mutex_unlock(&amp;mutex);
        return;
    }
    buf_flag = true;
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (image_obj_tracked_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}
#else
#endif

void image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_obj_tracked_flag = true;
    ROS_INFO(&quot;catch publish request&quot;);
    if (publish() == false) {
        ROS_INFO(&quot;waitting...&quot;);
    }
    pthread_mutex_unlock(&amp;mutex);
}

void* thread(void* args) {
    ros::NodeHandle nh_rcv;
    ros::CallbackQueue rcv_callbackqueue;
    nh_rcv.setCallbackQueue(&amp;rcv_callbackqueue);
    ros::Subscriber image_obj_tracked_sub = nh_rcv.subscribe(&quot;/image_obj_tracked&quot;, 1, image_obj_tracked_callback);
    while (nh_rcv.ok()) {
        rcv_callbackqueue.callAvailable(ros::WallDuration(3.0f));
        pthread_mutex_lock(&amp;mutex);
        bool flag = (image_obj_tracked_flag == false &amp;&amp; buf_flag == true);
        if (flag) {
            ROS_INFO(&quot;timeout&quot;);
            if(!publish()) {
                /* when to publish is failure, republish */
                struct timespec sleep_time;
                sleep_time.tv_sec = 0;
                sleep_time.tv_nsec = 200000000; //5Hz
                while (!publish() &amp;&amp; ros::ok())
                    nanosleep(&amp;sleep_time, NULL);
            }
        }
        pthread_mutex_unlock(&amp;mutex);

    }
    return NULL;
}

int main(int argc, char **argv) {
    /* init */
    buf_flag = false;
    image_obj_tracked_flag = false;
    ros::init(argc, argv, &quot;sync_tracking&quot;);
    ros::NodeHandle nh;

    /* create server thread */
    pthread_t th;
    pthread_create(&amp;th, NULL, thread, (void *)NULL );

    ros::Subscriber image_obj_ranged_sub = nh.subscribe(&quot;/image_obj_ranged&quot;, 1, image_obj_ranged_callback);
    ros::Subscriber image_raw_sub = nh.subscribe(&quot;/sync_drivers/image_raw&quot;, 1, image_raw_callback);
    image_obj_ranged__pub = nh.advertise&lt;cv_tracker::image_obj_ranged&gt;(&quot;/sync_tracking/image_obj_ranged&quot;, 5);
    image_raw__pub = nh.advertise&lt;sensor_msgs::Image&gt;(&quot;/sync_tracking/image_raw&quot;, 5);

    while ((!buf_flag) &amp;&amp; ros::ok()) {
        ros::spinOnce();
        usleep(100000);
    }
    pthread_mutex_lock(&amp;mutex);
    if(!publish()) {
        /* when to publish is failure, republish */
        struct timespec sleep_time;
        sleep_time.tv_sec = 0;
        sleep_time.tv_nsec = 200000000; //5Hz
        while (!publish() || ros::ok())
            nanosleep(&amp;sleep_time, NULL);
    }
    pthread_mutex_unlock(&amp;mutex);

    ros::spin();
    pthread_mutex_unlock(&amp;mutex);

    /* shutdown server thread */
    ROS_INFO(&quot;wait until shutdown a thread&quot;);
    pthread_kill(th, SIGINT);
    pthread_join(th, NULL);

    return 0;
}



#if 0
cv_tracker::image_obj_ranged image_obj_ranged_buf;
sensor_msgs::Image image_raw_buf;

void image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_obj_ranged_ringbuf.push_front(*image_obj_ranged_msg);

    //image_raw is empty
    if (image_raw_ringbuf.begin() == image_raw_ringbuf.end()) {
        pthread_mutex_unlock(&amp;mutex);
        ROS_INFO(&quot;image_raw ring buffer is empty&quot;);
        return;
    }

    buf_flag = true;

    // image_obj_ranged &gt; image_raw
    if (get_time(&amp;(image_obj_ranged_ringbuf.front().header)) &gt;= get_time(&amp;(image_raw_ringbuf.front().header))) {
        image_raw_buf = image_raw_ringbuf.front();
        boost::circular_buffer&lt;cv_tracker::image_obj_ranged&gt;::iterator it = image_obj_ranged_ringbuf.begin();
        if (image_obj_ranged_ringbuf.size() == 1) {
            image_obj_ranged_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            return;
        } else {
            for (it++; it != image_obj_ranged_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(image_raw_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(image_raw_ringbuf.front().header), &amp;(it-&gt;header))) {
                    image_obj_ranged_buf = *(it-1);
                    break;
                }
            }
            if (it == image_obj_ranged_ringbuf.end()) {
                image_obj_ranged_buf = image_obj_ranged_ringbuf.back();
            }
        }

    } else {
        image_obj_ranged_buf = image_obj_ranged_ringbuf.front();
        boost::circular_buffer&lt;sensor_msgs::Image&gt;::iterator it = image_raw_ringbuf.begin();
        if (image_raw_ringbuf.size() == 1) {
            image_raw_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            return;
        }

        for (it++; it != image_raw_ringbuf.end(); it++) {
            if (fabs_time_diff(&amp;(image_obj_ranged_ringbuf.front().header), &amp;((it-1)-&gt;header))
                &lt; fabs_time_diff(&amp;(image_obj_ranged_ringbuf.front().header), &amp;(it-&gt;header))) {
                image_raw_buf = *(it-1);
                break;
            }
        }

        if (it == image_raw_ringbuf.end()) {
            image_raw_buf = image_raw_ringbuf.back();
        }
    }
    pthread_mutex_unlock(&amp;mutex);
}

void image_raw_callback(const sensor_msgs::Image::ConstPtr&amp; image_raw_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_raw_ringbuf.push_front(*image_raw_msg);
    //image_obj_ranged is empty
    if (image_obj_ranged_ringbuf.begin() == image_obj_ranged_ringbuf.end()) {
        ROS_INFO(&quot;image_obj_ranged ring buffer is empty&quot;);
        pthread_mutex_unlock(&amp;mutex);
        return;
    }

    buf_flag = true;

    // image_obj_ranged &gt; image_raw
    if (get_time(&amp;(image_obj_ranged_ringbuf.front().header)) &gt;= get_time(&amp;(image_raw_ringbuf.front().header))) {
        image_raw_buf = image_raw_ringbuf.front();
        boost::circular_buffer&lt;cv_tracker::image_obj_ranged&gt;::iterator it = image_obj_ranged_ringbuf.begin();
        if (image_obj_ranged_ringbuf.size() == 1) {
            image_obj_ranged_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            return;
        } else {
            for (it++; it != image_obj_ranged_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(image_raw_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(image_raw_ringbuf.front().header), &amp;(it-&gt;header))) {
                    image_obj_ranged_buf = *(it-1);
                    break;
                }
            }
            if (it == image_obj_ranged_ringbuf.end()) {
                image_obj_ranged_buf = image_obj_ranged_ringbuf.back();
            }
        }

    } else {
        image_obj_ranged_buf = image_obj_ranged_ringbuf.front();
        boost::circular_buffer&lt;sensor_msgs::Image&gt;::iterator it = image_raw_ringbuf.begin();
        if (image_raw_ringbuf.size() == 1) {
            image_raw_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            return;
        }

        for (it++; it != image_raw_ringbuf.end(); it++) {
            if (fabs_time_diff(&amp;(image_obj_ranged_ringbuf.front().header), &amp;((it-1)-&gt;header))
                &lt; fabs_time_diff(&amp;(image_obj_ranged_ringbuf.front().header), &amp;(it-&gt;header))) {
                image_raw_buf = *(it-1);
                break;
            }
        }

        if (it == image_raw_ringbuf.end()) {
            image_raw_buf = image_raw_ringbuf.back();
        }
    }
    pthread_mutex_unlock(&amp;mutex);
}

bool publish() {
    if (buf_flag) {
        pthread_mutex_lock(&amp;mutex);
        // scan_ringbuf.clear();
        // image_ringbuf.clear();
        // scan_ringbuf.push_front(scan_buf);
        // image_ringbuf.push_front(image_buf);
        ROS_INFO(&quot;publish&quot;);
        image_obj_ranged__pub.publish(image_obj_ranged_buf);
        image_raw__pub.publish(image_raw_buf);
        pthread_mutex_unlock(&amp;mutex);
        return true;
    } else {
        ROS_INFO(&quot;publish failed&quot;);
        return false;
    }
}

#endif
#endif
</old_file>
			</file>
			<file old_path="ros/src/system/sync/computing/perception/detection/packages/cv_tracker/nodes/obj_reproj/sync_obj_reproj.cpp" new_path="ros/src/system/sync/computing/perception/detection/packages/cv_tracker/nodes/obj_reproj/sync_obj_reproj.cpp">
				<diff>@@ -1,7 +1,7 @@
 #include &quot;ros/ros.h&quot;
-#include &quot;cv_tracker/image_obj_tracked.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_tracked.h&quot;
 #include &quot;geometry_msgs/PoseStamped.h&quot;
-#include &quot;cv_tracker/obj_label.h&quot;
+#include &quot;cv_tracker_msgs/obj_label.h&quot;
 #include &quot;sync.hpp&quot;
 
 int main(int argc, char **argv) {
@@ -13,7 +13,7 @@ int main(int argc, char **argv) {
     std::string pub1(&quot;/image_obj_tracked&quot;);
     std::string pub2(&quot;/current_pose&quot;);
 
-    Synchronizer&lt;cv_tracker::image_obj_tracked, geometry_msgs::PoseStamped, cv_tracker::obj_label&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
+    Synchronizer&lt;cv_tracker_msgs::image_obj_tracked, geometry_msgs::PoseStamped, cv_tracker_msgs::obj_label&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
     synchronizer.run();
 
     return 0;
@@ -39,9 +39,9 @@ int main(int argc, char **argv) {
 #include &lt;pthread.h&gt;
 #include &quot;t_sync_message.h&quot;
 /* user header */
-#include &quot;cv_tracker/image_obj_tracked.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_tracked.h&quot;
 #include &quot;geometry_msgs/PoseStamped.h&quot;
-#include &quot;cv_tracker/obj_label.h&quot;
+#include &quot;cv_tracker_msgs/obj_label.h&quot;
 
 /* ----mode---- */
 #define _REQ_PUB 1
@@ -51,7 +51,7 @@ int main(int argc, char **argv) {
 bool buf_flag;
 pthread_mutex_t mutex;
 /* user var */
-boost::circular_buffer&lt;cv_tracker::image_obj_tracked&gt; image_obj_tracked_ringbuf(10);
+boost::circular_buffer&lt;cv_tracker_msgs::image_obj_tracked&gt; image_obj_tracked_ringbuf(10);
 boost::circular_buffer&lt;geometry_msgs::PoseStamped&gt; current_pose_ringbuf(10);
 ros::Publisher image_obj_tracked__pub;
 ros::Publisher current_pose__pub;
@@ -71,10 +71,10 @@ double get_time(const std_msgs::Header *timespec) {
 
 
 #if _REQ_PUB
-cv_tracker::image_obj_tracked* p_image_obj_tracked_buf;
+cv_tracker_msgs::image_obj_tracked* p_image_obj_tracked_buf;
 geometry_msgs::PoseStamped* p_current_pose_buf;
 
-void publish_msg(cv_tracker::image_obj_tracked* p_image_obj_tracked_buf, geometry_msgs::PoseStamped* p_current_pose_buf) {
+void publish_msg(cv_tracker_msgs::image_obj_tracked* p_image_obj_tracked_buf, geometry_msgs::PoseStamped* p_current_pose_buf) {
     ROS_INFO(&quot;publish&quot;);
     image_obj_tracked__pub.publish(*p_image_obj_tracked_buf);
     current_pose__pub.publish(*p_current_pose_buf);
@@ -97,7 +97,7 @@ bool publish() {
         // image_obj_tracked &gt; current_pose
         if (get_time(&amp;(image_obj_tracked_ringbuf.front().header)) &gt;= get_time(&amp;(current_pose_ringbuf.front().header))) {
             p_current_pose_buf = &amp;(current_pose_ringbuf.front());
-            boost::circular_buffer&lt;cv_tracker::image_obj_tracked&gt;::iterator it = image_obj_tracked_ringbuf.begin();
+            boost::circular_buffer&lt;cv_tracker_msgs::image_obj_tracked&gt;::iterator it = image_obj_tracked_ringbuf.begin();
             if (image_obj_tracked_ringbuf.size() == 1) {
                 p_image_obj_tracked_buf = &amp;*it;
                 publish_msg(p_image_obj_tracked_buf, p_current_pose_buf);
@@ -163,7 +163,7 @@ bool publish() {
     }
 }
 
-void image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
+void image_obj_tracked_callback(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
     pthread_mutex_lock(&amp;mutex);
     image_obj_tracked_ringbuf.push_front(*image_obj_tracked_msg);
     //current_pose is empty
@@ -204,7 +204,7 @@ void current_pose_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; current_p
 #else
 #endif
 
-void obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) {
+void obj_label_callback(const cv_tracker_msgs::obj_label::ConstPtr&amp; obj_label_msg) {
     pthread_mutex_lock(&amp;mutex);
     obj_label_flag = true;
     ROS_INFO(&quot;catch publish request&quot;);
@@ -252,7 +252,7 @@ int main(int argc, char **argv) {
 
     ros::Subscriber image_obj_tracked_sub = nh.subscribe(&quot;/image_obj_tracked&quot;, 1, image_obj_tracked_callback);
     ros::Subscriber current_pose_sub = nh.subscribe(&quot;/current_pose&quot;, 1, current_pose_callback);
-    image_obj_tracked__pub = nh.advertise&lt;cv_tracker::image_obj_tracked&gt;(&quot;/sync_reprojection/image_obj_tracked&quot;, 5);
+    image_obj_tracked__pub = nh.advertise&lt;cv_tracker_msgs::image_obj_tracked&gt;(&quot;/sync_reprojection/image_obj_tracked&quot;, 5);
     current_pose__pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/sync_reprojection/current_pose&quot;, 5);
 
     while (!buf_flag &amp;&amp; ros::ok()) {
@@ -281,10 +281,10 @@ int main(int argc, char **argv) {
 }
 
 #if 0
-cv_tracker::image_obj_tracked image_obj_tracked_buf;
+cv_tracker_msgs::image_obj_tracked image_obj_tracked_buf;
 geometry_msgs::PoseStamped current_pose_buf;
 
-void image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
+void image_obj_tracked_callback(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
     pthread_mutex_lock(&amp;mutex);
     image_obj_tracked_ringbuf.push_front(*image_obj_tracked_msg);
 
@@ -300,7 +300,7 @@ void image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; i
     // image_obj_tracked &gt; current_pose
     if (get_time(&amp;(image_obj_tracked_ringbuf.front().header)) &gt;= get_time(&amp;(current_pose_ringbuf.front().header))) {
         current_pose_buf = current_pose_ringbuf.front();
-        boost::circular_buffer&lt;cv_tracker::image_obj_tracked&gt;::iterator it = image_obj_tracked_ringbuf.begin();
+        boost::circular_buffer&lt;cv_tracker_msgs::image_obj_tracked&gt;::iterator it = image_obj_tracked_ringbuf.begin();
         if (image_obj_tracked_ringbuf.size() == 1) {
             image_obj_tracked_buf = *it;
             pthread_mutex_unlock(&amp;mutex);
@@ -372,7 +372,7 @@ void current_pose_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; current_p
     // image_obj_tracked &gt; current_pose
     if (get_time(&amp;(image_obj_tracked_ringbuf.front().header)) &gt;= get_time(&amp;(current_pose_ringbuf.front().header))) {
         current_pose_buf = current_pose_ringbuf.front();
-        boost::circular_buffer&lt;cv_tracker::image_obj_tracked&gt;::iterator it = image_obj_tracked_ringbuf.begin();
+        boost::circular_buffer&lt;cv_tracker_msgs::image_obj_tracked&gt;::iterator it = image_obj_tracked_ringbuf.begin();
         if (image_obj_tracked_ringbuf.size() == 1) {
             image_obj_tracked_buf = *it;
             pthread_mutex_unlock(&amp;mutex);
</diff>
				<old_file>#include &quot;ros/ros.h&quot;
#include &quot;cv_tracker/image_obj_tracked.h&quot;
#include &quot;geometry_msgs/PoseStamped.h&quot;
#include &quot;cv_tracker/obj_label.h&quot;
#include &quot;sync.hpp&quot;

int main(int argc, char **argv) {
    ros::init(argc, argv, &quot;sync_reprojection&quot;);
    std::string ns(ros::this_node::getNamespace());
    std::string sub1(&quot;/image_obj_tracked&quot;);
    std::string sub2(&quot;/current_pose&quot;);
    std::string req(&quot;/obj_label&quot;);
    std::string pub1(&quot;/image_obj_tracked&quot;);
    std::string pub2(&quot;/current_pose&quot;);

    Synchronizer&lt;cv_tracker::image_obj_tracked, geometry_msgs::PoseStamped, cv_tracker::obj_label&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
    synchronizer.run();

    return 0;
}

#if 0
/* ----header---- */
/* common header */
#include &quot;ros/ros.h&quot;
#include &lt;ros/callback_queue.h&gt;
#include &lt;boost/circular_buffer.hpp&gt;
#include &lt;vector&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;signal.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;sys/select.h&gt;
#include &lt;mqueue.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;errno.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;
#include &quot;t_sync_message.h&quot;
/* user header */
#include &quot;cv_tracker/image_obj_tracked.h&quot;
#include &quot;geometry_msgs/PoseStamped.h&quot;
#include &quot;cv_tracker/obj_label.h&quot;

/* ----mode---- */
#define _REQ_PUB 1

/* ----var---- */
/* common var */
bool buf_flag;
pthread_mutex_t mutex;
/* user var */
boost::circular_buffer&lt;cv_tracker::image_obj_tracked&gt; image_obj_tracked_ringbuf(10);
boost::circular_buffer&lt;geometry_msgs::PoseStamped&gt; current_pose_ringbuf(10);
ros::Publisher image_obj_tracked__pub;
ros::Publisher current_pose__pub;
bool obj_label_flag;

/* ----function---- */
double fabs_time_diff(std_msgs::Header *timespec1, std_msgs::Header *timespec2) {
    double time1 = (double)timespec1-&gt;stamp.sec + (double)timespec1-&gt;stamp.nsec/1000000000L;
    double time2 = (double)timespec2-&gt;stamp.sec + (double)timespec2-&gt;stamp.nsec/1000000000L;

    return fabs(time1 - time2);
}

double get_time(const std_msgs::Header *timespec) {
    return (double)timespec-&gt;stamp.sec + (double)timespec-&gt;stamp.nsec/1000000000L;
}


#if _REQ_PUB
cv_tracker::image_obj_tracked* p_image_obj_tracked_buf;
geometry_msgs::PoseStamped* p_current_pose_buf;

void publish_msg(cv_tracker::image_obj_tracked* p_image_obj_tracked_buf, geometry_msgs::PoseStamped* p_current_pose_buf) {
    ROS_INFO(&quot;publish&quot;);
    image_obj_tracked__pub.publish(*p_image_obj_tracked_buf);
    current_pose__pub.publish(*p_current_pose_buf);
}

bool publish() {
    if (buf_flag) {
        //image_obj_tracked is empty
        if (image_obj_tracked_ringbuf.begin() == image_obj_tracked_ringbuf.end()) {
            ROS_INFO(&quot;image_obj_tracked ring buffer is empty&quot;);
            return false;
        }

        //current_pose is empty
        if (current_pose_ringbuf.begin() == current_pose_ringbuf.end()) {
            ROS_INFO(&quot;current_pose ring buffer is empty&quot;);
            return false;
        }

        // image_obj_tracked &gt; current_pose
        if (get_time(&amp;(image_obj_tracked_ringbuf.front().header)) &gt;= get_time(&amp;(current_pose_ringbuf.front().header))) {
            p_current_pose_buf = &amp;(current_pose_ringbuf.front());
            boost::circular_buffer&lt;cv_tracker::image_obj_tracked&gt;::iterator it = image_obj_tracked_ringbuf.begin();
            if (image_obj_tracked_ringbuf.size() == 1) {
                p_image_obj_tracked_buf = &amp;*it;
                publish_msg(p_image_obj_tracked_buf, p_current_pose_buf);
                if (obj_label_flag == true){
                    buf_flag = false;
                    obj_label_flag = false;
                    image_obj_tracked_ringbuf.clear();
                    current_pose_ringbuf.clear();
                }
                return true;
            } else {
                for (it++; it != image_obj_tracked_ringbuf.end(); it++) {
                    if (fabs_time_diff(&amp;(current_pose_ringbuf.front().header), &amp;((it-1)-&gt;header))
                        &lt; fabs_time_diff(&amp;(current_pose_ringbuf.front().header), &amp;(it-&gt;header))) {
                        p_image_obj_tracked_buf = &amp;*(it-1);
                        break;
                    }
                }
                if (it == image_obj_tracked_ringbuf.end()) {
                    p_image_obj_tracked_buf = &amp;(image_obj_tracked_ringbuf.back());
                }
            }
        }
        // image_obj_tracked &lt; current_pose
        else {
            p_image_obj_tracked_buf = &amp;(image_obj_tracked_ringbuf.front());
            boost::circular_buffer&lt;geometry_msgs::PoseStamped&gt;::iterator it = current_pose_ringbuf.begin();
            if (current_pose_ringbuf.size() == 1) {
                p_current_pose_buf = &amp;*it;
                publish_msg(p_image_obj_tracked_buf, p_current_pose_buf);
                if (obj_label_flag == true){
                    buf_flag = false;
                    obj_label_flag = false;
                    image_obj_tracked_ringbuf.clear();
                    current_pose_ringbuf.clear();
                }
                return true;
            }

            for (it++; it != current_pose_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(image_obj_tracked_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(image_obj_tracked_ringbuf.front().header), &amp;(it-&gt;header))) {
                    p_current_pose_buf = &amp;*(it-1);
                    break;
                }
            }

            if (it == current_pose_ringbuf.end()) {
                p_current_pose_buf = &amp;(current_pose_ringbuf.back());
            }
        }
        publish_msg(p_image_obj_tracked_buf, p_current_pose_buf);
        if (obj_label_flag == true){
            buf_flag = false;
            obj_label_flag = false;
            image_obj_tracked_ringbuf.clear();
            current_pose_ringbuf.clear();
        }

        return true;
    } else {
        return false;
    }
}

void image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_obj_tracked_ringbuf.push_front(*image_obj_tracked_msg);
    //current_pose is empty
    if (current_pose_ringbuf.begin() == current_pose_ringbuf.end()) {
        buf_flag = false;
        pthread_mutex_unlock(&amp;mutex);
        ROS_INFO(&quot;current_pose ring buffer is empty&quot;);
        return;
    }
    buf_flag = true;
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (obj_label_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}

void current_pose_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; current_pose_msg) {
    pthread_mutex_lock(&amp;mutex);
    current_pose_ringbuf.push_front(*current_pose_msg);
    //image_obj_tracked is empty
    if (image_obj_tracked_ringbuf.begin() == image_obj_tracked_ringbuf.end()) {
        ROS_INFO(&quot;image_obj_tracked ring buffer is empty&quot;);
        buf_flag = false;
        pthread_mutex_unlock(&amp;mutex);
        return;
    }
    buf_flag = true;
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (obj_label_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}

#else
#endif

void obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) {
    pthread_mutex_lock(&amp;mutex);
    obj_label_flag = true;
    ROS_INFO(&quot;catch publish request&quot;);
    if (publish() == false) {
        ROS_INFO(&quot;waitting...&quot;);
    }
    pthread_mutex_unlock(&amp;mutex);}

void* thread(void* args)
{
    ros::NodeHandle nh_rcv;
    ros::CallbackQueue rcv_callbackqueue;
    nh_rcv.setCallbackQueue(&amp;rcv_callbackqueue);
    ros::Subscriber obj_label_sub = nh_rcv.subscribe(&quot;/obj_label&quot;, 5, obj_label_callback);
    while (nh_rcv.ok()) {
        rcv_callbackqueue.callAvailable(ros::WallDuration(1.0f));
        pthread_mutex_lock(&amp;mutex);
        bool flag = (obj_label_flag == false &amp;&amp; buf_flag == true);
        if (flag) {
            ROS_INFO(&quot;timeout&quot;);
            if(!publish()) {
                /* when to publish is failure, republish */
                struct timespec sleep_time;
                sleep_time.tv_sec = 0;
                sleep_time.tv_nsec = 200000000; //5Hz
                while (!publish() &amp;&amp; ros::ok())
                    nanosleep(&amp;sleep_time, NULL);
            }
        }
        pthread_mutex_unlock(&amp;mutex);
    }
    return NULL;
}

int main(int argc, char **argv) {
    /* init */
    buf_flag = false;
    obj_label_flag = false;
    ros::init(argc, argv, &quot;sync_reprojection&quot;);
    ros::NodeHandle nh;

    /* create server thread */
    pthread_t th;
    pthread_create(&amp;th, NULL, thread, (void *)NULL );

    ros::Subscriber image_obj_tracked_sub = nh.subscribe(&quot;/image_obj_tracked&quot;, 1, image_obj_tracked_callback);
    ros::Subscriber current_pose_sub = nh.subscribe(&quot;/current_pose&quot;, 1, current_pose_callback);
    image_obj_tracked__pub = nh.advertise&lt;cv_tracker::image_obj_tracked&gt;(&quot;/sync_reprojection/image_obj_tracked&quot;, 5);
    current_pose__pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/sync_reprojection/current_pose&quot;, 5);

    while (!buf_flag &amp;&amp; ros::ok()) {
        ros::spinOnce();
        usleep(100000);
    }
    pthread_mutex_lock(&amp;mutex);
    if(!publish()) {
        /* when to publish is failure, republish */
        struct timespec sleep_time;
        sleep_time.tv_sec = 0;
        sleep_time.tv_nsec = 200000000; //5Hz
        while (!publish() &amp;&amp; ros::ok())
            nanosleep(&amp;sleep_time, NULL);
    }
    pthread_mutex_unlock(&amp;mutex);

    ros::spin();

    /* shutdown server thread */
    ROS_INFO(&quot;wait until shutdown a thread&quot;);
    pthread_kill(th, SIGINT);
    pthread_join(th, NULL);

    return 0;
}

#if 0
cv_tracker::image_obj_tracked image_obj_tracked_buf;
geometry_msgs::PoseStamped current_pose_buf;

void image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_obj_tracked_ringbuf.push_front(*image_obj_tracked_msg);

    //current_pose is empty
    if (current_pose_ringbuf.begin() == current_pose_ringbuf.end()) {
        pthread_mutex_unlock(&amp;mutex);
        ROS_INFO(&quot;current_pose ring buffer is empty&quot;);
        return;
    }

    buf_flag = true;

    // image_obj_tracked &gt; current_pose
    if (get_time(&amp;(image_obj_tracked_ringbuf.front().header)) &gt;= get_time(&amp;(current_pose_ringbuf.front().header))) {
        current_pose_buf = current_pose_ringbuf.front();
        boost::circular_buffer&lt;cv_tracker::image_obj_tracked&gt;::iterator it = image_obj_tracked_ringbuf.begin();
        if (image_obj_tracked_ringbuf.size() == 1) {
            image_obj_tracked_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            pthread_mutex_lock(&amp;mutex);
            if (obj_label_flag == true) {
                publish();
            }
            pthread_mutex_unlock(&amp;mutex);
            return;
        } else {
            for (it++; it != image_obj_tracked_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(current_pose_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(current_pose_ringbuf.front().header), &amp;(it-&gt;header))) {
                    image_obj_tracked_buf = *(it-1);
                    break;
                }
            }
            if (it == image_obj_tracked_ringbuf.end()) {
                image_obj_tracked_buf = image_obj_tracked_ringbuf.back();
            }
        }

    } else {
        image_obj_tracked_buf = image_obj_tracked_ringbuf.front();
        boost::circular_buffer&lt;geometry_msgs::PoseStamped&gt;::iterator it = current_pose_ringbuf.begin();
        if (current_pose_ringbuf.size() == 1) {
            current_pose_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            pthread_mutex_lock(&amp;mutex);
            if (obj_label_flag == true) {
                publish();
            }
            pthread_mutex_unlock(&amp;mutex);
            return;
        }

        for (it++; it != current_pose_ringbuf.end(); it++) {
            if (fabs_time_diff(&amp;(image_obj_tracked_ringbuf.front().header), &amp;((it-1)-&gt;header))
                &lt; fabs_time_diff(&amp;(image_obj_tracked_ringbuf.front().header), &amp;(it-&gt;header))) {
                current_pose_buf = *(it-1);
                break;
            }
        }

        if (it == current_pose_ringbuf.end()) {
            current_pose_buf = current_pose_ringbuf.back();
        }
    }
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (obj_label_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}

void current_pose_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; current_pose_msg) {
    pthread_mutex_lock(&amp;mutex);
    current_pose_ringbuf.push_front(*current_pose_msg);
    //image_obj_tracked is empty
    if (image_obj_tracked_ringbuf.begin() == image_obj_tracked_ringbuf.end()) {
        ROS_INFO(&quot;image_obj_tracked ring buffer is empty&quot;);
        pthread_mutex_unlock(&amp;mutex);
        return;
    }

    buf_flag = true;

    // image_obj_tracked &gt; current_pose
    if (get_time(&amp;(image_obj_tracked_ringbuf.front().header)) &gt;= get_time(&amp;(current_pose_ringbuf.front().header))) {
        current_pose_buf = current_pose_ringbuf.front();
        boost::circular_buffer&lt;cv_tracker::image_obj_tracked&gt;::iterator it = image_obj_tracked_ringbuf.begin();
        if (image_obj_tracked_ringbuf.size() == 1) {
            image_obj_tracked_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            pthread_mutex_lock(&amp;mutex);
            if (obj_label_flag == true) {
                publish();
            }
            pthread_mutex_unlock(&amp;mutex);
            return;
        } else {
            for (it++; it != image_obj_tracked_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(current_pose_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(current_pose_ringbuf.front().header), &amp;(it-&gt;header))) {
                    image_obj_tracked_buf = *(it-1);
                    break;
                }
            }
            if (it == image_obj_tracked_ringbuf.end()) {
                image_obj_tracked_buf = image_obj_tracked_ringbuf.back();
            }
        }

    } else {
        image_obj_tracked_buf = image_obj_tracked_ringbuf.front();
        boost::circular_buffer&lt;geometry_msgs::PoseStamped&gt;::iterator it = current_pose_ringbuf.begin();
        if (current_pose_ringbuf.size() == 1) {
            current_pose_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            pthread_mutex_lock(&amp;mutex);
            if (obj_label_flag == true) {
                publish();
            }
            pthread_mutex_unlock(&amp;mutex);
            return;
        }

        for (it++; it != current_pose_ringbuf.end(); it++) {
            if (fabs_time_diff(&amp;(image_obj_tracked_ringbuf.front().header), &amp;((it-1)-&gt;header))
                &lt; fabs_time_diff(&amp;(image_obj_tracked_ringbuf.front().header), &amp;(it-&gt;header))) {
                current_pose_buf = *(it-1);
                break;
            }
        }

        if (it == current_pose_ringbuf.end()) {
            current_pose_buf = current_pose_ringbuf.back();
        }
    }
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (obj_label_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}

bool publish() {
    if (buf_flag) {
        ROS_INFO(&quot;publish&quot;);
        image_obj_tracked__pub.publish(image_obj_tracked_buf);
        current_pose__pub.publish(current_pose_buf);
        if (obj_label_flag == true){
            buf_flag = false;
            obj_label_flag = false;
            image_obj_tracked_ringbuf.clear();
            current_pose_ringbuf.clear();
        }
        return true;
    } else {
        ROS_INFO(&quot;publish failed&quot;);
        return false;
    }
}
#endif
#endif
</old_file>
			</file>
			<file old_path="ros/src/system/sync/computing/perception/detection/packages/cv_tracker/nodes/range_fusion/sync_range_fusion.cpp" new_path="ros/src/system/sync/computing/perception/detection/packages/cv_tracker/nodes/range_fusion/sync_range_fusion.cpp">
				<diff>@@ -1,7 +1,7 @@
 #include &quot;ros/ros.h&quot;
-#include &quot;cv_tracker/image_obj.h&quot;
+#include &quot;cv_tracker_msgs/image_obj.h&quot;
 #include &quot;points2image/PointsImage.h&quot;
-#include &quot;cv_tracker/image_obj_ranged.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
 #include &quot;sync.hpp&quot;
 
 int main(int argc, char **argv) {
@@ -13,7 +13,7 @@ int main(int argc, char **argv) {
     std::string pub1(&quot;/image_obj&quot;);
     std::string pub2(&quot;/vscan_image&quot;);
 
-    Synchronizer&lt;cv_tracker::image_obj, points2image::PointsImage, cv_tracker::image_obj_ranged&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
+    Synchronizer&lt;cv_tracker_msgs::image_obj, points2image::PointsImage, cv_tracker_msgs::image_obj_ranged&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
     synchronizer.run();
 
     return 0;
@@ -39,9 +39,9 @@ int main(int argc, char **argv) {
 #include &lt;pthread.h&gt;
 #include &quot;t_sync_message.h&quot;
 /* user header */
-#include &quot;cv_tracker/image_obj.h&quot;
+#include &quot;cv_tracker_msgs/image_obj.h&quot;
 #include &quot;points2image/PointsImage.h&quot;
-#include &quot;cv_tracker/image_obj_ranged.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
 
 /* ----mode---- */
 #define _REQ_PUB 1
@@ -51,7 +51,7 @@ int main(int argc, char **argv) {
 bool buf_flag;
 pthread_mutex_t mutex;
 /* user var */
-boost::circular_buffer&lt;cv_tracker::image_obj&gt; image_obj_ringbuf(10);
+boost::circular_buffer&lt;cv_tracker_msgs::image_obj&gt; image_obj_ringbuf(10);
 boost::circular_buffer&lt;points2image::PointsImage&gt; vscan_image_ringbuf(10);
 ros::Publisher image_obj__pub;
 ros::Publisher vscan_image__pub;
@@ -71,10 +71,10 @@ double get_time(const std_msgs::Header *timespec) {
 
 
 #if _REQ_PUB
-cv_tracker::image_obj* p_image_obj_buf;
+cv_tracker_msgs::image_obj* p_image_obj_buf;
 points2image::PointsImage* p_vscan_image_buf;
 
-void publish_msg(cv_tracker::image_obj* p_image_obj_buf, points2image::PointsImage* p_vscan_image_buf) {
+void publish_msg(cv_tracker_msgs::image_obj* p_image_obj_buf, points2image::PointsImage* p_vscan_image_buf) {
     ROS_INFO(&quot;publish&quot;);
     image_obj__pub.publish(*p_image_obj_buf);
     vscan_image__pub.publish(*p_vscan_image_buf);
@@ -97,7 +97,7 @@ bool publish() {
         // image_obj &gt; vscan_image
         if (get_time(&amp;(image_obj_ringbuf.front().header)) &gt;= get_time(&amp;(vscan_image_ringbuf.front().header))) {
             p_vscan_image_buf = &amp;(vscan_image_ringbuf.front());
-            boost::circular_buffer&lt;cv_tracker::image_obj&gt;::iterator it = image_obj_ringbuf.begin();
+            boost::circular_buffer&lt;cv_tracker_msgs::image_obj&gt;::iterator it = image_obj_ringbuf.begin();
             if (image_obj_ringbuf.size() == 1) {
                 p_image_obj_buf = &amp;*it;
                 publish_msg(p_image_obj_buf, p_vscan_image_buf);
@@ -163,7 +163,7 @@ bool publish() {
     }
 }
 
-void image_obj_callback(const cv_tracker::image_obj::ConstPtr&amp; image_obj_msg) {
+void image_obj_callback(const cv_tracker_msgs::image_obj::ConstPtr&amp; image_obj_msg) {
     pthread_mutex_lock(&amp;mutex);
     image_obj_ringbuf.push_front(*image_obj_msg);
     //vscan_image is empty
@@ -203,7 +203,7 @@ void vscan_image_callback(const points2image::PointsImage::ConstPtr&amp; vscan_image
 #else
 #endif
 
-void image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
+void image_obj_ranged_callback(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
     pthread_mutex_lock(&amp;mutex);
     image_obj_ranged_flag = true;
     ROS_INFO(&quot;catch publish request&quot;);
@@ -252,7 +252,7 @@ int main(int argc, char **argv) {
 
     ros::Subscriber image_obj_sub = nh.subscribe(&quot;/image_obj&quot;, 1, image_obj_callback);
     ros::Subscriber vscan_image_sub = nh.subscribe(&quot;/vscan_image&quot;, 1, vscan_image_callback);
-    image_obj__pub = nh.advertise&lt;cv_tracker::image_obj&gt;(&quot;/sync_ranging/image_obj&quot;, 5);
+    image_obj__pub = nh.advertise&lt;cv_tracker_msgs::image_obj&gt;(&quot;/sync_ranging/image_obj&quot;, 5);
     vscan_image__pub = nh.advertise&lt;points2image::PointsImage&gt;(&quot;/sync_ranging/vscan_image&quot;, 5);
 
     while ((!buf_flag) &amp;&amp; ros::ok()) {
@@ -284,10 +284,10 @@ int main(int argc, char **argv) {
 
 
 #if 0
-cv_tracker::image_obj image_obj_buf;
+cv_tracker_msgs::image_obj image_obj_buf;
 points2image::PointsImage vscan_image_buf;
 
-void image_obj_callback(const cv_tracker::image_obj::ConstPtr&amp; image_obj_msg) {
+void image_obj_callback(const cv_tracker_msgs::image_obj::ConstPtr&amp; image_obj_msg) {
     pthread_mutex_lock(&amp;mutex);
     image_obj_ringbuf.push_front(*image_obj_msg);
 
@@ -303,7 +303,7 @@ void image_obj_callback(const cv_tracker::image_obj::ConstPtr&amp; image_obj_msg) {
     // image_obj &gt; vscan_image
     if (get_time(&amp;(image_obj_ringbuf.front().header)) &gt;= get_time(&amp;(vscan_image_ringbuf.front().header))) {
         vscan_image_buf = vscan_image_ringbuf.front();
-        boost::circular_buffer&lt;cv_tracker::image_obj&gt;::iterator it = image_obj_ringbuf.begin();
+        boost::circular_buffer&lt;cv_tracker_msgs::image_obj&gt;::iterator it = image_obj_ringbuf.begin();
         if (image_obj_ringbuf.size() == 1) {
             image_obj_buf = *it;
             pthread_mutex_unlock(&amp;mutex);
@@ -360,7 +360,7 @@ void vscan_image_callback(const points2image::PointsImage::ConstPtr&amp; vscan_image
     // image_obj &gt; vscan_image
     if (get_time(&amp;(image_obj_ringbuf.front().header)) &gt;= get_time(&amp;(vscan_image_ringbuf.front().header))) {
         vscan_image_buf = vscan_image_ringbuf.front();
-        boost::circular_buffer&lt;cv_tracker::image_obj&gt;::iterator it = image_obj_ringbuf.begin();
+        boost::circular_buffer&lt;cv_tracker_msgs::image_obj&gt;::iterator it = image_obj_ringbuf.begin();
         if (image_obj_ringbuf.size() == 1) {
             image_obj_buf = *it;
             pthread_mutex_unlock(&amp;mutex);
</diff>
				<old_file>#include &quot;ros/ros.h&quot;
#include &quot;cv_tracker/image_obj.h&quot;
#include &quot;points2image/PointsImage.h&quot;
#include &quot;cv_tracker/image_obj_ranged.h&quot;
#include &quot;sync.hpp&quot;

int main(int argc, char **argv) {
    ros::init(argc, argv, &quot;sync_ranging&quot;);
    std::string ns(ros::this_node::getNamespace());
    std::string sub1(&quot;/image_obj&quot;);
    std::string sub2(&quot;/vscan_image&quot;);
    std::string req(&quot;/image_obj_ranged&quot;);
    std::string pub1(&quot;/image_obj&quot;);
    std::string pub2(&quot;/vscan_image&quot;);

    Synchronizer&lt;cv_tracker::image_obj, points2image::PointsImage, cv_tracker::image_obj_ranged&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
    synchronizer.run();

    return 0;
}

#if 0
/* ----header---- */
/* common header */
#include &quot;ros/ros.h&quot;
#include &lt;ros/callback_queue.h&gt;
#include &lt;boost/circular_buffer.hpp&gt;
#include &lt;vector&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;signal.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;sys/select.h&gt;
#include &lt;mqueue.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;errno.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;
#include &quot;t_sync_message.h&quot;
/* user header */
#include &quot;cv_tracker/image_obj.h&quot;
#include &quot;points2image/PointsImage.h&quot;
#include &quot;cv_tracker/image_obj_ranged.h&quot;

/* ----mode---- */
#define _REQ_PUB 1

/* ----var---- */
/* common var */
bool buf_flag;
pthread_mutex_t mutex;
/* user var */
boost::circular_buffer&lt;cv_tracker::image_obj&gt; image_obj_ringbuf(10);
boost::circular_buffer&lt;points2image::PointsImage&gt; vscan_image_ringbuf(10);
ros::Publisher image_obj__pub;
ros::Publisher vscan_image__pub;
bool image_obj_ranged_flag;

/* ----function---- */
double fabs_time_diff(std_msgs::Header *timespec1, std_msgs::Header *timespec2) {
    double time1 = (double)timespec1-&gt;stamp.sec + (double)timespec1-&gt;stamp.nsec/1000000000L;
    double time2 = (double)timespec2-&gt;stamp.sec + (double)timespec2-&gt;stamp.nsec/1000000000L;

    return fabs(time1 - time2);
}

double get_time(const std_msgs::Header *timespec) {
    return (double)timespec-&gt;stamp.sec + (double)timespec-&gt;stamp.nsec/1000000000L;
}


#if _REQ_PUB
cv_tracker::image_obj* p_image_obj_buf;
points2image::PointsImage* p_vscan_image_buf;

void publish_msg(cv_tracker::image_obj* p_image_obj_buf, points2image::PointsImage* p_vscan_image_buf) {
    ROS_INFO(&quot;publish&quot;);
    image_obj__pub.publish(*p_image_obj_buf);
    vscan_image__pub.publish(*p_vscan_image_buf);
}

bool publish() {
    if (buf_flag) {
        //image_obj is empty
        if (image_obj_ringbuf.begin() == image_obj_ringbuf.end()) {
            ROS_INFO(&quot;image_obj ring buffer is empty&quot;);
            return false;
        }

        //vscan_image is empty
        if (vscan_image_ringbuf.begin() == vscan_image_ringbuf.end()) {
            ROS_INFO(&quot;vscan_image ring buffer is empty&quot;);
            return false;
        }

        // image_obj &gt; vscan_image
        if (get_time(&amp;(image_obj_ringbuf.front().header)) &gt;= get_time(&amp;(vscan_image_ringbuf.front().header))) {
            p_vscan_image_buf = &amp;(vscan_image_ringbuf.front());
            boost::circular_buffer&lt;cv_tracker::image_obj&gt;::iterator it = image_obj_ringbuf.begin();
            if (image_obj_ringbuf.size() == 1) {
                p_image_obj_buf = &amp;*it;
                publish_msg(p_image_obj_buf, p_vscan_image_buf);
                if (image_obj_ranged_flag == true){
                    buf_flag = false;
                    image_obj_ranged_flag = false;
                    image_obj_ringbuf.clear();
                    vscan_image_ringbuf.clear();
                }
                return true;
            } else {
                for (it++; it != image_obj_ringbuf.end(); it++) {
                    if (fabs_time_diff(&amp;(vscan_image_ringbuf.front().header), &amp;((it-1)-&gt;header))
                        &lt; fabs_time_diff(&amp;(vscan_image_ringbuf.front().header), &amp;(it-&gt;header))) {
                        p_image_obj_buf = &amp;*(it-1);
                        break;
                    }
                }
                if (it == image_obj_ringbuf.end()) {
                    p_image_obj_buf = &amp;(image_obj_ringbuf.back());
                }
            }
        }
        // image_obj &lt; vscan_image
        else {
            p_image_obj_buf = &amp;(image_obj_ringbuf.front());
            boost::circular_buffer&lt;points2image::PointsImage&gt;::iterator it = vscan_image_ringbuf.begin();
            if (vscan_image_ringbuf.size() == 1) {
                p_vscan_image_buf = &amp;*it;
                publish_msg(p_image_obj_buf, p_vscan_image_buf);
                if (image_obj_ranged_flag == true){
                    buf_flag = false;
                    image_obj_ranged_flag = false;
                    image_obj_ringbuf.clear();
                    vscan_image_ringbuf.clear();
                }
                return true;
            }

            for (it++; it != vscan_image_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(image_obj_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(image_obj_ringbuf.front().header), &amp;(it-&gt;header))) {
                    p_vscan_image_buf = &amp;*(it-1);
                    break;
                }
            }

            if (it == vscan_image_ringbuf.end()) {
                p_vscan_image_buf = &amp;(vscan_image_ringbuf.back());
            }
        }
        publish_msg(p_image_obj_buf, p_vscan_image_buf);
        if (image_obj_ranged_flag == true){
            buf_flag = false;
            image_obj_ranged_flag = false;
            image_obj_ringbuf.clear();
            vscan_image_ringbuf.clear();
        }

        return true;
    } else {
        return false;
    }
}

void image_obj_callback(const cv_tracker::image_obj::ConstPtr&amp; image_obj_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_obj_ringbuf.push_front(*image_obj_msg);
    //vscan_image is empty
    if (vscan_image_ringbuf.begin() == vscan_image_ringbuf.end()) {
        ROS_INFO(&quot;vscan_image ring buffer is empty&quot;);
        buf_flag = false;
        pthread_mutex_unlock(&amp;mutex);
        return;
    }
    buf_flag = true;
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (image_obj_ranged_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}

void vscan_image_callback(const points2image::PointsImage::ConstPtr&amp; vscan_image_msg) {
    pthread_mutex_lock(&amp;mutex);
    vscan_image_ringbuf.push_front(*vscan_image_msg);
    //image_obj is empty
    if (image_obj_ringbuf.begin() == image_obj_ringbuf.end()) {
        ROS_INFO(&quot;image_obj ring buffer is empty&quot;);
        buf_flag = false;
        pthread_mutex_unlock(&amp;mutex);
        return;
    }
    buf_flag = true;
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (image_obj_ranged_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}
#else
#endif

void image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_obj_ranged_flag = true;
    ROS_INFO(&quot;catch publish request&quot;);
    if (publish() == false) {
        ROS_INFO(&quot;waitting...&quot;);
    }
    pthread_mutex_unlock(&amp;mutex);
}

void* thread(void* args) {
    ros::NodeHandle nh_rcv;
    ros::CallbackQueue rcv_callbackqueue;
    nh_rcv.setCallbackQueue(&amp;rcv_callbackqueue);
    ros::Subscriber image_obj_ranged_sub = nh_rcv.subscribe(&quot;/image_obj_ranged&quot;, 1, image_obj_ranged_callback);
    while (nh_rcv.ok()) {
        rcv_callbackqueue.callAvailable(ros::WallDuration(3.0f));
        pthread_mutex_lock(&amp;mutex);
        bool flag = (image_obj_ranged_flag == false &amp;&amp; buf_flag == true);
        if (flag) {
            ROS_INFO(&quot;timeout&quot;);
            if(!publish()) {
                /* when to publish is failure, republish */
                struct timespec sleep_time;
                sleep_time.tv_sec = 0;
                sleep_time.tv_nsec = 200000000; //5Hz
                while (!publish() &amp;&amp; ros::ok())
                    nanosleep(&amp;sleep_time, NULL);
            }
        }
        pthread_mutex_unlock(&amp;mutex);

    }
    return NULL;
}

int main(int argc, char **argv) {
    /* init */
    buf_flag = false;
    image_obj_ranged_flag = false;
    ros::init(argc, argv, &quot;sync_ranging&quot;);
    ros::NodeHandle nh;

    /* create server thread */
    pthread_t th;
    pthread_create(&amp;th, NULL, thread, (void *)NULL );

    ros::Subscriber image_obj_sub = nh.subscribe(&quot;/image_obj&quot;, 1, image_obj_callback);
    ros::Subscriber vscan_image_sub = nh.subscribe(&quot;/vscan_image&quot;, 1, vscan_image_callback);
    image_obj__pub = nh.advertise&lt;cv_tracker::image_obj&gt;(&quot;/sync_ranging/image_obj&quot;, 5);
    vscan_image__pub = nh.advertise&lt;points2image::PointsImage&gt;(&quot;/sync_ranging/vscan_image&quot;, 5);

    while ((!buf_flag) &amp;&amp; ros::ok()) {
        ros::spinOnce();
        usleep(100000);
    }
    pthread_mutex_lock(&amp;mutex);
    if(!publish()) {
        /* when to publish is failure, republish */
        struct timespec sleep_time;
        sleep_time.tv_sec = 0;
        sleep_time.tv_nsec = 200000000; //5Hz
        while (!publish() &amp;&amp; ros::ok())
            nanosleep(&amp;sleep_time, NULL);
    }
    pthread_mutex_unlock(&amp;mutex);

    ros::spin();
    pthread_mutex_unlock(&amp;mutex);

    /* shutdown server thread */
    ROS_INFO(&quot;wait until shutdown a thread&quot;);
    pthread_kill(th, SIGINT);
    pthread_join(th, NULL);

    return 0;
}



#if 0
cv_tracker::image_obj image_obj_buf;
points2image::PointsImage vscan_image_buf;

void image_obj_callback(const cv_tracker::image_obj::ConstPtr&amp; image_obj_msg) {
    pthread_mutex_lock(&amp;mutex);
    image_obj_ringbuf.push_front(*image_obj_msg);

    //vscan_image is empty
    if (vscan_image_ringbuf.begin() == vscan_image_ringbuf.end()) {
        pthread_mutex_unlock(&amp;mutex);
        ROS_INFO(&quot;vscan_image ring buffer is empty&quot;);
        return;
    }

    buf_flag = true;

    // image_obj &gt; vscan_image
    if (get_time(&amp;(image_obj_ringbuf.front().header)) &gt;= get_time(&amp;(vscan_image_ringbuf.front().header))) {
        vscan_image_buf = vscan_image_ringbuf.front();
        boost::circular_buffer&lt;cv_tracker::image_obj&gt;::iterator it = image_obj_ringbuf.begin();
        if (image_obj_ringbuf.size() == 1) {
            image_obj_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            return;
        } else {
            for (it++; it != image_obj_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(vscan_image_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(vscan_image_ringbuf.front().header), &amp;(it-&gt;header))) {
                    image_obj_buf = *(it-1);
                    break;
                }
            }
            if (it == image_obj_ringbuf.end()) {
                image_obj_buf = image_obj_ringbuf.back();
            }
        }

    } else {
        image_obj_buf = image_obj_ringbuf.front();
        boost::circular_buffer&lt;points2image::PointsImage&gt;::iterator it = vscan_image_ringbuf.begin();
        if (vscan_image_ringbuf.size() == 1) {
            vscan_image_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            return;
        }

        for (it++; it != vscan_image_ringbuf.end(); it++) {
            if (fabs_time_diff(&amp;(image_obj_ringbuf.front().header), &amp;((it-1)-&gt;header))
                &lt; fabs_time_diff(&amp;(image_obj_ringbuf.front().header), &amp;(it-&gt;header))) {
                vscan_image_buf = *(it-1);
                break;
            }
        }

        if (it == vscan_image_ringbuf.end()) {
            vscan_image_buf = vscan_image_ringbuf.back();
        }
    }
    pthread_mutex_unlock(&amp;mutex);
}

void vscan_image_callback(const points2image::PointsImage::ConstPtr&amp; vscan_image_msg) {
    pthread_mutex_lock(&amp;mutex);
    vscan_image_ringbuf.push_front(*vscan_image_msg);
    //image_obj is empty
    if (image_obj_ringbuf.begin() == image_obj_ringbuf.end()) {
        ROS_INFO(&quot;image_obj ring buffer is empty&quot;);
        pthread_mutex_unlock(&amp;mutex);
        return;
    }

    buf_flag = true;

    // image_obj &gt; vscan_image
    if (get_time(&amp;(image_obj_ringbuf.front().header)) &gt;= get_time(&amp;(vscan_image_ringbuf.front().header))) {
        vscan_image_buf = vscan_image_ringbuf.front();
        boost::circular_buffer&lt;cv_tracker::image_obj&gt;::iterator it = image_obj_ringbuf.begin();
        if (image_obj_ringbuf.size() == 1) {
            image_obj_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            return;
        } else {
            for (it++; it != image_obj_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(vscan_image_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(vscan_image_ringbuf.front().header), &amp;(it-&gt;header))) {
                    image_obj_buf = *(it-1);
                    break;
                }
            }
            if (it == image_obj_ringbuf.end()) {
                image_obj_buf = image_obj_ringbuf.back();
            }
        }

    } else {
        image_obj_buf = image_obj_ringbuf.front();
        boost::circular_buffer&lt;points2image::PointsImage&gt;::iterator it = vscan_image_ringbuf.begin();
        if (vscan_image_ringbuf.size() == 1) {
            vscan_image_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            return;
        }

        for (it++; it != vscan_image_ringbuf.end(); it++) {
            if (fabs_time_diff(&amp;(image_obj_ringbuf.front().header), &amp;((it-1)-&gt;header))
                &lt; fabs_time_diff(&amp;(image_obj_ringbuf.front().header), &amp;(it-&gt;header))) {
                vscan_image_buf = *(it-1);
                break;
            }
        }

        if (it == vscan_image_ringbuf.end()) {
            vscan_image_buf = vscan_image_ringbuf.back();
        }
    }
    pthread_mutex_unlock(&amp;mutex);
}

bool publish() {
    if (buf_flag) {
        pthread_mutex_lock(&amp;mutex);
        // scan_ringbuf.clear();
        // image_ringbuf.clear();
        // scan_ringbuf.push_front(scan_buf);
        // image_ringbuf.push_front(image_buf);
        ROS_INFO(&quot;publish&quot;);
        image_obj__pub.publish(image_obj_buf);
        vscan_image__pub.publish(vscan_image_buf);
        pthread_mutex_unlock(&amp;mutex);
        return true;
    } else {
        ROS_INFO(&quot;publish failed&quot;);
        return false;
    }
}

#endif
#endif
</old_file>
			</file>
			<file old_path="ros/src/system/sync/computing/perception/detection/packages/lidar_tracker/nodes/obj_fusion/sync_obj_fusion.cpp" new_path="ros/src/system/sync/computing/perception/detection/packages/lidar_tracker/nodes/obj_fusion/sync_obj_fusion.cpp">
				<diff>@@ -1,5 +1,5 @@
 #include &quot;ros/ros.h&quot;
-#include &quot;cv_tracker/obj_label.h&quot;
+#include &quot;cv_tracker_msgs/obj_label.h&quot;
 #include &quot;lidar_tracker/centroids.h&quot;
 #include &quot;visualization_msgs/MarkerArray.h&quot;
 #include &quot;sync.hpp&quot;
@@ -13,7 +13,7 @@ int main(int argc, char **argv) {
     std::string pub1(&quot;/obj_label&quot;);
     std::string pub2(&quot;/cluster_centroids&quot;);
 
-    Synchronizer&lt;cv_tracker::obj_label, lidar_tracker::centroids, visualization_msgs::MarkerArray&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
+    Synchronizer&lt;cv_tracker_msgs::obj_label, lidar_tracker::centroids, visualization_msgs::MarkerArray&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
     synchronizer.run();
 
     return 0;
@@ -39,7 +39,7 @@ int main(int argc, char **argv) {
 #include &lt;pthread.h&gt;
 #include &quot;t_sync_message.h&quot;
 /* user header */
-#include &quot;cv_tracker/obj_label.h&quot;
+#include &quot;cv_tracker_msgs/obj_label.h&quot;
 #include &quot;lidar_tracker/centroids.h&quot;
 #include &quot;visualization_msgs/MarkerArray.h&quot;
 
@@ -51,7 +51,7 @@ int main(int argc, char **argv) {
 bool buf_flag;
 pthread_mutex_t mutex;
 /* user var */
-boost::circular_buffer&lt;cv_tracker::obj_label&gt; obj_label_ringbuf(10);
+boost::circular_buffer&lt;cv_tracker_msgs::obj_label&gt; obj_label_ringbuf(10);
 boost::circular_buffer&lt;lidar_tracker::centroids&gt; cluster_centroids_ringbuf(10);
 ros::Publisher obj_label__pub;
 ros::Publisher cluster_centroids__pub;
@@ -71,10 +71,10 @@ double get_time(const std_msgs::Header *timespec) {
 
 
 #if _REQ_PUB
-cv_tracker::obj_label* p_obj_label_buf;
+cv_tracker_msgs::obj_label* p_obj_label_buf;
 lidar_tracker::centroids* p_cluster_centroids_buf;
 
-void publish_msg(cv_tracker::obj_label* p_obj_label_buf, lidar_tracker::centroids* p_cluster_centroids_buf)
+void publish_msg(cv_tracker_msgs::obj_label* p_obj_label_buf, lidar_tracker::centroids* p_cluster_centroids_buf)
 {
     ROS_INFO(&quot;publish&quot;);
     obj_label__pub.publish(*p_obj_label_buf);
@@ -98,7 +98,7 @@ bool publish() {
         // obj_label &gt; cluster_centroids
         if (get_time(&amp;(obj_label_ringbuf.front().header)) &gt;= get_time(&amp;(cluster_centroids_ringbuf.front().header))) {
             p_cluster_centroids_buf = &amp;(cluster_centroids_ringbuf.front());
-            boost::circular_buffer&lt;cv_tracker::obj_label&gt;::iterator it = obj_label_ringbuf.begin();
+            boost::circular_buffer&lt;cv_tracker_msgs::obj_label&gt;::iterator it = obj_label_ringbuf.begin();
             if (obj_label_ringbuf.size() == 1) {
                 p_obj_label_buf = &amp;*it;
                 publish_msg(p_obj_label_buf, p_cluster_centroids_buf);
@@ -163,7 +163,7 @@ bool publish() {
     }
 }
 
-void obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) {
+void obj_label_callback(const cv_tracker_msgs::obj_label::ConstPtr&amp; obj_label_msg) {
     pthread_mutex_lock(&amp;mutex);
     obj_label_ringbuf.push_front(*obj_label_msg);
     //cluster_centroids is empty
@@ -203,7 +203,7 @@ void cluster_centroids_callback(const lidar_tracker::centroids::ConstPtr&amp; cluste
 }
 
 #else
-cv_tracker::obj_label obj_label_buf;
+cv_tracker_msgs::obj_label obj_label_buf;
 lidar_tracker::centroids cluster_centroids_buf;
 
 bool publish() {
@@ -224,7 +224,7 @@ bool publish() {
     }
 }
 
-void obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) {
+void obj_label_callback(const cv_tracker_msgs::obj_label::ConstPtr&amp; obj_label_msg) {
     pthread_mutex_lock(&amp;mutex);
     obj_label_ringbuf.push_front(*obj_label_msg);
 
@@ -240,7 +240,7 @@ void obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) {
     // obj_label &gt; cluster_centroids
     if (get_time(&amp;(obj_label_ringbuf.front().header)) &gt;= get_time(&amp;(cluster_centroids_ringbuf.front().header))) {
         cluster_centroids_buf = cluster_centroids_ringbuf.front();
-        boost::circular_buffer&lt;cv_tracker::obj_label&gt;::iterator it = obj_label_ringbuf.begin();
+        boost::circular_buffer&lt;cv_tracker_msgs::obj_label&gt;::iterator it = obj_label_ringbuf.begin();
         if (obj_label_ringbuf.size() == 1) {
             obj_label_buf = *it;
             pthread_mutex_unlock(&amp;mutex);
@@ -307,7 +307,7 @@ void cluster_centroids_callback(const lidar_tracker::centroids::ConstPtr&amp; cluste
     // obj_label &gt; cluster_centroids
     if (get_time(&amp;(obj_label_ringbuf.front().header)) &gt;= get_time(&amp;(cluster_centroids_ringbuf.front().header))) {
         cluster_centroids_buf = cluster_centroids_ringbuf.front();
-        boost::circular_buffer&lt;cv_tracker::obj_label&gt;::iterator it = obj_label_ringbuf.begin();
+        boost::circular_buffer&lt;cv_tracker_msgs::obj_label&gt;::iterator it = obj_label_ringbuf.begin();
         if (obj_label_ringbuf.size() == 1) {
             obj_label_buf = *it;
             pthread_mutex_unlock(&amp;mutex);
@@ -409,7 +409,7 @@ int main(int argc, char **argv) {
 
     ros::Subscriber obj_label_sub = nh.subscribe(&quot;/obj_label&quot;, 1, obj_label_callback);
     ros::Subscriber cluster_centroids_sub = nh.subscribe(&quot;/cluster_centroids&quot;, 1, cluster_centroids_callback);
-    obj_label__pub = nh.advertise&lt;cv_tracker::obj_label&gt;(&quot;/sync_obj_fusion/obj_label&quot;, 5);
+    obj_label__pub = nh.advertise&lt;cv_tracker_msgs::obj_label&gt;(&quot;/sync_obj_fusion/obj_label&quot;, 5);
     cluster_centroids__pub = nh.advertise&lt;lidar_tracker::centroids&gt;(&quot;/sync_obj_fusion/cluster_centroids&quot;, 5);
     while (!buf_flag &amp;&amp; ros::ok()) {
         ros::spinOnce();
</diff>
				<old_file>#include &quot;ros/ros.h&quot;
#include &quot;cv_tracker/obj_label.h&quot;
#include &quot;lidar_tracker/centroids.h&quot;
#include &quot;visualization_msgs/MarkerArray.h&quot;
#include &quot;sync.hpp&quot;

int main(int argc, char **argv) {
    ros::init(argc, argv, &quot;sync_obj_fusion&quot;);
    std::string ns(ros::this_node::getNamespace());
    std::string sub1(&quot;/obj_label&quot;);
    std::string sub2(&quot;/cluster_centroids&quot;);
    std::string req(&quot;/obj_pose&quot;);
    std::string pub1(&quot;/obj_label&quot;);
    std::string pub2(&quot;/cluster_centroids&quot;);

    Synchronizer&lt;cv_tracker::obj_label, lidar_tracker::centroids, visualization_msgs::MarkerArray&gt; synchronizer(sub1, sub2, pub1, pub2, req, ns);
    synchronizer.run();

    return 0;
}

#if 0
/* ----header---- */
/* common header */
#include &quot;ros/ros.h&quot;
#include &lt;ros/callback_queue.h&gt;
#include &lt;boost/circular_buffer.hpp&gt;
#include &lt;vector&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;signal.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;sys/select.h&gt;
#include &lt;mqueue.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;errno.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;
#include &quot;t_sync_message.h&quot;
/* user header */
#include &quot;cv_tracker/obj_label.h&quot;
#include &quot;lidar_tracker/centroids.h&quot;
#include &quot;visualization_msgs/MarkerArray.h&quot;

/* ----mode---- */
#define _REQ_PUB 1

/* ----var---- */
/* common var */
bool buf_flag;
pthread_mutex_t mutex;
/* user var */
boost::circular_buffer&lt;cv_tracker::obj_label&gt; obj_label_ringbuf(10);
boost::circular_buffer&lt;lidar_tracker::centroids&gt; cluster_centroids_ringbuf(10);
ros::Publisher obj_label__pub;
ros::Publisher cluster_centroids__pub;
bool obj_pose_flag;

/* ----function---- */
double fabs_time_diff(std_msgs::Header *timespec1, std_msgs::Header *timespec2) {
    double time1 = (double)timespec1-&gt;stamp.sec + (double)timespec1-&gt;stamp.nsec/1000000000L;
    double time2 = (double)timespec2-&gt;stamp.sec + (double)timespec2-&gt;stamp.nsec/1000000000L;

    return fabs(time1 - time2);
}

double get_time(const std_msgs::Header *timespec) {
    return (double)timespec-&gt;stamp.sec + (double)timespec-&gt;stamp.nsec/1000000000L;
}


#if _REQ_PUB
cv_tracker::obj_label* p_obj_label_buf;
lidar_tracker::centroids* p_cluster_centroids_buf;

void publish_msg(cv_tracker::obj_label* p_obj_label_buf, lidar_tracker::centroids* p_cluster_centroids_buf)
{
    ROS_INFO(&quot;publish&quot;);
    obj_label__pub.publish(*p_obj_label_buf);
    cluster_centroids__pub.publish(*p_cluster_centroids_buf);
}

bool publish() {
    if (buf_flag) {
        //obj_label is empty
        if (obj_label_ringbuf.begin() == obj_label_ringbuf.end()) {
            ROS_INFO(&quot;obj_label ring buffer is empty&quot;);
            return false;
        }

        //cluster_centroids is empty
        if (cluster_centroids_ringbuf.begin() == cluster_centroids_ringbuf.end()) {
            ROS_INFO(&quot;cluster_centroids ring buffer is empty&quot;);
            return false;
        }

        // obj_label &gt; cluster_centroids
        if (get_time(&amp;(obj_label_ringbuf.front().header)) &gt;= get_time(&amp;(cluster_centroids_ringbuf.front().header))) {
            p_cluster_centroids_buf = &amp;(cluster_centroids_ringbuf.front());
            boost::circular_buffer&lt;cv_tracker::obj_label&gt;::iterator it = obj_label_ringbuf.begin();
            if (obj_label_ringbuf.size() == 1) {
                p_obj_label_buf = &amp;*it;
                publish_msg(p_obj_label_buf, p_cluster_centroids_buf);
                if (obj_pose_flag == true){
                    buf_flag = false;
                    obj_pose_flag = false;
                    obj_label_ringbuf.clear();
                    cluster_centroids_ringbuf.clear();
                }
                return true;
            } else {
                for (it++; it != obj_label_ringbuf.end(); it++) {
                    if (fabs_time_diff(&amp;(cluster_centroids_ringbuf.front().header), &amp;((it-1)-&gt;header))
                        &lt; fabs_time_diff(&amp;(cluster_centroids_ringbuf.front().header), &amp;(it-&gt;header))) {
                        p_obj_label_buf = &amp;*(it-1);
                        break;
                    }
                }
                if (it == obj_label_ringbuf.end()) {
                    p_obj_label_buf = &amp;(obj_label_ringbuf.back());
                }
            }
        }
        // obj_label &lt; cluster_centroids
        else {
            p_obj_label_buf = &amp;(obj_label_ringbuf.front());
            boost::circular_buffer&lt;lidar_tracker::centroids&gt;::iterator it = cluster_centroids_ringbuf.begin();
            if (cluster_centroids_ringbuf.size() == 1) {
                p_cluster_centroids_buf = &amp;*it;
                publish_msg(p_obj_label_buf, p_cluster_centroids_buf);
                if (obj_pose_flag == true){
                    buf_flag = false;
                    obj_pose_flag = false;
                    obj_label_ringbuf.clear();
                    cluster_centroids_ringbuf.clear();
                }
                return true;
            }

            for (it++; it != cluster_centroids_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(obj_label_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(obj_label_ringbuf.front().header), &amp;(it-&gt;header))) {
                    p_cluster_centroids_buf = &amp;*(it-1);
                    break;
                }
            }

            if (it == cluster_centroids_ringbuf.end()) {
                p_cluster_centroids_buf = &amp;(cluster_centroids_ringbuf.back());
            }
        }
        publish_msg(p_obj_label_buf, p_cluster_centroids_buf);
        if (obj_pose_flag == true){
            buf_flag = false;
            obj_pose_flag = false;
            obj_label_ringbuf.clear();
            cluster_centroids_ringbuf.clear();
        }
        return true;
    } else {
        return false;
    }
}

void obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) {
    pthread_mutex_lock(&amp;mutex);
    obj_label_ringbuf.push_front(*obj_label_msg);
    //cluster_centroids is empty
    if (cluster_centroids_ringbuf.begin() == cluster_centroids_ringbuf.end()) {
        buf_flag = false;
        pthread_mutex_unlock(&amp;mutex);
        ROS_INFO(&quot;cluster_centroids ring buffer is empty&quot;);
        return;
    }
    buf_flag = true;
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (obj_pose_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}

void cluster_centroids_callback(const lidar_tracker::centroids::ConstPtr&amp; cluster_centroids_msg) {
    pthread_mutex_lock(&amp;mutex);
    cluster_centroids_ringbuf.push_front(*cluster_centroids_msg);
    //obj_label is empty
    if (obj_label_ringbuf.begin() == obj_label_ringbuf.end()) {
        buf_flag = false;
        ROS_INFO(&quot;obj_label ring buffer is empty&quot;);
        pthread_mutex_unlock(&amp;mutex);
        return;
    }

    buf_flag = true;
    pthread_mutex_unlock(&amp;mutex);
    pthread_mutex_lock(&amp;mutex);
    if (obj_pose_flag == true) {
        publish();
    }
    pthread_mutex_unlock(&amp;mutex);
}

#else
cv_tracker::obj_label obj_label_buf;
lidar_tracker::centroids cluster_centroids_buf;

bool publish() {
    if (buf_flag) {
        ROS_INFO(&quot;publish&quot;);
        obj_label__pub.publish(obj_label_buf);
        cluster_centroids__pub.publish(cluster_centroids_buf);
        if (obj_pose_flag == true){
            buf_flag = false;
            obj_pose_flag = false;
            obj_label_ringbuf.clear();
            cluster_centroids_ringbuf.clear();
        }
        return true;
    } else {
        ROS_INFO(&quot;publish failed&quot;);
        return false;
    }
}

void obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) {
    pthread_mutex_lock(&amp;mutex);
    obj_label_ringbuf.push_front(*obj_label_msg);

    //cluster_centroids is empty
    if (cluster_centroids_ringbuf.begin() == cluster_centroids_ringbuf.end()) {
        pthread_mutex_unlock(&amp;mutex);
        ROS_INFO(&quot;cluster_centroids ring buffer is empty&quot;);
        return;
    }

    buf_flag = true;

    // obj_label &gt; cluster_centroids
    if (get_time(&amp;(obj_label_ringbuf.front().header)) &gt;= get_time(&amp;(cluster_centroids_ringbuf.front().header))) {
        cluster_centroids_buf = cluster_centroids_ringbuf.front();
        boost::circular_buffer&lt;cv_tracker::obj_label&gt;::iterator it = obj_label_ringbuf.begin();
        if (obj_label_ringbuf.size() == 1) {
            obj_label_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            pthread_mutex_lock(&amp;mutex);
            if (obj_pose_flag == true) {
                publish();
            }
            pthread_mutex_unlock(&amp;mutex);
            return;
        } else {
            for (it++; it != obj_label_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(cluster_centroids_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(cluster_centroids_ringbuf.front().header), &amp;(it-&gt;header))) {
                    obj_label_buf = *(it-1);
                    break;
                }
            }
            if (it == obj_label_ringbuf.end()) {
                obj_label_buf = obj_label_ringbuf.back();
            }
        }

    } else {
        obj_label_buf = obj_label_ringbuf.front();
        boost::circular_buffer&lt;lidar_tracker::centroids&gt;::iterator it = cluster_centroids_ringbuf.begin();
        if (cluster_centroids_ringbuf.size() == 1) {
            cluster_centroids_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            pthread_mutex_lock(&amp;mutex);
            if (obj_pose_flag == true) {
                publish();
            }
            pthread_mutex_unlock(&amp;mutex);
            return;
        }

        for (it++; it != cluster_centroids_ringbuf.end(); it++) {
            if (fabs_time_diff(&amp;(obj_label_ringbuf.front().header), &amp;((it-1)-&gt;header))
                &lt; fabs_time_diff(&amp;(obj_label_ringbuf.front().header), &amp;(it-&gt;header))) {
                cluster_centroids_buf = *(it-1);
                break;
            }
        }

        if (it == cluster_centroids_ringbuf.end()) {
            cluster_centroids_buf = cluster_centroids_ringbuf.back();
        }
    }
    pthread_mutex_unlock(&amp;mutex);
}

void cluster_centroids_callback(const lidar_tracker::centroids::ConstPtr&amp; cluster_centroids_msg) {
    pthread_mutex_lock(&amp;mutex);
    cluster_centroids_ringbuf.push_front(*cluster_centroids_msg);
    //obj_label is empty
    if (obj_label_ringbuf.begin() == obj_label_ringbuf.end()) {
        ROS_INFO(&quot;obj_label ring buffer is empty&quot;);
        pthread_mutex_unlock(&amp;mutex);
        return;
    }

    buf_flag = true;

    // obj_label &gt; cluster_centroids
    if (get_time(&amp;(obj_label_ringbuf.front().header)) &gt;= get_time(&amp;(cluster_centroids_ringbuf.front().header))) {
        cluster_centroids_buf = cluster_centroids_ringbuf.front();
        boost::circular_buffer&lt;cv_tracker::obj_label&gt;::iterator it = obj_label_ringbuf.begin();
        if (obj_label_ringbuf.size() == 1) {
            obj_label_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            pthread_mutex_lock(&amp;mutex);
            if (obj_pose_flag == true) {
                publish();
            }
            pthread_mutex_unlock(&amp;mutex);
            return;
        } else {
            for (it++; it != obj_label_ringbuf.end(); it++) {
                if (fabs_time_diff(&amp;(cluster_centroids_ringbuf.front().header), &amp;((it-1)-&gt;header))
                    &lt; fabs_time_diff(&amp;(cluster_centroids_ringbuf.front().header), &amp;(it-&gt;header))) {
                    obj_label_buf = *(it-1);
                    break;
                }
            }
            if (it == obj_label_ringbuf.end()) {
                obj_label_buf = obj_label_ringbuf.back();
            }
        }

    } else {
        obj_label_buf = obj_label_ringbuf.front();
        boost::circular_buffer&lt;lidar_tracker::centroids&gt;::iterator it = cluster_centroids_ringbuf.begin();
        if (cluster_centroids_ringbuf.size() == 1) {
            cluster_centroids_buf = *it;
            pthread_mutex_unlock(&amp;mutex);
            pthread_mutex_lock(&amp;mutex);
            if (obj_pose_flag == true) {
                publish();
            }
            pthread_mutex_unlock(&amp;mutex);
            return;
        }

        for (it++; it != cluster_centroids_ringbuf.end(); it++) {
            if (fabs_time_diff(&amp;(obj_label_ringbuf.front().header), &amp;((it-1)-&gt;header))
                &lt; fabs_time_diff(&amp;(obj_label_ringbuf.front().header), &amp;(it-&gt;header))) {
                cluster_centroids_buf = *(it-1);
                break;
            }
        }

        if (it == cluster_centroids_ringbuf.end()) {
            cluster_centroids_buf = cluster_centroids_ringbuf.back();
        }
    }
    pthread_mutex_unlock(&amp;mutex);
}

#endif

void obj_pose_callback(const visualization_msgs::MarkerArray::ConstPtr&amp; obj_pose_msg) {
    pthread_mutex_lock(&amp;mutex);
    obj_pose_flag = true;
    ROS_INFO(&quot;catch publish request&quot;);
    if (publish() == false) {
        ROS_INFO(&quot;waitting...&quot;);
    }
    pthread_mutex_unlock(&amp;mutex);}

void* thread(void* args)
{
    ros::NodeHandle nh_rcv;
    ros::CallbackQueue rcv_callbackqueue;
    nh_rcv.setCallbackQueue(&amp;rcv_callbackqueue);
    ros::Subscriber obj_pose_sub = nh_rcv.subscribe(&quot;/obj_car/obj_pose&quot;, 5, obj_pose_callback);
    while (nh_rcv.ok()) {
        rcv_callbackqueue.callAvailable(ros::WallDuration(1.0f));
        pthread_mutex_lock(&amp;mutex);
        bool flag = (obj_pose_flag == false &amp;&amp; buf_flag == true);
        if (flag) {
            ROS_INFO(&quot;timeout&quot;);
            if(!publish()) {
                /* when to publish is failure, republish */
                struct timespec sleep_time;
                sleep_time.tv_sec = 0;
                sleep_time.tv_nsec = 200000000; //5Hz
                while (!publish() &amp;&amp; ros::ok())
                    nanosleep(&amp;sleep_time, NULL);
            }
        }
        pthread_mutex_unlock(&amp;mutex);
    }
    return NULL;
}

int main(int argc, char **argv) {
    /* init */
    buf_flag = false;
    obj_pose_flag = false;
    ros::init(argc, argv, &quot;sync_obj_fusion&quot;);
    ros::NodeHandle nh;

    /* create server thread */
    pthread_t th;
    pthread_create(&amp;th, NULL, thread, (void *)NULL );

    ros::Subscriber obj_label_sub = nh.subscribe(&quot;/obj_label&quot;, 1, obj_label_callback);
    ros::Subscriber cluster_centroids_sub = nh.subscribe(&quot;/cluster_centroids&quot;, 1, cluster_centroids_callback);
    obj_label__pub = nh.advertise&lt;cv_tracker::obj_label&gt;(&quot;/sync_obj_fusion/obj_label&quot;, 5);
    cluster_centroids__pub = nh.advertise&lt;lidar_tracker::centroids&gt;(&quot;/sync_obj_fusion/cluster_centroids&quot;, 5);
    while (!buf_flag &amp;&amp; ros::ok()) {
        ros::spinOnce();
        usleep(100000);
    }
    pthread_mutex_lock(&amp;mutex);
    if(!publish()) {
        /* when to publish is failure, republish */
        struct timespec sleep_time;
        sleep_time.tv_sec = 0;
        sleep_time.tv_nsec = 200000000; //5Hz
        while (!publish() &amp;&amp; ros::ok())
            nanosleep(&amp;sleep_time, NULL);
    }
    pthread_mutex_unlock(&amp;mutex);

    ros::spin();

    /* shutdown server thread */
    ROS_INFO(&quot;wait until shutdown a thread&quot;);
    pthread_kill(th, SIGINT);
    pthread_join(th, NULL);

    return 0;
}
#endif
</old_file>
			</file>
			<file old_path="ros/src/system/sync/time_monitor.cpp" new_path="ros/src/system/sync/time_monitor.cpp">
				<diff>@@ -37,12 +37,12 @@
 /* user header */
 #include &quot;sensor_msgs/Image.h&quot;
 #include &quot;sensor_msgs/PointCloud2.h&quot;
-#include &quot;cv_tracker/image_obj.h&quot;
+#include &quot;cv_tracker_msgs/image_obj.h&quot;
 #include &quot;points2image/PointsImage.h&quot;
-#include &quot;cv_tracker/image_obj_ranged.h&quot;
-#include &quot;cv_tracker/image_obj_tracked.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
+#include &quot;cv_tracker_msgs/image_obj_tracked.h&quot;
 #include &quot;geometry_msgs/PoseStamped.h&quot;
-#include &quot;cv_tracker/obj_label.h&quot;
+#include &quot;cv_tracker_msgs/obj_label.h&quot;
 #include &quot;lidar_tracker/centroids.h&quot;
 #include &quot;visualization_msgs/MarkerArray.h&quot;
 #include &quot;synchronization/time_monitor.h&quot;
@@ -181,19 +181,19 @@ public:
     void points_image_callback(const points2image::PointsImage::ConstPtr&amp; points_image_msg);
     void vscan_points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; vscan_points_msg);
     void vscan_image_callback(const points2image::PointsImage::ConstPtr&amp; vscan_image_msg);
-    void image_obj_callback(const cv_tracker::image_obj::ConstPtr&amp; image_obj_msg);
-    void image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg);
-    void image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg);
+    void image_obj_callback(const cv_tracker_msgs::image_obj::ConstPtr&amp; image_obj_msg);
+    void image_obj_ranged_callback(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg);
+    void image_obj_tracked_callback(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg);
     void current_pose_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; current_pose_msg);
-    void obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) ;
+    void obj_label_callback(const cv_tracker_msgs::obj_label::ConstPtr&amp; obj_label_msg) ;
     void cluster_centroids_callback(const lidar_tracker::centroids::ConstPtr&amp; cluster_centroids_msg);
 //    void obj_pose_callback(const visualization_msgs::MarkerArray::ConstPtr&amp; obj_pose_msg);
     void obj_pose_callback(const std_msgs::Time::ConstPtr&amp; obj_pose_timestamp_msg);
     // sync
-    void sync_image_obj_ranged_callback(const cv_tracker::image_obj::ConstPtr&amp; sync_image_obj_msg);
-    void sync_image_obj_tracked_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; sync_image_obj_ranged_msg);
-    void sync_obj_label_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; sync_image_obj_tracked_msg);
-    void sync_obj_pose_callback(const cv_tracker::obj_label::ConstPtr&amp; sync_obj_label_msg);
+    void sync_image_obj_ranged_callback(const cv_tracker_msgs::image_obj::ConstPtr&amp; sync_image_obj_msg);
+    void sync_image_obj_tracked_callback(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; sync_image_obj_ranged_msg);
+    void sync_obj_label_callback(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; sync_image_obj_tracked_msg);
+    void sync_obj_pose_callback(const cv_tracker_msgs::obj_label::ConstPtr&amp; sync_obj_label_msg);
     // time difference
     void time_diff_callback(const synchronization::time_diff::ConstPtr&amp; time_diff_msg);
     void run();
@@ -276,17 +276,17 @@ void TimeManager::vscan_image_callback(const points2image::PointsImage::ConstPtr
     vscan_image_.push_front(vscan_image_msg-&gt;header.stamp, get_walltime_now());
 }
 
-void TimeManager::image_obj_callback(const cv_tracker::image_obj::ConstPtr&amp; image_obj_msg) {
+void TimeManager::image_obj_callback(const cv_tracker_msgs::image_obj::ConstPtr&amp; image_obj_msg) {
 //    ROS_INFO(&quot;image_obj: \t\t\t%d.%d&quot;, image_obj_msg-&gt;header.stamp.sec, image_obj_msg-&gt;header.stamp.nsec);
     image_obj_.push_front(image_obj_msg-&gt;header.stamp, get_walltime_now());
 }
 
-void TimeManager::image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
+void TimeManager::image_obj_ranged_callback(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
 //    ROS_INFO(&quot;image_obj_ranged: \t\t%d.%d&quot;, image_obj_ranged_msg-&gt;header.stamp.sec, image_obj_ranged_msg-&gt;header.stamp.nsec);
     image_obj_ranged_.push_front(image_obj_ranged_msg-&gt;header.stamp, get_walltime_now());
 }
 
-void TimeManager::image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
+void TimeManager::image_obj_tracked_callback(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
 //    ROS_INFO(&quot;image_obj_tracked: \t\t%d.%d&quot;, image_obj_tracked_msg-&gt;header.stamp.sec, image_obj_tracked_msg-&gt;header.stamp.nsec);
     image_obj_tracked_.push_front(image_obj_tracked_msg-&gt;header.stamp, get_walltime_now());
 }
@@ -296,7 +296,7 @@ void TimeManager::current_pose_callback(const geometry_msgs::PoseStamped::ConstP
     current_pose_.push_front(current_pose_msg-&gt;header.stamp, get_walltime_now());
 }
 
-void TimeManager::obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) {
+void TimeManager::obj_label_callback(const cv_tracker_msgs::obj_label::ConstPtr&amp; obj_label_msg) {
 //    ROS_INFO(&quot;obj_label: \t\t\t%d.%d&quot;, obj_label_msg-&gt;header.stamp.sec, obj_label_msg-&gt;header.stamp.nsec);
     obj_label_.push_front(obj_label_msg-&gt;header.stamp, get_walltime_now());
 }
@@ -307,22 +307,22 @@ void TimeManager::cluster_centroids_callback(const lidar_tracker::centroids::Con
 }
 
 /* sync */
-void TimeManager::sync_image_obj_ranged_callback(const cv_tracker::image_obj::ConstPtr&amp; sync_image_obj_msg) {
+void TimeManager::sync_image_obj_ranged_callback(const cv_tracker_msgs::image_obj::ConstPtr&amp; sync_image_obj_msg) {
 //    ROS_INFO(&quot;sync_image_obj_ranged: \t\t%d.%d&quot;, sync_image_obj_msg-&gt;header.stamp.sec, sync_image_obj_msg-&gt;header.stamp.nsec);
     sync_image_obj_ranged_.push_front(sync_image_obj_msg-&gt;header.stamp, get_walltime_now());
 }
 
-void TimeManager::sync_image_obj_tracked_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; sync_image_obj_ranged_msg) {
+void TimeManager::sync_image_obj_tracked_callback(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; sync_image_obj_ranged_msg) {
 //    ROS_INFO(&quot;sync_image_obj_tracked: \t%d.%d&quot;, sync_image_obj_ranged_msg-&gt;header.stamp.sec, sync_image_obj_ranged_msg-&gt;header.stamp.nsec);
     sync_image_obj_tracked_.push_front(sync_image_obj_ranged_msg-&gt;header.stamp, get_walltime_now());
 }
 
-void TimeManager::sync_obj_label_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; sync_image_obj_tracked_msg) {
+void TimeManager::sync_obj_label_callback(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; sync_image_obj_tracked_msg) {
 //    ROS_INFO(&quot;sync_obj_label: \t\t%d.%d&quot;, sync_image_obj_tracked_msg-&gt;header.stamp.sec, sync_image_obj_tracked_msg-&gt;header.stamp.nsec);
     sync_obj_label_.push_front(sync_image_obj_tracked_msg-&gt;header.stamp, get_walltime_now());
 }
 
-void TimeManager::sync_obj_pose_callback(const cv_tracker::obj_label::ConstPtr&amp; sync_obj_label_msg) {
+void TimeManager::sync_obj_pose_callback(const cv_tracker_msgs::obj_label::ConstPtr&amp; sync_obj_label_msg) {
 //    ROS_INFO(&quot;sync_obj_pose: \t\t\t%d.%d&quot;, sync_obj_label_msg-&gt;header.stamp.sec, sync_obj_label_msg-&gt;header.stamp.nsec);
     sync_obj_pose_.push_front(sync_obj_label_msg-&gt;header.stamp, get_walltime_now());
 }
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
/* ----header---- */
/* common header */
#include &quot;ros/ros.h&quot;
#include &lt;sstream&gt;
#include &lt;vector&gt;
#include &lt;boost/circular_buffer.hpp&gt;
#include &quot;std_msgs/Time.h&quot;
/* user header */
#include &quot;sensor_msgs/Image.h&quot;
#include &quot;sensor_msgs/PointCloud2.h&quot;
#include &quot;cv_tracker/image_obj.h&quot;
#include &quot;points2image/PointsImage.h&quot;
#include &quot;cv_tracker/image_obj_ranged.h&quot;
#include &quot;cv_tracker/image_obj_tracked.h&quot;
#include &quot;geometry_msgs/PoseStamped.h&quot;
#include &quot;cv_tracker/obj_label.h&quot;
#include &quot;lidar_tracker/centroids.h&quot;
#include &quot;visualization_msgs/MarkerArray.h&quot;
#include &quot;synchronization/time_monitor.h&quot;
#include &quot;synchronization/time_diff.h&quot;

/* ----var---- */
/* common var */

/* user var */
class KeyPair
{
    boost::circular_buffer&lt;ros::Time&gt; sensor;
    boost::circular_buffer&lt;ros::Time&gt; execution;

public:
    KeyPair() {
        sensor.resize(1);
        execution.resize(1);
    }
    void resize(int size) {
        sensor.resize(size);
        execution.resize(size);
    }
    void push_front(ros::Time sensor_time, ros::Time execution_time) {
        sensor.push_front(sensor_time);
        execution.push_front(execution_time);
    }
    ros::Time front(void) {
        return execution.front();
    }

    ros::Time find(ros::Time sensor_time) {
        boost::circular_buffer&lt;ros::Time&gt;::iterator it = sensor.begin();
        for (int i = 0; it != sensor.end(); it++, i++) {
            if (it-&gt;sec == sensor_time.sec &amp;&amp; it-&gt;nsec == sensor_time.nsec) {
                return execution.at(i); // find
            }
        }
        ROS_ERROR(&quot;error:not found a pair&quot;);
        ros::Time failed;
        failed.sec = 0;
        failed.nsec = 0;
        return failed; // not find
    }
};


class TimeManager
{
    /*
     * KeyPair
     */
    KeyPair image_raw_;
    KeyPair points_raw_;
    KeyPair points_image_;
    KeyPair vscan_points_;
    KeyPair vscan_image_;
    KeyPair image_obj_;
    KeyPair image_obj_ranged_;
    KeyPair image_obj_tracked_;
    KeyPair current_pose_;
    KeyPair obj_label_;
    KeyPair cluster_centroids_;
    KeyPair obj_pose_;
    // sync
    KeyPair sync_image_obj_ranged_;
    KeyPair sync_image_obj_tracked_;
    KeyPair sync_obj_label_;
    KeyPair sync_obj_pose_;
    // time difference
    KeyPair time_diff_;

    /*
     * Nodehandle, Subscriber, Publisher
     */
    // Nodehandle
    ros::NodeHandle nh;
    // Subscriber
    ros::Subscriber image_raw_sub;
    ros::Subscriber points_raw_sub;
    ros::Subscriber points_image_sub;
    ros::Subscriber vscan_points_sub;
    ros::Subscriber vscan_image_sub;
    ros::Subscriber image_obj_sub;
    ros::Subscriber image_obj_ranged_sub;
    ros::Subscriber image_obj_tracked_sub;
    ros::Subscriber current_pose_sub;
    ros::Subscriber obj_label_sub;
    ros::Subscriber cluster_centroids_sub;
    ros::Subscriber obj_pose_sub;
    ros::Subscriber time_diff_sub;
    ros::Subscriber sync_image_obj_ranged_sub; // sync
    ros::Subscriber sync_image_obj_tracked_sub; // sync
    ros::Subscriber sync_obj_label_sub; // sync
    ros::Subscriber sync_obj_pose_sub; // sync
    // Publisher
    ros::Publisher time_monitor_pub;

    bool is_points_image_;
    bool is_vscan_image_;

    ros::Time get_walltime_now() {
        ros::WallTime non_sim_current_time = ros::WallTime::now();
        ros::Time casted_time;
        casted_time.sec = non_sim_current_time.sec;
        casted_time.nsec = non_sim_current_time.nsec;
        return casted_time;
    }


    double ros_time2msec(ros::Time time) {
        return (double)time.sec*1000L + (double)time.nsec/1000000L;
    }
    double time_diff(ros::Time sensor_time, ros::Time execution_time) {
        if (execution_time.sec == 0 &amp;&amp; execution_time.nsec == 0) { // not find
            ROS_ERROR(&quot;error:execution time is 0&quot;);
            return 0.0;
        }
        if (sensor_time.sec == 0 &amp;&amp; sensor_time.nsec == 0) { // not find
            ROS_ERROR(&quot;error:execution time is 0&quot;);
            return 0.0;
        }

        double time_diff = ros_time2msec(execution_time) - ros_time2msec(sensor_time);
        if (time_diff &gt;= 0)
            return time_diff;
        else
            ROS_ERROR(&quot;error:time difference is less than 0&quot;);
            return 0.0;
    }

public:
    TimeManager(int);
    void image_raw_callback(const sensor_msgs::Image::ConstPtr&amp; image_raw_msg);
    void points_raw_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; points_raw_msg);
    void points_image_callback(const points2image::PointsImage::ConstPtr&amp; points_image_msg);
    void vscan_points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; vscan_points_msg);
    void vscan_image_callback(const points2image::PointsImage::ConstPtr&amp; vscan_image_msg);
    void image_obj_callback(const cv_tracker::image_obj::ConstPtr&amp; image_obj_msg);
    void image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg);
    void image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg);
    void current_pose_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; current_pose_msg);
    void obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) ;
    void cluster_centroids_callback(const lidar_tracker::centroids::ConstPtr&amp; cluster_centroids_msg);
//    void obj_pose_callback(const visualization_msgs::MarkerArray::ConstPtr&amp; obj_pose_msg);
    void obj_pose_callback(const std_msgs::Time::ConstPtr&amp; obj_pose_timestamp_msg);
    // sync
    void sync_image_obj_ranged_callback(const cv_tracker::image_obj::ConstPtr&amp; sync_image_obj_msg);
    void sync_image_obj_tracked_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; sync_image_obj_ranged_msg);
    void sync_obj_label_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; sync_image_obj_tracked_msg);
    void sync_obj_pose_callback(const cv_tracker::obj_label::ConstPtr&amp; sync_obj_label_msg);
    // time difference
    void time_diff_callback(const synchronization::time_diff::ConstPtr&amp; time_diff_msg);
    void run();
};

TimeManager::TimeManager(int buffer_size) {
    ros::NodeHandle private_nh(&quot;~&quot;);
    private_nh.param(&quot;is_points_image&quot;, is_points_image_, true);
    private_nh.param(&quot;is_vscan_image&quot;, is_vscan_image_, false);

    if (is_vscan_image_ == is_points_image_) {
        ROS_ERROR(&quot;choose is_points_image or is_vscan_image&quot;);
        is_points_image_ = true;
        is_vscan_image_ = false;
    }

    time_monitor_pub = nh.advertise&lt;synchronization::time_monitor&gt; (&quot;/times&quot;, 10);
    image_raw_sub = nh.subscribe(&quot;/sync_drivers/image_raw&quot;, 10, &amp;TimeManager::image_raw_callback, this);
    points_raw_sub = nh.subscribe(&quot;/sync_drivers/points_raw&quot;, 10, &amp;TimeManager::points_raw_callback, this);
    points_image_sub = nh.subscribe(&quot;/points_image&quot;, 10, &amp;TimeManager::points_image_callback, this);
    vscan_points_sub = nh.subscribe(&quot;/vscan_points&quot;, 10, &amp;TimeManager::vscan_points_callback, this);
    vscan_image_sub = nh.subscribe(&quot;/vscan_image&quot;, 10, &amp;TimeManager::vscan_image_callback, this);
    image_obj_sub = nh.subscribe(&quot;/image_obj&quot;, 10, &amp;TimeManager::image_obj_callback, this);
    image_obj_ranged_sub = nh.subscribe(&quot;/image_obj_ranged&quot;, 10, &amp;TimeManager::image_obj_ranged_callback, this);
    image_obj_tracked_sub = nh.subscribe(&quot;/image_obj_tracked&quot;, 10, &amp;TimeManager::image_obj_tracked_callback, this);
    current_pose_sub = nh.subscribe(&quot;/current_pose&quot;, 10, &amp;TimeManager::current_pose_callback, this);
    obj_label_sub = nh.subscribe(&quot;/obj_label&quot;, 10, &amp;TimeManager::obj_label_callback, this);
    cluster_centroids_sub = nh.subscribe(&quot;/cluster_centroids&quot;, 10, &amp;TimeManager::cluster_centroids_callback, this);
    obj_pose_sub = nh.subscribe(&quot;/obj_pose_timestamp&quot;, 10, &amp;TimeManager::obj_pose_callback, this);
//    obj_pose_sub = nh.subscribe(&quot;/obj_car/obj_pose&quot;, 10, &amp;TimeManager::obj_pose_callback, this);
    // sync
    sync_image_obj_ranged_sub = nh.subscribe(&quot;/sync_ranging/image_obj&quot;, 10 , &amp;TimeManager::sync_image_obj_ranged_callback, this);
    sync_image_obj_tracked_sub = nh.subscribe(&quot;/sync_tracking/image_obj_ranged&quot;, 10, &amp;TimeManager::sync_image_obj_tracked_callback, this);
    sync_obj_label_sub = nh.subscribe(&quot;/sync_reprojection/image_obj_tracked&quot;, 10, &amp;TimeManager::sync_obj_label_callback, this);
    sync_obj_pose_sub = nh.subscribe(&quot;/sync_obj_fusion/obj_label&quot;, 10, &amp;TimeManager::sync_obj_pose_callback, this);
    // time difference
    time_diff_sub = nh.subscribe(&quot;/time_difference&quot;, 10, &amp;TimeManager::time_diff_callback, this);

    image_raw_.resize(buffer_size);
    points_raw_.resize(buffer_size);
    points_image_.resize(buffer_size);
    vscan_points_.resize(buffer_size);
    vscan_image_.resize(buffer_size);
    image_obj_.resize(buffer_size);
    image_obj_ranged_.resize(buffer_size);
    image_obj_tracked_.resize(buffer_size);
    current_pose_.resize(buffer_size);
    obj_label_.resize(buffer_size);
    obj_pose_.resize(buffer_size);
    cluster_centroids_.resize(buffer_size);
    sync_image_obj_ranged_.resize(buffer_size);
    sync_image_obj_tracked_.resize(buffer_size);
    sync_obj_label_.resize(buffer_size);
    sync_obj_pose_.resize(buffer_size);
    time_diff_.resize(buffer_size);
}

void TimeManager::image_raw_callback(const sensor_msgs::Image::ConstPtr&amp; image_raw_msg) {
//    ROS_INFO(&quot;image_raw: \t\t\t%d.%d&quot;, image_raw_msg-&gt;header.stamp.sec, image_raw_msg-&gt;header.stamp.nsec);
    image_raw_.push_front(image_raw_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::points_raw_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; points_raw_msg) {
//    ROS_INFO(&quot;points_raw: \t\t\t%d.%d&quot;, points_raw_msg-&gt;header.stamp.sec, points_raw_msg-&gt;header.stamp.nsec);
    points_raw_.push_front(points_raw_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::points_image_callback(const points2image::PointsImage::ConstPtr&amp; points_image_msg) {
//    ROS_INFO(&quot;vscan_image: \t\t\t%d.%d&quot;, vscan_image_msg-&gt;header.stamp.sec, vscan_image_msg-&gt;header.stamp.nsec);
    points_image_.push_front(points_image_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::vscan_points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; vscan_points_msg) {
//    ROS_INFO(&quot;vscan_points: \t\t\t%d.%d&quot;, vscan_points_msg-&gt;header.stamp.sec, vscan_points_msg-&gt;header.stamp.nsec);
    vscan_points_.push_front(vscan_points_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::vscan_image_callback(const points2image::PointsImage::ConstPtr&amp; vscan_image_msg) {
//    ROS_INFO(&quot;vscan_image: \t\t\t%d.%d&quot;, vscan_image_msg-&gt;header.stamp.sec, vscan_image_msg-&gt;header.stamp.nsec);
    vscan_image_.push_front(vscan_image_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::image_obj_callback(const cv_tracker::image_obj::ConstPtr&amp; image_obj_msg) {
//    ROS_INFO(&quot;image_obj: \t\t\t%d.%d&quot;, image_obj_msg-&gt;header.stamp.sec, image_obj_msg-&gt;header.stamp.nsec);
    image_obj_.push_front(image_obj_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::image_obj_ranged_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; image_obj_ranged_msg) {
//    ROS_INFO(&quot;image_obj_ranged: \t\t%d.%d&quot;, image_obj_ranged_msg-&gt;header.stamp.sec, image_obj_ranged_msg-&gt;header.stamp.nsec);
    image_obj_ranged_.push_front(image_obj_ranged_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::image_obj_tracked_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; image_obj_tracked_msg) {
//    ROS_INFO(&quot;image_obj_tracked: \t\t%d.%d&quot;, image_obj_tracked_msg-&gt;header.stamp.sec, image_obj_tracked_msg-&gt;header.stamp.nsec);
    image_obj_tracked_.push_front(image_obj_tracked_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::current_pose_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; current_pose_msg) {
//    ROS_INFO(&quot;current_pose: \t\t\t%d.%d&quot;, current_pose_msg-&gt;header.stamp.sec, current_pose_msg-&gt;header.stamp.nsec);
    current_pose_.push_front(current_pose_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::obj_label_callback(const cv_tracker::obj_label::ConstPtr&amp; obj_label_msg) {
//    ROS_INFO(&quot;obj_label: \t\t\t%d.%d&quot;, obj_label_msg-&gt;header.stamp.sec, obj_label_msg-&gt;header.stamp.nsec);
    obj_label_.push_front(obj_label_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::cluster_centroids_callback(const lidar_tracker::centroids::ConstPtr&amp; cluster_centroids_msg) {
//    ROS_INFO(&quot;cluster_centroids: \t\t%d.%d&quot;, cluster_centroids_msg-&gt;header.stamp.sec, cluster_centroids_msg-&gt;header.stamp.nsec);
    cluster_centroids_.push_front(cluster_centroids_msg-&gt;header.stamp, get_walltime_now());
}

/* sync */
void TimeManager::sync_image_obj_ranged_callback(const cv_tracker::image_obj::ConstPtr&amp; sync_image_obj_msg) {
//    ROS_INFO(&quot;sync_image_obj_ranged: \t\t%d.%d&quot;, sync_image_obj_msg-&gt;header.stamp.sec, sync_image_obj_msg-&gt;header.stamp.nsec);
    sync_image_obj_ranged_.push_front(sync_image_obj_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::sync_image_obj_tracked_callback(const cv_tracker::image_obj_ranged::ConstPtr&amp; sync_image_obj_ranged_msg) {
//    ROS_INFO(&quot;sync_image_obj_tracked: \t%d.%d&quot;, sync_image_obj_ranged_msg-&gt;header.stamp.sec, sync_image_obj_ranged_msg-&gt;header.stamp.nsec);
    sync_image_obj_tracked_.push_front(sync_image_obj_ranged_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::sync_obj_label_callback(const cv_tracker::image_obj_tracked::ConstPtr&amp; sync_image_obj_tracked_msg) {
//    ROS_INFO(&quot;sync_obj_label: \t\t%d.%d&quot;, sync_image_obj_tracked_msg-&gt;header.stamp.sec, sync_image_obj_tracked_msg-&gt;header.stamp.nsec);
    sync_obj_label_.push_front(sync_image_obj_tracked_msg-&gt;header.stamp, get_walltime_now());
}

void TimeManager::sync_obj_pose_callback(const cv_tracker::obj_label::ConstPtr&amp; sync_obj_label_msg) {
//    ROS_INFO(&quot;sync_obj_pose: \t\t\t%d.%d&quot;, sync_obj_label_msg-&gt;header.stamp.sec, sync_obj_label_msg-&gt;header.stamp.nsec);
    sync_obj_pose_.push_front(sync_obj_label_msg-&gt;header.stamp, get_walltime_now());
}

/* time difference */
void TimeManager::time_diff_callback(const synchronization::time_diff::ConstPtr&amp; time_diff_msg) {
    ros::Time sensors_time_diff;
    double lidar = (double)time_diff_msg-&gt;lidar.sec + (double)time_diff_msg-&gt;lidar.nsec/1000000000.0L;
    double camera = (double)time_diff_msg-&gt;camera.sec + (double)time_diff_msg-&gt;camera.nsec/1000000000.0L;

    if (time_diff_msg-&gt;lidar.sec &gt; time_diff_msg-&gt;camera.sec) {
        sensors_time_diff.sec = time_diff_msg-&gt;lidar.sec - time_diff_msg-&gt;camera.sec;
        if (time_diff_msg-&gt;lidar.nsec &gt;= time_diff_msg-&gt;camera.nsec) {
            sensors_time_diff.nsec = time_diff_msg-&gt;lidar.nsec - time_diff_msg-&gt;camera.nsec;
        } else {
            sensors_time_diff.sec -= 1;
            sensors_time_diff.nsec = 1000000000L + time_diff_msg-&gt;lidar.nsec - time_diff_msg-&gt;camera.nsec;
        }
    } else if  (time_diff_msg-&gt;lidar.sec &lt; time_diff_msg-&gt;camera.sec) {
        sensors_time_diff.sec = time_diff_msg-&gt;camera.sec - time_diff_msg-&gt;lidar.sec;
        if (time_diff_msg-&gt;camera.nsec &gt;= time_diff_msg-&gt;lidar.nsec) {
            sensors_time_diff.nsec = time_diff_msg-&gt;camera.nsec - time_diff_msg-&gt;lidar.nsec;
        } else {
            sensors_time_diff.sec -= 1;
            sensors_time_diff.nsec = 1000000000L + time_diff_msg-&gt;camera.nsec - time_diff_msg-&gt;lidar.nsec;
        }
    } else if (time_diff_msg-&gt;lidar.sec == time_diff_msg-&gt;camera.sec) {
        sensors_time_diff.sec = 0;
        if (time_diff_msg-&gt;lidar.nsec &gt;= time_diff_msg-&gt;camera.nsec) {
            sensors_time_diff.nsec = time_diff_msg-&gt;lidar.nsec - time_diff_msg-&gt;camera.nsec;
        } else {
            sensors_time_diff.nsec = time_diff_msg-&gt;camera.nsec - time_diff_msg-&gt;lidar.nsec;
        }
    } else {
        // not impl
        ROS_ERROR(&quot;Exception error&quot;);
    }
    time_diff_.push_front(time_diff_msg-&gt;header.stamp, sensors_time_diff);
}

void TimeManager::obj_pose_callback(const std_msgs::Time::ConstPtr&amp; obj_pose_timestamp_msg) {
//    ROS_INFO(&quot;obj_pose: \t\t\t%d.%d&quot;, obj_pose_timestamp_msg-&gt;data.sec, obj_pose_timestamp_msg-&gt;data.nsec);
    obj_pose_.push_front(obj_pose_timestamp_msg-&gt;data, get_walltime_now());
    static ros::Time pre_sensor_time;

    synchronization::time_monitor time_monitor_msg;
    time_monitor_msg.header.frame_id = &quot;0&quot;;
    time_monitor_msg.header.stamp = ros::Time::now();

    // ROS_INFO(&quot;-------------------------------------&quot;);
    // ROS_INFO(&quot;image_raw&quot;);
    if (!ros::Time::isSimTime()) {
        time_monitor_msg.image_raw = time_diff(obj_pose_timestamp_msg-&gt;data,
                                               image_raw_.find(obj_pose_timestamp_msg-&gt;data));
    } else {
        time_monitor_msg.image_raw = 0;
    }

    // ROS_INFO(&quot;points_raw&quot;);
    if (!ros::Time::isSimTime()) {
        time_monitor_msg.points_raw = time_diff(obj_pose_timestamp_msg-&gt;data,
                                                points_raw_.find(obj_pose_timestamp_msg-&gt;data));
    } else {
        time_monitor_msg.points_raw = 0;
    }

    if (is_points_image_) {
        // ROS_INFO(&quot;points_image&quot;);
        time_monitor_msg.points_image = time_diff(points_raw_.find(obj_pose_timestamp_msg-&gt;data),
                                                  points_image_.find(obj_pose_timestamp_msg-&gt;data));
    }
    if (is_vscan_image_) {
        // ROS_INFO(&quot;vscan_points&quot;);
        time_monitor_msg.vscan_points = time_diff(points_raw_.find(obj_pose_timestamp_msg-&gt;data),
                                                  vscan_points_.find(obj_pose_timestamp_msg-&gt;data));
        // ROS_INFO(&quot;vscan_image&quot;);
        time_monitor_msg.vscan_image = time_diff(vscan_points_.find(obj_pose_timestamp_msg-&gt;data),
        vscan_image_.find(obj_pose_timestamp_msg-&gt;data));
    }

    // ROS_INFO(&quot;image_obj&quot;);
    time_monitor_msg.image_obj = time_diff(image_raw_.find(obj_pose_timestamp_msg-&gt;data),
                                           image_obj_.find(obj_pose_timestamp_msg-&gt;data));
    // ROS_INFO(&quot;image_obj_ranged&quot;);
    time_monitor_msg.image_obj_ranged = time_diff(sync_image_obj_ranged_.find(obj_pose_timestamp_msg-&gt;data),
                                                  image_obj_ranged_.find(obj_pose_timestamp_msg-&gt;data));
    // ROS_INFO(&quot;image_obj_tracked&quot;);
    time_monitor_msg.image_obj_tracked = time_diff(sync_image_obj_tracked_.find(obj_pose_timestamp_msg-&gt;data),
                                                   image_obj_tracked_.find(obj_pose_timestamp_msg-&gt;data));
    // ROS_INFO(&quot;current_pose&quot;);
    time_monitor_msg.current_pose = time_diff(points_raw_.find(obj_pose_timestamp_msg-&gt;data),
                                              current_pose_.find(obj_pose_timestamp_msg-&gt;data));
    // ROS_INFO(&quot;obj_label&quot;);
    time_monitor_msg.obj_label = time_diff(sync_obj_label_.find(obj_pose_timestamp_msg-&gt;data),
                                           obj_label_.find(obj_pose_timestamp_msg-&gt;data));
    // ROS_INFO(&quot;cluster_centroids&quot;);
    time_monitor_msg.cluster_centroids = time_diff(points_raw_.find(obj_pose_timestamp_msg-&gt;data),
                                                   cluster_centroids_.find(obj_pose_timestamp_msg-&gt;data));
    // ROS_INFO(&quot;obj_pose&quot;);
    time_monitor_msg.obj_pose = time_diff(sync_obj_pose_.find(obj_pose_timestamp_msg-&gt;data),
                                          obj_pose_.find(obj_pose_timestamp_msg-&gt;data));
    // ROS_INFO(&quot;-------------------------------------&quot;);

    if (!ros::Time::isSimTime()) {
        time_monitor_msg.execution_time = time_diff(obj_pose_timestamp_msg-&gt;data, obj_pose_.find(obj_pose_timestamp_msg-&gt;data));
    } else {
        time_monitor_msg.execution_time = time_diff(points_raw_.find(obj_pose_timestamp_msg-&gt;data), obj_pose_.find(obj_pose_timestamp_msg-&gt;data));
    }

    time_monitor_msg.cycle_time = time_diff(pre_sensor_time, obj_pose_timestamp_msg-&gt;data); // cycle time
    time_monitor_msg.time_diff = ros_time2msec(time_diff_.find(obj_pose_timestamp_msg-&gt;data)); // time difference
    time_monitor_pub.publish(time_monitor_msg);

    pre_sensor_time = obj_pose_timestamp_msg-&gt;data;
}

void TimeManager::run() {
    ros::spin();
}

int main(int argc, char **argv) {
  ros::init(argc, argv, &quot;time_monitor&quot;);

  TimeManager time_manager(64);
  time_manager.run();

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="b8ddc5f8925e8608d94bdc4051a66a9e3495a5a2" fix_time="261,78554">
		<msg>fix vg440 acceletation</msg>
		<modified_files>
			<file old_path="ros/src/sensing/drivers/imu/packages/memsic/nodes/vg440/vg440_node.cpp" new_path="ros/src/sensing/drivers/imu/packages/memsic/nodes/vg440/vg440_node.cpp">
				<diff>@@ -313,7 +313,7 @@ struct SNAV1Msg{
   double dRollRate; //[rad/s]
   double dPitchRate;
   double dYawRate;
-  double dXAccel; //[m/s^2]
+  double dXAccel; //[G]
   double dYAccel;
   double dZAccel;
   double dNVel;   //[m/s]
@@ -349,12 +349,14 @@ bool MsgToNav1(const unsigned char* data, SNAV1Msg &amp;sMsg) {
 }
 
 void Nav1ToRosImu(const SNAV1Msg &amp;rNav1, sensor_msgs::Imu &amp;ImuData) {
+  const double gravityAccel = 9.80665;
+  
   ImuData.angular_velocity.x = rNav1.dRollRate;
   ImuData.angular_velocity.y = rNav1.dPitchRate;
   ImuData.angular_velocity.z = rNav1.dYawRate;
-  ImuData.linear_acceleration.x = rNav1.dXAccel;
-  ImuData.linear_acceleration.y = rNav1.dYAccel;
-  ImuData.linear_acceleration.z = rNav1.dZAccel;
+  ImuData.linear_acceleration.x = rNav1.dXAccel * gravityAccel;
+  ImuData.linear_acceleration.y = rNav1.dYAccel * gravityAccel;
+  ImuData.linear_acceleration.z = rNav1.dZAccel * gravityAccel;
   ImuData.orientation = tf::createQuaternionMsgFromRollPitchYaw(rNav1.dRollAngle, rNav1.dPitchAngle, rNav1.dYawAngle);
 }
 
</diff>
				<old_file>#include &lt;ros/ros.h&gt;
#include &lt;sstream&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include &lt;iostream&gt;
#include &lt;boost/array.hpp&gt;
#include &lt;boost/asio.hpp&gt;
#include &lt;fstream&gt;
#include &lt;iomanip&gt;
#include &lt;boost/thread.hpp&gt;
#include &lt;sys/time.h&gt;
#include &lt;boost/lambda/lambda.hpp&gt;
#include &lt;boost/asio/deadline_timer.hpp&gt;
#include &lt;unistd.h&gt;
#include &lt;sensor_msgs/Imu.h&gt;
#include &lt;tf/tf.h&gt;
using namespace boost::lambda;
using namespace std;

class mmtimer{
public:
  mmtimer(void) {
    restart();
  }
  virtual ~mmtimer(void) {}
  double elapsed() {
    timeval tv2;
    gettimeofday(&amp;tv2, NULL);
    double time2 = tv2.tv_sec + (double)tv2.tv_usec*1e-6;
    return time2-_time;
  }
  void restart() {
    timeval tv;
    gettimeofday(&amp;tv, NULL);
    _time = tv.tv_sec + (double)tv.tv_usec*1e-6;
  }
private:
  double _time;
};


const int MAXQUEUE = 500;
struct QUEUE_TYPE
{
  int count;
  int front;
  int rear;
  char entry[MAXQUEUE];
};
struct XBOW_PACKET
{
  unsigned short packet_type;
  char length;
  unsigned short crc;
  char data[256];
};
QUEUE_TYPE circ_buf;

int process_xbow_packet(QUEUE_TYPE *queue_ptr, XBOW_PACKET *result);
unsigned short calcCRC(QUEUE_TYPE *queue_ptr, unsigned int startIndex, unsigned int num);
void Initialize(QUEUE_TYPE *queue_ptr);
int AddQueue(char item, QUEUE_TYPE *queue_ptr);
int DeleteQueue(char *item, QUEUE_TYPE *queue_ptr);
char peekByte(QUEUE_TYPE *queue_ptr, unsigned int index);
unsigned short peekWord(QUEUE_TYPE *queue_ptr, unsigned int index);
int Pop(QUEUE_TYPE *queue_ptr, int numToPop);
int Size(QUEUE_TYPE *queue_ptr);
int Empty(QUEUE_TYPE *queue_ptr);
int Full(QUEUE_TYPE *queue_ptr);

/*******************************************************************************
* FUNCTION: process_xbow_packet looks for packets in a queue
* ARGUMENTS: queue_ptr: is pointer to queue to process
* result: will contain the parsed info when return value is 1
* RETURNS: 0 when failed.
* 1 when successful
*******************************************************************************/
int process_xbow_packet(QUEUE_TYPE *queue_ptr, XBOW_PACKET *result)
{
  unsigned short myCRC = 0, packetCRC = 0, numToPop=0, counter=0;
//	unsigned short packet_type = 0;
//	char packet[100], tempchar, dataLength;
  char dataLength;
  if(Empty(queue_ptr))
  {
    return 0; /* empty buffer */
  }
  /* find header */
  for(numToPop=0; numToPop+1&lt;Size(queue_ptr) ;numToPop+=1)
  {
    if(0x5555==peekWord(queue_ptr, numToPop)) break;
  }
  Pop(queue_ptr, numToPop);
  if(Size(queue_ptr) &lt;= 0)
  {
  /* header was not found */
    return 0;
  }
  /* make sure we can read through minimum length packet */
  if(Size(queue_ptr)&lt;7)
  {
    return 0;
  }
  /* get data length (5th byte of packet) */
  dataLength = peekByte(queue_ptr, 4);
  /* make sure we can read through entire packet */
  if(Size(queue_ptr) &lt; 7+dataLength)
  {
    return 0;
  }
  /* check CRC */
  myCRC = calcCRC(queue_ptr, 2,dataLength+3);
  packetCRC = peekWord(queue_ptr, dataLength+5);
  if(myCRC != packetCRC)
  {
    Pop(queue_ptr, dataLength+7);
    return 0;
  }
  /* fill out result of parsing in structure */
  result-&gt;packet_type = peekWord(queue_ptr, 2);
  result-&gt;length = peekByte(queue_ptr, 4);
  result-&gt;crc = packetCRC;
  for(counter=0; counter &lt; result-&gt;length; counter++)
  {
    result-&gt;data[counter] = peekByte(queue_ptr, 5+counter);
  }
  Pop(queue_ptr, dataLength+7);
  return 1;
}

/*******************************************************************************
* FUNCTION: calcCRC calculates a 2-byte CRC on serial data using
* CRC-CCITT 16-bit standard maintained by the ITU
* (International Telecommunications Union).
* ARGUMENTS: queue_ptr is pointer to queue holding area to be CRCed
* startIndex is offset into buffer where to begin CRC calculation
* num is offset into buffer where to stop CRC calculation
* RETURNS: 2-byte CRC
440 Series User’s Manual
Doc# 7430-0131-01 Rev. D Page 73
*******************************************************************************/
unsigned short calcCRC(QUEUE_TYPE *queue_ptr, unsigned int startIndex, unsigned int num) {
  unsigned int i=0, j=0;
  unsigned short crc=0x1D0F; //non-augmented inital value equivalent to augmented initial value 0xFFFF
  for (i=0; i&lt;num; i+=1) {
    crc ^= peekByte(queue_ptr, startIndex+i) &lt;&lt; 8;
    for(j=0;j&lt;8;j+=1) {
      if(crc &amp; 0x8000) crc = (crc &lt;&lt; 1) ^ 0x1021;
      else crc = crc &lt;&lt; 1;
    }
  }
  return crc;
}
// for user send packets
unsigned short calcCRC(unsigned char *byte_ptr, unsigned int num) {
  unsigned int i=0, j=0;
  unsigned short crc=0x1D0F; //non-augmented inital value equivalent to augmented initial value 0xFFFF
  for (i=0; i&lt;num; i+=1) {
    crc ^= byte_ptr[i] &lt;&lt; 8;
    for(j=0;j&lt;8;j+=1) {
      if(crc &amp; 0x8000) crc = (crc &lt;&lt; 1) ^ 0x1021;
      else crc = crc &lt;&lt; 1;
    }
  }
  return crc;
}
/*******************************************************************************
* FUNCTION: Initialize - initialize the queue
* ARGUMENTS: queue_ptr is pointer to the queue
*******************************************************************************/
void Initialize(QUEUE_TYPE *queue_ptr)
{
  queue_ptr-&gt;count = 0;
  queue_ptr-&gt;front = 0;
  queue_ptr-&gt;rear = -1;
}
/*******************************************************************************
* FUNCTION: AddQueue - add item in front of queue
* ARGUMENTS: item holds item to be added to queue
* queue_ptr is pointer to the queue
* RETURNS: returns 0 if queue is full. 1 if successful
*******************************************************************************/
int AddQueue(char item, QUEUE_TYPE *queue_ptr)
{
  int retval = 0;
  if(queue_ptr-&gt;count &gt;= MAXQUEUE)
  {
    retval = 0; /* queue is full */
  }
  else
  {
    queue_ptr-&gt;count++;
    queue_ptr-&gt;rear = (queue_ptr-&gt;rear + 1) % MAXQUEUE;
    queue_ptr-&gt;entry[queue_ptr-&gt;rear] = item;
    retval = 1;
  }
  return retval;
}
/*******************************************************************************
* FUNCTION: DeleteQeue - return an item from the queue
* ARGUMENTS: item will hold item popped from queue
* queue_ptr is pointer to the queue
* RETURNS: returns 0 if queue is empty. 1 if successful
440 Series User’s Manual
Doc# 7430-0131-01 Rev. D Page 74
*******************************************************************************/
int DeleteQueue(char *item, QUEUE_TYPE *queue_ptr)
{
  int retval = 0;
  if(queue_ptr-&gt;count &lt;= 0)
  {
    retval = 0; /* queue is empty */
  }
  else
  {
    queue_ptr -&gt; count--;
    *item = queue_ptr-&gt;entry[queue_ptr-&gt;front];
    queue_ptr-&gt;front = (queue_ptr-&gt;front+1) % MAXQUEUE;
    retval=1;
  }
  return retval;
}
/*******************************************************************************
* FUNCTION: peekByte returns 1 byte from buffer without popping
* ARGUMENTS: queue_ptr is pointer to the queue to return byte from
* index is offset into buffer to which byte to return
* RETURNS: 1 byte
* REMARKS: does not do boundary checking. please do this first
*******************************************************************************/
char peekByte(QUEUE_TYPE *queue_ptr, unsigned int index) {
  char byte;
  int firstIndex;
  firstIndex = (queue_ptr-&gt;front + index) % MAXQUEUE;
  byte = queue_ptr-&gt;entry[firstIndex];
  return byte;
}
/*******************************************************************************
* FUNCTION: peekWord returns 2-byte word from buffer without popping
* ARGUMENTS: queue_ptr is pointer to the queue to return word from
* index is offset into buffer to which word to return
* RETURNS: 2-byte word
* REMARKS: does not do boundary checking. please do this first
*******************************************************************************/
unsigned short peekWord(QUEUE_TYPE *queue_ptr, unsigned int index) {
  unsigned short word, firstIndex, secondIndex;
  firstIndex = (queue_ptr-&gt;front + index) % MAXQUEUE;
  secondIndex = (queue_ptr-&gt;front + index + 1) % MAXQUEUE;
  word = (queue_ptr-&gt;entry[firstIndex] &lt;&lt; 8) &amp; 0xFF00;
  word |= (0x00FF &amp; queue_ptr-&gt;entry[secondIndex]);
  return word;
}
/*******************************************************************************
* FUNCTION: Pop - discard item(s) from queue
440 Series User’s Manual
Doc# 7430-0131-01 Rev. D Page 75
* ARGUMENTS: queue_ptr is pointer to the queue
* numToPop is number of items to discard
* RETURNS: return the number of items discarded
*******************************************************************************/
int Pop(QUEUE_TYPE *queue_ptr, int numToPop)
{
  int i=0;
  char tempchar;
  for(i=0; i&lt;numToPop; i++)
  {
    if(!DeleteQueue(&amp;tempchar, queue_ptr))
    {
      break;
    }
  }
  return i;
}
/*******************************************************************************
* FUNCTION: Size
* ARGUMENTS: queue_ptr is pointer to the queue
* RETURNS: return the number of items in the queue
*******************************************************************************/
int Size(QUEUE_TYPE *queue_ptr)
{
  return queue_ptr-&gt;count;
}
/*******************************************************************************
* FUNCTION: Empty
* ARGUMENTS: queue_ptr is pointer to the queue
* RETURNS: return 1 if empty, 0 if not
*******************************************************************************/
int Empty(QUEUE_TYPE *queue_ptr)
{
  return queue_ptr-&gt;count &lt;= 0;
}
/*******************************************************************************
* FUNCTION: Full
* ARGUMENTS: queue_ptr is pointer to the queue
* RETURNS: return 1 if full, 0 if not full
*******************************************************************************/
int Full(QUEUE_TYPE *queue_ptr)
{
  return queue_ptr-&gt;count &gt;= MAXQUEUE;
}

inline short MKShort(const unsigned char* data) {
  return (short)data[1] + (short)data[0]*256;
}
inline int MKInt(const unsigned char* data) {
  return (int)data[3] + (int)data[2]*256 + (int)data[1]*256*256 + (int)data[0]*256*256*256;
}

struct SNAV1Msg{

  double dRollAngle; //[rad]
  double dPitchAngle;
  double dYawAngle;
  double dRollRate; //[rad/s]
  double dPitchRate;
  double dYawRate;
  double dXAccel; //[m/s^2]
  double dYAccel;
  double dZAccel;
  double dNVel;   //[m/s]
  double dEVel;
  double dDVel;
  double dLongitude;
  double dLatitude;
  double dAltitude;
  short xRateTemp;
  unsigned int timeITOW;
  unsigned short BITStatus;
};

bool MsgToNav1(const unsigned char* data, SNAV1Msg &amp;sMsg) {
  sMsg.dRollAngle  = MKShort(data+0)*2.0*M_PI/(256*256);
  sMsg.dPitchAngle = MKShort(data+2)*2.0*M_PI/(256*256);
  sMsg.dYawAngle   = MKShort(data+4)*2.0*M_PI/(256*256);
  sMsg.dRollRate = MKShort(data+6)*7.0*M_PI/(256*256);
  sMsg.dPitchRate = MKShort(data+8)*7.0*M_PI/(256*256);
  sMsg.dYawRate = MKShort(data+10)*7.0*M_PI/(256*256);
  sMsg.dXAccel = MKShort(data+12)*20.0/(256*256);
  sMsg.dYAccel = MKShort(data+14)*20.0/(256*256);
  sMsg.dZAccel = MKShort(data+16)*20.0/(256*256);
  sMsg.dNVel = MKShort(data+18)*512.0/(256*256);
  sMsg.dEVel = MKShort(data+20)*512.0/(256*256);
  sMsg.dDVel = MKShort(data+22)*512.0/(256*256);
  sMsg.dLongitude = MKInt(data+24)*2.0*M_PI/(256*256);
  sMsg.dLatitude = MKInt(data+28)*2.0*M_PI/(256*256);
  sMsg.dAltitude = MKShort(data+32)/4.0;
  sMsg.xRateTemp = MKShort(data+34)*200.0/(256*256);
  sMsg.timeITOW			= (unsigned int)MKInt(data+36);
  sMsg.BITStatus     = (unsigned short)MKShort(data+40);
}

void Nav1ToRosImu(const SNAV1Msg &amp;rNav1, sensor_msgs::Imu &amp;ImuData) {
  ImuData.angular_velocity.x = rNav1.dRollRate;
  ImuData.angular_velocity.y = rNav1.dPitchRate;
  ImuData.angular_velocity.z = rNav1.dYawRate;
  ImuData.linear_acceleration.x = rNav1.dXAccel;
  ImuData.linear_acceleration.y = rNav1.dYAccel;
  ImuData.linear_acceleration.z = rNav1.dZAccel;
  ImuData.orientation = tf::createQuaternionMsgFromRollPitchYaw(rNav1.dRollAngle, rNav1.dPitchAngle, rNav1.dYawAngle);
}

void RunVG440(const std::string &amp;rsPort, int nBaudRate, const std::string &amp;rsTopic, const std::string &amp;rsFrame)
{
  using namespace boost::asio;

  try {

    QUEUE_TYPE *_pQueue = new QUEUE_TYPE;
    Initialize(_pQueue);
    XBOW_PACKET packet;

    ros::NodeHandle n;
    ros::Publisher Publisher = n.advertise&lt;sensor_msgs::Imu&gt;(rsTopic, 1000);

    io_service io;
    serial_port port( io, rsPort );
    port.set_option(serial_port_base::baud_rate(nBaudRate));
    port.set_option(serial_port_base::character_size(8));
    port.set_option(serial_port_base::flow_control(serial_port_base::flow_control::none));
    port.set_option(serial_port_base::parity(serial_port_base::parity::none));
    port.set_option(serial_port_base::stop_bits(serial_port_base::stop_bits::one));

    boost::array&lt;unsigned char, 5000&gt; DataBuf;
    int nCnt = 0;
    mmtimer mt;
    while (ros::ok())  {
      try {
        size_t nRet = boost::asio::read(port, boost::asio::buffer(DataBuf), boost::asio::transfer_at_least(1));
        for (int n=0; n&lt;nRet; ++n) {
          AddQueue(DataBuf[n], _pQueue);
        }
        if (process_xbow_packet(_pQueue, &amp;packet)) {
          /*
            Packet Type
            0x4e31:N1 NAV440の初期値
          */
          if (packet.packet_type == 0x4e31) { 
            sensor_msgs::Imu ImuData;
            ImuData.header.stamp = ros::Time::now();
            ImuData.header.frame_id = rsFrame;
            ImuData.header.seq = nCnt;
            SNAV1Msg NAV1;
            MsgToNav1((unsigned char*)packet.data, NAV1);
            Nav1ToRosImu(NAV1, ImuData);
            Publisher.publish(ImuData);
            ++nCnt;
            if (nCnt % 100 == 0) {
              cout &lt;&lt; &quot;FPS: &quot; &lt;&lt; nCnt/mt.elapsed() &lt;&lt; endl;
            }
          }
          else {
            cout &lt;&lt; &quot;other msg:&quot; &lt;&lt; packet.packet_type &lt;&lt; endl;
          }
        }
      }
      catch (boost::system::system_error &amp;e) {
        if (e.code().message() == &quot;Interrupted system call&quot;) { //ctrl+c
          ros::shutdown();
        }
        else {
          cout &lt;&lt; &quot;ReadData Error:&quot; &lt;&lt; e.what() &lt;&lt; endl;
        }
      }
      ros::spinOnce();
    }
  }
  catch (std::exception &amp;e) {
    cout &lt;&lt; &quot;RunVG400 Error: &quot; &lt;&lt; e.what() &lt;&lt; endl;
  }
}

int main(int argc, char **argv) {

  string sTopic;
  string sPort;
  string sFrame;
  int nBaudRate;

  string sFrameDefault = &quot;/vg440&quot;;
  string sTopicDefault = &quot;/imu_data&quot;;
  string sPortDefault  = &quot;/dev/ttyUSB0&quot;;
  int nBaudRateDefault = 57600;
  ros::init(argc, argv, &quot;vg440_node&quot;);
  ros::NodeHandle n_private_(&quot;~&quot;);
  n_private_.param(&quot;frame&quot;, sFrame, sFrameDefault);
  n_private_.param(&quot;topic&quot;, sTopic, sTopicDefault);
  n_private_.param(&quot;port&quot;,  sPort,  sPortDefault);
  n_private_.param(&quot;baudrate&quot;,  nBaudRate,  nBaudRateDefault);

  RunVG440(sPort, nBaudRate, sTopic, sFrame);

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="cea33d7e1e80047749a0d8a2ab3edf729399b482" fix_time="210,68491">
		<msg>Fixed compatibility issues with indigo</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/lib/image/kf/src/kf.cpp" new_path="ros/src/computing/perception/detection/lib/image/kf/src/kf.cpp">
				<diff>@@ -60,8 +60,12 @@
 #define SSTR( x ) dynamic_cast&lt; std::ostringstream &amp; &gt;( \
         ( std::ostringstream() &lt;&lt; std::dec &lt;&lt; x ) ).str()
 
-
+#include &lt;opencv2/core/version.hpp&gt;
+#if (CV_MAJOR_VERSION == 3)
 #include &quot;gencolors.cpp&quot;
+#else
+#include &lt;opencv2/contrib/contrib.hpp&gt;
+#endif
 
 struct ObjectDetection_
 {
@@ -960,8 +964,12 @@ int kf_main(int argc, char* argv[])
 
 	image_objects = n.advertise&lt;cv_tracker_msgs::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
 
+#if (CV_MAJOR_VERSION == 3)
 	generateColors(_colors, 25);
+#else
+	cv::generateColors(_colors, 25);
 
+#endif
 	std::string image_topic;
 	std::string obj_topic;
 	if (private_nh.getParam(&quot;image_node&quot;, image_topic))
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

//ROS STUFF
#include &lt;ros/ros.h&gt;

#include &lt;message_filters/subscriber.h&gt;
#include &lt;message_filters/time_synchronizer.h&gt;

#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;runtime_manager/ConfigCarKf.h&gt;
#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;

#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
#include &lt;std_msgs/Header.h&gt;

//TRACKING STUFF
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/objdetect/objdetect.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;opencv2/video/tracking.hpp&gt;
#include &lt;opencv2/calib3d/calib3d.hpp&gt;

#include &lt;iostream&gt;
#include &lt;stdio.h&gt;

#include &lt;sstream&gt;
#include &lt;algorithm&gt;
#include &lt;iterator&gt;

#define SSTR( x ) dynamic_cast&lt; std::ostringstream &amp; &gt;( \
        ( std::ostringstream() &lt;&lt; std::dec &lt;&lt; x ) ).str()


#include &quot;gencolors.cpp&quot;

struct ObjectDetection_
{
	//ObjectDetection_();
	//ObjectDetection_(const cv::Rect&amp; rect, float score, int classId=1);
	cv::Rect rect;
	float score;
	int classID;
};

ros::Publisher image_objects;//ROS

static int 			DEFAULT_LIFESPAN; //LIFESPAN of objects before stop being tracked, in frames
static int	 		INITIAL_LIFESPAN; //LIFESPAN of objects before stop being tracked, in frames
static int			ORB_NUM_FEATURES;
static unsigned int	ORB_MIN_MATCHES;
static float		ORB_KNN_RATIO;
static float 		NOISE_COV;
static float 		MEAS_NOISE_COV;
static float 		ERROR_ESTIMATE_COV;
static float 		OVERLAPPING_PERC;
static bool 		SHOW_PREDICTIONS;
static bool 		USE_ORB;

static bool 		track_ready_;
static bool 		detect_ready_;
static cv_tracker_msgs::image_obj_tracked kf_objects_msg_;

struct kstate
{
	cv::KalmanFilter	KF;//KalmanFilter for this object
	cv::Rect		pos;//position of the object centerx, centery, width, height
	float			score;//DPM score
	bool			active;//if too old (lifespan) don't use
	unsigned int		id;//id of this tracked object
	cv::Mat			image;//image containing the detected and tracked object
	int			lifespan;//remaining lifespan before deprecate
	//ObjectDetection_ obj;//currently not used
	cv::Scalar	color;
	int		real_data;
	//std::vector&lt;KeyPoint&gt; orbKeypoints;
	//cv::Mat				orbDescriptors;
	float range;//range to this object gotten by range_fusion
	float min_height;//minimum height detected by range_fusion
	float max_height;//maximum height detected by range_fusion
};

//tracking required code
std::vector&lt;kstate&gt; 	_kstates;
std::vector&lt;bool&gt; 	_active;
std::vector&lt;cv::Scalar&gt;	_colors;
std::vector&lt;ObjectDetection_&gt; _dpm_detections;

std::string object_type;
std::vector&lt;float&gt; _ranges;
std::vector&lt;float&gt; _min_heights;
std::vector&lt;float&gt; _max_heights;

std_msgs::Header    image_objects_header;

//static bool _ready;

long int _counter = 0;
//

void getRectFromPoints(std::vector&lt; cv::Point2f &gt; corners, cv::Rect&amp; outBoundingBox)
{
	int min_x=0, min_y=0, max_x=0, max_y=0;
	for (unsigned int i=0; i&lt;corners.size(); i++)
	{
		if (corners[i].x &gt; 0)
		{
			if (corners[i].x &lt; min_x)
				min_x = corners[i].x;
			if (corners[i].x&gt;max_x)
				max_x = corners[i].x;
		}
		if (corners[i].y &gt; 0)
		{
			if (corners[i].y &lt; min_y)
				min_y = corners[i].y;
			if (corners[i].y &gt; max_y)
				max_y = corners[i].y;
		}
	}
	outBoundingBox.x 		= min_x;
	outBoundingBox.y 		= min_y;
	outBoundingBox.width 	= max_x - min_x;
	outBoundingBox.height 	= max_y - min_y;

}

/*bool orbMatch(cv::Mat&amp; inImageScene, cv::Mat&amp; inImageObj, cv::Rect&amp; outBoundingBox, unsigned int inMinMatches=2, float inKnnRatio=0.7)
{
	//vector of keypoints
	std::vector&lt; cv::KeyPoint &gt; keypointsO;
	std::vector&lt; cv::KeyPoint &gt; keypointsS;

	cv::Mat descriptors_object, descriptors_scene;

	cv::Mat outImg;
	inImageScene.copyTo(outImg);

	//-- Step 1: Extract keypoints
	cv::OrbFeatureDetector orb(ORB_NUM_FEATURES);
	orb.detect(inImageScene, keypointsS);
	if (keypointsS.size() &lt; ORB_MIN_MATCHES)
	{
		//cout &lt;&lt; &quot;Not enough keypoints S, object not found&gt;&quot; &lt;&lt; keypointsS.size() &lt;&lt; endl;
		return false;
	}
	orb.detect(inImageObj, keypointsO);
	if (keypointsO.size() &lt; ORB_MIN_MATCHES)
	{
		//cout &lt;&lt; &quot;Not enough keypoints O, object not found&gt;&quot; &lt;&lt; keypointsO.size() &lt;&lt; endl;
		return false;
	}

	//Calculate descriptors (feature vectors)
	cv::OrbDescriptorExtractor extractor;
	extractor.compute(inImageScene, keypointsS, descriptors_scene);
	extractor.compute(inImageObj, keypointsO, descriptors_object);

	//Matching descriptor vectors using FLANN matcher
	cv::BFMatcher matcher;
	//descriptors_scene.size(), keypointsO.size(), keypointsS.size();
	std::vector&lt; std::vector&lt; cv::DMatch &gt;  &gt; matches;
	matcher.knnMatch(descriptors_object, descriptors_scene, matches, 2);
	std::vector&lt; cv::DMatch &gt; good_matches;
	good_matches.reserve(matches.size());

	for (size_t i = 0; i &lt; matches.size(); ++i)
	{
		if (matches[i].size() &lt; 3)
			continue;

		const cv::DMatch &amp;m1 = matches[i][0];
		const cv::DMatch &amp;m2 = matches[i][1];

		if (m1.distance &lt;= inKnnRatio * m2.distance)
			good_matches.push_back(m1);
	}

	if ((good_matches.size() &gt;= inMinMatches))
	{
		std::vector&lt; cv::Point2f &gt; obj;
		std::vector&lt; cv::Point2f &gt; scene;

		for (unsigned int i = 0; i &lt; good_matches.size(); i++)
		{
			// Get the keypoints from the good matches
			obj.push_back(keypointsO[good_matches[i].queryIdx].pt);
			scene.push_back(keypointsS[good_matches[i].trainIdx].pt);
		}

		cv::Mat H = findHomography(obj, scene, CV_RANSAC);

		// Get the corners from the image_1 ( the object to be &quot;detected&quot; )
		std::vector&lt; cv::Point2f &gt; obj_corners(4);
		obj_corners[0] = cvPoint(0, 0); obj_corners[1] = cvPoint(inImageObj.cols, 0);
		obj_corners[2] = cvPoint(inImageObj.cols, inImageObj.rows); obj_corners[3] = cvPoint(0, inImageObj.rows);
		std::vector&lt; cv::Point2f &gt; scene_corners(4);

		perspectiveTransform(obj_corners, scene_corners, H);

		// Draw lines between the corners (the mapped object in the scene - image_2 )
		line(outImg, scene_corners[0], scene_corners[1], cv::Scalar(255, 0, 0), 2); //TOP line
		line(outImg, scene_corners[1], scene_corners[2], cv::Scalar(255, 0, 0), 2);
		line(outImg, scene_corners[2], scene_corners[3], cv::Scalar(255, 0, 0), 2);
		line(outImg, scene_corners[3], scene_corners[0], cv::Scalar(255, 0, 0), 2);

		//imshow(&quot;Scene&quot;, outImg);
		//imshow(&quot;Obj&quot;, inImageObj);
		//cvWaitKey(5);

		return true;
	}

	return false;
}*/

///Returns true if an im1 is contained in im2 or viceversa
bool crossCorr(cv::Mat im1, cv::Mat im2)
{
	//im1 roi from the previous frame
	//im2 roi fromcurrent frame
	if (im1.rows &lt;= 0 || im1.cols &lt;= 0 || im2.rows &lt;= 0 || im2.cols &lt;= 0)
		return false;

	cv::Mat result, larger_im, smaller_im;

	/// Create the result matrix
	int result_cols;
	int result_rows;

	//select largest image
	if (im2.cols &gt; im1.cols)
	{
		larger_im = im2;
		smaller_im = im1;
	}
	else
	{
		larger_im = im1;
		smaller_im = im2;
	}
	//check rows to be also larger otherwise crop the smaller to remove extra rows
	if (larger_im.rows &lt; smaller_im.rows)
	{
		//add rows to match sizes
		cv::Mat rows = cv::Mat::ones(smaller_im.rows - larger_im.rows, larger_im.cols, larger_im.type());
		larger_im.push_back(rows);
	}

	result_cols = larger_im.cols - smaller_im.cols + 1;
	result_rows = larger_im.rows - smaller_im.rows + 1;
	result.create(result_cols, result_rows, CV_32FC1);

	/// Do the Matching and Normalize
	matchTemplate(larger_im, smaller_im, result, CV_TM_CCORR_NORMED);
	//normalize(result, result, 0, 1, NORM_MINMAX, -1, cv::Mat());

	/// Localizing the best match with minMaxLoc
	double minVal; double maxVal; cv::Point minLoc; cv::Point maxLoc;
	cv::Point matchLoc;

	minMaxLoc(result, &amp;minVal, &amp;maxVal, &amp;minLoc, &amp;maxLoc, cv::Mat());

	matchLoc = maxLoc;

	/// Show me what you got
	cv::Mat scene = larger_im.clone();
	rectangle(scene, matchLoc, cv::Point(matchLoc.x + smaller_im.cols, matchLoc.y + smaller_im.rows), cv::Scalar(0, 0, 255), 2, 8, 0);
	//imshow(image_window, scene);
	//imshow(result_window, result);

	//if (maxVal&gt;0.89 &amp;&amp; minVal &lt;0.3)
	bool ret;
	int thresWidth = (larger_im.cols)*.7;
	if ( (maxVal &gt; 0.5) &amp;&amp; (smaller_im.cols &gt; thresWidth) )//good threshold and consistent size
	{

		//std::cout &lt;&lt; &quot;matched&quot; &lt;&lt; endl;
		ret = true;
	}
	else
	{
		//std::cout &lt;&lt; &quot;non matched&quot; &lt;&lt; endl;
		ret = false;
	}
	//cv::imshow(&quot;match1&quot;, scene);
	//cv::imshow(&quot;match2&quot;, smaller_im);

	return ret;
}

void posScaleToBbox(std::vector&lt;kstate&gt; kstates, std::vector&lt;kstate&gt;&amp; trackedDetections)
{
	for (unsigned int i = 0; i &lt; kstates.size(); i++)
	{
		if (kstates[i].active)
		{
			kstate tmp;
			tmp.pos.x = kstates[i].pos.x;// -(kstates[i].pos.width / 2);
			tmp.pos.y = kstates[i].pos.y;// -(kstates[i].pos.height / 2);
			tmp.pos.width = kstates[i].pos.width;
			tmp.pos.height = kstates[i].pos.height;
			tmp.color = kstates[i].color;
			tmp.id = kstates[i].id;
			tmp.score = kstates[i].score;
			tmp.lifespan = kstates[i].lifespan;
			tmp.real_data = kstates[i].real_data;
			tmp.range = kstates[i].range;
			tmp.min_height = kstates[i].min_height;
			tmp.max_height = kstates[i].max_height;

			//fill in also LAtentSvm object
			//tmp.obj.rect = tmp.pos;
			//tmp.obj.score = tmp.score;

			if (tmp.pos.x &lt; 0)
				tmp.pos.x = 0;
			if (tmp.pos.y &lt; 0)
				tmp.pos.y = 0;

			trackedDetections.push_back(tmp);
		}
	}
}

int getAvailableIndex(std::vector&lt;kstate&gt;&amp; kstates)
{
	unsigned int cur_size = kstates.size();
	std::vector&lt;bool&gt; ids;

	ids.resize(cur_size, false);

	for (unsigned int i=0; i&lt;cur_size;i++)
	{
		ids[kstates[i].id]= true;
	}
	for (unsigned int i=0; i&lt;cur_size;i++)
	{
		if(ids[i] == false)
			return i;
	}
	return cur_size;
}

void initTracking(ObjectDetection_ object, std::vector&lt;kstate&gt;&amp; kstates,
		  ObjectDetection_ detection,
		  cv::Mat&amp; image, std::vector&lt;cv::Scalar&gt; colors, float range)
{
	kstate new_state;
	//cv::KalmanFilter KF(4, 2, 0);//XY Only
	cv::KalmanFilter KF(8, 4, 0);

	/*cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(2, 1) &lt;&lt; object.rect.x,//XY Only
		object.rect.y);*/
	cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(4, 1) &lt;&lt; object.rect.x,
		object.rect.y, object.rect.width, object.rect.height);

	/*KF.transitioncv::Matrix = (cv::Mat_&lt;float&gt;(4, 4) &lt;&lt; 1, 0, 1, 0,//XY Only
												0, 1, 0, 1,
												0, 0, 1, 0,
												0, 0, 0, 1);*/
	KF.transitionMatrix = (cv::Mat_&lt;float&gt;(8, 8)
	&lt;&lt;	1, 0, 0, 0, 1, 0, 0, 0,
		0, 1, 0, 0, 0, 1, 0, 0,
		0, 0, 1, 0, 0, 0, 1, 0,
		0, 0, 0, 1, 0, 0, 0, 1,
		0, 0, 0, 0, 1, 0, 0, 0,
		0, 0, 0, 0, 0, 1, 0, 0,
		0, 0, 0, 0, 0, 0, 1, 0,
		0, 0, 0, 0, 0, 0, 0, 1);

	//init pre
	KF.statePre.at&lt;float&gt;(0) = object.rect.x;
	KF.statePre.at&lt;float&gt;(1) = object.rect.y;
	KF.statePre.at&lt;float&gt;(2) = object.rect.width;//XY Only
	KF.statePre.at&lt;float&gt;(3) = object.rect.height;//XY Only
	//init post
	KF.statePost.at&lt;float&gt;(0) = object.rect.x;
	KF.statePost.at&lt;float&gt;(1) = object.rect.y;
	KF.statePost.at&lt;float&gt;(2) = object.rect.width;//XY Only
	KF.statePost.at&lt;float&gt;(3) = object.rect.height;//XY Only

	cv::setIdentity(KF.measurementMatrix);
	cv::setIdentity(KF.processNoiseCov, cv:: Scalar::all(NOISE_COV));//1e-4
	cv::setIdentity(KF.measurementNoiseCov, cv::Scalar::all(MEAS_NOISE_COV));//1e-3
	cv::setIdentity(KF.errorCovPost, cv::Scalar::all(ERROR_ESTIMATE_COV));//100

	//clip detection
	//check that predicted positions are inside the image
	if (detection.rect.x &lt; 0)
		detection.rect.x = 0;
	if (detection.rect.x &gt; image.cols)
		detection.rect.x = image.cols - 1;
	if (detection.rect.y &lt; 0)
		detection.rect.y = 0;
	if (detection.rect.height &gt; image.rows)
		detection.rect.height = image.rows - 1;
	if (detection.rect.width + detection.rect.x &gt; image.cols)
		detection.rect.width = image.cols - detection.rect.x;
	if (detection.rect.height + detection.rect.y &gt; image.rows)
		detection.rect.height = image.rows - detection.rect.y;

	//save data to kstate
	new_state.active = true;
	new_state.image = image(cv::Rect(detection.rect.x,
		detection.rect.y,
		detection.rect.width,
		detection.rect.height)).clone();//Crop image and obtain only object (ROI)
	new_state.KF = KF;
	new_state.lifespan = INITIAL_LIFESPAN;//start only with 1
	new_state.pos = object.rect;
	new_state.score = object.score;
	new_state.id = getAvailableIndex(kstates);
	new_state.color = colors[new_state.id];
	new_state.real_data = 1;
	new_state.range = range;

	//extractOrbFeatures(new_state.image, new_state.orbKeypoints, new_state.orbDescriptors, ORB_NUM_FEATURES);

	kstates.push_back(new_state);

}

//checks whether an index was previously removed
bool isInRemoved(std::vector&lt;unsigned int&gt; removedIndices, unsigned int index)
{
	for (unsigned int i=0; i&lt; removedIndices.size(); i++)
	{
		if (index == removedIndices[i])
			return true;
	}
	return false;
}

void removeUnusedObjects(std::vector&lt;kstate&gt;&amp; states)
{
	std::vector&lt;kstate&gt;::iterator it;
	for(it = states.begin(); it != states.end();)
	{
		if (!(it-&gt;active))
			it = states.erase(it);
		else
			it++;
	}
}

bool alreadyMatched(int check_index, std::vector&lt;int&gt;&amp; matched_indices)
{
	for (unsigned int i = 0; i &lt; matched_indices.size(); i++)
	{
		if (matched_indices[i] == check_index)
			return true;
	}
	return false;
}

void Sort(const std::vector&lt;float&gt; in_scores, std::vector&lt;unsigned int&gt;&amp; in_out_indices)
{
	for (unsigned int i = 0; i &lt; in_scores.size(); i++)
		for (unsigned int j = i + 1; j &lt; in_scores.size(); j++)
		{
			if (in_scores[in_out_indices[j]] &gt; in_scores[in_out_indices[i]])
			{
				//float x_tmp = x[i];
				int index_tmp = in_out_indices[i];
				//x[i] = x[j];
				in_out_indices[i] = in_out_indices[j];
				//x[j] = x_tmp;
				in_out_indices[j] = index_tmp;
			}
		}
}

void ApplyNonMaximumSuppresion(std::vector&lt; kstate &gt;&amp; in_source, float in_nms_threshold)
{
	std::vector&lt; kstate &gt; tmp_source = in_source;

	if (tmp_source.empty())
		return ;

	unsigned int size = in_source.size();

	std::vector&lt;float&gt; area(size);
	std::vector&lt;float&gt; scores(size);
	std::vector&lt;int&gt; x1(size);
	std::vector&lt;int&gt; y1(size);
	std::vector&lt;int&gt; x2(size);
	std::vector&lt;int&gt; y2(size);
	std::vector&lt;unsigned int&gt; indices(size);
	std::vector&lt;bool&gt; is_suppresed(size);

	for(unsigned int i = 0; i&lt; in_source.size(); i++)
	{
		kstate tmp = in_source[i];
		area[i] = tmp.pos.width * tmp.pos.height;
		indices[i] = i;
		is_suppresed[i] = false;
		scores[i] = tmp.score;
		x1[i] = tmp.pos.x;
		y1[i] = tmp.pos.y;
		x2[i] = tmp.pos.width + tmp.pos.x;
		y2[i] = tmp.pos.height + tmp.pos.y;
	}

	Sort(scores, indices);//returns indices ordered based on scores

	for(unsigned int i=0; i&lt; size; i++)
	{
		if(!is_suppresed[indices[i]])
		{
			for(unsigned int j= i+1; j&lt; size; j++)
			{
				int x1_max = std::max(x1[indices[i]], x1[indices[j]]);
				int x2_min = std::min(x2[indices[i]], x2[indices[j]]);
				int y1_max = std::max(y1[indices[i]], y1[indices[j]]);
				int y2_min = std::min(y2[indices[i]], y2[indices[j]]);
				int overlap_width = x2_min - x1_max + 1;
				int overlap_height = y2_min - y1_max + 1;
				if(overlap_width &gt; 0 &amp;&amp; overlap_height&gt;0)
				{
					float overlap_part = (overlap_width*overlap_height)/area[indices[j]];
					if(overlap_part &gt; in_nms_threshold)
					{
						is_suppresed[indices[j]] = true;
					}
				}
			}
		}
	}

	unsigned int size_out = 0;
	for (unsigned int i = 0; i &lt; size; i++)
	{
		if (!is_suppresed[i])
			size_out++;
	}

	std::vector&lt; kstate &gt; filtered_detections(size_out);

	unsigned int index = 0;
	for(unsigned int i = 0 ; i &lt; size_out; i++)
	{
		if(!is_suppresed[indices[i]])
		{
			filtered_detections[index] = in_source[indices[i]];//x1[indices[i]];
			index++;
		}
	}
	in_source = filtered_detections;
}

void doTracking(std::vector&lt;ObjectDetection_&gt;&amp; detections, int frameNumber,
		std::vector&lt;kstate&gt;&amp; kstates, std::vector&lt;bool&gt;&amp; active, cv::Mat&amp; image,
		std::vector&lt;kstate&gt;&amp; trackedDetections, std::vector&lt;cv::Scalar&gt; &amp; colors)
{
	std::vector&lt;ObjectDetection_&gt; objects;
	//vector&lt;LatentSvmDetector::ObjectDetection_&gt; tracked_objects;
	std::vector&lt;bool&gt; predict_indices;//this will correspond to kstates i
	std::vector&lt;bool&gt; correct_indices;//this will correspond to kstates i
	std::vector&lt;int&gt; correct_detection_indices;//this will correspond to kstates i, used to store the index of the corresponding object
	std::vector&lt;bool&gt; add_as_new_indices;//this will correspond to detections j

	//predict_indices.assign(kstates.size(), true);//always predict
	correct_indices.assign(kstates.size(), false);//correct only those matched
	correct_detection_indices.assign(kstates.size(), false);//correct only those matched
	add_as_new_indices.assign(detections.size(), true);//if the detection was not found add as new

	//Convert Bounding box coordinates from (x1,y1,w,h) to (BoxCenterX, BoxCenterY, width, height)
	objects = detections;//bboxToPosScale(detections);

	std::vector&lt;int&gt; already_matched;
	//compare detections from this frame with tracked objects
	for (unsigned int j = 0; j &lt; detections.size(); j++)
	{
		for (unsigned int i = 0; i &lt; kstates.size(); i++)
		{
			//compare only to active tracked objects(not too old)
			if (kstates[i].active)
			{
				//extend the roi 20%
				int new_x = (detections[j].rect.x - detections[j].rect.width*.1);
				int new_y = (detections[j].rect.y - detections[j].rect.height*.1);

				if (new_x &lt; 0)			new_x = 0;
				if (new_x &gt; image.cols)	new_x = image.cols;
				if (new_y &lt; 0)			new_y = 0;
				if (new_y &gt; image.rows) new_y = image.rows;

				int new_width = detections[j].rect.width*1.2;
				int new_height = detections[j].rect.height*1.2;

				if (new_width  + new_x &gt; image.cols)	new_width  = image.cols - new_x;
				if (new_height + new_y &gt; image.rows)	new_height = image.rows - new_y;

				cv::Rect roi_20(new_x, new_y, new_width, new_height);
				//cv::Rect roi(detections[j].rect);
				cv::Rect roi(roi_20);
				cv::Mat currentObjectROI = image(roi).clone();//Crop image and obtain only object (ROI)

				//cv::Rect intersect = detections[j].rect &amp; kstates[i].pos;//check overlapping

				cv::Rect boundingbox;
				bool matched = false;
				//try to match with previous frame
				//if ( !USE_ORB )
					matched = ( !alreadyMatched(j, already_matched) &amp;&amp; crossCorr(kstates[i].image, currentObjectROI));
				//else
				//	matched = (!alreadyMatched(j, already_matched) &amp;&amp; orbMatch(currentObjectROI, kstates[i].image, boundingbox, ORB_MIN_MATCHES, ORB_KNN_RATIO));

				if(matched)
				{
					correct_indices[i] = true;//if ROI on this frame is matched to a previous object, correct
					correct_detection_indices[i] = j;//store the index of the detection corresponding to matched kstate
					add_as_new_indices[j] = false;//if matched do not add as new
					//kstates[i].image = currentObjectROI;//update image with current frame data
					kstates[i].score = detections[j].score;
					kstates[i].range = _ranges[j];
					already_matched.push_back(j);
				}//crossCorr

			}//kstates[i].active
		}//for (int i = 0; i &lt; kstates.size(); i++)
	}//for (int j = 0; j &lt; detections.size(); j++)


	//do prediction and correction for the marked states
	for (unsigned int i = 0; i &lt; kstates.size(); i++)
	{
		if (kstates[i].active)//predict and correct only active states
		{
			//update params before predicting
			cv::setIdentity(kstates[i].KF.measurementMatrix);
			cv::setIdentity(kstates[i].KF.processNoiseCov, cv::Scalar::all(NOISE_COV));//1e-4
			cv::setIdentity(kstates[i].KF.measurementNoiseCov, cv::Scalar::all(MEAS_NOISE_COV));//1e-3
			cv::setIdentity(kstates[i].KF.errorCovPost, cv::Scalar::all(ERROR_ESTIMATE_COV));//100

			cv::Mat prediction = kstates[i].KF.predict();
			cv::Mat correction;
			kstates[i].pos.x = prediction.at&lt;float&gt;(0);
			kstates[i].pos.y = prediction.at&lt;float&gt;(1);
			kstates[i].pos.width = prediction.at&lt;float&gt;(2);
			kstates[i].pos.height = prediction.at&lt;float&gt;(3);
			kstates[i].real_data = 0;
			kstates[i].range = 0.0f;//fixed to zero temporarily as this is not real_data
			kstates[i].min_height = 0.0f;//fixed to zero temporarily as this is not real_data
			kstates[i].max_height = 0.0f;//fixed to zero temporarily as this is not real_data

			//now do respective corrections on KFs (updates)
			if (correct_indices[i])
			{
				//a match was found hence update KF measurement
				int j = correct_detection_indices[i];//obtain the index of the detection

				//cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(2, 1) &lt;&lt; objects[j].rect.x, //XY ONLY
				//												objects[j].rect.y);
				cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(4, 1) &lt;&lt; objects[j].rect.x,
					objects[j].rect.y,
					objects[j].rect.width,
					objects[j].rect.height);

				correction = kstates[i].KF.correct(measurement);//UPDATE KF with new info
				kstates[i].lifespan = DEFAULT_LIFESPAN; //RESET Lifespan of object

				//kstates[i].pos.width = objects[j].rect.width;//XY ONLY
				//kstates[i].pos.height = objects[j].rect.height;//XY ONLY

				//use real data instead of predicted if set
				kstates[i].pos.x = objects[j].rect.x;
				kstates[i].pos.y = objects[j].rect.y;
				kstates[i].pos.width = objects[j].rect.width;
				kstates[i].pos.height = objects[j].rect.height;
				kstates[i].real_data = 1;
				//cv::Mat im1 = image(kstates[i].pos);
				//cv::Mat im2 = image(objects[j].rect);
				kstates[i].range = _ranges[j];
				kstates[i].min_height = _min_heights[j];
				kstates[i].max_height = _max_heights[j];
			}


			//check that new widths and heights don't go beyond the image size
			if (kstates[i].pos.width + kstates[i].pos.x &gt; image.cols)
				kstates[i].pos.width = image.cols - kstates[i].pos.x;
			if (kstates[i].pos.height + kstates[i].pos.y &gt; image.rows)
				kstates[i].pos.height = image.rows - kstates[i].pos.y;

			//check that predicted positions are inside the image
			if (kstates[i].pos.x &lt; 0)
				kstates[i].pos.x = 0;
			if (kstates[i].pos.x &gt; image.cols)
				kstates[i].pos.x = image.cols;
			if (kstates[i].pos.y &lt; 0)
				kstates[i].pos.y = 0;
			if (kstates[i].pos.y &gt; image.rows)
				kstates[i].pos.y = image.rows;

			//remove those where the dimensions of are unlikely to be real
			if (kstates[i].pos.width &gt; kstates[i].pos.height*4)
				kstates[i].active = false;

			if (kstates[i].pos.height &gt; kstates[i].pos.width*2)
				kstates[i].active = false;

			kstates[i].lifespan--;//reduce lifespan
			if (kstates[i].lifespan &lt;= 0)
			{
				kstates[i].active = false; //Too old, stop tracking.
			}
		}
	}

	//finally add non matched detections as new
	for (unsigned int i = 0; i &lt; add_as_new_indices.size(); i++)
	{
		if (add_as_new_indices[i])
		{
			initTracking(objects[i], kstates, detections[i], image, colors, _ranges[i]);
		}
	}
	/*
	//check overlapping states and remove them
	float overlap = (OVERLAPPING_PERC/100);
	std::vector&lt;unsigned int&gt; removedIndices;
	for (unsigned int i = 0; i &lt; kstates.size() ; i++)
	{
		for (unsigned int j = kstates.size() - 1; j &gt; 0; j--)
		{
			if (i==j || isInRemoved(removedIndices, i) || isInRemoved(removedIndices, j))
				continue;
			//cout &lt;&lt; &quot;i:&quot; &lt;&lt; i &lt;&lt; &quot; j:&quot; &lt;&lt; j &lt;&lt; endl;
			cv::Rect intersection = kstates[i].pos &amp; kstates[j].pos;

			if ( ( (intersection.width &gt;= kstates[i].pos.width * overlap) &amp;&amp; (intersection.height &gt;= kstates[i].pos.height * overlap) ) ||
				( (intersection.width &gt;= kstates[j].pos.width * overlap) &amp;&amp; (intersection.height &gt;= kstates[j].pos.height * overlap) ) )
			{
				//if one state is overlapped by &quot;overlap&quot; % remove it (mark it as unused
				if (kstates[i].real_data &amp;&amp; !(kstates[j].real_data))
				{
					kstates[j].active = false;
					removedIndices.push_back(j);
				}
				else if (!(kstates[i].real_data) &amp;&amp; (kstates[j].real_data))
				{
					kstates[i].active = false;
					removedIndices.push_back(i);
				}
				else
				{
					kstates[j].active = false;
					removedIndices.push_back(j);
				}
			}
		}
	}*/
	ApplyNonMaximumSuppresion(kstates, OVERLAPPING_PERC);

	removeUnusedObjects(kstates);

	//return to x,y,w,h
	posScaleToBbox(kstates, trackedDetections);

}

void publish_if_possible()
{
	if (track_ready_ &amp;&amp; detect_ready_)
	{
		image_objects.publish(kf_objects_msg_);
		track_ready_ = false;
		detect_ready_ = false;
	}
}

void trackAndDrawObjects(cv::Mat&amp; image, int frameNumber, std::vector&lt;ObjectDetection_&gt; detections,
			 std::vector&lt;kstate&gt;&amp; kstates, std::vector&lt;bool&gt;&amp; active,
			 std::vector&lt;cv::Scalar&gt; colors, const sensor_msgs::Image&amp; image_source)
{
	std::vector&lt;kstate&gt; tracked_detections;

	cv::TickMeter tm;
	tm.start();
	//std::cout &lt;&lt; &quot;START tracking...&quot;;
	doTracking(detections, frameNumber, kstates, active, image, tracked_detections, colors);
	tm.stop();
	//std::cout &lt;&lt; &quot;END Tracking time = &quot; &lt;&lt; tm.getTimeSec() &lt;&lt; &quot; sec&quot; &lt;&lt; std::endl;

	//ROS
	int num = tracked_detections.size();
	std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; rect_ranged_array;
	std::vector&lt;int&gt; real_data(num,0);
	std::vector&lt;int&gt; obj_id(num, 0);
	std::vector&lt;int&gt; lifespan(num, 0);
	//ENDROS

	for (size_t i = 0; i &lt; tracked_detections.size(); i++)
	{
		kstate od = tracked_detections[i];
		cv_tracker_msgs::image_rect_ranged rect_ranged_;

		//od.rect contains x,y, width, height
		rectangle(image, od.pos, od.color, 3);
		putText(image, SSTR(od.id), cv::Point(od.pos.x + 4, od.pos.y + 13), cv::FONT_HERSHEY_SIMPLEX, 0.55, od.color, 2);
		//ROS
		obj_id[i] = od.id; // ?
		rect_ranged_.rect.x	= od.pos.x;
		rect_ranged_.rect.y	= od.pos.y;
		rect_ranged_.rect.width	= od.pos.width;
		rect_ranged_.rect.height = od.pos.height;
		rect_ranged_.range	= od.range;
		rect_ranged_.min_height	= od.min_height;
		rect_ranged_.max_height	= od.max_height;

		rect_ranged_array.push_back(rect_ranged_);

		real_data[i] = od.real_data;
		lifespan[i] = od.lifespan;
		//ENDROS
	}
	//more ros
	cv_tracker_msgs::image_obj_tracked kf_objects_msg;

	kf_objects_msg.type = object_type;
	kf_objects_msg.total_num = num;
	copy(rect_ranged_array.begin(), rect_ranged_array.end(), back_inserter(kf_objects_msg.rect_ranged)); // copy vector
	copy(real_data.begin(), real_data.end(), back_inserter(kf_objects_msg.real_data)); // copy vector
	copy(obj_id.begin(), obj_id.end(), back_inserter(kf_objects_msg.obj_id)); // copy vector
	copy(lifespan.begin(), lifespan.end(), back_inserter(kf_objects_msg.lifespan)); // copy vector

//	kf_objects_msg_.header = image_source.header;
	kf_objects_msg.header = image_objects_header;
	kf_objects_msg_ = kf_objects_msg;;
	track_ready_ = true;
	publish_if_possible();

	//cout &lt;&lt; &quot;.&quot;&lt;&lt; endl;
}

void image_callback(const sensor_msgs::Image&amp; image_source)
{
	//if (!_ready)
	//	return;

	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
	cv::Mat imageTrack = cv_image-&gt;image;
	trackAndDrawObjects(imageTrack, _counter, _dpm_detections, _kstates, _active, _colors, image_source);
	//_ready=false;
	//imshow(&quot;Tracked&quot;, imageTrack);

	_counter++;
}

void detections_callback(cv_tracker_msgs::image_obj_ranged image_objects_msg)
{
	if(!detect_ready_)
	{
		unsigned int num = image_objects_msg.obj.size();
		std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects = image_objects_msg.obj;
		object_type = image_objects_msg.type;
		image_objects_header = image_objects_msg.header;
		//points are X,Y,W,H and repeat for each instance
		_dpm_detections.clear();
		_ranges.clear();
		_min_heights.clear();
		_max_heights.clear();

		for (unsigned int i=0; i&lt;num;i++)
		{
			cv::Rect tmp;
			tmp.x = objects.at(i).rect.x;
			tmp.y = objects.at(i).rect.y;
			tmp.width = objects.at(i).rect.width;
			tmp.height = objects.at(i).rect.height;
			ObjectDetection_ obj_tmp;
			obj_tmp.rect = tmp; obj_tmp.score=0;
			_dpm_detections.push_back(obj_tmp);
			_ranges.push_back(objects.at(i).range);
			_min_heights.push_back(objects.at(i).min_height);
			_max_heights.push_back(objects.at(i).max_height);
		}
		//_ready = true;
		detect_ready_ = true;
	}
	//cout &lt;&lt; &quot;received pos&quot; &lt;&lt; endl;

	publish_if_possible();
}

static void kf_config_cb(const runtime_manager::ConfigCarKf::ConstPtr&amp; param)
{
	if (param-&gt;initial_lifespan &gt; 0)
		INITIAL_LIFESPAN	= param-&gt;initial_lifespan;
	if (param-&gt;default_lifespan &gt; 0)
		DEFAULT_LIFESPAN	= param-&gt;default_lifespan;
	if(param-&gt;noise_covariance &gt; 0)
		NOISE_COV			= param-&gt;noise_covariance;
	if(param-&gt;measurement_noise_covariance &gt; 0)
		MEAS_NOISE_COV		= param-&gt;measurement_noise_covariance;
	if(param-&gt;error_estimate_covariance &gt; 0)
		ERROR_ESTIMATE_COV	= param-&gt;error_estimate_covariance;
	if(param-&gt;percentage_of_overlapping &gt; 0)
		OVERLAPPING_PERC	= param-&gt;percentage_of_overlapping;

	ORB_NUM_FEATURES	= 2000;
	ORB_MIN_MATCHES		= 3;
	ORB_KNN_RATIO		= 0.7;

	USE_ORB				= param-&gt;use_orb;
}

void init_params()
{
	DEFAULT_LIFESPAN	= 8;
	INITIAL_LIFESPAN	= 4;
	NOISE_COV			= 1;
	MEAS_NOISE_COV		= 25;
	ERROR_ESTIMATE_COV	= 1000000;
	OVERLAPPING_PERC	= 80.0;
	SHOW_PREDICTIONS	= false;

	ORB_NUM_FEATURES	= 2000;
	ORB_MIN_MATCHES		= 3;
	ORB_KNN_RATIO		= 0.7;
	USE_ORB				= false;
}

int kf_main(int argc, char* argv[])
{
	ros::init(argc, argv, &quot;kf&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	image_objects = n.advertise&lt;cv_tracker_msgs::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);

	generateColors(_colors, 25);

	std::string image_topic;
	std::string obj_topic;
	if (private_nh.getParam(&quot;image_node&quot;, image_topic))
    	{
        	ROS_INFO(&quot;Setting image node to %s&quot;, image_topic.c_str());
    	}
	else
	{
		ROS_INFO(&quot;No image node received, defaulting to image_raw, you can use _image_node:=YOUR_TOPIC&quot;);
		image_topic = &quot;/image_raw&quot;;
	}
	if (private_nh.getParam(&quot;object_node&quot;, image_topic))
    	{
        	ROS_INFO(&quot;Setting object node to %s&quot;, image_topic.c_str());
    	}
	else
	{
		ROS_INFO(&quot;No object node received, defaulting to image_obj_ranged, you can use _object_node:=YOUR_TOPIC&quot;);
		obj_topic = &quot;image_obj_ranged&quot;;
	}

	init_params();

	ros::Subscriber sub_image = n.subscribe(image_topic, 1, image_callback);
	ros::Subscriber sub_dpm = n.subscribe(obj_topic, 1, detections_callback);


	std::string config_topic(&quot;/config&quot;);
	config_topic += ros::this_node::getNamespace() + &quot;/kf&quot;;
	ros::Subscriber config_subscriber = n.subscribe(config_topic, 1, kf_config_cb);

	//TimeSynchronizer&lt;Image, dpm::ImageObjects&gt; sync(image_sub, pos_sub, 10);

	//sync.registerCallback(boost::bind(&amp;sync_callback, _1, _2));
	track_ready_ = false;
	detect_ready_ = false;

	ros::spin();
	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/lib/lktracker/LkTracker.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/lib/lktracker/LkTracker.cpp">
				<diff>@@ -22,7 +22,11 @@ LkTracker::LkTracker(int in_id, float in_min_height, float in_max_height, float
 	previous_centroid_x_	= 0;
 	previous_centroid_y_	= 0;
 
+#if (CV_MAJOR_VERSION == 3)
 	generateColors(colors_, 2);
+#else
+	cv::generateColors(colors_, 2);
+#endif
 	lifespan_				= 45;
 	DEFAULT_LIFESPAN_		= 45;
 	object_id				= in_id;
</diff>
				<old_file>#include &quot;LkTracker.hpp&quot;


LkTracker::LkTracker(int in_id, float in_min_height, float in_max_height, float in_range)
{
	max_point_count_ 		= 500;
	criteria_max_iteration_	= 20;
	criteria_epsilon_		= 0.03;
	corner_window_size_		= 31;
	corner_subwindow_size_	= 10;
	term_criteria_ 			= cv::TermCriteria(	CV_TERMCRIT_ITER|CV_TERMCRIT_EPS,	//type
										criteria_max_iteration_, 					//max iteration count
										criteria_epsilon_							//epsilon
										);
	sub_pixel_window_size_ 	= cv::Size(corner_subwindow_size_, corner_subwindow_size_);
	window_size_ 			= cv::Size(corner_window_size_, corner_window_size_);

	frame_count_			= 0;

	current_centroid_x_		= 0;
	current_centroid_y_		= 0;
	previous_centroid_x_	= 0;
	previous_centroid_y_	= 0;

	generateColors(colors_, 2);
	lifespan_				= 45;
	DEFAULT_LIFESPAN_		= 45;
	object_id				= in_id;

	min_height_ 			= in_min_height;
	max_height_ 			= in_max_height;
	range_					= in_range;
}
ObjectDetection LkTracker::GetTrackedObject()
{
	return current_rect_;
}
void LkTracker::ArrowedLine(cv::Mat&amp; in_image, cv::Point in_point1, cv::Point in_point2, const cv::Scalar&amp; in_color,
				int in_thickness, int in_line_type, int in_shift, double in_tip_length)
{
	const double tipSize = cv::norm(in_point1-in_point2) * in_tip_length; // Factor to normalize the size of the tip depending on the length of the arrow
	cv::line(in_image, in_point1, in_point2, in_color, in_thickness, in_line_type, in_shift);

	const double angle = atan2( (double) in_point1.y - in_point2.y, (double) in_point1.x - in_point2.x );
	cv::Point p(cvRound(in_point2.x + tipSize * cos(angle + CV_PI / 4)),
	cvRound(in_point2.y + tipSize * sin(angle + CV_PI / 4)));

	cv::line(in_image, p, in_point2, in_color, in_thickness, in_line_type, in_shift);

	p.x = cvRound(in_point2.x + tipSize * cos(angle - CV_PI / 4));
	p.y = cvRound(in_point2.y + tipSize * sin(angle - CV_PI / 4));

	cv::line(in_image, p, in_point2, in_color, in_thickness, in_line_type, in_shift);
}

/*void OrbFeatures(cv::Mat in_image)
{
	cv::OrbFeatureDetector orb(500);
	std::vector&lt; cv::KeyPoint &gt; keypoints;
	orb.detect(in_image, keypoints);

	cv::OrbDescriptorExtractor extractor;
	cv::Mat descriptors;
	cv::Mat training_descriptors(1, extractor.descriptorSize(), extractor.descriptorType());
	extractor.compute(in_image, keypoints, descriptors);
	training_descriptors.push_back(descriptors);

	cv::BOWKMeansTrainer bow_trainer(2);
	bow_trainer.add(descriptors);

	cv::Mat vocabulary = bow_trainer.cluster();
}*/

unsigned int	LkTracker::GetRemainingLifespan()
{
	return lifespan_;
}

void LkTracker::NullifyLifespan()
{
	lifespan_ = 0;
}

unsigned long int LkTracker::GetFrameCount()
{
	return frame_count_;
}

cv::Mat LkTracker::Track(cv::Mat in_image, ObjectDetection in_detection, bool in_update)
{
	cv::Mat gray_image;
	//cv::cvtColor(in_image, in_image, cv::COLOR_RGB2BGR);
	cv::cvtColor(in_image, gray_image, cv::COLOR_BGR2GRAY);
	cv::Mat mask(gray_image.size(), CV_8UC1);
	//cv::TickMeter timer;

	//timer.start();

	if (in_update &amp;&amp; in_detection.rect.width &gt; 0)
	{
		//MATCH
		matched_detection_ = in_detection;
		if (matched_detection_.rect.x &lt; 0) matched_detection_.rect.x = 0;
		if (matched_detection_.rect.y &lt; 0) matched_detection_.rect.y = 0;
		if (matched_detection_.rect.x + matched_detection_.rect.width &gt; in_image.cols) matched_detection_.rect.width = in_image.cols - matched_detection_.rect.x;
		if (matched_detection_.rect.y + matched_detection_.rect.height &gt; in_image.rows) matched_detection_.rect.height = in_image.rows - matched_detection_.rect.y;

		mask.setTo(cv::Scalar::all(0));
		mask(matched_detection_.rect) = 1;							//fill with ones only the ROI

		lifespan_ = DEFAULT_LIFESPAN_;
	}
	int sum_x = 0;
	int sum_y = 0;
	std::vector&lt;cv::Point2f&gt; valid_points;

	lifespan_--;
	if ( ( in_update || prev_image_.empty() ) &amp;&amp;
		 ( matched_detection_.rect.width&gt;0 &amp;&amp; matched_detection_.rect.height &gt;0 )
		)																//add as new object
	{
		cv::goodFeaturesToTrack(gray_image,			//input to extract corners
								current_points_,	//out array with corners in the image
								max_point_count_,	//maximum number of corner points to obtain
								0.01,				//quality level
								10,					//minimum distance between corner points
								mask,//mask ROI
								3,					//block size
								true,				//true to use harris corner detector, otherwise use tomasi
								0.04);				//harris detector free parameter
		if (current_points_.size()&lt;=0)
		{
			ObjectDetection tmp_det; tmp_det.rect = cv::Rect(0,0,0,0); tmp_det.score=0;
			current_rect_ = tmp_det;
			return in_image;
		}
		cv::cornerSubPix(gray_image,
					current_points_,
					sub_pixel_window_size_,
					cv::Size(-1,-1),
					term_criteria_);
		//frame_count_ = 0;
		current_centroid_x_ = 0;
		current_centroid_y_ = 0;
		//current_points_.push_back(cv::Point(matched_detection_.x, matched_detection_.y));

		for (std::size_t i = 0; i &lt; current_points_.size(); i++)
		{
			//cv::circle(in_image, current_points_[i], 3 , cv::Scalar(0,255,0), 2);
			current_centroid_x_+= current_points_[i].x;
			current_centroid_y_+= current_points_[i].y;
			valid_points.push_back(current_points_[i]);
		}
		//std::cout &lt;&lt; &quot;CENTROID&quot; &lt;&lt; current_centroid_x_ &lt;&lt;&quot;,&quot;&lt;&lt; current_centroid_y_&lt;&lt; std::endl &lt;&lt; std::endl;

	}
	else if ( !prev_points_.empty() )//try to match current object
	{
		std::vector&lt;uchar&gt; status;
		std::vector&lt;float&gt; err;
		if(prev_image_.empty())
			in_image.copyTo(prev_image_);
		cv::calcOpticalFlowPyrLK(prev_image_, 			//previous image frame
								gray_image, 			//current image frame
								prev_points_, 			//previous corner points
								current_points_, 		//current corner points (tracked)
								status,
								err,
								window_size_,
								3,
								term_criteria_,
								0,
								0.001);
		std::size_t i = 0, k = 0;

		current_centroid_x_ = 0;
		current_centroid_y_ = 0;

		//process points
		for (i=0, k=0 ; i &lt; prev_points_.size(); i++)
		{
			if( !status[i] )
			{
				continue;
			}
			cv::Point2f p,q;
			p.x = (int)prev_points_[i].x;		p.y = (int)prev_points_[i].y;
			q.x = (int)current_points_[i].x;	q.y = (int)current_points_[i].y;

			sum_y = p.y-q.y;
			sum_x = p.x -q.x;

			current_centroid_x_+= current_points_[i].x;
			current_centroid_y_+= current_points_[i].y;

			current_points_[k++] = current_points_[i];
			valid_points.push_back(current_points_[i]);
			//cv::circle(in_image, current_points_[i], 3 , cv::Scalar(0,255,0), 2);
		}
	}
	if (valid_points.size()&lt;=2)
	{
		ObjectDetection tmp_det; tmp_det.rect = cv::Rect(0,0,0,0); tmp_det.score=0;
		current_rect_ = tmp_det;
		
		return in_image;
	}
	frame_count_++;

	cv::Mat labels;
	cv::Mat centers;

	cv::kmeans(valid_points,
					2,
					labels,
					cv::TermCriteria( CV_TERMCRIT_EPS+CV_TERMCRIT_ITER, 10, 1.0),
					3,
					cv::KMEANS_PP_CENTERS,
					centers);

	cv::Point2f center1 = centers.at&lt;cv::Point2f&gt;(0);
	cv::Point2f center2 = centers.at&lt;cv::Point2f&gt;(1);

	cv::Point centroid(current_centroid_x_/valid_points.size(), current_centroid_y_/valid_points.size());

	int cluster_nums[2] = {0,0};
	std::vector&lt;cv::Scalar&gt; colors(2);
	if (center1.x &lt; center2.x || center1.x &lt; center2.x)
	{
		colors[0]=colors_[0];
		colors[1]=colors_[1];
	}
	else
	{
		colors[0]=colors_[1];
		colors[1]=colors_[0];
	}

	//cv::circle(in_image, center1, 5 , (cv::Scalar)colors[0], 3);
	//cv::circle(in_image, center2, 5 , (cv::Scalar)colors[1], 3);

	std::vector&lt;cv::Point2f&gt; points_clusters[2];
	std::vector&lt;cv::Point2f&gt; close_points;
	//count points for each cluster
	for (std::size_t i = 0; i &lt; valid_points.size(); i++)
	{
		int cluster_index = labels.at&lt;int&gt;(i);
		cluster_nums[cluster_index]++;
		points_clusters[cluster_index].push_back(valid_points[i]);
		if (cv::norm(valid_points[i] - center1) &lt; matched_detection_.rect.width*0.8 &amp;&amp;
				cv::norm(valid_points[i] - center2) &lt; matched_detection_.rect.width*0.8) //distance between point and cluster centroid
		{
			close_points.push_back(valid_points[i]);
		}
		//cv::circle(in_image, valid_points[i], 2, colors[cluster_index], 2);
	}

	std::vector&lt;cv::Point2f&gt; final_points;

	if (cv::norm(center2-center1) &gt; matched_detection_.rect.width*0.75)//if centroids are too far keep only the one with the most points
	{
		if (cluster_nums[0] &gt; cluster_nums[1])
			final_points = points_clusters[0];
		else
			final_points = points_clusters[1];
	}
	else
		final_points = close_points;

	GetRectFromPoints(final_points,
			current_rect_.rect);

	current_rect_.classID = matched_detection_.classID;
	current_rect_.score = matched_detection_.score;

	if (current_rect_.rect.width &lt;= matched_detection_.rect.width*0.15 ||
			current_rect_.rect.height &lt;= matched_detection_.rect.height*0.15
		)
	{
		//std::cout &lt;&lt; &quot;TRACK STOPPED&quot; &lt;&lt; std::endl;
		prev_points_.clear();
		current_points_.clear();
		ObjectDetection tmp_det; tmp_det.rect = cv::Rect(0,0,0,0); tmp_det.score=0;
		current_rect_ = tmp_det;
		return in_image;
	}

	//cv::rectangle(in_image, current_rect_, cv::Scalar(0,0,255), 2);

	if (prev_points_.size() &gt; 0 )
	{
		cv::Point center_point = cv::Point(current_rect_.rect.x + current_rect_.rect.width/2, current_rect_.rect.y + current_rect_.rect.height/2);
		cv::Point direction_point;
		float sum_angle = atan2(sum_y, sum_x);

		direction_point.x = (center_point.x - 100 * cos(sum_angle));
		direction_point.y = (center_point.y - 100 * sin(sum_angle));

		//ArrowedLine(in_image, center_point, direction_point, cv::Scalar(0,0,255), 2);

		//cv::circle(in_image, center_point, 4 , cv::Scalar(0,0,255), 2);
		//cv::circle(in_image, center_point, 2 , cv::Scalar(0,0,255), 2);
	}

	//finally store current state into previous
	std::swap(final_points, prev_points_);
	cv::swap(prev_image_, gray_image);

	if (current_centroid_x_ &gt; 0 &amp;&amp; current_centroid_y_ &gt; 0)
	{
		previous_centroid_x_ = current_centroid_x_;
		previous_centroid_y_ = current_centroid_y_;
	}

	//timer.stop();

	//std::cout &lt;&lt; timer.getTimeMilli() &lt;&lt; std::endl;

	return in_image;
}

void LkTracker::GetRectFromPoints(std::vector&lt; cv::Point2f &gt; in_corners_points, cv::Rect&amp; out_boundingbox)
{

	if (in_corners_points.empty())
	{
		return;
	}

	int min_x=in_corners_points[0].x, min_y=in_corners_points[0].y, max_x=in_corners_points[0].x, max_y=in_corners_points[0].y;

	for (unsigned int i=0; i&lt;in_corners_points.size(); i++)
	{
		if (in_corners_points[i].x &gt; 0 )
		{
			if (in_corners_points[i].x &lt; min_x)
				min_x = in_corners_points[i].x;
			if (in_corners_points[i].x &gt; max_x)
				max_x = in_corners_points[i].x;
		}

		if (in_corners_points[i].y &gt; 0 )
		{
			if (in_corners_points[i].y &lt; min_y)
				min_y = in_corners_points[i].y;
			if (in_corners_points[i].y &gt; max_y)
				max_y = in_corners_points[i].y;
		}
	}
	out_boundingbox.x 		= min_x;
	out_boundingbox.y 		= min_y;
	out_boundingbox.width 	= max_x - min_x;
	out_boundingbox.height 	= max_y - min_y;

	return;
}

</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/lib/lktracker/LkTracker.hpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/lib/lktracker/LkTracker.hpp">
				<diff>@@ -9,12 +9,16 @@
 #include &lt;opencv2/core/core.hpp&gt;
 #include &lt;opencv2/objdetect/objdetect.hpp&gt;
 #include &lt;opencv2/highgui/highgui.hpp&gt;
-//#include &lt;opencv2/contrib/contrib.hpp&gt;
 #include &lt;opencv2/video/tracking.hpp&gt;
 #include &lt;opencv2/calib3d/calib3d.hpp&gt;
 #include &lt;opencv2/features2d/features2d.hpp&gt;
 
+#include &lt;opencv2/core/version.hpp&gt;
+#if (CV_MAJOR_VERSION == 3)
 #include &quot;gencolors.cpp&quot;
+#else
+#include &lt;opencv2/contrib/contrib.hpp&gt;
+#endif
 
 struct ObjectDetection
 {
</diff>
				<old_file>#ifndef LKTRACKER_HPP_
#define LKTRACKER_HPP_

#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include &lt;iostream&gt;

// OpenCV includes
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/objdetect/objdetect.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
//#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &lt;opencv2/video/tracking.hpp&gt;
#include &lt;opencv2/calib3d/calib3d.hpp&gt;
#include &lt;opencv2/features2d/features2d.hpp&gt;

#include &quot;gencolors.cpp&quot;

struct ObjectDetection
{
	//ObjectDetection();
	//ObjectDetection(const cv::Rect&amp; rect, float score, int classId=1);
	cv::Rect rect;
	float score;
	int classID;
};

class LkTracker
{
	int 					max_point_count_;
	int						criteria_max_iteration_;
	float 					criteria_epsilon_;
	int						corner_window_size_;
	int						corner_subwindow_size_;

	unsigned long int 		frame_count_;
	unsigned int 			lifespan_;

	cv::Mat 				prev_image_;
	cv::Mat 				current_image_;
	cv::TermCriteria 		term_criteria_;
	cv::Size 				sub_pixel_window_size_;
	cv::Size 				window_size_;

	ObjectDetection	matched_detection_;
	ObjectDetection	current_rect_;//stores the current tracked object

	int 					current_centroid_x_;
	int 					current_centroid_y_;

	int 					previous_centroid_x_;
	int 					previous_centroid_y_;

	std::vector&lt;cv::Scalar&gt;	colors_;

	std::vector&lt;cv::Point2f&gt; prev_points_;
	std::vector&lt;cv::Point2f&gt; current_points_;
	void 					GetRectFromPoints(std::vector&lt; cv::Point2f &gt; in_corners_points, cv::Rect&amp; out_boundingbox);
	void 					ArrowedLine(cv::Mat&amp; in_image, cv::Point in_point1, cv::Point in_point2, const cv::Scalar&amp; in_color,
								int in_thickness=1, int in_line_type=8, int in_shift=0, double in_tip_length=0.1);
public:
	int						object_id;
	float					min_height_;
	float					max_height_;
	float					range_;
	unsigned int 			DEFAULT_LIFESPAN_;


	LkTracker(int in_id, float in_min_height, float in_max_height, float in_range);
	cv::Mat 								Track(cv::Mat image, ObjectDetection in_detections, bool in_update);
	ObjectDetection	GetTrackedObject();
	unsigned int							GetRemainingLifespan();
	void 									NullifyLifespan();
	unsigned long int						GetFrameCount();
};

extern int klt_main(int argc, char* argv[]);

#endif /* LKTRACKER_HPP_ */
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/dpm_ocv/dpm_ocv.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/dpm_ocv/dpm_ocv.cpp">
				<diff>@@ -6,7 +6,7 @@
 #include &lt;ros/ros.h&gt;
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;cv_tracker/image_obj.h&gt;
+#include &lt;cv_tracker_msgs/image_obj.h&gt;
 #include &lt;runtime_manager/ConfigCarDpm.h&gt;
 
 #include &lt;dpm_ocv.hpp&gt;
@@ -135,7 +135,7 @@ void objectDetect::run()
 	config_topic += ros::this_node::getNamespace() + &quot;/dpm&quot;;
 	config_sub_ = nh_.subscribe&lt;runtime_manager::ConfigCarDpm&gt;(config_topic, 1, &amp;objectDetect::configCallback, this);
 	img_sub_ = nh_.subscribe&lt;sensor_msgs::Image&gt;(image_topic_name, 1, &amp;objectDetect::imageCallback, this);
-	detect_pub_ = nh_.advertise&lt;cv_tracker::image_obj&gt;(&quot;image_obj&quot;, 1);
+	detect_pub_ = nh_.advertise&lt;cv_tracker_msgs::image_obj&gt;(&quot;image_obj&quot;, 1);
 }
 
 // Callback
@@ -164,14 +164,14 @@ void objectDetect::imageCallback(const sensor_msgs::ImageConstPtr&amp; img)
 	std::vector&lt;int&gt; corner_point_array(num * 4.0);
 	std::vector&lt;int&gt; type_array(num, 0);
 
-	cv_tracker::image_obj msg;
+	cv_tracker_msgs::image_obj msg;
 	msg.header = img-&gt;header;
 	msg.type = object_class;
 
 	for(size_t i = 0; i &lt; detections.size(); i++)
 	{
 		const cv::LatentSvmDetector::ObjectDetection&amp; od = detections[i];
-		cv_tracker::image_rect rect;
+		cv_tracker_msgs::image_rect rect;
 
 		type_array[i] = od.classID;
 		rect.x = od.rect.x;
</diff>
				<old_file>#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;opencv2/objdetect/objdetect.hpp&gt;
#include &lt;opencv2/contrib/contrib.hpp&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_tracker/image_obj.h&gt;
#include &lt;runtime_manager/ConfigCarDpm.h&gt;

#include &lt;dpm_ocv.hpp&gt;

#define XSTR(x) #x
#define STR(x) XSTR(x)

#if defined(HAS_GPU)
static bool use_gpu = true;
#endif

static constexpr float SCORE_THRESHOLD = -0.5;
static constexpr int NUM_CELLS = 8;
static constexpr int NUM_BINS = 9;

class objectDetect
{
public:
	objectDetect();
	~objectDetect();
	void run();

private:
	void imageCallback(const sensor_msgs::ImageConstPtr&amp; img);
	void configCallback(const runtime_manager::ConfigCarDpm::ConstPtr&amp; param);

	ros::NodeHandle nh_;
	ros::Subscriber config_sub_;
	ros::Subscriber img_sub_;
	ros::Publisher detect_pub_;
	DPMOCVCPULatentSvmDetector *cpu_detector_;
#if defined(HAS_GPU)
	DPMOCVGPULatentSvmDetector *gpu_detector_;
#endif
	double score_threshold_;
	double overlap_threshold_;
	double val_of_truncate_;
	int num_threads_;
	int lambda_;
	int num_cells_;
	int num_bins_;
	std::string model_file_;
	std::string object_class;
	std::string image_topic_name;
};

// Constructor
objectDetect::objectDetect() :
	cpu_detector_(NULL),
#if defined(HAS_GPU)
	gpu_detector_(NULL),
#endif
	object_class(&quot;car&quot;)
{
	ros::NodeHandle private_nh_(&quot;~&quot;);

	private_nh_.param(&quot;overlap_threshold&quot;, overlap_threshold_, 0.5);
	private_nh_.param(&quot;num_threads&quot;, num_threads_, 8);
	private_nh_.param(&quot;lambda&quot;, lambda_, 10);
	private_nh_.param(&quot;num_cells&quot;, num_cells_, NUM_CELLS);
	private_nh_.param(&quot;num_bins&quot;, num_bins_, NUM_BINS);
	private_nh_.param(&quot;val_of_tuncate&quot;, val_of_truncate_, 0.2);
	private_nh_.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name, &quot;/image_raw&quot;);

	if (!private_nh_.getParam(&quot;detection_class_name&quot;, object_class))  {
		object_class = &quot;car&quot;;
	}

#if defined(HAS_GPU)
	if (!private_nh_.getParam(&quot;use_gpu&quot;, use_gpu)) {
		use_gpu = false;
	}
#endif

	std::string default_model;
	// switch (type) {
	// case DetectType::CAR:
	// 	default_model =  std::string(STR(MODEL_DIR) &quot;car_2008.xml&quot;);
	// 	break;
	// case DetectType::PEDESTRIAN:
	// 	default_model =  std::string(STR(MODEL_DIR) &quot;person.xml&quot;);
	// 	break;
	// default:
	// 	break;
	// }
	if (object_class == &quot;car&quot;) {
		default_model =  std::string(STR(MODEL_DIR) &quot;car_2008.xml&quot;);
	}
	else if (object_class == &quot;person&quot;) {
		default_model =  std::string(STR(MODEL_DIR) &quot;person.xml&quot;);
	}

	private_nh_.param(&quot;model_file&quot;, model_file_, default_model);

	std::vector&lt;std::string&gt; model_filenames;
	model_filenames.clear();
	model_filenames.push_back(model_file_);

	cpu_detector_ = new DPMOCVCPULatentSvmDetector(model_filenames);
	if (!private_nh_.getParam(&quot;score_threshold&quot;, score_threshold_))
	{
		score_threshold_ = SCORE_THRESHOLD;
	}

#if defined(HAS_GPU)
	gpu_detector_ = new DPMOCVGPULatentSvmDetector(model_filenames, (float)score_threshold_);
#endif
}

// Destructor
objectDetect::~objectDetect()
{
	delete cpu_detector_;
#if defined(HAS_GPU)
	if(gpu_detector_ != NULL)
	{
		delete(gpu_detector_);
		gpu_detector_ = NULL;
	}
#endif
}

void objectDetect::run()
{
	std::string config_topic(&quot;/config&quot;);
	config_topic += ros::this_node::getNamespace() + &quot;/dpm&quot;;
	config_sub_ = nh_.subscribe&lt;runtime_manager::ConfigCarDpm&gt;(config_topic, 1, &amp;objectDetect::configCallback, this);
	img_sub_ = nh_.subscribe&lt;sensor_msgs::Image&gt;(image_topic_name, 1, &amp;objectDetect::imageCallback, this);
	detect_pub_ = nh_.advertise&lt;cv_tracker::image_obj&gt;(&quot;image_obj&quot;, 1);
}

// Callback
void objectDetect::imageCallback(const sensor_msgs::ImageConstPtr&amp; img)
{
	// transform image
	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(img, sensor_msgs::image_encodings::BGR8);
	cv::Mat image = cv_image-&gt;image;

	std::vector&lt;cv::LatentSvmDetector::ObjectDetection&gt; detections;

	// detection main
#if defined(HAS_GPU)
	if (use_gpu) {
		gpu_detector_-&gt;detect(image, detections, (float)overlap_threshold_, num_threads_,
			lambda_, num_cells_, (float)val_of_truncate_);
	} else {
#endif
		cpu_detector_-&gt;detect(image, detections, (float)overlap_threshold_, num_threads_,
			score_threshold_, lambda_, num_cells_, num_bins_);
#if defined(HAS_GPU)
	}
#endif

	int num = detections.size();
	std::vector&lt;int&gt; corner_point_array(num * 4.0);
	std::vector&lt;int&gt; type_array(num, 0);

	cv_tracker::image_obj msg;
	msg.header = img-&gt;header;
	msg.type = object_class;

	for(size_t i = 0; i &lt; detections.size(); i++)
	{
		const cv::LatentSvmDetector::ObjectDetection&amp; od = detections[i];
		cv_tracker::image_rect rect;

		type_array[i] = od.classID;
		rect.x = od.rect.x;
		rect.y = od.rect.y;
		rect.width = od.rect.width;
		rect.height = od.rect.height;
		rect.score = od.score;
		msg.obj.push_back(rect);
	}

	detect_pub_.publish(msg);
}

void objectDetect::configCallback(const runtime_manager::ConfigCarDpm::ConstPtr&amp; param)
{
	score_threshold_   = param-&gt;score_threshold;
	overlap_threshold_ = param-&gt;group_threshold;
	lambda_			   = param-&gt;Lambda;
	num_cells_		   = param-&gt;num_cells;
	num_bins_		   = param-&gt;num_bins;
}

int main(int argc, char* argv[])
{
	ros::init(argc, argv, &quot;dpm_ocv&quot;);

	objectDetect detector;

	detector.run();

	ros::spin();
	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/kf_track/kf_track.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/kf_track/kf_track.cpp">
				<diff>@@ -30,7 +30,7 @@
 
 #include &lt;string&gt;
 #include &lt;ros/ros.h&gt;
-#include &lt;cv_tracker/ImageObjects.h&gt;
+#include &lt;cv_tracker_msgs/ImageObjects.h&gt;
 
 extern int kf_main(int argc, char* argv[]);
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;string&gt;
#include &lt;ros/ros.h&gt;
#include &lt;cv_tracker/ImageObjects.h&gt;

extern int kf_main(int argc, char* argv[]);

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;kf_track&quot;);

	ros::NodeHandle n;

	return kf_main(argc, argv);
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/draw_rects.cpp" new_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/draw_rects.cpp">
				<diff>@@ -1,10 +1,16 @@
 #include &quot;draw_rects.h&quot;
 #include &lt;string&gt;
 #include &lt;vector&gt;
-//#include &lt;opencv2/contrib/contrib.hpp&gt;
-#include &quot;gencolors.cpp&quot;
 
 
+#include &lt;opencv2/core/version.hpp&gt;
+
+#if (CV_MAJOR_VERSION == 3)
+#include &quot;gencolors.cpp&quot;
+#else
+#include &lt;opencv2/contrib/contrib.hpp&gt;
+#endif
+
 namespace integrated_viewer
 {
   const int        DrawRects::kRectangleThickness = 3;
@@ -13,7 +19,11 @@ namespace integrated_viewer
   
   DrawRects::DrawRects(void) {
     // Generate color map to represent tracked object
+#if (CV_MAJOR_VERSION == 3)
     generateColors(color_map_, 25);
+#else
+    cv::generateColors(color_map_, 25);
+#endif
 
   } // DrawRects::DrawRects()
 
</diff>
				<old_file>#include &quot;draw_rects.h&quot;
#include &lt;string&gt;
#include &lt;vector&gt;
//#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &quot;gencolors.cpp&quot;


namespace integrated_viewer
{
  const int        DrawRects::kRectangleThickness = 3;
  const cv::Scalar DrawRects::kBlue               = CV_RGB(0, 0, 255);
  const cv::Scalar DrawRects::kGreen              = CV_RGB(0, 255, 0);
  
  DrawRects::DrawRects(void) {
    // Generate color map to represent tracked object
    generateColors(color_map_, 25);

  } // DrawRects::DrawRects()


  void DrawRects::DrawImageObj(const cv_tracker_msgs::image_obj::ConstPtr&amp; rect_data,
                               cv::Mat &amp;image) {
    if (rect_data == NULL) {
      return;
    }

    cv::Scalar rectangle_color;
    if (rect_data-&gt;type == &quot;car&quot;) {
      rectangle_color = kBlue;
    } else {
      rectangle_color = kGreen;
    }
    
    // Draw rectangles for each objects
    for (const auto&amp; rectangle : rect_data-&gt;obj) {
      // Make label shown on a rectangle
      std::ostringstream label;
      label &lt;&lt; rect_data-&gt;type &lt;&lt; &quot;:&quot; &lt;&lt; std::setprecision(2) &lt;&lt; rectangle.score;

      // Draw object information label
      DrawLabel(label.str(), cv::Point(rectangle.x, rectangle.y), image);

      // Draw rectangle
      cv::rectangle(image,
                    cv::Point(rectangle.x, rectangle.y),
                    cv::Point(rectangle.x + rectangle.width, rectangle.y + rectangle.height),
                    rectangle_color,
                    kRectangleThickness,
                    CV_AA,
                    0);
    }
  } // DrawRects::DrawImageObj()


  void DrawRects::DrawImageObjRanged(const cv_tracker_msgs::image_obj_ranged::ConstPtr&amp; rect_data,
                                     cv::Mat &amp;image) {
    if (rect_data == NULL) {
      return;
    }

    cv::Scalar rectangle_color;
    if (rect_data-&gt;type == &quot;car&quot;) {
      rectangle_color = kBlue;
    } else {
      rectangle_color = kGreen;
    }
    
    // Draw rectangles for each objects
    for (const auto&amp; ojbect : rect_data-&gt;obj) {
      // Make label shown on a rectangle
      std::ostringstream label;
      label &lt;&lt; rect_data-&gt;type &lt;&lt; &quot; : &quot; &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; ojbect.range / 100 &lt;&lt; &quot; m&quot;;

      // Draw object information label
      DrawLabel(label.str(), cv::Point(ojbect.rect.x, ojbect.rect.y), image);

      // Draw rectangle
      cv::rectangle(image,
                    cv::Point(ojbect.rect.x, ojbect.rect.y),
                    cv::Point(ojbect.rect.x + ojbect.rect.width, ojbect.rect.y + ojbect.rect.height),
                    rectangle_color,
                    kRectangleThickness,
                    CV_AA,
                    0);
    }
  } // DrawRects::DrawImageObjRanged()


  void DrawRects::DrawImageObjTracked(const cv_tracker_msgs::image_obj_tracked::ConstPtr&amp; rect_data,
                                      cv::Mat &amp;image) {
    if (rect_data == NULL) {
      return;
    }

    for (const auto&amp; object : rect_data-&gt;rect_ranged) {
      int index = &amp;object - &amp;(rect_data-&gt;rect_ranged[0]);
      int object_id = rect_data-&gt;obj_id[index];

      // Make label shown on a rectangle
      std::ostringstream label;
      label &lt;&lt; rect_data-&gt;type &lt;&lt; &quot;_&quot; &lt;&lt; object_id &lt;&lt; &quot; : &quot; &lt;&lt; std::setprecision(2) &lt;&lt; rect_data-&gt;lifespan[index];

      // Draw object information label
      DrawLabel(label.str(), cv::Point(object.rect.x, object.rect.y), image);
      
      // Draw rectangle
      cv::rectangle(image,
                    cv::Point(object.rect.x, object.rect.y),
                    cv::Point(object.rect.x + object.rect.width, object.rect.y + object.rect.height),
                    color_map_[object_id],
                    kRectangleThickness,
                    CV_AA,
                    0);
    }
  } // DrawRects::DrawImageObjTracked()


  void DrawRects::DrawLabel(const std::string&amp; label,
                            const cv::Point&amp; rectangle_origin,
                            cv::Mat &amp;image) {
    // label's property
    const int    font_face      = cv::FONT_HERSHEY_COMPLEX;
    const double font_scale     = 0.5;
    const int    font_thickness = 1;
    int          font_baseline  = 0;

    cv::Size label_size = cv::getTextSize(label,
                                          font_face,
                                          font_scale,
                                          font_thickness,
                                          &amp;font_baseline);

    cv::Point label_origin = cv::Point(rectangle_origin.x - kRectangleThickness,
                                       rectangle_origin.y - font_baseline - kRectangleThickness);

    // Fill label's background by black
    cv::rectangle(image,
                  cv::Point(label_origin.x, label_origin.y + font_baseline),
                  cv::Point(label_origin.x + label_size.width, label_origin.y - label_size.height),
                  CV_RGB(0, 0, 0),
                  CV_FILLED);

    // Draw label text by white
    cv::putText(image,
                label,
                label_origin,
                font_face,
                font_scale,
                CV_RGB(255, 255, 255));
        
  } // DrawRects::DrawLabel()
} // end namespace integrated_viewer
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/image_viewer_plugin.cpp" new_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/image_viewer_plugin.cpp">
				<diff>@@ -1,7 +1,11 @@
 #include &lt;ros/ros.h&gt;
 #include &lt;opencv/cv.h&gt;
 #include &lt;opencv/highgui.h&gt;
+
+#if (CV_MAJOR_VERSION == 3)
 #include &lt;opencv2/imgcodecs/imgcodecs.hpp&gt;
+#endif
+
 #include &lt;QString&gt;
 #include &lt;QImage&gt;
 
</diff>
				<old_file>#include &lt;ros/ros.h&gt;
#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/imgcodecs/imgcodecs.hpp&gt;
#include &lt;QString&gt;
#include &lt;QImage&gt;

#include &quot;image_viewer_plugin.h&quot;
#include &quot;draw_rects.h&quot;
#include &quot;draw_points.h&quot;

#define XSTR(x) #x
#define STR(x) XSTR(x)

namespace integrated_viewer
{
  const QString     ImageViewerPlugin::kImageDataType               = &quot;sensor_msgs/Image&quot;;
  const QString     ImageViewerPlugin::kRectDataTypeBase            = &quot;cv_tracker_msgs/image_obj&quot;;
  const QString     ImageViewerPlugin::kPointDataType               = &quot;points2image/PointsImage&quot;;
  const QString     ImageViewerPlugin::kBlankTopic                  = &quot;-----&quot;;
  const std::string ImageViewerPlugin::kRectDataTypeImageObjRanged  = &quot;cv_tracker_msgs/image_obj_ranged&quot;;
  const std::string ImageViewerPlugin::kRectDataTypeImageObjTracked = &quot;cv_tracker_msgs/image_obj_tracked&quot;;

  ImageViewerPlugin::ImageViewerPlugin(QWidget* parent)
    : rviz::Panel(parent) {

    // Initialize Form
    ui_.setupUi(this);

    // Load default image
    default_image_ = cv::imread(STR(IMAGE_VIEWER_DEFAULT_IMAGE));

    points_msg_ = NULL;
    image_obj_msg_ = NULL;
    image_obj_ranged_msg_ = NULL;
    image_obj_tracked_msg_ = NULL;

    UpdateTopicList();

    viewed_image_ = default_image_.clone();
    default_image_shown_ = true;
    ShowImageOnUi();

    // If combobox is clicked, topic list will be update
    ui_.image_topic_combo_box_-&gt;installEventFilter(this);
    ui_.rect_topic_combo_box_-&gt;installEventFilter(this);
    ui_.point_topic_combo_box_-&gt;installEventFilter(this);

  } // ImageViewerPlugin::ImageViewerPlugin()


  void ImageViewerPlugin::UpdateTopicList(void) {
    // The topic list that can be selected from the UI
    QStringList image_topic_list;
    QStringList rect_topic_list;
    QStringList point_topic_list;

    // The topic name currently chosen
    QString image_topic_current = ui_.image_topic_combo_box_-&gt;currentText();
    QString rect_topic_current = ui_.rect_topic_combo_box_-&gt;currentText();
    QString point_topic_current = ui_.point_topic_combo_box_-&gt;currentText();

    if (image_topic_current == &quot;&quot;) {
      image_topic_current = kBlankTopic;
    }

    if (rect_topic_current == &quot;&quot;) {
      rect_topic_current = kBlankTopic;
    }

    if (point_topic_current == &quot;&quot;) {
      point_topic_current = kBlankTopic;
    }

    // reset topic information list for detection result
    rect_topic_info_.clear();

    // Insert blank topic name to the top of the lists
    image_topic_list &lt;&lt; kBlankTopic;
    rect_topic_list  &lt;&lt; kBlankTopic;
    point_topic_list &lt;&lt; kBlankTopic;

    // Get all available topic 
    ros::master::V_TopicInfo master_topics;
    ros::master::getTopics(master_topics);

    // Analyse topics
    for (ros::master::V_TopicInfo::iterator it = master_topics.begin(); it != master_topics.end(); it++) {
      const ros::master::TopicInfo&amp; info = *it;
      const QString topic_name = QString::fromStdString(info.name);
      const QString topic_type = QString::fromStdString(info.datatype);
      
      // Check whether this topic is image
      if (topic_type.contains(kImageDataType) == true) {
        image_topic_list &lt;&lt; topic_name;
        continue;
      }

      // Check whether this topic is rectangle
      if (topic_type.contains(kRectDataTypeBase) == true) { 
        // This condition will also be true for &quot;image_obj_ranged&quot;and &quot;image_obj_tracked&quot;
        rect_topic_list &lt;&lt; topic_name;
        // Insert topic name and data type to a list
        rect_topic_info_[info.name] = info.datatype;
        continue;
      }

      // Check whether this topic is point cloud
      if (topic_type.contains(kPointDataType) == true) {
        point_topic_list &lt;&lt; topic_name;
        continue;
      }
    }

    // remove all list items from combo box
    ui_.image_topic_combo_box_-&gt;clear();
    ui_.rect_topic_combo_box_-&gt;clear();
    ui_.point_topic_combo_box_-&gt;clear();

    // set new items to combo box
    ui_.image_topic_combo_box_-&gt;addItems(image_topic_list);
    ui_.rect_topic_combo_box_-&gt;addItems(rect_topic_list);
    ui_.point_topic_combo_box_-&gt;addItems(point_topic_list);
   
    ui_.image_topic_combo_box_-&gt;insertSeparator(1);
    ui_.rect_topic_combo_box_-&gt;insertSeparator(1);
    ui_.point_topic_combo_box_-&gt;insertSeparator(1);

    // set last topic as current
    int image_topic_index = ui_.image_topic_combo_box_-&gt;findText(image_topic_current);
    int rect_topic_index = ui_.rect_topic_combo_box_-&gt;findText(rect_topic_current);
    int point_topic_index = ui_.point_topic_combo_box_-&gt;findText(point_topic_current);

    if (image_topic_index != -1) {
      ui_.image_topic_combo_box_-&gt;setCurrentIndex(image_topic_index);
    }

    if (rect_topic_index != -1) {
      ui_.rect_topic_combo_box_-&gt;setCurrentIndex(rect_topic_index);
    }

    if (point_topic_index != -1) {
      ui_.point_topic_combo_box_-&gt;setCurrentIndex(point_topic_index);
    }

  } // ImageViewerPlugin::UpdateTopicList()





  // The behavior of combo box for image
  void ImageViewerPlugin::on_image_topic_combo_box__activated(int index) {
    // Extract selected topic name from combo box
    std::string selected_topic = ui_.image_topic_combo_box_-&gt;itemText(index).toStdString();
    if (selected_topic == kBlankTopic.toStdString() || selected_topic == &quot;&quot;) {
      image_sub_.shutdown();
      // If blank name is selected as image topic, show default image
      viewed_image_ = default_image_.clone();
      default_image_shown_ = true;
      ShowImageOnUi();
      return;
    }
    
    // if selected topic is not blank or empty, start callback function
    default_image_shown_ = false;
    image_sub_ = node_handle_.subscribe&lt;sensor_msgs::Image&gt;(selected_topic,
                                                            1,
                                                            &amp;ImageViewerPlugin::ImageCallback,
                                                            this);

  } // ImageViewerPlugin::on_image_topic_combo_box__activated()


  void ImageViewerPlugin::ImageCallback(const sensor_msgs::Image::ConstPtr&amp; msg) {
    // Get image from topic
    const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
    viewed_image_ = cv_bridge::toCvCopy(msg, encoding)-&gt;image;

    ShowImageOnUi();
  } // ImageViewerPlugin::ImageCallback()


  // The behavior of combo box for detection result rectangle
  void ImageViewerPlugin::on_rect_topic_combo_box__activated(int index) {
    // Extract selected topic name from combo box
    std::string selected_topic = ui_.rect_topic_combo_box_-&gt;itemText(index).toStdString();
    if (selected_topic == kBlankTopic.toStdString() || selected_topic == &quot;&quot;) {
      rect_sub_.shutdown();
      image_obj_msg_         = NULL;
      image_obj_ranged_msg_  = NULL;
      image_obj_tracked_msg_ = NULL;
      return;
    }

    // Switch booted callback function by topic name 
    std::string topic_type = rect_topic_info_[selected_topic];
    if (topic_type.find(kRectDataTypeImageObjRanged) != std::string::npos) {
      image_obj_msg_         = NULL;
      image_obj_ranged_msg_  = NULL;
      image_obj_tracked_msg_ = NULL;
      // this topic type is image_obj_ranged
      rect_sub_ = node_handle_.subscribe&lt;cv_tracker_msgs::image_obj_ranged&gt;(selected_topic,
                                                                       1,
                                                                       &amp;ImageViewerPlugin::ImageObjRangedCallback,
                                                                       this);

    } else if (topic_type.find(kRectDataTypeImageObjTracked) != std::string::npos) {
      image_obj_msg_         = NULL;
      image_obj_ranged_msg_  = NULL;
      image_obj_tracked_msg_ = NULL;
      // this topic type is image_obj_tracked
      rect_sub_ = node_handle_.subscribe&lt;cv_tracker_msgs::image_obj_tracked&gt;(selected_topic,
                                                                       1,
                                                                       &amp;ImageViewerPlugin::ImageObjTrackedCallback,
                                                                       this);
    } else {
      image_obj_msg_         = NULL;
      image_obj_ranged_msg_  = NULL;
      image_obj_tracked_msg_ = NULL;
      // this topic type is image_obj
      rect_sub_ = node_handle_.subscribe&lt;cv_tracker_msgs::image_obj&gt;(selected_topic,
                                                                1,
                                                                &amp;ImageViewerPlugin::ImageObjCallback,
                                                                this);
    }


  } // ImageViewerPlugin::on_rect_topic_combo_box__activated()
  

  void ImageViewerPlugin::ImageObjCallback(const cv_tracker_msgs::image_obj::ConstPtr&amp; msg) {
    image_obj_msg_ = msg;
  } // ImageViewerPlugin::ImageObjCallback()

  void ImageViewerPlugin::ImageObjRangedCallback(const cv_tracker_msgs::image_obj_ranged::ConstPtr &amp;msg) {
    image_obj_ranged_msg_ = msg;
  } // ImageViewerPlugin::ImageObjRangedCallback()

  void ImageViewerPlugin::ImageObjTrackedCallback(const cv_tracker_msgs::image_obj_tracked::ConstPtr &amp;msg) {
    image_obj_tracked_msg_ = msg;
  } // ImageViewerPlugin::ImageObjTrackedCallback()


  // The behavior of combo box for points image
  void ImageViewerPlugin::on_point_topic_combo_box__activated(int index) {
    // Extract selected topic name from combo box
    std::string selected_topic = ui_.point_topic_combo_box_-&gt;itemText(index).toStdString();
    if (selected_topic == kBlankTopic.toStdString() || selected_topic == &quot;&quot;) {
      point_sub_.shutdown();
      points_msg_ = NULL;
      return;
    }

    // if selected topic is not blank or empty , start callback function
    point_sub_ = node_handle_.subscribe&lt;points2image::PointsImage&gt;(selected_topic,
                                                                   1,
                                                                   &amp;ImageViewerPlugin::PointCallback,
                                                                   this);

  } // ImageViewerPlugin::on_point_topic_combo_box__activated()


  void ImageViewerPlugin::PointCallback(const points2image::PointsImage::ConstPtr &amp;msg) {
    points_msg_ = msg;
  } // ImageViewerPlugin::PointCallback()


  void ImageViewerPlugin::ShowImageOnUi(void) {
    // Additional things will be drawn if shown image is not default one
    if (!default_image_shown_) {
      // Draw detection result rectangles on the image
      rects_drawer_.DrawImageObj(image_obj_msg_, viewed_image_);
      rects_drawer_.DrawImageObjRanged(image_obj_ranged_msg_, viewed_image_);
      rects_drawer_.DrawImageObjTracked(image_obj_tracked_msg_, viewed_image_);

      // Draw points on the image
      points_drawer_.Draw(points_msg_, viewed_image_);
    }
    // Convert cv::Mat to QPixmap to show modified image on the UI
    QPixmap view_on_ui = convert_image::CvMatToQPixmap(viewed_image_);

    // Reflect image on UI
    int height = ui_.view_-&gt;height();
    int width  = ui_.view_-&gt;width();
    ui_.view_-&gt;setPixmap(view_on_ui.scaled(width,
                                           height,
                                           Qt::KeepAspectRatio,
                                           Qt::SmoothTransformation));
  } // ImageViewerPlugin::ShowImageOnUi()


  void ImageViewerPlugin::resizeEvent(QResizeEvent *) {
    ShowImageOnUi();
  } // ImageViewerPlugin::resizeEvent()


  bool ImageViewerPlugin::eventFilter(QObject* object, QEvent* event) {
    if (event-&gt;type() == QEvent::MouseButtonPress) {
      // combo box will update its contents if this filter is applied
      UpdateTopicList();
    }

    return QObject::eventFilter(object, event);
  }


} // end namespace integrated_viewer


// Tell pluginlib about this class.  Every class which should be
// loadable by pluginlib::ClassLoader must have these two lines
// compiled in its .cpp file, outside of any namespace scope.
#include &lt;pluginlib/class_list_macros.h&gt;
PLUGINLIB_EXPORT_CLASS(integrated_viewer::ImageViewerPlugin, rviz::Panel)
// END_TUTORIAL
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp">
				<diff>@@ -49,8 +49,12 @@
 
 #include &lt;opencv/cv.h&gt;
 #include &lt;opencv/highgui.h&gt;
-//#include &lt;opencv2/contrib/contrib.hpp&gt;
+#include &lt;opencv2/core/version.hpp&gt;
+#if (CV_MAJOR_VERSION == 3)
 #include &quot;gencolors.cpp&quot;
+#else
+#include &lt;opencv2/contrib/contrib.hpp&gt;
+#endif
 
 #include &lt;chrono&gt;
 #include &lt;iostream&gt;
@@ -676,7 +680,11 @@ int main (int argc, char** argv)
 	_transform = &amp;transform;
 	_transform_listener = &amp;listener;
 
+#if (CV_MAJOR_VERSION == 3)
 	generateColors(_colors, 100);
+#else
+	cv::generateColors(_colors, 100);
+#endif
 
 	_pub_cluster_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_cluster&quot;,1);
 	_pub_ground_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_ground&quot;,1);
</diff>
				<old_file>#include &lt;ros/ros.h&gt;

#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/PCLPointCloud2.h&gt;
#include &lt;pcl/conversions.h&gt;
#include &lt;pcl_ros/transforms.h&gt;
#include &lt;pcl_ros/point_cloud.h&gt;

#include &lt;pcl/ModelCoefficients.h&gt;
#include &lt;pcl/point_types.h&gt;

#include &lt;pcl/filters/extract_indices.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;
#include &lt;pcl/filters/conditional_removal.h&gt;

#include &lt;pcl/features/normal_3d.h&gt;
#include &lt;pcl/features/normal_3d_omp.h&gt;
#include &lt;pcl/features/don.h&gt;

#include &lt;pcl/kdtree/kdtree.h&gt;

#include &lt;pcl/sample_consensus/method_types.h&gt;
#include &lt;pcl/sample_consensus/model_types.h&gt;

#include &lt;pcl/segmentation/sac_segmentation.h&gt;
#include &lt;pcl/segmentation/extract_clusters.h&gt;
#include &lt;pcl/segmentation/conditional_euclidean_clustering.h&gt;

#include &lt;pcl/common/common.h&gt;

#include &lt;pcl/search/organized.h&gt;
#include &lt;pcl/search/kdtree.h&gt;

#include &lt;pcl/segmentation/extract_clusters.h&gt;

#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;lidar_tracker/centroids.h&gt;
#include &lt;lidar_tracker/CloudCluster.h&gt;
#include &lt;lidar_tracker/CloudClusterArray.h&gt;

#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;

#include &lt;tf/tf.h&gt;

#include &lt;limits&gt;
#include &lt;cmath&gt;

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
//#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &quot;gencolors.cpp&quot;

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;

#include &quot;Cluster.h&quot;

//#include &lt;vector_map/vector_map.h&gt;
//#include &lt;vector_map_server/GetSignal.h&gt;

using namespace cv;

std::vector&lt;cv::Scalar&gt; _colors;
ros::Publisher _pub_cluster_cloud;
ros::Publisher _pub_ground_cloud;
ros::Publisher _centroid_pub;
ros::Publisher _marker_pub;
ros::Publisher _pub_clusters_message;
visualization_msgs::Marker _visualization_marker;

ros::Publisher _pub_points_lanes_cloud;
ros::Publisher _pub_jsk_boundingboxes;

std_msgs::Header _velodyne_header;

pcl::PointCloud&lt;pcl::PointXYZ&gt; _sensor_cloud;

std::vector&lt;double&gt; _clustering_thresholds;
std::vector&lt;double&gt; _clustering_distances;

tf::StampedTransform* _transform;
tf::StampedTransform* _velodyne_output_transform;
tf::TransformListener* _transform_listener;

std::string _output_frame;
static bool _velodyne_transform_available;
static bool _downsample_cloud;
static bool _pose_estimation;
static double _leaf_size;
static int _cluster_size_min;
static int _cluster_size_max;

static bool _remove_ground;	//only ground

static bool _using_sensor_cloud;
static bool _use_diffnormals;

static double _clip_min_height;
static double _clip_max_height;

static bool _keep_lanes;
static double _keep_lane_left_distance;
static double _keep_lane_right_distance;

static double _max_boundingbox_side;
static double _remove_points_upto;

void transformBoundingBox(const jsk_recognition_msgs::BoundingBox&amp; in_boundingbox, jsk_recognition_msgs::BoundingBox&amp; out_boundingbox, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	geometry_msgs::PoseStamped pose_in, pose_out;
	pose_in.header = in_header;
	pose_in.pose = in_boundingbox.pose;
	try
	{
		_transform_listener-&gt;transformPose(in_target_frame, ros::Time(), pose_in, in_header.frame_id,  pose_out);
	}
	catch (tf::TransformException &amp;ex)
	{
		ROS_ERROR(&quot;transformBoundingBox: %s&quot;,ex.what());
	}
	out_boundingbox.pose = pose_out.pose;
	out_boundingbox.header = in_header;
	out_boundingbox.header.frame_id = in_target_frame;
	out_boundingbox.dimensions = in_boundingbox.dimensions;
	out_boundingbox.value = in_boundingbox.value;
	out_boundingbox.label = in_boundingbox.label;
}

void publishCloudClusters(const ros::Publisher* in_publisher, const lidar_tracker::CloudClusterArray&amp; in_clusters, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		lidar_tracker::CloudClusterArray clusters_transformed;
		clusters_transformed.header = in_header;
		clusters_transformed.header.frame_id = in_target_frame;
		for (auto i=clusters_transformed.clusters.begin(); i!= clusters_transformed.clusters.end(); i++)
		{
			lidar_tracker::CloudCluster cluster_transformed;
			cluster_transformed.header = in_header;
			try
			{
				_transform_listener-&gt;lookupTransform(in_target_frame, _velodyne_header.frame_id,
										ros::Time(), *_transform);
				pcl_ros::transformPointCloud(in_target_frame, *_transform, i-&gt;cloud, cluster_transformed.cloud);

				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;min_point, in_header.frame_id, cluster_transformed.min_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;max_point, in_header.frame_id, cluster_transformed.max_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;avg_point, in_header.frame_id, cluster_transformed.avg_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;centroid_point, in_header.frame_id, cluster_transformed.centroid_point);

				cluster_transformed.dimensions = i-&gt;dimensions;
				cluster_transformed.eigen_values = i-&gt;eigen_values;
				cluster_transformed.eigen_vectors = i-&gt;eigen_vectors;

				transformBoundingBox(i-&gt;bounding_box, cluster_transformed.bounding_box, in_target_frame, in_header);

				clusters_transformed.clusters.push_back(cluster_transformed);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCloudClusters: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(clusters_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_clusters);
	}
}

void publishCentroids(const ros::Publisher* in_publisher, const lidar_tracker::centroids&amp; in_centroids, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		lidar_tracker::centroids centroids_transformed;
		centroids_transformed.header = in_header;
		centroids_transformed.header.frame_id = in_target_frame;
		for (auto i=centroids_transformed.points.begin(); i!= centroids_transformed.points.end(); i++)
		{
			geometry_msgs::PointStamped centroid_in, centroid_out;
			centroid_in.header = in_header;
			centroid_in.point = *i;
			try
			{
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), centroid_in, in_header.frame_id, centroid_out);

				centroids_transformed.points.push_back(centroid_out.point);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCentroids: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(centroids_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_centroids);
	}
}

void publishBoundingBoxArray(const ros::Publisher* in_publisher, const jsk_recognition_msgs::BoundingBoxArray&amp; in_boundingbox_array, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		jsk_recognition_msgs::BoundingBoxArray boundingboxes_transformed;
		boundingboxes_transformed.header = in_header;
		boundingboxes_transformed.header.frame_id = in_target_frame;
		for (auto i=in_boundingbox_array.boxes.begin(); i!= in_boundingbox_array.boxes.end(); i++)
		{
			jsk_recognition_msgs::BoundingBox boundingbox_transformed;
			transformBoundingBox(*i, boundingbox_transformed, in_target_frame, in_header);
			boundingboxes_transformed.boxes.push_back(boundingbox_transformed);
		}
		in_publisher-&gt;publish(boundingboxes_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_boundingbox_array);
	}
}

void publishCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void publishColorCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void keepLanePoints(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
					pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr,
					float in_left_lane_threshold = 1.5,
					float in_right_lane_threshold = 1.5)
{
	pcl::PointIndices::Ptr far_indices (new pcl::PointIndices);
	for(unsigned int i=0; i&lt; in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x=in_cloud_ptr-&gt;points[i].x;
		current_point.y=in_cloud_ptr-&gt;points[i].y;
		current_point.z=in_cloud_ptr-&gt;points[i].z;

		if (
				current_point.y &gt; (in_left_lane_threshold) || current_point.y &lt; -1.0*in_right_lane_threshold
			)
		{
			far_indices-&gt;indices.push_back(i);
		}
	}
	out_cloud_ptr-&gt;points.clear();
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(far_indices);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_cloud_ptr);
}

std::vector&lt;ClusterPtr&gt; clusterAndColor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		lidar_tracker::centroids&amp; in_out_centroids,
		double in_max_cluster_distance=0.5)
{
	pcl::search::KdTree&lt;pcl::PointXYZ&gt;::Ptr tree (new pcl::search::KdTree&lt;pcl::PointXYZ&gt;);

	if (in_cloud_ptr-&gt;points.size() &gt; 0)
		tree-&gt;setInputCloud (in_cloud_ptr);

	std::vector&lt;pcl::PointIndices&gt; cluster_indices;

	pcl::EuclideanClusterExtraction&lt;pcl::PointXYZ&gt; ec;
	ec.setClusterTolerance (in_max_cluster_distance); //
	ec.setMinClusterSize (_cluster_size_min);
	ec.setMaxClusterSize (_cluster_size_max);
	ec.setSearchMethod(tree);
	ec.setInputCloud (in_cloud_ptr);
	ec.extract (cluster_indices);


	/*pcl::ConditionalEuclideanClustering&lt;pcl::PointXYZ&gt; cec (true);
	cec.setInputCloud (in_cloud_ptr);
	cec.setConditionFunction (&amp;independentDistance);
	cec.setMinClusterSize (cluster_size_min);
	cec.setMaxClusterSize (cluster_size_max);
	cec.setClusterTolerance (_distance*2.0f);
	cec.segment (cluster_indices);*/

	/////////////////////////////////
	//---	3. Color clustered points
	/////////////////////////////////
	unsigned int k = 0;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr final_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

	std::vector&lt;ClusterPtr&gt; clusters;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr cloud_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);//coord + color cluster
	for (auto it = cluster_indices.begin(); it != cluster_indices.end(); ++it)
	{
		ClusterPtr cluster(new Cluster());
		cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;indices, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		clusters.push_back(cluster);

		k++;
	}
	//std::cout &lt;&lt; &quot;Clusters: &quot; &lt;&lt; k &lt;&lt; std::endl;
	return clusters;

}

void segmentByDistance(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		lidar_tracker::centroids&amp; in_out_centroids,
		lidar_tracker::CloudClusterArray&amp; in_out_clusters)
{
	//cluster the pointcloud according to the distance of the points using different thresholds (not only one for the entire pc)
	//in this way, the points farther in the pc will also be clustered

	//0 =&gt; 0-15m d=0.5
	//1 =&gt; 15-30 d=1
	//2 =&gt; 30-45 d=1.6
	//3 =&gt; 45-60 d=2.1
	//4 =&gt; &gt;60   d=2.6

	std::vector&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr&gt; cloud_segments_array(5);

	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr tmp_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		cloud_segments_array[i] = tmp_cloud;
	}

	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x = in_cloud_ptr-&gt;points[i].x;
		current_point.y = in_cloud_ptr-&gt;points[i].y;
		current_point.z = in_cloud_ptr-&gt;points[i].z;

		float origin_distance = sqrt( pow(current_point.x,2) + pow(current_point.y,2) );

		if 		(origin_distance &lt; _clustering_distances[0] )	{cloud_segments_array[0]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[1])		{cloud_segments_array[1]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[2])		{cloud_segments_array[2]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[3])		{cloud_segments_array[3]-&gt;points.push_back (current_point);}
		else													{cloud_segments_array[4]-&gt;points.push_back (current_point);}
	}

	std::vector &lt;ClusterPtr&gt; all_clusters;
	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
		std::vector&lt;ClusterPtr&gt; local_clusters = clusterAndColor(cloud_segments_array[i], out_cloud_ptr, in_out_boundingbox_array, in_out_centroids, _clustering_thresholds[i]);

		all_clusters.insert(all_clusters.end(), local_clusters.begin(), local_clusters.end());
	}

	//Clusters can be merged or checked in here
	//....
	//Get final PointCloud to be published

	for(unsigned int i=0; i&lt;all_clusters.size(); i++)
	{
		*out_cloud_ptr = *out_cloud_ptr + *(all_clusters[i]-&gt;GetCloud());

		jsk_recognition_msgs::BoundingBox bounding_box = all_clusters[i]-&gt;GetBoundingBox();
		pcl::PointXYZ min_point = all_clusters[i]-&gt;GetMinPoint();
		pcl::PointXYZ max_point = all_clusters[i]-&gt;GetMaxPoint();
		pcl::PointXYZ center_point = all_clusters[i]-&gt;GetCentroid();
		geometry_msgs::Point centroid;
		centroid.x = center_point.x; centroid.y = center_point.y; centroid.z = center_point.z;
		bounding_box.header = _velodyne_header;

		if (	//(fabs(bounding_box.pose.position.x) &gt; 2.1 &amp;&amp; fabs(bounding_box.pose.position.y) &gt; 0.8 ) &amp;&amp; //ignore points that belong to our car
				bounding_box.dimensions.x &gt;0 &amp;&amp; bounding_box.dimensions.y &gt;0 &amp;&amp; bounding_box.dimensions.z &gt; 0 &amp;&amp;
				bounding_box.dimensions.x &lt; _max_boundingbox_side &amp;&amp; bounding_box.dimensions.y &lt; _max_boundingbox_side
				&amp;&amp;max_point.z &gt; -1.5 &amp;&amp; min_point.z &gt; -1.5 &amp;&amp; min_point.z &lt; 1.0
				)
		{
			in_out_boundingbox_array.boxes.push_back(bounding_box);
			in_out_centroids.points.push_back(centroid);
			_visualization_marker.points.push_back(centroid);

			lidar_tracker::CloudCluster cloud_cluster;
			all_clusters[i]-&gt;ToRosMessage(_velodyne_header, cloud_cluster);
			in_out_clusters.clusters.push_back(cloud_cluster);
		}
	}
}

void removeFloor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_nofloor_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_onlyfloor_cloud_ptr, float in_max_height=0.2, float in_floor_max_angle=0.35)
{
	pcl::SACSegmentation&lt;pcl::PointXYZ&gt; seg;
	pcl::PointIndices::Ptr inliers (new pcl::PointIndices);
	pcl::ModelCoefficients::Ptr coefficients (new pcl::ModelCoefficients);

	seg.setOptimizeCoefficients (true);
	seg.setModelType(pcl::SACMODEL_PERPENDICULAR_PLANE);
	seg.setMethodType(pcl::SAC_RANSAC);
	seg.setMaxIterations(100);
	seg.setAxis(Eigen::Vector3f(0,0,1));
	seg.setEpsAngle(in_floor_max_angle);

	seg.setDistanceThreshold (in_max_height);//floor distance
	seg.setOptimizeCoefficients(true);
	seg.setInputCloud(in_cloud_ptr);
	seg.segment(*inliers, *coefficients);
	if (inliers-&gt;indices.size () == 0)
	{
		std::cout &lt;&lt; &quot;Could not estimate a planar model for the given dataset.&quot; &lt;&lt; std::endl;
	}

	/*REMOVE THE FLOOR FROM THE CLOUD*/
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(inliers);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_nofloor_cloud_ptr);

	/*EXTRACT THE FLOOR FROM THE CLOUD*/
	extract.setNegative(false);//true removes the indices, false leaves only the indices
	extract.filter(*out_onlyfloor_cloud_ptr);
}

void downsampleCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_leaf_size=0.2)
{

	pcl::VoxelGrid&lt;pcl::PointXYZ&gt; sor;
	sor.setInputCloud(in_cloud_ptr);
	sor.setLeafSize((float)in_leaf_size, (float)in_leaf_size, (float)in_leaf_size);
	sor.filter(*out_cloud_ptr);

}

void clipCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_min_height=-1.3, float in_max_height=0.5)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		if (in_cloud_ptr-&gt;points[i].z &gt;= in_min_height &amp;&amp;
				in_cloud_ptr-&gt;points[i].z &lt;= in_max_height)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void differenceNormalsSegmentation(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr)
{

	float small_scale=0.5;
	float large_scale=2.0;
	float angle_threshold=0.5;
	pcl::search::Search&lt;pcl::PointXYZ&gt;::Ptr tree;
	if (in_cloud_ptr-&gt;isOrganized ())
	{
		tree.reset (new pcl::search::OrganizedNeighbor&lt;pcl::PointXYZ&gt; ());
	}
	else
	{
		tree.reset (new pcl::search::KdTree&lt;pcl::PointXYZ&gt; (false));
	}

	// Set the input pointcloud for the search tree
	tree-&gt;setInputCloud (in_cloud_ptr);

	pcl::NormalEstimationOMP&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	//pcl::gpu::NormalEstimation&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	normal_estimation.setInputCloud (in_cloud_ptr);
	normal_estimation.setSearchMethod (tree);

	normal_estimation.setViewPoint (std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max ());

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_small_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_large_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	normal_estimation.setRadiusSearch (small_scale);
	normal_estimation.compute (*normals_small_scale);

	normal_estimation.setRadiusSearch (large_scale);
	normal_estimation.compute (*normals_large_scale);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::copyPointCloud&lt;pcl::PointXYZ, pcl::PointNormal&gt;(*in_cloud_ptr, *diffnormals_cloud);

	// Create DoN operator
	pcl::DifferenceOfNormalsEstimation&lt;pcl::PointXYZ, pcl::PointNormal, pcl::PointNormal&gt; diffnormals_estimator;
	diffnormals_estimator.setInputCloud (in_cloud_ptr);
	diffnormals_estimator.setNormalScaleLarge (normals_large_scale);
	diffnormals_estimator.setNormalScaleSmall (normals_small_scale);

	diffnormals_estimator.initCompute();

	diffnormals_estimator.computeFeature(*diffnormals_cloud);

	pcl::ConditionOr&lt;pcl::PointNormal&gt;::Ptr range_cond (new pcl::ConditionOr&lt;pcl::PointNormal&gt;() );
	range_cond-&gt;addComparison (pcl::FieldComparison&lt;pcl::PointNormal&gt;::ConstPtr (
			new pcl::FieldComparison&lt;pcl::PointNormal&gt; (&quot;curvature&quot;, pcl::ComparisonOps::GT, angle_threshold) )
			);
	// Build the filter
	pcl::ConditionalRemoval&lt;pcl::PointNormal&gt; cond_removal;
	cond_removal.setCondition(range_cond);
	cond_removal.setInputCloud (diffnormals_cloud);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud_filtered (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	// Apply filter
	cond_removal.filter (*diffnormals_cloud_filtered);

	pcl::copyPointCloud&lt;pcl::PointNormal, pcl::PointXYZ&gt;(*diffnormals_cloud, *out_cloud_ptr);
}

void removePointsUpTo(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, const double in_distance)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		float origin_distance = sqrt( pow(in_cloud_ptr-&gt;points[i].x,2) + pow(in_cloud_ptr-&gt;points[i].y,2) );
		if (origin_distance &gt; in_distance)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void velodyne_callback(const sensor_msgs::PointCloud2ConstPtr&amp; in_sensor_cloud)
{
	if (!_using_sensor_cloud)
	{
		_using_sensor_cloud = true;

		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr current_sensor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr removed_points_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr downsampled_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr inlanes_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr nofloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr onlyfloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr diffnormals_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr clipped_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr colored_clustered_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

		lidar_tracker::centroids centroids;
		lidar_tracker::CloudClusterArray cloud_clusters;
		jsk_recognition_msgs::BoundingBoxArray boundingbox_array;

		pcl::fromROSMsg(*in_sensor_cloud, *current_sensor_cloud_ptr);

		_velodyne_header = in_sensor_cloud-&gt;header;

		if (_remove_points_upto &gt; 0.0)
		{
			removePointsUpTo(current_sensor_cloud_ptr, removed_points_cloud_ptr, _remove_points_upto);
		}
		else
			removed_points_cloud_ptr = current_sensor_cloud_ptr;

		if (_downsample_cloud)
			downsampleCloud(removed_points_cloud_ptr, downsampled_cloud_ptr, _leaf_size);
		else
			downsampled_cloud_ptr=removed_points_cloud_ptr;

		if(_keep_lanes)
			keepLanePoints(downsampled_cloud_ptr, inlanes_cloud_ptr, _keep_lane_left_distance, _keep_lane_right_distance);
		else
			inlanes_cloud_ptr = downsampled_cloud_ptr;

		if(_remove_ground)
		{
			removeFloor(inlanes_cloud_ptr, nofloor_cloud_ptr, onlyfloor_cloud_ptr);
			publishCloud(&amp;_pub_ground_cloud, onlyfloor_cloud_ptr);
		}
		else
			nofloor_cloud_ptr = inlanes_cloud_ptr;

		clipCloud(nofloor_cloud_ptr, clipped_cloud_ptr, _clip_min_height, _clip_max_height);
		publishCloud(&amp;_pub_points_lanes_cloud, clipped_cloud_ptr);

		if (_use_diffnormals)
			differenceNormalsSegmentation(clipped_cloud_ptr, diffnormals_cloud_ptr);
		else
			diffnormals_cloud_ptr = clipped_cloud_ptr;

		segmentByDistance(diffnormals_cloud_ptr, colored_clustered_cloud_ptr, boundingbox_array, centroids, cloud_clusters);
		publishColorCloud(&amp;_pub_cluster_cloud, colored_clustered_cloud_ptr);
		// Publish BB
		boundingbox_array.header = _velodyne_header;
		publishBoundingBoxArray(&amp;_pub_jsk_boundingboxes, boundingbox_array, _output_frame, _velodyne_header);
		centroids.header = _velodyne_header;
		publishCentroids(&amp;_centroid_pub, centroids, _output_frame, _velodyne_header);

		_marker_pub.publish(_visualization_marker);
		_visualization_marker.points.clear();//transform? is it used?
		cloud_clusters.header = _velodyne_header;
		publishCloudClusters(&amp;_pub_clusters_message, cloud_clusters, _output_frame, _velodyne_header);

		_using_sensor_cloud = false;
	}
}

/*
void vectormap_callback(const visualization_msgs::MarkerArray::Ptr in_vectormap_markers)
{
	float min_x=std::numeric_limits&lt;float&gt;::max();float max_x=-std::numeric_limits&lt;float&gt;::max();
	float min_y=std::numeric_limits&lt;float&gt;::max();float max_y=-std::numeric_limits&lt;float&gt;::max();
	pcl::PointXYZ min_point;
	pcl::PointXYZ max_point;
	std::vector&lt;geometry_msgs::Point&gt; vectormap_points;
	for(auto i=in_vectormap_markers-&gt;markers.begin(); i!= in_vectormap_markers-&gt;markers.end(); i++)
	{
		visualization_msgs::Marker current_marker = *i;
		if (current_marker.ns == &quot;road_edge&quot;)
		{
			for (unsigned int j=0; j&lt; current_marker.points.size(); j++)
			{
				geometry_msgs::Point p = current_marker.points[j];
				if(p.x&lt;min_x)	min_x = p.x;
				if(p.y&lt;min_y)	min_y = p.y;
				if(p.x&gt;max_x)	max_x = p.x;
				if(p.y&gt;max_y)	max_y = p.y;
				vectormap_points.push_back(p);
			}
		}
	}
	min_point.x = min_x;	min_point.y = min_y;
	max_point.x = max_x;	max_point.y = max_y;

	min_point.x*=-1.0;
	min_point.y*=-1.0;
	//translate the points to the minimum point
	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		(*i).x+=min_point.x;
		(*i).y+=min_point.y;
	}
	max_point.x+=min_point.x;
	max_point.y+=min_point.y;
	//get world tf
	_transform_listener-&gt;lookupTransform(&quot;/map&quot;, &quot;/world&quot;,
					ros::Time(_velodyne_header.stamp), *_transform);

	tf::Vector3 map_origin_point;
	map_origin_point = _transform-&gt;getOrigin();

	cv::Mat map_image = cv::Mat::zeros(max_point.x, max_point.y, CV_8UC1);

	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		map_image.at&lt;uchar&gt;( (int)(i-&gt;x), (int)(i-&gt;y) ) = 255;
	}
	cv::imshow(&quot;vectormap&quot;, map_image);
	cv::waitKey(0);
}*/

int main (int argc, char** argv)
{
	// Initialize ROS
	ros::init (argc, argv, &quot;euclidean_cluster&quot;);

	ros::NodeHandle h;
	ros::NodeHandle private_nh(&quot;~&quot;);

	tf::StampedTransform transform;
	tf::TransformListener listener;

	_transform = &amp;transform;
	_transform_listener = &amp;listener;

	generateColors(_colors, 100);

	_pub_cluster_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_cluster&quot;,1);
	_pub_ground_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_ground&quot;,1);
	_centroid_pub = h.advertise&lt;lidar_tracker::centroids&gt;(&quot;/cluster_centroids&quot;,1);
	_marker_pub = h.advertise&lt;visualization_msgs::Marker&gt;(&quot;centroid_marker&quot;,1);

	_pub_points_lanes_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_lanes&quot;,1);
	_pub_jsk_boundingboxes = h.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(&quot;/bounding_boxes&quot;,1);
	_pub_clusters_message = h.advertise&lt;lidar_tracker::CloudClusterArray&gt;(&quot;/cloud_clusters&quot;,1);

	std::string points_topic;

	_using_sensor_cloud = false;

	if (private_nh.getParam(&quot;points_node&quot;, points_topic))
	{
		ROS_INFO(&quot;euclidean_cluster &gt; Setting points node to %s&quot;, points_topic.c_str());
	}
	else
	{
		ROS_INFO(&quot;euclidean_cluster &gt; No points node received, defaulting to points_raw, you can use _points_node:=YOUR_TOPIC&quot;);
		points_topic = &quot;/points_raw&quot;;
	}

	_use_diffnormals = false;
	if (private_nh.getParam(&quot;use_diffnormals&quot;, _use_diffnormals))
	{
		if (_use_diffnormals)
			ROS_INFO(&quot;Euclidean Clustering: Applying difference of normals on clustering pipeline&quot;);
		else
			ROS_INFO(&quot;Euclidean Clustering: Difference of Normals will not be used.&quot;);
	}

	/* Initialize tuning parameter */
	private_nh.param(&quot;downsample_cloud&quot;, _downsample_cloud, false);	ROS_INFO(&quot;downsample_cloud: %d&quot;, _downsample_cloud);
	private_nh.param(&quot;remove_ground&quot;, _remove_ground, true);		ROS_INFO(&quot;remove_ground: %d&quot;, _remove_ground);
	private_nh.param(&quot;leaf_size&quot;, _leaf_size, 0.1);					ROS_INFO(&quot;leaf_size: %f&quot;, _leaf_size);
	private_nh.param(&quot;cluster_size_min&quot;, _cluster_size_min, 20);	ROS_INFO(&quot;cluster_size_min %d&quot;, _cluster_size_min);
	private_nh.param(&quot;cluster_size_max&quot;, _cluster_size_max, 100000);ROS_INFO(&quot;cluster_size_max: %d&quot;, _cluster_size_max);
	private_nh.param(&quot;pose_estimation&quot;, _pose_estimation, false);	ROS_INFO(&quot;pose_estimation: %d&quot;, _pose_estimation);
	private_nh.param(&quot;clip_min_height&quot;, _clip_min_height, -1.3);	ROS_INFO(&quot;clip_min_height: %f&quot;, _clip_min_height);
	private_nh.param(&quot;clip_max_height&quot;, _clip_max_height, 0.5);		ROS_INFO(&quot;clip_max_height: %f&quot;, _clip_max_height);
	private_nh.param(&quot;keep_lanes&quot;, _keep_lanes, false);				ROS_INFO(&quot;keep_lanes: %d&quot;, _keep_lanes);
	private_nh.param(&quot;keep_lane_left_distance&quot;, _keep_lane_left_distance, 5.0);		ROS_INFO(&quot;keep_lane_left_distance: %f&quot;, _keep_lane_left_distance);
	private_nh.param(&quot;keep_lane_right_distance&quot;, _keep_lane_right_distance, 5.0);	ROS_INFO(&quot;keep_lane_right_distance: %f&quot;, _keep_lane_right_distance);
	private_nh.param(&quot;clustering_thresholds&quot;, _clustering_thresholds);
	private_nh.param(&quot;clustering_distances&quot;, _clustering_distances);
	private_nh.param(&quot;max_boundingbox_side&quot;, _max_boundingbox_side, 10.0);			ROS_INFO(&quot;_max_boundingbox_side: %f&quot;, _max_boundingbox_side);
	private_nh.param&lt;std::string&gt;(&quot;output_frame&quot;, _output_frame, &quot;velodyne&quot;);			ROS_INFO(&quot;output_frame: %s&quot;, _output_frame.c_str());
	private_nh.param(&quot;remove_points_upto&quot;, _remove_points_upto, 0.0);		ROS_INFO(&quot;remove_points_upto: %f&quot;, _remove_points_upto);

	_velodyne_transform_available = false;

	if (_clustering_distances.size()!=4)
	{
		_clustering_distances = {15, 30, 45, 60};//maximum distance from sensor origin to separate segments
	}
	if (_clustering_thresholds.size()!=5)
	{
		_clustering_thresholds = {0.5, 1.1, 1.6, 2.1, 2.6};//Nearest neighbor distance threshold for each segment
	}

	std::cout &lt;&lt; &quot;_clustering_thresholds: &quot;; for (auto i = _clustering_thresholds.begin(); i != _clustering_thresholds.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt; std::endl;
	std::cout &lt;&lt; &quot;_clustering_distances: &quot;;for (auto i = _clustering_distances.begin(); i != _clustering_distances.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt;std::endl;

	// Create a ROS subscriber for the input point cloud
	ros::Subscriber sub = h.subscribe (points_topic, 1, velodyne_callback);
	//ros::Subscriber sub_vectormap = h.subscribe (&quot;vector_map&quot;, 1, vectormap_callback);

	_visualization_marker.header.frame_id = &quot;velodyne&quot;;
	_visualization_marker.header.stamp = ros::Time();
	_visualization_marker.ns = &quot;my_namespace&quot;;
	_visualization_marker.id = 0;
	_visualization_marker.type = visualization_msgs::Marker::SPHERE_LIST;
	_visualization_marker.action = visualization_msgs::Marker::ADD;
	_visualization_marker.scale.x = 1.0;
	_visualization_marker.scale.y = 1.0;
	_visualization_marker.scale.z = 1.0;
	_visualization_marker.color.a = 1.0;
	_visualization_marker.color.r = 0.0;
	_visualization_marker.color.g = 0.0;
	_visualization_marker.color.b = 1.0;
	// marker.lifetime = ros::Duration(0.1);
	_visualization_marker.frame_locked = true;

	// Spin
	ros::spin ();
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/tlr_tuner/tunerBody.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/tlr_tuner/tunerBody.cpp">
				<diff>@@ -1,6 +1,15 @@
 #include &quot;tunerBody.h&quot;
 #include &quot;road_wizard/TunedResult.h&quot;
 
+
+#include &lt;opencv2/core/version.hpp&gt;
+#if (CV_MAJOR_VERSION != 3)
+#define CV cv
+#else
+#define CV cv::internal
+#endif
+
+
 static constexpr int32_t ADVERTISE_QUEUE_SIZE = 10;
 static constexpr bool    ADVERTISE_LATCH      = true;
 
@@ -396,63 +405,69 @@ void TunerBody::saveResult(std::string fileName)
 
   /* write data to file */
   {
-    cv::internal::WriteStructContext st_red(cvfs, &quot;RED&quot;, CV_NODE_MAP);
+    CV::WriteStructContext st_red(cvfs, &quot;RED&quot;, CV_NODE_MAP);
+    //cv::internal::WriteStructContext st_red(cvfs, &quot;RED&quot;, CV_NODE_MAP);
     {
-      cv::internal::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
+      CV::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
+      //cv::internal::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
       cv::write(cvfs, &quot;center&quot;, Red_set.hue.center);
       cv::write(cvfs, &quot;range&quot;, Red_set.hue.range);
     }
 
     {
-      cv::internal::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
+      CV::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
       cv::write(cvfs, &quot;center&quot;, Red_set.sat.center);
       cv::write(cvfs, &quot;range&quot;, Red_set.sat.range);
     }
 
     {
-      cv::internal::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
+      CV::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
       cv::write(cvfs, &quot;center&quot;, Red_set.val.center);
       cv::write(cvfs, &quot;range&quot;, Red_set.val.range);
     }
   }
 
   {
-    cv::internal::WriteStructContext st_yellow(cvfs, &quot;YELLOW&quot;, CV_NODE_MAP);
+    CV::WriteStructContext st_yellow(cvfs, &quot;YELLOW&quot;, CV_NODE_MAP);
+    //CV::WriteStructContext st_yellow(cvfs, &quot;YELLOW&quot;, CV_NODE_MAP);
     {
-      cv::internal::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
+      CV::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
+      //CV::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
       cv::write(cvfs, &quot;center&quot;, Yellow_set.hue.center);
       cv::write(cvfs, &quot;range&quot;, Yellow_set.hue.range);
     }
 
     {
-      cv::internal::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
+      CV::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
+      //CV::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
       cv::write(cvfs, &quot;center&quot;, Yellow_set.sat.center);
       cv::write(cvfs, &quot;range&quot;, Yellow_set.sat.range);
     }
 
     {
-      cv::internal::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
+      CV::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
+     // CV::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
       cv::write(cvfs, &quot;center&quot;, Yellow_set.val.center);
       cv::write(cvfs, &quot;range&quot;, Yellow_set.val.range);
     }
   }
 
   {
-    cv::internal::WriteStructContext st_green(cvfs, &quot;GREEN&quot;, CV_NODE_MAP);
+    CV::WriteStructContext st_green(cvfs, &quot;GREEN&quot;, CV_NODE_MAP);
     {
-      cv::internal::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
+      CV::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
       cv::write(cvfs, &quot;center&quot;, Green_set.hue.center);
       cv::write(cvfs, &quot;range&quot;, Green_set.hue.range);
     }
 
     {
-      cv::internal::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
+      CV::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
       cv::write(cvfs, &quot;center&quot;, Green_set.sat.center);
       cv::write(cvfs, &quot;range&quot;, Green_set.sat.range);
     }
 
     {
-      cv::internal::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
+      CV::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
       cv::write(cvfs, &quot;center&quot;, Green_set.val.center);
       cv::write(cvfs, &quot;range&quot;, Green_set.val.range);
     }
</diff>
				<old_file>#include &quot;tunerBody.h&quot;
#include &quot;road_wizard/TunedResult.h&quot;

static constexpr int32_t ADVERTISE_QUEUE_SIZE = 10;
static constexpr bool    ADVERTISE_LATCH      = true;

/* definition of class static private variables */
cv::Point       TunerBody::Clicked_point;
int             TunerBody::Signal_color;
cv::Mat         TunerBody::src_img;
cv::Mat         TunerBody::mask;
std::string     TunerBody::windowName;
thresholds_set  TunerBody::Red_set;
thresholds_set  TunerBody::Yellow_set;
thresholds_set  TunerBody::Green_set;
thresholds_set* TunerBody::Selected_set;
bool            TunerBody::updateImage;


/*============== Utility function ==============*/
static void onMouse(int event, int x, int y, int, void*)
{
  if (event != cv::EVENT_LBUTTONDOWN) {
    return;
  }

  TunerBody::setClickedPoint(cv::Point(x, y));

  return;
} /* void onMouse() */


/*============== Utility function ==============*/
static void colorTrack(const cv::Mat&amp; hsv_img,
                       const int hue,
                       const int sat,
                       const int val,
                       const int hw,
                       const int sw,
                       const int vw,
                       cv::Mat *dst)
{
  cv::Mat kernel = cv::Mat::ones(5, 5, CV_8U); /* kernel for dilation and erosion*/

  /* create mask image */
  cv::inRange(hsv_img, cv::Scalar(hue - hw, sat - sw, val - vw), cv::Scalar(hue + hw, sat + sw, val + vw), *dst);

  /* remove noise */
  dilate(*dst, *dst, kernel, cv::Point(-1, -1), 2);
  erode(*dst, *dst, kernel, cv::Point(-1, -1), 2);

} /* void colorTrack() */


/*============== Utility function ==============*/
static int index_max(std::vector&lt;std::vector&lt;cv::Point&gt; &gt; cnt)
{
  unsigned int max_elementNum = 0;
  int maxIdx = -1;

  for (unsigned int i=0; i&lt;cnt.size(); i++)
    {
      unsigned int elementNum = cnt[i].size();
      if (elementNum &gt; max_elementNum) {
        max_elementNum = elementNum;
        maxIdx = i;
      }
    }

  return maxIdx;

} /* int index_max() */


TunerBody::TunerBody()
{
  /* initialize private values */
  Clicked_point = cv::Point(-1, -1);
  Signal_color  = GREEN;
  H_slider_val  = 0;
  S_slider_val  = 0;
  V_slider_val  = 0;
  windowName    = &quot;Traffic Lignt Detector Tuner&quot;;

  Red_set.hue.center = 0;
  Red_set.hue.range  = 0;
  Red_set.sat.center = 0;
  Red_set.sat.range  = 0;
  Red_set.val.center = 0;
  Red_set.val.range  = 0;
  Red_set.isUpdated  = false;
  Yellow_set.hue.center = 0;
  Yellow_set.hue.range  = 0;
  Yellow_set.sat.center = 0;
  Yellow_set.sat.range  = 0;
  Yellow_set.val.center = 0;
  Yellow_set.val.range  = 0;
  Yellow_set.isUpdated  = false;
  Green_set.hue.center = 0;
  Green_set.hue.range  = 0;
  Green_set.sat.center = 0;
  Green_set.sat.range  = 0;
  Green_set.val.center = 0;
  Green_set.val.range  = 0;
  Green_set.isUpdated  = false;

  Selected_set = &amp;Green_set;

  updateImage = true;

  /* create track bars */
  cv::namedWindow(windowName);
  cv::createTrackbar(&quot;H&quot;, windowName, &amp;H_slider_val, 127, NULL, NULL);
  cv::createTrackbar(&quot;S&quot;, windowName, &amp;S_slider_val, 127, NULL, NULL);
  cv::createTrackbar(&quot;V&quot;, windowName, &amp;V_slider_val, 127, NULL, NULL);

} /* TunerBody::TunerBody() */


TunerBody::~TunerBody()
{
  cv::destroyAllWindows();
} /* TunerBody::~TunerBody() */


void TunerBody::image_raw_callBack(const sensor_msgs::Image&amp; image_msg)
{
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, sensor_msgs::image_encodings::BGR8);
  if (updateImage) {
    src_img       = cv_image-&gt;image.clone();
    updateImage   = false;
    Clicked_point = cv::Point(-1, -1); // if image is reloaded, reset clicked point to out of image
  }
} /* TunerBody::image_raw_callBack() */


void TunerBody::launch(void)
{
  ros::NodeHandle n;
  ros::NodeHandle private_nh(&quot;~&quot;);
  std::string image_topic_name;
  private_nh.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name, &quot;/image_raw&quot;);

  ros::Subscriber image_sub = n.subscribe(image_topic_name, 1, image_raw_callBack);

  ros::Publisher tunedResult_pub = n.advertise &lt;road_wizard::TunedResult&gt; (&quot;tuned_result&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);

  /* valiables to check status change */
  cv::Point prev_clicked = cv::Point(-1, -1);
  int       prev_hw      = 0;
  int       prev_sw      = 0;
  int       prev_vw      = 0;

  while (ros::ok())
    {
      ros::spinOnce();

      if (src_img.empty())
        continue;

      base = cv::Mat::zeros(src_img.rows, src_img.cols * 2, CV_8UC3);
      mask = cv::Mat::zeros(src_img.rows, src_img.cols, CV_8UC1);

      cv::Mat result = src_img.clone();

      /* get clicked coordinates on the image */
      cv::Point targetPoint = Clicked_point;


      /* get current slider position */
      int hw = H_slider_val;
      int sw = S_slider_val;
      int vw = V_slider_val;

      cv::setMouseCallback(windowName, onMouse);

      /* convert input image to HSV color image */
      cv::Mat hsv_img;
      cv::cvtColor(src_img, hsv_img, cv::COLOR_BGR2HSV);

      if (targetPoint != prev_clicked &amp;&amp;
          targetPoint != cv::Point(-1, -1))
        {
          std::cerr &lt;&lt; &quot;Selected_set updated&quot; &lt;&lt; std::endl;
          int hue = (int)hsv_img.at&lt;cv::Vec3b&gt;(targetPoint.y, targetPoint.x)[0];
          int sat = (int)hsv_img.at&lt;cv::Vec3b&gt;(targetPoint.y, targetPoint.x)[1];
          int val = (int)hsv_img.at&lt;cv::Vec3b&gt;(targetPoint.y, targetPoint.x)[2];

          /* save HSV values into correspond variables */
          Selected_set-&gt;hue.center = hue;
          Selected_set-&gt;sat.center = sat;
          Selected_set-&gt;val.center = val;
          Selected_set-&gt;isUpdated  = true;
        }

      Selected_set-&gt;hue.range  = hw;
      Selected_set-&gt;sat.range  = sw;
      Selected_set-&gt;val.range  = vw;

      if (prev_hw != hw || prev_sw != sw || prev_vw != vw) {
        Selected_set-&gt;isUpdated = true;
      }

      colorTrack(hsv_img,
                 Selected_set-&gt;hue.center,
                 Selected_set-&gt;sat.center,
                 Selected_set-&gt;val.center,
                 Selected_set-&gt;hue.range,
                 Selected_set-&gt;sat.range,
                 Selected_set-&gt;val.range,
                 &amp;mask);

      std::vector&lt; std::vector&lt;cv::Point&gt; &gt; contours;
      std::vector&lt;cv::Vec4i&gt; hierarchy;

      cv::Mat mask_clone = mask.clone();
      cv::findContours(mask_clone,
                       contours,
                       hierarchy,
                       CV_RETR_TREE,
                       CV_CHAIN_APPROX_SIMPLE);

      int maxIndex = index_max(contours);

      std::vector&lt;cv::Point&gt; hull;
      if (maxIndex != -1)
        {
          convexHull(contours[maxIndex], hull); /*draw round detected area by line*/
          drawContours(result, std::vector&lt; std::vector&lt;cv::Point&gt; &gt;(1, hull), 0, CV_RGB(220, 30, 20), 3);
        }

      /* display result */
      cv::Mat roi_result = base(cv::Rect(0, 0, result.cols, result.rows));
      result.copyTo(roi_result);

      cv::Scalar mask_color;
      switch (Signal_color) {
      case GREEN:
        mask_color = CV_RGB(0, 255, 0);
        break;
      case YELLOW:
        mask_color = CV_RGB(255, 255, 0);
        break;
      case RED:
        mask_color = CV_RGB(255, 0, 0);
        break;
      }

      cv::Mat colorBack(mask.rows, mask.cols, CV_8UC3, mask_color);
      cv::Mat mask_colored;
      colorBack.copyTo(mask_colored, mask);

      cv::Mat roi_mask = base(cv::Rect(result.cols, 0, mask_colored.cols, mask_colored.rows));
      mask_colored.copyTo(roi_mask);

      cv::imshow(windowName, base);
      cv::waitKey(10);
      // if ( (cv::waitKey(10)) == '\x1b') { /* if 'ESC' key is typed, finish the program */
      //   break;
      // }

      /* save current status */
      prev_clicked = targetPoint;
      prev_hw = hw;
      prev_sw = sw;
      prev_vw = vw;

      /* publish tuned result */
      road_wizard::TunedResult res;
      res.Red.Hue.center = Red_set.hue.center;
      res.Red.Hue.range  = Red_set.hue.range;
      res.Red.Sat.center = Red_set.sat.center;
      res.Red.Sat.range  = Red_set.sat.range;
      res.Red.Val.center = Red_set.val.center;
      res.Red.Val.range  = Red_set.val.range;

      res.Yellow.Hue.center = Yellow_set.hue.center;
      res.Yellow.Hue.range  = Yellow_set.hue.range;
      res.Yellow.Sat.center = Yellow_set.sat.center;
      res.Yellow.Sat.range  = Yellow_set.sat.range;
      res.Yellow.Val.center = Yellow_set.val.center;
      res.Yellow.Val.range  = Yellow_set.val.range;

      res.Green.Hue.center = Green_set.hue.center;
      res.Green.Hue.range  = Green_set.hue.range;
      res.Green.Sat.center = Green_set.sat.center;
      res.Green.Sat.range  = Green_set.sat.range;
      res.Green.Val.center = Green_set.val.center;
      res.Green.Val.range  = Green_set.val.range;

      tunedResult_pub.publish(res);

    }

  cv::destroyAllWindows();

} /* void TunerBody::launch() */


void TunerBody::setColor(signal_state state)
{
  switch (state) {
  case GREEN:
    Selected_set = &amp;Green_set;
    break;
  case YELLOW:
    Selected_set = &amp;Yellow_set;
    break;
  case RED:
    Selected_set = &amp;Red_set;
    break;
  }

  Signal_color = state;

  /* update trackbar position according to current status */
  cv::setTrackbarPos(&quot;H&quot;, windowName, Selected_set-&gt;hue.range);
  cv::setTrackbarPos(&quot;S&quot;, windowName, Selected_set-&gt;sat.range);
  cv::setTrackbarPos(&quot;V&quot;, windowName, Selected_set-&gt;val.range);

  /* update mask image according to current status */
  cv::Mat hsv_img;
  cv::cvtColor(src_img, hsv_img, cv::COLOR_BGR2HSV);
  colorTrack(hsv_img,
             Selected_set-&gt;hue.center,
             Selected_set-&gt;sat.center,
             Selected_set-&gt;val.center,
             Selected_set-&gt;hue.range,
             Selected_set-&gt;sat.range,
             Selected_set-&gt;val.range,
             &amp;mask);

} /* void TunerBody::setColor() */


void TunerBody::setClickedPoint(cv::Point pt)
{
  Clicked_point = pt;
} /* void TunerBody::setClickedPoint() */



void TunerBody::saveResult(std::string fileName)
{

  if (Red_set.isUpdated == false) {
    /*
      ========== Red : Default values ==========
      340               &lt; Hue &lt; 50 (circled)
      DEFAULT_SAT_LOWER &lt; Sat &lt; DEFAULT_SAT_UPPER
      DEFAULT_VAL_LOWER &lt; Val &lt; DEFAULT_VAL_UPPER
    */
    Red_set.hue.center = ( (((360 + 50) - 340 ) / 2 ) + 340) % 360;
    Red_set.hue.range  = (((360 + 50) - 340 ) / 2 );
    Red_set.sat.center = ((DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2 ) + DEFAULT_SAT_LOWER;
    Red_set.sat.range  = (DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2;
    Red_set.val.center = ((DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2 ) + DEFAULT_VAL_LOWER;
    Red_set.val.range  = (DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2;
    std::cout &lt;&lt; &quot;Red is default setting&quot; &lt;&lt; std::endl;
  }

  if (Yellow_set.isUpdated == false) {
    /*
      ========== Yellow : Default values ==========
      50                &lt; Hue &lt; 70
      DEFAULT_SAT_LOWER &lt; Sat &lt; DEFAULT_SAT_UPPER
      DEFAULT_VAL_LOWER &lt; Val &lt; DEFAULT_VAL_UPPER
     */
    Yellow_set.hue.center = ( ((70 - 50 ) / 2 ) + 50) % 360;
    Yellow_set.hue.range  = ((70 - 50 ) / 2 );
    Yellow_set.sat.center = ((DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2 ) + DEFAULT_SAT_LOWER;
    Yellow_set.sat.range  = (DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2;
    Yellow_set.val.center = ((DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2 ) + DEFAULT_VAL_LOWER;
    Yellow_set.val.range  = (DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2;
    std::cout &lt;&lt; &quot;Yellow is default setting&quot; &lt;&lt; std::endl;
  }

  if (Green_set.isUpdated == false) {
    /*
      ========== Green : Default values ==========
      80                &lt; Hue &lt; 190
      DEFAULT_SAT_LOWER &lt; Sat &lt; DEFAULT_SAT_UPPER
      DEFAULT_VAL_LOWER &lt; Val &lt; DEFAULT_VAL_UPPER
     */
    Green_set.hue.center = ( ((190 - 80 ) / 2 ) + 80) % 360;
    Green_set.hue.range  = ((190 - 80 ) / 2 );
    Green_set.sat.center = ((DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2 ) + DEFAULT_SAT_LOWER;
    Green_set.sat.range  = (DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2;
    Green_set.val.center = ((DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2 ) + DEFAULT_VAL_LOWER;
    Green_set.val.range  = (DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2;
    std::cout &lt;&lt; &quot;Green is default setting&quot; &lt;&lt; std::endl;
  }

  /* open file strage */
  cv::FileStorage cvfs(fileName, CV_STORAGE_WRITE);

  /* write data to file */
  {
    cv::internal::WriteStructContext st_red(cvfs, &quot;RED&quot;, CV_NODE_MAP);
    {
      cv::internal::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Red_set.hue.center);
      cv::write(cvfs, &quot;range&quot;, Red_set.hue.range);
    }

    {
      cv::internal::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Red_set.sat.center);
      cv::write(cvfs, &quot;range&quot;, Red_set.sat.range);
    }

    {
      cv::internal::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Red_set.val.center);
      cv::write(cvfs, &quot;range&quot;, Red_set.val.range);
    }
  }

  {
    cv::internal::WriteStructContext st_yellow(cvfs, &quot;YELLOW&quot;, CV_NODE_MAP);
    {
      cv::internal::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Yellow_set.hue.center);
      cv::write(cvfs, &quot;range&quot;, Yellow_set.hue.range);
    }

    {
      cv::internal::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Yellow_set.sat.center);
      cv::write(cvfs, &quot;range&quot;, Yellow_set.sat.range);
    }

    {
      cv::internal::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Yellow_set.val.center);
      cv::write(cvfs, &quot;range&quot;, Yellow_set.val.range);
    }
  }

  {
    cv::internal::WriteStructContext st_green(cvfs, &quot;GREEN&quot;, CV_NODE_MAP);
    {
      cv::internal::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Green_set.hue.center);
      cv::write(cvfs, &quot;range&quot;, Green_set.hue.range);
    }

    {
      cv::internal::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Green_set.sat.center);
      cv::write(cvfs, &quot;range&quot;, Green_set.sat.range);
    }

    {
      cv::internal::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Green_set.val.center);
      cv::write(cvfs, &quot;range&quot;, Green_set.val.range);
    }
  }

} /* void TunerBody::saveResult() */


void TunerBody::openSetting(std::string fileName)
{
  /* open file strage */
  cv::FileStorage cvfs(fileName, CV_STORAGE_READ);

  /* read data from file */
  cv::FileNode topNode(cvfs.fs, NULL);
  {
    cv::FileNode nd_red = topNode[std::string(&quot;RED&quot;)];
    {
      cv::FileNode nd_hue = nd_red[&quot;Hue&quot;];
      Red_set.hue.center  = nd_hue[&quot;center&quot;];
      Red_set.hue.range   = nd_hue[&quot;range&quot;];
    }

    {
      cv::FileNode nd_sat = nd_red[&quot;Saturation&quot;];
      Red_set.sat.center  = nd_sat[&quot;center&quot;];
      Red_set.sat.range   = nd_sat[&quot;range&quot;];
    }

    {
      cv::FileNode nd_val = nd_red[&quot;Value&quot;];
      Red_set.val.center  = nd_val[&quot;center&quot;];
      Red_set.val.range   = nd_val[&quot;range&quot;];
    }

    Red_set.isUpdated = true;
  }

  {
    cv::FileNode nd_yellow = topNode[std::string(&quot;YELLOW&quot;)];
    {
      cv::FileNode nd_hue   = nd_yellow[&quot;Hue&quot;];
      Yellow_set.hue.center = nd_hue[&quot;center&quot;];
      Yellow_set.hue.range  = nd_hue[&quot;range&quot;];
    }

    {
      cv::FileNode nd_sat   = nd_yellow[&quot;Saturation&quot;];
      Yellow_set.sat.center = nd_sat[&quot;center&quot;];
      Yellow_set.sat.range  = nd_sat[&quot;range&quot;];
    }

    {
      cv::FileNode nd_val   = nd_yellow[&quot;Value&quot;];
      Yellow_set.val.center = nd_val[&quot;center&quot;];
      Yellow_set.val.range  = nd_val[&quot;range&quot;];
    }

    Yellow_set.isUpdated = true;
  }

  {
    cv::FileNode nd_green = topNode[std::string(&quot;GREEN&quot;)];
    {
      cv::FileNode nd_hue  = nd_green[&quot;Hue&quot;];
      Green_set.hue.center = nd_hue[&quot;center&quot;];
      Green_set.hue.range  = nd_hue[&quot;range&quot;];
    }

    {
      cv::FileNode nd_sat  = nd_green[&quot;Saturation&quot;];
      Green_set.sat.center = nd_sat[&quot;center&quot;];
      Green_set.sat.range  = nd_sat[&quot;range&quot;];
    }

    {
      cv::FileNode nd_val  = nd_green[&quot;Value&quot;];
      Green_set.val.center = nd_val[&quot;center&quot;];
      Green_set.val.range  = nd_val[&quot;range&quot;];
    }

    Green_set.isUpdated = true;
  }

  /* set trackbar position to current status */
  cv::setTrackbarPos(&quot;H&quot;, windowName, Selected_set-&gt;hue.range);
  cv::setTrackbarPos(&quot;S&quot;, windowName, Selected_set-&gt;sat.range);
  cv::setTrackbarPos(&quot;V&quot;, windowName, Selected_set-&gt;val.range);

  /* sat mask image to current status */
  cv::Mat hsv_img;
  cv::cvtColor(src_img, hsv_img, cv::COLOR_BGR2HSV);
  colorTrack(hsv_img,
             Selected_set-&gt;hue.center,
             Selected_set-&gt;sat.center,
             Selected_set-&gt;val.center,
             Selected_set-&gt;hue.range,
             Selected_set-&gt;sat.range,
             Selected_set-&gt;val.range,
             &amp;mask);

} /* void TunerBody::openSetting() */

void TunerBody::setUpdateImage(void)
{
  updateImage = true;
} /* void TunerBody::setUpdateImage() */
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/tlr_tuner/tunerBody.h" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/tlr_tuner/tunerBody.h">
				<diff>@@ -3,7 +3,9 @@
 
 #include &lt;iostream&gt;
 #include &lt;string&gt;
+
 #include &lt;opencv2/opencv.hpp&gt;
+
 #include &lt;ros/ros.h&gt;
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/Image.h&gt;
</diff>
				<old_file>#ifndef TUNER_BODY_H
#define TUNER_BODY_H

#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;

#define DEFAULT_SAT_LOWER ((double)0.37 * 255)
#define DEFAULT_SAT_UPPER (255)
#define DEFAULT_VAL_LOWER (90)
#define DEFAULT_VAL_UPPER (255)

typedef struct {
    int center;
    int range;
} value_set;

typedef struct {
    value_set hue;
    value_set sat;
    value_set val;
    bool isUpdated;
} thresholds_set;

class TunerBody
{

private:
    static cv::Point Clicked_point;
    static int Signal_color;
    int H_slider_val;
    int S_slider_val;
    int V_slider_val;
    static cv::Mat src_img;
    cv::Mat base;
    static cv::Mat mask;
    static std::string windowName;
    static thresholds_set Red_set;
    static thresholds_set Yellow_set;
    static thresholds_set Green_set;
    static thresholds_set* Selected_set;
    static bool updateImage;

public:
    enum signal_state {
        GREEN = 0,
        YELLOW = 1,
        RED = 2,
    };

    TunerBody();
    ~TunerBody();
    void launch(void);
    static void setColor(signal_state state);
    static void setClickedPoint(cv::Point pt);
    static void saveResult(std::string fileName);
    static void openSetting(std::string fileName);
    static void setUpdateImage(void);
    static void image_raw_callBack(const sensor_msgs::Image&amp; image_msg);

};

#endif // TUNER_BODY_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_viewer/image_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_viewer/image_viewer.cpp">
				<diff>@@ -31,8 +31,14 @@
 #include &lt;string&gt;
 #include &lt;vector&gt;
 
-//#include &lt;opencv2/contrib/contrib.hpp&gt;
+#include &lt;opencv/cv.h&gt;
+#include &lt;opencv/highgui.h&gt;
+#include &lt;opencv2/core/version.hpp&gt;
+#if (CV_MAJOR_VERSION == 3)
 #include &quot;gencolors.cpp&quot;
+#else
+#include &lt;opencv2/contrib/contrib.hpp&gt;
+#endif
 
 #include &lt;ros/ros.h&gt;
 #include &lt;cv_bridge/cv_bridge.h&gt;
@@ -292,7 +298,11 @@ int main(int argc, char **argv)
 		image_topic_name = &quot;/image_raw&quot;;
 	}
 
+#if (CV_MAJOR_VERSION == 3)
 	generateColors(_colors, 25);
+#else
+	cv::generateColors(_colors, 25);
+#endif
 
 	ros::Subscriber scriber = n.subscribe(image_topic_name, 1, image_viewer_callback);
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *	list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *	this list of conditions and the following disclaimer in the documentation
 *	and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *	contributors may be used to endorse or promote products derived from
 *	this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;string&gt;
#include &lt;vector&gt;

//#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &quot;gencolors.cpp&quot;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;

#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
#include &lt;cv_tracker_msgs/image_obj.h&gt;

//DPM related
static std::vector&lt;cv::Rect&gt; cars;		//objects detected
static std::vector&lt;float&gt; cars_score;		//score of each object
//KF related
static std::vector&lt;cv::Rect&gt; cars_tracked;	//objects tracked for current frame
static std::vector&lt;int&gt; cars_tracked_lifespan;	//remaining lifespan
static std::vector&lt;int&gt; cars_tracked_id;	//objects' id
static std::vector&lt;int&gt; cars_tracked_real_data;	//states if the data contained in the index is real or prediction

//DPM related
static std::vector&lt;cv::Rect&gt; peds;
static std::vector&lt;float&gt; peds_score;
//KF related
static std::vector&lt;cv::Rect&gt; peds_tracked;
static std::vector&lt;int&gt; peds_tracked_lifespan;
static std::vector&lt;int&gt; peds_tracked_id;
static std::vector&lt;int&gt; peds_tracked_real_data;

static std::vector&lt;cv::Scalar&gt; _colors;

static const int OBJ_RECT_THICKNESS = 3;

static bool _drawing = false;
static bool car_track_ready = false;
static bool car_dpm_ready = false;
static bool ped_track_ready = false;
static bool ped_dpm_ready = false;

static bool car_image_obj_ready = false;
static bool pedestrian_image_obj_ready = false;

static const std::string window_name = &quot;Image Viewer&quot;;

/*static void dashed_rectangle(cv::Mat&amp; img, const cv::Rect&amp; r, const cv::Scalar&amp; color,
			     int thickness = 2, int dash_length = 10)
{
	//draw horizontal dashed lines
	for (int i = 0; i &lt; r.width; i+=dash_length) {
		cv::line(img, cv::Point(r.x+i, r.y),  cv::Point(r.x+i+(dash_length/2), r.y), color, thickness);
		cv::line(img, cv::Point(r.x+i, r.y + r.height), cv::Point(r.x+i+(dash_length/2), r.y + r.height), color, thickness);
	}

	//draw vertical dashes lines
	for (int i = 0; i &lt; r.height; i+=dash_length) {
		cv::line(img, cv::Point(r.x, r.y+i), cv::Point(r.x, r.y+i+(dash_length/2)), color, thickness);
		cv::line(img, cv::Point(r.x +r.width, r.y+i), cv::Point(r.x+ r.width, r.y+i+(dash_length/2)), color, thickness);
	}
}*/

static void drawDetections(std::vector&lt;cv::Rect&gt; dets, std::vector&lt;float&gt; scores, std::string objectLabel, IplImage frame)
{
	/* variables for object label */
	CvFont font;
	const float hscale = 0.5f;
	const float vscale = 0.5f;
	const float italicScale = 0.0f;
	const int thickness = 1;
	CvSize text_size;
	int baseline = 0;

	cvInitFont(&amp;font, CV_FONT_HERSHEY_COMPLEX, hscale, vscale, italicScale, thickness, CV_AA);

	//UNTRACKED
	for(std::size_t i = 0; i &lt; dets.size(); ++i) {
#ifdef TEMP_DISABLED
		//temporal way to avoid drawing detections in the sky
		if (dets[i].y &lt;= frame.height * 0.3)
			continue;
#endif
		std::ostringstream label;
		label &lt;&lt; objectLabel &lt;&lt; &quot;:&quot; &lt;&lt; std::setprecision(2) &lt;&lt; scores[i];
		std::string text = label.str();

		//get text size
		cvGetTextSize(text.data(),
			&amp;font,
			&amp;text_size,
			&amp;baseline);

		//cvRectangle( &amp;frame,
			//cvPoint(dets[i].x, dets[i].y),
			//cvPoint(dets[i].x+dets[i].width, dets[i].y+dets[i].height),
			//CV_RGB(0, 0, 255), OBJ_RECT_THICKNESS, CV_AA, 0);
		cvCircle(&amp;frame, cvPoint(dets[i].x+dets[i].width/2, dets[i].y+dets[i].height/2), 30, cvScalar(0,255,0),3);		/* draw object label */
		CvPoint textOrg = cvPoint(dets[i].x - OBJ_RECT_THICKNESS, dets[i].y - baseline - OBJ_RECT_THICKNESS);

		cvRectangle(&amp;frame,
			cvPoint(textOrg.x + 0 , textOrg.y + baseline),
			cvPoint(textOrg.x + text_size.width, textOrg.y - text_size.height),
			CV_RGB(0, 0, 0), // text background is black
			-1, 8, 0);
		cvPutText(&amp;frame,
			text.data(),
			textOrg,
			&amp;font,
			CV_RGB(255, 255, 255) // text color is white
			);
	}
}

static void drawTracked(std::vector&lt;cv::Rect&gt; dets, std::vector&lt;int&gt; lifespan, std::vector&lt;int&gt; obj_id,
			std::vector&lt;int&gt; real_data, std::string objectLabel, cv::Mat imageTrack)
{
	for(std::size_t i=0; i&lt;dets.size();i++) {
#ifdef TEMP_DISABLED
		//temporal way to avoid drawing detections in the sky
		if (dets[i].y &lt;= imageTrack.rows * 0.3)
			continue;
#endif

		std::ostringstream label;
		label &lt;&lt; objectLabel &lt;&lt; &quot;_&quot; &lt;&lt; obj_id[i] &lt;&lt; &quot;:&quot; &lt;&lt; std::setprecision(2) &lt;&lt; lifespan[i];
		std::string text = label.str();

		//if (real_data[i])
			//rectangle(imageTrack, dets[i], _colors[obj_id[i]], 3);
	//	else
			//dashed_rectangle(imageTrack, dets[i], _colors[obj_id[i]], 3, 10);

		putText(imageTrack, text.c_str(), cv::Point(dets[i].x + 4, dets[i].y + 15),
			cv::FONT_HERSHEY_SIMPLEX, 0.55, _colors[obj_id[i]], 2);
		cv::circle(imageTrack, cv::Point(dets[i].x+dets[i].width/2, dets[i].y+dets[i].height/2), 30, _colors[obj_id[i]],3);
	}
}

static void image_viewer_callback(const sensor_msgs::Image&amp; image_source)
{
	_drawing = true;

	const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source,
							     encoding);
	IplImage frame = cv_image-&gt;image;

	cv::Mat matImage(cv_image-&gt;image);
	cv::Mat imageTrack = matImage.clone();

	//UNTRACKED
	putText(matImage, &quot;PIXEL_XY&quot;, cv::Point(10,10), cv::FONT_HERSHEY_SIMPLEX, 0.55, cv::Scalar(0, 0, 255), 2);
	if (car_dpm_ready)
		drawDetections(cars, cars_score, &quot;car&quot;, frame);
	if (ped_dpm_ready)
		drawDetections(peds, peds_score, &quot;pedestrian&quot;, frame);

	if (car_image_obj_ready)
		drawDetections(cars, cars_score, &quot;car&quot;, frame);
	if (pedestrian_image_obj_ready)
		drawDetections(peds, peds_score, &quot;pedestrian&quot;, frame);

	//TRACKED
	putText(imageTrack, &quot;PIXEL_XY_TRACKED&quot;, cv::Point(10,10), cv::FONT_HERSHEY_SIMPLEX, 0.55, cv::Scalar(0, 255, 0), 2);
	if(car_track_ready)
		drawTracked(cars_tracked, cars_tracked_lifespan, cars_tracked_id, cars_tracked_real_data, &quot;car&quot;, imageTrack);
	if(ped_track_ready)
		drawTracked(peds_tracked, peds_tracked_lifespan, peds_tracked_id, peds_tracked_real_data, &quot;pedestrian&quot;, imageTrack);

	cv::Mat merged;
	hconcat(matImage, imageTrack, merged);

	if (cvGetWindowHandle(window_name.c_str()) != NULL) // Guard not to write destroyed window by using close button on the window
		{
			imshow(window_name, merged);
			cvWaitKey(2);
		}

	_drawing = false;
}

static void image_obj_update_cb(const cv_tracker_msgs::image_obj&amp; image_objs)
{
	if(_drawing)
		return;

	bool is_car = (image_objs.type == &quot;car&quot;);
	std::vector&lt;cv::Rect&gt;&amp; objs = is_car ? cars : peds;
	std::vector&lt;float&gt;&amp; scores = is_car ? cars_score : peds_score;
	
	objs.clear();
	scores.clear();

	for (const auto&amp; obj : image_objs.obj) {
		cv::Rect tmp;
		tmp.x = obj.x;
		tmp.y = obj.y;
		tmp.width = obj.width;
		tmp.height = obj.height;

		objs.push_back(tmp);
		scores.push_back(obj.score);
	}

	if (is_car) {
		car_image_obj_ready = true;
	} else {
		pedestrian_image_obj_ready = true;
	}
}

static void image_obj_updater_cb_tracked(const cv_tracker_msgs::image_obj_tracked&amp; image_objs_tracked_msg)
{
	if(_drawing)
		return;
	bool is_car = (image_objs_tracked_msg.type == &quot;car&quot;);
	std::vector&lt;cv::Rect&gt;&amp; objs_tracked = is_car ? cars_tracked : peds_tracked;
	std::vector&lt;int&gt;&amp; objs_tracked_lifespan = is_car ? cars_tracked_lifespan : peds_tracked_lifespan;
	std::vector&lt;int&gt;&amp; objs_tracked_id = is_car ? cars_tracked_id : peds_tracked_id;
	std::vector&lt;int&gt;&amp; objs_tracked_real_data = is_car ? cars_tracked_real_data : peds_tracked_real_data;

	objs_tracked_lifespan = image_objs_tracked_msg.lifespan;
	objs_tracked_id = image_objs_tracked_msg.obj_id;
	objs_tracked_real_data = image_objs_tracked_msg.real_data;

	objs_tracked.clear();
	for (const auto&amp; rect_ranged : image_objs_tracked_msg.rect_ranged)
		{
			cv::Rect tmp;
			tmp.x = rect_ranged.rect.x;
			tmp.y = rect_ranged.rect.y;
			tmp.width = rect_ranged.rect.width;
			tmp.height = rect_ranged.rect.height;

			objs_tracked.push_back(tmp);
		}

	if(is_car) {
		car_track_ready = true;
	} else {
		ped_track_ready = true;
	}
}

int main(int argc, char **argv)
{

	/* create resizable window */
	cv::namedWindow(window_name, cv::WINDOW_NORMAL);
	cv::startWindowThread();

	ros::init(argc, argv, &quot;image_viewer&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	std::string image_topic_name;

	if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
		ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
	} else {
		ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
		image_topic_name = &quot;/image_raw&quot;;
	}

	generateColors(_colors, 25);

	ros::Subscriber scriber = n.subscribe(image_topic_name, 1, image_viewer_callback);

	ros::Subscriber scriber_car = n.subscribe(&quot;/obj_car/image_obj&quot;, 1,
						image_obj_update_cb);
	ros::Subscriber scriber_ped = n.subscribe(&quot;/obj_person/image_obj&quot;, 1,
						image_obj_update_cb);

	ros::Subscriber scriber_ped_tracked = n.subscribe(&quot;/obj_person/image_obj_tracked&quot;, 1,
						image_obj_updater_cb_tracked);
	ros::Subscriber scriber_car_tracked = n.subscribe(&quot;/obj_car/image_obj_tracked&quot;, 1,
						image_obj_updater_cb_tracked);

	ros::spin();

	/* destroy window */
	cv::destroyWindow(window_name);

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/points_image_d_viewer/points_image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/points_image_d_viewer/points_image_d_viewer.cpp">
				<diff>@@ -31,8 +31,13 @@
 #include &lt;opencv/cv.h&gt;
 #include &lt;opencv/highgui.h&gt;
 #include &lt;opencv2/opencv.hpp&gt;
-//#include &lt;opencv2/contrib/contrib.hpp&gt;
+
+#include &lt;opencv2/core/version.hpp&gt;
+#if (CV_MAJOR_VERSION == 3)
 #include &quot;gencolors.cpp&quot;
+#else
+#include &lt;opencv2/contrib/contrib.hpp&gt;
+#endif
 
 #include &lt;ros/ros.h&gt;
 #include &lt;cv_bridge/cv_bridge.h&gt;
@@ -367,7 +372,11 @@ int main(int argc, char **argv)
     points_node = &quot;/points_image&quot;;
   }
 
-  generateColors(_colors, 25);
+#if (CV_MAJOR_VERSION == 3)
+	generateColors(_colors, 25);
+#else
+	cv::generateColors(_colors, 25);
+#endif
 
   ros::Subscriber scriber = n.subscribe(image_topic_name, 1,
                                         image_cb);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/opencv.hpp&gt;
//#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &quot;gencolors.cpp&quot;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;points2image/PointsImage.h&gt;

#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
#include &lt;float.h&gt;

#define NO_DATA 0
static char window_name[] = &quot;points_image_d_viewer&quot;;

static bool existImage = false;
static bool existPoints = false;
static sensor_msgs::Image image_msg;
static points2image::PointsImageConstPtr points_msg;
static cv::Mat colormap;

#if 0
static std::vector&lt;cv::Rect&gt; cars;
static std::vector&lt;cv::Rect&gt; peds;
#else
static cv_tracker_msgs::image_obj_ranged car_fused_objects;
static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
#endif

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
  float abs_x  = (float)fabs(x);
  const int rangeScale = 100;
  return(abs_x &lt; FLT_MIN*rangeScale);
}

static std::vector&lt;cv::Scalar&gt; _colors;

#define	IMAGE_WIDTH	800
#define	IMAGE_HEIGHT	600

static const int OBJ_RECT_THICKNESS = 3;

static void drawRects(IplImage *Image,
                      std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                      CvScalar color,
                      int threshold_height)
{
  unsigned int object_num = objects.size();
  for(unsigned int i = 0; i &lt; object_num; i++) {
    if (objects.at(i).rect.y &gt; threshold_height &amp;&amp; !isNearlyNODATA(objects.at(i).range)) {  // temporal way to avoid drawing detections in the sky
      CvPoint p1=cvPoint(objects.at(i).rect.x, objects.at(i).rect.y);
      CvPoint p2=cvPoint(objects.at(i).rect.x + objects.at(i).rect.width, objects.at(i).rect.y + objects.at(i).rect.height);
      cvRectangle(Image,p1,p2,color,OBJ_RECT_THICKNESS);
    }
  }
}

static void putDistance(IplImage *Image,
                        std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                        int threshold_height,
                        const char* objectLabel)
{
  char distance_string[32];
  CvFont dfont;
  float hscale	    = 0.7f;
  float vscale	    = 0.7f;
  float italicscale = 0.0f;
  int	thickness   = 1;

  CvFont      dfont_label;
  float       hscale_label = 0.5f;
  float       vscale_label = 0.5f;
  CvSize      text_size;
  int         baseline     = 0;

  cvInitFont(&amp;dfont_label, CV_FONT_HERSHEY_COMPLEX, hscale_label, vscale_label, italicscale, thickness, CV_AA);
  cvGetTextSize(objectLabel,
                &amp;dfont_label,
                &amp;text_size,
                &amp;baseline);

  for (unsigned int i=0; i&lt;objects.size(); i++)
    {
      if (objects.at(i).rect.y &gt; threshold_height) // temporal way to avoid drawing detections in the sky
        {
          if (!isNearlyNODATA(objects.at(i).range))
            {

              /*put label */
              CvPoint labelOrg = cvPoint(objects.at(i).rect.x - OBJ_RECT_THICKNESS,
                                         objects.at(i).rect.y - baseline - OBJ_RECT_THICKNESS);

              cvRectangle(Image,
                          cvPoint(labelOrg.x + 0, labelOrg.y + baseline),
                          cvPoint(labelOrg.x + text_size.width, labelOrg.y - text_size.height),
                          CV_RGB(0, 0, 0), // label background is black
                          -1, 8, 0
                          );
              cvPutText(Image,
                        objectLabel,
                        labelOrg,
                        &amp;dfont_label,
                        CV_RGB(255, 255, 255) // label text color is white
                        );

              /* put distance data */
              cvRectangle(Image,
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 45),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 5),
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) + (((int)log10(objects.at(i).range/100)+1) * 8 + 38),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 30),
                          cv::Scalar(255,255,255),
                          -1);

              cvInitFont (&amp;dfont,
                          CV_FONT_HERSHEY_COMPLEX,
                          hscale,
                          vscale,
                          italicscale,
                          thickness,
                          CV_AA);

              sprintf(distance_string, &quot;%.2f m&quot;, objects.at(i).range / 100); //unit of length is meter
              cvPutText(Image,
                        distance_string,
                        cvPoint(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 40),
                                objects.at(i).rect.y + objects.at(i).rect.height + 25),
                        &amp;dfont,
                        CV_RGB(255, 0, 0));
            }

        }
    }
}

void show(void)
{
  if(!existImage || !existPoints){
    return;
  }
  const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, encoding);
  IplImage frame = cv_image-&gt;image;

  cv::Mat matImage = cv::cvarrToMat(&amp;frame);//(&amp;frame, false);

  /* DRAW RECTANGLES of detected objects */
#if 0
  for(std::size_t i=0; i&lt;cars.size();i++) {
      if(cars[i].y &gt; matImage.rows*.3) { //temporal way to avoid drawing detections in the sky
          cvRectangle( &amp;frame,
                       cvPoint(cars[i].x, cars[i].y),
                       cvPoint(cars[i].x+cars[i].width, cars[i].y+cars[i].height),
                       _colors[0], 3, 8,0 );
    }
  }
  for(std::size_t i=0; i&lt;peds.size();i++) {
    if(peds[i].y &gt; matImage.rows*.3) {
      cvRectangle( &amp;frame,
                   cvPoint(peds[i].x, peds[i].y),
                   cvPoint(peds[i].x+peds[i].width, peds[i].y+peds[i].height),
                   _colors[1], 3, 8,0 );
    }
  }
#else
  drawRects(&amp;frame,
            car_fused_objects.obj,
            cvScalar(255.0, 255.0, 0,0),
            matImage.rows*.10);

  drawRects(&amp;frame,
            pedestrian_fused_objects.obj,
            cvScalar(0.0, 255.0, 0,0),
            matImage.rows*.10);
#endif
  /* PUT DISTANCE text on image */
  putDistance(&amp;frame,
              car_fused_objects.obj,
              matImage.rows*.10,
              car_fused_objects.type.c_str());
  putDistance(&amp;frame,
              pedestrian_fused_objects.obj,
              matImage.rows*.10,
              pedestrian_fused_objects.type.c_str());

  /* DRAW POINTS of lidar scanning */
  int w = matImage.size().width;
  int h = matImage.size().height;

  int n = w * h;
  float min_d = 1&lt;&lt;16, max_d = -1;
  //	int min_i = 1&lt;&lt;8, max_i = -1;
  for(int i=0; i&lt;n; i++){
    int di = points_msg-&gt;distance[i];
    max_d = di &gt; max_d ? di : max_d;
    min_d = di &lt; min_d ? di : min_d;
    // int it = points_msg-&gt;intensity[i];
    // max_i = it &gt; max_i ? it : max_i;
    // min_i = it &lt; min_i ? it : min_i;
  }
  float wid_d = max_d - min_d;

  for(int y=0; y&lt;h; y++){
    for(int x=0; x&lt;w; x++){
      int j = y * w + x;
      double distance = points_msg-&gt;distance[j];
      if(distance == 0){
        continue;
      }
      int colorid= wid_d ? ( (distance - min_d) * 255 / wid_d ) : 128;
      cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
      int g = color[1];
      int b = color[2];
      int r = color[0];
      cvRectangle(&amp;frame, cvPoint(x, y), cvPoint(x+1, y+1), CV_RGB(r, g, b));
    }
  }

  if (cvGetWindowHandle(window_name) != NULL) // Guard not to write destroyed window by using close button on the window
    {
      cvShowImage(window_name, &amp;frame);
      cvWaitKey(2);
    }
}

#if 0
static void car_updater_callback(dpm::ImageObjects image_objects_msg)
{
  int num = image_objects_msg.car_num;
  std::vector&lt;int&gt; points = image_objects_msg.corner_point;
  //points are X,Y,W,H and repeat for each instance
  cars.clear();

  for (int i=0; i&lt;num;i++) {
    cv::Rect tmp;
    tmp.x = points[i*4 + 0];
    tmp.y = points[i*4 + 1];
    tmp.width = points[i*4 + 2];
    tmp.height = points[i*4 + 3];
    cars.push_back(tmp);
  }
}
#else
static void car_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
{
  car_fused_objects = fused_car_msg;
  //  show();
}
#endif

#if 0
static void ped_updater_callback(dpm::ImageObjects image_objects_msg)
{
  int num = image_objects_msg.car_num;
  std::vector&lt;int&gt; points = image_objects_msg.corner_point;
  //points are X,Y,W,H and repeat for each instance
  peds.clear();

  for (int i=0; i&lt;num;i++) {
    cv::Rect tmp;
    tmp.x = points[i*4 + 0];
    tmp.y = points[i*4 + 1];
    tmp.width = points[i*4 + 2];
    tmp.height = points[i*4 + 3];
    peds.push_back(tmp);
  }
}
#else
static void ped_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
{
  pedestrian_fused_objects = fused_pds_msg;
  //  show();
}
#endif

static void image_cb(const sensor_msgs::Image&amp; msg)
{
  image_msg = msg;
  existImage = true;
  show();
}

static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
{
  points_msg = msg;
  existPoints = true;
  show();
}

int main(int argc, char **argv)
{
  /* create resizable window */
  cvNamedWindow(window_name, CV_WINDOW_NORMAL);
  cvStartWindowThread();

  ros::init(argc, argv, &quot;points_image_d_viewer&quot;);
  ros::NodeHandle n;
  ros::NodeHandle private_nh(&quot;~&quot;);

  std::string image_topic_name;
  std::string car_node;
  std::string pedestrian_node;
  std::string points_node;

  if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
    ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
  } else {
    ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
    image_topic_name = &quot;/image_raw&quot;;
  }

  if (private_nh.getParam(&quot;car_node&quot;, car_node)) {
    ROS_INFO(&quot;Setting car positions node to %s&quot;, car_node.c_str());
  } else {
    ROS_INFO(&quot;No car positions node received, defaulting to car_pixel_xyz, you can use _car_node:=YOUR_TOPIC&quot;);
    car_node = &quot;/obj_car/image_obj_ranged&quot;;
  }

  if (private_nh.getParam(&quot;pedestrian_node&quot;, pedestrian_node)) {
    ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, pedestrian_node.c_str());
  } else {
    ROS_INFO(&quot;No pedestrian positions node received, defaulting to pedestrian_pixel_xyz, you can use _pedestrian_node:=YOUR_TOPIC&quot;);
    pedestrian_node = &quot;/obj_person/image_obj_ranged&quot;;
  }

  if (private_nh.getParam(&quot;points_node&quot;, points_node)) {
    ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, points_node.c_str());
  } else {
    ROS_INFO(&quot;No points node received, defaulting to points_image, you can use _points_node:=YOUR_TOPIC&quot;);
    points_node = &quot;/points_image&quot;;
  }

  generateColors(_colors, 25);

  ros::Subscriber scriber = n.subscribe(image_topic_name, 1,
                                        image_cb);
  ros::Subscriber scriber_car = n.subscribe(car_node, 1,
                                            car_updater_callback);
  ros::Subscriber scriber_ped = n.subscribe(pedestrian_node, 1,
                                            ped_updater_callback);
  ros::Subscriber scriber_points = n.subscribe(points_node, 1,
                                               points_cb);

  cv::Mat grayscale(256,1,CV_8UC1);
  for(int i=0;i&lt;256;i++) {
    grayscale.at&lt;uchar&gt;(i)=i;
  }
  cv::applyColorMap(grayscale,colormap,cv::COLORMAP_JET);

  ros::spin();

  cvDestroyWindow(window_name);

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/vscan_image_d_viewer/vscan_image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/vscan_image_d_viewer/vscan_image_d_viewer.cpp">
				<diff>@@ -256,8 +256,11 @@ int main(int argc, char **argv)
 		ROS_INFO(&quot;No points node received, defaulting to points_image, you can use _points_node:=YOUR_TOPIC&quot;);
 		points_node = &quot;/vscan_image&quot;;
 	}
-
+#if (CV_MAJOR_VERSION == 3)
 	generateColors(_colors, 25);
+#else
+	cv::generateColors(_colors, 25);
+#endif
 
 	ros::Subscriber scriber = n.subscribe(image_topic_name, 1,
 					    image_cb);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv2/opencv.hpp&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;points2image/PointsImage.h&gt;

#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
#include &lt;float.h&gt;

#include &lt;opencv2/core/core.hpp&gt;

#include &quot;gencolors.cpp&quot;

#define NO_DATA 0
static char window_name[] = &quot;vscan_image_d_viewer&quot;;

static bool existImage = false;
static bool existPoints = false;
static sensor_msgs::Image image_msg;
static points2image::PointsImageConstPtr points_msg;
static cv::Mat colormap;

#if 0
static std::vector&lt;cv::Rect&gt; cars;
static std::vector&lt;cv::Rect&gt; peds;
#else
static cv_tracker_msgs::image_obj_ranged car_fused_objects;
static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
#endif

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
	float abs_x  = (float)fabs(x);
	const int rangeScale = 100;
	return(abs_x &lt; FLT_MIN*rangeScale);
}

static std::vector&lt;cv::Scalar&gt; _colors;

#define	IMAGE_WIDTH		800
#define	IMAGE_HEIGHT 	600

#define POINTS_THRESHOLD 0.1

static const int OBJ_RECT_THICKNESS = 3;

static void drawRects(cv::Mat image,
                    std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
					CvScalar color,
					int threshold_height,
					std::string objectClass)
{
	int object_num = objects.size();
	char distance_string[32];
	int fontFace = cv::FONT_HERSHEY_SIMPLEX; double fontScale = 0.55; int fontThick = 2;
	std::vector&lt;int&gt; pointsInBoundingBox;
	for(int i = 0; i &lt; object_num; i++)
	{
		//corner_point[0]=&gt;X1		corner_point[1]=&gt;Y1
		//corner_point[2]=&gt;width	corner_point[3]=&gt;height
		cv::Rect detection = cv::Rect(objects.at(i).rect.x, objects.at(i).rect.y, objects.at(i).rect.width, objects.at(i).rect.height);

		rectangle(image, detection, color, OBJ_RECT_THICKNESS);//draw bounding box
		putText(image, objectClass, cv::Point(detection.x + 4, detection.y + 10), fontFace, fontScale, color, fontThick);//draw label text

		sprintf(distance_string, &quot;D:%.2f m H:%.1f,%.1f&quot;, objects.at(i).range / 100, objects.at(i).min_height, objects.at(i).max_height);
		//Size textSize = getTextSize(string(distance_string), fontFace, fontScale, fontThick, 0);
		//rectangle(image, cv::Rect( detection.x, detection.y, textSize.width + 4, textSize.height + 10), Scalar::all(0), CV_FILLED);//draw fill distance rectangle
		putText(image, std::string(distance_string), cv::Point(detection.x + 4, detection.y - 10), fontFace, fontScale, color, fontThick);//draw distance text
	}
}

static void drawVScanPoints(cv::Mat image)
{
	/* DRAW POINTS of lidar scanning */
    int w = image.size().width;
	int h = image.size().height;

	int i, n = w * h;
	float min_d = 1&lt;&lt;16, max_d = -1;
	//	int min_i = 1&lt;&lt;8, max_i = -1;
	for(i=0; i&lt;n; i++){
		int di = points_msg-&gt;distance[i];
		max_d = di &gt; max_d ? di : max_d;
		min_d = di &lt; min_d ? di : min_d;
		// int it = points_msg-&gt;intensity[i];
		// max_i = it &gt; max_i ? it : max_i;
		// min_i = it &lt; min_i ? it : min_i;
	}
	float wid_d = max_d - min_d;

	int x, y;
	for(y=0; y&lt;h; y++){
		for(x=0; x&lt;w; x++){
			int i = y * w + x;
			double distance = points_msg-&gt;distance[i];

			if(distance == 0){
				continue;
			}
			int colorid= wid_d ? ( (distance - min_d) * 255 / wid_d ) : 128;
			cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
			int g = color[1];
			int b = color[2];
			int r = color[0];
			rectangle(image, cv::Rect(x, y,1, 1), cv::Scalar(r, g, b), OBJ_RECT_THICKNESS);
		}
	}
}

static void show(void)
{
	if(!existImage || !existPoints){
		return;
	}
	const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, encoding);
	IplImage frame = cv_image-&gt;image;

	cv::Mat matImage=cv::cvarrToMat(&amp;frame);//(&amp;frame, false);

	//Draw VScan Points
	drawVScanPoints(matImage);

	/* DRAW RECTANGLES of detected objects */
	drawRects(matImage,
		  car_fused_objects.obj,
		  cv::Scalar(255.0, 255.0, 0,0),
		  matImage.rows*.25,
		  car_fused_objects.type);

	drawRects(matImage,
		  pedestrian_fused_objects.obj,
		  cv::Scalar(0.0, 255.0, 0,0),
		  matImage.rows*.25,
		  pedestrian_fused_objects.type);

	if (cvGetWindowHandle(window_name) != NULL) // Guard not to write destroyed window by using close button on the window
	{
		cvShowImage(window_name, &amp;frame);
		cvWaitKey(2);
	}
}
static void car_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
{
	car_fused_objects = fused_car_msg;
	//  show();
}

static void ped_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
{
  pedestrian_fused_objects = fused_pds_msg;
  //  show();
}

static void image_cb(const sensor_msgs::Image&amp; msg)
{
	image_msg = msg;
	existImage = true;
	show();
}

static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
{
	points_msg = msg;
	existPoints = true;
	show();
}

int main(int argc, char **argv)
{
	/* create resizable window */
	cvNamedWindow(window_name, CV_WINDOW_NORMAL);
	cvStartWindowThread();

	ros::init(argc, argv, &quot;vscan_image_d_viewer&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	std::string image_topic_name;
	std::string car_node;
	std::string pedestrian_node;
	std::string points_node;

	if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name))
	{
		ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
	}
	else
	{
		ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
		image_topic_name = &quot;/image_raw&quot;;
	}

	if (private_nh.getParam(&quot;car_node&quot;, car_node))
	{
		ROS_INFO(&quot;Setting car positions node to %s&quot;, car_node.c_str());
	}
	else
	{
		ROS_INFO(&quot;No car positions node received, defaulting to car_pixel_xyz, you can use _car_node:=YOUR_TOPIC&quot;);
		car_node = &quot;/obj_car/image_obj_ranged&quot;;
	}

	if (private_nh.getParam(&quot;pedestrian_node&quot;, pedestrian_node))
	{
		ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, pedestrian_node.c_str());
	}
	else
	{
		ROS_INFO(&quot;No pedestrian positions node received, defaulting to pedestrian_pixel_xyz, you can use _pedestrian_node:=YOUR_TOPIC&quot;);
		pedestrian_node = &quot;/obj_person/image_obj_ranged&quot;;
	}

	if (private_nh.getParam(&quot;points_node&quot;, points_node))
	{
		ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, points_node.c_str());
	}
	else
	{
		ROS_INFO(&quot;No points node received, defaulting to points_image, you can use _points_node:=YOUR_TOPIC&quot;);
		points_node = &quot;/vscan_image&quot;;
	}

	generateColors(_colors, 25);

	ros::Subscriber scriber = n.subscribe(image_topic_name, 1,
					    image_cb);
	ros::Subscriber scriber_car = n.subscribe(car_node, 1,
						car_updater_callback);
	ros::Subscriber scriber_ped = n.subscribe(pedestrian_node, 1,
						ped_updater_callback);
	ros::Subscriber scriber_points = n.subscribe(points_node, 1,
						points_cb);

	cv::Mat grayscale(256,1,CV_8UC1);
	for(int i=0;i&lt;256;i++)
	{
		grayscale.at&lt;uchar&gt;(i)=i;
	}
	cv::applyColorMap(grayscale,colormap,cv::COLORMAP_JET);

	ros::spin();

	cvDestroyWindow(window_name);

	return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="35c05d52525612f62c10c3e363d08e5824bb345b" fix_time="181,31938">
		<msg>fixed compile issue for ssd node</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/ssd/ssd_node.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/ssd/ssd_node.cpp">
				<diff>@@ -33,7 +33,7 @@
 #include &lt;runtime_manager/ConfigSsd.h&gt;
 #include &lt;sensor_msgs/Image.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;cv_tracker/image_obj.h&gt;
+#include &lt;cv_tracker_msgs/image_obj.h&gt;
 
 #include &lt;rect_class_score.h&gt;
 
@@ -67,7 +67,7 @@ class RosSsdApp
 	//vector of indices of the classes to search for
 	std::vector&lt;unsigned int&gt; detect_classes_;
 
-	void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, cv_tracker::image_obj&amp; out_message, cv::Mat&amp; in_image, std::string in_class)
+	void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, cv_tracker_msgs::image_obj&amp; out_message, cv::Mat&amp; in_image, std::string in_class)
 	{
 		for (unsigned int i = 0; i &lt; in_objects.size(); ++i)
 		{
@@ -79,7 +79,7 @@ class RosSsdApp
 				)//check if the score is larger than minimum required
 			{
 				//std::cout &lt;&lt; in_objects[i].toString() &lt;&lt; std::endl;
-				cv_tracker::image_rect rect;
+				cv_tracker_msgs::image_rect rect;
 
 				rect.x = in_objects[i].x;
 				rect.y = in_objects[i].y;
@@ -118,8 +118,8 @@ class RosSsdApp
 		//std::cout &lt;&lt; &quot;Detection took: &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; std::endl;
 
 		//Prepare Output message
-		cv_tracker::image_obj output_car_message;
-		cv_tracker::image_obj output_person_message;
+		cv_tracker_msgs::image_obj output_car_message;
+		cv_tracker_msgs::image_obj output_person_message;
 		output_car_message.header = image_source.header;
 		output_car_message.type = &quot;car&quot;;
 
@@ -207,8 +207,8 @@ public:
 		}
 		ROS_INFO(&quot;SSD Detector initialized.&quot;);
 
-		publisher_car_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
-		publisher_person_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);
+		publisher_car_objects_ = node_handle_.advertise&lt;cv_tracker_msgs::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
+		publisher_person_objects_ = node_handle_.advertise&lt;cv_tracker_msgs::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);
 
 		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str());
 		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str, 1, &amp;RosSsdApp::image_callback, this);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
#include &lt;string&gt;
#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;runtime_manager/ConfigSsd.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_tracker/image_obj.h&gt;

#include &lt;rect_class_score.h&gt;

#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;

#include &quot;ssd_detector.h&quot;

class RosSsdApp
{
	ros::Subscriber subscriber_image_raw_;
	ros::Subscriber subscriber_ssd_config_;
	ros::Publisher publisher_car_objects_;
	ros::Publisher publisher_person_objects_;
	ros::NodeHandle node_handle_;

	cv::Scalar pixel_mean_;

	//Caffe based Object Detection ConvNet
	SsdDetector* ssd_detector_;

	//The minimum score required to filter the detected objects by the ConvNet
	float score_threshold_;

	//If GPU is enabled, stores the GPU Device to use
	unsigned int gpu_device_id_;

	//Sets whether or not use GPU acceleration
	bool use_gpu_;

	//vector of indices of the classes to search for
	std::vector&lt;unsigned int&gt; detect_classes_;

	void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, cv_tracker::image_obj&amp; out_message, cv::Mat&amp; in_image, std::string in_class)
	{
		for (unsigned int i = 0; i &lt; in_objects.size(); ++i)
		{
			if ( (in_objects[i].score &gt; score_threshold_)
				&amp;&amp; (	(in_class == &quot;car&quot; &amp;&amp; (in_objects[i].class_type == Ssd::CAR || in_objects[i].class_type == Ssd::BUS))
						|| (in_class == &quot;person&quot; &amp;&amp; (in_objects[i].class_type == Ssd::PERSON || in_objects[i].class_type == Ssd::BICYCLE))
					)

				)//check if the score is larger than minimum required
			{
				//std::cout &lt;&lt; in_objects[i].toString() &lt;&lt; std::endl;
				cv_tracker::image_rect rect;

				rect.x = in_objects[i].x;
				rect.y = in_objects[i].y;
				rect.width = in_objects[i].w;
				rect.height = in_objects[i].h;
				if (in_objects[i].x &lt; 0)
					rect.x = 0;
				if (in_objects[i].y &lt; 0)
					rect.y = 0;
				if (in_objects[i].w &lt; 0)
					rect.width = 0;
				if (in_objects[i].h &lt; 0)
					rect.height = 0;

				rect.score = in_objects[i].score;

				out_message.obj.push_back(rect);

			}
		}
	}

	void image_callback(const sensor_msgs::Image&amp; image_source)
	{
		//Receive Image, convert it to OpenCV Mat
		cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, &quot;bgr8&quot;);//toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
		cv::Mat image = cv_image-&gt;image;

		//Detect Object in image
		std::vector&lt; RectClassScore&lt;float&gt; &gt; detections;
		//cv::TickMeter timer; timer.start();
		//std::cout &lt;&lt; &quot;score:&quot; &lt;&lt; score_threshold_ &lt;&lt; &quot; slices:&quot; &lt;&lt; image_slices_ &lt;&lt; &quot; slices overlap:&quot; &lt;&lt; slices_overlap_ &lt;&lt; &quot;nms&quot; &lt;&lt; group_threshold_ &lt;&lt; std::endl;
		detections = ssd_detector_-&gt;Detect(image);

		//timer.stop();
		//std::cout &lt;&lt; &quot;Detection took: &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; std::endl;

		//Prepare Output message
		cv_tracker::image_obj output_car_message;
		cv_tracker::image_obj output_person_message;
		output_car_message.header = image_source.header;
		output_car_message.type = &quot;car&quot;;

		output_person_message.header = image_source.header;
		output_person_message.type = &quot;person&quot;;

		//Convert Objects to Message type
		//timer.reset(); timer.start();
		convert_rect_to_image_obj(detections, output_car_message, image, &quot;car&quot;);
		convert_rect_to_image_obj(detections, output_person_message, image, &quot;person&quot;);

		publisher_car_objects_.publish(output_car_message);
		publisher_person_objects_.publish(output_person_message);
	}


	void config_cb(const runtime_manager::ConfigSsd::ConstPtr&amp; param)
	{
		score_threshold_ 	= param-&gt;score_threshold;
	}

public:
	void Run()
	{
		//ROS STUFF
		ros::NodeHandle private_node_handle(&quot;~&quot;);//to receive args

		//RECEIVE IMAGE TOPIC NAME
		std::string image_raw_topic_str;
		if (private_node_handle.getParam(&quot;image_raw_node&quot;, image_raw_topic_str))
		{
			ROS_INFO(&quot;Setting image node to %s&quot;, image_raw_topic_str.c_str());
		}
		else
		{
			ROS_INFO(&quot;No image node received, defaulting to /image_raw, you can use _image_raw_node:=YOUR_TOPIC&quot;);
			image_raw_topic_str = &quot;/image_raw&quot;;
		}

		//RECEIVE CONVNET FILENAMES
		std::string network_definition_file;
		std::string pretrained_model_file;
		if (private_node_handle.getParam(&quot;network_definition_file&quot;, network_definition_file))
		{
			ROS_INFO(&quot;Network Definition File: %s&quot;, network_definition_file.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Network Definition File was received. Finishing execution.&quot;);
			return;
		}
		if (private_node_handle.getParam(&quot;pretrained_model_file&quot;, pretrained_model_file))
		{
			ROS_INFO(&quot;Pretrained Model File: %s&quot;, pretrained_model_file.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Pretrained Model File was received. Finishing execution.&quot;);
			return;
		}

		if (private_node_handle.getParam(&quot;score_threshold&quot;, score_threshold_))
		{
			ROS_INFO(&quot;Score Threshold: %f&quot;, score_threshold_);
		}

		if (private_node_handle.getParam(&quot;use_gpu&quot;, use_gpu_))
		{
			ROS_INFO(&quot;GPU Mode: %d&quot;, use_gpu_);
		}
		int gpu_id;
		if (private_node_handle.getParam(&quot;gpu_device_id&quot;, gpu_id ))
		{
			ROS_INFO(&quot;GPU Device ID: %d&quot;, gpu_id);
			gpu_device_id_ = (unsigned int) gpu_id;
		}

		//SSD STUFF
		ssd_detector_ = new SsdDetector(network_definition_file, pretrained_model_file, pixel_mean_, use_gpu_, gpu_device_id_);

		if (NULL == ssd_detector_)
		{
			ROS_INFO(&quot;Error while creating SSD Object&quot;);
			return;
		}
		ROS_INFO(&quot;SSD Detector initialized.&quot;);

		publisher_car_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
		publisher_person_objects_ = node_handle_.advertise&lt;cv_tracker::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);

		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str());
		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str, 1, &amp;RosSsdApp::image_callback, this);

		std::string config_topic(&quot;/config&quot;);
		config_topic += &quot;/ssd&quot;;
		subscriber_ssd_config_ = node_handle_.subscribe(config_topic, 1, &amp;RosSsdApp::config_cb, this);

		ros::spin();
		ROS_INFO(&quot;END Ssd&quot;);

	}

	~RosSsdApp()
	{
		if (NULL != ssd_detector_)
			delete ssd_detector_;
	}

	RosSsdApp()
	{
		ssd_detector_ 	= NULL;
		score_threshold_= 0.5;
		use_gpu_ 		= false;
		gpu_device_id_ 	= 0;
		pixel_mean_		= cv::Scalar(102.9801, 115.9465, 122.7717);
	}
};

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;ssd_unc&quot;);

	RosSsdApp app;

	app.Run();

	return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="6db940b6c4c9a2ff4ca060ca2e98bf4e7677e5c6" fix_time="192,48615">
		<msg>Reorganization and fix for Ubuntu 16.04</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/Thirdparty/Pangolin/include/pangolin/config.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/Thirdparty/Pangolin/include/pangolin/config.h">
				<diff>@@ -39,7 +39,7 @@
 #define HAVE_GLEW
 /* #undef GLEW_STATIC */
 
-#define HAVE_GLUT
+/* #undef HAVE_GLUT */
 /* #undef HAVE_FREEGLUT */
 /* #undef HAVE_APPLE_OPENGL_FRAMEWORK */
 /* #undef HAVE_MODIFIED_OSXGLUT */
</diff>
				<old_file>#ifndef PANGOLIN_CONFIG_H
#define PANGOLIN_CONFIG_H

/*
 * Configuration Header for Pangolin
 */

/// Version
#define PANGOLIN_VERSION_MAJOR 
#define PANGOLIN_VERSION_MINOR 
#define PANGOLIN_VERSION_STRING &quot;&quot;

/// Pangolin options
#define BUILD_PANGOLIN_GUI
#define BUILD_PANGOLIN_VARS
/* #undef BUILD_PANGOLIN_VIDEO */

/// Configured libraries
/* #undef HAVE_CUDA */
/* #undef HAVE_PYTHON */

/* #undef CPP11_NO_BOOST */
/* #undef HAVE_EIGEN */
/* #undef HAVE_TOON */

/* #undef HAVE_DC1394 */
/* #undef HAVE_V4L */
/* #undef HAVE_OPENNI */
/* #undef HAVE_OPENNI2 */
/* #undef HAVE_UVC */
/* #undef HAVE_DEPTHSENSE */
/* #undef HAVE_TELICAM */
/* #undef HAVE_PLEORA */

/* #undef HAVE_FFMPEG */
/* #undef HAVE_FFMPEG_MAX_ANALYZE_DURATION2 */
/* #undef HAVE_FFMPEG_AVFORMAT_ALLOC_OUTPUT_CONTEXT2 */

#define HAVE_GLEW
/* #undef GLEW_STATIC */

#define HAVE_GLUT
/* #undef HAVE_FREEGLUT */
/* #undef HAVE_APPLE_OPENGL_FRAMEWORK */
/* #undef HAVE_MODIFIED_OSXGLUT */
/* #undef HAVE_GLES */
/* #undef HAVE_GLES_2 */
/* #undef HAVE_OCULUS */

/* #undef HAVE_PNG */
/* #undef HAVE_JPEG */
/* #undef HAVE_TIFF */
/* #undef HAVE_OPENEXR */

/// Platform
#define _UNIX_
/* #undef _WIN_ */
/* #undef _OSX_ */
/* #undef _LINUX_ */
/* #undef _ANDROID_ */
/* #undef _IOS_ */

/// Compiler
#define _GCC_
/* #undef _CLANG_ */
/* #undef _MSVC_ */

/// Defines generated when calling into Pangolin API. Not to be
/// used in compiled library code, only inlined header code.
#if (__cplusplus &gt; 199711L) || (_MSC_VER &gt;= 1700)
#define CALLEE_HAS_CPP11
#define CALLEE_HAS_RVALREF
#endif

#if (__cplusplus &gt; 199711L) || (_MSC_VER &gt;= 1800)
#define CALLEE_HAS_VARIADIC_TEMPLATES
#endif

#endif //PANGOLIN_CONFIG_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/Thirdparty/g2o/g2o/solvers/.linear_solver_eigen.h.swp" new_path="ros/src/computing/perception/localization/packages/orb_localizer/Thirdparty/g2o/g2o/solvers/.linear_solver_eigen.h.swp">
				<diff>Binary files /dev/null and b/ros/src/computing/perception/localization/packages/orb_localizer/Thirdparty/g2o/g2o/solvers/.linear_solver_eigen.h.swp differ
</diff>
				<old_file></old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/Thirdparty/g2o/g2o/solvers/linear_solver_eigen.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/Thirdparty/g2o/g2o/solvers/linear_solver_eigen.h">
				<diff>@@ -51,7 +51,12 @@ class LinearSolverEigen: public LinearSolver&lt;MatrixType&gt;
   public:
     typedef Eigen::SparseMatrix&lt;double, Eigen::ColMajor&gt; SparseMatrix;
     typedef Eigen::Triplet&lt;double&gt; Triplet;
-    typedef Eigen::PermutationMatrix&lt;Eigen::Dynamic, Eigen::Dynamic, SparseMatrix::Index&gt; PermutationMatrix;
+
+#if EIGEN_VERSION_AT_LEAST(3,2,90)
+    typedef Eigen::PermutationMatrix&lt;Eigen::Dynamic, Eigen::Dynamic, SparseMatrix::StorageIndex&gt; PermutationMatrix;
+#else
+    typedef Eigen::PermutationMatrix&lt;Eigen::Dynamic, Eigen::Dynamic, SparseMatrix::Index&gt; PermutationMatrix;	
+#endif
     /**
      * \brief Sub-classing Eigen's SimplicialLDLT to perform ordering with a given ordering
      */
</diff>
				<old_file>// g2o - General Graph Optimization
// Copyright (C) 2011 R. Kuemmerle, G. Grisetti, W. Burgard
// All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
// * Redistributions of source code must retain the above copyright notice,
//   this list of conditions and the following disclaimer.
// * Redistributions in binary form must reproduce the above copyright
//   notice, this list of conditions and the following disclaimer in the
//   documentation and/or other materials provided with the distribution.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS
// IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
// TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
// PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

#ifndef G2O_LINEAR_SOLVER_EIGEN_H
#define G2O_LINEAR_SOLVER_EIGEN_H

#include &lt;Eigen/Sparse&gt;
#include &lt;Eigen/SparseCholesky&gt;

#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &quot;g2o/core/batch_stats.h&quot;
#include &quot;g2o/core/eigen_types.h&quot;
#include &quot;g2o/core/linear_solver.h&quot;
#include &quot;g2o/stuff/timeutil.h&quot;

namespace g2o {

/**
 * \brief linear solver which uses the sparse Cholesky solver from Eigen
 *
 * Has no dependencies except Eigen. Hence, should compile almost everywhere
 * without to much issues. Performance should be similar to CSparse, I guess.
 */
template &lt;typename MatrixType&gt;
class LinearSolverEigen: public LinearSolver&lt;MatrixType&gt;
{
  public:
    typedef Eigen::SparseMatrix&lt;double, Eigen::ColMajor&gt; SparseMatrix;
    typedef Eigen::Triplet&lt;double&gt; Triplet;
    typedef Eigen::PermutationMatrix&lt;Eigen::Dynamic, Eigen::Dynamic, SparseMatrix::Index&gt; PermutationMatrix;
    /**
     * \brief Sub-classing Eigen's SimplicialLDLT to perform ordering with a given ordering
     */
    class CholeskyDecomposition : public Eigen::SimplicialLDLT&lt;SparseMatrix, Eigen::Upper&gt;
    {
      public:
        CholeskyDecomposition() : Eigen::SimplicialLDLT&lt;SparseMatrix, Eigen::Upper&gt;() {}
        using Eigen::SimplicialLDLT&lt; SparseMatrix, Eigen::Upper&gt;::analyzePattern_preordered;

        void analyzePatternWithPermutation(SparseMatrix&amp; a, const PermutationMatrix&amp; permutation)
        {
          m_Pinv = permutation;
          m_P = permutation.inverse();
          int size = a.cols();
          SparseMatrix ap(size, size);
          ap.selfadjointView&lt;Eigen::Upper&gt;() = a.selfadjointView&lt;UpLo&gt;().twistedBy(m_P);
          analyzePattern_preordered(ap, true);
        }
    };

  public:
    LinearSolverEigen() :
      LinearSolver&lt;MatrixType&gt;(),
      _init(true), _blockOrdering(false), _writeDebug(false)
    {
    }

    virtual ~LinearSolverEigen()
    {
    }

    virtual bool init()
    {
      _init = true;
      return true;
    }

    bool solve(const SparseBlockMatrix&lt;MatrixType&gt;&amp; A, double* x, double* b)
    {
      if (_init)
        _sparseMatrix.resize(A.rows(), A.cols());
      fillSparseMatrix(A, !_init);
      if (_init) // compute the symbolic composition once
        computeSymbolicDecomposition(A);
      _init = false;

      double t=get_monotonic_time();
      _cholesky.factorize(_sparseMatrix);
      if (_cholesky.info() != Eigen::Success) { // the matrix is not positive definite
        if (_writeDebug) {
          std::cerr &lt;&lt; &quot;Cholesky failure, writing debug.txt (Hessian loadable by Octave)&quot; &lt;&lt; std::endl;
          A.writeOctave(&quot;debug.txt&quot;);
        }
        return false;
      }

      // Solving the system
      VectorXD::MapType xx(x, _sparseMatrix.cols());
      VectorXD::ConstMapType bb(b, _sparseMatrix.cols());
      xx = _cholesky.solve(bb);
      G2OBatchStatistics* globalStats = G2OBatchStatistics::globalStats();
      if (globalStats) {
        globalStats-&gt;timeNumericDecomposition = get_monotonic_time() - t;
        globalStats-&gt;choleskyNNZ = _cholesky.matrixL().nestedExpression().nonZeros() + _sparseMatrix.cols(); // the elements of D
      }

      return true;
    }

    //! do the AMD ordering on the blocks or on the scalar matrix
    bool blockOrdering() const { return _blockOrdering;}
    void setBlockOrdering(bool blockOrdering) { _blockOrdering = blockOrdering;}

    //! write a debug dump of the system matrix if it is not SPD in solve
    virtual bool writeDebug() const { return _writeDebug;}
    virtual void setWriteDebug(bool b) { _writeDebug = b;}

  protected:
    bool _init;
    bool _blockOrdering;
    bool _writeDebug;
    SparseMatrix _sparseMatrix;
    CholeskyDecomposition _cholesky;

    /**
     * compute the symbolic decompostion of the matrix only once.
     * Since A has the same pattern in all the iterations, we only
     * compute the fill-in reducing ordering once and re-use for all
     * the following iterations.
     */
    void computeSymbolicDecomposition(const SparseBlockMatrix&lt;MatrixType&gt;&amp; A)
    {
      double t=get_monotonic_time();
      if (! _blockOrdering) {
        _cholesky.analyzePattern(_sparseMatrix);
      } else {
        // block ordering with the Eigen Interface
        // This is really ugly currently, as it calls internal functions from Eigen
        // and modifies the SparseMatrix class
        Eigen::PermutationMatrix&lt;Eigen::Dynamic,Eigen::Dynamic&gt; blockP;
        {
          // prepare a block structure matrix for calling AMD
          std::vector&lt;Triplet&gt; triplets;
          for (size_t c = 0; c &lt; A.blockCols().size(); ++c){
            const typename SparseBlockMatrix&lt;MatrixType&gt;::IntBlockMap&amp; column = A.blockCols()[c];
            for (typename SparseBlockMatrix&lt;MatrixType&gt;::IntBlockMap::const_iterator it = column.begin(); it != column.end(); ++it) {
              const int&amp; r = it-&gt;first;
              if (r &gt; static_cast&lt;int&gt;(c)) // only upper triangle
                break;
              triplets.push_back(Triplet(r, c, 0.));
            }
          }

          // call the AMD ordering on the block matrix.
          // Relies on Eigen's internal stuff, probably bad idea
          SparseMatrix auxBlockMatrix(A.blockCols().size(), A.blockCols().size());
          auxBlockMatrix.setFromTriplets(triplets.begin(), triplets.end());
          typename CholeskyDecomposition::CholMatrixType C;
          C = auxBlockMatrix.selfadjointView&lt;Eigen::Upper&gt;();
          Eigen::internal::minimum_degree_ordering(C, blockP);
        }

        int rows = A.rows();
        assert(rows == A.cols() &amp;&amp; &quot;Matrix A is not square&quot;);

        // Adapt the block permutation to the scalar matrix
        PermutationMatrix scalarP;
        scalarP.resize(rows);
        int scalarIdx = 0;
        for (int i = 0; i &lt; blockP.size(); ++i) {
          const int&amp; p = blockP.indices()(i);
          int base  = A.colBaseOfBlock(p);
          int nCols = A.colsOfBlock(p);
          for (int j = 0; j &lt; nCols; ++j)
            scalarP.indices()(scalarIdx++) = base++;
        }
        assert(scalarIdx == rows &amp;&amp; &quot;did not completely fill the permutation matrix&quot;);
        // analyze with the scalar permutation
        _cholesky.analyzePatternWithPermutation(_sparseMatrix, scalarP);

      }
      G2OBatchStatistics* globalStats = G2OBatchStatistics::globalStats();
      if (globalStats)
        globalStats-&gt;timeSymbolicDecomposition = get_monotonic_time() - t;
    }

    void fillSparseMatrix(const SparseBlockMatrix&lt;MatrixType&gt;&amp; A, bool onlyValues)
    {
      if (onlyValues) {
        A.fillCCS(_sparseMatrix.valuePtr(), true);
      } else {

        // create from triplet structure
        std::vector&lt;Triplet&gt; triplets;
        triplets.reserve(A.nonZeros());
        for (size_t c = 0; c &lt; A.blockCols().size(); ++c) {
          int colBaseOfBlock = A.colBaseOfBlock(c);
          const typename SparseBlockMatrix&lt;MatrixType&gt;::IntBlockMap&amp; column = A.blockCols()[c];
          for (typename SparseBlockMatrix&lt;MatrixType&gt;::IntBlockMap::const_iterator it = column.begin(); it != column.end(); ++it) {
            int rowBaseOfBlock = A.rowBaseOfBlock(it-&gt;first);
            const MatrixType&amp; m = *(it-&gt;second);
            for (int cc = 0; cc &lt; m.cols(); ++cc) {
              int aux_c = colBaseOfBlock + cc;
              for (int rr = 0; rr &lt; m.rows(); ++rr) {
                int aux_r = rowBaseOfBlock + rr;
                if (aux_r &gt; aux_c)
                  break;
                triplets.push_back(Triplet(aux_r, aux_c, m(rr, cc)));
              }
            }
          }
        }
        _sparseMatrix.setFromTriplets(triplets.begin(), triplets.end());

      }
    }
};

} // end namespace

#endif
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Converter.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Converter.h">
				<diff>@@ -49,7 +49,7 @@ public:
     static Eigen::Matrix&lt;double,3,1&gt; toVector3d(const cv::Point3f &amp;cvPoint);
     static Eigen::Matrix&lt;double,3,3&gt; toMatrix3d(const cv::Mat &amp;cvMat3);
 
-    static std::vector&lt;float&gt; toQuaternion(const cv::Mat &amp;M);
+    static Eigen::Quaterniond toQuaternion(const cv::Mat &amp;M);
 };
 
 }// namespace ORB_SLAM
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#ifndef CONVERTER_H
#define CONVERTER_H

#include&lt;opencv2/core/core.hpp&gt;

#include&lt;Eigen/Dense&gt;
#include &quot;g2o/types/types_six_dof_expmap.h&quot;
#include &quot;g2o/types/types_seven_dof_expmap.h&quot;

namespace ORB_SLAM2
{

class Converter
{
public:
    static std::vector&lt;cv::Mat&gt; toDescriptorVector(const cv::Mat &amp;Descriptors);

    static g2o::SE3Quat toSE3Quat(const cv::Mat &amp;cvT);
    static g2o::SE3Quat toSE3Quat(const g2o::Sim3 &amp;gSim3);

    static cv::Mat toCvMat(const g2o::SE3Quat &amp;SE3);
    static cv::Mat toCvMat(const g2o::Sim3 &amp;Sim3);
    static cv::Mat toCvMat(const Eigen::Matrix&lt;double,4,4&gt; &amp;m);
    static cv::Mat toCvMat(const Eigen::Matrix3d &amp;m);
    static cv::Mat toCvMat(const Eigen::Matrix&lt;double,3,1&gt; &amp;m);
    static cv::Mat toCvSE3(const Eigen::Matrix&lt;double,3,3&gt; &amp;R, const Eigen::Matrix&lt;double,3,1&gt; &amp;t);

    static Eigen::Matrix&lt;double,3,1&gt; toVector3d(const cv::Mat &amp;cvVector);
    static Eigen::Matrix&lt;double,3,1&gt; toVector3d(const cv::Point3f &amp;cvPoint);
    static Eigen::Matrix&lt;double,3,3&gt; toMatrix3d(const cv::Mat &amp;cvMat3);

    static std::vector&lt;float&gt; toQuaternion(const cv::Mat &amp;M);
};

}// namespace ORB_SLAM

#endif // CONVERTER_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Frame.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Frame.h">
				<diff>@@ -189,6 +189,10 @@ public:
 
     static bool mbInitialComputations;
 
+    // the image itself. only useful for monocular
+    cv::Mat image;
+
+    void debug (const string &amp;dirname=&quot;debug&quot;);
 
 private:
 
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#ifndef FRAME_H
#define FRAME_H

#include &lt;vector&gt;


#include &quot;DBoW2/BowVector.h&quot;
#include &quot;DBoW2/FeatureVector.h&quot;
#include &quot;ORBVocabulary.h&quot;
#include &quot;ORBextractor.h&quot;

#include &lt;opencv2/opencv.hpp&gt;

namespace ORB_SLAM2
{
#define FRAME_GRID_ROWS 48
#define FRAME_GRID_COLS 64

class MapPoint;
class KeyFrame;

class Frame
{
public:
    Frame();

    // Copy constructor.
    Frame(const Frame &amp;frame);

    // Constructor for stereo cameras.
    Frame(const cv::Mat &amp;imLeft, const cv::Mat &amp;imRight, const double &amp;timeStamp, ORBextractor* extractorLeft, ORBextractor* extractorRight, ORBVocabulary* voc, cv::Mat &amp;K, cv::Mat &amp;distCoef, const float &amp;bf, const float &amp;thDepth);

    // Constructor for RGB-D cameras.
    Frame(const cv::Mat &amp;imGray, const cv::Mat &amp;imDepth, const double &amp;timeStamp, ORBextractor* extractor,ORBVocabulary* voc, cv::Mat &amp;K, cv::Mat &amp;distCoef, const float &amp;bf, const float &amp;thDepth);

    // Constructor for Monocular cameras.
    Frame(const cv::Mat &amp;imGray, const double &amp;timeStamp, ORBextractor* extractor,ORBVocabulary* voc, cv::Mat &amp;K, cv::Mat &amp;distCoef, const float &amp;bf, const float &amp;thDepth);

    // Extract ORB on the image. 0 for left image and 1 for right image.
    void ExtractORB(int flag, const cv::Mat &amp;im);

    // Compute Bag of Words representation.
    void ComputeBoW();

    // Set the camera pose.
    void SetPose(cv::Mat Tcw);

    // Computes rotation, translation and camera center matrices from the camera pose.
    void UpdatePoseMatrices();

    // Returns the camera center.
    inline cv::Mat GetCameraCenter(){
        return mOw.clone();
    }

    // Returns inverse of rotation
    inline cv::Mat GetRotationInverse(){
        return mRwc.clone();
    }

    // Check if a MapPoint is in the frustum of the camera
    // and fill variables of the MapPoint to be used by the tracking
    bool isInFrustum(MapPoint* pMP, float viewingCosLimit);

    // Compute the cell of a keypoint (return false if outside the grid)
    bool PosInGrid(const cv::KeyPoint &amp;kp, int &amp;posX, int &amp;posY);

    vector&lt;size_t&gt; GetFeaturesInArea(const float &amp;x, const float  &amp;y, const float  &amp;r, const int minLevel=-1, const int maxLevel=-1) const;

    // Search a match for each keypoint in the left image to a keypoint in the right image.
    // If there is a match, depth is computed and the right coordinate associated to the left keypoint is stored.
    void ComputeStereoMatches();

    // Associate a &quot;right&quot; coordinate to a keypoint if there is valid depth in the depthmap.
    void ComputeStereoFromRGBD(const cv::Mat &amp;imDepth);

    // Backprojects a keypoint (if stereo/depth info available) into 3D world coordinates.
    cv::Mat UnprojectStereo(const int &amp;i);

    /* Returns normalized frame's direction vector (really axis of quaternion) */
    void getDirectionVector (float &amp;dirX, float &amp;dirY, float &amp;dirZ);

public:
    // Vocabulary used for relocalization.
    ORBVocabulary* mpORBvocabulary;

    // Feature extractor. The right is used only in the stereo case.
    ORBextractor* mpORBextractorLeft, *mpORBextractorRight;

    // Frame timestamp.
    double mTimeStamp;

    // Calibration matrix and OpenCV distortion parameters.
    cv::Mat mK;
    static float fx;
    static float fy;
    static float cx;
    static float cy;
    static float invfx;
    static float invfy;
    cv::Mat mDistCoef;

    // Stereo baseline multiplied by fx.
    float mbf;

    // Stereo baseline in meters.
    float mb;

    // Threshold close/far points. Close points are inserted from 1 view.
    // Far points are inserted as in the monocular case from 2 views.
    float mThDepth;

    // Number of KeyPoints.
    int N;

    // Vector of keypoints (original for visualization) and undistorted (actually used by the system).
    // In the stereo case, mvKeysUn is redundant as images must be rectified.
    // In the RGB-D case, RGB images can be distorted.
    std::vector&lt;cv::KeyPoint&gt; mvKeys, mvKeysRight;
    std::vector&lt;cv::KeyPoint&gt; mvKeysUn;

    // Corresponding stereo coordinate and depth for each keypoint.
    // &quot;Monocular&quot; keypoints have a negative value.
    std::vector&lt;float&gt; mvuRight;
    std::vector&lt;float&gt; mvDepth;

    // Bag of Words Vector structures.
    DBoW2::BowVector mBowVec;
    DBoW2::FeatureVector mFeatVec;

    // ORB descriptor, each row associated to a keypoint.
    cv::Mat mDescriptors, mDescriptorsRight;

    // MapPoints associated to keypoints, NULL pointer if no association.
    std::vector&lt;MapPoint*&gt; mvpMapPoints;

    // Flag to identify outlier associations.
    std::vector&lt;bool&gt; mvbOutlier;

    // Keypoints are assigned to cells in a grid to reduce matching complexity when projecting MapPoints.
    static float mfGridElementWidthInv;
    static float mfGridElementHeightInv;
    std::vector&lt;std::size_t&gt; mGrid[FRAME_GRID_COLS][FRAME_GRID_ROWS];

    // Camera pose.
    cv::Mat mTcw;

    // Current and Next Frame id.
    static long unsigned int nNextId;
    long unsigned int mnId;

    // Reference Keyframe.
    KeyFrame* mpReferenceKF;

    // Scale pyramid info.
    int mnScaleLevels;
    float mfScaleFactor;
    float mfLogScaleFactor;
    vector&lt;float&gt; mvScaleFactors;
    vector&lt;float&gt; mvInvScaleFactors;
    vector&lt;float&gt; mvLevelSigma2;
    vector&lt;float&gt; mvInvLevelSigma2;

    // Undistorted Image Bounds (computed once).
    static float mnMinX;
    static float mnMaxX;
    static float mnMinY;
    static float mnMaxY;

    static bool mbInitialComputations;


private:

    // Undistort keypoints given OpenCV distortion parameters.
    // Only for the RGB-D case. Stereo must be already rectified!
    // (called in the constructor).
    void UndistortKeyPoints();

    // Computes image bounds for the undistorted image (called in the constructor).
    void ComputeImageBounds(const cv::Mat &amp;imLeft);

    // Assign keypoints to the grid for speed up feature matching (called in the constructor).
    void AssignFeaturesToGrid();

    // Rotation, translation and camera center
    cv::Mat mRcw;
    cv::Mat mtcw;
    cv::Mat mRwc;
    cv::Mat mOw; //==mtwc
};

}// namespace ORB_SLAM

#endif // FRAME_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/KeyFrame.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/KeyFrame.h">
				<diff>@@ -31,6 +31,7 @@
 #include &lt;mutex&gt;
 #include &lt;list&gt;
 #include &lt;map&gt;
+#include &lt;set&gt;
 #include &lt;boost/serialization/serialization.hpp&gt;
 
 
@@ -76,6 +77,7 @@ public:
 
     // Bag of Words Representation
     void ComputeBoW();
+    void RecomputeBoW (ORBVocabulary *newvoc);
 
     // Covisibility graph functions
     void AddConnection(KeyFrame* pKF, const int &amp;weight);
@@ -213,6 +215,7 @@ public:
     int mnMaxY;
     cv::Mat mK;
 
+    void debug (const string &amp;dirname=&quot;debug&quot;);
 
     // The following variables need to be accessed trough a mutex to be thread safe.
 protected:
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#ifndef KEYFRAME_H
#define KEYFRAME_H

#include &quot;MapPoint.h&quot;
#include &quot;DBoW2/BowVector.h&quot;
#include &quot;DBoW2/FeatureVector.h&quot;
#include &quot;ORBVocabulary.h&quot;
#include &quot;ORBextractor.h&quot;
#include &quot;Frame.h&quot;

#include &lt;mutex&gt;
#include &lt;list&gt;
#include &lt;map&gt;
#include &lt;boost/serialization/serialization.hpp&gt;


typedef int64_t idtype;


namespace boost {
namespace serialization {

template &lt;class Archive&gt;
	void save (Archive &amp; ar, const ORB_SLAM2::KeyFrame &amp;keyframe, const unsigned int version);
template &lt;class Archive&gt;
	void load (Archive &amp; ar, ORB_SLAM2::KeyFrame &amp;keyframe, const unsigned int version);

}
}



namespace ORB_SLAM2
{

class Map;
class MapPoint;
class Frame;
class KeyFrameDatabase;

class KeyFrame
{
public:
    KeyFrame(Frame &amp;F, Map* pMap, KeyFrameDatabase* pKFDB);

    KeyFrame() {}

    // Pose functions
    void SetPose(const cv::Mat &amp;Tcw);
    cv::Mat GetPose();
    cv::Mat GetPoseInverse();
    cv::Mat GetCameraCenter();
    cv::Mat GetStereoCenter();
    cv::Mat GetRotation();
    cv::Mat GetTranslation();

    // Bag of Words Representation
    void ComputeBoW();

    // Covisibility graph functions
    void AddConnection(KeyFrame* pKF, const int &amp;weight);
    void EraseConnection(KeyFrame* pKF);
    void UpdateConnections();
    void UpdateBestCovisibles();
    std::set&lt;KeyFrame *&gt; GetConnectedKeyFrames();
    std::vector&lt;KeyFrame* &gt; GetVectorCovisibleKeyFrames();
    std::vector&lt;KeyFrame*&gt; GetBestCovisibilityKeyFrames(const int &amp;N);
    std::vector&lt;KeyFrame*&gt; GetCovisiblesByWeight(const int &amp;w);
    int GetWeight(KeyFrame* pKF);

    // Spanning tree functions
    void AddChild(KeyFrame* pKF);
    void EraseChild(KeyFrame* pKF);
    void ChangeParent(KeyFrame* pKF);
    std::set&lt;KeyFrame*&gt; GetChilds();
    KeyFrame* GetParent();
    bool hasChild(KeyFrame* pKF);

    // Loop Edges
    void AddLoopEdge(KeyFrame* pKF);
    std::set&lt;KeyFrame*&gt; GetLoopEdges();

    // MapPoint observation functions
    void AddMapPoint(MapPoint* pMP, const size_t &amp;idx);
    void EraseMapPointMatch(const size_t &amp;idx);
    void EraseMapPointMatch(MapPoint* pMP);
    void ReplaceMapPointMatch(const size_t &amp;idx, MapPoint* pMP);
    std::set&lt;MapPoint*&gt; GetMapPoints();
    std::vector&lt;MapPoint*&gt; GetMapPointMatches();
    int TrackedMapPoints(const int &amp;minObs);
    MapPoint* GetMapPoint(const size_t &amp;idx);

    // KeyPoint functions
    std::vector&lt;size_t&gt; GetFeaturesInArea(const float &amp;x, const float  &amp;y, const float  &amp;r) const;
    cv::Mat UnprojectStereo(int i);

    // Image
    bool IsInImage(const float &amp;x, const float &amp;y) const;

    // Enable/Disable bad flag changes
    void SetNotErase();
    void SetErase();

    // Set/check bad flag
    void SetBadFlag();
    bool isBad();

    // Compute Scene Depth (q=2 median). Used in monocular.
    float ComputeSceneMedianDepth(const int q);

    static bool weightComp( int a, int b){
        return a&gt;b;
    }

    static bool lId(KeyFrame* pKF1, KeyFrame* pKF2){
        return pKF1-&gt;mnId&lt;pKF2-&gt;mnId;
    }

    // Called after map loading for each keyframe
    void fixConnections (Map *smap, KeyFrameDatabase *kfdb);

    /* Returns normalized keyframe's direction vector (really axis of quaternion) */
    void getDirectionVector (float &amp;dirX, float &amp;dirY, float &amp;dirZ);

    // The following variables are accesed from only 1 thread or never change (no mutex needed).
public:

    static long unsigned int nNextId;
    long unsigned int mnId;
    long unsigned int mnFrameId;

    double mTimeStamp;

    // Grid (to speed up feature matching)
    int mnGridCols;
    int mnGridRows;
    float mfGridElementWidthInv;
    float mfGridElementHeightInv;

    // Variables used by the tracking
    long unsigned int mnTrackReferenceForFrame;
    long unsigned int mnFuseTargetForKF;

    // Variables used by the local mapping
    long unsigned int mnBALocalForKF;
    long unsigned int mnBAFixedForKF;

    // Variables used by the keyframe database
    long unsigned int mnLoopQuery;
    int mnLoopWords;
    float mLoopScore;
    long unsigned int mnRelocQuery;
    int mnRelocWords;
    float mRelocScore;

    // Variables used by loop closing
    cv::Mat mTcwGBA;
    cv::Mat mTcwBefGBA;
    long unsigned int mnBAGlobalForKF;

    // Calibration parameters
    float fx, fy, cx, cy, invfx, invfy, mbf, mb, mThDepth;

    // Number of KeyPoints
    int N;

    // KeyPoints, stereo coordinate and descriptors (all associated by an index)
    std::vector&lt;cv::KeyPoint&gt; mvKeys;
    std::vector&lt;cv::KeyPoint&gt; mvKeysUn;
    std::vector&lt;float&gt; mvuRight; // negative value for monocular points
    std::vector&lt;float&gt; mvDepth; // negative value for monocular points
    cv::Mat mDescriptors;

    //BoW
    DBoW2::BowVector mBowVec;
    DBoW2::FeatureVector mFeatVec;

    // Pose relative to parent (this is computed when bad flag is activated)
    cv::Mat mTcp;

    // Scale
    int mnScaleLevels;
    float mfScaleFactor;
    float mfLogScaleFactor;
    std::vector&lt;float&gt; mvScaleFactors;
    std::vector&lt;float&gt; mvLevelSigma2;
    std::vector&lt;float&gt; mvInvLevelSigma2;

    // Image bounds and calibration
    int mnMinX;
    int mnMinY;
    int mnMaxX;
    int mnMaxY;
    cv::Mat mK;


    // The following variables need to be accessed trough a mutex to be thread safe.
protected:


    template &lt;class Archive&gt;
    friend void boost::serialization::save (Archive &amp; ar, const ORB_SLAM2::KeyFrame &amp;keyframe, const unsigned int version);

    template &lt;class Archive&gt;
    friend void boost::serialization::load (Archive &amp; ar, ORB_SLAM2::KeyFrame &amp;keyframe, const unsigned int version);


    // SE3 Pose and camera center
    cv::Mat Tcw;
    cv::Mat Twc;
    cv::Mat Ow;

    cv::Mat Cw; // Stereo middle point. Only for visualization

    // MapPoints associated to keypoints
    std::vector&lt;MapPoint*&gt; mvpMapPoints;

    // BoW
    KeyFrameDatabase* mpKeyFrameDB;
    ORBVocabulary* mpORBvocabulary;

    // Grid over the image to speed up feature matching
    std::vector&lt; std::vector &lt;std::vector&lt;size_t&gt; &gt; &gt; mGrid;

    std::map&lt;KeyFrame*,int&gt; mConnectedKeyFrameWeights;
    std::vector&lt;KeyFrame*&gt; mvpOrderedConnectedKeyFrames;
    std::vector&lt;int&gt; mvOrderedWeights;

    // Spanning Tree and Loop Edges
    bool mbFirstConnection;
    KeyFrame* mpParent;
    std::set&lt;KeyFrame*&gt; mspChildrens;
    std::set&lt;KeyFrame*&gt; mspLoopEdges;

    // Bad flags
    bool mbNotErase;
    bool mbToBeErased;
    bool mbBad;    

    float mHalfBaseline; // Only for visualization

    Map* mpMap;

    std::mutex mMutexPose;
    std::mutex mMutexConnections;
    std::mutex mMutexFeatures;


public:

	// these class members are meant to be temporary when serializing.
	map&lt;idtype,int&gt; _imConnectedKeyFrameWeights;
	vector&lt;idtype&gt; _vmvpOrderedConnectedKeyFrames;
	int _parentId;
	set&lt;idtype&gt; _vmspChildrens;
	set&lt;idtype&gt; _vmspLoopEdges;
	vector&lt;idtype&gt; _mapPointIdList;
	static map&lt;idtype, KeyFrame*&gt; objectListLookup;

    cv::Mat extPosition;
    cv::Mat extOrientation;

	// These two static variables are set by other threads
	static std::mutex extPoseMutex;
	static cv::Mat extEgoPosition;
	static cv::Mat extEgoOrientation;

};

} //namespace ORB_SLAM

#endif // KEYFRAME_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/KeyFrameDatabase.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/KeyFrameDatabase.h">
				<diff>@@ -52,13 +52,14 @@ namespace ORB_SLAM2
 
 class KeyFrame;
 class Frame;
+class Map;
 
 
 class KeyFrameDatabase
 {
 public:
 
-    KeyFrameDatabase(const ORBVocabulary &amp;voc);
+    KeyFrameDatabase(ORBVocabulary &amp;voc);
 
    void add(KeyFrame* pKF);
 
@@ -72,9 +73,13 @@ public:
    // Relocalization
    std::vector&lt;KeyFrame*&gt; DetectRelocalizationCandidates(Frame* F);
 
+   std::vector&lt;KeyFrame*&gt; DetectRelocalizationCandidatesSimple (Frame* F);
+
 	ORBVocabulary* getVocabulary ()
 	{ return const_cast&lt;ORBVocabulary*&gt; (mpVoc); }
 
+	void replaceVocabulary (ORBVocabulary *newvoc, Map *cmap);
+
 protected:
 
 	template &lt;class Archive&gt;
@@ -85,7 +90,7 @@ protected:
 
 
   // Associated vocabulary
-  const ORBVocabulary* mpVoc;
+  ORBVocabulary* mpVoc;
 
   // Inverted file
   std::vector&lt;list&lt;KeyFrame*&gt; &gt; mvInvertedFile;
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#ifndef KEYFRAMEDATABASE_H
#define KEYFRAMEDATABASE_H

#include &lt;vector&gt;
#include &lt;list&gt;
#include &lt;set&gt;

//#include &quot;KeyFrame.h&quot;
#include &quot;Frame.h&quot;
#include &quot;ORBVocabulary.h&quot;

#include&lt;mutex&gt;

#include &lt;boost/thread.hpp&gt;
#include &lt;boost/serialization/serialization.hpp&gt;


namespace boost {
namespace serialization {

template &lt;class Archive&gt;
	void save (Archive &amp; ar, const ORB_SLAM2::KeyFrameDatabase &amp;kfdb, const unsigned int version);
template &lt;class Archive&gt;
	void load (Archive &amp; ar, ORB_SLAM2::KeyFrameDatabase &amp;kfdb, const unsigned int version);

}
}


namespace ORB_SLAM2
{

class KeyFrame;
class Frame;


class KeyFrameDatabase
{
public:

    KeyFrameDatabase(const ORBVocabulary &amp;voc);

   void add(KeyFrame* pKF);

   void erase(KeyFrame* pKF);

   void clear();

   // Loop Detection
   std::vector&lt;KeyFrame *&gt; DetectLoopCandidates(KeyFrame* pKF, float minScore);

   // Relocalization
   std::vector&lt;KeyFrame*&gt; DetectRelocalizationCandidates(Frame* F);

	ORBVocabulary* getVocabulary ()
	{ return const_cast&lt;ORBVocabulary*&gt; (mpVoc); }

protected:

	template &lt;class Archive&gt;
	friend void boost::serialization::save (Archive &amp; ar, const ORB_SLAM2::KeyFrameDatabase &amp;kfdb, const unsigned int version);

	template &lt;class Archive&gt;
	friend void boost::serialization::load (Archive &amp; ar, ORB_SLAM2::KeyFrameDatabase &amp;kfdb, const unsigned int version);


  // Associated vocabulary
  const ORBVocabulary* mpVoc;

  // Inverted file
  std::vector&lt;list&lt;KeyFrame*&gt; &gt; mvInvertedFile;

  // Mutex
  std::mutex mMutex;
};

} //namespace ORB_SLAM


#endif
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/LocalMapping.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/LocalMapping.h">
				<diff>@@ -40,7 +40,7 @@ class Map;
 class LocalMapping
 {
 public:
-    LocalMapping(Map* pMap, const float bMonocular);
+    LocalMapping(Map* pMap, const float bMonocular, const bool offlineMode=false);
 
     void SetLoopCloser(LoopClosing* pLoopCloser);
 
@@ -77,6 +77,8 @@ public:
 
     std::mutex localMappingRunMutex;
 
+    const bool offlineMapping;
+
 protected:
 
     bool CheckNewKeyFrames();
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#ifndef LOCALMAPPING_H
#define LOCALMAPPING_H

#include &quot;KeyFrame.h&quot;
#include &quot;Map.h&quot;
#include &quot;LoopClosing.h&quot;
#include &quot;Tracking.h&quot;
#include &quot;KeyFrameDatabase.h&quot;

#include &lt;mutex&gt;


namespace ORB_SLAM2
{

class Tracking;
class LoopClosing;
class Map;

class LocalMapping
{
public:
    LocalMapping(Map* pMap, const float bMonocular);

    void SetLoopCloser(LoopClosing* pLoopCloser);

    void SetTracker(Tracking* pTracker);

    // Main function
    void Run();

    // This is used for single thread mode (aka. bag mapping)
    void RunOnce ();

    void InsertKeyFrame(KeyFrame* pKF);

    // Thread Synch
    void RequestStop();
    void RequestReset(const bool _offline=false);
    bool Stop();
    void Release();
    bool isStopped();
    bool stopRequested();
    bool AcceptKeyFrames();
    void SetAcceptKeyFrames(bool flag);
    bool SetNotStop(bool flag);

    void InterruptBA();

    void RequestFinish();
    bool isFinished();

    int KeyframesInQueue(){
        unique_lock&lt;std::mutex&gt; lock(mMutexNewKFs);
        return mlNewKeyFrames.size();
    }

    std::mutex localMappingRunMutex;

protected:

    bool CheckNewKeyFrames();
    void ProcessNewKeyFrame();
    void CreateNewMapPoints();

    void MapPointCulling();
    void SearchInNeighbors();

    void KeyFrameCulling();

    cv::Mat ComputeF12(KeyFrame* &amp;pKF1, KeyFrame* &amp;pKF2);

    cv::Mat SkewSymmetricMatrix(const cv::Mat &amp;v);

    bool mbMonocular;

    void ResetIfRequested();
    bool mbResetRequested;
    std::mutex mMutexReset;

    bool CheckFinish();
    void SetFinish();
    bool mbFinishRequested;
    bool mbFinished;
    std::mutex mMutexFinish;

    Map* mpMap;

    LoopClosing* mpLoopCloser;
    Tracking* mpTracker;

    std::list&lt;KeyFrame*&gt; mlNewKeyFrames;

    KeyFrame* mpCurrentKeyFrame;

    std::list&lt;MapPoint*&gt; mlpRecentAddedMapPoints;

    std::mutex mMutexNewKFs;

    bool mbAbortBA;

    bool mbStopped;
    bool mbStopRequested;
    bool mbNotStop;
    std::mutex mMutexStop;

    bool mbAcceptKeyFrames;
    std::mutex mMutexAccept;
};

} //namespace ORB_SLAM

#endif // LOCALMAPPING_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/LoopClosing.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/LoopClosing.h">
				<diff>@@ -51,7 +51,7 @@ public:
 
 public:
 
-    LoopClosing(Map* pMap, KeyFrameDatabase* pDB, ORBVocabulary* pVoc,const bool bFixScale);
+    LoopClosing(Map* pMap, KeyFrameDatabase* pDB, ORBVocabulary* pVoc,const bool bFixScale, const bool offlineMode=false);
 
     void SetTracker(Tracking* pTracker);
 
@@ -85,6 +85,8 @@ public:
 
     std::mutex loopCloserRunMutex;
 
+    const bool offlineMapping;
+
 protected:
 
     bool CheckNewKeyFrames();
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#ifndef LOOPCLOSING_H
#define LOOPCLOSING_H

#include &quot;KeyFrame.h&quot;
#include &quot;LocalMapping.h&quot;
#include &quot;Map.h&quot;
#include &quot;ORBVocabulary.h&quot;
#include &quot;Tracking.h&quot;

#include &quot;KeyFrameDatabase.h&quot;

#include &lt;thread&gt;
#include &lt;mutex&gt;
#include &quot;g2o/types/types_seven_dof_expmap.h&quot;

namespace ORB_SLAM2
{

class Tracking;
class LocalMapping;
class KeyFrameDatabase;


class LoopClosing
{
public:

    typedef pair&lt;set&lt;KeyFrame*&gt;,int&gt; ConsistentGroup;    
    typedef map&lt;KeyFrame*,g2o::Sim3,std::less&lt;KeyFrame*&gt;,
        Eigen::aligned_allocator&lt;std::pair&lt;const KeyFrame*, g2o::Sim3&gt; &gt; &gt; KeyFrameAndPose;

public:

    LoopClosing(Map* pMap, KeyFrameDatabase* pDB, ORBVocabulary* pVoc,const bool bFixScale);

    void SetTracker(Tracking* pTracker);

    void SetLocalMapper(LocalMapping* pLocalMapper);

    // Main function
    void Run();

    // This is used for single thread mode (aka. bag mapping)
    void RunOnce ();

    void InsertKeyFrame(KeyFrame *pKF);

    void RequestReset(const bool _offline=false);

    // This function will run in a separate thread
    void RunGlobalBundleAdjustment(unsigned long nLoopKF);

    bool isRunningGBA(){
        unique_lock&lt;std::mutex&gt; lock(mMutexGBA);
        return mbRunningGBA;
    }
    bool isFinishedGBA(){
        unique_lock&lt;std::mutex&gt; lock(mMutexGBA);
        return mbFinishedGBA;
    }   

    void RequestFinish();

    bool isFinished();

    std::mutex loopCloserRunMutex;

protected:

    bool CheckNewKeyFrames();

    bool DetectLoop();

    bool ComputeSim3();

    void SearchAndFuse(const KeyFrameAndPose &amp;CorrectedPosesMap);

    void CorrectLoop();

    void ResetIfRequested();
    bool mbResetRequested;
    std::mutex mMutexReset;

    bool CheckFinish();
    void SetFinish();
    bool mbFinishRequested;
    bool mbFinished;
    std::mutex mMutexFinish;

    Map* mpMap;
    Tracking* mpTracker;

    KeyFrameDatabase* mpKeyFrameDB;
    ORBVocabulary* mpORBVocabulary;

    LocalMapping *mpLocalMapper;

    std::list&lt;KeyFrame*&gt; mlpLoopKeyFrameQueue;

    std::mutex mMutexLoopQueue;

    // Loop detector parameters
    float mnCovisibilityConsistencyTh;

    // Loop detector variables
    KeyFrame* mpCurrentKF;
    KeyFrame* mpMatchedKF;
    std::vector&lt;ConsistentGroup&gt; mvConsistentGroups;
    std::vector&lt;KeyFrame*&gt; mvpEnoughConsistentCandidates;
    std::vector&lt;KeyFrame*&gt; mvpCurrentConnectedKFs;
    std::vector&lt;MapPoint*&gt; mvpCurrentMatchedPoints;
    std::vector&lt;MapPoint*&gt; mvpLoopMapPoints;
    cv::Mat mScw;
    g2o::Sim3 mg2oScw;

    long unsigned int mLastLoopKFid;

    // Variables related to Global Bundle Adjustment
    bool mbRunningGBA;
    bool mbFinishedGBA;
    bool mbStopGBA;
    std::mutex mMutexGBA;
    std::thread* mpThreadGBA;

    // Fix scale in the stereo/RGB-D case
    bool mbFixScale;
};

} //namespace ORB_SLAM

#endif // LOOPCLOSING_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Map.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Map.h">
				<diff>@@ -35,6 +35,7 @@
 #include &lt;pcl/octree/octree.h&gt;
 #include &lt;pcl/octree/impl/octree_search.hpp&gt;
 
+#include &lt;ORBVocabulary.h&gt;
 
 namespace ORB_SLAM2
 {
@@ -42,6 +43,7 @@ namespace ORB_SLAM2
 class MapPoint;
 class KeyFrame;
 class KeyFrameDatabase;
+class Frame;
 
 
 /*
@@ -75,6 +77,8 @@ public:
 
     long unsigned int GetMaxKFid();
 
+    void extractVocabulary (ORBVocabulary *cvoc);
+
     void clear();
 
     std::vector&lt;KeyFrame*&gt; mvpKeyFrameOrigins;
@@ -102,9 +106,16 @@ public:
 			numOfReferencePoint;
 	};
 
-	KeyFrame* getNearestKeyFrame (const float &amp;x, const float &amp;y, const float &amp;z, const float fdir_x, const float fdir_y, const float fdir_z);
+//	KeyFrame* getNearestKeyFrame (
+//		const float &amp;x, const float &amp;y, const float &amp;z,
+//		const float fdir_x, const float fdir_y, const float fdir_z,
+//		vector&lt;KeyFrame*&gt; *kfSelectors=NULL);
+	KeyFrame* getNearestKeyFrame (
+		const Eigen::Vector3f &amp;position,
+		const Eigen::Quaternionf &amp;orientation,
+		vector&lt;KeyFrame*&gt; *kfSelectors);
+
 	KeyFrame* offsetKeyframe (KeyFrame* kfSrc, int offset);
-//	KeyFrame* offsetKeyframe (KeyFrame* kfSrc, float offset);
 
 	// These are used for augmented localization
 	std::vector&lt;KeyFrame*&gt; kfListSorted;
@@ -125,6 +136,8 @@ protected:
     pcl::PointCloud&lt;KeyFramePt&gt;::Ptr kfCloud;
     pcl::octree::OctreePointCloudSearch&lt;KeyFramePt&gt;::Ptr kfOctree;
 
+    KeyFrameDatabase *mKeyFrameDb;
+
 };
 
 } //namespace ORB_SLAM
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#ifndef MAP_H
#define MAP_H

#include &lt;set&gt;
#include &lt;string&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;exception&gt;
#include &lt;vector&gt;
#include &lt;map&gt;
#include &lt;mutex&gt;

// For Fast keyframe search
#define PCL_NO_PRECOMPILE
#include &lt;pcl/point_cloud.h&gt;
#include &lt;pcl/octree/octree.h&gt;
#include &lt;pcl/octree/impl/octree_search.hpp&gt;


namespace ORB_SLAM2
{

class MapPoint;
class KeyFrame;
class KeyFrameDatabase;


/*
 * Warning: please do NOT modify this point structure
 * We have observed significant performance reduction.
 */
struct KeyFramePt {
	PCL_ADD_POINT4D;
	ORB_SLAM2::KeyFrame *kf;
	EIGEN_MAKE_ALIGNED_OPERATOR_NEW
} EIGEN_ALIGN16 ;


class Map
{
public:
    Map();

    void AddKeyFrame(KeyFrame* pKF);
    void AddMapPoint(MapPoint* pMP);
    void EraseMapPoint(MapPoint* pMP);
    void EraseKeyFrame(KeyFrame* pKF);
    void SetReferenceMapPoints(const std::vector&lt;MapPoint*&gt; &amp;vpMPs);

    std::vector&lt;KeyFrame*&gt; GetAllKeyFrames();
    std::vector&lt;MapPoint*&gt; GetAllMapPoints();
    std::vector&lt;MapPoint*&gt; GetReferenceMapPoints();

    long unsigned int MapPointsInMap();
    long unsigned  KeyFramesInMap();

    long unsigned int GetMaxKFid();

    void clear();

    std::vector&lt;KeyFrame*&gt; mvpKeyFrameOrigins;

    std::mutex mMutexMapUpdate;

    // This avoid that two points are created simultaneously in separate threads (id conflict)
    std::mutex mMutexPointCreation;


// Map Storage Handlers
    class BadMapFile : public std::exception
	{};
    class MapFileException : public std::exception
	{};

    void saveToDisk (const std::string &amp;filename, KeyFrameDatabase *kfMemDb);
    void loadFromDisk (const std::string &amp;filename, KeyFrameDatabase *kfMemDb=NULL);

	struct MapFileHeader {
		char signature[7];
		long unsigned int
			numOfKeyFrame,
			numOfMapPoint,
			numOfReferencePoint;
	};

	KeyFrame* getNearestKeyFrame (const float &amp;x, const float &amp;y, const float &amp;z, const float fdir_x, const float fdir_y, const float fdir_z);
	KeyFrame* offsetKeyframe (KeyFrame* kfSrc, int offset);
//	KeyFrame* offsetKeyframe (KeyFrame* kfSrc, float offset);

	// These are used for augmented localization
	std::vector&lt;KeyFrame*&gt; kfListSorted;
	std::map&lt;KeyFrame*, int&gt; kfMapSortedId;

	bool mbMapUpdated;

protected:
    std::set&lt;MapPoint*&gt; mspMapPoints;
    std::set&lt;KeyFrame*&gt; mspKeyFrames;

    std::vector&lt;MapPoint*&gt; mvpReferenceMapPoints;

    long unsigned int mnMaxKFid;

    std::mutex mMutexMap;

    pcl::PointCloud&lt;KeyFramePt&gt;::Ptr kfCloud;
    pcl::octree::OctreePointCloudSearch&lt;KeyFramePt&gt;::Ptr kfOctree;

};

} //namespace ORB_SLAM

#endif // MAP_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Optimizer.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Optimizer.h">
				<diff>@@ -21,7 +21,7 @@
 #ifndef OPTIMIZER_H
 #define OPTIMIZER_H
 
-#include &quot;Map.h&quot;
+//#include &quot;Map.h&quot;
 #include &quot;MapPoint.h&quot;
 #include &quot;KeyFrame.h&quot;
 #include &quot;LoopClosing.h&quot;
@@ -33,6 +33,7 @@ namespace ORB_SLAM2
 {
 
 class LoopClosing;
+class Map;
 
 class Optimizer
 {
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#ifndef OPTIMIZER_H
#define OPTIMIZER_H

#include &quot;Map.h&quot;
#include &quot;MapPoint.h&quot;
#include &quot;KeyFrame.h&quot;
#include &quot;LoopClosing.h&quot;
#include &quot;Frame.h&quot;

#include &quot;g2o/types/types_seven_dof_expmap.h&quot;

namespace ORB_SLAM2
{

class LoopClosing;

class Optimizer
{
public:
    void static BundleAdjustment(const std::vector&lt;KeyFrame*&gt; &amp;vpKF, const std::vector&lt;MapPoint*&gt; &amp;vpMP,
                                 int nIterations = 5, bool *pbStopFlag=NULL, const unsigned long nLoopKF=0,
                                 const bool bRobust = true);
    void static GlobalBundleAdjustemnt(Map* pMap, int nIterations=5, bool *pbStopFlag=NULL,
                                       const unsigned long nLoopKF=0, const bool bRobust = true);
    void static LocalBundleAdjustment(KeyFrame* pKF, bool *pbStopFlag, Map *pMap);
    int static PoseOptimization(Frame* pFrame);

    // if bFixScale is true, 6DoF optimization (stereo,rgbd), 7DoF otherwise (mono)
    void static OptimizeEssentialGraph(Map* pMap, KeyFrame* pLoopKF, KeyFrame* pCurKF,
                                       const LoopClosing::KeyFrameAndPose &amp;NonCorrectedSim3,
                                       const LoopClosing::KeyFrameAndPose &amp;CorrectedSim3,
                                       const map&lt;KeyFrame *, set&lt;KeyFrame *&gt; &gt; &amp;LoopConnections,
                                       const bool &amp;bFixScale);

    // if bFixScale is true, optimize SE3 (stereo,rgbd), Sim3 otherwise (mono)
    static int OptimizeSim3(KeyFrame* pKF1, KeyFrame* pKF2, std::vector&lt;MapPoint *&gt; &amp;vpMatches1,
                            g2o::Sim3 &amp;g2oS12, const float th2, const bool bFixScale);
};

} //namespace ORB_SLAM

#endif // OPTIMIZER_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/System.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/System.h">
				<diff>@@ -75,7 +75,9 @@ public:
 		const eSensor sensor,
 		const bool bUseViewer = true,
 		const string &amp;mapFileName=string(),
-		const operationMode mode=System::MAPPING);
+		const operationMode mode=System::MAPPING,
+		bool doOfflineMapping=false
+    );
 
     // Proccess the given stereo frame. Images must be synchronized and rectified.
     // Input images: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.
@@ -139,6 +141,9 @@ public:
 
     const operationMode opMode;
 
+    const bool offlineMapping;
+    float fps;
+
 private:
 
     // Input sensor
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/


#ifndef SYSTEM_H
#define SYSTEM_H

#include&lt;string&gt;
#include&lt;thread&gt;
#include &lt;mutex&gt;
#include&lt;opencv2/core/core.hpp&gt;

#include &quot;Tracking.h&quot;
#include &quot;FrameDrawer.h&quot;
#include &quot;MapDrawer.h&quot;
#include &quot;Map.h&quot;
#include &quot;LocalMapping.h&quot;
#include &quot;LoopClosing.h&quot;
#include &quot;KeyFrameDatabase.h&quot;
#include &quot;ORBVocabulary.h&quot;
#include &quot;Viewer.h&quot;


using std::string;


namespace ORB_SLAM2
{

class Viewer;
class FrameDrawer;
class Map;
class Tracking;
class LocalMapping;
class LoopClosing;

class System
{
public:
    // Input sensor
    enum eSensor{
        MONOCULAR=0,
        STEREO=1,
        RGBD=2
    };

    enum operationMode {
    	MAPPING=0,
		LOCALIZATION=1
    };

public:

    // Initialize the SLAM system. It launches the Local Mapping, Loop Closing and Viewer threads.
    System (
    	const string &amp;strVocFile,
		const string &amp;strSettingsFile,
		const eSensor sensor,
		const bool bUseViewer = true,
		const string &amp;mapFileName=string(),
		const operationMode mode=System::MAPPING);

    // Proccess the given stereo frame. Images must be synchronized and rectified.
    // Input images: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.
    // Returns the camera pose (empty if tracking fails).
    cv::Mat TrackStereo(const cv::Mat &amp;imLeft, const cv::Mat &amp;imRight, const double &amp;timestamp);

    // Process the given rgbd frame. Depthmap must be registered to the RGB frame.
    // Input image: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.
    // Input depthmap: Float (CV_32F).
    // Returns the camera pose (empty if tracking fails).
    cv::Mat TrackRGBD(const cv::Mat &amp;im, const cv::Mat &amp;depthmap, const double &amp;timestamp);

    // Proccess the given monocular frame
    // Input images: RGB (CV_8UC3) or grayscale (CV_8U). RGB is converted to grayscale.
    // Returns the camera pose (empty if tracking fails).
    cv::Mat TrackMonocular(const cv::Mat &amp;im, const double &amp;timestamp);

    // This stops local mapping thread (map building) and performs only camera tracking.
    void ActivateLocalizationMode();
    // This resumes local mapping thread and performs SLAM again.
    void DeactivateLocalizationMode();

    // Reset the system (clear map)
    void Reset();

    // All threads will be requested to finish.
    // It waits until all threads have finished.
    // This function must be called before saving the trajectory.
    void Shutdown();

    // Save camera trajectory in the TUM RGB-D dataset format.
    // Call first Shutdown()
    // See format details at: http://vision.in.tum.de/data/datasets/rgbd-dataset
    void SaveTrajectoryTUM(const string &amp;filename);

    // Save keyframe poses in the TUM RGB-D dataset format.
    // Use this function in the monocular case.
    // Call first Shutdown()
    // See format details at: http://vision.in.tum.de/data/datasets/rgbd-dataset
    void SaveKeyFrameTrajectoryTUM(const string &amp;filename);

    // Save camera trajectory in the KITTI dataset format.
    // Call first Shutdown()
    // See format details at: http://www.cvlibs.net/datasets/kitti/eval_odometry.php
    void SaveTrajectoryKITTI(const string &amp;filename);

    // TODO: Save/Load functions
    // LoadMap () should be called before grabbing image
    void SaveMap(const string &amp;filename);
    void LoadMap(const string &amp;filename);

    // Move retrievable setting here
    cv::FileStorage fsSettings;

    // 'get' resources
    Tracking* getTracker() { return mpTracker; }
    Map* getMap() { return mpMap; }
    LoopClosing* getLoopCloser() { return mpLoopCloser; }
    LocalMapping* getLocalMapper() { return mpLocalMapper; }
    FrameDrawer* getFrameDrawer() { return mpFrameDrawer; }

    const operationMode opMode;

private:

    // Input sensor
    eSensor mSensor;

    // ORB vocabulary used for place recognition and feature matching.
    ORBVocabulary* mpVocabulary;

    // KeyFrame database for place recognition (relocalization and loop detection).
    KeyFrameDatabase* mpKeyFrameDatabase;

    // Map structure that stores the pointers to all KeyFrames and MapPoints.
    Map* mpMap;
    const string &amp;mapFileName;

    // Tracker. It receives a frame and computes the associated camera pose.
    // It also decides when to insert a new keyframe, create some new MapPoints and
    // performs relocalization if tracking fails.
    Tracking* mpTracker;

    // Local Mapper. It manages the local map and performs local bundle adjustment.
    LocalMapping* mpLocalMapper;

    // Loop Closer. It searches loops with every new keyframe. If there is a loop it performs
    // a pose graph optimization and full bundle adjustment (in a new thread) afterwards.
    LoopClosing* mpLoopCloser;

    // The viewer draws the map and the current camera pose. It uses Pangolin.
    Viewer* mpViewer;

    FrameDrawer* mpFrameDrawer;
    MapDrawer* mpMapDrawer;

    // System threads: Local Mapping, Loop Closing, Viewer.
    // The Tracking thread &quot;lives&quot; in the main execution thread that creates the System object.
    std::thread* mptLocalMapping;
    std::thread* mptLoopClosing;
    std::thread* mptViewer;

    // Reset flag
    std::mutex mMutexReset;
    bool mbReset;

    // Change mode flags
    std::mutex mMutexMode;
    bool mbActivateLocalizationMode;
    bool mbDeactivateLocalizationMode;
};

}// namespace ORB_SLAM

#endif // SYSTEM_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Tracking.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/include/Tracking.h">
				<diff>@@ -25,6 +25,8 @@
 #include&lt;opencv2/core/core.hpp&gt;
 #include&lt;opencv2/features2d/features2d.hpp&gt;
 
+#include &lt;Eigen/Geometry&gt;
+
 #include&quot;Viewer.h&quot;
 #include&quot;FrameDrawer.h&quot;
 #include&quot;Map.h&quot;
@@ -40,6 +42,10 @@
 
 #include &lt;mutex&gt;
 
+
+typedef Eigen::Transform&lt;float,3,Eigen::Affine&gt; Transform3;
+
+
 namespace ORB_SLAM2
 {
 
@@ -62,6 +68,8 @@ public:
     cv::Mat GrabImageRGBD(const cv::Mat &amp;imRGB,const cv::Mat &amp;imD, const double &amp;timestamp);
     cv::Mat GrabImageMonocular(const cv::Mat &amp;im, const double &amp;timestamp);
 
+    Transform3 LocalizeImage (const cv::Mat &amp;image, const double &amp;timestamp);
+
     void SetLocalMapper(LocalMapping* pLocalMapper);
     void SetLoopClosing(LoopClosing* pLoopClosing);
     void SetViewer(Viewer* pViewer);
@@ -160,7 +168,12 @@ protected:
     void UpdateLastFrame();
     bool TrackWithMotionModel();
 
-    bool Relocalization();
+    enum RelocalizationMode {
+    	SEARCH_DB = 1,
+		SEARCH_MAPPING = 2,
+		SEARCH_LOCAL_MAP = 3
+    };
+    bool Relocalization (RelocalizationMode=SEARCH_DB);
 
     void UpdateLocalMap();
     void UpdateLocalPoints();
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/


#ifndef TRACKING_H
#define TRACKING_H

#include&lt;opencv2/core/core.hpp&gt;
#include&lt;opencv2/features2d/features2d.hpp&gt;

#include&quot;Viewer.h&quot;
#include&quot;FrameDrawer.h&quot;
#include&quot;Map.h&quot;
#include&quot;LocalMapping.h&quot;
#include&quot;LoopClosing.h&quot;
#include&quot;Frame.h&quot;
#include &quot;ORBVocabulary.h&quot;
#include&quot;KeyFrameDatabase.h&quot;
#include&quot;ORBextractor.h&quot;
#include &quot;Initializer.h&quot;
#include &quot;MapDrawer.h&quot;
#include &quot;System.h&quot;

#include &lt;mutex&gt;

namespace ORB_SLAM2
{

class Viewer;
class FrameDrawer;
class Map;
class LocalMapping;
class LoopClosing;
class System;

class Tracking
{  

public:
    Tracking(System* pSys, ORBVocabulary* pVoc, FrameDrawer* pFrameDrawer, MapDrawer* pMapDrawer, Map* pMap,
             KeyFrameDatabase* pKFDB, const string &amp;strSettingPath, const int sensor);

    // Preprocess the input and call Track(). Extract features and performs stereo matching.
    cv::Mat GrabImageStereo(const cv::Mat &amp;imRectLeft,const cv::Mat &amp;imRectRight, const double &amp;timestamp);
    cv::Mat GrabImageRGBD(const cv::Mat &amp;imRGB,const cv::Mat &amp;imD, const double &amp;timestamp);
    cv::Mat GrabImageMonocular(const cv::Mat &amp;im, const double &amp;timestamp);

    void SetLocalMapper(LocalMapping* pLocalMapper);
    void SetLoopClosing(LoopClosing* pLoopClosing);
    void SetViewer(Viewer* pViewer);

    // Load new settings
    // The focal length should be similar or scale prediction will fail when projecting points
    // TODO: Modify MapPoint::PredictScale to take into account focal length
    void ChangeCalibration(const string &amp;strSettingPath);
    void ChangeCalibration(const double fx, const double fy, const double cx, const double cy);

    // Use this function if you have deactivated local mapping and you only want to localize the camera.
    void InformOnlyTracking(const bool &amp;flag);

    void setMapLoaded ();

    // XXX: Stub
    KeyFrame* getNearestKeyFrame()
    { return mpLastKeyFrame; }

    inline void setFps (int f)
    {  mMaxFrames = f; }

public:

    // Tracking states
    enum eTrackingState{
        SYSTEM_NOT_READY=-1,
        NO_IMAGES_YET=0,
        NOT_INITIALIZED=1,
        OK=2,
        LOST=3,
		MAP_OPEN=4
    };

    enum trackingMode {
    	RELOCALIZATION = 0,
		TRACK_WITH_MOTION_MODEL = 1,
		TRACK_REFERENCE_KEYFRAME = 2,
		TRACK_LOCAL_MAP = 3
    };

    eTrackingState mState;
    eTrackingState mLastProcessedState;

    // Input sensor
    int mSensor;

    // Current Frame
    Frame mCurrentFrame;
    cv::Mat mImGray;

    // Initialization Variables (Monocular)
    std::vector&lt;int&gt; mvIniLastMatches;
    std::vector&lt;int&gt; mvIniMatches;
    std::vector&lt;cv::Point2f&gt; mvbPrevMatched;
    std::vector&lt;cv::Point3f&gt; mvIniP3D;
    Frame mInitialFrame;

    // Lists used to recover the full camera trajectory at the end of the execution.
    // Basically we store the reference keyframe for each frame and its relative transformation
    list&lt;cv::Mat&gt; mlRelativeFramePoses;
    list&lt;KeyFrame*&gt; mlpReferences;
    list&lt;double&gt; mlFrameTimes;
    list&lt;bool&gt; mlbLost;

    // True if local mapping is deactivated and we are performing only localization
    bool mbOnlyTracking;

    void Reset();

    // used when offline
    LocalMapping *mLocalMapper;
    LoopClosing *mLoopCloser;

    trackingMode lastTrackingMode;

    bool trackingIsGood() const
    {return mLastProcessedState==ORB_SLAM2::Tracking::OK and !mCurrentFrame.mTcw.empty(); }

protected:

    // Main tracking function. It is independent of the input sensor.
    void Track();

    // Map initialization for stereo and RGB-D
    void StereoInitialization();

    void MapOpenMonocularInitialization();

    // Map initialization for monocular
    void MonocularInitialization();
    void CreateInitialMapMonocular();

    void CheckReplacedInLastFrame();
    bool TrackReferenceKeyFrame();
    void UpdateLastFrame();
    bool TrackWithMotionModel();

    bool Relocalization();

    void UpdateLocalMap();
    void UpdateLocalPoints();
    void UpdateLocalKeyFrames();

    bool TrackLocalMap();
    void SearchLocalPoints();

    bool NeedNewKeyFrame();
    void CreateNewKeyFrame();

    // In case of performing only localization, this flag is true when there are no matches to
    // points in the map. Still tracking will continue if there are enough matches with temporal points.
    // In that case we are doing visual odometry. The system will try to do relocalization to recover
    // &quot;zero-drift&quot; localization to the map.
    bool mbVO;

    //Other Thread Pointers
    LocalMapping* mpLocalMapper;
    LoopClosing* mpLoopClosing;

    //ORB
    ORBextractor* mpORBextractorLeft, *mpORBextractorRight;
    ORBextractor* mpIniORBextractor;

    //BoW
    ORBVocabulary* mpORBVocabulary;
    KeyFrameDatabase* mpKeyFrameDB;

    // Initalization (only for monocular)
    Initializer* mpInitializer;

    //Local Map
    KeyFrame* mpReferenceKF;
    std::vector&lt;KeyFrame*&gt; mvpLocalKeyFrames;
    std::vector&lt;MapPoint*&gt; mvpLocalMapPoints;
    
    // System
    System* mpSystem;
    
    //Drawers
    Viewer* mpViewer;
    FrameDrawer* mpFrameDrawer;
    MapDrawer* mpMapDrawer;

    //Map
    Map* mpMap;

    //Calibration matrix
    cv::Mat mK;
    cv::Mat mDistCoef;
    float mbf;

    //New KeyFrame rules (according to fps)
    int mMinFrames;
    int mMaxFrames;

    // Threshold close/far points
    // Points seen as close by the stereo/RGBD sensor are considered reliable
    // and inserted from just one frame. Far points requiere a match in two keyframes.
    float mThDepth;

    // For RGB-D inputs only. For some datasets (e.g. TUM) the depthmap values are scaled.
    float mDepthMapFactor;

    //Current matches in frame
    int mnMatchesInliers;

    //Last Frame, KeyFrame and Relocalisation Info
    KeyFrame* mpLastKeyFrame;
    Frame mLastFrame;
    unsigned int mnLastKeyFrameId;
    unsigned int mnLastRelocFrameId;

    //Motion Model
    cv::Mat mVelocity;

    //Color order (true RGB, false BGR, ignored if grayscale)
    bool mbRGB;

    list&lt;MapPoint*&gt; mlpTemporalPoints;

    int
		// Working resolution
		imageWorkWidth,
		imageWorkHeight,
		// ROI
		ROIx0,
		ROIy0,
		ROIwidth,
		ROIheight;
};

} //namespace ORB_SLAM

#endif // TRACKING_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/common.cpp" new_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/common.cpp">
				<diff>@@ -5,6 +5,7 @@
 #include &lt;iostream&gt;
 #include &lt;exception&gt;
 #include &quot;common.h&quot;
+#include &quot;Converter.h&quot;
 
 
 #define foreach BOOST_FOREACH
@@ -13,6 +14,66 @@
 using std::cout;
 using std::endl;
 using std::exception;
+using ORB_SLAM2::KeyFrame;
+
+
+void equalizeImageHistogramFromMask (cv::Mat &amp;input, cv::Mat &amp;output, cv::Mat &amp;mask)
+{
+	cv::Mat LUT = cv::Mat::zeros(1, 256, CV_8U);
+	cv::MatND hist;
+	int histSize = 256;
+	float range[] = {0,255};
+	const float *ranges[] = {range};
+//	uint8_t
+	cv::calcHist (&amp;input, 1, 0, mask, hist, 1, &amp;histSize, ranges, true, false);
+
+	int i=0;
+	while (!hist.at&lt;uint8_t&gt;(i))
+		i++;
+	int total = (int)input.total();
+
+	int miz=(int)hist.at&lt;float&gt;(i);
+	float scale = 255.0f / (total-miz);
+	int sum = 0;
+	for (LUT.at&lt;uchar&gt;(i++)=0; i&lt;256; ++i) {
+		sum += (int)hist.at&lt;float&gt;(i);
+		LUT.at&lt;uchar&gt;(i) = cv::saturate_cast&lt;uchar&gt;(sum * scale);
+	}
+
+	cv::LUT(input, LUT, output);
+//	cv::equalizeHist(output, output);
+}
+
+
+float detectCcdSmear (cv::Mat &amp;colorInput)
+{
+	// 1. Convert image to HSV and take V channel -&gt; V
+	cv::Mat imgHsv, V;
+	cv::cvtColor(colorInput, imgHsv, CV_BGR2HSV);
+	cv::extractChannel(imgHsv, V, 2);
+	// 2. Normalize V
+	V.convertTo(V, CV_32F);
+	V /= 255.0;
+	// Sum all elements of V per column
+	cv::Mat tv = cv::Mat::zeros(V.cols, 1, CV_32F);
+	for (int i=0; i&lt;V.cols; i++) {
+		tv.at&lt;float&gt;(i) = cv::sum(V.col(i))[0];
+	}
+	tv /= (float)V.rows;
+	// Count number of columns that are out of range
+	const float th = 0.1;
+	int nc = 0;
+	for (int i=0; i&lt;V.cols; i++) {
+		if (tv.at&lt;float&gt;(i) &gt;= 1.0-th)
+			nc += 1;
+	}
+	// done
+	if (nc &lt; 2)
+		return -1;
+	else return 1.0;
+	// XXX: how to quantize nc to scale 0~1.0 ?
+}
+
 
 
 void tfToCV(const tf::Transform &amp;src, cv::Mat &amp;position, cv::Mat &amp;orientation)
@@ -80,3 +141,53 @@ tf::Transform FramePose (ORB_SLAM2::Frame *cframe)
 
 	return tf::Transform(M, V);
 }
+
+
+tf::Transform KeyFramePoseToTf (KeyFrame *kf)
+{
+	tf::Transform kfpose;
+
+	cv::Mat t = kf-&gt;GetCameraCenter();
+	cv::Mat orient = kf-&gt;GetRotation().t();
+	Eigen::Quaterniond q = ORB_SLAM2::Converter::toQuaternion(orient);
+
+	kfpose.setOrigin(tf::Vector3(t.at&lt;float&gt;(0), t.at&lt;float&gt;(1), t.at&lt;float&gt;(2)));
+	kfpose.setRotation(tf::Quaternion(q.x(), q.y(), q.z(), q.w()));
+
+	return kfpose;
+}
+
+
+tf::Transform getKeyFrameExtPose (const KeyFrame *kf)
+{
+	tf::Transform Ext;
+
+	if (kf-&gt;extPosition.empty() or kf-&gt;extOrientation.empty()) {
+		Ext.setOrigin(tf::Vector3(NAN, NAN, NAN));
+		Ext.setRotation(tf::Quaternion(NAN, NAN, NAN, NAN));
+	}
+
+	else {
+		Ext.setOrigin (tf::Vector3(
+			kf-&gt;extPosition.at&lt;double&gt;(0),
+			kf-&gt;extPosition.at&lt;double&gt;(1),
+			kf-&gt;extPosition.at&lt;double&gt;(2) ));
+		Ext.setRotation(tf::Quaternion(
+			kf-&gt;extOrientation.at&lt;double&gt;(0),
+			kf-&gt;extOrientation.at&lt;double&gt;(1),
+			kf-&gt;extOrientation.at&lt;double&gt;(2),
+			kf-&gt;extOrientation.at&lt;double&gt;(3) ));
+	}
+	return Ext;
+}
+
+
+cv::Vec3d
+tfToCv (const tf::Vector3 &amp;pos)
+{
+	cv::Vec3d cvVec;
+	cvVec[0] = pos.x();
+	cvVec[1] = pos.y();
+	cvVec[2] = pos.z();
+	return cvVec;
+}
</diff>
				<old_file>#include &lt;boost/foreach.hpp&gt;
#include &lt;rosbag/view.h&gt;
#include &lt;tf/tfMessage.h&gt;
#include &lt;geometry_msgs/TransformStamped.h&gt;
#include &lt;iostream&gt;
#include &lt;exception&gt;
#include &quot;common.h&quot;


#define foreach BOOST_FOREACH


using std::cout;
using std::endl;
using std::exception;


void tfToCV(const tf::Transform &amp;src, cv::Mat &amp;position, cv::Mat &amp;orientation)
{
	position = cv::Mat (3,1,CV_64F);
	tf::Vector3 p = src.getOrigin();
	position.at&lt;double&gt;(0) = p.x(),
		position.at&lt;double&gt;(1) = p.y(),
		position.at&lt;double&gt;(2) = p.z();

	orientation = cv::Mat (4,1,CV_64F);
	tf::Quaternion otn = src.getRotation();
	orientation.at&lt;double&gt;(0) = otn.x(),
		orientation.at&lt;double&gt;(1) = otn.y(),
		orientation.at&lt;double&gt;(2) = otn.z(),
		orientation.at&lt;double&gt;(3) = otn.w();
}


void recomputeNewCameraParameter (
	// Original
	double fx1, double fy1, double cx1, double cy1,
	// New
	double &amp;fx2, double &amp;fy2, double &amp;cx2, double &amp;cy2,
	int width1, int height1,
	int width2, int height2
)
{
	double ratio = (double)width1 / (double)width2;
	fx2 = fx1 / ratio;
	fy2 = fy1 / ratio;
	cx2 = cx1 / ratio;
	cy2 = cy1 / ratio;
}


void tf2positiondirection (const tf::Transform &amp;pose, float positiondirection[6])
{
	// position
	positiondirection[0] = pose.getOrigin().x();
	positiondirection[1] = pose.getOrigin().y();
	positiondirection[2] = pose.getOrigin().z();
	float fdirx = pose.getRotation().x(),
		fdiry = pose.getRotation().y(),
		fdirz = pose.getRotation().z(),
		fdirnorm;
	fdirnorm = sqrtf(fdirx*fdirx + fdiry*fdiry + fdirz*fdirz);
	fdirx /= fdirnorm;
	fdiry /= fdirnorm;
	fdirz /= fdirnorm;
	positiondirection[3] = fdirx;
	positiondirection[4] = fdiry;
	positiondirection[5] = fdirz;
}


tf::Transform FramePose (ORB_SLAM2::Frame *cframe)
{
	cv::Mat Rwc = cframe-&gt;mTcw.rowRange(0,3).colRange(0,3).t();
	cv::Mat twc = -Rwc * cframe-&gt;mTcw.rowRange(0,3).col(3);
	tf::Matrix3x3 M(Rwc.at&lt;float&gt;(0,0),Rwc.at&lt;float&gt;(0,1),Rwc.at&lt;float&gt;(0,2),
					Rwc.at&lt;float&gt;(1,0),Rwc.at&lt;float&gt;(1,1),Rwc.at&lt;float&gt;(1,2),
					Rwc.at&lt;float&gt;(2,0),Rwc.at&lt;float&gt;(2,1),Rwc.at&lt;float&gt;(2,2));
	tf::Vector3 V(twc.at&lt;float&gt;(0), twc.at&lt;float&gt;(1), twc.at&lt;float&gt;(2));

	return tf::Transform(M, V);
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/common.h" new_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/common.h">
				<diff>@@ -2,6 +2,10 @@
 #ifndef _ORB_UTILS_H
 #define _ORB_UTILS_H 1
 
+#include &lt;opencv2/core/core.hpp&gt;
+#include &lt;opencv2/imgproc/imgproc.hpp&gt;
+#include &lt;opencv2/highgui/highgui.hpp&gt;
+
 #include &lt;tf/tf.h&gt;
 #include &lt;opencv2/core/core.hpp&gt;
 #include &lt;rosbag/bag.h&gt;
@@ -9,6 +13,7 @@
 #include &lt;vector&gt;
 #include &lt;exception&gt;
 #include &quot;Frame.h&quot;
+#include &quot;KeyFrame.h&quot;
 
 
 using std::string;
@@ -30,5 +35,34 @@ void tf2positiondirection (const tf::Transform &amp;pose, float positiondirection[6]
 
 tf::Transform FramePose (ORB_SLAM2::Frame *cframe);
 
+void equalizeImageHistogramFromMask (cv::Mat &amp;input, cv::Mat &amp;output, cv::Mat &amp;mask);
+
+float detectCcdSmear (cv::Mat &amp;colorInput);
+
+// Keyframe positions
+tf::Transform KeyFramePoseToTf (ORB_SLAM2::KeyFrame *kf);
+tf::Transform getKeyFrameExtPose (const ORB_SLAM2::KeyFrame *kf);
+
+cv::Vec3d tfToCv (const tf::Vector3 &amp;pos);
+
+
+
+class OrbException: public exception
+{
+public:
+	inline OrbException (const string &amp;s):
+		msg(s)
+	{}
+
+	inline const char *what() const noexcept
+	{ return msg.c_str(); }
+
+protected:
+	string msg;
+};
+
+
+
+
 
 #endif /* _ORB_UTILS_H */
</diff>
				<old_file>
#ifndef _ORB_UTILS_H
#define _ORB_UTILS_H 1

#include &lt;tf/tf.h&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;rosbag/bag.h&gt;
#include &lt;string&gt;
#include &lt;vector&gt;
#include &lt;exception&gt;
#include &quot;Frame.h&quot;


using std::string;
using std::vector;
using std::exception;


void tfToCV(const tf::Transform &amp;src, cv::Mat &amp;position, cv::Mat &amp;orientation);
void recomputeNewCameraParameter (
	// Original
	double fx1, double fy1, double cx1, double cy1,
	// New
	double &amp;fx2, double &amp;fy2, double &amp;cx2, double &amp;cy2,
	int width1, int height1,
	int width2, int height2
);

void tf2positiondirection (const tf::Transform &amp;pose, float positiondirection[6]);

tf::Transform FramePose (ORB_SLAM2::Frame *cframe);


#endif /* _ORB_UTILS_H */
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/dumpmap/dumpmap.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/dumpmap/dumpmap.cc">
				<diff>@@ -9,12 +9,38 @@
 #include &lt;iostream&gt;
 #include &quot;Map.h&quot;
 #include &quot;KeyFrame.h&quot;
+#include &quot;MapPoint.h&quot;
 #include &quot;Converter.h&quot;
+#include &quot;ORBVocabulary.h&quot;
 
 
 using namespace std;
 using ORB_SLAM2::Map;
 using ORB_SLAM2::KeyFrame;
+using ORB_SLAM2::MapPoint;
+
+
+const string mapvoc = &quot;/tmp/orbvocz.txt&quot;;
+
+
+void dumpVocabularyX (const ORB_SLAM2::Map &amp;Map, const string &amp;resultingVocTextfile)
+{
+	ORB_SLAM2::ORBVocabulary mapVoc(10, 6);
+	vector&lt;vector&lt;DBoW2::FORB::TDescriptor&gt; &gt; keymapFeatures;
+	keymapFeatures.reserve(Map.kfListSorted.size());
+
+	vector&lt;KeyFrame*&gt; allKeyFrames = Map.kfListSorted;
+	for (vector&lt;KeyFrame*&gt;::const_iterator it=allKeyFrames.begin(); it!=allKeyFrames.end(); it++) {
+
+		KeyFrame *kf = *it;
+		vector&lt;cv::Mat&gt; vCurrentDesc = ORB_SLAM2::Converter::toDescriptorVector(kf-&gt;mDescriptors);
+
+		keymapFeatures.push_back(vCurrentDesc);
+	}
+
+	mapVoc.create(keymapFeatures);
+	mapVoc.saveToTextFile(resultingVocTextfile);
+}
 
 
 int main (int argc, char **argv)
@@ -33,21 +59,43 @@ int main (int argc, char **argv)
 
 		KeyFrame *kf = *it;
 		cv::Mat pos = kf-&gt;GetCameraCenter();
+		const float
+			x = pos.at&lt;float&gt;(0),
+			y = pos.at&lt;float&gt;(1),
+			z = pos.at&lt;float&gt;(2);
+
 		cv::Mat orient = kf-&gt;GetRotation().t();
-		vector&lt;float&gt; q = ORB_SLAM2::Converter::toQuaternion(orient);
+		Eigen::Quaterniond q = ORB_SLAM2::Converter::toQuaternion(orient);
+
 
 //		cout &lt;&lt; kf-&gt;mnId &lt;&lt; &quot; &quot;;
-        cout &lt;&lt; std::fixed &lt;&lt; setprecision(6) &lt;&lt; kf-&gt;mTimeStamp
-        		&lt;&lt; setprecision(7) &lt;&lt; &quot; &quot; &lt;&lt; pos.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; pos.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; pos.at&lt;float&gt;(2)
-          &lt;&lt; &quot; &quot; &lt;&lt; q[0] &lt;&lt; &quot; &quot; &lt;&lt; q[1] &lt;&lt; &quot; &quot; &lt;&lt; q[2] &lt;&lt; &quot; &quot; &lt;&lt; q[3];
+        cout &lt;&lt; std::fixed &lt;&lt; setprecision(6) &lt;&lt;
+        		// First column: timestamp
+        		kf-&gt;mnId &lt;&lt; &quot; &quot;
+        		&lt;&lt; kf-&gt;mTimeStamp
+        		&lt;&lt; setprecision(7) &lt;&lt; &quot; &quot;
+				// Columns 1-3: ORB coordinate
+				&lt;&lt; pos.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; pos.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; pos.at&lt;float&gt;(2)
+				&lt;&lt; &quot; &quot;
+				// Columns 4-7: ORB Orientation in quaternion
+				&lt;&lt; q.x() &lt;&lt; &quot; &quot; &lt;&lt; q.y() &lt;&lt; &quot; &quot; &lt;&lt; q.z() &lt;&lt; &quot; &quot; &lt;&lt; q.w();
         if (kf-&gt;extPosition.empty()) {
         	cout &lt;&lt; &quot; x x x x x x x &quot;;
         }
         else {
-			cout &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extPosition.at&lt;double&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extPosition.at&lt;double&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extPosition.at&lt;double&gt;(2);
-			cout &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(2) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(3);
+			cout &lt;&lt; &quot; &quot;
+				// Columns 8-10: Reference coordinate
+				&lt;&lt; kf-&gt;extPosition.at&lt;double&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extPosition.at&lt;double&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extPosition.at&lt;double&gt;(2);
+			cout &lt;&lt; &quot; &quot;
+				// Columns 11-14: Reference orientation in quaternion
+				&lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(2) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(3);
         }
 		cout &lt;&lt; endl;
 
 	}
+
+//	cerr &lt;&lt; &quot;Saving vocabulary to &quot; &lt;&lt; mapvoc &lt;&lt; endl;
+//	dumpVocabulary(World, mapvoc);
+
+	return 0;
 }
</diff>
				<old_file>/*
 * dumpmap.cc
 *
 *  Created on: Nov 27, 2015
 *      Author: sujiwo
 */

#include &lt;string&gt;
#include &lt;iostream&gt;
#include &quot;Map.h&quot;
#include &quot;KeyFrame.h&quot;
#include &quot;Converter.h&quot;


using namespace std;
using ORB_SLAM2::Map;
using ORB_SLAM2::KeyFrame;


int main (int argc, char **argv)
{
	string mapfile (argv[1]);
	ORB_SLAM2::Map World;
	World.loadFromDisk (mapfile);

	vector&lt;KeyFrame*&gt; allKeyFrames = World.kfListSorted;

	cout &lt;&lt; std::fixed &lt;&lt; setprecision(7);
//	cout &lt;&lt; &quot;First keyframe time: &quot; &lt;&lt; allKeyFrames[0]-&gt;mTimeStamp &lt;&lt; endl;
//	cout &lt;&lt; &quot;Last keyframe time: &quot; &lt;&lt; allKeyFrames.back()-&gt;mTimeStamp &lt;&lt; endl;

	for (vector&lt;KeyFrame*&gt;::const_iterator it=allKeyFrames.begin(); it!=allKeyFrames.end(); it++) {

		KeyFrame *kf = *it;
		cv::Mat pos = kf-&gt;GetCameraCenter();
		cv::Mat orient = kf-&gt;GetRotation().t();
		vector&lt;float&gt; q = ORB_SLAM2::Converter::toQuaternion(orient);

//		cout &lt;&lt; kf-&gt;mnId &lt;&lt; &quot; &quot;;
        cout &lt;&lt; std::fixed &lt;&lt; setprecision(6) &lt;&lt; kf-&gt;mTimeStamp
        		&lt;&lt; setprecision(7) &lt;&lt; &quot; &quot; &lt;&lt; pos.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; pos.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; pos.at&lt;float&gt;(2)
          &lt;&lt; &quot; &quot; &lt;&lt; q[0] &lt;&lt; &quot; &quot; &lt;&lt; q[1] &lt;&lt; &quot; &quot; &lt;&lt; q[2] &lt;&lt; &quot; &quot; &lt;&lt; q[3];
        if (kf-&gt;extPosition.empty()) {
        	cout &lt;&lt; &quot; x x x x x x x &quot;;
        }
        else {
			cout &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extPosition.at&lt;double&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extPosition.at&lt;double&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extPosition.at&lt;double&gt;(2);
			cout &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(2) &lt;&lt; &quot; &quot; &lt;&lt; kf-&gt;extOrientation.at&lt;double&gt;(3);
        }
		cout &lt;&lt; endl;

	}
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/orb_mapping/orb_mapping.cpp" new_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/orb_mapping/orb_mapping.cpp">
				<diff>@@ -32,21 +32,15 @@ namespace enc = sensor_msgs::image_encodings;
 class ORB_Mapper
 {
 public:
-	ORB_Mapper (ORB_SLAM2::System&amp; pSL, ros::NodeHandle &amp;nh) :
+	ORB_Mapper (ORB_SLAM2::System&amp; pSL, ros::NodeHandle &amp;nh, int fps_=10) :
 		SLAMSystem (pSL),
 		rosnode (nh),
 		extListener (NULL),
 		lastImageTimestamp (0.0),
-//		doStop (false),
-		externalLocalizerThread (NULL),
+		doStop (false),
+		fps (fps_),
 		gotFirstFrame (false)
 	{
-		externalFrameFixed = (string)pSL.fsSettings[&quot;ExternalReference.Mapping.frame1&quot;];
-		externalFrameMoving = (string)pSL.fsSettings[&quot;ExternalReference.Mapping.frame2&quot;];
-
-		// TF Listener
-//		externalLocalizerThread = new std::thread (&amp;ORB_Mapper::externalLocalizerGrab, this);
-
 		// Image Subscription
 	    if ((int)SLAMSystem.fsSettings[&quot;Camera.compressed&quot;]==0) {
 	    	th = image_transport::TransportHints (&quot;raw&quot;);
@@ -57,7 +51,6 @@ public:
 		imageBuf = new image_transport::ImageTransport(rosnode);
 //		imageSub = imageBuf-&gt;subscribe((string)SLAMSystem.fsSettings[&quot;Camera.topic&quot;], 1, &amp;ORB_Mapper::imageCallback, this, th);
 
-		// XXX: put topic name into ros parameter
 		string groundTruthPose;
 		rosnode.getParam(&quot;external_localization_topic&quot;, groundTruthPose);
 		poseSub = rosnode.subscribe (groundTruthPose, 2, &amp;ORB_Mapper::poseCallback, this);
@@ -72,34 +65,14 @@ public:
 	}
 
 
-//	void externalLocalizerGrab ()
-//	{
-//		if (extListener==NULL)
-//			extListener = new tf::TransformListener ();
-//
-//		ros::Rate fps((int)SLAMSystem.fsSettings[&quot;Camera.fps&quot;] * 2);
-//
-//		while (ros::ok()) {
-//
-//			if (doStop == true)
-//				break;
-//
-//			try {
-//
-//				extListener-&gt;lookupTransform (externalFrameFixed, externalFrameMoving, ros::Time(0), extPose);
-//				unique_lock&lt;mutex&gt; lock(ORB_SLAM2::KeyFrame::extPoseMutex);
-//				tfToCV (extPose, ORB_SLAM2::KeyFrame::extEgoPosition, ORB_SLAM2::KeyFrame::extEgoOrientation);
-//
-//			} catch (tf::TransformException &amp;e) {
-//
-//				unique_lock&lt;mutex&gt; lock(ORB_SLAM2::KeyFrame::extPoseMutex);
-//				ORB_SLAM2::KeyFrame::extEgoPosition.release();
-//				ORB_SLAM2::KeyFrame::extEgoOrientation.release();
-//
-//			}
-//			fps.sleep();
-//		}
-//	}
+	void slamFeeder ()
+	{
+		ros::Rate hzs (fps);
+
+		while (doStop==false) {
+			hzs.sleep();
+		}
+	}
 
 
 	void poseCallback (const geometry_msgs::PoseStampedConstPtr &amp;cpose)
@@ -210,20 +183,25 @@ private:
 	ORB_SLAM2::System &amp;SLAMSystem;
 	ros::Subscriber poseSub;
 
-	string externalFrameFixed;
-	string externalFrameMoving;
+//	string externalFrameFixed;
+//	string externalFrameMoving;
 
 	double lastImageTimestamp;
 	bool gotFirstFrame;
 
+	int fps;
+
+	mutex mtxCImage;
+	cv::Mat currentImage;
+
 public:
-//	volatile bool doStop;
+	volatile bool doStop;
 
 	image_transport::TransportHints th;
 	image_transport::ImageTransport *imageBuf;
 	image_transport::Subscriber imageSub;
 
-	thread *externalLocalizerThread;
+	thread slamFeederT;
 
 };
 
@@ -257,10 +235,10 @@ int main (int argc, char *argv[])
 
 	string imageTopic;
 	nodeHandler.getParam(&quot;image_topic&quot;, imageTopic);
-	Mapper.imageSub = Mapper.imageBuf-&gt;subscribe (imageTopic, 1,  &amp;ORB_Mapper::imageCallback, &amp;Mapper, Mapper.th);
+	Mapper.imageSub = Mapper.imageBuf-&gt;subscribe (imageTopic, 100,  &amp;ORB_Mapper::imageCallback, &amp;Mapper, Mapper.th);
 
 	ros::spin();
-//    Mapper.doStop = true;
+    Mapper.doStop = true;
 //    Mapper.externalLocalizerThread-&gt;join();
 
     ros::shutdown();
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  XXX: Licensing has not been cleared yet.
*/

#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;thread&gt;

#include &lt;ros/ros.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;image_transport/image_transport.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &quot;boost/date_time/posix_time/posix_time.hpp&quot;

#include &quot;System.h&quot;
#include &quot;../common.h&quot;


using namespace std;
using namespace ORB_SLAM2;
using namespace boost::posix_time;
namespace enc = sensor_msgs::image_encodings;


class ORB_Mapper
{
public:
	ORB_Mapper (ORB_SLAM2::System&amp; pSL, ros::NodeHandle &amp;nh) :
		SLAMSystem (pSL),
		rosnode (nh),
		extListener (NULL),
		lastImageTimestamp (0.0),
//		doStop (false),
		externalLocalizerThread (NULL),
		gotFirstFrame (false)
	{
		externalFrameFixed = (string)pSL.fsSettings[&quot;ExternalReference.Mapping.frame1&quot;];
		externalFrameMoving = (string)pSL.fsSettings[&quot;ExternalReference.Mapping.frame2&quot;];

		// TF Listener
//		externalLocalizerThread = new std::thread (&amp;ORB_Mapper::externalLocalizerGrab, this);

		// Image Subscription
	    if ((int)SLAMSystem.fsSettings[&quot;Camera.compressed&quot;]==0) {
	    	th = image_transport::TransportHints (&quot;raw&quot;);
	    }
	    else if ((int)SLAMSystem.fsSettings[&quot;Camera.compressed&quot;]==1) {
	    	th = image_transport::TransportHints (&quot;compressed&quot;);
	    }
		imageBuf = new image_transport::ImageTransport(rosnode);
//		imageSub = imageBuf-&gt;subscribe((string)SLAMSystem.fsSettings[&quot;Camera.topic&quot;], 1, &amp;ORB_Mapper::imageCallback, this, th);

		// XXX: put topic name into ros parameter
		string groundTruthPose;
		rosnode.getParam(&quot;external_localization_topic&quot;, groundTruthPose);
		poseSub = rosnode.subscribe (groundTruthPose, 2, &amp;ORB_Mapper::poseCallback, this);
	}


	~ORB_Mapper ()
	{
		delete (imageBuf);
		if (extListener != NULL)
			delete (extListener);
	}


//	void externalLocalizerGrab ()
//	{
//		if (extListener==NULL)
//			extListener = new tf::TransformListener ();
//
//		ros::Rate fps((int)SLAMSystem.fsSettings[&quot;Camera.fps&quot;] * 2);
//
//		while (ros::ok()) {
//
//			if (doStop == true)
//				break;
//
//			try {
//
//				extListener-&gt;lookupTransform (externalFrameFixed, externalFrameMoving, ros::Time(0), extPose);
//				unique_lock&lt;mutex&gt; lock(ORB_SLAM2::KeyFrame::extPoseMutex);
//				tfToCV (extPose, ORB_SLAM2::KeyFrame::extEgoPosition, ORB_SLAM2::KeyFrame::extEgoOrientation);
//
//			} catch (tf::TransformException &amp;e) {
//
//				unique_lock&lt;mutex&gt; lock(ORB_SLAM2::KeyFrame::extPoseMutex);
//				ORB_SLAM2::KeyFrame::extEgoPosition.release();
//				ORB_SLAM2::KeyFrame::extEgoOrientation.release();
//
//			}
//			fps.sleep();
//		}
//	}


	void poseCallback (const geometry_msgs::PoseStampedConstPtr &amp;cpose)
	{
//		printf (&quot;%f %f %f\n&quot;, cpose-&gt;pose.position.x, cpose-&gt;pose.position.y, cpose-&gt;pose.position.z);
		unique_lock &lt;mutex&gt; lock (ORB_SLAM2::KeyFrame::extPoseMutex);
		ORB_SLAM2::KeyFrame::extEgoPosition = cv::Mat (3,1,CV_64F);
		ORB_SLAM2::KeyFrame::extEgoPosition.at&lt;double&gt;(0) = cpose-&gt;pose.position.x,
		ORB_SLAM2::KeyFrame::extEgoPosition.at&lt;double&gt;(1) = cpose-&gt;pose.position.y,
		ORB_SLAM2::KeyFrame::extEgoPosition.at&lt;double&gt;(2) = cpose-&gt;pose.position.z;

		ORB_SLAM2::KeyFrame::extEgoOrientation = cv::Mat (4,1,CV_64F);
		ORB_SLAM2::KeyFrame::extEgoOrientation.at&lt;double&gt;(0) = cpose-&gt;pose.orientation.x,
		ORB_SLAM2::KeyFrame::extEgoOrientation.at&lt;double&gt;(1) = cpose-&gt;pose.orientation.y,
		ORB_SLAM2::KeyFrame::extEgoOrientation.at&lt;double&gt;(2) = cpose-&gt;pose.orientation.z,
		ORB_SLAM2::KeyFrame::extEgoOrientation.at&lt;double&gt;(3) = cpose-&gt;pose.orientation.w;
	}


	void imageCallback (const sensor_msgs::ImageConstPtr&amp; msg)
	{
		// Activate this timer if you need time logging
		ptime rT1, rT2;
		rT1 = microsec_clock::local_time();

		// Copy the ros image message to cv::Mat.
		cv_bridge::CvImageConstPtr cv_ptr;
		try
		{
			cv_ptr = cv_bridge::toCvShare(msg);
		}
		catch (cv_bridge::Exception&amp; e)
		{
			ROS_ERROR(&quot;cv_bridge exception: %s&quot;, e.what());
			return;
		}

		cv::Mat image;
		// Check if we need debayering
		if (enc::isBayer(msg-&gt;encoding)) {
			int code=-1;
			if (msg-&gt;encoding == enc::BAYER_RGGB8 ||
				msg-&gt;encoding == enc::BAYER_RGGB16) {
				code = cv::COLOR_BayerBG2BGR;
			}
			else if (msg-&gt;encoding == enc::BAYER_BGGR8 ||
					 msg-&gt;encoding == enc::BAYER_BGGR16) {
				code = cv::COLOR_BayerRG2BGR;
			}
			else if (msg-&gt;encoding == enc::BAYER_GBRG8 ||
					 msg-&gt;encoding == enc::BAYER_GBRG16) {
				code = cv::COLOR_BayerGR2BGR;
			}
			else if (msg-&gt;encoding == enc::BAYER_GRBG8 ||
					 msg-&gt;encoding == enc::BAYER_GRBG16) {
				code = cv::COLOR_BayerGB2BGR;
			}
			cv::cvtColor(cv_ptr-&gt;image, image, code);
		}
		else
			image = cv_ptr-&gt;image;

		const double imageTime = msg-&gt;header.stamp.toSec();
		lastImageTimestamp = imageTime;

		if (gotFirstFrame==false) {
			double fx2, fy2, cx2, cy2;
			recomputeNewCameraParameter (
				(double)SLAMSystem.fsSettings[&quot;Camera.fx&quot;],
				(double)SLAMSystem.fsSettings[&quot;Camera.fy&quot;],
				(double)SLAMSystem.fsSettings[&quot;Camera.cx&quot;],
				(double)SLAMSystem.fsSettings[&quot;Camera.cy&quot;],
				fx2, fy2, cx2, cy2,
				msg-&gt;width, msg-&gt;height,
				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Width&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Height&quot;]);
			// send camera parameters to tracker
			SLAMSystem.getTracker()-&gt;ChangeCalibration (fx2, fy2, cx2, cy2);
			gotFirstFrame = true;
		}

		// Processing before sending image to tracker
		// Do Resizing and cropping here
		cv::resize(image, image,
			cv::Size(
				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Width&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Height&quot;]
			));
		image = image(
			cv::Rect(
				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.x0&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.y0&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.width&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.height&quot;]
			)).clone();

		SLAMSystem.TrackMonocular(image, imageTime);

	}


private:
	// External localization
	tf::TransformListener *extListener;
	tf::StampedTransform extPose;

	ros::NodeHandle &amp;rosnode;
	ORB_SLAM2::System &amp;SLAMSystem;
	ros::Subscriber poseSub;

	string externalFrameFixed;
	string externalFrameMoving;

	double lastImageTimestamp;
	bool gotFirstFrame;

public:
//	volatile bool doStop;

	image_transport::TransportHints th;
	image_transport::ImageTransport *imageBuf;
	image_transport::Subscriber imageSub;

	thread *externalLocalizerThread;

};






int main (int argc, char *argv[])
{
	const string orbVocabFile (ORB_SLAM_VOCABULARY);

	ros::init(argc, argv, &quot;orb_mapping&quot;, ros::init_options::AnonymousName);
	ros::start();
	ros::NodeHandle nodeHandler(&quot;~&quot;);

	string mapPath;
	nodeHandler.getParam(&quot;map_file&quot;, mapPath);

	string configFile;
	nodeHandler.getParam(&quot;configuration_file&quot;, configFile);

	ORB_SLAM2::System SLAM(orbVocabFile,
		configFile,
		ORB_SLAM2::System::MONOCULAR,
		true,
		mapPath,
		System::MAPPING);

	ORB_Mapper Mapper (SLAM, nodeHandler);

	string imageTopic;
	nodeHandler.getParam(&quot;image_topic&quot;, imageTopic);
	Mapper.imageSub = Mapper.imageBuf-&gt;subscribe (imageTopic, 1,  &amp;ORB_Mapper::imageCallback, &amp;Mapper, Mapper.th);

	ros::spin();
//    Mapper.doStop = true;
//    Mapper.externalLocalizerThread-&gt;join();

    ros::shutdown();
    SLAM.Shutdown();

    return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/orb_matching/orb_matching.cpp" new_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/orb_matching/orb_matching.cpp">
				<diff>@@ -3,545 +3,22 @@
  *  All rights reserved.
  *
  *  XXX: Licensing has not been cleared yet.
-*/
-
-#include &lt;iostream&gt;
-#include &lt;string&gt;
-#include &lt;thread&gt;
-#include &lt;cmath&gt;
-
-#include &lt;ros/ros.h&gt;
-#include &lt;tf/transform_listener.h&gt;
-#include &lt;sensor_msgs/Image.h&gt;
-#include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;geometry_msgs/PoseStamped.h&gt;
-#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;
-#include &lt;cv_bridge/cv_bridge.h&gt;
-#include &lt;image_transport/image_transport.h&gt;
-#include &lt;tf/transform_broadcaster.h&gt;
-#include &quot;boost/date_time/posix_time/posix_time.hpp&quot;
-
-#include &quot;System.h&quot;
-#include &quot;Converter.h&quot;
-#include &quot;../common.h&quot;
-
-
-using namespace std;
-using namespace ORB_SLAM2;
-using namespace boost::posix_time;
-namespace enc = sensor_msgs::image_encodings;
-
-
-class ORB_Matcher
-{
-public:
-	ORB_Matcher (ORB_SLAM2::System&amp; pSL, ros::NodeHandle &amp;nh) :
-		SLAMSystem (pSL), rosnode(nh),
-		lastImageTimestamp (0.0),
-		gotFirstFrame (false),
-		lastKeyframeId (0)
-	{
-		externalFrameFixed = (string)pSL.fsSettings[&quot;Localization.frame1&quot;];
-		externalFrameMoving = (string)pSL.fsSettings[&quot;Localization.frame2&quot;];
-		offsetKeyframe = SLAMSystem.fsSettings[&quot;ExternalLocalization.OffsetKeyframes&quot;];
-
-		cout &lt;&lt; &quot;TF: From &quot; &lt;&lt; externalFrameFixed &lt;&lt; &quot; to &quot; &lt;&lt; externalFrameMoving &lt;&lt; endl;
-
-		// Image Subscription
-	    if ((int)SLAMSystem.fsSettings[&quot;Camera.compressed&quot;]==0) {
-	    	th = image_transport::TransportHints (&quot;raw&quot;);
-	    }
-	    else if ((int)SLAMSystem.fsSettings[&quot;Camera.compressed&quot;]==1) {
-	    	th = image_transport::TransportHints (&quot;compressed&quot;);
-	    }
-		imageBuf = new image_transport::ImageTransport(rosnode);
-
-		// Result Publishers
-		string poseTopic;
-		rosnode.getParam(&quot;pose_topic&quot;, poseTopic);
-		posePublisher = rosnode.advertise&lt;geometry_msgs::PoseStamped&gt; (poseTopic, 1);
-		mTfBr = new tf::TransformBroadcaster();
-
-		// start of debug preparation
-		cout &lt;&lt; std::fixed &lt;&lt; setprecision(7);
-		visualDebugView = imageBuf-&gt;advertise(&quot;framebuffer&quot;, 1);
-	}
-
-
-	~ORB_Matcher ()
-	{
-		delete (imageBuf);
-		delete (mTfBr);
-	}
-
-
-	void imageCallback (const sensor_msgs::ImageConstPtr&amp; msg)
-	{
-		// Activate this timer if you need time logging
-		ptime rT1, rT2;
-		rT1 = microsec_clock::local_time();
-
-		// Copy the ros image message to cv::Mat.
-		cv_bridge::CvImageConstPtr cv_ptr;
-		try
-		{
-			cv_ptr = cv_bridge::toCvShare(msg);
-		}
-		catch (cv_bridge::Exception&amp; e)
-		{
-			ROS_ERROR(&quot;cv_bridge exception: %s&quot;, e.what());
-			return;
-		}
-
-		cv::Mat image;
-		// Check if we need debayering
-		if (enc::isBayer(msg-&gt;encoding)) {
-			int code=-1;
-			if (msg-&gt;encoding == enc::BAYER_RGGB8 ||
-				msg-&gt;encoding == enc::BAYER_RGGB16) {
-				code = cv::COLOR_BayerBG2BGR;
-			}
-			else if (msg-&gt;encoding == enc::BAYER_BGGR8 ||
-					 msg-&gt;encoding == enc::BAYER_BGGR16) {
-				code = cv::COLOR_BayerRG2BGR;
-			}
-			else if (msg-&gt;encoding == enc::BAYER_GBRG8 ||
-					 msg-&gt;encoding == enc::BAYER_GBRG16) {
-				code = cv::COLOR_BayerGR2BGR;
-			}
-			else if (msg-&gt;encoding == enc::BAYER_GRBG8 ||
-					 msg-&gt;encoding == enc::BAYER_GRBG16) {
-				code = cv::COLOR_BayerGB2BGR;
-			}
-			cv::cvtColor(cv_ptr-&gt;image, image, code);
-		}
-		else
-			image = cv_ptr-&gt;image;
-
-		const double imageTime = msg-&gt;header.stamp.toSec();
-		lastImageTimestamp = imageTime;
-
-		if (gotFirstFrame==false) {
-			double fx2, fy2, cx2, cy2;
-			recomputeNewCameraParameter (
-				(double)SLAMSystem.fsSettings[&quot;Camera.fx&quot;],
-				(double)SLAMSystem.fsSettings[&quot;Camera.fy&quot;],
-				(double)SLAMSystem.fsSettings[&quot;Camera.cx&quot;],
-				(double)SLAMSystem.fsSettings[&quot;Camera.cy&quot;],
-				fx2, fy2, cx2, cy2,
-				msg-&gt;width, msg-&gt;height,
-				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Width&quot;],
-				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Height&quot;]);
-			// send camera parameters to tracker
-			SLAMSystem.getTracker()-&gt;ChangeCalibration (fx2, fy2, cx2, cy2);
-			gotFirstFrame = true;
-		}
-
-		// Processing before sending image to tracker
-		// Do Resizing and cropping here
-		cv::resize(image, image,
-			cv::Size(
-				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Width&quot;],
-				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Height&quot;]
-			));
-		image = image(
-			cv::Rect(
-				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.x0&quot;],
-				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.y0&quot;],
-				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.width&quot;],
-				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.height&quot;]
-			)).clone();
-
-		SLAMSystem.TrackMonocular(image, imageTime);
-
-		// Reinsert TF publisher, but only for localization. Original ORB-SLAM2 removes it.
-		bool tfOk = false;
-		tf::Transform locRef;
-
-		Frame &amp;cframe = SLAMSystem.getTracker()-&gt;mCurrentFrame;
-		if (SLAMSystem.getTracker()-&gt;trackingIsGood())
-		{
-
-			tf::Transform tfTcw = FramePose(&amp;cframe);
-			mTfBr-&gt;sendTransform(tf::StampedTransform(tfTcw, ros::Time(imageTime), &quot;/ORB_SLAM/World&quot;, &quot;/ORB_SLAM/Camera&quot;));
-
-	//		 Here, we use offset of external localization from the keyframe
-
-				try {
-					locRef = localizeByReference(tfTcw);
-					publishPose(&amp;locRef);
-					tfOk = true;
-//					lastDebugMessage = &quot;&quot;;
-				} catch (exception &amp;e) {
-//					lastDebugMessage = e.what();
-					publishPose(NULL);
-				}
-
-		} else {
-			publishPose (NULL);
-		}
-
-		rT2 = microsec_clock::local_time();
-//		cputimeDebug = (rT2-rT1).total_microseconds() * 1e-6;
-
-		// Debugging
-		SLAMSystem.getFrameDrawer()-&gt;DrawFrame();
-		cv::Mat framebufferDbg = SLAMSystem.getFrameDrawer()-&gt;getLastFrame();
-		cv_bridge::CvImage bagImage;
-		bagImage.image = framebufferDbg;
-		bagImage.header.stamp = ros::Time(lastImageTimestamp);
-		bagImage.encoding = &quot;bgr8&quot;;
-		visualDebugView.publish(bagImage.toImageMsg());
-	}
-
-private:
-	tf::Transform localizeByReference (const tf::Transform &amp;tfOrb, ORB_SLAM2::KeyFrame *kf)
-	{
-		lastKeyframeId = kf-&gt;mnId;
-
-		ORB_SLAM2::KeyFrame *kOffset = SLAMSystem.getMap()-&gt;offsetKeyframe(kf, offsetKeyframe);
-		if (kOffset==NULL)
-			throw std::out_of_range(&quot;No offset keyframe found&quot;);
-
-		if (kf-&gt;extPosition.empty() or kOffset-&gt;extPosition.empty())
-			throw std::out_of_range(&quot;External reference of keyframe not found&quot;);
-
-		tf::Transform kfTr = KeyFramePoseToTf(kf);
-		tf::Transform extRef = getKeyFrameExtPose(kf);
-
-		tf::Transform kfTrOffset = KeyFramePoseToTf(kOffset);
-		tf::Transform extRefOffset = getKeyFrameExtPose(kOffset);
-		return localizeByReference (tfOrb, kfTr, kfTrOffset, extRef, extRefOffset);
-	}
-
-
-	tf::Transform rotateAxes (const tf::Transform &amp;cPose, const float roll=0, const float pitch=0, const float yaw=0)
-	{
-		tf::Transform rotation;
-		rotation.setOrigin (tf::Vector3 (0,0,0));
-		rotation.setRotation (tf::Quaternion(roll, pitch, yaw).normalize());
-		return cPose * rotation;
-	}
-
-
-	/*
-	 * Main routine for localization by reference
-	 */
-	tf::Transform localizeByReference (
-	    	const tf::Transform &amp;tfOrb,
-			const tf::Transform &amp;tfOrbMap, const tf::Transform &amp;tfOrbMapOffset,
-	    	const tf::Transform &amp;realMapPose, const tf::Transform &amp;realMapOffset)
-	{
-		double offDistO = cv::norm(
-			tfToCv(tfOrbMap.getOrigin()) -
-			tfToCv(tfOrbMapOffset.getOrigin()));
-		double offDistE = cv::norm(
-			tfToCv(realMapPose.getOrigin()) -
-			tfToCv(realMapOffset.getOrigin()));
-		double scale = offDistE / offDistO;
-
-		// change orientation from camera to velodyne
-		tf::Transform flipAxes;
-		flipAxes.setOrigin(tf::Vector3(0, 0, 0));
-		flipAxes.setRotation (tf::Quaternion(M_PI/2, 0, -M_PI/2).normalize());
-
-		tf::Transform orbRel = tfOrbMap.inverse() * tfOrb;
-
-		tf::Transform scaledRel = orbRel;
-		scaledRel.setOrigin(orbRel.getOrigin() * scale);
-		scaledRel = flipAxes*scaledRel;
-
-		tf::Transform tfResult = realMapPose * scaledRel;
-
-		// Still need to rotate axes
-		return rotateAxes (tfResult, 0, M_PI/2, M_PI/2);
-	}
-
-
-	tf::Transform localizeByReference(const tf::Transform &amp;tfOrb)
-	{
-		float fdirx = tfOrb.getRotation().x(),
-			fdiry = tfOrb.getRotation().y(),
-			fdirz = tfOrb.getRotation().z(),
-			fdirnorm;
-		fdirnorm = sqrtf(fdirx*fdirx + fdiry*fdiry + fdirz*fdirz);
-		fdirx /= fdirnorm;
-		fdiry /= fdirnorm;
-		fdirz /= fdirnorm;
-
-		ORB_SLAM2::KeyFrame *kfNear = SLAMSystem.getMap()-&gt;getNearestKeyFrame(
-			tfOrb.getOrigin().x(),
-			tfOrb.getOrigin().y(),
-			tfOrb.getOrigin().z(),
-			fdirx, fdiry, fdirz);
-		if (kfNear==NULL)
-			throw std::out_of_range(&quot;No nearest keyframe found&quot;);
-
-		lastKeyframeId = kfNear-&gt;mnId;
-		return localizeByReference (tfOrb, kfNear);
-	}
-
-
-	tf::Transform localizeByReference(Frame *sframe)
-	{
-	//	const tf::Transform
-	}
-
-
-	tf::Transform localizeByReference(const tf::Transform &amp;tfOrb, ORB_SLAM2::Map *mapsrc, const int offsetNum)
-	{
-		float positiondir[6];
-		tf2positiondirection(tfOrb, positiondir);
-
-		ORB_SLAM2::KeyFrame *kfNear = mapsrc-&gt;getNearestKeyFrame(
-			positiondir[0], positiondir[1], positiondir[2],
-			positiondir[3], positiondir[4], positiondir[5]);
-		if (kfNear==NULL)
-			throw std::out_of_range(&quot;No keyframe found&quot;);
-		ORB_SLAM2::KeyFrame *kOffset = mapsrc-&gt;offsetKeyframe(kfNear, offsetNum);
-		if (kOffset==NULL)
-			throw std::out_of_range(&quot;No offset keyframe found&quot;);
-
-		tf::Transform kfTr = KeyFramePoseToTf(kfNear);
-		tf::Transform extRef = getKeyFrameExtPose(kfNear);
-
-		tf::Transform kfTrOffset = KeyFramePoseToTf(kOffset);
-		tf::Transform extRefOffset = getKeyFrameExtPose(kOffset);
-
-		return localizeByReference (tfOrb, kfTr, kfTrOffset, extRef, extRefOffset);
-	}
-
-
-	tf2_msgs::TFMessage createTfMessage (const tf::Transform &amp;srcTransform,
-		const string &amp;frameSrc, const string &amp;frameTarget,
-		double timestamp=-1)
-	{
-		ros::Time msgTime;
-		tf2_msgs::TFMessage tfretval;
-
-		if (timestamp&gt;0)
-			msgTime = ros::Time(timestamp);
-		else msgTime = ros::Time::now();
-
-		geometry_msgs::TransformStamped newTransform;
-		newTransform.header.stamp = msgTime;
-		newTransform.header.frame_id = frameSrc;
-		newTransform.child_frame_id = frameTarget;
-		newTransform.transform.translation.x = srcTransform.getOrigin().x();
-		newTransform.transform.translation.y = srcTransform.getOrigin().y();
-		newTransform.transform.translation.z = srcTransform.getOrigin().z();
-		newTransform.transform.rotation.x = srcTransform.getRotation().x();
-		newTransform.transform.rotation.y = srcTransform.getRotation().y();
-		newTransform.transform.rotation.z = srcTransform.getRotation().z();
-		newTransform.transform.rotation.w = srcTransform.getRotation().w();
-		tfretval.transforms.push_back (newTransform);
-
-		return tfretval;
-	}
-
-
-	tf::Transform getKeyFrameExtPose (const KeyFrame *kf)
-	{
-		tf::Transform Ext;
-
-		if (kf-&gt;extPosition.empty() or kf-&gt;extOrientation.empty()) {
-			Ext.setOrigin(tf::Vector3(NAN, NAN, NAN));
-			Ext.setRotation(tf::Quaternion(NAN, NAN, NAN, NAN));
-		}
-
-		else {
-			Ext.setOrigin (tf::Vector3(
-				kf-&gt;extPosition.at&lt;double&gt;(0),
-				kf-&gt;extPosition.at&lt;double&gt;(1),
-				kf-&gt;extPosition.at&lt;double&gt;(2) ));
-			Ext.setRotation(tf::Quaternion(
-				kf-&gt;extOrientation.at&lt;double&gt;(0),
-				kf-&gt;extOrientation.at&lt;double&gt;(1),
-				kf-&gt;extOrientation.at&lt;double&gt;(2),
-				kf-&gt;extOrientation.at&lt;double&gt;(3) ));
-		}
-		return Ext;
-	}
-
-
-	tf::Transform KeyFramePoseToTf (KeyFrame *kf)
-	{
-		tf::Transform kfpose;
-
-		cv::Mat t = kf-&gt;GetCameraCenter();
-		cv::Mat orient = kf-&gt;GetRotation().t();
-		vector&lt;float&gt; q = ORB_SLAM2::Converter::toQuaternion(orient);
-
-		kfpose.setOrigin(tf::Vector3(t.at&lt;float&gt;(0), t.at&lt;float&gt;(1), t.at&lt;float&gt;(2)));
-		kfpose.setRotation(tf::Quaternion(q[0], q[1], q[2], q[3]));
-
-		return kfpose;
-	}
-
-
-	cv::Vec3d tfToCv (const tf::Vector3 &amp;pos)
-	{
-		cv::Vec3d cvVec;
-		cvVec[0] = pos.x();
-		cvVec[1] = pos.y();
-		cvVec[2] = pos.z();
-		return cvVec;
-	}
-
-
-	cv::Mat tfToCv (const tf::Transform &amp;tfsrc)
-	{
-		cv::Mat rtval = cv::Mat::eye(4,4, CV_32F);
-		rtval.rowRange(0, 3).col(3).at&lt;float&gt;(0) = tfsrc.getOrigin().x();
-		rtval.rowRange(0, 3).col(3).at&lt;float&gt;(1) = tfsrc.getOrigin().y();
-		rtval.rowRange(0, 3).col(3).at&lt;float&gt;(2) = tfsrc.getOrigin().z();
-
-		tf::Matrix3x3 rot (tfsrc.getRotation());
-		for (int i=0; i&lt;3; i++) {
-			for (int j=0; j&lt;3; j++) {
-				rtval.at&lt;float&gt;(i,j) = rot[i][j];
-			}
-		}
-		return rtval;
-	}
-
-
-	void publishPose (const tf::Transform *pose)
-	{
-		geometry_msgs::PoseStamped gpose;
-		gpose.header.frame_id = externalFrameFixed;
-		gpose.header.stamp = ros::Time(lastImageTimestamp);
-
-		if (pose==NULL) {
-			gpose.pose.position.x =
-			gpose.pose.position.y =
-			gpose.pose.position.z = 1e15;
-			gpose.pose.orientation.x = 1.0;
-			gpose.pose.orientation.y = .0;
-			gpose.pose.orientation.z = .0;
-			gpose.pose.orientation.w = .0;
-		}
-
-		else {
-			gpose.pose.position.x = pose-&gt;getOrigin().x();
-			gpose.pose.position.y = pose-&gt;getOrigin().y();
-			gpose.pose.position.z = pose-&gt;getOrigin().z();
-			gpose.pose.orientation.x = pose-&gt;getRotation().x();
-			gpose.pose.orientation.y = pose-&gt;getRotation().y();
-			gpose.pose.orientation.z = pose-&gt;getRotation().z();
-			gpose.pose.orientation.w = pose-&gt;getRotation().w();
-			mTfBr-&gt;sendTransform (tf::StampedTransform(*pose, ros::Time(lastImageTimestamp), externalFrameFixed, externalFrameMoving));
-		}
-
-		posePublisher.publish (gpose);
-	}
-
-
-	void publishPoseWithCovariance (const tf::Transform *pose)
-	{
-		geometry_msgs::PoseWithCovarianceStamped gpose;
-		gpose.header.frame_id = externalFrameFixed;
-		gpose.header.stamp = ros::Time(lastImageTimestamp);
-
-		// XXX: check how we can set the covariance
-
-		if (pose==NULL) {
-			gpose.pose.pose.position.x =
-			gpose.pose.pose.position.y =
-			gpose.pose.pose.position.z = 1e15;
-			gpose.pose.pose.orientation.x = 1.0;
-			gpose.pose.pose.orientation.y = .0;
-			gpose.pose.pose.orientation.z = .0;
-			gpose.pose.pose.orientation.w = .0;
-		}
-
-		else {
-			gpose.pose.pose.position.x = pose-&gt;getOrigin().x();
-			gpose.pose.pose.position.y = pose-&gt;getOrigin().y();
-			gpose.pose.pose.position.z = pose-&gt;getOrigin().z();
-			gpose.pose.pose.orientation.x = pose-&gt;getRotation().x();
-			gpose.pose.pose.orientation.y = pose-&gt;getRotation().y();
-			gpose.pose.pose.orientation.z = pose-&gt;getRotation().z();
-			gpose.pose.pose.orientation.w = pose-&gt;getRotation().w();
-
-			tf::StampedTransform tfMsg;
-			tfMsg.stamp_ = ros::Time(lastImageTimestamp);
-			tfMsg.frame_id_ = externalFrameFixed;
-			tfMsg.child_frame_id_ = externalFrameMoving;
-			tfMsg.setData(*pose);
-			mTfBr-&gt;sendTransform(tfMsg);
-		}
-
-		posePublisher.publish(gpose);
-	}
-
-
-/*
- * Variable members
  */
-private:
-	tf::StampedTransform extPose;
 
-	ros::NodeHandle &amp;rosnode;
-	ORB_SLAM2::System &amp;SLAMSystem;
-	ros::Publisher posePublisher;
-	tf::TransformBroadcaster *mTfBr;
-
-	// Debug
-	image_transport::Publisher visualDebugView;
-
-	string externalFrameFixed;
-	string externalFrameMoving;
-
-	double lastImageTimestamp;
-	bool gotFirstFrame;
-
-	// Logging
-	uint32_t lastKeyframeId;
-	int offsetKeyframe;
-
-public:
-	image_transport::TransportHints th;
-	image_transport::ImageTransport *imageBuf;
-	image_transport::Subscriber imageSub;
-
-};
 
+#include &lt;iostream&gt;
+#include &quot;Matcher.h&quot;
 
 
 
 int main (int argc, char *argv[])
 {
-//	const string mapPath = (argc==3) ? argv[2] : string();
-	const string orbVocabFile (ORB_SLAM_VOCABULARY);
-//	const string configFile = argv[1];
-
 	ros::init(argc, argv, &quot;orb_matching&quot;, ros::init_options::AnonymousName);
 	ros::start();
 	ros::NodeHandle nodeHandler (&quot;~&quot;);
 
-	string mapPath;
-	nodeHandler.getParam(&quot;map_file&quot;, mapPath);
-
-	string configFile;
-	nodeHandler.getParam(&quot;configuration_file&quot;, configFile);
-
-	ORB_SLAM2::System SLAM(orbVocabFile,
-		configFile,
-		ORB_SLAM2::System::MONOCULAR,
-		false,
-		mapPath,
-		System::LOCALIZATION);
-
-	ORB_Matcher Matcher (SLAM, nodeHandler);
-	string imageTopic;
-	nodeHandler.getParam(&quot;image_topic&quot;, imageTopic);
-	Matcher.imageSub = Matcher.imageBuf-&gt;subscribe (imageTopic, 1, &amp;ORB_Matcher::imageCallback, &amp;Matcher, Matcher.th);
-	cerr &lt;&lt; &quot;ORB Localizer ready&quot; &lt;&lt; endl;
+	Matcher orb_matching (nodeHandler);
 	ros::spin();
 
-	SLAM.Shutdown();
 	ros::shutdown();
-
-	return 0;
 }
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  XXX: Licensing has not been cleared yet.
*/

#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;thread&gt;
#include &lt;cmath&gt;

#include &lt;ros/ros.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;image_transport/image_transport.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &quot;boost/date_time/posix_time/posix_time.hpp&quot;

#include &quot;System.h&quot;
#include &quot;Converter.h&quot;
#include &quot;../common.h&quot;


using namespace std;
using namespace ORB_SLAM2;
using namespace boost::posix_time;
namespace enc = sensor_msgs::image_encodings;


class ORB_Matcher
{
public:
	ORB_Matcher (ORB_SLAM2::System&amp; pSL, ros::NodeHandle &amp;nh) :
		SLAMSystem (pSL), rosnode(nh),
		lastImageTimestamp (0.0),
		gotFirstFrame (false),
		lastKeyframeId (0)
	{
		externalFrameFixed = (string)pSL.fsSettings[&quot;Localization.frame1&quot;];
		externalFrameMoving = (string)pSL.fsSettings[&quot;Localization.frame2&quot;];
		offsetKeyframe = SLAMSystem.fsSettings[&quot;ExternalLocalization.OffsetKeyframes&quot;];

		cout &lt;&lt; &quot;TF: From &quot; &lt;&lt; externalFrameFixed &lt;&lt; &quot; to &quot; &lt;&lt; externalFrameMoving &lt;&lt; endl;

		// Image Subscription
	    if ((int)SLAMSystem.fsSettings[&quot;Camera.compressed&quot;]==0) {
	    	th = image_transport::TransportHints (&quot;raw&quot;);
	    }
	    else if ((int)SLAMSystem.fsSettings[&quot;Camera.compressed&quot;]==1) {
	    	th = image_transport::TransportHints (&quot;compressed&quot;);
	    }
		imageBuf = new image_transport::ImageTransport(rosnode);

		// Result Publishers
		string poseTopic;
		rosnode.getParam(&quot;pose_topic&quot;, poseTopic);
		posePublisher = rosnode.advertise&lt;geometry_msgs::PoseStamped&gt; (poseTopic, 1);
		mTfBr = new tf::TransformBroadcaster();

		// start of debug preparation
		cout &lt;&lt; std::fixed &lt;&lt; setprecision(7);
		visualDebugView = imageBuf-&gt;advertise(&quot;framebuffer&quot;, 1);
	}


	~ORB_Matcher ()
	{
		delete (imageBuf);
		delete (mTfBr);
	}


	void imageCallback (const sensor_msgs::ImageConstPtr&amp; msg)
	{
		// Activate this timer if you need time logging
		ptime rT1, rT2;
		rT1 = microsec_clock::local_time();

		// Copy the ros image message to cv::Mat.
		cv_bridge::CvImageConstPtr cv_ptr;
		try
		{
			cv_ptr = cv_bridge::toCvShare(msg);
		}
		catch (cv_bridge::Exception&amp; e)
		{
			ROS_ERROR(&quot;cv_bridge exception: %s&quot;, e.what());
			return;
		}

		cv::Mat image;
		// Check if we need debayering
		if (enc::isBayer(msg-&gt;encoding)) {
			int code=-1;
			if (msg-&gt;encoding == enc::BAYER_RGGB8 ||
				msg-&gt;encoding == enc::BAYER_RGGB16) {
				code = cv::COLOR_BayerBG2BGR;
			}
			else if (msg-&gt;encoding == enc::BAYER_BGGR8 ||
					 msg-&gt;encoding == enc::BAYER_BGGR16) {
				code = cv::COLOR_BayerRG2BGR;
			}
			else if (msg-&gt;encoding == enc::BAYER_GBRG8 ||
					 msg-&gt;encoding == enc::BAYER_GBRG16) {
				code = cv::COLOR_BayerGR2BGR;
			}
			else if (msg-&gt;encoding == enc::BAYER_GRBG8 ||
					 msg-&gt;encoding == enc::BAYER_GRBG16) {
				code = cv::COLOR_BayerGB2BGR;
			}
			cv::cvtColor(cv_ptr-&gt;image, image, code);
		}
		else
			image = cv_ptr-&gt;image;

		const double imageTime = msg-&gt;header.stamp.toSec();
		lastImageTimestamp = imageTime;

		if (gotFirstFrame==false) {
			double fx2, fy2, cx2, cy2;
			recomputeNewCameraParameter (
				(double)SLAMSystem.fsSettings[&quot;Camera.fx&quot;],
				(double)SLAMSystem.fsSettings[&quot;Camera.fy&quot;],
				(double)SLAMSystem.fsSettings[&quot;Camera.cx&quot;],
				(double)SLAMSystem.fsSettings[&quot;Camera.cy&quot;],
				fx2, fy2, cx2, cy2,
				msg-&gt;width, msg-&gt;height,
				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Width&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Height&quot;]);
			// send camera parameters to tracker
			SLAMSystem.getTracker()-&gt;ChangeCalibration (fx2, fy2, cx2, cy2);
			gotFirstFrame = true;
		}

		// Processing before sending image to tracker
		// Do Resizing and cropping here
		cv::resize(image, image,
			cv::Size(
				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Width&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.WorkingResolution.Height&quot;]
			));
		image = image(
			cv::Rect(
				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.x0&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.y0&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.width&quot;],
				(int)SLAMSystem.fsSettings[&quot;Camera.ROI.height&quot;]
			)).clone();

		SLAMSystem.TrackMonocular(image, imageTime);

		// Reinsert TF publisher, but only for localization. Original ORB-SLAM2 removes it.
		bool tfOk = false;
		tf::Transform locRef;

		Frame &amp;cframe = SLAMSystem.getTracker()-&gt;mCurrentFrame;
		if (SLAMSystem.getTracker()-&gt;trackingIsGood())
		{

			tf::Transform tfTcw = FramePose(&amp;cframe);
			mTfBr-&gt;sendTransform(tf::StampedTransform(tfTcw, ros::Time(imageTime), &quot;/ORB_SLAM/World&quot;, &quot;/ORB_SLAM/Camera&quot;));

	//		 Here, we use offset of external localization from the keyframe

				try {
					locRef = localizeByReference(tfTcw);
					publishPose(&amp;locRef);
					tfOk = true;
//					lastDebugMessage = &quot;&quot;;
				} catch (exception &amp;e) {
//					lastDebugMessage = e.what();
					publishPose(NULL);
				}

		} else {
			publishPose (NULL);
		}

		rT2 = microsec_clock::local_time();
//		cputimeDebug = (rT2-rT1).total_microseconds() * 1e-6;

		// Debugging
		SLAMSystem.getFrameDrawer()-&gt;DrawFrame();
		cv::Mat framebufferDbg = SLAMSystem.getFrameDrawer()-&gt;getLastFrame();
		cv_bridge::CvImage bagImage;
		bagImage.image = framebufferDbg;
		bagImage.header.stamp = ros::Time(lastImageTimestamp);
		bagImage.encoding = &quot;bgr8&quot;;
		visualDebugView.publish(bagImage.toImageMsg());
	}

private:
	tf::Transform localizeByReference (const tf::Transform &amp;tfOrb, ORB_SLAM2::KeyFrame *kf)
	{
		lastKeyframeId = kf-&gt;mnId;

		ORB_SLAM2::KeyFrame *kOffset = SLAMSystem.getMap()-&gt;offsetKeyframe(kf, offsetKeyframe);
		if (kOffset==NULL)
			throw std::out_of_range(&quot;No offset keyframe found&quot;);

		if (kf-&gt;extPosition.empty() or kOffset-&gt;extPosition.empty())
			throw std::out_of_range(&quot;External reference of keyframe not found&quot;);

		tf::Transform kfTr = KeyFramePoseToTf(kf);
		tf::Transform extRef = getKeyFrameExtPose(kf);

		tf::Transform kfTrOffset = KeyFramePoseToTf(kOffset);
		tf::Transform extRefOffset = getKeyFrameExtPose(kOffset);
		return localizeByReference (tfOrb, kfTr, kfTrOffset, extRef, extRefOffset);
	}


	tf::Transform rotateAxes (const tf::Transform &amp;cPose, const float roll=0, const float pitch=0, const float yaw=0)
	{
		tf::Transform rotation;
		rotation.setOrigin (tf::Vector3 (0,0,0));
		rotation.setRotation (tf::Quaternion(roll, pitch, yaw).normalize());
		return cPose * rotation;
	}


	/*
	 * Main routine for localization by reference
	 */
	tf::Transform localizeByReference (
	    	const tf::Transform &amp;tfOrb,
			const tf::Transform &amp;tfOrbMap, const tf::Transform &amp;tfOrbMapOffset,
	    	const tf::Transform &amp;realMapPose, const tf::Transform &amp;realMapOffset)
	{
		double offDistO = cv::norm(
			tfToCv(tfOrbMap.getOrigin()) -
			tfToCv(tfOrbMapOffset.getOrigin()));
		double offDistE = cv::norm(
			tfToCv(realMapPose.getOrigin()) -
			tfToCv(realMapOffset.getOrigin()));
		double scale = offDistE / offDistO;

		// change orientation from camera to velodyne
		tf::Transform flipAxes;
		flipAxes.setOrigin(tf::Vector3(0, 0, 0));
		flipAxes.setRotation (tf::Quaternion(M_PI/2, 0, -M_PI/2).normalize());

		tf::Transform orbRel = tfOrbMap.inverse() * tfOrb;

		tf::Transform scaledRel = orbRel;
		scaledRel.setOrigin(orbRel.getOrigin() * scale);
		scaledRel = flipAxes*scaledRel;

		tf::Transform tfResult = realMapPose * scaledRel;

		// Still need to rotate axes
		return rotateAxes (tfResult, 0, M_PI/2, M_PI/2);
	}


	tf::Transform localizeByReference(const tf::Transform &amp;tfOrb)
	{
		float fdirx = tfOrb.getRotation().x(),
			fdiry = tfOrb.getRotation().y(),
			fdirz = tfOrb.getRotation().z(),
			fdirnorm;
		fdirnorm = sqrtf(fdirx*fdirx + fdiry*fdiry + fdirz*fdirz);
		fdirx /= fdirnorm;
		fdiry /= fdirnorm;
		fdirz /= fdirnorm;

		ORB_SLAM2::KeyFrame *kfNear = SLAMSystem.getMap()-&gt;getNearestKeyFrame(
			tfOrb.getOrigin().x(),
			tfOrb.getOrigin().y(),
			tfOrb.getOrigin().z(),
			fdirx, fdiry, fdirz);
		if (kfNear==NULL)
			throw std::out_of_range(&quot;No nearest keyframe found&quot;);

		lastKeyframeId = kfNear-&gt;mnId;
		return localizeByReference (tfOrb, kfNear);
	}


	tf::Transform localizeByReference(Frame *sframe)
	{
	//	const tf::Transform
	}


	tf::Transform localizeByReference(const tf::Transform &amp;tfOrb, ORB_SLAM2::Map *mapsrc, const int offsetNum)
	{
		float positiondir[6];
		tf2positiondirection(tfOrb, positiondir);

		ORB_SLAM2::KeyFrame *kfNear = mapsrc-&gt;getNearestKeyFrame(
			positiondir[0], positiondir[1], positiondir[2],
			positiondir[3], positiondir[4], positiondir[5]);
		if (kfNear==NULL)
			throw std::out_of_range(&quot;No keyframe found&quot;);
		ORB_SLAM2::KeyFrame *kOffset = mapsrc-&gt;offsetKeyframe(kfNear, offsetNum);
		if (kOffset==NULL)
			throw std::out_of_range(&quot;No offset keyframe found&quot;);

		tf::Transform kfTr = KeyFramePoseToTf(kfNear);
		tf::Transform extRef = getKeyFrameExtPose(kfNear);

		tf::Transform kfTrOffset = KeyFramePoseToTf(kOffset);
		tf::Transform extRefOffset = getKeyFrameExtPose(kOffset);

		return localizeByReference (tfOrb, kfTr, kfTrOffset, extRef, extRefOffset);
	}


	tf2_msgs::TFMessage createTfMessage (const tf::Transform &amp;srcTransform,
		const string &amp;frameSrc, const string &amp;frameTarget,
		double timestamp=-1)
	{
		ros::Time msgTime;
		tf2_msgs::TFMessage tfretval;

		if (timestamp&gt;0)
			msgTime = ros::Time(timestamp);
		else msgTime = ros::Time::now();

		geometry_msgs::TransformStamped newTransform;
		newTransform.header.stamp = msgTime;
		newTransform.header.frame_id = frameSrc;
		newTransform.child_frame_id = frameTarget;
		newTransform.transform.translation.x = srcTransform.getOrigin().x();
		newTransform.transform.translation.y = srcTransform.getOrigin().y();
		newTransform.transform.translation.z = srcTransform.getOrigin().z();
		newTransform.transform.rotation.x = srcTransform.getRotation().x();
		newTransform.transform.rotation.y = srcTransform.getRotation().y();
		newTransform.transform.rotation.z = srcTransform.getRotation().z();
		newTransform.transform.rotation.w = srcTransform.getRotation().w();
		tfretval.transforms.push_back (newTransform);

		return tfretval;
	}


	tf::Transform getKeyFrameExtPose (const KeyFrame *kf)
	{
		tf::Transform Ext;

		if (kf-&gt;extPosition.empty() or kf-&gt;extOrientation.empty()) {
			Ext.setOrigin(tf::Vector3(NAN, NAN, NAN));
			Ext.setRotation(tf::Quaternion(NAN, NAN, NAN, NAN));
		}

		else {
			Ext.setOrigin (tf::Vector3(
				kf-&gt;extPosition.at&lt;double&gt;(0),
				kf-&gt;extPosition.at&lt;double&gt;(1),
				kf-&gt;extPosition.at&lt;double&gt;(2) ));
			Ext.setRotation(tf::Quaternion(
				kf-&gt;extOrientation.at&lt;double&gt;(0),
				kf-&gt;extOrientation.at&lt;double&gt;(1),
				kf-&gt;extOrientation.at&lt;double&gt;(2),
				kf-&gt;extOrientation.at&lt;double&gt;(3) ));
		}
		return Ext;
	}


	tf::Transform KeyFramePoseToTf (KeyFrame *kf)
	{
		tf::Transform kfpose;

		cv::Mat t = kf-&gt;GetCameraCenter();
		cv::Mat orient = kf-&gt;GetRotation().t();
		vector&lt;float&gt; q = ORB_SLAM2::Converter::toQuaternion(orient);

		kfpose.setOrigin(tf::Vector3(t.at&lt;float&gt;(0), t.at&lt;float&gt;(1), t.at&lt;float&gt;(2)));
		kfpose.setRotation(tf::Quaternion(q[0], q[1], q[2], q[3]));

		return kfpose;
	}


	cv::Vec3d tfToCv (const tf::Vector3 &amp;pos)
	{
		cv::Vec3d cvVec;
		cvVec[0] = pos.x();
		cvVec[1] = pos.y();
		cvVec[2] = pos.z();
		return cvVec;
	}


	cv::Mat tfToCv (const tf::Transform &amp;tfsrc)
	{
		cv::Mat rtval = cv::Mat::eye(4,4, CV_32F);
		rtval.rowRange(0, 3).col(3).at&lt;float&gt;(0) = tfsrc.getOrigin().x();
		rtval.rowRange(0, 3).col(3).at&lt;float&gt;(1) = tfsrc.getOrigin().y();
		rtval.rowRange(0, 3).col(3).at&lt;float&gt;(2) = tfsrc.getOrigin().z();

		tf::Matrix3x3 rot (tfsrc.getRotation());
		for (int i=0; i&lt;3; i++) {
			for (int j=0; j&lt;3; j++) {
				rtval.at&lt;float&gt;(i,j) = rot[i][j];
			}
		}
		return rtval;
	}


	void publishPose (const tf::Transform *pose)
	{
		geometry_msgs::PoseStamped gpose;
		gpose.header.frame_id = externalFrameFixed;
		gpose.header.stamp = ros::Time(lastImageTimestamp);

		if (pose==NULL) {
			gpose.pose.position.x =
			gpose.pose.position.y =
			gpose.pose.position.z = 1e15;
			gpose.pose.orientation.x = 1.0;
			gpose.pose.orientation.y = .0;
			gpose.pose.orientation.z = .0;
			gpose.pose.orientation.w = .0;
		}

		else {
			gpose.pose.position.x = pose-&gt;getOrigin().x();
			gpose.pose.position.y = pose-&gt;getOrigin().y();
			gpose.pose.position.z = pose-&gt;getOrigin().z();
			gpose.pose.orientation.x = pose-&gt;getRotation().x();
			gpose.pose.orientation.y = pose-&gt;getRotation().y();
			gpose.pose.orientation.z = pose-&gt;getRotation().z();
			gpose.pose.orientation.w = pose-&gt;getRotation().w();
			mTfBr-&gt;sendTransform (tf::StampedTransform(*pose, ros::Time(lastImageTimestamp), externalFrameFixed, externalFrameMoving));
		}

		posePublisher.publish (gpose);
	}


	void publishPoseWithCovariance (const tf::Transform *pose)
	{
		geometry_msgs::PoseWithCovarianceStamped gpose;
		gpose.header.frame_id = externalFrameFixed;
		gpose.header.stamp = ros::Time(lastImageTimestamp);

		// XXX: check how we can set the covariance

		if (pose==NULL) {
			gpose.pose.pose.position.x =
			gpose.pose.pose.position.y =
			gpose.pose.pose.position.z = 1e15;
			gpose.pose.pose.orientation.x = 1.0;
			gpose.pose.pose.orientation.y = .0;
			gpose.pose.pose.orientation.z = .0;
			gpose.pose.pose.orientation.w = .0;
		}

		else {
			gpose.pose.pose.position.x = pose-&gt;getOrigin().x();
			gpose.pose.pose.position.y = pose-&gt;getOrigin().y();
			gpose.pose.pose.position.z = pose-&gt;getOrigin().z();
			gpose.pose.pose.orientation.x = pose-&gt;getRotation().x();
			gpose.pose.pose.orientation.y = pose-&gt;getRotation().y();
			gpose.pose.pose.orientation.z = pose-&gt;getRotation().z();
			gpose.pose.pose.orientation.w = pose-&gt;getRotation().w();

			tf::StampedTransform tfMsg;
			tfMsg.stamp_ = ros::Time(lastImageTimestamp);
			tfMsg.frame_id_ = externalFrameFixed;
			tfMsg.child_frame_id_ = externalFrameMoving;
			tfMsg.setData(*pose);
			mTfBr-&gt;sendTransform(tfMsg);
		}

		posePublisher.publish(gpose);
	}


/*
 * Variable members
 */
private:
	tf::StampedTransform extPose;

	ros::NodeHandle &amp;rosnode;
	ORB_SLAM2::System &amp;SLAMSystem;
	ros::Publisher posePublisher;
	tf::TransformBroadcaster *mTfBr;

	// Debug
	image_transport::Publisher visualDebugView;

	string externalFrameFixed;
	string externalFrameMoving;

	double lastImageTimestamp;
	bool gotFirstFrame;

	// Logging
	uint32_t lastKeyframeId;
	int offsetKeyframe;

public:
	image_transport::TransportHints th;
	image_transport::ImageTransport *imageBuf;
	image_transport::Subscriber imageSub;

};




int main (int argc, char *argv[])
{
//	const string mapPath = (argc==3) ? argv[2] : string();
	const string orbVocabFile (ORB_SLAM_VOCABULARY);
//	const string configFile = argv[1];

	ros::init(argc, argv, &quot;orb_matching&quot;, ros::init_options::AnonymousName);
	ros::start();
	ros::NodeHandle nodeHandler (&quot;~&quot;);

	string mapPath;
	nodeHandler.getParam(&quot;map_file&quot;, mapPath);

	string configFile;
	nodeHandler.getParam(&quot;configuration_file&quot;, configFile);

	ORB_SLAM2::System SLAM(orbVocabFile,
		configFile,
		ORB_SLAM2::System::MONOCULAR,
		false,
		mapPath,
		System::LOCALIZATION);

	ORB_Matcher Matcher (SLAM, nodeHandler);
	string imageTopic;
	nodeHandler.getParam(&quot;image_topic&quot;, imageTopic);
	Matcher.imageSub = Matcher.imageBuf-&gt;subscribe (imageTopic, 1, &amp;ORB_Matcher::imageCallback, &amp;Matcher, Matcher.th);
	cerr &lt;&lt; &quot;ORB Localizer ready&quot; &lt;&lt; endl;
	ros::spin();

	SLAM.Shutdown();
	ros::shutdown();

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/map_publisher.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/nodes/visualization/map_publisher.cc">
				<diff>@@ -16,8 +16,10 @@
 #include &lt;ros/ros.h&gt;
 #include &lt;visualization_msgs/Marker.h&gt;
 #include &lt;geometry_msgs/PoseArray.h&gt;
+#include &lt;tf/tf.h&gt;
+#include &quot;../common.h&quot;
 
-#include &quot;../__nodes/ImageGrabber.h&quot;
+//#include &quot;../__nodes/ImageGrabber.h&quot;
 
 
 using namespace std;
@@ -156,43 +158,28 @@ protected:
 
 		for (KeyFrame *keyframe: keyFrameList) {
 
-			float qdir[4];
-
-			cv::Mat Tcw, Twc, ow,
-				p1w, p2w, p3w, p4w;
+			tf::Transform keyframePose;
 
 			if (pubMode==ORB_COORD) {
-				tf::Transform kfOrbPose = ImageGrabber::KeyFramePoseToTf(keyframe);
-				cv::Mat kfPose = ImageGrabber::tfToCv(kfOrbPose);
-				ow = kfPose.rowRange(0, 3).col(3);
-				qdir[0] = kfOrbPose.getRotation().x();
-				qdir[1] = kfOrbPose.getRotation().y();
-				qdir[2] = kfOrbPose.getRotation().z();
-				qdir[3] = kfOrbPose.getRotation().w();
+				keyframePose = KeyFramePoseToTf (keyframe);
 			}
 
 			else {
 				if (keyframe-&gt;extPosition.empty())
 					continue;
-				tf::Transform kfExtPose = ImageGrabber::getKeyFrameExtPose(keyframe);
-				cv::Mat extPose = ImageGrabber::tfToCv(kfExtPose);
-				ow = extPose.rowRange(0, 3).col(3);
-				qdir[0] = kfExtPose.getRotation().x();
-				qdir[1] = kfExtPose.getRotation().y();
-				qdir[2] = kfExtPose.getRotation().z();
-				qdir[3] = kfExtPose.getRotation().w();
+				keyframePose = getKeyFrameExtPose (keyframe);
 			}
 
 			geometry_msgs::Point kfCenter;
 			geometry_msgs::Quaternion kfDirection;
 
-			kfCenter.x = ow.at&lt;float&gt;(0);
-			kfCenter.y = ow.at&lt;float&gt;(1);
-			kfCenter.z = ow.at&lt;float&gt;(2);
-			kfDirection.x = qdir[0];
-			kfDirection.y = qdir[1];
-			kfDirection.z = qdir[2];
-			kfDirection.w = qdir[3];
+			kfCenter.x = keyframePose.getOrigin().x();
+			kfCenter.y = keyframePose.getOrigin().y();
+			kfCenter.z = keyframePose.getOrigin().z();
+			kfDirection.x = keyframePose.getRotation().x();
+			kfDirection.y = keyframePose.getRotation().x();
+			kfDirection.z = keyframePose.getRotation().x();
+			kfDirection.w = keyframePose.getRotation().x();
 
 			geometry_msgs::Pose kfPose;
 			kfPose.position = kfCenter;
</diff>
				<old_file>/*
 * map_publisher.cc
 *
 *  Created on: Jul 11, 2016
 *      Author: sujiwo
 */


#include &lt;string&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &quot;Map.h&quot;
#include &quot;KeyFrame.h&quot;
#include &quot;MapPoint.h&quot;
#include &quot;Converter.h&quot;
#include &lt;ros/ros.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;geometry_msgs/PoseArray.h&gt;

#include &quot;../__nodes/ImageGrabber.h&quot;


using namespace std;
using ORB_SLAM2::Map;
using ORB_SLAM2::KeyFrame;
using ORB_SLAM2::MapPoint;



class MapPublisher
{
public:
	enum coordMode {
		ORB_COORD = 0,
		EXT_COORD = 1
	};


	MapPublisher (Map &amp;mapsrc,
			ros::NodeHandle &amp;nh,
			coordMode cmode=ORB_COORD) :
		mMap (mapsrc),
		rosNode (nh),
		pubMode (cmode)
	{
	    string MAP_FRAME_ID;
	    if (cmode==EXT_COORD)
	    	MAP_FRAME_ID = &quot;world&quot;;
	    else
	    	MAP_FRAME_ID = &quot;ORB_SLAM/World&quot;;

	    const char* POINTS_NAMESPACE = &quot;MapPoints&quot;;
	    const char* KEYFRAMES_NAMESPACE = &quot;KeyFrames&quot;;
	    const char* GRAPH_NAMESPACE = &quot;Graph&quot;;

	    // Configure MapPoints
	    fPointSize = 0.03;
	    fCameraSize = 0.07;
	    mPoints.header.frame_id = MAP_FRAME_ID;
	    mPoints.ns = POINTS_NAMESPACE;
	    mPoints.id = 0;
	    mPoints.type = visualization_msgs::Marker::POINTS;
	    mPoints.scale.x=fPointSize;
		mPoints.scale.y=fPointSize;
		mPoints.pose.orientation.w=1.0;
		mPoints.action=visualization_msgs::Marker::ADD;
		mPoints.color.b = 1.0;
		mPoints.color.a = 1.0;

	    //Configure KeyFrames
		mKeyFrames.header.frame_id = MAP_FRAME_ID;
//		mKeyFrames.ns = KEYFRAMES_NAMESPACE;
//		mKeyFrames.id=1;
//		mKeyFrames.type = visualization_msgs::Marker::LINE_LIST;
//		mKeyFrames.scale.x=0.005;
//		mKeyFrames.pose.orientation.w=1.0;
//		mKeyFrames.action=visualization_msgs::Marker::ADD;
//	    mKeyFrames.color.b = 1.0f;
//	    mKeyFrames.color.a = 1.0;

	    //Configure Covisibility Graph
		mCovisibilityGraph.header.frame_id = MAP_FRAME_ID;
		mCovisibilityGraph.ns = GRAPH_NAMESPACE;
		mCovisibilityGraph.id=2;
		mCovisibilityGraph.type = visualization_msgs::Marker::LINE_LIST;
		mCovisibilityGraph.scale.x=0.002;
		mCovisibilityGraph.pose.orientation.w=1.0;
		mCovisibilityGraph.action=visualization_msgs::Marker::ADD;
		mCovisibilityGraph.color.b=0.7f;
		mCovisibilityGraph.color.g=0.7f;
		mCovisibilityGraph.color.a = 0.3;

		mappointPublisher = rosNode.advertise&lt;visualization_msgs::Marker&gt; (&quot;ORB_SLAM/Map/MapPoint&quot;, 10);
//		mappointPublisher = rosNode.advertise&lt;
		keyframePosePublisher = rosNode.advertise&lt;geometry_msgs::PoseArray&gt; (&quot;ORB_SLAM/Map/KeyFrame&quot;, 10);
		mapPointList = mMap.GetAllMapPoints();
		keyFrameList = mMap.GetAllKeyFrames();
	}


	void paint ()
	{
		if (pubMode==ORB_COORD)
			publishMapPoints();
		publishKeyFrames();
//		publishGraph();

		cout &lt;&lt; &quot;Painted&quot; &lt;&lt; endl;
	}


protected:
	ros::NodeHandle &amp;rosNode;
	Map &amp;mMap;
	const coordMode pubMode;
	ros::Publisher mappointPublisher;
	ros::Publisher keyframePosePublisher;

	vector &lt;MapPoint*&gt; mapPointList;
	vector &lt;KeyFrame*&gt; keyFrameList;

	visualization_msgs::Marker mPoints;
//	visualization_msgs::Marker mKeyFrames;
	geometry_msgs::PoseArray mKeyFrames;
	visualization_msgs::Marker mCovisibilityGraph;

	float fPointSize,
		fCameraSize;


	void publishMapPoints ()
	{
		mPoints.points.clear();

		for (MapPoint *cmp: mapPointList) {
//			cerr &lt;&lt; &quot;P&quot; &lt;&lt; endl;
			if (cmp-&gt;isBad()) {
				continue;
			}
			geometry_msgs::Point p;
			cv::Mat pos = cmp-&gt;GetWorldPos();
			p.x = pos.at&lt;float&gt;(0);
			p.y = pos.at&lt;float&gt;(1);
			p.z = pos.at&lt;float&gt;(2);
			mPoints.points.push_back(p);
		}

		mPoints.header.stamp = ros::Time::now();
		mappointPublisher.publish (mPoints);
	}


	void publishKeyFrames ()
	{
		mKeyFrames.poses.clear();

		for (KeyFrame *keyframe: keyFrameList) {

			float qdir[4];

			cv::Mat Tcw, Twc, ow,
				p1w, p2w, p3w, p4w;

			if (pubMode==ORB_COORD) {
				tf::Transform kfOrbPose = ImageGrabber::KeyFramePoseToTf(keyframe);
				cv::Mat kfPose = ImageGrabber::tfToCv(kfOrbPose);
				ow = kfPose.rowRange(0, 3).col(3);
				qdir[0] = kfOrbPose.getRotation().x();
				qdir[1] = kfOrbPose.getRotation().y();
				qdir[2] = kfOrbPose.getRotation().z();
				qdir[3] = kfOrbPose.getRotation().w();
			}

			else {
				if (keyframe-&gt;extPosition.empty())
					continue;
				tf::Transform kfExtPose = ImageGrabber::getKeyFrameExtPose(keyframe);
				cv::Mat extPose = ImageGrabber::tfToCv(kfExtPose);
				ow = extPose.rowRange(0, 3).col(3);
				qdir[0] = kfExtPose.getRotation().x();
				qdir[1] = kfExtPose.getRotation().y();
				qdir[2] = kfExtPose.getRotation().z();
				qdir[3] = kfExtPose.getRotation().w();
			}

			geometry_msgs::Point kfCenter;
			geometry_msgs::Quaternion kfDirection;

			kfCenter.x = ow.at&lt;float&gt;(0);
			kfCenter.y = ow.at&lt;float&gt;(1);
			kfCenter.z = ow.at&lt;float&gt;(2);
			kfDirection.x = qdir[0];
			kfDirection.y = qdir[1];
			kfDirection.z = qdir[2];
			kfDirection.w = qdir[3];

			geometry_msgs::Pose kfPose;
			kfPose.position = kfCenter;
			kfPose.orientation = kfDirection;
			mKeyFrames.poses.push_back (kfPose);

		}

		keyframePosePublisher.publish(mKeyFrames);
	}


	void publishGraph ()
	{

	}
};



int main (int argc, char *argv[])
{
	if (argc&lt;2) {
		cerr &lt;&lt; &quot;Please specify map file&quot; &lt;&lt; endl;
		exit(-1);
	}
	string mapfile (argv[1]);
	ORB_SLAM2::Map World;
	World.loadFromDisk (mapfile);

	// ROS Stuff
	ros::init(argc, argv, &quot;orb_map_publisher&quot;);
	ros::start();
	ros::NodeHandle nodeHandler;

	cout &lt;&lt; &quot;** Ready&quot; &lt;&lt; endl;
	MapPublisher mpPub (
		World,
		nodeHandler,
		argc&gt;2 ? MapPublisher::EXT_COORD : MapPublisher::ORB_COORD);

	ros::Rate r(1.0);
	while (ros::ok()) {
		mpPub.paint();
		r.sleep();
	}
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Converter.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Converter.cc">
				<diff>@@ -134,18 +134,12 @@ Eigen::Matrix&lt;double,3,3&gt; Converter::toMatrix3d(const cv::Mat &amp;cvMat3)
     return M;
 }
 
-std::vector&lt;float&gt; Converter::toQuaternion(const cv::Mat &amp;M)
+Eigen::Quaterniond Converter::toQuaternion(const cv::Mat &amp;M)
 {
     Eigen::Matrix&lt;double,3,3&gt; eigMat = toMatrix3d(M);
     Eigen::Quaterniond q(eigMat);
 
-    std::vector&lt;float&gt; v(4);
-    v[0] = q.x();
-    v[1] = q.y();
-    v[2] = q.z();
-    v[3] = q.w();
-
-    return v;
+    return q;
 }
 
 } //namespace ORB_SLAM
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/


#include &quot;Converter.h&quot;

namespace ORB_SLAM2
{

std::vector&lt;cv::Mat&gt; Converter::toDescriptorVector(const cv::Mat &amp;Descriptors)
{
    std::vector&lt;cv::Mat&gt; vDesc;
    vDesc.reserve(Descriptors.rows);
    for (int j=0;j&lt;Descriptors.rows;j++)
        vDesc.push_back(Descriptors.row(j));

    return vDesc;
}

g2o::SE3Quat Converter::toSE3Quat(const cv::Mat &amp;cvT)
{
    Eigen::Matrix&lt;double,3,3&gt; R;
    R &lt;&lt; cvT.at&lt;float&gt;(0,0), cvT.at&lt;float&gt;(0,1), cvT.at&lt;float&gt;(0,2),
         cvT.at&lt;float&gt;(1,0), cvT.at&lt;float&gt;(1,1), cvT.at&lt;float&gt;(1,2),
         cvT.at&lt;float&gt;(2,0), cvT.at&lt;float&gt;(2,1), cvT.at&lt;float&gt;(2,2);

    Eigen::Matrix&lt;double,3,1&gt; t(cvT.at&lt;float&gt;(0,3), cvT.at&lt;float&gt;(1,3), cvT.at&lt;float&gt;(2,3));

    return g2o::SE3Quat(R,t);
}

cv::Mat Converter::toCvMat(const g2o::SE3Quat &amp;SE3)
{
    Eigen::Matrix&lt;double,4,4&gt; eigMat = SE3.to_homogeneous_matrix();
    return toCvMat(eigMat);
}

cv::Mat Converter::toCvMat(const g2o::Sim3 &amp;Sim3)
{
    Eigen::Matrix3d eigR = Sim3.rotation().toRotationMatrix();
    Eigen::Vector3d eigt = Sim3.translation();
    double s = Sim3.scale();
    return toCvSE3(s*eigR,eigt);
}

cv::Mat Converter::toCvMat(const Eigen::Matrix&lt;double,4,4&gt; &amp;m)
{
    cv::Mat cvMat(4,4,CV_32F);
    for(int i=0;i&lt;4;i++)
        for(int j=0; j&lt;4; j++)
            cvMat.at&lt;float&gt;(i,j)=m(i,j);

    return cvMat.clone();
}

cv::Mat Converter::toCvMat(const Eigen::Matrix3d &amp;m)
{
    cv::Mat cvMat(3,3,CV_32F);
    for(int i=0;i&lt;3;i++)
        for(int j=0; j&lt;3; j++)
            cvMat.at&lt;float&gt;(i,j)=m(i,j);

    return cvMat.clone();
}

cv::Mat Converter::toCvMat(const Eigen::Matrix&lt;double,3,1&gt; &amp;m)
{
    cv::Mat cvMat(3,1,CV_32F);
    for(int i=0;i&lt;3;i++)
            cvMat.at&lt;float&gt;(i)=m(i);

    return cvMat.clone();
}

cv::Mat Converter::toCvSE3(const Eigen::Matrix&lt;double,3,3&gt; &amp;R, const Eigen::Matrix&lt;double,3,1&gt; &amp;t)
{
    cv::Mat cvMat = cv::Mat::eye(4,4,CV_32F);
    for(int i=0;i&lt;3;i++)
    {
        for(int j=0;j&lt;3;j++)
        {
            cvMat.at&lt;float&gt;(i,j)=R(i,j);
        }
    }
    for(int i=0;i&lt;3;i++)
    {
        cvMat.at&lt;float&gt;(i,3)=t(i);
    }

    return cvMat.clone();
}

Eigen::Matrix&lt;double,3,1&gt; Converter::toVector3d(const cv::Mat &amp;cvVector)
{
    Eigen::Matrix&lt;double,3,1&gt; v;
    v &lt;&lt; cvVector.at&lt;float&gt;(0), cvVector.at&lt;float&gt;(1), cvVector.at&lt;float&gt;(2);

    return v;
}

Eigen::Matrix&lt;double,3,1&gt; Converter::toVector3d(const cv::Point3f &amp;cvPoint)
{
    Eigen::Matrix&lt;double,3,1&gt; v;
    v &lt;&lt; cvPoint.x, cvPoint.y, cvPoint.z;

    return v;
}

Eigen::Matrix&lt;double,3,3&gt; Converter::toMatrix3d(const cv::Mat &amp;cvMat3)
{
    Eigen::Matrix&lt;double,3,3&gt; M;

    M &lt;&lt; cvMat3.at&lt;float&gt;(0,0), cvMat3.at&lt;float&gt;(0,1), cvMat3.at&lt;float&gt;(0,2),
         cvMat3.at&lt;float&gt;(1,0), cvMat3.at&lt;float&gt;(1,1), cvMat3.at&lt;float&gt;(1,2),
         cvMat3.at&lt;float&gt;(2,0), cvMat3.at&lt;float&gt;(2,1), cvMat3.at&lt;float&gt;(2,2);

    return M;
}

std::vector&lt;float&gt; Converter::toQuaternion(const cv::Mat &amp;M)
{
    Eigen::Matrix&lt;double,3,3&gt; eigMat = toMatrix3d(M);
    Eigen::Quaterniond q(eigMat);

    std::vector&lt;float&gt; v(4);
    v[0] = q.x();
    v[1] = q.y();
    v[2] = q.z();
    v[3] = q.w();

    return v;
}

} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Frame.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Frame.cc">
				<diff>@@ -175,7 +175,8 @@ Frame::Frame(const cv::Mat &amp;imGray, const cv::Mat &amp;imDepth, const double &amp;timeSt
 Frame::Frame(const cv::Mat &amp;imGray, const double &amp;timeStamp, ORBextractor* extractor,ORBVocabulary* voc, cv::Mat &amp;K, cv::Mat &amp;distCoef, const float &amp;bf, const float &amp;thDepth)
     :mpORBvocabulary(voc),mpORBextractorLeft(extractor),mpORBextractorRight(static_cast&lt;ORBextractor*&gt;(NULL)),
      mTimeStamp(timeStamp), mK(K.clone()),mDistCoef(distCoef.clone()), mbf(bf), mThDepth(thDepth),
-	 mpReferenceKF(NULL)
+	 mpReferenceKF(NULL),
+	 image (imGray)
 {
     // Frame ID
     mnId=nNextId++;
@@ -682,7 +683,34 @@ cv::Mat Frame::UnprojectStereo(const int &amp;i)
 
 void Frame::getDirectionVector (float &amp;dirX, float &amp;dirY, float &amp;dirZ)
 {
+	cv::Mat orient = this-&gt;mTcw.t();
+	dirX = orient.at&lt;float&gt;(0,2);
+	dirY = orient.at&lt;float&gt;(1,2);
+	dirZ = orient.at&lt;float&gt;(2,2);
+	float norm = sqrtf(dirX*dirX + dirY*dirY + dirZ*dirZ);
+	dirX /= norm;
+	dirY /= norm;
+	dirZ /= norm;
+}
+
 
+const string frameDebugImage (&quot;frame.jpg&quot;);
+
+void Frame::debug (const string &amp;dirname)
+{
+	const string imageFilename = dirname + &quot;/&quot; + frameDebugImage ;
+
+	cv::Mat dbgImage = this-&gt;image.clone();
+	if (dbgImage.channels()&lt;3)
+		cv::cvtColor (dbgImage, dbgImage, CV_GRAY2BGR);
+
+	const int size = 3;
+	for (int i=0; i&lt;mvKeys.size(); i++) {
+		cv::circle (dbgImage, mvKeys[i].pt, size, cv::Scalar(0,255,0), -1);
+	}
+
+	cv::imwrite (imageFilename, dbgImage);
 }
 
+
 } //namespace ORB_SLAM
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#include &quot;Frame.h&quot;
#include &quot;Converter.h&quot;
#include &quot;ORBmatcher.h&quot;
#include &lt;thread&gt;

namespace ORB_SLAM2
{

long unsigned int Frame::nNextId=0;
bool Frame::mbInitialComputations=true;
float Frame::cx, Frame::cy, Frame::fx, Frame::fy, Frame::invfx, Frame::invfy;
float Frame::mnMinX, Frame::mnMinY, Frame::mnMaxX, Frame::mnMaxY;
float Frame::mfGridElementWidthInv, Frame::mfGridElementHeightInv;

Frame::Frame()
{}

//Copy Constructor
Frame::Frame(const Frame &amp;frame)
    :mpORBvocabulary(frame.mpORBvocabulary), mpORBextractorLeft(frame.mpORBextractorLeft), mpORBextractorRight(frame.mpORBextractorRight),
     mTimeStamp(frame.mTimeStamp), mK(frame.mK.clone()), mDistCoef(frame.mDistCoef.clone()),
     mbf(frame.mbf), mb(frame.mb), mThDepth(frame.mThDepth), N(frame.N), mvKeys(frame.mvKeys),
     mvKeysRight(frame.mvKeysRight), mvKeysUn(frame.mvKeysUn),  mvuRight(frame.mvuRight),
     mvDepth(frame.mvDepth), mBowVec(frame.mBowVec), mFeatVec(frame.mFeatVec),
     mDescriptors(frame.mDescriptors.clone()), mDescriptorsRight(frame.mDescriptorsRight.clone()),
     mvpMapPoints(frame.mvpMapPoints), mvbOutlier(frame.mvbOutlier), mnId(frame.mnId),
     mpReferenceKF(frame.mpReferenceKF), mnScaleLevels(frame.mnScaleLevels),
     mfScaleFactor(frame.mfScaleFactor), mfLogScaleFactor(frame.mfLogScaleFactor),
     mvScaleFactors(frame.mvScaleFactors), mvInvScaleFactors(frame.mvInvScaleFactors),
     mvLevelSigma2(frame.mvLevelSigma2), mvInvLevelSigma2(frame.mvInvLevelSigma2)
{
    for(int i=0;i&lt;FRAME_GRID_COLS;i++)
        for(int j=0; j&lt;FRAME_GRID_ROWS; j++)
            mGrid[i][j]=frame.mGrid[i][j];

    if(!frame.mTcw.empty())
        SetPose(frame.mTcw);
}


Frame::Frame(const cv::Mat &amp;imLeft, const cv::Mat &amp;imRight, const double &amp;timeStamp, ORBextractor* extractorLeft, ORBextractor* extractorRight, ORBVocabulary* voc, cv::Mat &amp;K, cv::Mat &amp;distCoef, const float &amp;bf, const float &amp;thDepth)
    :mpORBvocabulary(voc),mpORBextractorLeft(extractorLeft),mpORBextractorRight(extractorRight), mTimeStamp(timeStamp), mK(K.clone()),mDistCoef(distCoef.clone()), mbf(bf), mThDepth(thDepth),
     mpReferenceKF(NULL)
{
    // Frame ID
    mnId=nNextId++;

    // Scale Level Info
    mnScaleLevels = mpORBextractorLeft-&gt;GetLevels();
    mfScaleFactor = mpORBextractorLeft-&gt;GetScaleFactor();
    mfLogScaleFactor = log(mfScaleFactor);
    mvScaleFactors = mpORBextractorLeft-&gt;GetScaleFactors();
    mvInvScaleFactors = mpORBextractorLeft-&gt;GetInverseScaleFactors();
    mvLevelSigma2 = mpORBextractorLeft-&gt;GetScaleSigmaSquares();
    mvInvLevelSigma2 = mpORBextractorLeft-&gt;GetInverseScaleSigmaSquares();

    // ORB extraction
    thread threadLeft(&amp;Frame::ExtractORB,this,0,imLeft);
    thread threadRight(&amp;Frame::ExtractORB,this,1,imRight);
    threadLeft.join();
    threadRight.join();

    if(mvKeys.empty())
        return;

    N = mvKeys.size();

    UndistortKeyPoints();

    ComputeStereoMatches();

    mvpMapPoints = vector&lt;MapPoint*&gt;(N,static_cast&lt;MapPoint*&gt;(NULL));    
    mvbOutlier = vector&lt;bool&gt;(N,false);


    // This is done only for the first Frame (or after a change in the calibration)
    if(mbInitialComputations)
    {
        ComputeImageBounds(imLeft);

        mfGridElementWidthInv=static_cast&lt;float&gt;(FRAME_GRID_COLS)/(mnMaxX-mnMinX);
        mfGridElementHeightInv=static_cast&lt;float&gt;(FRAME_GRID_ROWS)/(mnMaxY-mnMinY);

        fx = K.at&lt;float&gt;(0,0);
        fy = K.at&lt;float&gt;(1,1);
        cx = K.at&lt;float&gt;(0,2);
        cy = K.at&lt;float&gt;(1,2);
        invfx = 1.0f/fx;
        invfy = 1.0f/fy;

        mbInitialComputations=false;
    }

    mb = mbf/fx;

    AssignFeaturesToGrid();
}

Frame::Frame(const cv::Mat &amp;imGray, const cv::Mat &amp;imDepth, const double &amp;timeStamp, ORBextractor* extractor,ORBVocabulary* voc, cv::Mat &amp;K, cv::Mat &amp;distCoef, const float &amp;bf, const float &amp;thDepth)
    :mpORBvocabulary(voc),mpORBextractorLeft(extractor),mpORBextractorRight(static_cast&lt;ORBextractor*&gt;(NULL)),
     mTimeStamp(timeStamp), mK(K.clone()),mDistCoef(distCoef.clone()), mbf(bf), mThDepth(thDepth),
	 mpReferenceKF(NULL)
{
    // Frame ID
    mnId=nNextId++;

    // Scale Level Info
    mnScaleLevels = mpORBextractorLeft-&gt;GetLevels();
    mfScaleFactor = mpORBextractorLeft-&gt;GetScaleFactor();    
    mfLogScaleFactor = log(mfScaleFactor);
    mvScaleFactors = mpORBextractorLeft-&gt;GetScaleFactors();
    mvInvScaleFactors = mpORBextractorLeft-&gt;GetInverseScaleFactors();
    mvLevelSigma2 = mpORBextractorLeft-&gt;GetScaleSigmaSquares();
    mvInvLevelSigma2 = mpORBextractorLeft-&gt;GetInverseScaleSigmaSquares();

    // ORB extraction
    ExtractORB(0,imGray);

    N = mvKeys.size();

    if(mvKeys.empty())
        return;

    UndistortKeyPoints();

    ComputeStereoFromRGBD(imDepth);

    mvpMapPoints = vector&lt;MapPoint*&gt;(N,static_cast&lt;MapPoint*&gt;(NULL));
    mvbOutlier = vector&lt;bool&gt;(N,false);

    // This is done only for the first Frame (or after a change in the calibration)
    if(mbInitialComputations)
    {
        ComputeImageBounds(imGray);

        mfGridElementWidthInv=static_cast&lt;float&gt;(FRAME_GRID_COLS)/static_cast&lt;float&gt;(mnMaxX-mnMinX);
        mfGridElementHeightInv=static_cast&lt;float&gt;(FRAME_GRID_ROWS)/static_cast&lt;float&gt;(mnMaxY-mnMinY);

        fx = K.at&lt;float&gt;(0,0);
        fy = K.at&lt;float&gt;(1,1);
        cx = K.at&lt;float&gt;(0,2);
        cy = K.at&lt;float&gt;(1,2);
        invfx = 1.0f/fx;
        invfy = 1.0f/fy;

        mbInitialComputations=false;
    }

    mb = mbf/fx;

    AssignFeaturesToGrid();
}


Frame::Frame(const cv::Mat &amp;imGray, const double &amp;timeStamp, ORBextractor* extractor,ORBVocabulary* voc, cv::Mat &amp;K, cv::Mat &amp;distCoef, const float &amp;bf, const float &amp;thDepth)
    :mpORBvocabulary(voc),mpORBextractorLeft(extractor),mpORBextractorRight(static_cast&lt;ORBextractor*&gt;(NULL)),
     mTimeStamp(timeStamp), mK(K.clone()),mDistCoef(distCoef.clone()), mbf(bf), mThDepth(thDepth),
	 mpReferenceKF(NULL)
{
    // Frame ID
    mnId=nNextId++;

    // Scale Level Info
    mnScaleLevels = mpORBextractorLeft-&gt;GetLevels();
    mfScaleFactor = mpORBextractorLeft-&gt;GetScaleFactor();
    mfLogScaleFactor = log(mfScaleFactor);
    mvScaleFactors = mpORBextractorLeft-&gt;GetScaleFactors();
    mvInvScaleFactors = mpORBextractorLeft-&gt;GetInverseScaleFactors();
    mvLevelSigma2 = mpORBextractorLeft-&gt;GetScaleSigmaSquares();
    mvInvLevelSigma2 = mpORBextractorLeft-&gt;GetInverseScaleSigmaSquares();

    // ORB extraction
    ExtractORB(0,imGray);

    N = mvKeys.size();

    if(mvKeys.empty())
        return;

    UndistortKeyPoints();

    // Set no stereo information
    mvuRight = vector&lt;float&gt;(N,-1);
    mvDepth = vector&lt;float&gt;(N,-1);

    mvpMapPoints = vector&lt;MapPoint*&gt;(N,static_cast&lt;MapPoint*&gt;(NULL));
    mvbOutlier = vector&lt;bool&gt;(N,false);

    // This is done only for the first Frame (or after a change in the calibration)
    if(mbInitialComputations)
    {
        ComputeImageBounds(imGray);

        mfGridElementWidthInv=static_cast&lt;float&gt;(FRAME_GRID_COLS)/static_cast&lt;float&gt;(mnMaxX-mnMinX);
        mfGridElementHeightInv=static_cast&lt;float&gt;(FRAME_GRID_ROWS)/static_cast&lt;float&gt;(mnMaxY-mnMinY);

        fx = K.at&lt;float&gt;(0,0);
        fy = K.at&lt;float&gt;(1,1);
        cx = K.at&lt;float&gt;(0,2);
        cy = K.at&lt;float&gt;(1,2);
        invfx = 1.0f/fx;
        invfy = 1.0f/fy;

        mbInitialComputations=false;
    }

    mb = mbf/fx;

    AssignFeaturesToGrid();
}

void Frame::AssignFeaturesToGrid()
{
    int nReserve = 0.5f*N/(FRAME_GRID_COLS*FRAME_GRID_ROWS);
    for(unsigned int i=0; i&lt;FRAME_GRID_COLS;i++)
        for (unsigned int j=0; j&lt;FRAME_GRID_ROWS;j++)
            mGrid[i][j].reserve(nReserve);

    for(int i=0;i&lt;N;i++)
    {
        const cv::KeyPoint &amp;kp = mvKeysUn[i];

        int nGridPosX, nGridPosY;
        if(PosInGrid(kp,nGridPosX,nGridPosY))
            mGrid[nGridPosX][nGridPosY].push_back(i);
    }
}

void Frame::ExtractORB(int flag, const cv::Mat &amp;im)
{
    if(flag==0)
        (*mpORBextractorLeft)(im,cv::Mat(),mvKeys,mDescriptors);
    else
        (*mpORBextractorRight)(im,cv::Mat(),mvKeysRight,mDescriptorsRight);
}

void Frame::SetPose(cv::Mat Tcw)
{
    mTcw = Tcw.clone();
    UpdatePoseMatrices();
}

void Frame::UpdatePoseMatrices()
{ 
    mRcw = mTcw.rowRange(0,3).colRange(0,3);
    mRwc = mRcw.t();
    mtcw = mTcw.rowRange(0,3).col(3);
    mOw = -mRcw.t()*mtcw;
}

bool Frame::isInFrustum(MapPoint *pMP, float viewingCosLimit)
{
    pMP-&gt;mbTrackInView = false;

    // 3D in absolute coordinates
    cv::Mat P = pMP-&gt;GetWorldPos(); 

    // 3D in camera coordinates
    const cv::Mat Pc = mRcw*P+mtcw;
    const float &amp;PcX = Pc.at&lt;float&gt;(0);
    const float &amp;PcY= Pc.at&lt;float&gt;(1);
    const float &amp;PcZ = Pc.at&lt;float&gt;(2);

    // Check positive depth
    if(PcZ&lt;0.0f)
        return false;

    // Project in image and check it is not outside
    const float invz = 1.0f/PcZ;
    const float u=fx*PcX*invz+cx;
    const float v=fy*PcY*invz+cy;

    if(u&lt;mnMinX || u&gt;mnMaxX)
        return false;
    if(v&lt;mnMinY || v&gt;mnMaxY)
        return false;

    // Check distance is in the scale invariance region of the MapPoint
    const float maxDistance = pMP-&gt;GetMaxDistanceInvariance();
    const float minDistance = pMP-&gt;GetMinDistanceInvariance();
    const cv::Mat PO = P-mOw;
    const float dist = cv::norm(PO);

    if(dist&lt;minDistance || dist&gt;maxDistance)
        return false;

   // Check viewing angle
    cv::Mat Pn = pMP-&gt;GetNormal();

    const float viewCos = PO.dot(Pn)/dist;

    if(viewCos&lt;viewingCosLimit)
        return false;

    // Predict scale in the image
    const int nPredictedLevel = pMP-&gt;PredictScale(dist,mfLogScaleFactor);

    // Data used by the tracking
    pMP-&gt;mbTrackInView = true;
    pMP-&gt;mTrackProjX = u;
    pMP-&gt;mTrackProjXR = u - mbf*invz;
    pMP-&gt;mTrackProjY = v;
    pMP-&gt;mnTrackScaleLevel= nPredictedLevel;
    pMP-&gt;mTrackViewCos = viewCos;

    return true;
}

vector&lt;size_t&gt; Frame::GetFeaturesInArea(const float &amp;x, const float  &amp;y, const float  &amp;r, const int minLevel, const int maxLevel) const
{
    vector&lt;size_t&gt; vIndices;
    vIndices.reserve(N);

    const int nMinCellX = max(0,(int)floor((x-mnMinX-r)*mfGridElementWidthInv));
    if(nMinCellX&gt;=FRAME_GRID_COLS)
        return vIndices;

    const int nMaxCellX = min((int)FRAME_GRID_COLS-1,(int)ceil((x-mnMinX+r)*mfGridElementWidthInv));
    if(nMaxCellX&lt;0)
        return vIndices;

    const int nMinCellY = max(0,(int)floor((y-mnMinY-r)*mfGridElementHeightInv));
    if(nMinCellY&gt;=FRAME_GRID_ROWS)
        return vIndices;

    const int nMaxCellY = min((int)FRAME_GRID_ROWS-1,(int)ceil((y-mnMinY+r)*mfGridElementHeightInv));
    if(nMaxCellY&lt;0)
        return vIndices;

    const bool bCheckLevels = (minLevel&gt;0) || (maxLevel&gt;=0);

    for(int ix = nMinCellX; ix&lt;=nMaxCellX; ix++)
    {
        for(int iy = nMinCellY; iy&lt;=nMaxCellY; iy++)
        {
            const vector&lt;size_t&gt; vCell = mGrid[ix][iy];
            if(vCell.empty())
                continue;

            for(size_t j=0, jend=vCell.size(); j&lt;jend; j++)
            {
                const cv::KeyPoint &amp;kpUn = mvKeysUn[vCell[j]];
                if(bCheckLevels)
                {
                    if(kpUn.octave&lt;minLevel)
                        continue;
                    if(maxLevel&gt;=0)
                        if(kpUn.octave&gt;maxLevel)
                            continue;
                }

                const float distx = kpUn.pt.x-x;
                const float disty = kpUn.pt.y-y;

                if(fabs(distx)&lt;r &amp;&amp; fabs(disty)&lt;r)
                    vIndices.push_back(vCell[j]);
            }
        }
    }

    return vIndices;
}

bool Frame::PosInGrid(const cv::KeyPoint &amp;kp, int &amp;posX, int &amp;posY)
{
    posX = round((kp.pt.x-mnMinX)*mfGridElementWidthInv);
    posY = round((kp.pt.y-mnMinY)*mfGridElementHeightInv);

    //Keypoint's coordinates are undistorted, which could cause to go out of the image
    if(posX&lt;0 || posX&gt;=FRAME_GRID_COLS || posY&lt;0 || posY&gt;=FRAME_GRID_ROWS)
        return false;

    return true;
}


void Frame::ComputeBoW()
{
    if(mBowVec.empty())
    {
        vector&lt;cv::Mat&gt; vCurrentDesc = Converter::toDescriptorVector(mDescriptors);
        mpORBvocabulary-&gt;transform(vCurrentDesc,mBowVec,mFeatVec,4);
    }
}

void Frame::UndistortKeyPoints()
{
    if(mDistCoef.at&lt;float&gt;(0)==0.0)
    {
        mvKeysUn=mvKeys;
        return;
    }

    // Fill matrix with points
    cv::Mat mat(N,2,CV_32F);
    for(int i=0; i&lt;N; i++)
    {
        mat.at&lt;float&gt;(i,0)=mvKeys[i].pt.x;
        mat.at&lt;float&gt;(i,1)=mvKeys[i].pt.y;
    }

    // Undistort points
    mat=mat.reshape(2);
    cv::undistortPoints(mat,mat,mK,mDistCoef,cv::Mat(),mK);
    mat=mat.reshape(1);

    // Fill undistorted keypoint vector
    mvKeysUn.resize(N);
    for(int i=0; i&lt;N; i++)
    {
        cv::KeyPoint kp = mvKeys[i];
        kp.pt.x=mat.at&lt;float&gt;(i,0);
        kp.pt.y=mat.at&lt;float&gt;(i,1);
        mvKeysUn[i]=kp;
    }
}

void Frame::ComputeImageBounds(const cv::Mat &amp;imLeft)
{
    if(mDistCoef.at&lt;float&gt;(0)!=0.0)
    {
        cv::Mat mat(4,2,CV_32F);
        mat.at&lt;float&gt;(0,0)=0.0; mat.at&lt;float&gt;(0,1)=0.0;
        mat.at&lt;float&gt;(1,0)=imLeft.cols; mat.at&lt;float&gt;(1,1)=0.0;
        mat.at&lt;float&gt;(2,0)=0.0; mat.at&lt;float&gt;(2,1)=imLeft.rows;
        mat.at&lt;float&gt;(3,0)=imLeft.cols; mat.at&lt;float&gt;(3,1)=imLeft.rows;

        // Undistort corners
        mat=mat.reshape(2);
        cv::undistortPoints(mat,mat,mK,mDistCoef,cv::Mat(),mK);
        mat=mat.reshape(1);

        mnMinX = min(mat.at&lt;float&gt;(0,0),mat.at&lt;float&gt;(2,0));
        mnMaxX = max(mat.at&lt;float&gt;(1,0),mat.at&lt;float&gt;(3,0));
        mnMinY = min(mat.at&lt;float&gt;(0,1),mat.at&lt;float&gt;(1,1));
        mnMaxY = max(mat.at&lt;float&gt;(2,1),mat.at&lt;float&gt;(3,1));

    }
    else
    {
        mnMinX = 0.0f;
        mnMaxX = imLeft.cols;
        mnMinY = 0.0f;
        mnMaxY = imLeft.rows;
    }
}

void Frame::ComputeStereoMatches()
{
    mvuRight = vector&lt;float&gt;(N,-1.0f);
    mvDepth = vector&lt;float&gt;(N,-1.0f);

    const int nRows = mpORBextractorLeft-&gt;mvImagePyramid[0].rows;

    //Assign keypoints to row table
    vector&lt;vector&lt;size_t&gt; &gt; vRowIndices(nRows,vector&lt;size_t&gt;());

    for(int i=0; i&lt;nRows; i++)
        vRowIndices[i].reserve(200);

    const int Nr = mvKeysRight.size();

    for(int iR=0; iR&lt;Nr; iR++)
    {
        const cv::KeyPoint &amp;kp = mvKeysRight[iR];
        const float &amp;kpY = kp.pt.y;
        const float r = 2.0f*mvScaleFactors[mvKeysRight[iR].octave];
        const int maxr = ceil(kpY+r);
        const int minr = floor(kpY-r);

        for(int yi=minr;yi&lt;=maxr;yi++)
            vRowIndices[yi].push_back(iR);
    }

    // Set limits for search
    const float minZ = mb;
    const float minD = -3;
    const float maxD = mbf/minZ;

    // For each left keypoint search a match in the right image
    vector&lt;pair&lt;int, int&gt; &gt; vDistIdx;
    vDistIdx.reserve(N);

    for(int iL=0; iL&lt;N; iL++)
    {
        const cv::KeyPoint &amp;kpL = mvKeys[iL];
        const int &amp;levelL = kpL.octave;
        const float &amp;vL = kpL.pt.y;
        const float &amp;uL = kpL.pt.x;

        const vector&lt;size_t&gt; &amp;vCandidates = vRowIndices[vL];

        if(vCandidates.empty())
            continue;

        const float minU = uL-maxD;
        const float maxU = uL-minD;

        if(maxU&lt;0)
            continue;

        int bestDist = ORBmatcher::TH_HIGH;
        size_t bestIdxR = 0;

        const cv::Mat &amp;dL = mDescriptors.row(iL);

        // Compare descriptor to right keypoints
        for(size_t iC=0; iC&lt;vCandidates.size(); iC++)
        {
            const size_t iR = vCandidates[iC];
            const cv::KeyPoint &amp;kpR = mvKeysRight[iR];

            if(kpR.octave&lt;levelL-1 || kpR.octave&gt;levelL+1)
                continue;

            const float &amp;uR = kpR.pt.x;

            if(uR&gt;=minU &amp;&amp; uR&lt;=maxU)
            {
                const cv::Mat &amp;dR = mDescriptorsRight.row(iR);
                const int dist = ORBmatcher::DescriptorDistance(dL,dR);

                if(dist&lt;bestDist)
                {
                    bestDist = dist;
                    bestIdxR = iR;
                }
            }
        }

        // Subpixel match by correlation
        if(bestDist&lt;ORBmatcher::TH_HIGH)
        {
            // coordinates in image pyramid at keypoint scale
            const float uR0 = mvKeysRight[bestIdxR].pt.x;
            const float scaleFactor = mvInvScaleFactors[kpL.octave];
            const float scaleduL = round(kpL.pt.x*scaleFactor);
            const float scaledvL = round(kpL.pt.y*scaleFactor);
            const float scaleduR0 = round(uR0*scaleFactor);

            // sliding window search
            const int w = 5;
            cv::Mat IL = mpORBextractorLeft-&gt;mvImagePyramid[kpL.octave].rowRange(scaledvL-w,scaledvL+w+1).colRange(scaleduL-w,scaleduL+w+1);
            IL.convertTo(IL,CV_32F);
            IL = IL - IL.at&lt;float&gt;(w,w) *cv::Mat::ones(IL.rows,IL.cols,CV_32F);

            int bestDist = INT_MAX;
            int bestincR = 0;
            const int L = 5;
            vector&lt;float&gt; vDists;
            vDists.resize(2*L+1);

            const float iniu = scaleduR0+L-w;
            const float endu = scaleduR0+L+w+1;
            if(iniu&lt;0 || endu &gt;= mpORBextractorRight-&gt;mvImagePyramid[kpL.octave].cols)
                continue;

            for(int incR=-L; incR&lt;=+L; incR++)
            {
                cv::Mat IR = mpORBextractorRight-&gt;mvImagePyramid[kpL.octave].rowRange(scaledvL-w,scaledvL+w+1).colRange(scaleduR0+incR-w,scaleduR0+incR+w+1);
                IR.convertTo(IR,CV_32F);
                IR = IR - IR.at&lt;float&gt;(w,w) *cv::Mat::ones(IR.rows,IR.cols,CV_32F);

                float dist = cv::norm(IL,IR,cv::NORM_L1);
                if(dist&lt;bestDist)
                {
                    bestDist =  dist;
                    bestincR = incR;
                }

                vDists[L+incR] = dist;
            }

            if(bestincR==-L || bestincR==L)
                continue;

            // Sub-pixel match (Parabola fitting)
            const float dist1 = vDists[L+bestincR-1];
            const float dist2 = vDists[L+bestincR];
            const float dist3 = vDists[L+bestincR+1];

            const float deltaR = (dist1-dist3)/(2.0f*(dist1+dist3-2.0f*dist2));

            if(deltaR&lt;-1 || deltaR&gt;1)
                continue;

            // Re-scaled coordinate
            float bestuR = mvScaleFactors[kpL.octave]*((float)scaleduR0+(float)bestincR+deltaR);

            float disparity = (uL-bestuR);

            if(disparity&gt;=0 &amp;&amp; disparity&lt;maxD)
            {
                if(disparity&lt;=0)
                {
                    disparity=0.01;
                    bestuR = uL-0.01;
                }
                mvDepth[iL]=mbf/disparity;
                mvuRight[iL] = bestuR;
                vDistIdx.push_back(pair&lt;int,int&gt;(bestDist,iL));
            }
        }
    }

    sort(vDistIdx.begin(),vDistIdx.end());
    const float median = vDistIdx[vDistIdx.size()/2].first;
    const float thDist = 1.5f*1.4f*median;

    for(int i=vDistIdx.size()-1;i&gt;=0;i--)
    {
        if(vDistIdx[i].first&lt;thDist)
            break;
        else
        {
            mvuRight[vDistIdx[i].second]=-1;
            mvDepth[vDistIdx[i].second]=-1;
        }
    }
}


void Frame::ComputeStereoFromRGBD(const cv::Mat &amp;imDepth)
{
    mvuRight = vector&lt;float&gt;(N,-1);
    mvDepth = vector&lt;float&gt;(N,-1);

    for(int i=0; i&lt;N; i++)
    {
        const cv::KeyPoint &amp;kp = mvKeys[i];
        const cv::KeyPoint &amp;kpU = mvKeysUn[i];

        const float &amp;v = kp.pt.y;
        const float &amp;u = kp.pt.x;

        const float d = imDepth.at&lt;float&gt;(v,u);

        if(d&gt;0)
        {
            mvDepth[i] = d;
            mvuRight[i] = kpU.pt.x-mbf/d;
        }
    }
}

cv::Mat Frame::UnprojectStereo(const int &amp;i)
{
    const float z = mvDepth[i];
    if(z&gt;0)
    {
        const float u = mvKeysUn[i].pt.x;
        const float v = mvKeysUn[i].pt.y;
        const float x = (u-cx)*z*invfx;
        const float y = (v-cy)*z*invfy;
        cv::Mat x3Dc = (cv::Mat_&lt;float&gt;(3,1) &lt;&lt; x, y, z);
        return mRwc*x3Dc+mOw;
    }
    else
        return cv::Mat();
}


void Frame::getDirectionVector (float &amp;dirX, float &amp;dirY, float &amp;dirZ)
{

}

} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/FrameDrawer.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/FrameDrawer.cc">
				<diff>@@ -119,9 +119,9 @@ cv::Mat FrameDrawer::DrawFrame()
     }
 
     // Put ORB points in frame
-	for (auto &amp;kp: vCurrentKeys) {
-		cv::circle (workingFrame, kp.pt, 1, cv::Scalar(255,0,0),-1);
-	}
+//	for (auto &amp;kp: vCurrentKeys) {
+//		cv::circle (workingFrame, kp.pt, 1, cv::Scalar(255,0,0),-1);
+//	}
 
     cv::Mat imWithInfo;
     DrawTextInfo(workingFrame,state, imWithInfo);
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#include &quot;FrameDrawer.h&quot;
#include &quot;Tracking.h&quot;

#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;

#include&lt;mutex&gt;

namespace ORB_SLAM2
{

FrameDrawer::FrameDrawer(Map* pMap):mpMap(pMap)
{
    mState=Tracking::SYSTEM_NOT_READY;
    mIm = cv::Mat(480,640,CV_8UC3, cv::Scalar(0,0,0));
}

cv::Mat FrameDrawer::DrawFrame()
{
//    cv::Mat im;
    vector&lt;cv::KeyPoint&gt; vIniKeys; // Initialization: KeyPoints in reference frame
    vector&lt;int&gt; vMatches; // Initialization: correspondeces with reference keypoints
    vector&lt;cv::KeyPoint&gt; vCurrentKeys; // KeyPoints in current frame
    vector&lt;bool&gt; vbVO, vbMap; // Tracked MapPoints in current frame
    int state; // Tracking state

    //Copy variables within scoped mutex
    {
        unique_lock&lt;mutex&gt; lock(mMutex);
        state=mState;
        if(mState==Tracking::SYSTEM_NOT_READY)
            mState=Tracking::NO_IMAGES_YET;

        mIm.copyTo(workingFrame);

        if(mState==Tracking::NOT_INITIALIZED)
        {
            vCurrentKeys = mvCurrentKeys;
            vIniKeys = mvIniKeys;
            vMatches = mvIniMatches;
        }
        else if(mState==Tracking::OK)
        {
            vCurrentKeys = mvCurrentKeys;
            vbVO = mvbVO;
            vbMap = mvbMap;
        }
        else if(mState==Tracking::LOST)
        {
            vCurrentKeys = mvCurrentKeys;
        }
    } // destroy scoped mutex -&gt; release mutex

    if(workingFrame.channels()&lt;3) //this should be always true
    	cvtColor(workingFrame, workingFrame, CV_GRAY2BGR);

	//Draw
	if(state==Tracking::NOT_INITIALIZED) //INITIALIZING
	{
		for(unsigned int i=0; i&lt;vMatches.size(); i++)
		{
			if(vMatches[i]&gt;=0)
			{
				cv::line(workingFrame, vIniKeys[i].pt, vCurrentKeys[vMatches[i]].pt,
					cv::Scalar(0,255,0));
			}
		}
	}
    else if(state==Tracking::OK) //TRACKING
    {
        mnTracked=0;
        mnTrackedVO=0;
        const float r = 5;
        for(int i=0;i&lt;N;i++)
        {
            if(vbVO[i] || vbMap[i])
            {
                cv::Point2f pt1,pt2;
                pt1.x=vCurrentKeys[i].pt.x-r;
                pt1.y=vCurrentKeys[i].pt.y-r;
                pt2.x=vCurrentKeys[i].pt.x+r;
                pt2.y=vCurrentKeys[i].pt.y+r;

                // This is a match to a MapPoint in the map
                if(vbMap[i])
                {
                    cv::rectangle(workingFrame, pt1,pt2,cv::Scalar(0,255,0));
                    cv::circle(workingFrame, vCurrentKeys[i].pt,2,cv::Scalar(0,255,0),-1);
                    mnTracked++;
                }
                else // This is match to a &quot;visual odometry&quot; MapPoint created in the last frame
                {
                    cv::rectangle(workingFrame, pt1, pt2, cv::Scalar(255,0,0));
                    cv::circle(workingFrame, vCurrentKeys[i].pt, 2, cv::Scalar(255,0,0), -1);
                    mnTrackedVO++;
                }
            }
        }
    }

    // Put ORB points in frame
	for (auto &amp;kp: vCurrentKeys) {
		cv::circle (workingFrame, kp.pt, 1, cv::Scalar(255,0,0),-1);
	}

    cv::Mat imWithInfo;
    DrawTextInfo(workingFrame,state, imWithInfo);

    imWithInfo.copyTo(workingFrame);
    return imWithInfo;
}


void FrameDrawer::DrawTextInfo(cv::Mat &amp;im, int nState, cv::Mat &amp;imText)
{
    stringstream s;
    if(nState==Tracking::NO_IMAGES_YET)
        s &lt;&lt; &quot; WAITING FOR IMAGES&quot;;
    else if(nState==Tracking::NOT_INITIALIZED)
        s &lt;&lt; &quot; TRYING TO INITIALIZE &quot;;
    else if(nState==Tracking::OK)
    {
        if(!mbOnlyTracking)
            s &lt;&lt; &quot;SLAM MODE |  &quot;;
        else
            s &lt;&lt; &quot;LOCALIZATION | &quot;;
        int nKFs = mpMap-&gt;KeyFramesInMap();
        int nMPs = mpMap-&gt;MapPointsInMap();
        s &lt;&lt; &quot;KFs: &quot; &lt;&lt; nKFs &lt;&lt; &quot;, MPs: &quot; &lt;&lt; nMPs &lt;&lt; &quot;, Matches: &quot; &lt;&lt; mnTracked;
        if(mnTrackedVO&gt;0)
            s &lt;&lt; &quot;, + VO matches: &quot; &lt;&lt; mnTrackedVO;
    }
    else if(nState==Tracking::LOST)
    {
        s &lt;&lt; &quot; TRACK LOST. TRYING TO RELOCALIZE &quot;;
    }
    else if(nState==Tracking::SYSTEM_NOT_READY)
    {
        s &lt;&lt; &quot; LOADING ORB VOCABULARY. PLEASE WAIT...&quot;;
    }

    int baseline=0;
    cv::Size textSize = cv::getTextSize(s.str(),cv::FONT_HERSHEY_PLAIN,1,1,&amp;baseline);

    imText = cv::Mat(im.rows+textSize.height+10,im.cols,im.type());
    im.copyTo(imText.rowRange(0,im.rows).colRange(0,im.cols));
    imText.rowRange(im.rows,imText.rows) = cv::Mat::zeros(textSize.height+10,im.cols,im.type());
    cv::putText(imText,s.str(),cv::Point(5,imText.rows-5),cv::FONT_HERSHEY_PLAIN,1,cv::Scalar(255,255,255),1,8);

}

void FrameDrawer::Update(Tracking *pTracker)
{
    unique_lock&lt;mutex&gt; lock(mMutex);
    pTracker-&gt;mImGray.copyTo(mIm);
    mvCurrentKeys=pTracker-&gt;mCurrentFrame.mvKeys;
    N = mvCurrentKeys.size();
    mvbVO = vector&lt;bool&gt;(N,false);
    mvbMap = vector&lt;bool&gt;(N,false);
    mbOnlyTracking = pTracker-&gt;mbOnlyTracking;


    if(pTracker-&gt;mLastProcessedState==Tracking::NOT_INITIALIZED)
    {
        mvIniKeys=pTracker-&gt;mInitialFrame.mvKeys;
        mvIniMatches=pTracker-&gt;mvIniMatches;
    }
    else if(pTracker-&gt;mLastProcessedState==Tracking::OK)
    {
        for(int i=0;i&lt;N;i++)
        {
            MapPoint* pMP = pTracker-&gt;mCurrentFrame.mvpMapPoints[i];
            if(pMP)
            {
                if(!pTracker-&gt;mCurrentFrame.mvbOutlier[i])
                {
                    if(pMP-&gt;Observations()&gt;0)
                        mvbMap[i]=true;
                    else
                        mvbVO[i]=true;
                }
            }
        }
    }
    mState=static_cast&lt;int&gt;(pTracker-&gt;mLastProcessedState);
}

} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/KeyFrame.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/KeyFrame.cc">
				<diff>@@ -83,6 +83,17 @@ void KeyFrame::ComputeBoW()
     }
 }
 
+
+void KeyFrame::RecomputeBoW (ORBVocabulary *newvoc)
+{
+	mpORBvocabulary = newvoc;
+	mBowVec.clear();
+	mFeatVec.clear();
+	vector&lt;cv::Mat&gt; vCurrentDesc = Converter::toDescriptorVector(mDescriptors);
+	mpORBvocabulary-&gt;transform (vCurrentDesc, mBowVec, mFeatVec, 4);
+}
+
+
 void KeyFrame::SetPose(const cv::Mat &amp;Tcw_)
 {
     unique_lock&lt;mutex&gt; lock(mMutexPose);
@@ -730,11 +741,18 @@ void KeyFrame::fixConnections (Map *smap, KeyFrameDatabase *kfdb)
 void KeyFrame::getDirectionVector (float &amp;dirX, float &amp;dirY, float &amp;dirZ)
 {
 	cv::Mat orient = this-&gt;GetRotation().t();
-	vector&lt;float&gt; q = ORB_SLAM2::Converter::toQuaternion(orient);
-	float norm = sqrtf(q[0]*q[0] + q[1]*q[1] + q[2]*q[2]);
-	dirX = q[0]/norm;
-	dirY = q[1]/norm;
-	dirZ = q[2]/norm;
+//	Eigen::Quaterniond q = ORB_SLAM2::Converter::toQuaternion(orient);
+//	float norm = sqrtf(q.x()*q.x() + q.y()*q.y() + q.z()*q.z());
+//	dirX = q.x()/norm;
+//	dirY = q.y()/norm;
+//	dirZ = q.z()/norm;
+	dirX = orient.at&lt;float&gt;(0,2);
+	dirY = orient.at&lt;float&gt;(1,2);
+	dirZ = orient.at&lt;float&gt;(2,2);
+	float norm = sqrtf(dirX*dirX + dirY*dirY + dirZ*dirZ);
+	dirX /= norm;
+	dirY /= norm;
+	dirZ /= norm;
 }
 
 
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#include &quot;KeyFrame.h&quot;
#include &quot;Converter.h&quot;
#include &quot;ORBmatcher.h&quot;
#include &lt;mutex&gt;
#include &quot;KeyFrameDatabase.h&quot;
#include &quot;MapObjectSerialization.h&quot;
#include &quot;MapPoint.h&quot;



namespace ORB_SLAM2
{

long unsigned int KeyFrame::nNextId=0;
map&lt;idtype, KeyFrame*&gt; KeyFrame::objectListLookup;
cv::Mat KeyFrame::extEgoPosition;
cv::Mat KeyFrame::extEgoOrientation;
std::mutex KeyFrame::extPoseMutex;


KeyFrame::KeyFrame(Frame &amp;F, Map *pMap, KeyFrameDatabase *pKFDB):
    mnFrameId(F.mnId),  mTimeStamp(F.mTimeStamp), mnGridCols(FRAME_GRID_COLS), mnGridRows(FRAME_GRID_ROWS),
    mfGridElementWidthInv(F.mfGridElementWidthInv), mfGridElementHeightInv(F.mfGridElementHeightInv),
    mnTrackReferenceForFrame(0), mnFuseTargetForKF(0), mnBALocalForKF(0), mnBAFixedForKF(0),
    mnLoopQuery(0), mnLoopWords(0), mnRelocQuery(0), mnRelocWords(0), mnBAGlobalForKF(0),
    fx(F.fx), fy(F.fy), cx(F.cx), cy(F.cy), invfx(F.invfx), invfy(F.invfy),
    mbf(F.mbf), mb(F.mb), mThDepth(F.mThDepth), N(F.N), mvKeys(F.mvKeys), mvKeysUn(F.mvKeysUn),
    mvuRight(F.mvuRight), mvDepth(F.mvDepth), mDescriptors(F.mDescriptors.clone()),
    mBowVec(F.mBowVec), mFeatVec(F.mFeatVec), mnScaleLevels(F.mnScaleLevels), mfScaleFactor(F.mfScaleFactor),
    mfLogScaleFactor(F.mfLogScaleFactor), mvScaleFactors(F.mvScaleFactors), mvLevelSigma2(F.mvLevelSigma2),
    mvInvLevelSigma2(F.mvInvLevelSigma2), mnMinX(F.mnMinX), mnMinY(F.mnMinY), mnMaxX(F.mnMaxX),
    mnMaxY(F.mnMaxY), mK(F.mK), mvpMapPoints(F.mvpMapPoints), mpKeyFrameDB(pKFDB),
    mpORBvocabulary(F.mpORBvocabulary), mbFirstConnection(true), mpParent(NULL), mbNotErase(false),
    mbToBeErased(false), mbBad(false), mHalfBaseline(F.mb/2), mpMap(pMap)
{
    mnId=nNextId++;

    mGrid.resize(mnGridCols);
    for(int i=0; i&lt;mnGridCols;i++)
    {
        mGrid[i].resize(mnGridRows);
        for(int j=0; j&lt;mnGridRows; j++)
            mGrid[i][j] = F.mGrid[i][j];
    }

    SetPose(F.mTcw);

    unique_lock&lt;mutex&gt; lock (KeyFrame::extPoseMutex);
    if (!KeyFrame::extEgoPosition.empty() &amp;&amp; !KeyFrame::extEgoOrientation.empty()) {
    	this-&gt;extPosition = KeyFrame::extEgoPosition.clone();
    	this-&gt;extOrientation = KeyFrame::extEgoOrientation.clone();
    }
}

void KeyFrame::ComputeBoW()
{
    if(mBowVec.empty() || mFeatVec.empty())
    {
        vector&lt;cv::Mat&gt; vCurrentDesc = Converter::toDescriptorVector(mDescriptors);
        // Feature vector associate features with nodes in the 4th level (from leaves up)
        // We assume the vocabulary tree has 6 levels, change the 4 otherwise
        mpORBvocabulary-&gt;transform(vCurrentDesc,mBowVec,mFeatVec,4);
    }
}

void KeyFrame::SetPose(const cv::Mat &amp;Tcw_)
{
    unique_lock&lt;mutex&gt; lock(mMutexPose);
    Tcw_.copyTo(Tcw);
    cv::Mat Rcw = Tcw.rowRange(0,3).colRange(0,3);
    cv::Mat tcw = Tcw.rowRange(0,3).col(3);
    cv::Mat Rwc = Rcw.t();
    Ow = -Rwc*tcw;

    Twc = cv::Mat::eye(4,4,Tcw.type());
    Rwc.copyTo(Twc.rowRange(0,3).colRange(0,3));
    Ow.copyTo(Twc.rowRange(0,3).col(3));
    cv::Mat center = (cv::Mat_&lt;float&gt;(4,1) &lt;&lt; mHalfBaseline, 0 , 0, 1);
    Cw = Twc*center;
}

cv::Mat KeyFrame::GetPose()
{
    unique_lock&lt;mutex&gt; lock(mMutexPose);
    return Tcw.clone();
}

cv::Mat KeyFrame::GetPoseInverse()
{
    unique_lock&lt;mutex&gt; lock(mMutexPose);
    return Twc.clone();
}

cv::Mat KeyFrame::GetCameraCenter()
{
    unique_lock&lt;mutex&gt; lock(mMutexPose);
    return Ow.clone();
}

cv::Mat KeyFrame::GetStereoCenter()
{
    unique_lock&lt;mutex&gt; lock(mMutexPose);
    return Cw.clone();
}


cv::Mat KeyFrame::GetRotation()
{
    unique_lock&lt;mutex&gt; lock(mMutexPose);
    return Tcw.rowRange(0,3).colRange(0,3).clone();
}

cv::Mat KeyFrame::GetTranslation()
{
    unique_lock&lt;mutex&gt; lock(mMutexPose);
    return Tcw.rowRange(0,3).col(3).clone();
}

void KeyFrame::AddConnection(KeyFrame *pKF, const int &amp;weight)
{
    {
        unique_lock&lt;mutex&gt; lock(mMutexConnections);
        if(!mConnectedKeyFrameWeights.count(pKF))
            mConnectedKeyFrameWeights[pKF]=weight;
        else if(mConnectedKeyFrameWeights[pKF]!=weight)
            mConnectedKeyFrameWeights[pKF]=weight;
        else
            return;
    }

    UpdateBestCovisibles();
}

void KeyFrame::UpdateBestCovisibles()
{
    unique_lock&lt;mutex&gt; lock(mMutexConnections);
    vector&lt;pair&lt;int,KeyFrame*&gt; &gt; vPairs;
    vPairs.reserve(mConnectedKeyFrameWeights.size());
    for(map&lt;KeyFrame*,int&gt;::iterator mit=mConnectedKeyFrameWeights.begin(), mend=mConnectedKeyFrameWeights.end(); mit!=mend; mit++)
       vPairs.push_back(make_pair(mit-&gt;second,mit-&gt;first));

    sort(vPairs.begin(),vPairs.end());
    list&lt;KeyFrame*&gt; lKFs;
    list&lt;int&gt; lWs;
    for(size_t i=0, iend=vPairs.size(); i&lt;iend;i++)
    {
        lKFs.push_front(vPairs[i].second);
        lWs.push_front(vPairs[i].first);
    }

    mvpOrderedConnectedKeyFrames = vector&lt;KeyFrame*&gt;(lKFs.begin(),lKFs.end());
    mvOrderedWeights = vector&lt;int&gt;(lWs.begin(), lWs.end());    
}

set&lt;KeyFrame*&gt; KeyFrame::GetConnectedKeyFrames()
{
    unique_lock&lt;mutex&gt; lock(mMutexConnections);
    set&lt;KeyFrame*&gt; s;
    for(map&lt;KeyFrame*,int&gt;::iterator mit=mConnectedKeyFrameWeights.begin();mit!=mConnectedKeyFrameWeights.end();mit++)
        s.insert(mit-&gt;first);
    return s;
}

vector&lt;KeyFrame*&gt; KeyFrame::GetVectorCovisibleKeyFrames()
{
    unique_lock&lt;mutex&gt; lock(mMutexConnections);
    return mvpOrderedConnectedKeyFrames;
}

vector&lt;KeyFrame*&gt; KeyFrame::GetBestCovisibilityKeyFrames(const int &amp;N)
{
    unique_lock&lt;mutex&gt; lock(mMutexConnections);
    if((int)mvpOrderedConnectedKeyFrames.size()&lt;N)
        return mvpOrderedConnectedKeyFrames;
    else
        return vector&lt;KeyFrame*&gt;(mvpOrderedConnectedKeyFrames.begin(),mvpOrderedConnectedKeyFrames.begin()+N);

}

vector&lt;KeyFrame*&gt; KeyFrame::GetCovisiblesByWeight(const int &amp;w)
{
    unique_lock&lt;mutex&gt; lock(mMutexConnections);

    if(mvpOrderedConnectedKeyFrames.empty())
        return vector&lt;KeyFrame*&gt;();

    vector&lt;int&gt;::iterator it = upper_bound(mvOrderedWeights.begin(),mvOrderedWeights.end(),w,KeyFrame::weightComp);
    if(it==mvOrderedWeights.end())
        return vector&lt;KeyFrame*&gt;();
    else
    {
        int n = it-mvOrderedWeights.begin();
        return vector&lt;KeyFrame*&gt;(mvpOrderedConnectedKeyFrames.begin(), mvpOrderedConnectedKeyFrames.begin()+n);
    }
}

int KeyFrame::GetWeight(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lock(mMutexConnections);
    if(mConnectedKeyFrameWeights.count(pKF))
        return mConnectedKeyFrameWeights[pKF];
    else
        return 0;
}

void KeyFrame::AddMapPoint(MapPoint *pMP, const size_t &amp;idx)
{
    unique_lock&lt;mutex&gt; lock(mMutexFeatures);
    mvpMapPoints[idx]=pMP;
}

void KeyFrame::EraseMapPointMatch(const size_t &amp;idx)
{
    unique_lock&lt;mutex&gt; lock(mMutexFeatures);
    mvpMapPoints[idx]=static_cast&lt;MapPoint*&gt;(NULL);
}

void KeyFrame::EraseMapPointMatch(MapPoint* pMP)
{
    int idx = pMP-&gt;GetIndexInKeyFrame(this);
    if(idx&gt;=0)
        mvpMapPoints[idx]=static_cast&lt;MapPoint*&gt;(NULL);
}


void KeyFrame::ReplaceMapPointMatch(const size_t &amp;idx, MapPoint* pMP)
{
    mvpMapPoints[idx]=pMP;
}

set&lt;MapPoint*&gt; KeyFrame::GetMapPoints()
{
    unique_lock&lt;mutex&gt; lock(mMutexFeatures);
    set&lt;MapPoint*&gt; s;
    for(size_t i=0, iend=mvpMapPoints.size(); i&lt;iend; i++)
    {
        if(!mvpMapPoints[i])
            continue;
        MapPoint* pMP = mvpMapPoints[i];
        if(!pMP-&gt;isBad())
            s.insert(pMP);
    }
    return s;
}

int KeyFrame::TrackedMapPoints(const int &amp;minObs)
{
    unique_lock&lt;mutex&gt; lock(mMutexFeatures);

    int nPoints=0;
    const bool bCheckObs = minObs&gt;0;
    for(int i=0; i&lt;N; i++)
    {
        MapPoint* pMP = mvpMapPoints[i];
        if(pMP)
        {
            if(!pMP-&gt;isBad())
            {
                if(bCheckObs)
                {
                    if(mvpMapPoints[i]-&gt;Observations()&gt;=minObs)
                        nPoints++;
                }
                else
                    nPoints++;
            }
        }
    }

    return nPoints;
}

vector&lt;MapPoint*&gt; KeyFrame::GetMapPointMatches()
{
    unique_lock&lt;mutex&gt; lock(mMutexFeatures);
    return mvpMapPoints;
}

MapPoint* KeyFrame::GetMapPoint(const size_t &amp;idx)
{
    unique_lock&lt;mutex&gt; lock(mMutexFeatures);
    return mvpMapPoints[idx];
}

void KeyFrame::UpdateConnections()
{
    map&lt;KeyFrame*,int&gt; KFcounter;

    vector&lt;MapPoint*&gt; vpMP;

    {
        unique_lock&lt;mutex&gt; lockMPs(mMutexFeatures);
        vpMP = mvpMapPoints;
    }

    //For all map points in keyframe check in which other keyframes are they seen
    //Increase counter for those keyframes
    for(vector&lt;MapPoint*&gt;::iterator vit=vpMP.begin(), vend=vpMP.end(); vit!=vend; vit++)
    {
        MapPoint* pMP = *vit;

        if(!pMP)
            continue;

        if(pMP-&gt;isBad())
            continue;

        map&lt;KeyFrame*,size_t&gt; observations = pMP-&gt;GetObservations();

        for(map&lt;KeyFrame*,size_t&gt;::iterator mit=observations.begin(), mend=observations.end(); mit!=mend; mit++)
        {
            if(mit-&gt;first-&gt;mnId==mnId)
                continue;
            KFcounter[mit-&gt;first]++;
        }
    }

    // This should not happen
    if(KFcounter.empty())
        return;

    //If the counter is greater than threshold add connection
    //In case no keyframe counter is over threshold add the one with maximum counter
    int nmax=0;
    KeyFrame* pKFmax=NULL;
    int th = 15;

    vector&lt;pair&lt;int,KeyFrame*&gt; &gt; vPairs;
    vPairs.reserve(KFcounter.size());
    for(map&lt;KeyFrame*,int&gt;::iterator mit=KFcounter.begin(), mend=KFcounter.end(); mit!=mend; mit++)
    {
        if(mit-&gt;second&gt;nmax)
        {
            nmax=mit-&gt;second;
            pKFmax=mit-&gt;first;
        }
        if(mit-&gt;second&gt;=th)
        {
            vPairs.push_back(make_pair(mit-&gt;second,mit-&gt;first));
            (mit-&gt;first)-&gt;AddConnection(this,mit-&gt;second);
        }
    }

    if(vPairs.empty())
    {
        vPairs.push_back(make_pair(nmax,pKFmax));
        pKFmax-&gt;AddConnection(this,nmax);
    }

    sort(vPairs.begin(),vPairs.end());
    list&lt;KeyFrame*&gt; lKFs;
    list&lt;int&gt; lWs;
    for(size_t i=0; i&lt;vPairs.size();i++)
    {
        lKFs.push_front(vPairs[i].second);
        lWs.push_front(vPairs[i].first);
    }

    {
        unique_lock&lt;mutex&gt; lockCon(mMutexConnections);

        // mspConnectedKeyFrames = spConnectedKeyFrames;
        mConnectedKeyFrameWeights = KFcounter;
        mvpOrderedConnectedKeyFrames = vector&lt;KeyFrame*&gt;(lKFs.begin(),lKFs.end());
        mvOrderedWeights = vector&lt;int&gt;(lWs.begin(), lWs.end());

        if(mbFirstConnection &amp;&amp; mnId!=0)
        {
            mpParent = mvpOrderedConnectedKeyFrames.front();
            mpParent-&gt;AddChild(this);
            mbFirstConnection = false;
        }

    }
}

void KeyFrame::AddChild(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lockCon(mMutexConnections);
    mspChildrens.insert(pKF);
}

void KeyFrame::EraseChild(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lockCon(mMutexConnections);
    mspChildrens.erase(pKF);
}

void KeyFrame::ChangeParent(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lockCon(mMutexConnections);
    mpParent = pKF;
    pKF-&gt;AddChild(this);
}

set&lt;KeyFrame*&gt; KeyFrame::GetChilds()
{
    unique_lock&lt;mutex&gt; lockCon(mMutexConnections);
    return mspChildrens;
}

KeyFrame* KeyFrame::GetParent()
{
    unique_lock&lt;mutex&gt; lockCon(mMutexConnections);
    return mpParent;
}

bool KeyFrame::hasChild(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lockCon(mMutexConnections);
    return mspChildrens.count(pKF);
}

void KeyFrame::AddLoopEdge(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lockCon(mMutexConnections);
    mbNotErase = true;
    mspLoopEdges.insert(pKF);
}

set&lt;KeyFrame*&gt; KeyFrame::GetLoopEdges()
{
    unique_lock&lt;mutex&gt; lockCon(mMutexConnections);
    return mspLoopEdges;
}

void KeyFrame::SetNotErase()
{
    unique_lock&lt;mutex&gt; lock(mMutexConnections);
    mbNotErase = true;
}

void KeyFrame::SetErase()
{
    {
        unique_lock&lt;mutex&gt; lock(mMutexConnections);
        if(mspLoopEdges.empty())
        {
            mbNotErase = false;
        }
    }

    if(mbToBeErased)
    {
        SetBadFlag();
    }
}

void KeyFrame::SetBadFlag()
{   
    {
        unique_lock&lt;mutex&gt; lock(mMutexConnections);
        if(mnId==0)
            return;
        else if(mbNotErase)
        {
            mbToBeErased = true;
            return;
        }
    }

    for(map&lt;KeyFrame*,int&gt;::iterator mit = mConnectedKeyFrameWeights.begin(), mend=mConnectedKeyFrameWeights.end(); mit!=mend; mit++)
        mit-&gt;first-&gt;EraseConnection(this);

    for(size_t i=0; i&lt;mvpMapPoints.size(); i++)
        if(mvpMapPoints[i])
            mvpMapPoints[i]-&gt;EraseObservation(this);
    {
        unique_lock&lt;mutex&gt; lock(mMutexConnections);
        unique_lock&lt;mutex&gt; lock1(mMutexFeatures);

        mConnectedKeyFrameWeights.clear();
        mvpOrderedConnectedKeyFrames.clear();

        // Update Spanning Tree
        set&lt;KeyFrame*&gt; sParentCandidates;
        sParentCandidates.insert(mpParent);

        // Assign at each iteration one children with a parent (the pair with highest covisibility weight)
        // Include that children as new parent candidate for the rest
        while(!mspChildrens.empty())
        {
            bool bContinue = false;

            int max = -1;
            KeyFrame* pC;
            KeyFrame* pP;

            for(set&lt;KeyFrame*&gt;::iterator sit=mspChildrens.begin(), send=mspChildrens.end(); sit!=send; sit++)
            {
                KeyFrame* pKF = *sit;
                if(pKF-&gt;isBad())
                    continue;

                // Check if a parent candidate is connected to the keyframe
                vector&lt;KeyFrame*&gt; vpConnected = pKF-&gt;GetVectorCovisibleKeyFrames();
                for(size_t i=0, iend=vpConnected.size(); i&lt;iend; i++)
                {
                    for(set&lt;KeyFrame*&gt;::iterator spcit=sParentCandidates.begin(), spcend=sParentCandidates.end(); spcit!=spcend; spcit++)
                    {
                        if(vpConnected[i]-&gt;mnId == (*spcit)-&gt;mnId)
                        {
                            int w = pKF-&gt;GetWeight(vpConnected[i]);
                            if(w&gt;max)
                            {
                                pC = pKF;
                                pP = vpConnected[i];
                                max = w;
                                bContinue = true;
                            }
                        }
                    }
                }
            }

            if(bContinue)
            {
                pC-&gt;ChangeParent(pP);
                sParentCandidates.insert(pC);
                mspChildrens.erase(pC);
            }
            else
                break;
        }

        // If a children has no covisibility links with any parent candidate, assign to the original parent of this KF
        if(!mspChildrens.empty())
            for(set&lt;KeyFrame*&gt;::iterator sit=mspChildrens.begin(); sit!=mspChildrens.end(); sit++)
            {
                (*sit)-&gt;ChangeParent(mpParent);
            }

        mpParent-&gt;EraseChild(this);
        mTcp = Tcw*mpParent-&gt;GetPoseInverse();
        mbBad = true;
    }


    mpMap-&gt;EraseKeyFrame(this);
    mpKeyFrameDB-&gt;erase(this);
}

bool KeyFrame::isBad()
{
    unique_lock&lt;mutex&gt; lock(mMutexConnections);
    return mbBad;
}

void KeyFrame::EraseConnection(KeyFrame* pKF)
{
    bool bUpdate = false;
    {
        unique_lock&lt;mutex&gt; lock(mMutexConnections);
        if(mConnectedKeyFrameWeights.count(pKF))
        {
            mConnectedKeyFrameWeights.erase(pKF);
            bUpdate=true;
        }
    }

    if(bUpdate)
        UpdateBestCovisibles();
}

vector&lt;size_t&gt; KeyFrame::GetFeaturesInArea(const float &amp;x, const float &amp;y, const float &amp;r) const
{
    vector&lt;size_t&gt; vIndices;
    vIndices.reserve(N);

    const int nMinCellX = max(0,(int)floor((x-mnMinX-r)*mfGridElementWidthInv));
    if(nMinCellX&gt;=mnGridCols)
        return vIndices;

    const int nMaxCellX = min((int)mnGridCols-1,(int)ceil((x-mnMinX+r)*mfGridElementWidthInv));
    if(nMaxCellX&lt;0)
        return vIndices;

    const int nMinCellY = max(0,(int)floor((y-mnMinY-r)*mfGridElementHeightInv));
    if(nMinCellY&gt;=mnGridRows)
        return vIndices;

    const int nMaxCellY = min((int)mnGridRows-1,(int)ceil((y-mnMinY+r)*mfGridElementHeightInv));
    if(nMaxCellY&lt;0)
        return vIndices;

    for(int ix = nMinCellX; ix&lt;=nMaxCellX; ix++)
    {
        for(int iy = nMinCellY; iy&lt;=nMaxCellY; iy++)
        {
            const vector&lt;size_t&gt; vCell = mGrid[ix][iy];
            for(size_t j=0, jend=vCell.size(); j&lt;jend; j++)
            {
                const cv::KeyPoint &amp;kpUn = mvKeysUn[vCell[j]];
                const float distx = kpUn.pt.x-x;
                const float disty = kpUn.pt.y-y;

                if(fabs(distx)&lt;r &amp;&amp; fabs(disty)&lt;r)
                    vIndices.push_back(vCell[j]);
            }
        }
    }

    return vIndices;
}

bool KeyFrame::IsInImage(const float &amp;x, const float &amp;y) const
{
    return (x&gt;=mnMinX &amp;&amp; x&lt;mnMaxX &amp;&amp; y&gt;=mnMinY &amp;&amp; y&lt;mnMaxY);
}

cv::Mat KeyFrame::UnprojectStereo(int i)
{
    const float z = mvDepth[i];
    if(z&gt;0)
    {
        const float u = mvKeys[i].pt.x;
        const float v = mvKeys[i].pt.y;
        const float x = (u-cx)*z*invfx;
        const float y = (v-cy)*z*invfy;
        cv::Mat x3Dc = (cv::Mat_&lt;float&gt;(3,1) &lt;&lt; x, y, z);

        unique_lock&lt;mutex&gt; lock(mMutexPose);
        return Twc.rowRange(0,3).colRange(0,3)*x3Dc+Twc.rowRange(0,3).col(3);
    }
    else
        return cv::Mat();
}

float KeyFrame::ComputeSceneMedianDepth(const int q)
{
    vector&lt;MapPoint*&gt; vpMapPoints;
    cv::Mat Tcw_;
    {
        unique_lock&lt;mutex&gt; lock(mMutexFeatures);
        unique_lock&lt;mutex&gt; lock2(mMutexPose);
        vpMapPoints = mvpMapPoints;
        Tcw_ = Tcw.clone();
    }

    vector&lt;float&gt; vDepths;
    vDepths.reserve(N);
    cv::Mat Rcw2 = Tcw_.row(2).colRange(0,3);
    Rcw2 = Rcw2.t();
    float zcw = Tcw_.at&lt;float&gt;(2,3);
    for(int i=0; i&lt;N; i++)
    {
        if(mvpMapPoints[i])
        {
            MapPoint* pMP = mvpMapPoints[i];
            cv::Mat x3Dw = pMP-&gt;GetWorldPos();
            float z = Rcw2.dot(x3Dw)+zcw;
            vDepths.push_back(z);
        }
    }

    sort(vDepths.begin(),vDepths.end());

    return vDepths[(vDepths.size()-1)/q];
}


void KeyFrame::fixConnections (Map *smap, KeyFrameDatabase *kfdb)
{
	mpMap = smap;
	mpKeyFrameDB = kfdb;
	mpORBvocabulary = kfdb-&gt;getVocabulary();

	// Do something
	mConnectedKeyFrameWeights = createObjectList&lt;KeyFrame&gt; (_imConnectedKeyFrameWeights);

	mvpOrderedConnectedKeyFrames = createObjectList&lt;KeyFrame&gt; (_vmvpOrderedConnectedKeyFrames);
	mvpOrderedConnectedKeyFrames = purgeNull(mvpOrderedConnectedKeyFrames);

	mpParent = (_parentId==-1) ? NULL : objectListLookup[_parentId];

	mspChildrens = createObjectList&lt;KeyFrame&gt; (_vmspChildrens);

	mspLoopEdges = createObjectList&lt;KeyFrame&gt; (_vmspLoopEdges);

	mvpMapPoints = createObjectList&lt;MapPoint&gt; (_mapPointIdList);

	// memory clearing
	_imConnectedKeyFrameWeights.clear();
	_vmvpOrderedConnectedKeyFrames.clear();
	_vmspChildrens.clear();
	_vmspLoopEdges.clear();
	_mapPointIdList.clear();

	// Offset the map by a value
//	if (extPosition.empty())
//		return;
//	tf::Transform baseLinkToCamera;
//	baseLinkToCamera.setOrigin(tf::Vector3(1.7, 0.0, 1.5));
//	baseLinkToCamera.setRotation(tf::Quaternion());
//	tf::Transform egoExtPos, newEgoExtPos;
//	egoExtPos.setRotation(tf::Quaternion());
//	egoExtPos.setOrigin (tf::Vector3(extPosition.at&lt;double&gt;(0),
//		extPosition.at&lt;double&gt;(1),
//		extPosition.at&lt;double&gt;(2)));
//	newEgoExtPos = egoExtPos * baseLinkToCamera;
//	extPosition.at&lt;double&gt;(0) = newEgoExtPos.getOrigin().x();
//	extPosition.at&lt;double&gt;(1) = newEgoExtPos.getOrigin().y();
//	extPosition.at&lt;double&gt;(2) = newEgoExtPos.getOrigin().z();
//	cout &lt;&lt; extPosition &lt;&lt; endl;

	return;
}


void KeyFrame::getDirectionVector (float &amp;dirX, float &amp;dirY, float &amp;dirZ)
{
	cv::Mat orient = this-&gt;GetRotation().t();
	vector&lt;float&gt; q = ORB_SLAM2::Converter::toQuaternion(orient);
	float norm = sqrtf(q[0]*q[0] + q[1]*q[1] + q[2]*q[2]);
	dirX = q[0]/norm;
	dirY = q[1]/norm;
	dirZ = q[2]/norm;
}


} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/KeyFrameDatabase.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/KeyFrameDatabase.cc">
				<diff>@@ -21,6 +21,8 @@
 #include &quot;KeyFrame.h&quot;
 #include &quot;KeyFrameDatabase.h&quot;
 #include &quot;DBoW2/BowVector.h&quot;
+#include &quot;Map.h&quot;
+
 
 #include&lt;mutex&gt;
 
@@ -29,7 +31,7 @@ using namespace std;
 namespace ORB_SLAM2
 {
 
-KeyFrameDatabase::KeyFrameDatabase (const ORBVocabulary &amp;voc):
+KeyFrameDatabase::KeyFrameDatabase (ORBVocabulary &amp;voc):
     mpVoc(&amp;voc)
 {
     mvInvertedFile.resize(voc.size());
@@ -195,6 +197,38 @@ vector&lt;KeyFrame*&gt; KeyFrameDatabase::DetectLoopCandidates(KeyFrame* pKF, float mi
     return vpLoopCandidates;
 }
 
+
+vector&lt;KeyFrame*&gt; KeyFrameDatabase::DetectRelocalizationCandidatesSimple (Frame *F)
+{
+	vector&lt;KeyFrame*&gt; lKFsSharingWords;
+
+	for (auto &amp;wId: F-&gt;mBowVec) {
+		list&lt;KeyFrame*&gt; &amp;lKFs = mvInvertedFile[wId.first];
+		for (auto &amp;kfp: lKFs) {
+			lKFsSharingWords.push_back (kfp);
+		}
+	}
+
+	if (lKFsSharingWords.empty())
+		return vector&lt;KeyFrame*&gt; ();
+
+	// XXX: Bad decision
+	float s = 0;
+	KeyFrame *kfchk = NULL;
+	for (auto kf: lKFsSharingWords) {
+		float si = mpVoc-&gt;score (kf-&gt;mBowVec, F-&gt;mBowVec);
+		if (si &gt; s) {
+			s = si;
+			kfchk = kf;
+		}
+	}
+
+	vector&lt;KeyFrame*&gt; ret;
+	ret.push_back (kfchk);
+	return ret;
+}
+
+
 vector&lt;KeyFrame*&gt; KeyFrameDatabase::DetectRelocalizationCandidates(Frame *F)
 {
     list&lt;KeyFrame*&gt; lKFsSharingWords;
@@ -285,7 +319,7 @@ vector&lt;KeyFrame*&gt; KeyFrameDatabase::DetectRelocalizationCandidates(Frame *F)
             bestAccScore=accScore;
     }
 
-    // Return all those keyframes with a score higher than 0.75*bestScore
+    // Return all keyframes with a score higher than 0.75*bestScore
     float minScoreToRetain = 0.75f*bestAccScore;
     set&lt;KeyFrame*&gt; spAlreadyAddedKF;
     vector&lt;KeyFrame*&gt; vpRelocCandidates;
@@ -307,4 +341,20 @@ vector&lt;KeyFrame*&gt; KeyFrameDatabase::DetectRelocalizationCandidates(Frame *F)
     return vpRelocCandidates;
 }
 
+
+void KeyFrameDatabase::replaceVocabulary (ORBVocabulary *newvoc, Map *cmap)
+{
+	mpVoc = newvoc;
+	mvInvertedFile.clear ();
+
+	vector&lt;KeyFrame*&gt; kfList = cmap-&gt;GetAllKeyFrames();
+	mvInvertedFile.resize (kfList.size());
+
+	for (auto kf: kfList) {
+		this-&gt;add (kf);
+		kf-&gt;RecomputeBoW (newvoc);
+	}
+}
+
+
 } //namespace ORB_SLAM
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#include &quot;KeyFrame.h&quot;
#include &quot;KeyFrameDatabase.h&quot;
#include &quot;DBoW2/BowVector.h&quot;

#include&lt;mutex&gt;

using namespace std;

namespace ORB_SLAM2
{

KeyFrameDatabase::KeyFrameDatabase (const ORBVocabulary &amp;voc):
    mpVoc(&amp;voc)
{
    mvInvertedFile.resize(voc.size());
}


void KeyFrameDatabase::add(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lock(mMutex);

    for(DBoW2::BowVector::const_iterator vit= pKF-&gt;mBowVec.begin(), vend=pKF-&gt;mBowVec.end(); vit!=vend; vit++)
        mvInvertedFile[vit-&gt;first].push_back(pKF);
}

void KeyFrameDatabase::erase(KeyFrame* pKF)
{
    unique_lock&lt;mutex&gt; lock(mMutex);

    // Erase elements in the Inverse File for the entry
    for(DBoW2::BowVector::const_iterator vit=pKF-&gt;mBowVec.begin(), vend=pKF-&gt;mBowVec.end(); vit!=vend; vit++)
    {
        // List of keyframes that share the word
        list&lt;KeyFrame*&gt; &amp;lKFs =   mvInvertedFile[vit-&gt;first];

        for(list&lt;KeyFrame*&gt;::iterator lit=lKFs.begin(), lend= lKFs.end(); lit!=lend; lit++)
        {
            if(pKF==*lit)
            {
                lKFs.erase(lit);
                break;
            }
        }
    }
}

void KeyFrameDatabase::clear()
{
    mvInvertedFile.clear();
    mvInvertedFile.resize(mpVoc-&gt;size());
}


vector&lt;KeyFrame*&gt; KeyFrameDatabase::DetectLoopCandidates(KeyFrame* pKF, float minScore)
{
    set&lt;KeyFrame*&gt; spConnectedKeyFrames = pKF-&gt;GetConnectedKeyFrames();
    list&lt;KeyFrame*&gt; lKFsSharingWords;

    // Search all keyframes that share a word with current keyframes
    // Discard keyframes connected to the query keyframe
    {
        unique_lock&lt;mutex&gt; lock(mMutex);

        for(DBoW2::BowVector::const_iterator vit=pKF-&gt;mBowVec.begin(), vend=pKF-&gt;mBowVec.end(); vit != vend; vit++)
        {
            list&lt;KeyFrame*&gt; &amp;lKFs =   mvInvertedFile[vit-&gt;first];

            for(list&lt;KeyFrame*&gt;::iterator lit=lKFs.begin(), lend= lKFs.end(); lit!=lend; lit++)
            {
                KeyFrame* pKFi=*lit;
                if(pKFi-&gt;mnLoopQuery!=pKF-&gt;mnId)
                {
                    pKFi-&gt;mnLoopWords=0;
                    if(!spConnectedKeyFrames.count(pKFi))
                    {
                        pKFi-&gt;mnLoopQuery=pKF-&gt;mnId;
                        lKFsSharingWords.push_back(pKFi);
                    }
                }
                pKFi-&gt;mnLoopWords++;
            }
        }
    }

    if(lKFsSharingWords.empty())
        return vector&lt;KeyFrame*&gt;();

    list&lt;pair&lt;float,KeyFrame*&gt; &gt; lScoreAndMatch;

    // Only compare against those keyframes that share enough words
    int maxCommonWords=0;
    for(list&lt;KeyFrame*&gt;::iterator lit=lKFsSharingWords.begin(), lend= lKFsSharingWords.end(); lit!=lend; lit++)
    {
        if((*lit)-&gt;mnLoopWords&gt;maxCommonWords)
            maxCommonWords=(*lit)-&gt;mnLoopWords;
    }

    int minCommonWords = maxCommonWords*0.8f;

    int nscores=0;

    // Compute similarity score. Retain the matches whose score is higher than minScore
    for(list&lt;KeyFrame*&gt;::iterator lit=lKFsSharingWords.begin(), lend= lKFsSharingWords.end(); lit!=lend; lit++)
    {
        KeyFrame* pKFi = *lit;

        if(pKFi-&gt;mnLoopWords&gt;minCommonWords)
        {
            nscores++;

            float si = mpVoc-&gt;score(pKF-&gt;mBowVec,pKFi-&gt;mBowVec);

            pKFi-&gt;mLoopScore = si;
            if(si&gt;=minScore)
                lScoreAndMatch.push_back(make_pair(si,pKFi));
        }
    }

    if(lScoreAndMatch.empty())
        return vector&lt;KeyFrame*&gt;();

    list&lt;pair&lt;float,KeyFrame*&gt; &gt; lAccScoreAndMatch;
    float bestAccScore = minScore;

    // Lets now accumulate score by covisibility
    for(list&lt;pair&lt;float,KeyFrame*&gt; &gt;::iterator it=lScoreAndMatch.begin(), itend=lScoreAndMatch.end(); it!=itend; it++)
    {
        KeyFrame* pKFi = it-&gt;second;
        vector&lt;KeyFrame*&gt; vpNeighs = pKFi-&gt;GetBestCovisibilityKeyFrames(10);

        float bestScore = it-&gt;first;
        float accScore = it-&gt;first;
        KeyFrame* pBestKF = pKFi;
        for(vector&lt;KeyFrame*&gt;::iterator vit=vpNeighs.begin(), vend=vpNeighs.end(); vit!=vend; vit++)
        {
            KeyFrame* pKF2 = *vit;
            if(pKF2-&gt;mnLoopQuery==pKF-&gt;mnId &amp;&amp; pKF2-&gt;mnLoopWords&gt;minCommonWords)
            {
                accScore+=pKF2-&gt;mLoopScore;
                if(pKF2-&gt;mLoopScore&gt;bestScore)
                {
                    pBestKF=pKF2;
                    bestScore = pKF2-&gt;mLoopScore;
                }
            }
        }

        lAccScoreAndMatch.push_back(make_pair(accScore,pBestKF));
        if(accScore&gt;bestAccScore)
            bestAccScore=accScore;
    }

    // Return all those keyframes with a score higher than 0.75*bestScore
    float minScoreToRetain = 0.75f*bestAccScore;

    set&lt;KeyFrame*&gt; spAlreadyAddedKF;
    vector&lt;KeyFrame*&gt; vpLoopCandidates;
    vpLoopCandidates.reserve(lAccScoreAndMatch.size());

    for(list&lt;pair&lt;float,KeyFrame*&gt; &gt;::iterator it=lAccScoreAndMatch.begin(), itend=lAccScoreAndMatch.end(); it!=itend; it++)
    {
        if(it-&gt;first&gt;minScoreToRetain)
        {
            KeyFrame* pKFi = it-&gt;second;
            if(!spAlreadyAddedKF.count(pKFi))
            {
                vpLoopCandidates.push_back(pKFi);
                spAlreadyAddedKF.insert(pKFi);
            }
        }
    }


    return vpLoopCandidates;
}

vector&lt;KeyFrame*&gt; KeyFrameDatabase::DetectRelocalizationCandidates(Frame *F)
{
    list&lt;KeyFrame*&gt; lKFsSharingWords;

    // Search all keyframes that share a word with current frame
    {
        unique_lock&lt;mutex&gt; lock(mMutex);

        for(DBoW2::BowVector::const_iterator vit=F-&gt;mBowVec.begin(), vend=F-&gt;mBowVec.end(); vit != vend; vit++)
        {
            list&lt;KeyFrame*&gt; &amp;lKFs =   mvInvertedFile[vit-&gt;first];

            for(list&lt;KeyFrame*&gt;::iterator lit=lKFs.begin(), lend= lKFs.end(); lit!=lend; lit++)
            {
                KeyFrame* pKFi=*lit;
                if(pKFi-&gt;mnRelocQuery!=F-&gt;mnId)
                {
                    pKFi-&gt;mnRelocWords=0;
                    pKFi-&gt;mnRelocQuery=F-&gt;mnId;
                    lKFsSharingWords.push_back(pKFi);
                }
                pKFi-&gt;mnRelocWords++;
            }
        }
    }
    if(lKFsSharingWords.empty())
        return vector&lt;KeyFrame*&gt;();

    // Only compare against those keyframes that share enough words
    int maxCommonWords=0;
    for(list&lt;KeyFrame*&gt;::iterator lit=lKFsSharingWords.begin(), lend= lKFsSharingWords.end(); lit!=lend; lit++)
    {
        if((*lit)-&gt;mnRelocWords&gt;maxCommonWords)
            maxCommonWords=(*lit)-&gt;mnRelocWords;
    }

    int minCommonWords = maxCommonWords*0.8f;

    list&lt;pair&lt;float,KeyFrame*&gt; &gt; lScoreAndMatch;

    int nscores=0;

    // Compute similarity score.
    for(list&lt;KeyFrame*&gt;::iterator lit=lKFsSharingWords.begin(), lend= lKFsSharingWords.end(); lit!=lend; lit++)
    {
        KeyFrame* pKFi = *lit;

        if(pKFi-&gt;mnRelocWords&gt;minCommonWords)
        {
            nscores++;
            float si = mpVoc-&gt;score(F-&gt;mBowVec,pKFi-&gt;mBowVec);
            pKFi-&gt;mRelocScore=si;
            lScoreAndMatch.push_back(make_pair(si,pKFi));
        }
    }

    if(lScoreAndMatch.empty())
        return vector&lt;KeyFrame*&gt;();

    list&lt;pair&lt;float,KeyFrame*&gt; &gt; lAccScoreAndMatch;
    float bestAccScore = 0;

    // Lets now accumulate score by covisibility
    for(list&lt;pair&lt;float,KeyFrame*&gt; &gt;::iterator it=lScoreAndMatch.begin(), itend=lScoreAndMatch.end(); it!=itend; it++)
    {
        KeyFrame* pKFi = it-&gt;second;
        vector&lt;KeyFrame*&gt; vpNeighs = pKFi-&gt;GetBestCovisibilityKeyFrames(10);

        float bestScore = it-&gt;first;
        float accScore = bestScore;
        KeyFrame* pBestKF = pKFi;
        for(vector&lt;KeyFrame*&gt;::iterator vit=vpNeighs.begin(), vend=vpNeighs.end(); vit!=vend; vit++)
        {
            KeyFrame* pKF2 = *vit;
            if(pKF2-&gt;mnRelocQuery!=F-&gt;mnId)
                continue;

            accScore+=pKF2-&gt;mRelocScore;
            if(pKF2-&gt;mRelocScore&gt;bestScore)
            {
                pBestKF=pKF2;
                bestScore = pKF2-&gt;mRelocScore;
            }

        }
        lAccScoreAndMatch.push_back(make_pair(accScore,pBestKF));
        if(accScore&gt;bestAccScore)
            bestAccScore=accScore;
    }

    // Return all those keyframes with a score higher than 0.75*bestScore
    float minScoreToRetain = 0.75f*bestAccScore;
    set&lt;KeyFrame*&gt; spAlreadyAddedKF;
    vector&lt;KeyFrame*&gt; vpRelocCandidates;
    vpRelocCandidates.reserve(lAccScoreAndMatch.size());
    for(list&lt;pair&lt;float,KeyFrame*&gt; &gt;::iterator it=lAccScoreAndMatch.begin(), itend=lAccScoreAndMatch.end(); it!=itend; it++)
    {
        const float &amp;si = it-&gt;first;
        if(si&gt;minScoreToRetain)
        {
            KeyFrame* pKFi = it-&gt;second;
            if(!spAlreadyAddedKF.count(pKFi))
            {
                vpRelocCandidates.push_back(pKFi);
                spAlreadyAddedKF.insert(pKFi);
            }
        }
    }

    return vpRelocCandidates;
}

} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/LocalMapping.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/LocalMapping.cc">
				<diff>@@ -30,9 +30,10 @@
 namespace ORB_SLAM2
 {
 
-LocalMapping::LocalMapping(Map *pMap, const float bMonocular):
+LocalMapping::LocalMapping(Map *pMap, const float bMonocular, const bool offlineMode):
     mbMonocular(bMonocular), mbResetRequested(false), mbFinishRequested(false), mbFinished(true), mpMap(pMap),
-    mbAbortBA(false), mbStopped(false), mbStopRequested(false), mbNotStop(false), mbAcceptKeyFrames(true)
+    mbAbortBA(false), mbStopped(false), mbStopRequested(false), mbNotStop(false), mbAcceptKeyFrames(true),
+	offlineMapping (offlineMode)
 {
 }
 
@@ -126,8 +127,6 @@ void LocalMapping::Run()
 
 void LocalMapping::RunOnce()
 {
-    mbFinished = false;
-
 	// Check if there are keyframes in the queue
 	if(CheckNewKeyFrames())
 	{
@@ -148,7 +147,7 @@ void LocalMapping::RunOnce()
 
 		mbAbortBA = false;
 
-		if(!CheckNewKeyFrames() &amp;&amp; !stopRequested())
+		if(!CheckNewKeyFrames())
 		{
 			// Local BA
 			if(mpMap-&gt;KeyFramesInMap()&gt;2)
@@ -160,11 +159,6 @@ void LocalMapping::RunOnce()
 
 		mpLoopCloser-&gt;InsertKeyFrame(mpCurrentKeyFrame);
 	}
-
-	// Tracking will see that Local Mapping is busy
-	SetAcceptKeyFrames(true);
-
-    SetFinish();
 }
 
 
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#include &quot;LocalMapping.h&quot;
#include &quot;LoopClosing.h&quot;
#include &quot;ORBmatcher.h&quot;
#include &quot;Optimizer.h&quot;

#include&lt;mutex&gt;



namespace ORB_SLAM2
{

LocalMapping::LocalMapping(Map *pMap, const float bMonocular):
    mbMonocular(bMonocular), mbResetRequested(false), mbFinishRequested(false), mbFinished(true), mpMap(pMap),
    mbAbortBA(false), mbStopped(false), mbStopRequested(false), mbNotStop(false), mbAcceptKeyFrames(true)
{
}

void LocalMapping::SetLoopCloser(LoopClosing* pLoopCloser)
{
    mpLoopCloser = pLoopCloser;
}

void LocalMapping::SetTracker(Tracking *pTracker)
{
    mpTracker=pTracker;
}

void LocalMapping::Run()
{

    mbFinished = false;

    while(1)
    {
//    	localMappingRunMutex.lock ();
//    	cout &lt;&lt; &quot;LocalMapping Run start&quot; &lt;&lt; endl;

        // Tracking will see that Local Mapping is busy
        SetAcceptKeyFrames(false);

        // Check if there are keyframes in the queue
        if(CheckNewKeyFrames())
        {

            // BoW conversion and insertion in Map
            ProcessNewKeyFrame();

            // Check recent MapPoints
            MapPointCulling();

            // Triangulate new MapPoints
            CreateNewMapPoints();

            if(!CheckNewKeyFrames())
            {
                // Find more matches in neighbor keyframes and fuse point duplications
                SearchInNeighbors();
            }

            mbAbortBA = false;

            if(!CheckNewKeyFrames() &amp;&amp; !stopRequested())
            {
                // Local BA
                if(mpMap-&gt;KeyFramesInMap()&gt;2)
                    Optimizer::LocalBundleAdjustment(mpCurrentKeyFrame,&amp;mbAbortBA, mpMap);

                // Check redundant local Keyframes
                KeyFrameCulling();
            }

            mpLoopCloser-&gt;InsertKeyFrame(mpCurrentKeyFrame);

        }
        else if(Stop())
        {
            // Safe area to stop
            while(isStopped() &amp;&amp; !CheckFinish())
            {
                usleep(3000);
            }
//            localMappingRunMutex.unlock();
            if(CheckFinish()) {
//            	localMappingRunMutex.unlock();
                break;
            }
        }

        ResetIfRequested();

        // Tracking will see that Local Mapping is busy
        SetAcceptKeyFrames(true);
//        cout &lt;&lt; &quot;LocalMapping Run stop&quot; &lt;&lt; endl;
//        localMappingRunMutex.unlock();

        if(CheckFinish())
            break;

        usleep(3000);
    }

    SetFinish();
}


void LocalMapping::RunOnce()
{
    mbFinished = false;

	// Check if there are keyframes in the queue
	if(CheckNewKeyFrames())
	{
		// BoW conversion and insertion in Map
		ProcessNewKeyFrame();

		// Check recent MapPoints
		MapPointCulling();

		// Triangulate new MapPoints
		CreateNewMapPoints();

		if(!CheckNewKeyFrames())
		{
			// Find more matches in neighbor keyframes and fuse point duplications
			SearchInNeighbors();
		}

		mbAbortBA = false;

		if(!CheckNewKeyFrames() &amp;&amp; !stopRequested())
		{
			// Local BA
			if(mpMap-&gt;KeyFramesInMap()&gt;2)
				Optimizer::LocalBundleAdjustment(mpCurrentKeyFrame,&amp;mbAbortBA, mpMap);

			// Check redundant local Keyframes
			KeyFrameCulling();
		}

		mpLoopCloser-&gt;InsertKeyFrame(mpCurrentKeyFrame);
	}

	// Tracking will see that Local Mapping is busy
	SetAcceptKeyFrames(true);

    SetFinish();
}


void LocalMapping::InsertKeyFrame(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lock(mMutexNewKFs);
    mlNewKeyFrames.push_back(pKF);
    mbAbortBA=true;
}


bool LocalMapping::CheckNewKeyFrames()
{
    unique_lock&lt;mutex&gt; lock(mMutexNewKFs);
    return(!mlNewKeyFrames.empty());
}

void LocalMapping::ProcessNewKeyFrame()
{
    {
        unique_lock&lt;mutex&gt; lock(mMutexNewKFs);
        mpCurrentKeyFrame = mlNewKeyFrames.front();
        mlNewKeyFrames.pop_front();
    }

    // Compute Bags of Words structures
    mpCurrentKeyFrame-&gt;ComputeBoW();

    // Associate MapPoints to the new keyframe and update normal and descriptor
    const vector&lt;MapPoint*&gt; vpMapPointMatches = mpCurrentKeyFrame-&gt;GetMapPointMatches();

    for(size_t i=0; i&lt;vpMapPointMatches.size(); i++)
    {
        MapPoint* pMP = vpMapPointMatches[i];
        if(pMP)
        {
            if(!pMP-&gt;isBad())
            {
                if(!pMP-&gt;IsInKeyFrame(mpCurrentKeyFrame))
                {
                    pMP-&gt;AddObservation(mpCurrentKeyFrame, i);
                    pMP-&gt;UpdateNormalAndDepth();
                    pMP-&gt;ComputeDistinctiveDescriptors();
                }
                else // this can only happen for new stereo points inserted by the Tracking
                {
                    mlpRecentAddedMapPoints.push_back(pMP);
                }
            }
        }
    }    

    // Update links in the Covisibility Graph
    mpCurrentKeyFrame-&gt;UpdateConnections();

    // Insert Keyframe in Map
    mpMap-&gt;AddKeyFrame(mpCurrentKeyFrame);
}

void LocalMapping::MapPointCulling()
{
    // Check Recent Added MapPoints
    list&lt;MapPoint*&gt;::iterator lit = mlpRecentAddedMapPoints.begin();
    const unsigned long int nCurrentKFid = mpCurrentKeyFrame-&gt;mnId;

    int nThObs;
    if(mbMonocular)
        nThObs = 2;
    else
        nThObs = 3;
    const int cnThObs = nThObs;

    while(lit!=mlpRecentAddedMapPoints.end())
    {
        MapPoint* pMP = *lit;
        if(pMP-&gt;isBad())
        {
            lit = mlpRecentAddedMapPoints.erase(lit);
        }
        else if(pMP-&gt;GetFoundRatio()&lt;0.25f )
        {
            pMP-&gt;SetBadFlag();
            lit = mlpRecentAddedMapPoints.erase(lit);
        }
        else if(((int)nCurrentKFid-(int)pMP-&gt;mnFirstKFid)&gt;=2 &amp;&amp; pMP-&gt;Observations()&lt;=cnThObs)
        {
            pMP-&gt;SetBadFlag();
            lit = mlpRecentAddedMapPoints.erase(lit);
        }
        else if(((int)nCurrentKFid-(int)pMP-&gt;mnFirstKFid)&gt;=3)
            lit = mlpRecentAddedMapPoints.erase(lit);
        else
            lit++;
    }
}

void LocalMapping::CreateNewMapPoints()
{
    // Retrieve neighbor keyframes in covisibility graph
    int nn = 10;
    if(mbMonocular)
        nn=20;
    const vector&lt;KeyFrame*&gt; vpNeighKFs = mpCurrentKeyFrame-&gt;GetBestCovisibilityKeyFrames(nn);

    ORBmatcher matcher(0.6,false);

    cv::Mat Rcw1 = mpCurrentKeyFrame-&gt;GetRotation();
    cv::Mat Rwc1 = Rcw1.t();
    cv::Mat tcw1 = mpCurrentKeyFrame-&gt;GetTranslation();
    cv::Mat Tcw1(3,4,CV_32F);
    Rcw1.copyTo(Tcw1.colRange(0,3));
    tcw1.copyTo(Tcw1.col(3));
    cv::Mat Ow1 = mpCurrentKeyFrame-&gt;GetCameraCenter();

    const float &amp;fx1 = mpCurrentKeyFrame-&gt;fx;
    const float &amp;fy1 = mpCurrentKeyFrame-&gt;fy;
    const float &amp;cx1 = mpCurrentKeyFrame-&gt;cx;
    const float &amp;cy1 = mpCurrentKeyFrame-&gt;cy;
    const float &amp;invfx1 = mpCurrentKeyFrame-&gt;invfx;
    const float &amp;invfy1 = mpCurrentKeyFrame-&gt;invfy;

    const float ratioFactor = 1.5f*mpCurrentKeyFrame-&gt;mfScaleFactor;

    int nnew=0;

    // Search matches with epipolar restriction and triangulate
    for(size_t i=0; i&lt;vpNeighKFs.size(); i++)
    {
        if(i&gt;0 &amp;&amp; CheckNewKeyFrames())
            return;

        KeyFrame* pKF2 = vpNeighKFs[i];

        // Check first that baseline is not too short
        cv::Mat Ow2 = pKF2-&gt;GetCameraCenter();
        cv::Mat vBaseline = Ow2-Ow1;
        const float baseline = cv::norm(vBaseline);

        if(!mbMonocular)
        {
            if(baseline&lt;pKF2-&gt;mb)
            continue;
        }
        else
        {
            const float medianDepthKF2 = pKF2-&gt;ComputeSceneMedianDepth(2);
            const float ratioBaselineDepth = baseline/medianDepthKF2;

            if(ratioBaselineDepth&lt;0.01)
                continue;
        }

        // Compute Fundamental Matrix
        cv::Mat F12 = ComputeF12(mpCurrentKeyFrame,pKF2);

        // Search matches that fullfil epipolar constraint
        vector&lt;pair&lt;size_t,size_t&gt; &gt; vMatchedIndices;
        matcher.SearchForTriangulation(mpCurrentKeyFrame,pKF2,F12,vMatchedIndices,false);

        cv::Mat Rcw2 = pKF2-&gt;GetRotation();
        cv::Mat Rwc2 = Rcw2.t();
        cv::Mat tcw2 = pKF2-&gt;GetTranslation();
        cv::Mat Tcw2(3,4,CV_32F);
        Rcw2.copyTo(Tcw2.colRange(0,3));
        tcw2.copyTo(Tcw2.col(3));

        const float &amp;fx2 = pKF2-&gt;fx;
        const float &amp;fy2 = pKF2-&gt;fy;
        const float &amp;cx2 = pKF2-&gt;cx;
        const float &amp;cy2 = pKF2-&gt;cy;
        const float &amp;invfx2 = pKF2-&gt;invfx;
        const float &amp;invfy2 = pKF2-&gt;invfy;

        // Triangulate each match
        const int nmatches = vMatchedIndices.size();
        for(int ikp=0; ikp&lt;nmatches; ikp++)
        {
            const int &amp;idx1 = vMatchedIndices[ikp].first;
            const int &amp;idx2 = vMatchedIndices[ikp].second;

            const cv::KeyPoint &amp;kp1 = mpCurrentKeyFrame-&gt;mvKeysUn[idx1];
            const float kp1_ur=mpCurrentKeyFrame-&gt;mvuRight[idx1];
            bool bStereo1 = kp1_ur&gt;=0;

            const cv::KeyPoint &amp;kp2 = pKF2-&gt;mvKeysUn[idx2];
            const float kp2_ur = pKF2-&gt;mvuRight[idx2];
            bool bStereo2 = kp2_ur&gt;=0;

            // Check parallax between rays
            cv::Mat xn1 = (cv::Mat_&lt;float&gt;(3,1) &lt;&lt; (kp1.pt.x-cx1)*invfx1, (kp1.pt.y-cy1)*invfy1, 1.0);
            cv::Mat xn2 = (cv::Mat_&lt;float&gt;(3,1) &lt;&lt; (kp2.pt.x-cx2)*invfx2, (kp2.pt.y-cy2)*invfy2, 1.0);

            cv::Mat ray1 = Rwc1*xn1;
            cv::Mat ray2 = Rwc2*xn2;
            const float cosParallaxRays = ray1.dot(ray2)/(cv::norm(ray1)*cv::norm(ray2));

            float cosParallaxStereo = cosParallaxRays+1;
            float cosParallaxStereo1 = cosParallaxStereo;
            float cosParallaxStereo2 = cosParallaxStereo;

            if(bStereo1)
                cosParallaxStereo1 = cos(2*atan2(mpCurrentKeyFrame-&gt;mb/2,mpCurrentKeyFrame-&gt;mvDepth[idx1]));
            else if(bStereo2)
                cosParallaxStereo2 = cos(2*atan2(pKF2-&gt;mb/2,pKF2-&gt;mvDepth[idx2]));

            cosParallaxStereo = min(cosParallaxStereo1,cosParallaxStereo2);

            cv::Mat x3D;
            if(cosParallaxRays&lt;cosParallaxStereo &amp;&amp; cosParallaxRays&gt;0 &amp;&amp; (bStereo1 || bStereo2 || cosParallaxRays&lt;0.9998))
            {
                // Linear Triangulation Method
                cv::Mat A(4,4,CV_32F);
                A.row(0) = xn1.at&lt;float&gt;(0)*Tcw1.row(2)-Tcw1.row(0);
                A.row(1) = xn1.at&lt;float&gt;(1)*Tcw1.row(2)-Tcw1.row(1);
                A.row(2) = xn2.at&lt;float&gt;(0)*Tcw2.row(2)-Tcw2.row(0);
                A.row(3) = xn2.at&lt;float&gt;(1)*Tcw2.row(2)-Tcw2.row(1);

                cv::Mat w,u,vt;
                cv::SVD::compute(A,w,u,vt,cv::SVD::MODIFY_A| cv::SVD::FULL_UV);

                x3D = vt.row(3).t();

                if(x3D.at&lt;float&gt;(3)==0)
                    continue;

                // Euclidean coordinates
                x3D = x3D.rowRange(0,3)/x3D.at&lt;float&gt;(3);

            }
            else if(bStereo1 &amp;&amp; cosParallaxStereo1&lt;cosParallaxStereo2)
            {
                x3D = mpCurrentKeyFrame-&gt;UnprojectStereo(idx1);                
            }
            else if(bStereo2 &amp;&amp; cosParallaxStereo2&lt;cosParallaxStereo1)
            {
                x3D = pKF2-&gt;UnprojectStereo(idx2);
            }
            else
                continue; //No stereo and very low parallax

            cv::Mat x3Dt = x3D.t();

            //Check triangulation in front of cameras
            float z1 = Rcw1.row(2).dot(x3Dt)+tcw1.at&lt;float&gt;(2);
            if(z1&lt;=0)
                continue;

            float z2 = Rcw2.row(2).dot(x3Dt)+tcw2.at&lt;float&gt;(2);
            if(z2&lt;=0)
                continue;

            //Check reprojection error in first keyframe
            const float &amp;sigmaSquare1 = mpCurrentKeyFrame-&gt;mvLevelSigma2[kp1.octave];
            const float x1 = Rcw1.row(0).dot(x3Dt)+tcw1.at&lt;float&gt;(0);
            const float y1 = Rcw1.row(1).dot(x3Dt)+tcw1.at&lt;float&gt;(1);
            const float invz1 = 1.0/z1;

            if(!bStereo1)
            {
                float u1 = fx1*x1*invz1+cx1;
                float v1 = fy1*y1*invz1+cy1;
                float errX1 = u1 - kp1.pt.x;
                float errY1 = v1 - kp1.pt.y;
                if((errX1*errX1+errY1*errY1)&gt;5.991*sigmaSquare1)
                    continue;
            }
            else
            {
                float u1 = fx1*x1*invz1+cx1;
                float u1_r = u1 - mpCurrentKeyFrame-&gt;mbf*invz1;
                float v1 = fy1*y1*invz1+cy1;
                float errX1 = u1 - kp1.pt.x;
                float errY1 = v1 - kp1.pt.y;
                float errX1_r = u1_r - kp1_ur;
                if((errX1*errX1+errY1*errY1+errX1_r*errX1_r)&gt;7.8*sigmaSquare1)
                    continue;
            }

            //Check reprojection error in second keyframe
            const float sigmaSquare2 = pKF2-&gt;mvLevelSigma2[kp2.octave];
            const float x2 = Rcw2.row(0).dot(x3Dt)+tcw2.at&lt;float&gt;(0);
            const float y2 = Rcw2.row(1).dot(x3Dt)+tcw2.at&lt;float&gt;(1);
            const float invz2 = 1.0/z2;
            if(!bStereo2)
            {
                float u2 = fx2*x2*invz2+cx2;
                float v2 = fy2*y2*invz2+cy2;
                float errX2 = u2 - kp2.pt.x;
                float errY2 = v2 - kp2.pt.y;
                if((errX2*errX2+errY2*errY2)&gt;5.991*sigmaSquare2)
                    continue;
            }
            else
            {
                float u2 = fx2*x2*invz2+cx2;
                float u2_r = u2 - mpCurrentKeyFrame-&gt;mbf*invz2;
                float v2 = fy2*y2*invz2+cy2;
                float errX2 = u2 - kp2.pt.x;
                float errY2 = v2 - kp2.pt.y;
                float errX2_r = u2_r - kp2_ur;
                if((errX2*errX2+errY2*errY2+errX2_r*errX2_r)&gt;7.8*sigmaSquare2)
                    continue;
            }

            //Check scale consistency
            cv::Mat normal1 = x3D-Ow1;
            float dist1 = cv::norm(normal1);

            cv::Mat normal2 = x3D-Ow2;
            float dist2 = cv::norm(normal2);

            if(dist1==0 || dist2==0)
                continue;

            const float ratioDist = dist2/dist1;
            const float ratioOctave = mpCurrentKeyFrame-&gt;mvScaleFactors[kp1.octave]/pKF2-&gt;mvScaleFactors[kp2.octave];

            /*if(fabs(ratioDist-ratioOctave)&gt;ratioFactor)
                continue;*/
            if(ratioDist*ratioFactor&lt;ratioOctave || ratioDist&gt;ratioOctave*ratioFactor)
                continue;

            // Triangulation is succesfull
            MapPoint* pMP = new MapPoint(x3D,mpCurrentKeyFrame,mpMap);

            pMP-&gt;AddObservation(mpCurrentKeyFrame,idx1);            
            pMP-&gt;AddObservation(pKF2,idx2);

            mpCurrentKeyFrame-&gt;AddMapPoint(pMP,idx1);
            pKF2-&gt;AddMapPoint(pMP,idx2);

            pMP-&gt;ComputeDistinctiveDescriptors();

            pMP-&gt;UpdateNormalAndDepth();

            mpMap-&gt;AddMapPoint(pMP);
            mlpRecentAddedMapPoints.push_back(pMP);

            nnew++;
        }
    }
}

void LocalMapping::SearchInNeighbors()
{
    // Retrieve neighbor keyframes
    int nn = 10;
    if(mbMonocular)
        nn=20;
    const vector&lt;KeyFrame*&gt; vpNeighKFs = mpCurrentKeyFrame-&gt;GetBestCovisibilityKeyFrames(nn);
    vector&lt;KeyFrame*&gt; vpTargetKFs;
    for(vector&lt;KeyFrame*&gt;::const_iterator vit=vpNeighKFs.begin(), vend=vpNeighKFs.end(); vit!=vend; vit++)
    {
        KeyFrame* pKFi = *vit;
        if(pKFi-&gt;isBad() || pKFi-&gt;mnFuseTargetForKF == mpCurrentKeyFrame-&gt;mnId)
            continue;
        vpTargetKFs.push_back(pKFi);
        pKFi-&gt;mnFuseTargetForKF = mpCurrentKeyFrame-&gt;mnId;

        // Extend to some second neighbors
        const vector&lt;KeyFrame*&gt; vpSecondNeighKFs = pKFi-&gt;GetBestCovisibilityKeyFrames(5);
        for(vector&lt;KeyFrame*&gt;::const_iterator vit2=vpSecondNeighKFs.begin(), vend2=vpSecondNeighKFs.end(); vit2!=vend2; vit2++)
        {
            KeyFrame* pKFi2 = *vit2;
            if(pKFi2-&gt;isBad() || pKFi2-&gt;mnFuseTargetForKF==mpCurrentKeyFrame-&gt;mnId || pKFi2-&gt;mnId==mpCurrentKeyFrame-&gt;mnId)
                continue;
            vpTargetKFs.push_back(pKFi2);
        }
    }


    // Search matches by projection from current KF in target KFs
    ORBmatcher matcher;
    vector&lt;MapPoint*&gt; vpMapPointMatches = mpCurrentKeyFrame-&gt;GetMapPointMatches();
    for(vector&lt;KeyFrame*&gt;::iterator vit=vpTargetKFs.begin(), vend=vpTargetKFs.end(); vit!=vend; vit++)
    {
        KeyFrame* pKFi = *vit;

        matcher.Fuse(pKFi,vpMapPointMatches);
    }

    // Search matches by projection from target KFs in current KF
    vector&lt;MapPoint*&gt; vpFuseCandidates;
    vpFuseCandidates.reserve(vpTargetKFs.size()*vpMapPointMatches.size());

    for(vector&lt;KeyFrame*&gt;::iterator vitKF=vpTargetKFs.begin(), vendKF=vpTargetKFs.end(); vitKF!=vendKF; vitKF++)
    {
        KeyFrame* pKFi = *vitKF;

        vector&lt;MapPoint*&gt; vpMapPointsKFi = pKFi-&gt;GetMapPointMatches();

        for(vector&lt;MapPoint*&gt;::iterator vitMP=vpMapPointsKFi.begin(), vendMP=vpMapPointsKFi.end(); vitMP!=vendMP; vitMP++)
        {
            MapPoint* pMP = *vitMP;
            if(!pMP)
                continue;
            if(pMP-&gt;isBad() || pMP-&gt;mnFuseCandidateForKF == mpCurrentKeyFrame-&gt;mnId)
                continue;
            pMP-&gt;mnFuseCandidateForKF = mpCurrentKeyFrame-&gt;mnId;
            vpFuseCandidates.push_back(pMP);
        }
    }

    matcher.Fuse(mpCurrentKeyFrame,vpFuseCandidates);


    // Update points
    vpMapPointMatches = mpCurrentKeyFrame-&gt;GetMapPointMatches();
    for(size_t i=0, iend=vpMapPointMatches.size(); i&lt;iend; i++)
    {
        MapPoint* pMP=vpMapPointMatches[i];
        if(pMP)
        {
            if(!pMP-&gt;isBad())
            {
                pMP-&gt;ComputeDistinctiveDescriptors();
                pMP-&gt;UpdateNormalAndDepth();
            }
        }
    }

    // Update connections in covisibility graph
    mpCurrentKeyFrame-&gt;UpdateConnections();
}

cv::Mat LocalMapping::ComputeF12(KeyFrame *&amp;pKF1, KeyFrame *&amp;pKF2)
{
    cv::Mat R1w = pKF1-&gt;GetRotation();
    cv::Mat t1w = pKF1-&gt;GetTranslation();
    cv::Mat R2w = pKF2-&gt;GetRotation();
    cv::Mat t2w = pKF2-&gt;GetTranslation();

    cv::Mat R12 = R1w*R2w.t();
    cv::Mat t12 = -R1w*R2w.t()*t2w+t1w;

    cv::Mat t12x = SkewSymmetricMatrix(t12);

    const cv::Mat &amp;K1 = pKF1-&gt;mK;
    const cv::Mat &amp;K2 = pKF2-&gt;mK;


    return K1.t().inv()*t12x*R12*K2.inv();
}

void LocalMapping::RequestStop()
{
    unique_lock&lt;mutex&gt; lock(mMutexStop);
    mbStopRequested = true;
    unique_lock&lt;mutex&gt; lock2(mMutexNewKFs);
    mbAbortBA = true;
}

bool LocalMapping::Stop()
{
    unique_lock&lt;mutex&gt; lock(mMutexStop);
    if(mbStopRequested &amp;&amp; !mbNotStop)
    {
        mbStopped = true;
        cout &lt;&lt; &quot;Local Mapping STOP&quot; &lt;&lt; endl;
        return true;
    }

    return false;
}

bool LocalMapping::isStopped()
{
    unique_lock&lt;mutex&gt; lock(mMutexStop);
    return mbStopped;
}

bool LocalMapping::stopRequested()
{
    unique_lock&lt;mutex&gt; lock(mMutexStop);
    return mbStopRequested;
}

void LocalMapping::Release()
{
    unique_lock&lt;mutex&gt; lock(mMutexStop);
    unique_lock&lt;mutex&gt; lock2(mMutexFinish);
    if(mbFinished)
        return;
    mbStopped = false;
    mbStopRequested = false;
    for(list&lt;KeyFrame*&gt;::iterator lit = mlNewKeyFrames.begin(), lend=mlNewKeyFrames.end(); lit!=lend; lit++)
        delete *lit;
    mlNewKeyFrames.clear();

    cout &lt;&lt; &quot;Local Mapping RELEASE&quot; &lt;&lt; endl;
}

bool LocalMapping::AcceptKeyFrames()
{
    unique_lock&lt;mutex&gt; lock(mMutexAccept);
    return mbAcceptKeyFrames;
}

void LocalMapping::SetAcceptKeyFrames(bool flag)
{
    unique_lock&lt;mutex&gt; lock(mMutexAccept);
    mbAcceptKeyFrames=flag;
}

bool LocalMapping::SetNotStop(bool flag)
{
    unique_lock&lt;mutex&gt; lock(mMutexStop);

    if(flag &amp;&amp; mbStopped)
        return false;

    mbNotStop = flag;

    return true;
}

void LocalMapping::InterruptBA()
{
    mbAbortBA = true;
}

void LocalMapping::KeyFrameCulling()
{
    // Check redundant keyframes (only local keyframes)
    // A keyframe is considered redundant if the 90% of the MapPoints it sees, are seen
    // in at least other 3 keyframes (in the same or finer scale)
    // We only consider close stereo points
    vector&lt;KeyFrame*&gt; vpLocalKeyFrames = mpCurrentKeyFrame-&gt;GetVectorCovisibleKeyFrames();

    for(vector&lt;KeyFrame*&gt;::iterator vit=vpLocalKeyFrames.begin(), vend=vpLocalKeyFrames.end(); vit!=vend; vit++)
    {
        KeyFrame* pKF = *vit;
        if(pKF-&gt;mnId==0)
            continue;
        const vector&lt;MapPoint*&gt; vpMapPoints = pKF-&gt;GetMapPointMatches();

        int /*nObs = 2;
        if(mbMonocular)*/
            nObs = 3;
        const int thObs=nObs;
        int nRedundantObservations=0;
        int nMPs=0;
        for(size_t i=0, iend=vpMapPoints.size(); i&lt;iend; i++)
        {
            MapPoint* pMP = vpMapPoints[i];
            if(pMP)
            {
                if(!pMP-&gt;isBad())
                {
                    if(!mbMonocular)
                    {
                        if(pKF-&gt;mvDepth[i]&gt;pKF-&gt;mThDepth || pKF-&gt;mvDepth[i]&lt;0)
                            continue;
                    }

                    nMPs++;
                    if(pMP-&gt;Observations()&gt;thObs)
                    {
                        const int &amp;scaleLevel = pKF-&gt;mvKeysUn[i].octave;
                        const map&lt;KeyFrame*, size_t&gt; observations = pMP-&gt;GetObservations();
                        int nObs=0;
                        for(map&lt;KeyFrame*, size_t&gt;::const_iterator mit=observations.begin(), mend=observations.end(); mit!=mend; mit++)
                        {
                            KeyFrame* pKFi = mit-&gt;first;
                            if(pKFi==pKF)
                                continue;
                            const int &amp;scaleLeveli = pKFi-&gt;mvKeysUn[mit-&gt;second].octave;

                            if(scaleLeveli&lt;=scaleLevel+1)
                            {
                                nObs++;
                                if(nObs&gt;=thObs)
                                    break;
                            }
                        }
                        if(nObs&gt;=thObs)
                        {
                            nRedundantObservations++;
                        }
                    }
                }
            }
        }  

        if(nRedundantObservations&gt;0.9*nMPs)
            pKF-&gt;SetBadFlag();
    }
}

cv::Mat LocalMapping::SkewSymmetricMatrix(const cv::Mat &amp;v)
{
    return (cv::Mat_&lt;float&gt;(3,3) &lt;&lt;             0, -v.at&lt;float&gt;(2), v.at&lt;float&gt;(1),
            v.at&lt;float&gt;(2),               0,-v.at&lt;float&gt;(0),
            -v.at&lt;float&gt;(1),  v.at&lt;float&gt;(0),              0);
}


void LocalMapping::RequestReset(const bool _offline)
{
    {
        unique_lock&lt;mutex&gt; lock(mMutexReset);
        mbResetRequested = true;
    }

    if (_offline==true)
    	return ResetIfRequested();

    else while(1)
    {
        {
            unique_lock&lt;mutex&gt; lock2(mMutexReset);
            if(!mbResetRequested)
                break;
        }
        usleep(3000);
    }
}


void LocalMapping::ResetIfRequested()
{
    unique_lock&lt;mutex&gt; lock(mMutexReset);
    if(mbResetRequested)
    {
        mlNewKeyFrames.clear();
        mlpRecentAddedMapPoints.clear();
        mbResetRequested=false;
    }
}

void LocalMapping::RequestFinish()
{
    unique_lock&lt;mutex&gt; lock(mMutexFinish);
    mbFinishRequested = true;
}

bool LocalMapping::CheckFinish()
{
    unique_lock&lt;mutex&gt; lock(mMutexFinish);
    return mbFinishRequested;
}

void LocalMapping::SetFinish()
{
    unique_lock&lt;mutex&gt; lock(mMutexFinish);
    mbFinished = true;    
    unique_lock&lt;mutex&gt; lock2(mMutexStop);
    mbStopped = true;
}

bool LocalMapping::isFinished()
{
    unique_lock&lt;mutex&gt; lock(mMutexFinish);
    return mbFinished;
}

} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/LoopClosing.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/LoopClosing.cc">
				<diff>@@ -35,10 +35,11 @@
 namespace ORB_SLAM2
 {
 
-LoopClosing::LoopClosing(Map *pMap, KeyFrameDatabase *pDB, ORBVocabulary *pVoc, const bool bFixScale):
+LoopClosing::LoopClosing(Map *pMap, KeyFrameDatabase *pDB, ORBVocabulary *pVoc, const bool bFixScale, const bool offlineMode):
     mbResetRequested(false), mbFinishRequested(false), mbFinished(true), mpMap(pMap),
     mpKeyFrameDB(pDB), mpORBVocabulary(pVoc), mLastLoopKFid(0), mbRunningGBA(false), mbFinishedGBA(true),
-    mbStopGBA(false), mbFixScale(bFixScale)
+    mbStopGBA(false), mbFixScale(bFixScale),
+	offlineMapping (offlineMode)
 {
     mnCovisibilityConsistencyTh = 3;
     mpMatchedKF = NULL;
@@ -434,7 +435,8 @@ void LoopClosing::CorrectLoop()
 
     // Send a stop signal to Local Mapping
     // Avoid new keyframes are inserted while correcting the loop
-    mpLocalMapper-&gt;RequestStop();
+    if (offlineMapping==false)
+    	mpLocalMapper-&gt;RequestStop();
 
     // If a Global Bundle Adjustment is running, abort it
     if(isRunningGBA())
@@ -449,9 +451,11 @@ void LoopClosing::CorrectLoop()
     }
 
     // Wait until Local Mapping has effectively stopped
-    while(!mpLocalMapper-&gt;isStopped())
-    {
-        usleep(1000);
+    if (offlineMapping==false) {
+		while(!mpLocalMapper-&gt;isStopped())
+		{
+			usleep(1000);
+		}
     }
 
     // Ensure current keyframe is updated
@@ -690,12 +694,14 @@ void LoopClosing::RunGlobalBundleAdjustment(unsigned long nLoopKF)
         {
             cout &lt;&lt; &quot;Global Bundle Adjustment finished&quot; &lt;&lt; endl;
             cout &lt;&lt; &quot;Updating map ...&quot; &lt;&lt; endl;
-            mpLocalMapper-&gt;RequestStop();
-            // Wait until Local Mapping has effectively stopped
 
-            while(!mpLocalMapper-&gt;isStopped() &amp;&amp; !mpLocalMapper-&gt;isFinished())
-            {
-                usleep(1000);
+            if (offlineMapping==false) {
+            	mpLocalMapper-&gt;RequestStop();
+            // Wait until Local Mapping has effectively stopped
+				while(!mpLocalMapper-&gt;isStopped() &amp;&amp; !mpLocalMapper-&gt;isFinished())
+				{
+					usleep(1000);
+				}
             }
 
             // Get Map Mutex
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#include &quot;LoopClosing.h&quot;

#include &quot;Sim3Solver.h&quot;

#include &quot;Converter.h&quot;

#include &quot;Optimizer.h&quot;

#include &quot;ORBmatcher.h&quot;

#include&lt;mutex&gt;
#include&lt;thread&gt;


namespace ORB_SLAM2
{

LoopClosing::LoopClosing(Map *pMap, KeyFrameDatabase *pDB, ORBVocabulary *pVoc, const bool bFixScale):
    mbResetRequested(false), mbFinishRequested(false), mbFinished(true), mpMap(pMap),
    mpKeyFrameDB(pDB), mpORBVocabulary(pVoc), mLastLoopKFid(0), mbRunningGBA(false), mbFinishedGBA(true),
    mbStopGBA(false), mbFixScale(bFixScale)
{
    mnCovisibilityConsistencyTh = 3;
    mpMatchedKF = NULL;
}

void LoopClosing::SetTracker(Tracking *pTracker)
{
    mpTracker=pTracker;
}

void LoopClosing::SetLocalMapper(LocalMapping *pLocalMapper)
{
    mpLocalMapper=pLocalMapper;
}


void LoopClosing::RunOnce()
{
    mbFinished =false;

	// Check if there are keyframes in the queue
	if(CheckNewKeyFrames())
	{
		// Detect loop candidates and check covisibility consistency
		if(DetectLoop())
		{
			// Compute similarity transformation [sR|t]
			// In the stereo/RGBD case s=1
			if(ComputeSim3())
			{
				// Perform loop fusion and pose graph optimization
				CorrectLoop();
			}
		}
	}

    SetFinish();
}


void LoopClosing::Run()
{
    mbFinished =false;

    while(1)
    {
//    	loopCloserRunMutex.lock ();

        // Check if there are keyframes in the queue
        if(CheckNewKeyFrames())
        {
            // Detect loop candidates and check covisibility consistency
            if(DetectLoop())
            {
               // Compute similarity transformation [sR|t]
               // In the stereo/RGBD case s=1
               if(ComputeSim3())
               {
                   // Perform loop fusion and pose graph optimization
                   CorrectLoop();
               }
            }
        }       

        ResetIfRequested();

//        loopCloserRunMutex.unlock();

        if(CheckFinish())
            break;

        usleep(5000);
    }

    SetFinish();
}

void LoopClosing::InsertKeyFrame(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lock(mMutexLoopQueue);
    if(pKF-&gt;mnId!=0)
        mlpLoopKeyFrameQueue.push_back(pKF);
}

bool LoopClosing::CheckNewKeyFrames()
{
    unique_lock&lt;mutex&gt; lock(mMutexLoopQueue);
    return(!mlpLoopKeyFrameQueue.empty());
}

bool LoopClosing::DetectLoop()
{
    {
        unique_lock&lt;mutex&gt; lock(mMutexLoopQueue);
        mpCurrentKF = mlpLoopKeyFrameQueue.front();
        mlpLoopKeyFrameQueue.pop_front();
        // Avoid that a keyframe can be erased while it is being process by this thread
        mpCurrentKF-&gt;SetNotErase();
    }

    //If the map contains less than 10 KF or less than 10 KF have passed from last loop detection
    if(mpCurrentKF-&gt;mnId&lt;mLastLoopKFid+10)
    {
        mpKeyFrameDB-&gt;add(mpCurrentKF);
        mpCurrentKF-&gt;SetErase();
        return false;
    }

    // Compute reference BoW similarity score
    // This is the lowest score to a connected keyframe in the covisibility graph
    // We will impose loop candidates to have a higher similarity than this
    const vector&lt;KeyFrame*&gt; vpConnectedKeyFrames = mpCurrentKF-&gt;GetVectorCovisibleKeyFrames();
    const DBoW2::BowVector &amp;CurrentBowVec = mpCurrentKF-&gt;mBowVec;
    float minScore = 1;
    for(size_t i=0; i&lt;vpConnectedKeyFrames.size(); i++)
    {
        KeyFrame* pKF = vpConnectedKeyFrames[i];
        if(pKF-&gt;isBad())
            continue;
        const DBoW2::BowVector &amp;BowVec = pKF-&gt;mBowVec;

        float score = mpORBVocabulary-&gt;score(CurrentBowVec, BowVec);

        if(score&lt;minScore)
            minScore = score;
    }

    // Query the database imposing the minimum score
    vector&lt;KeyFrame*&gt; vpCandidateKFs = mpKeyFrameDB-&gt;DetectLoopCandidates(mpCurrentKF, minScore);

    // If there are no loop candidates, just add new keyframe and return false
    if(vpCandidateKFs.empty())
    {
        mpKeyFrameDB-&gt;add(mpCurrentKF);
        mvConsistentGroups.clear();
        mpCurrentKF-&gt;SetErase();
        return false;
    }

    // For each loop candidate check consistency with previous loop candidates
    // Each candidate expands a covisibility group (keyframes connected to the loop candidate in the covisibility graph)
    // A group is consistent with a previous group if they share at least a keyframe
    // We must detect a consistent loop in several consecutive keyframes to accept it
    mvpEnoughConsistentCandidates.clear();

    vector&lt;ConsistentGroup&gt; vCurrentConsistentGroups;
    vector&lt;bool&gt; vbConsistentGroup(mvConsistentGroups.size(),false);
    for(size_t i=0, iend=vpCandidateKFs.size(); i&lt;iend; i++)
    {
        KeyFrame* pCandidateKF = vpCandidateKFs[i];

        set&lt;KeyFrame*&gt; spCandidateGroup = pCandidateKF-&gt;GetConnectedKeyFrames();
        spCandidateGroup.insert(pCandidateKF);

        bool bEnoughConsistent = false;
        bool bConsistentForSomeGroup = false;
        for(size_t iG=0, iendG=mvConsistentGroups.size(); iG&lt;iendG; iG++)
        {
            set&lt;KeyFrame*&gt; sPreviousGroup = mvConsistentGroups[iG].first;

            bool bConsistent = false;
            for(set&lt;KeyFrame*&gt;::iterator sit=spCandidateGroup.begin(), send=spCandidateGroup.end(); sit!=send;sit++)
            {
                if(sPreviousGroup.count(*sit))
                {
                    bConsistent=true;
                    bConsistentForSomeGroup=true;
                    break;
                }
            }

            if(bConsistent)
            {
                int nPreviousConsistency = mvConsistentGroups[iG].second;
                int nCurrentConsistency = nPreviousConsistency + 1;
                if(!vbConsistentGroup[iG])
                {
                    ConsistentGroup cg = make_pair(spCandidateGroup,nCurrentConsistency);
                    vCurrentConsistentGroups.push_back(cg);
                    vbConsistentGroup[iG]=true; //this avoid to include the same group more than once
                }
                if(nCurrentConsistency&gt;=mnCovisibilityConsistencyTh &amp;&amp; !bEnoughConsistent)
                {
                    mvpEnoughConsistentCandidates.push_back(pCandidateKF);
                    bEnoughConsistent=true; //this avoid to insert the same candidate more than once
                }
            }
        }

        // If the group is not consistent with any previous group insert with consistency counter set to zero
        if(!bConsistentForSomeGroup)
        {
            ConsistentGroup cg = make_pair(spCandidateGroup,0);
            vCurrentConsistentGroups.push_back(cg);
        }
    }

    // Update Covisibility Consistent Groups
    mvConsistentGroups = vCurrentConsistentGroups;


    // Add Current Keyframe to database
    mpKeyFrameDB-&gt;add(mpCurrentKF);

    if(mvpEnoughConsistentCandidates.empty())
    {
        mpCurrentKF-&gt;SetErase();
        return false;
    }
    else
    {
        return true;
    }

    mpCurrentKF-&gt;SetErase();
    return false;
}

bool LoopClosing::ComputeSim3()
{
    // For each consistent loop candidate we try to compute a Sim3

    const int nInitialCandidates = mvpEnoughConsistentCandidates.size();

    // We compute first ORB matches for each candidate
    // If enough matches are found, we setup a Sim3Solver
    ORBmatcher matcher(0.75,true);

    vector&lt;Sim3Solver*&gt; vpSim3Solvers;
    vpSim3Solvers.resize(nInitialCandidates);

    vector&lt;vector&lt;MapPoint*&gt; &gt; vvpMapPointMatches;
    vvpMapPointMatches.resize(nInitialCandidates);

    vector&lt;bool&gt; vbDiscarded;
    vbDiscarded.resize(nInitialCandidates);

    int nCandidates=0; //candidates with enough matches

    for(int i=0; i&lt;nInitialCandidates; i++)
    {
        KeyFrame* pKF = mvpEnoughConsistentCandidates[i];

        // avoid that local mapping erase it while it is being processed in this thread
        pKF-&gt;SetNotErase();

        if(pKF-&gt;isBad())
        {
            vbDiscarded[i] = true;
            continue;
        }

        int nmatches = matcher.SearchByBoW(mpCurrentKF,pKF,vvpMapPointMatches[i]);

        if(nmatches&lt;20)
        {
            vbDiscarded[i] = true;
            continue;
        }
        else
        {
            Sim3Solver* pSolver = new Sim3Solver(mpCurrentKF,pKF,vvpMapPointMatches[i],mbFixScale);
            pSolver-&gt;SetRansacParameters(0.99,20,300);
            vpSim3Solvers[i] = pSolver;
        }

        nCandidates++;
    }

    bool bMatch = false;

    // Perform alternatively RANSAC iterations for each candidate
    // until one is succesful or all fail
    while(nCandidates&gt;0 &amp;&amp; !bMatch)
    {
        for(int i=0; i&lt;nInitialCandidates; i++)
        {
            if(vbDiscarded[i])
                continue;

            KeyFrame* pKF = mvpEnoughConsistentCandidates[i];

            // Perform 5 Ransac Iterations
            vector&lt;bool&gt; vbInliers;
            int nInliers;
            bool bNoMore;

            Sim3Solver* pSolver = vpSim3Solvers[i];
            cv::Mat Scm  = pSolver-&gt;iterate(5,bNoMore,vbInliers,nInliers);

            // If Ransac reachs max. iterations discard keyframe
            if(bNoMore)
            {
                vbDiscarded[i]=true;
                nCandidates--;
            }

            // If RANSAC returns a Sim3, perform a guided matching and optimize with all correspondences
            if(!Scm.empty())
            {
                vector&lt;MapPoint*&gt; vpMapPointMatches(vvpMapPointMatches[i].size(), static_cast&lt;MapPoint*&gt;(NULL));
                for(size_t j=0, jend=vbInliers.size(); j&lt;jend; j++)
                {
                    if(vbInliers[j])
                       vpMapPointMatches[j]=vvpMapPointMatches[i][j];
                }

                cv::Mat R = pSolver-&gt;GetEstimatedRotation();
                cv::Mat t = pSolver-&gt;GetEstimatedTranslation();
                const float s = pSolver-&gt;GetEstimatedScale();
                matcher.SearchBySim3(mpCurrentKF,pKF,vpMapPointMatches,s,R,t,7.5);

                g2o::Sim3 gScm(Converter::toMatrix3d(R),Converter::toVector3d(t),s);
                const int nInliers = Optimizer::OptimizeSim3(mpCurrentKF, pKF, vpMapPointMatches, gScm, 10, mbFixScale);

                // If optimization is succesful stop ransacs and continue
                if(nInliers&gt;=20)
                {
                    bMatch = true;
                    mpMatchedKF = pKF;
                    g2o::Sim3 gSmw(Converter::toMatrix3d(pKF-&gt;GetRotation()),Converter::toVector3d(pKF-&gt;GetTranslation()),1.0);
                    mg2oScw = gScm*gSmw;
                    mScw = Converter::toCvMat(mg2oScw);

                    mvpCurrentMatchedPoints = vpMapPointMatches;
                    break;
                }
            }
        }
    }

    if(!bMatch)
    {
        for(int i=0; i&lt;nInitialCandidates; i++)
             mvpEnoughConsistentCandidates[i]-&gt;SetErase();
        mpCurrentKF-&gt;SetErase();
        return false;
    }

    // Retrieve MapPoints seen in Loop Keyframe and neighbors
    vector&lt;KeyFrame*&gt; vpLoopConnectedKFs = mpMatchedKF-&gt;GetVectorCovisibleKeyFrames();
    vpLoopConnectedKFs.push_back(mpMatchedKF);
    mvpLoopMapPoints.clear();
    for(vector&lt;KeyFrame*&gt;::iterator vit=vpLoopConnectedKFs.begin(); vit!=vpLoopConnectedKFs.end(); vit++)
    {
        KeyFrame* pKF = *vit;
        vector&lt;MapPoint*&gt; vpMapPoints = pKF-&gt;GetMapPointMatches();
        for(size_t i=0, iend=vpMapPoints.size(); i&lt;iend; i++)
        {
            MapPoint* pMP = vpMapPoints[i];
            if(pMP)
            {
                if(!pMP-&gt;isBad() &amp;&amp; pMP-&gt;mnLoopPointForKF!=mpCurrentKF-&gt;mnId)
                {
                    mvpLoopMapPoints.push_back(pMP);
                    pMP-&gt;mnLoopPointForKF=mpCurrentKF-&gt;mnId;
                }
            }
        }
    }

    // Find more matches projecting with the computed Sim3
    matcher.SearchByProjection(mpCurrentKF, mScw, mvpLoopMapPoints, mvpCurrentMatchedPoints,10);

    // If enough matches accept Loop
    int nTotalMatches = 0;
    for(size_t i=0; i&lt;mvpCurrentMatchedPoints.size(); i++)
    {
        if(mvpCurrentMatchedPoints[i])
            nTotalMatches++;
    }

    if(nTotalMatches&gt;=40)
    {
        for(int i=0; i&lt;nInitialCandidates; i++)
            if(mvpEnoughConsistentCandidates[i]!=mpMatchedKF)
                mvpEnoughConsistentCandidates[i]-&gt;SetErase();
        return true;
    }
    else
    {
        for(int i=0; i&lt;nInitialCandidates; i++)
            mvpEnoughConsistentCandidates[i]-&gt;SetErase();
        mpCurrentKF-&gt;SetErase();
        return false;
    }

}

void LoopClosing::CorrectLoop()
{
    cout &lt;&lt; &quot;Loop detected!&quot; &lt;&lt; endl;

    // Send a stop signal to Local Mapping
    // Avoid new keyframes are inserted while correcting the loop
    mpLocalMapper-&gt;RequestStop();

    // If a Global Bundle Adjustment is running, abort it
    if(isRunningGBA())
    {
        mbStopGBA = true;

        while(!isFinishedGBA())
            usleep(5000);

        mpThreadGBA-&gt;join();
        delete mpThreadGBA;
    }

    // Wait until Local Mapping has effectively stopped
    while(!mpLocalMapper-&gt;isStopped())
    {
        usleep(1000);
    }

    // Ensure current keyframe is updated
    mpCurrentKF-&gt;UpdateConnections();

    // Retrive keyframes connected to the current keyframe and compute corrected Sim3 pose by propagation
    mvpCurrentConnectedKFs = mpCurrentKF-&gt;GetVectorCovisibleKeyFrames();
    mvpCurrentConnectedKFs.push_back(mpCurrentKF);

    KeyFrameAndPose CorrectedSim3, NonCorrectedSim3;
    CorrectedSim3[mpCurrentKF]=mg2oScw;
    cv::Mat Twc = mpCurrentKF-&gt;GetPoseInverse();


    {
        // Get Map Mutex
        unique_lock&lt;mutex&gt; lock(mpMap-&gt;mMutexMapUpdate);

        for(vector&lt;KeyFrame*&gt;::iterator vit=mvpCurrentConnectedKFs.begin(), vend=mvpCurrentConnectedKFs.end(); vit!=vend; vit++)
        {
            KeyFrame* pKFi = *vit;

            cv::Mat Tiw = pKFi-&gt;GetPose();

            if(pKFi!=mpCurrentKF)
            {
                cv::Mat Tic = Tiw*Twc;
                cv::Mat Ric = Tic.rowRange(0,3).colRange(0,3);
                cv::Mat tic = Tic.rowRange(0,3).col(3);
                g2o::Sim3 g2oSic(Converter::toMatrix3d(Ric),Converter::toVector3d(tic),1.0);
                g2o::Sim3 g2oCorrectedSiw = g2oSic*mg2oScw;
                //Pose corrected with the Sim3 of the loop closure
                CorrectedSim3[pKFi]=g2oCorrectedSiw;
            }

            cv::Mat Riw = Tiw.rowRange(0,3).colRange(0,3);
            cv::Mat tiw = Tiw.rowRange(0,3).col(3);
            g2o::Sim3 g2oSiw(Converter::toMatrix3d(Riw),Converter::toVector3d(tiw),1.0);
            //Pose without correction
            NonCorrectedSim3[pKFi]=g2oSiw;
        }

        // Correct all MapPoints obsrved by current keyframe and neighbors, so that they align with the other side of the loop
        for(KeyFrameAndPose::iterator mit=CorrectedSim3.begin(), mend=CorrectedSim3.end(); mit!=mend; mit++)
        {
            KeyFrame* pKFi = mit-&gt;first;
            g2o::Sim3 g2oCorrectedSiw = mit-&gt;second;
            g2o::Sim3 g2oCorrectedSwi = g2oCorrectedSiw.inverse();

            g2o::Sim3 g2oSiw =NonCorrectedSim3[pKFi];

            vector&lt;MapPoint*&gt; vpMPsi = pKFi-&gt;GetMapPointMatches();
            for(size_t iMP=0, endMPi = vpMPsi.size(); iMP&lt;endMPi; iMP++)
            {
                MapPoint* pMPi = vpMPsi[iMP];
                if(!pMPi)
                    continue;
                if(pMPi-&gt;isBad())
                    continue;
                if(pMPi-&gt;mnCorrectedByKF==mpCurrentKF-&gt;mnId)
                    continue;

                // Project with non-corrected pose and project back with corrected pose
                cv::Mat P3Dw = pMPi-&gt;GetWorldPos();
                Eigen::Matrix&lt;double,3,1&gt; eigP3Dw = Converter::toVector3d(P3Dw);
                Eigen::Matrix&lt;double,3,1&gt; eigCorrectedP3Dw = g2oCorrectedSwi.map(g2oSiw.map(eigP3Dw));

                cv::Mat cvCorrectedP3Dw = Converter::toCvMat(eigCorrectedP3Dw);
                pMPi-&gt;SetWorldPos(cvCorrectedP3Dw);
                pMPi-&gt;mnCorrectedByKF = mpCurrentKF-&gt;mnId;
                pMPi-&gt;mnCorrectedReference = pKFi-&gt;mnId;
                pMPi-&gt;UpdateNormalAndDepth();
            }

            // Update keyframe pose with corrected Sim3. First transform Sim3 to SE3 (scale translation)
            Eigen::Matrix3d eigR = g2oCorrectedSiw.rotation().toRotationMatrix();
            Eigen::Vector3d eigt = g2oCorrectedSiw.translation();
            double s = g2oCorrectedSiw.scale();

            eigt *=(1./s); //[R t/s;0 1]

            cv::Mat correctedTiw = Converter::toCvSE3(eigR,eigt);

            pKFi-&gt;SetPose(correctedTiw);

            // Make sure connections are updated
            pKFi-&gt;UpdateConnections();
        }

        // Start Loop Fusion
        // Update matched map points and replace if duplicated
        for(size_t i=0; i&lt;mvpCurrentMatchedPoints.size(); i++)
        {
            if(mvpCurrentMatchedPoints[i])
            {
                MapPoint* pLoopMP = mvpCurrentMatchedPoints[i];
                MapPoint* pCurMP = mpCurrentKF-&gt;GetMapPoint(i);
                if(pCurMP)
                    pCurMP-&gt;Replace(pLoopMP);
                else
                {
                    mpCurrentKF-&gt;AddMapPoint(pLoopMP,i);
                    pLoopMP-&gt;AddObservation(mpCurrentKF,i);
                    pLoopMP-&gt;ComputeDistinctiveDescriptors();
                }
            }
        }

    }

    // Project MapPoints observed in the neighborhood of the loop keyframe
    // into the current keyframe and neighbors using corrected poses.
    // Fuse duplications.
    SearchAndFuse(CorrectedSim3);


    // After the MapPoint fusion, new links in the covisibility graph will appear attaching both sides of the loop
    map&lt;KeyFrame*, set&lt;KeyFrame*&gt; &gt; LoopConnections;

    for(vector&lt;KeyFrame*&gt;::iterator vit=mvpCurrentConnectedKFs.begin(), vend=mvpCurrentConnectedKFs.end(); vit!=vend; vit++)
    {
        KeyFrame* pKFi = *vit;
        vector&lt;KeyFrame*&gt; vpPreviousNeighbors = pKFi-&gt;GetVectorCovisibleKeyFrames();

        // Update connections. Detect new links.
        pKFi-&gt;UpdateConnections();
        LoopConnections[pKFi]=pKFi-&gt;GetConnectedKeyFrames();
        for(vector&lt;KeyFrame*&gt;::iterator vit_prev=vpPreviousNeighbors.begin(), vend_prev=vpPreviousNeighbors.end(); vit_prev!=vend_prev; vit_prev++)
        {
            LoopConnections[pKFi].erase(*vit_prev);
        }
        for(vector&lt;KeyFrame*&gt;::iterator vit2=mvpCurrentConnectedKFs.begin(), vend2=mvpCurrentConnectedKFs.end(); vit2!=vend2; vit2++)
        {
            LoopConnections[pKFi].erase(*vit2);
        }
    }

    // Optimize graph
    Optimizer::OptimizeEssentialGraph(mpMap, mpMatchedKF, mpCurrentKF, NonCorrectedSim3, CorrectedSim3, LoopConnections, mbFixScale);

    // Add loop edge
    mpMatchedKF-&gt;AddLoopEdge(mpCurrentKF);
    mpCurrentKF-&gt;AddLoopEdge(mpMatchedKF);

    // Launch a new thread to perform Global Bundle Adjustment
    mbRunningGBA = true;
    mbFinishedGBA = false;
    mbStopGBA = false;
    mpThreadGBA = new thread(&amp;LoopClosing::RunGlobalBundleAdjustment,this,mpCurrentKF-&gt;mnId);

    // Loop closed. Release Local Mapping.
    mpLocalMapper-&gt;Release();    

    cout &lt;&lt; &quot;Loop Closed!&quot; &lt;&lt; endl;

    mLastLoopKFid = mpCurrentKF-&gt;mnId;   
}

void LoopClosing::SearchAndFuse(const KeyFrameAndPose &amp;CorrectedPosesMap)
{
    ORBmatcher matcher(0.8);

    for(KeyFrameAndPose::const_iterator mit=CorrectedPosesMap.begin(), mend=CorrectedPosesMap.end(); mit!=mend;mit++)
    {
        KeyFrame* pKF = mit-&gt;first;

        g2o::Sim3 g2oScw = mit-&gt;second;
        cv::Mat cvScw = Converter::toCvMat(g2oScw);

        vector&lt;MapPoint*&gt; vpReplacePoints(mvpLoopMapPoints.size(),static_cast&lt;MapPoint*&gt;(NULL));
        matcher.Fuse(pKF,cvScw,mvpLoopMapPoints,4,vpReplacePoints);

        // Get Map Mutex
        unique_lock&lt;mutex&gt; lock(mpMap-&gt;mMutexMapUpdate);
        const int nLP = mvpLoopMapPoints.size();
        for(int i=0; i&lt;nLP;i++)
        {
            MapPoint* pRep = vpReplacePoints[i];
            if(pRep)
            {
                pRep-&gt;Replace(mvpLoopMapPoints[i]);
            }
        }
    }
}


void LoopClosing::RequestReset(const bool _offline)
{
    {
        unique_lock&lt;mutex&gt; lock(mMutexReset);
        mbResetRequested = true;
    }

    if (_offline==true) {
    	return ResetIfRequested();
    }

    else while(1)
    {
        {
        unique_lock&lt;mutex&gt; lock2(mMutexReset);
        if(!mbResetRequested)
            break;
        }
        usleep(5000);
    }
}

void LoopClosing::ResetIfRequested()
{
    unique_lock&lt;mutex&gt; lock(mMutexReset);
    if(mbResetRequested)
    {
        mlpLoopKeyFrameQueue.clear();
        mLastLoopKFid=0;
        mbResetRequested=false;
    }
}

void LoopClosing::RunGlobalBundleAdjustment(unsigned long nLoopKF)
{
    cout &lt;&lt; &quot;Starting Global Bundle Adjustment&quot; &lt;&lt; endl;

    Optimizer::GlobalBundleAdjustemnt(mpMap,20,&amp;mbStopGBA,nLoopKF,false);

    // Update all MapPoints and KeyFrames
    // Local Mapping was active during BA, that means that there might be new keyframes
    // not included in the Global BA and they are not consistent with the updated map.
    // We need to propagate the correction through the spanning tree
    {
        unique_lock&lt;mutex&gt; lock(mMutexGBA);


        if(!mbStopGBA)
        {
            cout &lt;&lt; &quot;Global Bundle Adjustment finished&quot; &lt;&lt; endl;
            cout &lt;&lt; &quot;Updating map ...&quot; &lt;&lt; endl;
            mpLocalMapper-&gt;RequestStop();
            // Wait until Local Mapping has effectively stopped

            while(!mpLocalMapper-&gt;isStopped() &amp;&amp; !mpLocalMapper-&gt;isFinished())
            {
                usleep(1000);
            }

            // Get Map Mutex
            unique_lock&lt;mutex&gt; lock(mpMap-&gt;mMutexMapUpdate);

            // Correct keyframes starting at map first keyframe
            list&lt;KeyFrame*&gt; lpKFtoCheck(mpMap-&gt;mvpKeyFrameOrigins.begin(),mpMap-&gt;mvpKeyFrameOrigins.end());

            while(!lpKFtoCheck.empty())
            {
                KeyFrame* pKF = lpKFtoCheck.front();
                const set&lt;KeyFrame*&gt; sChilds = pKF-&gt;GetChilds();
                cv::Mat Twc = pKF-&gt;GetPoseInverse();
                for(set&lt;KeyFrame*&gt;::const_iterator sit=sChilds.begin();sit!=sChilds.end();sit++)
                {
                    KeyFrame* pChild = *sit;
                    if(pChild-&gt;mnBAGlobalForKF!=nLoopKF)
                    {
                        cv::Mat Tchildc = pChild-&gt;GetPose()*Twc;
                        pChild-&gt;mTcwGBA = Tchildc*pKF-&gt;mTcwGBA;//*Tcorc*pKF-&gt;mTcwGBA;
                        pChild-&gt;mnBAGlobalForKF=nLoopKF;

                    }
                    lpKFtoCheck.push_back(pChild);
                }

                pKF-&gt;mTcwBefGBA = pKF-&gt;GetPose();
                pKF-&gt;SetPose(pKF-&gt;mTcwGBA);
                lpKFtoCheck.pop_front();
            }

            // Correct MapPoints
            const vector&lt;MapPoint*&gt; vpMPs = mpMap-&gt;GetAllMapPoints();

            for(size_t i=0; i&lt;vpMPs.size(); i++)
            {
                MapPoint* pMP = vpMPs[i];

                if(pMP-&gt;isBad())
                    continue;

                if(pMP-&gt;mnBAGlobalForKF==nLoopKF)
                {
                    // If optimized by Global BA, just update
                    pMP-&gt;SetWorldPos(pMP-&gt;mPosGBA);
                }
                else
                {
                    // Update according to the correction of its reference keyframe
                    KeyFrame* pRefKF = pMP-&gt;GetReferenceKeyFrame();

                    if(pRefKF-&gt;mnBAGlobalForKF!=nLoopKF)
                        continue;

                    // Map to non-corrected camera
                    cv::Mat Rcw = pRefKF-&gt;mTcwBefGBA.rowRange(0,3).colRange(0,3);
                    cv::Mat tcw = pRefKF-&gt;mTcwBefGBA.rowRange(0,3).col(3);
                    cv::Mat Xc = Rcw*pMP-&gt;GetWorldPos()+tcw;

                    // Backproject using corrected camera
                    cv::Mat Twc = pRefKF-&gt;GetPoseInverse();
                    cv::Mat Rwc = Twc.rowRange(0,3).colRange(0,3);
                    cv::Mat twc = Twc.rowRange(0,3).col(3);

                    pMP-&gt;SetWorldPos(Rwc*Xc+twc);
                }
            }

            mpLocalMapper-&gt;Release();

            cout &lt;&lt; &quot;Map updated!&quot; &lt;&lt; endl;
        }

        mbFinishedGBA = true;
        mbRunningGBA = false;
    }
}

void LoopClosing::RequestFinish()
{
    unique_lock&lt;mutex&gt; lock(mMutexFinish);
    mbFinishRequested = true;
}

bool LoopClosing::CheckFinish()
{
    unique_lock&lt;mutex&gt; lock(mMutexFinish);
    return mbFinishRequested;
}

void LoopClosing::SetFinish()
{
    unique_lock&lt;mutex&gt; lock(mMutexFinish);
    mbFinished = true;
}

bool LoopClosing::isFinished()
{
    unique_lock&lt;mutex&gt; lock(mMutexFinish);
    return mbFinished;
}


} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Map.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Map.cc">
				<diff>@@ -20,8 +20,10 @@
 
 #include &quot;Map.h&quot;
 #include &quot;KeyFrame.h&quot;
+#include &quot;Frame.h&quot;
 #include &quot;MapPoint.h&quot;
 #include &quot;KeyFrameDatabase.h&quot;
+#include &quot;ORBVocabulary.h&quot;
 #include &lt;mutex&gt;
 #include &lt;cstdio&gt;
 #include &lt;exception&gt;
@@ -29,12 +31,24 @@
 
 #include &lt;boost/archive/binary_oarchive.hpp&gt;
 #include &lt;boost/archive/binary_iarchive.hpp&gt;
+#include &lt;boost/filesystem.hpp&gt;
 #include &quot;MapObjectSerialization.h&quot;
 
 
 using std::string;
 
 
+template&lt;class T&gt;
+vector&lt;T&gt; set2vector (const set&lt;T&gt; &amp;st)
+{
+	vector&lt;T&gt; rt;
+	for (auto &amp;smember: st) {
+		rt.push_back(smember);
+	}
+	return rt;
+}
+
+
 namespace ORB_SLAM2
 {
 
@@ -146,8 +160,7 @@ KeyFrame* Map::offsetKeyframe (KeyFrame* kfSrc, int offset)
 
 const char *signature = &quot;ORBSLAM&quot;;
 
-
-void Map::saveToDisk(const string &amp;filename, KeyFrameDatabase *keyframeDatabase)
+void Map::saveToDisk(const string &amp;mapfilename, KeyFrameDatabase *keyframeDatabase)
 {
 	MapFileHeader header;
 	memcpy (header.signature, signature, sizeof(header.signature));
@@ -156,7 +169,7 @@ void Map::saveToDisk(const string &amp;filename, KeyFrameDatabase *keyframeDatabase)
 	header.numOfReferencePoint = this-&gt;mvpReferenceMapPoints.size();
 
 	fstream mapFileFd;
-	mapFileFd.open(filename.c_str(), fstream::out | fstream::trunc);
+	mapFileFd.open(mapfilename.c_str(), fstream::out | fstream::trunc);
 	if (!mapFileFd.is_open())
 		throw MapFileException();
 	mapFileFd.write ((const char*)&amp;header, sizeof(header));
@@ -165,6 +178,13 @@ void Map::saveToDisk(const string &amp;filename, KeyFrameDatabase *keyframeDatabase)
 
 	boost::archive::binary_oarchive mapArchive (mapFileFd);
 
+	// Create new vocabulary
+	cout &lt;&lt; &quot;Creating new vocabulary... &quot;;
+	ORBVocabulary mapVoc(10, 6);
+	extractVocabulary (&amp;mapVoc);
+	keyframeDatabase-&gt;replaceVocabulary(&amp;mapVoc, this);
+	cout &lt;&lt; &quot;Done\n&quot;;
+
 	int p = 0;
 	for (set&lt;KeyFrame*&gt;::const_iterator kfit=mspKeyFrames.begin(); kfit!=mspKeyFrames.end(); kfit++) {
 		const KeyFrame *kf = *kfit;
@@ -172,11 +192,13 @@ void Map::saveToDisk(const string &amp;filename, KeyFrameDatabase *keyframeDatabase)
 			cerr &lt;&lt; endl &lt;&lt; &quot;NULL KF found&quot; &lt;&lt; endl;
 			continue;
 		}
+
 		mapArchive &lt;&lt; *kf;
 		cout &lt;&lt; &quot;Keyframes: &quot; &lt;&lt; ++p &lt;&lt; &quot;/&quot; &lt;&lt; mspKeyFrames.size() &lt;&lt; &quot;\r&quot;;
 	}
 	cout &lt;&lt; endl;
 
+	p = 0;
 	for (set&lt;MapPoint*&gt;::iterator mpit=mspMapPoints.begin(); mpit!=mspMapPoints.end(); mpit++) {
 		const MapPoint *mp = *mpit;
 		if (mp==NULL) {
@@ -184,14 +206,22 @@ void Map::saveToDisk(const string &amp;filename, KeyFrameDatabase *keyframeDatabase)
 			continue;
 		}
 		mapArchive &lt;&lt; *mp;
+		cout &lt;&lt; &quot;Map Points: &quot; &lt;&lt; ++p &lt;&lt; &quot;/&quot; &lt;&lt; mspMapPoints.size() &lt;&lt; &quot;\r&quot;;
 	}
+	cout &lt;&lt; endl;
 
 	vector&lt;idtype&gt; vmvpReferenceMapPoints = createIdList (mvpReferenceMapPoints);
 	mapArchive &lt;&lt; vmvpReferenceMapPoints;
 
 	mapArchive &lt;&lt; *keyframeDatabase;
-
 	mapFileFd.close();
+
+	cout &lt;&lt; &quot;Saving vocabulary... &quot;;
+	boost::filesystem::path mapPath (mapfilename);
+	boost::filesystem::path mapDir = mapPath.parent_path();
+	string mapVocab = mapPath.string() + &quot;.voc&quot;;
+	mapVoc.saveToTextFile (mapVocab);
+	cout &lt;&lt; &quot;Done\n&quot;;
 }
 
 
@@ -214,7 +244,7 @@ void Map::loadFromDisk(const string &amp;filename, KeyFrameDatabase *kfMemDb)
 		throw BadMapFile();
 	mapFileFd.read ((char*)&amp;header, sizeof(header));
 
-	if (strcmp(header.signature, signature) !=0)
+	if (strncmp(header.signature, signature, sizeof(signature)-1) !=0)
 		throw BadMapFile();
 	cout &lt;&lt; &quot;Keyframes: &quot; &lt;&lt; header.numOfKeyFrame &lt;&lt; &quot;, MapPoint: &quot; &lt;&lt; header.numOfMapPoint &lt;&lt; endl;
 
@@ -227,6 +257,12 @@ void Map::loadFromDisk(const string &amp;filename, KeyFrameDatabase *kfMemDb)
 			mspKeyFrames.insert (kf);
 		kfListSorted.push_back(kf);
 
+//		const cv::Mat camCenter = kf-&gt;GetCameraCenter();
+//		const float
+//			x = camCenter.at&lt;float&gt;(0),
+//			y = camCenter.at&lt;float&gt;(1),
+//			z = camCenter.at&lt;float&gt;(2);
+
 		// XXX: Need to increase KeyFrame::nNextId
 		// Also, adjust Frame::nNextId
 		if (kf-&gt;mnId &gt; KeyFrame::nNextId) {
@@ -304,42 +340,107 @@ void Map::loadFromDisk(const string &amp;filename, KeyFrameDatabase *kfMemDb)
 	kfOctree = pcl::octree::OctreePointCloudSearch&lt;KeyFramePt&gt;::Ptr (new pcl::octree::OctreePointCloudSearch&lt;KeyFramePt&gt; (MapOctreeResolution));
 	kfOctree-&gt;setInputCloud(kfCloud);
 	kfOctree-&gt;addPointsFromInputCloud();
+	mKeyFrameDb = kfMemDb;
 //	cout &lt;&lt; &quot;Done restoring Octree&quot; &lt;&lt; endl;
 }
 
 
 // we expect direction vector has been normalized,
 // as returned by Frame::getDirectionVector()
-KeyFrame* Map::getNearestKeyFrame (const float &amp;x, const float &amp;y, const float &amp;z,
-	const float fdir_x, const float fdir_y, const float fdir_z)
+//KeyFrame* Map::getNearestKeyFrame (const float &amp;x, const float &amp;y, const float &amp;z,
+//	const float fdir_x, const float fdir_y, const float fdir_z,
+//	vector&lt;KeyFrame*&gt; *kfSelectors)
+KeyFrame*
+Map::getNearestKeyFrame (const Eigen::Vector3f &amp;position,
+	const Eigen::Quaternionf &amp;orientation,
+	vector&lt;KeyFrame*&gt; *kfSelectors
+)
 {
 	KeyFramePt queryPoint;
-	queryPoint.x = x, queryPoint.y = y, queryPoint.z = z;
+	queryPoint.x = position.x(), queryPoint.y = position.y(), queryPoint.z = position.z();
 
-	const int k = 10;
+	const int k = 15;
 	vector&lt;int&gt; idcs;
 	vector&lt;float&gt; sqrDist;
 	idcs.resize(k);
 	sqrDist.resize(k);
 
 	int r = kfOctree-&gt;nearestKSearch(queryPoint, k, idcs, sqrDist);
-	if (r==0)
+	if (r==0) {
+		cerr &lt;&lt; &quot;*\n&quot;;
 		return NULL;
+	}
+
+	Eigen::Matrix3f mOrient = orientation.toRotationMatrix();
+	float
+		fdir_x = mOrient(0,2),
+		fdir_y = mOrient(1,2),
+		fdir_z = mOrient(2,2);
 
+	float cosd = 0;
+	KeyFrame *ckf = NULL;
+	int i = 0;
 	for (auto ip: idcs) {
+
 		float dirx, diry, dirz, cosT;
-		KeyFrame *ckf = kfCloud-&gt;at(ip).kf;
-		ckf-&gt;getDirectionVector(dirx, diry, dirz);
-		cosT = dirx*fdir_x + diry*fdir_y + dirz*fdir_z;
-		if (cosT &lt;= 0.86)
+		KeyFrame *checkKF = kfCloud-&gt;at(ip).kf;
+
+		// get direction vector
+		cv::Mat orient = checkKF-&gt;GetRotation().t();
+		dirx = orient.at&lt;float&gt;(0,2);
+		diry = orient.at&lt;float&gt;(1,2);
+		dirz = orient.at&lt;float&gt;(2,2);
+		float norm = sqrtf(dirx*dirx + diry*diry + dirz*dirz);
+		dirx /= norm;
+		diry /= norm;
+		dirz /= norm;
+
+		cosT = (dirx*fdir_x + diry*fdir_y + dirz*fdir_z) / (sqrtf(fdir_x*fdir_x + fdir_y*fdir_y + fdir_z*fdir_z) * sqrtf(dirx*dirx + diry*diry + dirz*dirz));
+
+		if (cosT &lt; 0)
 			continue;
 		else
-			return ckf;
+			return checkKF;
+//		if (cosT &gt; cosd) {
+//			cosd = cosT;
+//			ckf = checkKF;
+//		}
+//		if (kfSelectors!=NULL)
+//			kfSelectors-&gt;at(i) = checkKF;
+//		i+=1;
+	}
+
+	return ckf;
+}
+
+
+void Map::extractVocabulary (ORBVocabulary *mapVoc)
+{
+	vector&lt;vector&lt;DBoW2::FORB::TDescriptor&gt; &gt; keymapFeatures;
+	keymapFeatures.reserve (mspKeyFrames.size());
+
+	vector&lt;KeyFrame*&gt; allKeyFrames = GetAllKeyFrames();
+	fprintf (stderr, &quot;KF: %d\n&quot;, allKeyFrames.size());
+
+	for (vector&lt;KeyFrame*&gt;::const_iterator it=allKeyFrames.begin(); it!=allKeyFrames.end(); it++) {
+
+		KeyFrame *kf = *it;
+		vector&lt;cv::Mat&gt; kfDescriptor;
+
+		// take map points that are belong to this keyframe
+		set&lt;MapPoint*&gt; mapSet = kf-&gt;GetMapPoints();
+		vector&lt;MapPoint*&gt; mapPointList = set2vector(mapSet);
+
+		// for each map points, pick best descriptor and add to descriptors of this keyframe
+		for (auto &amp;mpp: mapPointList) {
+			cv::Mat mpDescriptor = mpp-&gt;GetDescriptor();
+			kfDescriptor.push_back(mpDescriptor);
+		}
+
+		keymapFeatures.push_back (kfDescriptor);
 	}
 
-	return NULL;
-//	KeyFrame *kfn = kfCloud-&gt;at(idcs[0]).kf;
-//	return kfn;
+	mapVoc-&gt;create (keymapFeatures);
 }
 
 
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#include &quot;Map.h&quot;
#include &quot;KeyFrame.h&quot;
#include &quot;MapPoint.h&quot;
#include &quot;KeyFrameDatabase.h&quot;
#include &lt;mutex&gt;
#include &lt;cstdio&gt;
#include &lt;exception&gt;
#include &lt;string&gt;

#include &lt;boost/archive/binary_oarchive.hpp&gt;
#include &lt;boost/archive/binary_iarchive.hpp&gt;
#include &quot;MapObjectSerialization.h&quot;


using std::string;


namespace ORB_SLAM2
{

Map::Map():
	mnMaxKFid(0),
	mbMapUpdated(false)
{
}

void Map::AddKeyFrame(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    mspKeyFrames.insert(pKF);
    if(pKF-&gt;mnId&gt;mnMaxKFid)
        mnMaxKFid=pKF-&gt;mnId;
}

void Map::AddMapPoint(MapPoint *pMP)
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    mspMapPoints.insert(pMP);
}

void Map::EraseMapPoint(MapPoint *pMP)
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    mspMapPoints.erase(pMP);

    // TODO: This only erase the pointer.
    // Delete the MapPoint
}

void Map::EraseKeyFrame(KeyFrame *pKF)
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    mspKeyFrames.erase(pKF);

    // TODO: This only erase the pointer.
    // Delete the MapPoint
}

void Map::SetReferenceMapPoints(const vector&lt;MapPoint *&gt; &amp;vpMPs)
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    mvpReferenceMapPoints = vpMPs;
}

vector&lt;KeyFrame*&gt; Map::GetAllKeyFrames()
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    return vector&lt;KeyFrame*&gt;(mspKeyFrames.begin(),mspKeyFrames.end());
}

vector&lt;MapPoint*&gt; Map::GetAllMapPoints()
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    return vector&lt;MapPoint*&gt;(mspMapPoints.begin(),mspMapPoints.end());
}

long unsigned int Map::MapPointsInMap()
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    return mspMapPoints.size();
}

long unsigned int Map::KeyFramesInMap()
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    return mspKeyFrames.size();
}

vector&lt;MapPoint*&gt; Map::GetReferenceMapPoints()
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    return mvpReferenceMapPoints;
}

long unsigned int Map::GetMaxKFid()
{
    unique_lock&lt;mutex&gt; lock(mMutexMap);
    return mnMaxKFid;
}

void Map::clear()
{
    for(set&lt;MapPoint*&gt;::iterator sit=mspMapPoints.begin(), send=mspMapPoints.end(); sit!=send; sit++)
        delete *sit;

    for(set&lt;KeyFrame*&gt;::iterator sit=mspKeyFrames.begin(), send=mspKeyFrames.end(); sit!=send; sit++)
        delete *sit;

    mspMapPoints.clear();
    mspKeyFrames.clear();
    mnMaxKFid = 0;
    mvpReferenceMapPoints.clear();
    mvpKeyFrameOrigins.clear();
}


KeyFrame* Map::offsetKeyframe (KeyFrame* kfSrc, int offset)
{
	try {
		int p = kfMapSortedId.at(kfSrc);
		p -= offset;
		return kfListSorted.at(p);
	} catch (...) {return NULL;}
}


const char *signature = &quot;ORBSLAM&quot;;


void Map::saveToDisk(const string &amp;filename, KeyFrameDatabase *keyframeDatabase)
{
	MapFileHeader header;
	memcpy (header.signature, signature, sizeof(header.signature));
	header.numOfKeyFrame = this-&gt;mspKeyFrames.size();
	header.numOfMapPoint = this-&gt;mspMapPoints.size();
	header.numOfReferencePoint = this-&gt;mvpReferenceMapPoints.size();

	fstream mapFileFd;
	mapFileFd.open(filename.c_str(), fstream::out | fstream::trunc);
	if (!mapFileFd.is_open())
		throw MapFileException();
	mapFileFd.write ((const char*)&amp;header, sizeof(header));

	cout &lt;&lt; &quot;Header written: &quot; &lt;&lt; header.numOfKeyFrame &lt;&lt; &quot; keyframes, &quot; &lt;&lt; header.numOfMapPoint &lt;&lt; &quot; points&quot; &lt;&lt; endl;

	boost::archive::binary_oarchive mapArchive (mapFileFd);

	int p = 0;
	for (set&lt;KeyFrame*&gt;::const_iterator kfit=mspKeyFrames.begin(); kfit!=mspKeyFrames.end(); kfit++) {
		const KeyFrame *kf = *kfit;
		if (kf==NULL) {
			cerr &lt;&lt; endl &lt;&lt; &quot;NULL KF found&quot; &lt;&lt; endl;
			continue;
		}
		mapArchive &lt;&lt; *kf;
		cout &lt;&lt; &quot;Keyframes: &quot; &lt;&lt; ++p &lt;&lt; &quot;/&quot; &lt;&lt; mspKeyFrames.size() &lt;&lt; &quot;\r&quot;;
	}
	cout &lt;&lt; endl;

	for (set&lt;MapPoint*&gt;::iterator mpit=mspMapPoints.begin(); mpit!=mspMapPoints.end(); mpit++) {
		const MapPoint *mp = *mpit;
		if (mp==NULL) {
			cerr &lt;&lt; endl &lt;&lt; &quot;NULL MP found&quot; &lt;&lt; endl;
			continue;
		}
		mapArchive &lt;&lt; *mp;
	}

	vector&lt;idtype&gt; vmvpReferenceMapPoints = createIdList (mvpReferenceMapPoints);
	mapArchive &lt;&lt; vmvpReferenceMapPoints;

	mapArchive &lt;&lt; *keyframeDatabase;

	mapFileFd.close();
}


struct _keyframeTimestampSortComparator {
	bool operator() (KeyFrame *kf1, KeyFrame *kf2)
	{ return kf1-&gt;mTimeStamp &lt; kf2-&gt;mTimeStamp; }
} keyframeTimestampSortComparator;


#define MapOctreeResolution 1.0

void Map::loadFromDisk(const string &amp;filename, KeyFrameDatabase *kfMemDb)
{
	MapFileHeader header;

	cout &lt;&lt; &quot;Opening &quot; &lt;&lt; filename &lt;&lt; &quot; ...\n&quot;;
	fstream mapFileFd;
	mapFileFd.open (filename.c_str(), fstream::in);
	if (!mapFileFd.is_open())
		throw BadMapFile();
	mapFileFd.read ((char*)&amp;header, sizeof(header));

	if (strcmp(header.signature, signature) !=0)
		throw BadMapFile();
	cout &lt;&lt; &quot;Keyframes: &quot; &lt;&lt; header.numOfKeyFrame &lt;&lt; &quot;, MapPoint: &quot; &lt;&lt; header.numOfMapPoint &lt;&lt; endl;

	boost::archive::binary_iarchive mapArchive (mapFileFd);

	for (unsigned int p=0; p&lt;header.numOfKeyFrame; p++) {
		KeyFrame *kf = new KeyFrame;
		mapArchive &gt;&gt; *kf;
		if (!kf-&gt;isBad())
			mspKeyFrames.insert (kf);
		kfListSorted.push_back(kf);

		// XXX: Need to increase KeyFrame::nNextId
		// Also, adjust Frame::nNextId
		if (kf-&gt;mnId &gt; KeyFrame::nNextId) {
			KeyFrame::nNextId = kf-&gt;mnId + 2;
			Frame::nNextId = kf-&gt;mnId + 3;
		}

	}

	std::sort(kfListSorted.begin(), kfListSorted.end(), keyframeTimestampSortComparator);
	for (unsigned int p=0; p&lt;kfListSorted.size(); p++) {
		KeyFrame *kf = kfListSorted[p];
		kfMapSortedId[kf] = p;
	}

	for (unsigned int p=0; p&lt;header.numOfMapPoint; p++) {
		try {

			MapPoint *mp = new MapPoint;
			mapArchive &gt;&gt; *mp;
			// Only insert if mapPoint has reference keyframe
			if (mp-&gt;mpRefKF != NULL)
				mspMapPoints.insert (mp);
			else
				delete (mp);
			if (mp-&gt;mnId &gt; MapPoint::nNextId) {
				MapPoint::nNextId = mp-&gt;mnId + 2;
			}

		} catch (boost::archive::archive_exception &amp;ae) {
			cout &lt;&lt; &quot;Archive exception at &quot; &lt;&lt; p &lt;&lt; &quot;: &quot; &lt;&lt; ae.code &lt;&lt; endl;
		} catch (std::exception &amp;e) {
			cout &lt;&lt; &quot;Unknown exception at &quot; &lt;&lt; p &lt;&lt; &quot;: &quot; &lt;&lt; e.what() &lt;&lt; endl;
		}
	}

	// Set KeyFrame::nNextId and Frame::nNextId as next largest

	if (kfMemDb==NULL)
		return;

	for (set&lt;KeyFrame*&gt;::iterator kfset=mspKeyFrames.begin(); kfset!=mspKeyFrames.end(); kfset++) {
		(*kfset)-&gt;fixConnections (this, kfMemDb);
	}

	for (set&lt;MapPoint*&gt;::iterator mpset=mspMapPoints.begin(); mpset!=mspMapPoints.end(); mpset++) {
		(*mpset)-&gt;fixConnections (this);
	}

	vector&lt;idtype&gt; vmvpReferenceMapPoints;
	mapArchive &gt;&gt; vmvpReferenceMapPoints;
	mvpReferenceMapPoints = createObjectList&lt;MapPoint&gt; (vmvpReferenceMapPoints);

	mapArchive &gt;&gt; *kfMemDb;

	mapFileFd.close();
	mbMapUpdated = true;
	cout &lt;&lt; &quot;Done restoring map&quot; &lt;&lt; endl;

	/* Point Cloud Reconstruction */
	kfCloud = pcl::PointCloud&lt;KeyFramePt&gt;::Ptr (new pcl::PointCloud&lt;KeyFramePt&gt;);
	kfCloud-&gt;width = mspKeyFrames.size();
	kfCloud-&gt;height = 1;
	kfCloud-&gt;resize(kfCloud-&gt;width);
	int p=0;
	for (set&lt;KeyFrame*&gt;::iterator kfi=mspKeyFrames.begin(); kfi!=mspKeyFrames.end(); kfi++) {
		KeyFrame *kf = *kfi;
		cv::Mat pos = kf-&gt;GetCameraCenter();
		kfCloud-&gt;at(p).x = pos.at&lt;float&gt;(0);
		kfCloud-&gt;at(p).y = pos.at&lt;float&gt;(1);
		kfCloud-&gt;at(p).z = pos.at&lt;float&gt;(2);
		kfCloud-&gt;at(p).kf = kf;
		p++;
	}
	kfOctree = pcl::octree::OctreePointCloudSearch&lt;KeyFramePt&gt;::Ptr (new pcl::octree::OctreePointCloudSearch&lt;KeyFramePt&gt; (MapOctreeResolution));
	kfOctree-&gt;setInputCloud(kfCloud);
	kfOctree-&gt;addPointsFromInputCloud();
//	cout &lt;&lt; &quot;Done restoring Octree&quot; &lt;&lt; endl;
}


// we expect direction vector has been normalized,
// as returned by Frame::getDirectionVector()
KeyFrame* Map::getNearestKeyFrame (const float &amp;x, const float &amp;y, const float &amp;z,
	const float fdir_x, const float fdir_y, const float fdir_z)
{
	KeyFramePt queryPoint;
	queryPoint.x = x, queryPoint.y = y, queryPoint.z = z;

	const int k = 10;
	vector&lt;int&gt; idcs;
	vector&lt;float&gt; sqrDist;
	idcs.resize(k);
	sqrDist.resize(k);

	int r = kfOctree-&gt;nearestKSearch(queryPoint, k, idcs, sqrDist);
	if (r==0)
		return NULL;

	for (auto ip: idcs) {
		float dirx, diry, dirz, cosT;
		KeyFrame *ckf = kfCloud-&gt;at(ip).kf;
		ckf-&gt;getDirectionVector(dirx, diry, dirz);
		cosT = dirx*fdir_x + diry*fdir_y + dirz*fdir_z;
		if (cosT &lt;= 0.86)
			continue;
		else
			return ckf;
	}

	return NULL;
//	KeyFrame *kfn = kfCloud-&gt;at(idcs[0]).kf;
//	return kfn;
}


} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Optimizer.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Optimizer.cc">
				<diff>@@ -18,6 +18,7 @@
 * along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
 */
 
+#include &quot;Map.h&quot;
 #include &quot;Optimizer.h&quot;
 
 #include &quot;g2o/core/block_solver.h&quot;
@@ -233,7 +234,6 @@ void Optimizer::BundleAdjustment(const vector&lt;KeyFrame *&gt; &amp;vpKFs, const vector&lt;M
             pMP-&gt;mnBAGlobalForKF = nLoopKF;
         }
     }
-
 }
 
 
@@ -451,7 +451,7 @@ int Optimizer::PoseOptimization(Frame *pFrame)
 
 
 void Optimizer::LocalBundleAdjustment(KeyFrame *pKF, bool* pbStopFlag, Map* pMap)
-{    
+{
     // Local KeyFrames: First Breath Search from Current Keyframe
     list&lt;KeyFrame*&gt; lLocalKeyFrames;
 
@@ -495,7 +495,7 @@ void Optimizer::LocalBundleAdjustment(KeyFrame *pKF, bool* pbStopFlag, Map* pMap
             KeyFrame* pKFi = mit-&gt;first;
 
             if(pKFi-&gt;mnBALocalForKF!=pKF-&gt;mnId &amp;&amp; pKFi-&gt;mnBAFixedForKF!=pKF-&gt;mnId)
-            {                
+            {
                 pKFi-&gt;mnBAFixedForKF=pKF-&gt;mnId;
                 if(!pKFi-&gt;isBad())
                     lFixedCameras.push_back(pKFi);
@@ -587,7 +587,7 @@ void Optimizer::LocalBundleAdjustment(KeyFrame *pKF, bool* pbStopFlag, Map* pMap
             KeyFrame* pKFi = mit-&gt;first;
 
             if(!pKFi-&gt;isBad())
-            {                
+            {
                 const cv::KeyPoint &amp;kpUn = pKFi-&gt;mvKeysUn[mit-&gt;second];
 
                 // Monocular observation
@@ -711,7 +711,7 @@ void Optimizer::LocalBundleAdjustment(KeyFrame *pKF, bool* pbStopFlag, Map* pMap
     vector&lt;pair&lt;KeyFrame*,MapPoint*&gt; &gt; vToErase;
     vToErase.reserve(vpEdgesMono.size()+vpEdgesStereo.size());
 
-    // Check inlier observations       
+    // Check inlier observations
     for(size_t i=0, iend=vpEdgesMono.size(); i&lt;iend;i++)
     {
         g2o::EdgeSE3ProjectXYZ* e = vpEdgesMono[i];
@@ -783,7 +783,7 @@ void Optimizer::OptimizeEssentialGraph(Map* pMap, KeyFrame* pLoopKF, KeyFrame* p
                                        const LoopClosing::KeyFrameAndPose &amp;CorrectedSim3,
                                        const map&lt;KeyFrame *, set&lt;KeyFrame *&gt; &gt; &amp;LoopConnections, const bool &amp;bFixScale)
 {
-    // Setup optimizer
+//     Setup optimizer
     g2o::SparseOptimizer optimizer;
     optimizer.setVerbose(false);
     g2o::BlockSolver_7_3::LinearSolverType * linearSolver =
@@ -1043,6 +1043,7 @@ void Optimizer::OptimizeEssentialGraph(Map* pMap, KeyFrame* pLoopKF, KeyFrame* p
     }
 }
 
+
 int Optimizer::OptimizeSim3(KeyFrame *pKF1, KeyFrame *pKF2, vector&lt;MapPoint *&gt; &amp;vpMatches1, g2o::Sim3 &amp;g2oS12, const float th2, const bool bFixScale)
 {
     g2o::SparseOptimizer optimizer;
</diff>
				<old_file>﻿/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/

#include &quot;Optimizer.h&quot;

#include &quot;g2o/core/block_solver.h&quot;
#include &quot;g2o/core/optimization_algorithm_levenberg.h&quot;
#include &quot;g2o/solvers/linear_solver_eigen.h&quot;
#include &quot;g2o/types/types_six_dof_expmap.h&quot;
#include &quot;g2o/core/robust_kernel_impl.h&quot;
#include &quot;g2o/solvers/linear_solver_dense.h&quot;
#include &quot;g2o/types/types_seven_dof_expmap.h&quot;

#include&lt;Eigen/StdVector&gt;

#include &quot;Converter.h&quot;

#include&lt;mutex&gt;

namespace ORB_SLAM2
{


void Optimizer::GlobalBundleAdjustemnt(Map* pMap, int nIterations, bool* pbStopFlag, const unsigned long nLoopKF, const bool bRobust)
{
    vector&lt;KeyFrame*&gt; vpKFs = pMap-&gt;GetAllKeyFrames();
    vector&lt;MapPoint*&gt; vpMP = pMap-&gt;GetAllMapPoints();
    BundleAdjustment(vpKFs,vpMP,nIterations,pbStopFlag, nLoopKF, bRobust);
}


void Optimizer::BundleAdjustment(const vector&lt;KeyFrame *&gt; &amp;vpKFs, const vector&lt;MapPoint *&gt; &amp;vpMP,
                                 int nIterations, bool* pbStopFlag, const unsigned long nLoopKF, const bool bRobust)
{
    vector&lt;bool&gt; vbNotIncludedMP;
    vbNotIncludedMP.resize(vpMP.size());

    g2o::SparseOptimizer optimizer;
    g2o::BlockSolver_6_3::LinearSolverType * linearSolver;

    linearSolver = new g2o::LinearSolverEigen&lt;g2o::BlockSolver_6_3::PoseMatrixType&gt;();

    g2o::BlockSolver_6_3 * solver_ptr = new g2o::BlockSolver_6_3(linearSolver);

    g2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
    optimizer.setAlgorithm(solver);

    if(pbStopFlag)
        optimizer.setForceStopFlag(pbStopFlag);

    long unsigned int maxKFid = 0;

    // Set KeyFrame vertices
    for(size_t i=0; i&lt;vpKFs.size(); i++)
    {
        KeyFrame* pKF = vpKFs[i];
        if(pKF-&gt;isBad())
            continue;
        g2o::VertexSE3Expmap * vSE3 = new g2o::VertexSE3Expmap();
        vSE3-&gt;setEstimate(Converter::toSE3Quat(pKF-&gt;GetPose()));
        vSE3-&gt;setId(pKF-&gt;mnId);
        vSE3-&gt;setFixed(pKF-&gt;mnId==0);
        optimizer.addVertex(vSE3);
        if(pKF-&gt;mnId&gt;maxKFid)
            maxKFid=pKF-&gt;mnId;
    }

    const float thHuber2D = sqrt(5.99);
    const float thHuber3D = sqrt(7.815);

    // Set MapPoint vertices
    for(size_t i=0; i&lt;vpMP.size(); i++)
    {
        MapPoint* pMP = vpMP[i];
        if(pMP-&gt;isBad())
            continue;
        g2o::VertexSBAPointXYZ* vPoint = new g2o::VertexSBAPointXYZ();
        vPoint-&gt;setEstimate(Converter::toVector3d(pMP-&gt;GetWorldPos()));
        const int id = pMP-&gt;mnId+maxKFid+1;
        vPoint-&gt;setId(id);
        vPoint-&gt;setMarginalized(true);
        optimizer.addVertex(vPoint);

       const map&lt;KeyFrame*,size_t&gt; observations = pMP-&gt;GetObservations();

        int nEdges = 0;
        //SET EDGES
        for(map&lt;KeyFrame*,size_t&gt;::const_iterator mit=observations.begin(); mit!=observations.end(); mit++)
        {

            KeyFrame* pKF = mit-&gt;first;
            if(pKF-&gt;isBad() || pKF-&gt;mnId&gt;maxKFid)
                continue;

            nEdges++;

            const cv::KeyPoint &amp;kpUn = pKF-&gt;mvKeysUn[mit-&gt;second];

            if(pKF-&gt;mvuRight[mit-&gt;second]&lt;0)
            {
                Eigen::Matrix&lt;double,2,1&gt; obs;
                obs &lt;&lt; kpUn.pt.x, kpUn.pt.y;

                g2o::EdgeSE3ProjectXYZ* e = new g2o::EdgeSE3ProjectXYZ();

                e-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(id)));
                e-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(pKF-&gt;mnId)));
                e-&gt;setMeasurement(obs);
                const float &amp;invSigma2 = pKF-&gt;mvInvLevelSigma2[kpUn.octave];
                e-&gt;setInformation(Eigen::Matrix2d::Identity()*invSigma2);

                if(bRobust)
                {
                    g2o::RobustKernelHuber* rk = new g2o::RobustKernelHuber;
                    e-&gt;setRobustKernel(rk);
                    rk-&gt;setDelta(thHuber2D);
                }

                e-&gt;fx = pKF-&gt;fx;
                e-&gt;fy = pKF-&gt;fy;
                e-&gt;cx = pKF-&gt;cx;
                e-&gt;cy = pKF-&gt;cy;

                optimizer.addEdge(e);
            }
            else
            {
                Eigen::Matrix&lt;double,3,1&gt; obs;
                const float kp_ur = pKF-&gt;mvuRight[mit-&gt;second];
                obs &lt;&lt; kpUn.pt.x, kpUn.pt.y, kp_ur;

                g2o::EdgeStereoSE3ProjectXYZ* e = new g2o::EdgeStereoSE3ProjectXYZ();

                e-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(id)));
                e-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(pKF-&gt;mnId)));
                e-&gt;setMeasurement(obs);
                const float &amp;invSigma2 = pKF-&gt;mvInvLevelSigma2[kpUn.octave];
                Eigen::Matrix3d Info = Eigen::Matrix3d::Identity()*invSigma2;
                e-&gt;setInformation(Info);

                if(bRobust)
                {
                    g2o::RobustKernelHuber* rk = new g2o::RobustKernelHuber;
                    e-&gt;setRobustKernel(rk);
                    rk-&gt;setDelta(thHuber3D);
                }

                e-&gt;fx = pKF-&gt;fx;
                e-&gt;fy = pKF-&gt;fy;
                e-&gt;cx = pKF-&gt;cx;
                e-&gt;cy = pKF-&gt;cy;
                e-&gt;bf = pKF-&gt;mbf;

                optimizer.addEdge(e);
            }
        }

        if(nEdges==0)
        {
            optimizer.removeVertex(vPoint);
            vbNotIncludedMP[i]=true;
        }
        else
        {
            vbNotIncludedMP[i]=false;
        }
    }

    // Optimize!
    optimizer.initializeOptimization();
    optimizer.optimize(nIterations);

    // Recover optimized data

    //Keyframes
    for(size_t i=0; i&lt;vpKFs.size(); i++)
    {
        KeyFrame* pKF = vpKFs[i];
        if(pKF-&gt;isBad())
            continue;
        g2o::VertexSE3Expmap* vSE3 = static_cast&lt;g2o::VertexSE3Expmap*&gt;(optimizer.vertex(pKF-&gt;mnId));
        g2o::SE3Quat SE3quat = vSE3-&gt;estimate();
        if(nLoopKF==0)
        {
            pKF-&gt;SetPose(Converter::toCvMat(SE3quat));
        }
        else
        {
            pKF-&gt;mTcwGBA.create(4,4,CV_32F);
            Converter::toCvMat(SE3quat).copyTo(pKF-&gt;mTcwGBA);
            pKF-&gt;mnBAGlobalForKF = nLoopKF;
        }
    }

    //Points
    for(size_t i=0; i&lt;vpMP.size(); i++)
    {
        if(vbNotIncludedMP[i])
            continue;

        MapPoint* pMP = vpMP[i];

        if(pMP-&gt;isBad())
            continue;
        g2o::VertexSBAPointXYZ* vPoint = static_cast&lt;g2o::VertexSBAPointXYZ*&gt;(optimizer.vertex(pMP-&gt;mnId+maxKFid+1));

        if(nLoopKF==0)
        {
            pMP-&gt;SetWorldPos(Converter::toCvMat(vPoint-&gt;estimate()));
            pMP-&gt;UpdateNormalAndDepth();
        }
        else
        {
            pMP-&gt;mPosGBA.create(3,1,CV_32F);
            Converter::toCvMat(vPoint-&gt;estimate()).copyTo(pMP-&gt;mPosGBA);
            pMP-&gt;mnBAGlobalForKF = nLoopKF;
        }
    }

}


int Optimizer::PoseOptimization(Frame *pFrame)
{
    g2o::SparseOptimizer optimizer;
    g2o::BlockSolver_6_3::LinearSolverType * linearSolver;

    linearSolver = new g2o::LinearSolverDense&lt;g2o::BlockSolver_6_3::PoseMatrixType&gt;();

    g2o::BlockSolver_6_3 * solver_ptr = new g2o::BlockSolver_6_3(linearSolver);

    g2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
    optimizer.setAlgorithm(solver);

    int nInitialCorrespondences=0;

    // Set Frame vertex
    g2o::VertexSE3Expmap * vSE3 = new g2o::VertexSE3Expmap();
    vSE3-&gt;setEstimate(Converter::toSE3Quat(pFrame-&gt;mTcw));
    vSE3-&gt;setId(0);
    vSE3-&gt;setFixed(false);
    optimizer.addVertex(vSE3);

    // Set MapPoint vertices
    const int N = pFrame-&gt;N;

    vector&lt;g2o::EdgeSE3ProjectXYZOnlyPose*&gt; vpEdgesMono;
    vector&lt;size_t&gt; vnIndexEdgeMono;
    vpEdgesMono.reserve(N);
    vnIndexEdgeMono.reserve(N);

    vector&lt;g2o::EdgeStereoSE3ProjectXYZOnlyPose*&gt; vpEdgesStereo;
    vector&lt;size_t&gt; vnIndexEdgeStereo;
    vpEdgesStereo.reserve(N);
    vnIndexEdgeStereo.reserve(N);

    const float deltaMono = sqrt(5.991);
    const float deltaStereo = sqrt(7.815);

    {
    unique_lock&lt;mutex&gt; lock(MapPoint::mGlobalMutex);

    for(int i=0; i&lt;N; i++)
    {
        MapPoint* pMP = pFrame-&gt;mvpMapPoints[i];
        if(pMP)
        {
            // Monocular observation
            if(pFrame-&gt;mvuRight[i]&lt;0)
            {
                nInitialCorrespondences++;
                pFrame-&gt;mvbOutlier[i] = false;

                Eigen::Matrix&lt;double,2,1&gt; obs;
                const cv::KeyPoint &amp;kpUn = pFrame-&gt;mvKeysUn[i];
                obs &lt;&lt; kpUn.pt.x, kpUn.pt.y;

                g2o::EdgeSE3ProjectXYZOnlyPose* e = new g2o::EdgeSE3ProjectXYZOnlyPose();

                e-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(0)));
                e-&gt;setMeasurement(obs);
                const float invSigma2 = pFrame-&gt;mvInvLevelSigma2[kpUn.octave];
                e-&gt;setInformation(Eigen::Matrix2d::Identity()*invSigma2);

                g2o::RobustKernelHuber* rk = new g2o::RobustKernelHuber;
                e-&gt;setRobustKernel(rk);
                rk-&gt;setDelta(deltaMono);

                e-&gt;fx = pFrame-&gt;fx;
                e-&gt;fy = pFrame-&gt;fy;
                e-&gt;cx = pFrame-&gt;cx;
                e-&gt;cy = pFrame-&gt;cy;
                cv::Mat Xw = pMP-&gt;GetWorldPos();
                e-&gt;Xw[0] = Xw.at&lt;float&gt;(0);
                e-&gt;Xw[1] = Xw.at&lt;float&gt;(1);
                e-&gt;Xw[2] = Xw.at&lt;float&gt;(2);

                optimizer.addEdge(e);

                vpEdgesMono.push_back(e);
                vnIndexEdgeMono.push_back(i);
            }
            else  // Stereo observation
            {
                nInitialCorrespondences++;
                pFrame-&gt;mvbOutlier[i] = false;

                //SET EDGE
                Eigen::Matrix&lt;double,3,1&gt; obs;
                const cv::KeyPoint &amp;kpUn = pFrame-&gt;mvKeysUn[i];
                const float &amp;kp_ur = pFrame-&gt;mvuRight[i];
                obs &lt;&lt; kpUn.pt.x, kpUn.pt.y, kp_ur;

                g2o::EdgeStereoSE3ProjectXYZOnlyPose* e = new g2o::EdgeStereoSE3ProjectXYZOnlyPose();

                e-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(0)));
                e-&gt;setMeasurement(obs);
                const float invSigma2 = pFrame-&gt;mvInvLevelSigma2[kpUn.octave];
                Eigen::Matrix3d Info = Eigen::Matrix3d::Identity()*invSigma2;
                e-&gt;setInformation(Info);

                g2o::RobustKernelHuber* rk = new g2o::RobustKernelHuber;
                e-&gt;setRobustKernel(rk);
                rk-&gt;setDelta(deltaStereo);

                e-&gt;fx = pFrame-&gt;fx;
                e-&gt;fy = pFrame-&gt;fy;
                e-&gt;cx = pFrame-&gt;cx;
                e-&gt;cy = pFrame-&gt;cy;
                e-&gt;bf = pFrame-&gt;mbf;
                cv::Mat Xw = pMP-&gt;GetWorldPos();
                e-&gt;Xw[0] = Xw.at&lt;float&gt;(0);
                e-&gt;Xw[1] = Xw.at&lt;float&gt;(1);
                e-&gt;Xw[2] = Xw.at&lt;float&gt;(2);

                optimizer.addEdge(e);

                vpEdgesStereo.push_back(e);
                vnIndexEdgeStereo.push_back(i);
            }
        }

    }
    }

    if(nInitialCorrespondences&lt;3)
        return 0;

    // We perform 4 optimizations, after each optimization we classify observation as inlier/outlier
    // At the next optimization, outliers are not included, but at the end they can be classified as inliers again.
    const float chi2Mono[4]={5.991,5.991,5.991,5.991};
    const float chi2Stereo[4]={7.815,7.815,7.815, 7.815};
    const int its[4]={10,10,10,10};

    int nBad=0;
    for(size_t it=0; it&lt;4; it++)
    {

        vSE3-&gt;setEstimate(Converter::toSE3Quat(pFrame-&gt;mTcw));
        optimizer.initializeOptimization(0);
        optimizer.optimize(its[it]);

        nBad=0;
        for(size_t i=0, iend=vpEdgesMono.size(); i&lt;iend; i++)
        {
            g2o::EdgeSE3ProjectXYZOnlyPose* e = vpEdgesMono[i];

            const size_t idx = vnIndexEdgeMono[i];

            if(pFrame-&gt;mvbOutlier[idx])
            {
                e-&gt;computeError();
            }

            const float chi2 = e-&gt;chi2();

            if(chi2&gt;chi2Mono[it])
            {
                pFrame-&gt;mvbOutlier[idx]=true;
                e-&gt;setLevel(1);
                nBad++;
            }
            else
            {
                pFrame-&gt;mvbOutlier[idx]=false;
                e-&gt;setLevel(0);
            }

            if(it==2)
                e-&gt;setRobustKernel(0);
        }

        for(size_t i=0, iend=vpEdgesStereo.size(); i&lt;iend; i++)
        {
            g2o::EdgeStereoSE3ProjectXYZOnlyPose* e = vpEdgesStereo[i];

            const size_t idx = vnIndexEdgeStereo[i];

            if(pFrame-&gt;mvbOutlier[idx])
            {
                e-&gt;computeError();
            }

            const float chi2 = e-&gt;chi2();

            if(chi2&gt;chi2Stereo[it])
            {
                pFrame-&gt;mvbOutlier[idx]=true;
                e-&gt;setLevel(1);
                nBad++;
            }
            else
            {
                e-&gt;setLevel(0);
                pFrame-&gt;mvbOutlier[idx]=false;
            }

            if(it==2)
                e-&gt;setRobustKernel(0);
        }

        if(optimizer.edges().size()&lt;10)
            break;
    }

    // Recover optimized pose and return number of inliers
    g2o::VertexSE3Expmap* vSE3_recov = static_cast&lt;g2o::VertexSE3Expmap*&gt;(optimizer.vertex(0));
    g2o::SE3Quat SE3quat_recov = vSE3_recov-&gt;estimate();
    cv::Mat pose = Converter::toCvMat(SE3quat_recov);
    pFrame-&gt;SetPose(pose);

    return nInitialCorrespondences-nBad;
}


void Optimizer::LocalBundleAdjustment(KeyFrame *pKF, bool* pbStopFlag, Map* pMap)
{    
    // Local KeyFrames: First Breath Search from Current Keyframe
    list&lt;KeyFrame*&gt; lLocalKeyFrames;

    lLocalKeyFrames.push_back(pKF);
    pKF-&gt;mnBALocalForKF = pKF-&gt;mnId;

    const vector&lt;KeyFrame*&gt; vNeighKFs = pKF-&gt;GetVectorCovisibleKeyFrames();
    for(int i=0, iend=vNeighKFs.size(); i&lt;iend; i++)
    {
        KeyFrame* pKFi = vNeighKFs[i];
        pKFi-&gt;mnBALocalForKF = pKF-&gt;mnId;
        if(!pKFi-&gt;isBad())
            lLocalKeyFrames.push_back(pKFi);
    }

    // Local MapPoints seen in Local KeyFrames
    list&lt;MapPoint*&gt; lLocalMapPoints;
    for(list&lt;KeyFrame*&gt;::iterator lit=lLocalKeyFrames.begin() , lend=lLocalKeyFrames.end(); lit!=lend; lit++)
    {
        vector&lt;MapPoint*&gt; vpMPs = (*lit)-&gt;GetMapPointMatches();
        for(vector&lt;MapPoint*&gt;::iterator vit=vpMPs.begin(), vend=vpMPs.end(); vit!=vend; vit++)
        {
            MapPoint* pMP = *vit;
            if(pMP)
                if(!pMP-&gt;isBad())
                    if(pMP-&gt;mnBALocalForKF!=pKF-&gt;mnId)
                    {
                        lLocalMapPoints.push_back(pMP);
                        pMP-&gt;mnBALocalForKF=pKF-&gt;mnId;
                    }
        }
    }

    // Fixed Keyframes. Keyframes that see Local MapPoints but that are not Local Keyframes
    list&lt;KeyFrame*&gt; lFixedCameras;
    for(list&lt;MapPoint*&gt;::iterator lit=lLocalMapPoints.begin(), lend=lLocalMapPoints.end(); lit!=lend; lit++)
    {
        map&lt;KeyFrame*,size_t&gt; observations = (*lit)-&gt;GetObservations();
        for(map&lt;KeyFrame*,size_t&gt;::iterator mit=observations.begin(), mend=observations.end(); mit!=mend; mit++)
        {
            KeyFrame* pKFi = mit-&gt;first;

            if(pKFi-&gt;mnBALocalForKF!=pKF-&gt;mnId &amp;&amp; pKFi-&gt;mnBAFixedForKF!=pKF-&gt;mnId)
            {                
                pKFi-&gt;mnBAFixedForKF=pKF-&gt;mnId;
                if(!pKFi-&gt;isBad())
                    lFixedCameras.push_back(pKFi);
            }
        }
    }

    // Setup optimizer
    g2o::SparseOptimizer optimizer;
    g2o::BlockSolver_6_3::LinearSolverType * linearSolver;

    linearSolver = new g2o::LinearSolverEigen&lt;g2o::BlockSolver_6_3::PoseMatrixType&gt;();

    g2o::BlockSolver_6_3 * solver_ptr = new g2o::BlockSolver_6_3(linearSolver);

    g2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
    optimizer.setAlgorithm(solver);

    if(pbStopFlag)
        optimizer.setForceStopFlag(pbStopFlag);

    unsigned long maxKFid = 0;

    // Set Local KeyFrame vertices
    for(list&lt;KeyFrame*&gt;::iterator lit=lLocalKeyFrames.begin(), lend=lLocalKeyFrames.end(); lit!=lend; lit++)
    {
        KeyFrame* pKFi = *lit;
        g2o::VertexSE3Expmap * vSE3 = new g2o::VertexSE3Expmap();
        vSE3-&gt;setEstimate(Converter::toSE3Quat(pKFi-&gt;GetPose()));
        vSE3-&gt;setId(pKFi-&gt;mnId);
        vSE3-&gt;setFixed(pKFi-&gt;mnId==0);
        optimizer.addVertex(vSE3);
        if(pKFi-&gt;mnId&gt;maxKFid)
            maxKFid=pKFi-&gt;mnId;
    }

    // Set Fixed KeyFrame vertices
    for(list&lt;KeyFrame*&gt;::iterator lit=lFixedCameras.begin(), lend=lFixedCameras.end(); lit!=lend; lit++)
    {
        KeyFrame* pKFi = *lit;
        g2o::VertexSE3Expmap * vSE3 = new g2o::VertexSE3Expmap();
        vSE3-&gt;setEstimate(Converter::toSE3Quat(pKFi-&gt;GetPose()));
        vSE3-&gt;setId(pKFi-&gt;mnId);
        vSE3-&gt;setFixed(true);
        optimizer.addVertex(vSE3);
        if(pKFi-&gt;mnId&gt;maxKFid)
            maxKFid=pKFi-&gt;mnId;
    }

    // Set MapPoint vertices
    const int nExpectedSize = (lLocalKeyFrames.size()+lFixedCameras.size())*lLocalMapPoints.size();

    vector&lt;g2o::EdgeSE3ProjectXYZ*&gt; vpEdgesMono;
    vpEdgesMono.reserve(nExpectedSize);

    vector&lt;KeyFrame*&gt; vpEdgeKFMono;
    vpEdgeKFMono.reserve(nExpectedSize);

    vector&lt;MapPoint*&gt; vpMapPointEdgeMono;
    vpMapPointEdgeMono.reserve(nExpectedSize);

    vector&lt;g2o::EdgeStereoSE3ProjectXYZ*&gt; vpEdgesStereo;
    vpEdgesStereo.reserve(nExpectedSize);

    vector&lt;KeyFrame*&gt; vpEdgeKFStereo;
    vpEdgeKFStereo.reserve(nExpectedSize);

    vector&lt;MapPoint*&gt; vpMapPointEdgeStereo;
    vpMapPointEdgeStereo.reserve(nExpectedSize);

    const float thHuberMono = sqrt(5.991);
    const float thHuberStereo = sqrt(7.815);

    for(list&lt;MapPoint*&gt;::iterator lit=lLocalMapPoints.begin(), lend=lLocalMapPoints.end(); lit!=lend; lit++)
    {
        MapPoint* pMP = *lit;
        g2o::VertexSBAPointXYZ* vPoint = new g2o::VertexSBAPointXYZ();
        vPoint-&gt;setEstimate(Converter::toVector3d(pMP-&gt;GetWorldPos()));
        int id = pMP-&gt;mnId+maxKFid+1;
        vPoint-&gt;setId(id);
        vPoint-&gt;setMarginalized(true);
        optimizer.addVertex(vPoint);

        const map&lt;KeyFrame*,size_t&gt; observations = pMP-&gt;GetObservations();

        //Set edges
        for(map&lt;KeyFrame*,size_t&gt;::const_iterator mit=observations.begin(), mend=observations.end(); mit!=mend; mit++)
        {
            KeyFrame* pKFi = mit-&gt;first;

            if(!pKFi-&gt;isBad())
            {                
                const cv::KeyPoint &amp;kpUn = pKFi-&gt;mvKeysUn[mit-&gt;second];

                // Monocular observation
                if(pKFi-&gt;mvuRight[mit-&gt;second]&lt;0)
                {
                    Eigen::Matrix&lt;double,2,1&gt; obs;
                    obs &lt;&lt; kpUn.pt.x, kpUn.pt.y;

                    g2o::EdgeSE3ProjectXYZ* e = new g2o::EdgeSE3ProjectXYZ();

                    e-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(id)));
                    e-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(pKFi-&gt;mnId)));
                    e-&gt;setMeasurement(obs);
                    const float &amp;invSigma2 = pKFi-&gt;mvInvLevelSigma2[kpUn.octave];
                    e-&gt;setInformation(Eigen::Matrix2d::Identity()*invSigma2);

                    g2o::RobustKernelHuber* rk = new g2o::RobustKernelHuber;
                    e-&gt;setRobustKernel(rk);
                    rk-&gt;setDelta(thHuberMono);

                    e-&gt;fx = pKFi-&gt;fx;
                    e-&gt;fy = pKFi-&gt;fy;
                    e-&gt;cx = pKFi-&gt;cx;
                    e-&gt;cy = pKFi-&gt;cy;

                    optimizer.addEdge(e);
                    vpEdgesMono.push_back(e);
                    vpEdgeKFMono.push_back(pKFi);
                    vpMapPointEdgeMono.push_back(pMP);
                }
                else // Stereo observation
                {
                    Eigen::Matrix&lt;double,3,1&gt; obs;
                    const float kp_ur = pKFi-&gt;mvuRight[mit-&gt;second];
                    obs &lt;&lt; kpUn.pt.x, kpUn.pt.y, kp_ur;

                    g2o::EdgeStereoSE3ProjectXYZ* e = new g2o::EdgeStereoSE3ProjectXYZ();

                    e-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(id)));
                    e-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(pKFi-&gt;mnId)));
                    e-&gt;setMeasurement(obs);
                    const float &amp;invSigma2 = pKFi-&gt;mvInvLevelSigma2[kpUn.octave];
                    Eigen::Matrix3d Info = Eigen::Matrix3d::Identity()*invSigma2;
                    e-&gt;setInformation(Info);

                    g2o::RobustKernelHuber* rk = new g2o::RobustKernelHuber;
                    e-&gt;setRobustKernel(rk);
                    rk-&gt;setDelta(thHuberStereo);

                    e-&gt;fx = pKFi-&gt;fx;
                    e-&gt;fy = pKFi-&gt;fy;
                    e-&gt;cx = pKFi-&gt;cx;
                    e-&gt;cy = pKFi-&gt;cy;
                    e-&gt;bf = pKFi-&gt;mbf;

                    optimizer.addEdge(e);
                    vpEdgesStereo.push_back(e);
                    vpEdgeKFStereo.push_back(pKFi);
                    vpMapPointEdgeStereo.push_back(pMP);
                }
            }
        }
    }

    if(pbStopFlag)
        if(*pbStopFlag)
            return;

    optimizer.initializeOptimization();
    optimizer.optimize(5);

    bool bDoMore= true;

    if(pbStopFlag)
        if(*pbStopFlag)
            bDoMore = false;

    if(bDoMore)
    {

    // Check inlier observations
    for(size_t i=0, iend=vpEdgesMono.size(); i&lt;iend;i++)
    {
        g2o::EdgeSE3ProjectXYZ* e = vpEdgesMono[i];
        MapPoint* pMP = vpMapPointEdgeMono[i];

        if(pMP-&gt;isBad())
            continue;

        if(e-&gt;chi2()&gt;5.991 || !e-&gt;isDepthPositive())
        {
            e-&gt;setLevel(1);
        }

        e-&gt;setRobustKernel(0);
    }

    for(size_t i=0, iend=vpEdgesStereo.size(); i&lt;iend;i++)
    {
        g2o::EdgeStereoSE3ProjectXYZ* e = vpEdgesStereo[i];
        MapPoint* pMP = vpMapPointEdgeStereo[i];

        if(pMP-&gt;isBad())
            continue;

        if(e-&gt;chi2()&gt;7.815 || !e-&gt;isDepthPositive())
        {
            e-&gt;setLevel(1);
        }

        e-&gt;setRobustKernel(0);
    }

    // Optimize again without the outliers

    optimizer.initializeOptimization(0);
    optimizer.optimize(10);

    }

    vector&lt;pair&lt;KeyFrame*,MapPoint*&gt; &gt; vToErase;
    vToErase.reserve(vpEdgesMono.size()+vpEdgesStereo.size());

    // Check inlier observations       
    for(size_t i=0, iend=vpEdgesMono.size(); i&lt;iend;i++)
    {
        g2o::EdgeSE3ProjectXYZ* e = vpEdgesMono[i];
        MapPoint* pMP = vpMapPointEdgeMono[i];

        if(pMP-&gt;isBad())
            continue;

        if(e-&gt;chi2()&gt;5.991 || !e-&gt;isDepthPositive())
        {
            KeyFrame* pKFi = vpEdgeKFMono[i];
            vToErase.push_back(make_pair(pKFi,pMP));
        }
    }

    for(size_t i=0, iend=vpEdgesStereo.size(); i&lt;iend;i++)
    {
        g2o::EdgeStereoSE3ProjectXYZ* e = vpEdgesStereo[i];
        MapPoint* pMP = vpMapPointEdgeStereo[i];

        if(pMP-&gt;isBad())
            continue;

        if(e-&gt;chi2()&gt;7.815 || !e-&gt;isDepthPositive())
        {
            KeyFrame* pKFi = vpEdgeKFStereo[i];
            vToErase.push_back(make_pair(pKFi,pMP));
        }
    }

    // Get Map Mutex
    unique_lock&lt;mutex&gt; lock(pMap-&gt;mMutexMapUpdate);

    if(!vToErase.empty())
    {
        for(size_t i=0;i&lt;vToErase.size();i++)
        {
            KeyFrame* pKFi = vToErase[i].first;
            MapPoint* pMPi = vToErase[i].second;
            pKFi-&gt;EraseMapPointMatch(pMPi);
            pMPi-&gt;EraseObservation(pKFi);
        }
    }

    // Recover optimized data

    //Keyframes
    for(list&lt;KeyFrame*&gt;::iterator lit=lLocalKeyFrames.begin(), lend=lLocalKeyFrames.end(); lit!=lend; lit++)
    {
        KeyFrame* pKF = *lit;
        g2o::VertexSE3Expmap* vSE3 = static_cast&lt;g2o::VertexSE3Expmap*&gt;(optimizer.vertex(pKF-&gt;mnId));
        g2o::SE3Quat SE3quat = vSE3-&gt;estimate();
        pKF-&gt;SetPose(Converter::toCvMat(SE3quat));
    }

    //Points
    for(list&lt;MapPoint*&gt;::iterator lit=lLocalMapPoints.begin(), lend=lLocalMapPoints.end(); lit!=lend; lit++)
    {
        MapPoint* pMP = *lit;
        g2o::VertexSBAPointXYZ* vPoint = static_cast&lt;g2o::VertexSBAPointXYZ*&gt;(optimizer.vertex(pMP-&gt;mnId+maxKFid+1));
        pMP-&gt;SetWorldPos(Converter::toCvMat(vPoint-&gt;estimate()));
        pMP-&gt;UpdateNormalAndDepth();
    }
}


void Optimizer::OptimizeEssentialGraph(Map* pMap, KeyFrame* pLoopKF, KeyFrame* pCurKF,
                                       const LoopClosing::KeyFrameAndPose &amp;NonCorrectedSim3,
                                       const LoopClosing::KeyFrameAndPose &amp;CorrectedSim3,
                                       const map&lt;KeyFrame *, set&lt;KeyFrame *&gt; &gt; &amp;LoopConnections, const bool &amp;bFixScale)
{
    // Setup optimizer
    g2o::SparseOptimizer optimizer;
    optimizer.setVerbose(false);
    g2o::BlockSolver_7_3::LinearSolverType * linearSolver =
           new g2o::LinearSolverEigen&lt;g2o::BlockSolver_7_3::PoseMatrixType&gt;();
    g2o::BlockSolver_7_3 * solver_ptr= new g2o::BlockSolver_7_3(linearSolver);
    g2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);

    solver-&gt;setUserLambdaInit(1e-16);
    optimizer.setAlgorithm(solver);

    const vector&lt;KeyFrame*&gt; vpKFs = pMap-&gt;GetAllKeyFrames();
    const vector&lt;MapPoint*&gt; vpMPs = pMap-&gt;GetAllMapPoints();

    const unsigned int nMaxKFid = pMap-&gt;GetMaxKFid();

    vector&lt;g2o::Sim3,Eigen::aligned_allocator&lt;g2o::Sim3&gt; &gt; vScw(nMaxKFid+1);
    vector&lt;g2o::Sim3,Eigen::aligned_allocator&lt;g2o::Sim3&gt; &gt; vCorrectedSwc(nMaxKFid+1);
    vector&lt;g2o::VertexSim3Expmap*&gt; vpVertices(nMaxKFid+1);

    const int minFeat = 100;

    // Set KeyFrame vertices
    for(size_t i=0, iend=vpKFs.size(); i&lt;iend;i++)
    {
        KeyFrame* pKF = vpKFs[i];
        if(pKF-&gt;isBad())
            continue;
        g2o::VertexSim3Expmap* VSim3 = new g2o::VertexSim3Expmap();

        const int nIDi = pKF-&gt;mnId;

        LoopClosing::KeyFrameAndPose::const_iterator it = CorrectedSim3.find(pKF);

        if(it!=CorrectedSim3.end())
        {
            vScw[nIDi] = it-&gt;second;
            VSim3-&gt;setEstimate(it-&gt;second);
        }
        else
        {
            Eigen::Matrix&lt;double,3,3&gt; Rcw = Converter::toMatrix3d(pKF-&gt;GetRotation());
            Eigen::Matrix&lt;double,3,1&gt; tcw = Converter::toVector3d(pKF-&gt;GetTranslation());
            g2o::Sim3 Siw(Rcw,tcw,1.0);
            vScw[nIDi] = Siw;
            VSim3-&gt;setEstimate(Siw);
        }

        if(pKF==pLoopKF)
            VSim3-&gt;setFixed(true);

        VSim3-&gt;setId(nIDi);
        VSim3-&gt;setMarginalized(false);
        VSim3-&gt;_fix_scale = bFixScale;

        optimizer.addVertex(VSim3);

        vpVertices[nIDi]=VSim3;
    }


    set&lt;pair&lt;long unsigned int,long unsigned int&gt; &gt; sInsertedEdges;

    const Eigen::Matrix&lt;double,7,7&gt; matLambda = Eigen::Matrix&lt;double,7,7&gt;::Identity();

    // Set Loop edges
    for(map&lt;KeyFrame *, set&lt;KeyFrame *&gt; &gt;::const_iterator mit = LoopConnections.begin(), mend=LoopConnections.end(); mit!=mend; mit++)
    {
        KeyFrame* pKF = mit-&gt;first;
        const long unsigned int nIDi = pKF-&gt;mnId;
        const set&lt;KeyFrame*&gt; &amp;spConnections = mit-&gt;second;
        const g2o::Sim3 Siw = vScw[nIDi];
        const g2o::Sim3 Swi = Siw.inverse();

        for(set&lt;KeyFrame*&gt;::const_iterator sit=spConnections.begin(), send=spConnections.end(); sit!=send; sit++)
        {
            const long unsigned int nIDj = (*sit)-&gt;mnId;
            if((nIDi!=pCurKF-&gt;mnId || nIDj!=pLoopKF-&gt;mnId) &amp;&amp; pKF-&gt;GetWeight(*sit)&lt;minFeat)
                continue;

            const g2o::Sim3 Sjw = vScw[nIDj];
            const g2o::Sim3 Sji = Sjw * Swi;

            g2o::EdgeSim3* e = new g2o::EdgeSim3();
            e-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(nIDj)));
            e-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(nIDi)));
            e-&gt;setMeasurement(Sji);

            e-&gt;information() = matLambda;

            optimizer.addEdge(e);

            sInsertedEdges.insert(make_pair(min(nIDi,nIDj),max(nIDi,nIDj)));
        }
    }

    // Set normal edges
    for(size_t i=0, iend=vpKFs.size(); i&lt;iend; i++)
    {
        KeyFrame* pKF = vpKFs[i];

        const int nIDi = pKF-&gt;mnId;

        g2o::Sim3 Swi;

        LoopClosing::KeyFrameAndPose::const_iterator iti = NonCorrectedSim3.find(pKF);

        if(iti!=NonCorrectedSim3.end())
            Swi = (iti-&gt;second).inverse();
        else
            Swi = vScw[nIDi].inverse();

        KeyFrame* pParentKF = pKF-&gt;GetParent();

        // Spanning tree edge
        if(pParentKF)
        {
            int nIDj = pParentKF-&gt;mnId;

            g2o::Sim3 Sjw;

            LoopClosing::KeyFrameAndPose::const_iterator itj = NonCorrectedSim3.find(pParentKF);

            if(itj!=NonCorrectedSim3.end())
                Sjw = itj-&gt;second;
            else
                Sjw = vScw[nIDj];

            g2o::Sim3 Sji = Sjw * Swi;

            g2o::EdgeSim3* e = new g2o::EdgeSim3();
            e-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(nIDj)));
            e-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(nIDi)));
            e-&gt;setMeasurement(Sji);

            e-&gt;information() = matLambda;
            optimizer.addEdge(e);
        }

        // Loop edges
        const set&lt;KeyFrame*&gt; sLoopEdges = pKF-&gt;GetLoopEdges();
        for(set&lt;KeyFrame*&gt;::const_iterator sit=sLoopEdges.begin(), send=sLoopEdges.end(); sit!=send; sit++)
        {
            KeyFrame* pLKF = *sit;
            if(pLKF-&gt;mnId&lt;pKF-&gt;mnId)
            {
                g2o::Sim3 Slw;

                LoopClosing::KeyFrameAndPose::const_iterator itl = NonCorrectedSim3.find(pLKF);

                if(itl!=NonCorrectedSim3.end())
                    Slw = itl-&gt;second;
                else
                    Slw = vScw[pLKF-&gt;mnId];

                g2o::Sim3 Sli = Slw * Swi;
                g2o::EdgeSim3* el = new g2o::EdgeSim3();
                el-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(pLKF-&gt;mnId)));
                el-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(nIDi)));
                el-&gt;setMeasurement(Sli);
                el-&gt;information() = matLambda;
                optimizer.addEdge(el);
            }
        }

        // Covisibility graph edges
        const vector&lt;KeyFrame*&gt; vpConnectedKFs = pKF-&gt;GetCovisiblesByWeight(minFeat);
        for(vector&lt;KeyFrame*&gt;::const_iterator vit=vpConnectedKFs.begin(); vit!=vpConnectedKFs.end(); vit++)
        {
            KeyFrame* pKFn = *vit;
            if(pKFn &amp;&amp; pKFn!=pParentKF &amp;&amp; !pKF-&gt;hasChild(pKFn) &amp;&amp; !sLoopEdges.count(pKFn))
            {
                if(!pKFn-&gt;isBad() &amp;&amp; pKFn-&gt;mnId&lt;pKF-&gt;mnId)
                {
                    if(sInsertedEdges.count(make_pair(min(pKF-&gt;mnId,pKFn-&gt;mnId),max(pKF-&gt;mnId,pKFn-&gt;mnId))))
                        continue;

                    g2o::Sim3 Snw;

                    LoopClosing::KeyFrameAndPose::const_iterator itn = NonCorrectedSim3.find(pKFn);

                    if(itn!=NonCorrectedSim3.end())
                        Snw = itn-&gt;second;
                    else
                        Snw = vScw[pKFn-&gt;mnId];

                    g2o::Sim3 Sni = Snw * Swi;

                    g2o::EdgeSim3* en = new g2o::EdgeSim3();
                    en-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(pKFn-&gt;mnId)));
                    en-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(nIDi)));
                    en-&gt;setMeasurement(Sni);
                    en-&gt;information() = matLambda;
                    optimizer.addEdge(en);
                }
            }
        }
    }

    // Optimize!
    optimizer.initializeOptimization();
    optimizer.optimize(20);

    unique_lock&lt;mutex&gt; lock(pMap-&gt;mMutexMapUpdate);

    // SE3 Pose Recovering. Sim3:[sR t;0 1] -&gt; SE3:[R t/s;0 1]
    for(size_t i=0;i&lt;vpKFs.size();i++)
    {
        KeyFrame* pKFi = vpKFs[i];

        const int nIDi = pKFi-&gt;mnId;

        g2o::VertexSim3Expmap* VSim3 = static_cast&lt;g2o::VertexSim3Expmap*&gt;(optimizer.vertex(nIDi));
        g2o::Sim3 CorrectedSiw =  VSim3-&gt;estimate();
        vCorrectedSwc[nIDi]=CorrectedSiw.inverse();
        Eigen::Matrix3d eigR = CorrectedSiw.rotation().toRotationMatrix();
        Eigen::Vector3d eigt = CorrectedSiw.translation();
        double s = CorrectedSiw.scale();

        eigt *=(1./s); //[R t/s;0 1]

        cv::Mat Tiw = Converter::toCvSE3(eigR,eigt);

        pKFi-&gt;SetPose(Tiw);
    }

    // Correct points. Transform to &quot;non-optimized&quot; reference keyframe pose and transform back with optimized pose
    for(size_t i=0, iend=vpMPs.size(); i&lt;iend; i++)
    {
        MapPoint* pMP = vpMPs[i];

        if(pMP-&gt;isBad())
            continue;

        int nIDr;
        if(pMP-&gt;mnCorrectedByKF==pCurKF-&gt;mnId)
        {
            nIDr = pMP-&gt;mnCorrectedReference;
        }
        else
        {
            KeyFrame* pRefKF = pMP-&gt;GetReferenceKeyFrame();
            nIDr = pRefKF-&gt;mnId;
        }


        g2o::Sim3 Srw = vScw[nIDr];
        g2o::Sim3 correctedSwr = vCorrectedSwc[nIDr];

        cv::Mat P3Dw = pMP-&gt;GetWorldPos();
        Eigen::Matrix&lt;double,3,1&gt; eigP3Dw = Converter::toVector3d(P3Dw);
        Eigen::Matrix&lt;double,3,1&gt; eigCorrectedP3Dw = correctedSwr.map(Srw.map(eigP3Dw));

        cv::Mat cvCorrectedP3Dw = Converter::toCvMat(eigCorrectedP3Dw);
        pMP-&gt;SetWorldPos(cvCorrectedP3Dw);

        pMP-&gt;UpdateNormalAndDepth();
    }
}

int Optimizer::OptimizeSim3(KeyFrame *pKF1, KeyFrame *pKF2, vector&lt;MapPoint *&gt; &amp;vpMatches1, g2o::Sim3 &amp;g2oS12, const float th2, const bool bFixScale)
{
    g2o::SparseOptimizer optimizer;
    g2o::BlockSolverX::LinearSolverType * linearSolver;

    linearSolver = new g2o::LinearSolverDense&lt;g2o::BlockSolverX::PoseMatrixType&gt;();

    g2o::BlockSolverX * solver_ptr = new g2o::BlockSolverX(linearSolver);

    g2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
    optimizer.setAlgorithm(solver);

    // Calibration
    const cv::Mat &amp;K1 = pKF1-&gt;mK;
    const cv::Mat &amp;K2 = pKF2-&gt;mK;

    // Camera poses
    const cv::Mat R1w = pKF1-&gt;GetRotation();
    const cv::Mat t1w = pKF1-&gt;GetTranslation();
    const cv::Mat R2w = pKF2-&gt;GetRotation();
    const cv::Mat t2w = pKF2-&gt;GetTranslation();

    // Set Sim3 vertex
    g2o::VertexSim3Expmap * vSim3 = new g2o::VertexSim3Expmap();    
    vSim3-&gt;_fix_scale=bFixScale;
    vSim3-&gt;setEstimate(g2oS12);
    vSim3-&gt;setId(0);
    vSim3-&gt;setFixed(false);
    vSim3-&gt;_principle_point1[0] = K1.at&lt;float&gt;(0,2);
    vSim3-&gt;_principle_point1[1] = K1.at&lt;float&gt;(1,2);
    vSim3-&gt;_focal_length1[0] = K1.at&lt;float&gt;(0,0);
    vSim3-&gt;_focal_length1[1] = K1.at&lt;float&gt;(1,1);
    vSim3-&gt;_principle_point2[0] = K2.at&lt;float&gt;(0,2);
    vSim3-&gt;_principle_point2[1] = K2.at&lt;float&gt;(1,2);
    vSim3-&gt;_focal_length2[0] = K2.at&lt;float&gt;(0,0);
    vSim3-&gt;_focal_length2[1] = K2.at&lt;float&gt;(1,1);
    optimizer.addVertex(vSim3);

    // Set MapPoint vertices
    const int N = vpMatches1.size();
    const vector&lt;MapPoint*&gt; vpMapPoints1 = pKF1-&gt;GetMapPointMatches();
    vector&lt;g2o::EdgeSim3ProjectXYZ*&gt; vpEdges12;
    vector&lt;g2o::EdgeInverseSim3ProjectXYZ*&gt; vpEdges21;
    vector&lt;size_t&gt; vnIndexEdge;

    vnIndexEdge.reserve(2*N);
    vpEdges12.reserve(2*N);
    vpEdges21.reserve(2*N);

    const float deltaHuber = sqrt(th2);

    int nCorrespondences = 0;

    for(int i=0; i&lt;N; i++)
    {
        if(!vpMatches1[i])
            continue;

        MapPoint* pMP1 = vpMapPoints1[i];
        MapPoint* pMP2 = vpMatches1[i];

        const int id1 = 2*i+1;
        const int id2 = 2*(i+1);

        const int i2 = pMP2-&gt;GetIndexInKeyFrame(pKF2);

        if(pMP1 &amp;&amp; pMP2)
        {
            if(!pMP1-&gt;isBad() &amp;&amp; !pMP2-&gt;isBad() &amp;&amp; i2&gt;=0)
            {
                g2o::VertexSBAPointXYZ* vPoint1 = new g2o::VertexSBAPointXYZ();
                cv::Mat P3D1w = pMP1-&gt;GetWorldPos();
                cv::Mat P3D1c = R1w*P3D1w + t1w;
                vPoint1-&gt;setEstimate(Converter::toVector3d(P3D1c));
                vPoint1-&gt;setId(id1);
                vPoint1-&gt;setFixed(true);
                optimizer.addVertex(vPoint1);

                g2o::VertexSBAPointXYZ* vPoint2 = new g2o::VertexSBAPointXYZ();
                cv::Mat P3D2w = pMP2-&gt;GetWorldPos();
                cv::Mat P3D2c = R2w*P3D2w + t2w;
                vPoint2-&gt;setEstimate(Converter::toVector3d(P3D2c));
                vPoint2-&gt;setId(id2);
                vPoint2-&gt;setFixed(true);
                optimizer.addVertex(vPoint2);
            }
            else
                continue;
        }
        else
            continue;

        nCorrespondences++;

        // Set edge x1 = S12*X2
        Eigen::Matrix&lt;double,2,1&gt; obs1;
        const cv::KeyPoint &amp;kpUn1 = pKF1-&gt;mvKeysUn[i];
        obs1 &lt;&lt; kpUn1.pt.x, kpUn1.pt.y;

        g2o::EdgeSim3ProjectXYZ* e12 = new g2o::EdgeSim3ProjectXYZ();
        e12-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(id2)));
        e12-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(0)));
        e12-&gt;setMeasurement(obs1);
        const float &amp;invSigmaSquare1 = pKF1-&gt;mvInvLevelSigma2[kpUn1.octave];
        e12-&gt;setInformation(Eigen::Matrix2d::Identity()*invSigmaSquare1);

        g2o::RobustKernelHuber* rk1 = new g2o::RobustKernelHuber;
        e12-&gt;setRobustKernel(rk1);
        rk1-&gt;setDelta(deltaHuber);
        optimizer.addEdge(e12);

        // Set edge x2 = S21*X1
        Eigen::Matrix&lt;double,2,1&gt; obs2;
        const cv::KeyPoint &amp;kpUn2 = pKF2-&gt;mvKeysUn[i2];
        obs2 &lt;&lt; kpUn2.pt.x, kpUn2.pt.y;

        g2o::EdgeInverseSim3ProjectXYZ* e21 = new g2o::EdgeInverseSim3ProjectXYZ();

        e21-&gt;setVertex(0, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(id1)));
        e21-&gt;setVertex(1, dynamic_cast&lt;g2o::OptimizableGraph::Vertex*&gt;(optimizer.vertex(0)));
        e21-&gt;setMeasurement(obs2);
        float invSigmaSquare2 = pKF2-&gt;mvInvLevelSigma2[kpUn2.octave];
        e21-&gt;setInformation(Eigen::Matrix2d::Identity()*invSigmaSquare2);

        g2o::RobustKernelHuber* rk2 = new g2o::RobustKernelHuber;
        e21-&gt;setRobustKernel(rk2);
        rk2-&gt;setDelta(deltaHuber);
        optimizer.addEdge(e21);

        vpEdges12.push_back(e12);
        vpEdges21.push_back(e21);
        vnIndexEdge.push_back(i);
    }

    // Optimize!
    optimizer.initializeOptimization();
    optimizer.optimize(5);

    // Check inliers
    int nBad=0;
    for(size_t i=0; i&lt;vpEdges12.size();i++)
    {
        g2o::EdgeSim3ProjectXYZ* e12 = vpEdges12[i];
        g2o::EdgeInverseSim3ProjectXYZ* e21 = vpEdges21[i];
        if(!e12 || !e21)
            continue;

        if(e12-&gt;chi2()&gt;th2 || e21-&gt;chi2()&gt;th2)
        {
            size_t idx = vnIndexEdge[i];
            vpMatches1[idx]=static_cast&lt;MapPoint*&gt;(NULL);
            optimizer.removeEdge(e12);
            optimizer.removeEdge(e21);
            vpEdges12[i]=static_cast&lt;g2o::EdgeSim3ProjectXYZ*&gt;(NULL);
            vpEdges21[i]=static_cast&lt;g2o::EdgeInverseSim3ProjectXYZ*&gt;(NULL);
            nBad++;
        }
    }

    int nMoreIterations;
    if(nBad&gt;0)
        nMoreIterations=10;
    else
        nMoreIterations=5;

    if(nCorrespondences-nBad&lt;10)
        return 0;

    // Optimize again only with inliers

    optimizer.initializeOptimization();
    optimizer.optimize(nMoreIterations);

    int nIn = 0;
    for(size_t i=0; i&lt;vpEdges12.size();i++)
    {
        g2o::EdgeSim3ProjectXYZ* e12 = vpEdges12[i];
        g2o::EdgeInverseSim3ProjectXYZ* e21 = vpEdges21[i];
        if(!e12 || !e21)
            continue;

        if(e12-&gt;chi2()&gt;th2 || e21-&gt;chi2()&gt;th2)
        {
            size_t idx = vnIndexEdge[i];
            vpMatches1[idx]=static_cast&lt;MapPoint*&gt;(NULL);
        }
        else
            nIn++;
    }

    // Recover optimized Sim3
    g2o::VertexSim3Expmap* vSim3_recov = static_cast&lt;g2o::VertexSim3Expmap*&gt;(optimizer.vertex(0));
    g2oS12= vSim3_recov-&gt;estimate();

    return nIn;
}


} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/System.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/System.cc">
				<diff>@@ -33,13 +33,15 @@ namespace ORB_SLAM2
 System::System(const string &amp;strVocFile, const string &amp;strSettingsFile, const eSensor sensor,
                const bool bUseViewer,
 			   const string &amp;mpMapFileName,
-			   const operationMode mode):
+			   const operationMode mode,
+			   bool doOfflineMapping):
 				mSensor(sensor),
 				mapFileName(mpMapFileName),
 				mbReset(false),
 				mbActivateLocalizationMode(false),
 				mbDeactivateLocalizationMode(false),
-				opMode (mode)
+				opMode (mode),
+				offlineMapping(doOfflineMapping)
 {
     // Output welcome message
     cout &lt;&lt; endl &lt;&lt;
@@ -66,10 +68,10 @@ System::System(const string &amp;strVocFile, const string &amp;strSettingsFile, const eS
     }
 
     //Load ORB Vocabulary
-    cout &lt;&lt; endl &lt;&lt; &quot;Loading ORB Vocabulary. This could take a while...&quot; &lt;&lt; endl;
 
     mpVocabulary = new ORBVocabulary();
-    if (strVocFile.empty() == false) {
+    if (opMode==MAPPING and strVocFile.empty() == false) {
+    	cout &lt;&lt; endl &lt;&lt; &quot;Loading Generic ORB Vocabulary...&quot; &lt;&lt; endl;
 		bool bVocLoad = mpVocabulary-&gt;loadFromTextFile(strVocFile);
 		if(!bVocLoad)
 		{
@@ -79,6 +81,22 @@ System::System(const string &amp;strVocFile, const string &amp;strSettingsFile, const eS
 		}
 		cout &lt;&lt; &quot;Vocabulary loaded!&quot; &lt;&lt; endl &lt;&lt; endl;
     }
+    else {
+    	cout &lt;&lt; endl &lt;&lt; &quot;Loading Custom ORB Vocabulary... &quot; ;
+    	string mapVoc = mapFileName + &quot;.voc&quot;;
+    	bool vocload = mpVocabulary-&gt;loadFromTextFile (mapVoc);
+		if(!vocload)
+		{
+			cerr &lt;&lt; &quot;Failed. Falling back to generic... &quot; &lt;&lt; endl;
+			vocload = mpVocabulary-&gt;loadFromTextFile (strVocFile);
+			if (vocload==false) {
+				cerr &lt;&lt; &quot;Failed to open at: &quot; &lt;&lt; strVocFile &lt;&lt; endl;
+				exit(-1);
+			}
+		}
+		cout &lt;&lt; &quot;Vocabulary loaded!&quot; &lt;&lt; endl &lt;&lt; endl;
+    }
+    fps = (float)fsSettings[&quot;Camera.fps&quot;];
 
     //Create KeyFrame Database
     mpKeyFrameDatabase = new KeyFrameDatabase(*mpVocabulary);
@@ -103,16 +121,18 @@ System::System(const string &amp;strVocFile, const string &amp;strSettingsFile, const eS
     if (mpMap-&gt;mbMapUpdated)
     	mpTracker-&gt;setMapLoaded();
 
-    mpLocalMapper = new LocalMapping(mpMap, mSensor==MONOCULAR);
-    mpLoopCloser = new LoopClosing(mpMap, mpKeyFrameDatabase, mpVocabulary, mSensor!=MONOCULAR);
+    mpLocalMapper = new LocalMapping(mpMap, mSensor==MONOCULAR, offlineMapping);
+    mpLoopCloser = new LoopClosing(mpMap, mpKeyFrameDatabase, mpVocabulary, mSensor!=MONOCULAR, offlineMapping);
 
     if (opMode==System::MAPPING) {
 
-		//Initialize the Local Mapping thread and launch
-		mptLocalMapping = new thread(&amp;ORB_SLAM2::LocalMapping::Run,mpLocalMapper);
+    	if (offlineMapping==false) {
+			//Initialize the Local Mapping thread and launch
+			mptLocalMapping = new thread(&amp;ORB_SLAM2::LocalMapping::Run,mpLocalMapper);
 
-		//Initialize the Loop Closing thread and launch
-		mptLoopClosing = new thread(&amp;ORB_SLAM2::LoopClosing::Run, mpLoopCloser);
+			//Initialize the Loop Closing thread and launch
+			mptLoopClosing = new thread(&amp;ORB_SLAM2::LoopClosing::Run, mpLoopCloser);
+    	}
 
 	    mpLocalMapper-&gt;SetTracker(mpTracker);
 	    mpLocalMapper-&gt;SetLoopCloser(mpLoopCloser);
@@ -207,6 +227,14 @@ cv::Mat System::TrackMonocular(const cv::Mat &amp;im, const double &amp;timestamp)
     }
 
     cv::Mat camPosOrb = mpTracker-&gt;GrabImageMonocular(im,timestamp);
+
+    if (offlineMapping==true) {
+    	int ifps = (int)fps;
+    	mpLocalMapper-&gt;RunOnce();
+    	if (mpTracker-&gt;mCurrentFrame.mnId % ifps == 0)
+    		mpLoopCloser-&gt;RunOnce();
+    }
+
     return camPosOrb;
 }
 
@@ -250,94 +278,94 @@ void System::Shutdown()
 
 void System::SaveTrajectoryTUM(const string &amp;filename)
 {
-    cout &lt;&lt; endl &lt;&lt; &quot;Saving camera trajectory to &quot; &lt;&lt; filename &lt;&lt; &quot; ...&quot; &lt;&lt; endl;
-
-    vector&lt;KeyFrame*&gt; vpKFs = mpMap-&gt;GetAllKeyFrames();
-    sort(vpKFs.begin(),vpKFs.end(),KeyFrame::lId);
-
-    // Transform all keyframes so that the first keyframe is at the origin.
-    // After a loop closure the first keyframe might not be at the origin.
-    cv::Mat Two = vpKFs[0]-&gt;GetPoseInverse();
-
-    ofstream f;
-    f.open(filename.c_str());
-    f &lt;&lt; fixed;
-
-    // Frame pose is stored relative to its reference keyframe (which is optimized by BA and pose graph).
-    // We need to get first the keyframe pose and then concatenate the relative transformation.
-    // Frames not localized (tracking failure) are not saved.
-
-    // For each frame we have a reference keyframe (lRit), the timestamp (lT) and a flag
-    // which is true when tracking failed (lbL).
-    list&lt;ORB_SLAM2::KeyFrame*&gt;::iterator lRit = mpTracker-&gt;mlpReferences.begin();
-    list&lt;double&gt;::iterator lT = mpTracker-&gt;mlFrameTimes.begin();
-    list&lt;bool&gt;::iterator lbL = mpTracker-&gt;mlbLost.begin();
-    for(list&lt;cv::Mat&gt;::iterator lit=mpTracker-&gt;mlRelativeFramePoses.begin(),
-        lend=mpTracker-&gt;mlRelativeFramePoses.end();lit!=lend;lit++, lRit++, lT++, lbL++)
-    {
-        if(*lbL)
-            continue;
-
-        KeyFrame* pKF = *lRit;
-
-        cv::Mat Trw = cv::Mat::eye(4,4,CV_32F);
-
-        // If the reference keyframe was culled, traverse the spanning tree to get a suitable keyframe.
-        while(pKF-&gt;isBad())
-        {
-            Trw = Trw*pKF-&gt;mTcp;
-            pKF = pKF-&gt;GetParent();
-        }
-
-        Trw = Trw*pKF-&gt;GetPose()*Two;
-
-        cv::Mat Tcw = (*lit)*Trw;
-        cv::Mat Rwc = Tcw.rowRange(0,3).colRange(0,3).t();
-        cv::Mat twc = -Rwc*Tcw.rowRange(0,3).col(3);
-
-        vector&lt;float&gt; q = Converter::toQuaternion(Rwc);
-
-        f &lt;&lt; setprecision(6) &lt;&lt; *lT &lt;&lt; &quot; &quot; &lt;&lt;  setprecision(9) &lt;&lt; twc.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; twc.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; twc.at&lt;float&gt;(2) &lt;&lt; &quot; &quot; &lt;&lt; q[0] &lt;&lt; &quot; &quot; &lt;&lt; q[1] &lt;&lt; &quot; &quot; &lt;&lt; q[2] &lt;&lt; &quot; &quot; &lt;&lt; q[3] &lt;&lt; endl;
-    }
-    f.close();
-    cout &lt;&lt; endl &lt;&lt; &quot;trajectory saved!&quot; &lt;&lt; endl;
+//    cout &lt;&lt; endl &lt;&lt; &quot;Saving camera trajectory to &quot; &lt;&lt; filename &lt;&lt; &quot; ...&quot; &lt;&lt; endl;
+//
+//    vector&lt;KeyFrame*&gt; vpKFs = mpMap-&gt;GetAllKeyFrames();
+//    sort(vpKFs.begin(),vpKFs.end(),KeyFrame::lId);
+//
+//    // Transform all keyframes so that the first keyframe is at the origin.
+//    // After a loop closure the first keyframe might not be at the origin.
+//    cv::Mat Two = vpKFs[0]-&gt;GetPoseInverse();
+//
+//    ofstream f;
+//    f.open(filename.c_str());
+//    f &lt;&lt; fixed;
+//
+//    // Frame pose is stored relative to its reference keyframe (which is optimized by BA and pose graph).
+//    // We need to get first the keyframe pose and then concatenate the relative transformation.
+//    // Frames not localized (tracking failure) are not saved.
+//
+//    // For each frame we have a reference keyframe (lRit), the timestamp (lT) and a flag
+//    // which is true when tracking failed (lbL).
+//    list&lt;ORB_SLAM2::KeyFrame*&gt;::iterator lRit = mpTracker-&gt;mlpReferences.begin();
+//    list&lt;double&gt;::iterator lT = mpTracker-&gt;mlFrameTimes.begin();
+//    list&lt;bool&gt;::iterator lbL = mpTracker-&gt;mlbLost.begin();
+//    for(list&lt;cv::Mat&gt;::iterator lit=mpTracker-&gt;mlRelativeFramePoses.begin(),
+//        lend=mpTracker-&gt;mlRelativeFramePoses.end();lit!=lend;lit++, lRit++, lT++, lbL++)
+//    {
+//        if(*lbL)
+//            continue;
+//
+//        KeyFrame* pKF = *lRit;
+//
+//        cv::Mat Trw = cv::Mat::eye(4,4,CV_32F);
+//
+//        // If the reference keyframe was culled, traverse the spanning tree to get a suitable keyframe.
+//        while(pKF-&gt;isBad())
+//        {
+//            Trw = Trw*pKF-&gt;mTcp;
+//            pKF = pKF-&gt;GetParent();
+//        }
+//
+//        Trw = Trw*pKF-&gt;GetPose()*Two;
+//
+//        cv::Mat Tcw = (*lit)*Trw;
+//        cv::Mat Rwc = Tcw.rowRange(0,3).colRange(0,3).t();
+//        cv::Mat twc = -Rwc*Tcw.rowRange(0,3).col(3);
+//
+//        vector&lt;float&gt; q = Converter::toQuaternion(Rwc);
+//
+//        f &lt;&lt; setprecision(6) &lt;&lt; *lT &lt;&lt; &quot; &quot; &lt;&lt;  setprecision(9) &lt;&lt; twc.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; twc.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; twc.at&lt;float&gt;(2) &lt;&lt; &quot; &quot; &lt;&lt; q[0] &lt;&lt; &quot; &quot; &lt;&lt; q[1] &lt;&lt; &quot; &quot; &lt;&lt; q[2] &lt;&lt; &quot; &quot; &lt;&lt; q[3] &lt;&lt; endl;
+//    }
+//    f.close();
+//    cout &lt;&lt; endl &lt;&lt; &quot;trajectory saved!&quot; &lt;&lt; endl;
 }
 
 
 void System::SaveKeyFrameTrajectoryTUM(const string &amp;filename)
 {
-    cout &lt;&lt; endl &lt;&lt; &quot;Saving keyframe trajectory to &quot; &lt;&lt; filename &lt;&lt; &quot; ...&quot; &lt;&lt; endl;
-
-    vector&lt;KeyFrame*&gt; vpKFs = mpMap-&gt;GetAllKeyFrames();
-    sort(vpKFs.begin(),vpKFs.end(),KeyFrame::lId);
-
-    // Transform all keyframes so that the first keyframe is at the origin.
-    // After a loop closure the first keyframe might not be at the origin.
-    //cv::Mat Two = vpKFs[0]-&gt;GetPoseInverse();
-
-    ofstream f;
-    f.open(filename.c_str());
-    f &lt;&lt; fixed;
-
-    for(size_t i=0; i&lt;vpKFs.size(); i++)
-    {
-        KeyFrame* pKF = vpKFs[i];
-
-       // pKF-&gt;SetPose(pKF-&gt;GetPose()*Two);
-
-        if(pKF-&gt;isBad())
-            continue;
-
-        cv::Mat R = pKF-&gt;GetRotation().t();
-        vector&lt;float&gt; q = Converter::toQuaternion(R);
-        cv::Mat t = pKF-&gt;GetCameraCenter();
-        f &lt;&lt; setprecision(6) &lt;&lt; pKF-&gt;mTimeStamp &lt;&lt; setprecision(7) &lt;&lt; &quot; &quot; &lt;&lt; t.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; t.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; t.at&lt;float&gt;(2)
-          &lt;&lt; &quot; &quot; &lt;&lt; q[0] &lt;&lt; &quot; &quot; &lt;&lt; q[1] &lt;&lt; &quot; &quot; &lt;&lt; q[2] &lt;&lt; &quot; &quot; &lt;&lt; q[3] &lt;&lt; endl;
-
-    }
-
-    f.close();
-    cout &lt;&lt; endl &lt;&lt; &quot;trajectory saved!&quot; &lt;&lt; endl;
+//    cout &lt;&lt; endl &lt;&lt; &quot;Saving keyframe trajectory to &quot; &lt;&lt; filename &lt;&lt; &quot; ...&quot; &lt;&lt; endl;
+//
+//    vector&lt;KeyFrame*&gt; vpKFs = mpMap-&gt;GetAllKeyFrames();
+//    sort(vpKFs.begin(),vpKFs.end(),KeyFrame::lId);
+//
+//    // Transform all keyframes so that the first keyframe is at the origin.
+//    // After a loop closure the first keyframe might not be at the origin.
+//    //cv::Mat Two = vpKFs[0]-&gt;GetPoseInverse();
+//
+//    ofstream f;
+//    f.open(filename.c_str());
+//    f &lt;&lt; fixed;
+//
+//    for(size_t i=0; i&lt;vpKFs.size(); i++)
+//    {
+//        KeyFrame* pKF = vpKFs[i];
+//
+//       // pKF-&gt;SetPose(pKF-&gt;GetPose()*Two);
+//
+//        if(pKF-&gt;isBad())
+//            continue;
+//
+//        cv::Mat R = pKF-&gt;GetRotation().t();
+//        vector&lt;float&gt; q = Converter::toQuaternion(R);
+//        cv::Mat t = pKF-&gt;GetCameraCenter();
+//        f &lt;&lt; setprecision(6) &lt;&lt; pKF-&gt;mTimeStamp &lt;&lt; setprecision(7) &lt;&lt; &quot; &quot; &lt;&lt; t.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; t.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; t.at&lt;float&gt;(2)
+//          &lt;&lt; &quot; &quot; &lt;&lt; q[0] &lt;&lt; &quot; &quot; &lt;&lt; q[1] &lt;&lt; &quot; &quot; &lt;&lt; q[2] &lt;&lt; &quot; &quot; &lt;&lt; q[3] &lt;&lt; endl;
+//
+//    }
+//
+//    f.close();
+//    cout &lt;&lt; endl &lt;&lt; &quot;trajectory saved!&quot; &lt;&lt; endl;
 }
 
 void System::SaveTrajectoryKITTI(const string &amp;filename)
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/



#include &quot;System.h&quot;
#include &quot;Converter.h&quot;
#include &lt;thread&gt;
#include &lt;pangolin/pangolin.h&gt;
#include &lt;iomanip&gt;
#include &lt;exception&gt;

namespace ORB_SLAM2
{

System::System(const string &amp;strVocFile, const string &amp;strSettingsFile, const eSensor sensor,
               const bool bUseViewer,
			   const string &amp;mpMapFileName,
			   const operationMode mode):
				mSensor(sensor),
				mapFileName(mpMapFileName),
				mbReset(false),
				mbActivateLocalizationMode(false),
				mbDeactivateLocalizationMode(false),
				opMode (mode)
{
    // Output welcome message
    cout &lt;&lt; endl &lt;&lt;
    &quot;ORB-SLAM2 Copyright (C) 2014-2016 Raul Mur-Artal, University of Zaragoza.&quot; &lt;&lt; endl &lt;&lt;
    &quot;This program comes with ABSOLUTELY NO WARRANTY;&quot; &lt;&lt; endl  &lt;&lt;
    &quot;This is free software, and you are welcome to redistribute it&quot; &lt;&lt; endl &lt;&lt;
    &quot;under certain conditions. See LICENSE.txt.&quot; &lt;&lt; endl &lt;&lt; endl;

    cout &lt;&lt; &quot;Input sensor was set to: &quot;;

    if(mSensor==MONOCULAR)
        cout &lt;&lt; &quot;Monocular&quot; &lt;&lt; endl;
    else if(mSensor==STEREO)
        cout &lt;&lt; &quot;Stereo&quot; &lt;&lt; endl;
    else if(mSensor==RGBD)
        cout &lt;&lt; &quot;RGB-D&quot; &lt;&lt; endl;

    //Check settings file
    fsSettings = cv::FileStorage(strSettingsFile.c_str(), cv::FileStorage::READ);
    if(!fsSettings.isOpened())
    {
       cerr &lt;&lt; &quot;Failed to open settings file at: &quot; &lt;&lt; strSettingsFile &lt;&lt; endl;
       exit(-1);
    }

    //Load ORB Vocabulary
    cout &lt;&lt; endl &lt;&lt; &quot;Loading ORB Vocabulary. This could take a while...&quot; &lt;&lt; endl;

    mpVocabulary = new ORBVocabulary();
    if (strVocFile.empty() == false) {
		bool bVocLoad = mpVocabulary-&gt;loadFromTextFile(strVocFile);
		if(!bVocLoad)
		{
			cerr &lt;&lt; &quot;Wrong path to vocabulary. &quot; &lt;&lt; endl;
			cerr &lt;&lt; &quot;Failed to open at: &quot; &lt;&lt; strVocFile &lt;&lt; endl;
			exit(-1);
		}
		cout &lt;&lt; &quot;Vocabulary loaded!&quot; &lt;&lt; endl &lt;&lt; endl;
    }

    //Create KeyFrame Database
    mpKeyFrameDatabase = new KeyFrameDatabase(*mpVocabulary);

    //Create the Map
    mpMap = new Map();
    try {
    	cout &lt;&lt; &quot;Loading map...&quot; &lt;&lt; endl;
    	mpMap-&gt;loadFromDisk (mapFileName, mpKeyFrameDatabase);
    } catch (exception &amp;e) {
    	cout &lt;&lt; &quot;Unable to load map &quot; &lt;&lt; mapFileName &lt;&lt; endl;
    }

    //Create Drawers. These are used by the Viewer
    mpFrameDrawer = new FrameDrawer(mpMap);
    mpMapDrawer = new MapDrawer(mpMap, strSettingsFile);

    //Initialize the Tracking thread
    //(it will live in the main thread of execution, the one that called this constructor)
    mpTracker = new Tracking(this, mpVocabulary, mpFrameDrawer, mpMapDrawer,
                             mpMap, mpKeyFrameDatabase, strSettingsFile, mSensor);
    if (mpMap-&gt;mbMapUpdated)
    	mpTracker-&gt;setMapLoaded();

    mpLocalMapper = new LocalMapping(mpMap, mSensor==MONOCULAR);
    mpLoopCloser = new LoopClosing(mpMap, mpKeyFrameDatabase, mpVocabulary, mSensor!=MONOCULAR);

    if (opMode==System::MAPPING) {

		//Initialize the Local Mapping thread and launch
		mptLocalMapping = new thread(&amp;ORB_SLAM2::LocalMapping::Run,mpLocalMapper);

		//Initialize the Loop Closing thread and launch
		mptLoopClosing = new thread(&amp;ORB_SLAM2::LoopClosing::Run, mpLoopCloser);

	    mpLocalMapper-&gt;SetTracker(mpTracker);
	    mpLocalMapper-&gt;SetLoopCloser(mpLoopCloser);

	    mpLoopCloser-&gt;SetTracker(mpTracker);
	    mpLoopCloser-&gt;SetLocalMapper(mpLocalMapper);

	    mpTracker-&gt;InformOnlyTracking(false);
    }

    else {
//    	ActivateLocalizationMode();
    	mpTracker-&gt;InformOnlyTracking(true);
    	mptLocalMapping = NULL;
    	mptLoopClosing = NULL;
    }

    //Initialize the Viewer thread and launch
    mpViewer = new Viewer(this, mpFrameDrawer,mpMapDrawer,mpTracker,fsSettings,
    	opMode);
    if(bUseViewer)
        mptViewer = new thread(&amp;Viewer::Run, mpViewer);

    mpTracker-&gt;SetViewer(mpViewer);

    //Set pointers between threads
    mpTracker-&gt;SetLocalMapper(mpLocalMapper);
    mpTracker-&gt;SetLoopClosing(mpLoopCloser);

}

cv::Mat System::TrackStereo(const cv::Mat &amp;imLeft, const cv::Mat &amp;imRight, const double &amp;timestamp)
{
    if(mSensor!=STEREO)
    {
        cerr &lt;&lt; &quot;ERROR: you called TrackStereo but input sensor was not set to STEREO.&quot; &lt;&lt; endl;
        exit(-1);
    }   

    // Check reset
    {
    unique_lock&lt;mutex&gt; lock(mMutexReset);
    if(mbReset)
    {
        mpTracker-&gt;Reset();
        mbReset = false;
    }
    }

    return mpTracker-&gt;GrabImageStereo(imLeft,imRight,timestamp);
}


cv::Mat System::TrackRGBD(const cv::Mat &amp;im, const cv::Mat &amp;depthmap, const double &amp;timestamp)
{
    if(mSensor!=RGBD)
    {
        cerr &lt;&lt; &quot;ERROR: you called TrackRGBD but input sensor was not set to RGBD.&quot; &lt;&lt; endl;
        exit(-1);
    }    

    // Check reset
    {
    unique_lock&lt;mutex&gt; lock(mMutexReset);
    if(mbReset)
    {
        mpTracker-&gt;Reset();
        mbReset = false;
    }
    }

    return mpTracker-&gt;GrabImageRGBD(im,depthmap,timestamp);
}


cv::Mat System::TrackMonocular(const cv::Mat &amp;im, const double &amp;timestamp)
{
    if(mSensor!=MONOCULAR)
    {
        cerr &lt;&lt; &quot;ERROR: you called TrackMonocular but input sensor was not set to Monocular.&quot; &lt;&lt; endl;
        exit(-1);
    }

    // Check reset
    {
    unique_lock&lt;mutex&gt; lock(mMutexReset);
    if(mbReset)
    {
        mpTracker-&gt;Reset();
        mbReset = false;
    }
    }

    cv::Mat camPosOrb = mpTracker-&gt;GrabImageMonocular(im,timestamp);
    return camPosOrb;
}


void System::Reset()
{
    unique_lock&lt;mutex&gt; lock(mMutexReset);
    mbReset = true;
}


void System::Shutdown()
{

	// Wait until all thread have effectively stopped
	if (opMode==System::MAPPING) {

		mpViewer-&gt;RequestFinish();

		mpLocalMapper-&gt;RequestFinish();
		mpLoopCloser-&gt;RequestFinish();

		while(!mpLocalMapper-&gt;isFinished() || !mpLoopCloser-&gt;isFinished()  ||
			  !mpViewer-&gt;isFinished()      || mpLoopCloser-&gt;isRunningGBA())
		{
			usleep(5000);
		}

		try {
			mpMap-&gt;saveToDisk(mapFileName, mpKeyFrameDatabase);
		} catch (...) {}

		while (!mpViewer-&gt;isFinished())
			usleep (5000);

		pangolin::BindToContext(&quot;ORB-SLAM2: Map Viewer&quot;);
	}

}


void System::SaveTrajectoryTUM(const string &amp;filename)
{
    cout &lt;&lt; endl &lt;&lt; &quot;Saving camera trajectory to &quot; &lt;&lt; filename &lt;&lt; &quot; ...&quot; &lt;&lt; endl;

    vector&lt;KeyFrame*&gt; vpKFs = mpMap-&gt;GetAllKeyFrames();
    sort(vpKFs.begin(),vpKFs.end(),KeyFrame::lId);

    // Transform all keyframes so that the first keyframe is at the origin.
    // After a loop closure the first keyframe might not be at the origin.
    cv::Mat Two = vpKFs[0]-&gt;GetPoseInverse();

    ofstream f;
    f.open(filename.c_str());
    f &lt;&lt; fixed;

    // Frame pose is stored relative to its reference keyframe (which is optimized by BA and pose graph).
    // We need to get first the keyframe pose and then concatenate the relative transformation.
    // Frames not localized (tracking failure) are not saved.

    // For each frame we have a reference keyframe (lRit), the timestamp (lT) and a flag
    // which is true when tracking failed (lbL).
    list&lt;ORB_SLAM2::KeyFrame*&gt;::iterator lRit = mpTracker-&gt;mlpReferences.begin();
    list&lt;double&gt;::iterator lT = mpTracker-&gt;mlFrameTimes.begin();
    list&lt;bool&gt;::iterator lbL = mpTracker-&gt;mlbLost.begin();
    for(list&lt;cv::Mat&gt;::iterator lit=mpTracker-&gt;mlRelativeFramePoses.begin(),
        lend=mpTracker-&gt;mlRelativeFramePoses.end();lit!=lend;lit++, lRit++, lT++, lbL++)
    {
        if(*lbL)
            continue;

        KeyFrame* pKF = *lRit;

        cv::Mat Trw = cv::Mat::eye(4,4,CV_32F);

        // If the reference keyframe was culled, traverse the spanning tree to get a suitable keyframe.
        while(pKF-&gt;isBad())
        {
            Trw = Trw*pKF-&gt;mTcp;
            pKF = pKF-&gt;GetParent();
        }

        Trw = Trw*pKF-&gt;GetPose()*Two;

        cv::Mat Tcw = (*lit)*Trw;
        cv::Mat Rwc = Tcw.rowRange(0,3).colRange(0,3).t();
        cv::Mat twc = -Rwc*Tcw.rowRange(0,3).col(3);

        vector&lt;float&gt; q = Converter::toQuaternion(Rwc);

        f &lt;&lt; setprecision(6) &lt;&lt; *lT &lt;&lt; &quot; &quot; &lt;&lt;  setprecision(9) &lt;&lt; twc.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; twc.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; twc.at&lt;float&gt;(2) &lt;&lt; &quot; &quot; &lt;&lt; q[0] &lt;&lt; &quot; &quot; &lt;&lt; q[1] &lt;&lt; &quot; &quot; &lt;&lt; q[2] &lt;&lt; &quot; &quot; &lt;&lt; q[3] &lt;&lt; endl;
    }
    f.close();
    cout &lt;&lt; endl &lt;&lt; &quot;trajectory saved!&quot; &lt;&lt; endl;
}


void System::SaveKeyFrameTrajectoryTUM(const string &amp;filename)
{
    cout &lt;&lt; endl &lt;&lt; &quot;Saving keyframe trajectory to &quot; &lt;&lt; filename &lt;&lt; &quot; ...&quot; &lt;&lt; endl;

    vector&lt;KeyFrame*&gt; vpKFs = mpMap-&gt;GetAllKeyFrames();
    sort(vpKFs.begin(),vpKFs.end(),KeyFrame::lId);

    // Transform all keyframes so that the first keyframe is at the origin.
    // After a loop closure the first keyframe might not be at the origin.
    //cv::Mat Two = vpKFs[0]-&gt;GetPoseInverse();

    ofstream f;
    f.open(filename.c_str());
    f &lt;&lt; fixed;

    for(size_t i=0; i&lt;vpKFs.size(); i++)
    {
        KeyFrame* pKF = vpKFs[i];

       // pKF-&gt;SetPose(pKF-&gt;GetPose()*Two);

        if(pKF-&gt;isBad())
            continue;

        cv::Mat R = pKF-&gt;GetRotation().t();
        vector&lt;float&gt; q = Converter::toQuaternion(R);
        cv::Mat t = pKF-&gt;GetCameraCenter();
        f &lt;&lt; setprecision(6) &lt;&lt; pKF-&gt;mTimeStamp &lt;&lt; setprecision(7) &lt;&lt; &quot; &quot; &lt;&lt; t.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt; t.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt; t.at&lt;float&gt;(2)
          &lt;&lt; &quot; &quot; &lt;&lt; q[0] &lt;&lt; &quot; &quot; &lt;&lt; q[1] &lt;&lt; &quot; &quot; &lt;&lt; q[2] &lt;&lt; &quot; &quot; &lt;&lt; q[3] &lt;&lt; endl;

    }

    f.close();
    cout &lt;&lt; endl &lt;&lt; &quot;trajectory saved!&quot; &lt;&lt; endl;
}

void System::SaveTrajectoryKITTI(const string &amp;filename)
{
    cout &lt;&lt; endl &lt;&lt; &quot;Saving camera trajectory to &quot; &lt;&lt; filename &lt;&lt; &quot; ...&quot; &lt;&lt; endl;

    vector&lt;KeyFrame*&gt; vpKFs = mpMap-&gt;GetAllKeyFrames();
    sort(vpKFs.begin(),vpKFs.end(),KeyFrame::lId);

    // Transform all keyframes so that the first keyframe is at the origin.
    // After a loop closure the first keyframe might not be at the origin.
    cv::Mat Two = vpKFs[0]-&gt;GetPoseInverse();

    ofstream f;
    f.open(filename.c_str());
    f &lt;&lt; fixed;

    // Frame pose is stored relative to its reference keyframe (which is optimized by BA and pose graph).
    // We need to get first the keyframe pose and then concatenate the relative transformation.
    // Frames not localized (tracking failure) are not saved.

    // For each frame we have a reference keyframe (lRit), the timestamp (lT) and a flag
    // which is true when tracking failed (lbL).
    list&lt;ORB_SLAM2::KeyFrame*&gt;::iterator lRit = mpTracker-&gt;mlpReferences.begin();
    list&lt;double&gt;::iterator lT = mpTracker-&gt;mlFrameTimes.begin();
    for(list&lt;cv::Mat&gt;::iterator lit=mpTracker-&gt;mlRelativeFramePoses.begin(), lend=mpTracker-&gt;mlRelativeFramePoses.end();lit!=lend;lit++, lRit++, lT++)
    {
        ORB_SLAM2::KeyFrame* pKF = *lRit;

        cv::Mat Trw = cv::Mat::eye(4,4,CV_32F);

        while(pKF-&gt;isBad())
        {
          //  cout &lt;&lt; &quot;bad parent&quot; &lt;&lt; endl;
            Trw = Trw*pKF-&gt;mTcp;
            pKF = pKF-&gt;GetParent();
        }

        Trw = Trw*pKF-&gt;GetPose()*Two;

        cv::Mat Tcw = (*lit)*Trw;
        cv::Mat Rwc = Tcw.rowRange(0,3).colRange(0,3).t();
        cv::Mat twc = -Rwc*Tcw.rowRange(0,3).col(3);

        f &lt;&lt; setprecision(9) &lt;&lt; Rwc.at&lt;float&gt;(0,0) &lt;&lt; &quot; &quot; &lt;&lt; Rwc.at&lt;float&gt;(0,1)  &lt;&lt; &quot; &quot; &lt;&lt; Rwc.at&lt;float&gt;(0,2) &lt;&lt; &quot; &quot;  &lt;&lt; twc.at&lt;float&gt;(0) &lt;&lt; &quot; &quot; &lt;&lt;
             Rwc.at&lt;float&gt;(1,0) &lt;&lt; &quot; &quot; &lt;&lt; Rwc.at&lt;float&gt;(1,1)  &lt;&lt; &quot; &quot; &lt;&lt; Rwc.at&lt;float&gt;(1,2) &lt;&lt; &quot; &quot;  &lt;&lt; twc.at&lt;float&gt;(1) &lt;&lt; &quot; &quot; &lt;&lt;
             Rwc.at&lt;float&gt;(2,0) &lt;&lt; &quot; &quot; &lt;&lt; Rwc.at&lt;float&gt;(2,1)  &lt;&lt; &quot; &quot; &lt;&lt; Rwc.at&lt;float&gt;(2,2) &lt;&lt; &quot; &quot;  &lt;&lt; twc.at&lt;float&gt;(2) &lt;&lt; endl;
    }
    f.close();
    cout &lt;&lt; endl &lt;&lt; &quot;trajectory saved!&quot; &lt;&lt; endl;
}


void System::LoadMap(const string &amp;filename)
{
	mpMap-&gt;loadFromDisk (filename, mpKeyFrameDatabase);
	mpTracker-&gt;setMapLoaded();
}


void System::SaveMap(const string &amp;filename)
{
	mpMap-&gt;saveToDisk(filename, mpKeyFrameDatabase);
}

} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Tracking.cc" new_path="ros/src/computing/perception/localization/packages/orb_localizer/src/Tracking.cc">
				<diff>@@ -59,7 +59,7 @@ Tracking::Tracking (
     mState(NO_IMAGES_YET), mSensor(sensor), mbOnlyTracking(false), mbVO(false), mpORBVocabulary(pVoc),
     mpKeyFrameDB(pKFDB), mpInitializer(static_cast&lt;Initializer*&gt;(NULL)), mpSystem(pSys),
     mpFrameDrawer(pFrameDrawer), mpMapDrawer(pMapDrawer), mpMap(pMap), mnLastRelocFrameId(0),
-	mLocalMapper(NULL), mLoopCloser(NULL)
+	mLocalMapper(NULL), mLoopCloser(NULL), mpReferenceKF(NULL)
 
 {
     // Load camera parameters from settings file
@@ -265,7 +265,7 @@ cv::Mat Tracking::GrabImageMonocular(const cv::Mat &amp;im, const double &amp;timestamp)
             cvtColor(mImGray,mImGray,CV_BGRA2GRAY);
     }
 
-    if(mState==NOT_INITIALIZED || mState==NO_IMAGES_YET)
+    if(mState==NOT_INITIALIZED or mState==NO_IMAGES_YET or mState==LOST)
         mCurrentFrame = Frame(mImGray,timestamp,mpIniORBextractor,mpORBVocabulary,mK,mDistCoef,mbf,mThDepth);
     else
         mCurrentFrame = Frame(mImGray,timestamp,mpORBextractorLeft,mpORBVocabulary,mK,mDistCoef,mbf,mThDepth);
@@ -276,10 +276,25 @@ cv::Mat Tracking::GrabImageMonocular(const cv::Mat &amp;im, const double &amp;timestamp)
 }
 
 
-void Tracking::Track()
+Transform3 Tracking::LocalizeImage (const cv::Mat &amp;image, const double &amp;timestamp)
 {
-//	printf (&quot;fx: %f, fy: %f, cx: %f, cy: %f\n&quot;, mK.at&lt;float&gt;(0,0), mK.at&lt;float&gt;(1,1), mK.at&lt;float&gt;(0,2), mK.at&lt;float&gt;(1,2));
+	mImGray = image;
+
+	if(mbRGB)
+		cvtColor(mImGray,mImGray,CV_RGB2GRAY);
+	else
+		cvtColor(mImGray,mImGray,CV_BGR2GRAY);
+
+	mCurrentFrame = Frame (mImGray, timestamp, mpIniORBextractor, mpORBVocabulary, mK, mDistCoef, mbf, mThDepth);
+
+	bool bOK = Relocalization();
+	if (bOK) {
+
+	}
+}
 
+void Tracking::Track()
+{
     if(mState==NO_IMAGES_YET)
     {
         mState = NOT_INITIALIZED;
@@ -332,7 +347,7 @@ void Tracking::Track()
             }
             else
             {
-                bOK = Relocalization();
+                bOK = Relocalization (SEARCH_MAPPING);
             }
 
             if (mState==MAP_OPEN) {
@@ -346,7 +361,13 @@ void Tracking::Track()
 
             if(mState==LOST || mState==MAP_OPEN)
             {
-                bOK = Relocalization();
+            	if (mpReferenceKF==NULL) {
+            		bOK = Relocalization (SEARCH_DB);
+            	}
+            	else {
+            		bOK = Relocalization(SEARCH_LOCAL_MAP);
+            		if (!bOK) bOK = Relocalization(SEARCH_DB);
+            	}
             }
             else
             {
@@ -383,7 +404,10 @@ void Tracking::Track()
                         vbOutMM = mCurrentFrame.mvbOutlier;
                         TcwMM = mCurrentFrame.mTcw.clone();
                     }
-                    bOKReloc = Relocalization();
+                    // XXX: Need to confirm if we need local map reloc.
+                    bOKReloc = Relocalization (SEARCH_LOCAL_MAP);
+                    if (!bOKReloc)
+                    	cerr &lt;&lt; &quot;XXX: Local map reloc failed in here\n&quot;;
 
                     if(bOKMM &amp;&amp; !bOKReloc)
                     {
@@ -640,6 +664,7 @@ void Tracking::MonocularInitialization()
         // Check if there are enough correspondences
         if(nmatches&lt;100)
         {
+        	cerr &lt;&lt; &quot;Not enough matches: &quot; &lt;&lt; nmatches &lt;&lt; endl;
             delete mpInitializer;
             mpInitializer = static_cast&lt;Initializer*&gt;(NULL);
             return;
@@ -671,6 +696,9 @@ void Tracking::MonocularInitialization()
 
             CreateInitialMapMonocular();
         }
+        else {
+        	cerr &lt;&lt; &quot;Initialization failed\n&quot;;
+        }
     }
 }
 
@@ -976,85 +1004,54 @@ bool Tracking::TrackWithMotionModel()
     return nmatchesMap&gt;=10;
 }
 
-//bool Tracking::TrackLocalMap()
-//{
-//#ifdef DEBUG_TRACKING
-//	cout &lt;&lt; &quot;Tracking Mode: TrackLocalMap()&quot; &lt;&lt; endl;
-//#endif
-//
-//    // We have an estimation of the camera pose and some map points tracked in the frame.
-//    // We retrieve the local map and try to find matches to points in the local map.
-//
-//    UpdateLocalMap();
-//
-//    SearchLocalPoints();
-//
-//    // Optimize Pose
-//    Optimizer::PoseOptimization(&amp;mCurrentFrame);
-//    mnMatchesInliers = 0;
-//
-//    // Update MapPoints Statistics
-//    for(int i=0; i&lt;mCurrentFrame.N; i++)
-//    {
-//        if(mCurrentFrame.mvpMapPoints[i])
-//        {
-//            if(!mCurrentFrame.mvbOutlier[i])
-//            {
-//                mCurrentFrame.mvpMapPoints[i]-&gt;IncreaseFound();
-//                if(!mbOnlyTracking)
-//                {
-//                    if(mCurrentFrame.mvpMapPoints[i]-&gt;Observations()&gt;0)
-//                        mnMatchesInliers++;
-//                }
-//                else
-//                    mnMatchesInliers++;
-//            }
-//            else if(mSensor==System::STEREO)
-//                mCurrentFrame.mvpMapPoints[i] = static_cast&lt;MapPoint*&gt;(NULL);
-//
-//        }
-//    }
-//
-//    // Decide if the tracking was successful
-//    // More restrictive if there was a relocalization recently
-//    if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+mMaxFrames &amp;&amp; mnMatchesInliers&lt;50) {
-////    	cerr &lt;&lt; &quot;TrackLocalMap Failure: A&quot; &lt;&lt; endl;
-//        return false;
-//    }
-//
-//    if(mnMatchesInliers&lt;30) {
-////    	cerr &lt;&lt; &quot;TrackLocalMap Failure: B&quot; &lt;&lt; endl;
-//        return false;
-//    }
-//    else
-//        return true;
-//}
-
-// This is taken from ORB-SLAM v1
 bool Tracking::TrackLocalMap()
 {
-	UpdateLocalMap();
-	SearchLocalPoints();
-	mnMatchesInliers = Optimizer::PoseOptimization(&amp;mCurrentFrame);
-#ifdef DEBUG_TRACKING
-//	cout &lt;&lt; &quot;Tracking Mode: TrackLocalMap(), matches: &quot; &lt;&lt; mnMatchesInliers &lt;&lt; endl;
-	lastTrackingMode = TRACK_LOCAL_MAP;
-#endif
+    // We have an estimation of the camera pose and some map points tracked in the frame.
+    // We retrieve the local map and try to find matches to points in the local map.
 
-	for (size_t i=0; i&lt;mCurrentFrame.mvpMapPoints.size(); i++) {
-		if (mCurrentFrame.mvpMapPoints[i]) {
-			if (!mCurrentFrame.mvbOutlier[i])
-				mCurrentFrame.mvpMapPoints[i]-&gt;IncreaseFound();
-		}
-	}
+    UpdateLocalMap();
 
-	if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+mMaxFrames &amp;&amp; mnMatchesInliers&lt;50)
-		return false;
+    SearchLocalPoints();
 
-	if(mnMatchesInliers&lt;30)
-		return false;
-	else
-		return true;
+    // Optimize Pose
+    Optimizer::PoseOptimization(&amp;mCurrentFrame);
+    mnMatchesInliers = 0;
+
+    // Update MapPoints Statistics
+    for(int i=0; i&lt;mCurrentFrame.N; i++)
+    {
+        if(mCurrentFrame.mvpMapPoints[i])
+        {
+            if(!mCurrentFrame.mvbOutlier[i])
+            {
+                mCurrentFrame.mvpMapPoints[i]-&gt;IncreaseFound();
+                if(!mbOnlyTracking)
+                {
+                    if(mCurrentFrame.mvpMapPoints[i]-&gt;Observations()&gt;0)
+                        mnMatchesInliers++;
+                }
+                else
+                    mnMatchesInliers++;
+            }
+            else if(mSensor==System::STEREO)
+                mCurrentFrame.mvpMapPoints[i] = static_cast&lt;MapPoint*&gt;(NULL);
+
+        }
+    }
+
+    // Decide if the tracking was successful
+    // More restrictive if there was a relocalization recently
+    if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+mMaxFrames &amp;&amp; mnMatchesInliers&lt;50) {
+//    	cerr &lt;&lt; &quot;TrackLocalMap Failure: A&quot; &lt;&lt; endl;
+        return false;
+    }
+
+    if(mnMatchesInliers&lt;30) {
+//    	cerr &lt;&lt; &quot;TrackLocalMap Failure: B&quot; &lt;&lt; endl;
+        return false;
+    }
+    else
+        return true;
 }
 
 
@@ -1070,8 +1067,10 @@ bool Tracking::NeedNewKeyFrame()
     const int nKFs = mpMap-&gt;KeyFramesInMap();
 
     // Do not insert keyframes if not enough frames have passed from last relocalisation
-    if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+mMaxFrames &amp;&amp; nKFs&gt;mMaxFrames)
-        return false;
+    if (mpSystem-&gt;offlineMapping==false) {
+		if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+mMaxFrames &amp;&amp; nKFs&gt;mMaxFrames)
+			return false;
+    }
 
     // Tracked MapPoints in the reference keyframe
     int nMinObs = 3;
@@ -1080,7 +1079,12 @@ bool Tracking::NeedNewKeyFrame()
     int nRefMatches = mpReferenceKF-&gt;TrackedMapPoints(nMinObs);
 
     // Local Mapping accept keyframes?
-    bool bLocalMappingIdle = mpLocalMapper-&gt;AcceptKeyFrames();
+    bool bLocalMappingIdle;
+    if (mpSystem-&gt;offlineMapping==false) {
+    	bLocalMappingIdle = mpLocalMapper-&gt;AcceptKeyFrames();
+    }
+    else
+    	bLocalMappingIdle = true;
 
 #ifdef DEBUG_TRACKING
 //	cout &lt;&lt; &quot;Checking if we need new keyframe&quot; &lt;&lt; endl;
@@ -1167,7 +1171,7 @@ bool Tracking::NeedNewKeyFrame()
 
 void Tracking::CreateNewKeyFrame()
 {
-    if(!mpLocalMapper-&gt;SetNotStop(true))
+    if(mpSystem-&gt;offlineMapping==false and !mpLocalMapper-&gt;SetNotStop(true))
         return;
 
     KeyFrame* pKF = new KeyFrame(mCurrentFrame,mpMap,mpKeyFrameDB);
@@ -1239,7 +1243,8 @@ void Tracking::CreateNewKeyFrame()
 
     mpLocalMapper-&gt;InsertKeyFrame(pKF);
 
-    mpLocalMapper-&gt;SetNotStop(false);
+    if (mpSystem-&gt;offlineMapping==false)
+    	mpLocalMapper-&gt;SetNotStop(false);
 
     mnLastKeyFrameId = mCurrentFrame.mnId;
     mpLastKeyFrame = pKF;
@@ -1443,19 +1448,30 @@ void Tracking::UpdateLocalKeyFrames()
     }
 }
 
-bool Tracking::Relocalization()
+bool Tracking::Relocalization (RelocalizationMode relocmode)
 {
-#ifdef DEBUG_TRACKING
-//	cout &lt;&lt; &quot;Tracking Mode: Relocalization()&quot; &lt;&lt; endl;
-	lastTrackingMode = RELOCALIZATION;
-#endif
-
     // Compute Bag of Words Vector
     mCurrentFrame.ComputeBoW();
 
     // Relocalization is performed when tracking is lost
-    // Track Lost: Query KeyFrame Database for keyframe candidates for relocalisation
-    vector&lt;KeyFrame*&gt; vpCandidateKFs = mpKeyFrameDB-&gt;DetectRelocalizationCandidates(&amp;mCurrentFrame);
+    vector&lt;KeyFrame*&gt; vpCandidateKFs;
+    switch (relocmode) {
+    case SEARCH_DB: {
+
+    	vpCandidateKFs = mpKeyFrameDB-&gt;DetectRelocalizationCandidatesSimple (&amp;mCurrentFrame);
+    	cerr &lt;&lt; &quot;Searching DB: &quot; &lt;&lt; vpCandidateKFs.size() &lt;&lt; endl;
+    } break;
+
+    case SEARCH_MAPPING: {
+    	vpCandidateKFs = mpKeyFrameDB-&gt;DetectRelocalizationCandidates (&amp;mCurrentFrame);
+    	cerr &lt;&lt; &quot;Searching previously matches: &quot; &lt;&lt; vpCandidateKFs.size() &lt;&lt; endl;
+    } break;
+
+    case SEARCH_LOCAL_MAP: {
+    	vpCandidateKFs = mvpLocalKeyFrames;
+    	cerr &lt;&lt; &quot;Searching Locality: &quot; &lt;&lt; vpCandidateKFs.size() &lt;&lt; endl;
+    } break;
+    }
 
     if(vpCandidateKFs.empty())
         return false;
@@ -1485,8 +1501,11 @@ bool Tracking::Relocalization()
         else
         {
             int nmatches = matcher.SearchByBoW(pKF,mCurrentFrame,vvpMapPointMatches[i]);
+//            cerr &lt;&lt; &quot;# BoW matches: &quot; &lt;&lt; nmatches &lt;&lt; endl;
+//            if(nmatches&lt;7)
             if(nmatches&lt;15)
             {
+            	cerr &lt;&lt; &quot;KF discarded: #&quot; &lt;&lt; pKF-&gt;mnId &lt;&lt; endl;
                 vbDiscarded[i] = true;
                 continue;
             }
@@ -1519,6 +1538,7 @@ bool Tracking::Relocalization()
 
             PnPsolver* pSolver = vpPnPsolvers[i];
             cv::Mat Tcw = pSolver-&gt;iterate(5,bNoMore,vbInliers,nInliers);
+//            cerr &lt;&lt; &quot;#Inliers: &quot; &lt;&lt; nInliers &lt;&lt; endl;
 
             // If Ransac reachs max. iterations discard keyframe
             if(bNoMore)
@@ -1603,6 +1623,7 @@ bool Tracking::Relocalization()
 
     if(!bMatch)
     {
+//    	fprintf(stderr, &quot;#KF: %d\n&quot;, nKFs);
         return false;
     }
     else
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/


#include &quot;Tracking.h&quot;

#include&lt;opencv2/core/core.hpp&gt;
#include&lt;opencv2/features2d/features2d.hpp&gt;

#include&quot;ORBmatcher.h&quot;
#include&quot;FrameDrawer.h&quot;
#include&quot;Converter.h&quot;
#include&quot;Map.h&quot;
#include&quot;Initializer.h&quot;

#include&quot;Optimizer.h&quot;
#include&quot;PnPsolver.h&quot;

#include&lt;iostream&gt;

#include&lt;mutex&gt;


#define DEBUG_TRACKING


using namespace std;

namespace ORB_SLAM2
{

Tracking::Tracking (
	System *pSys,
	ORBVocabulary* pVoc,
	FrameDrawer *pFrameDrawer,
	MapDrawer *pMapDrawer,
	Map *pMap,
	KeyFrameDatabase* pKFDB,
	const string &amp;strSettingPath,
	const int sensor):

    mState(NO_IMAGES_YET), mSensor(sensor), mbOnlyTracking(false), mbVO(false), mpORBVocabulary(pVoc),
    mpKeyFrameDB(pKFDB), mpInitializer(static_cast&lt;Initializer*&gt;(NULL)), mpSystem(pSys),
    mpFrameDrawer(pFrameDrawer), mpMapDrawer(pMapDrawer), mpMap(pMap), mnLastRelocFrameId(0),
	mLocalMapper(NULL), mLoopCloser(NULL)

{
    // Load camera parameters from settings file

    cv::FileStorage fSettings(strSettingPath, cv::FileStorage::READ);
    float fx = fSettings[&quot;Camera.fx&quot;];
    float fy = fSettings[&quot;Camera.fy&quot;];
    float cx = fSettings[&quot;Camera.cx&quot;];
    float cy = fSettings[&quot;Camera.cy&quot;];

    cv::Mat K = cv::Mat::eye(3,3,CV_32F);
    K.at&lt;float&gt;(0,0) = fx;
    K.at&lt;float&gt;(1,1) = fy;
    K.at&lt;float&gt;(0,2) = cx;
    K.at&lt;float&gt;(1,2) = cy;
    K.copyTo(mK);

    cv::Mat DistCoef(4,1,CV_32F);
    DistCoef.at&lt;float&gt;(0) = fSettings[&quot;Camera.k1&quot;];
    DistCoef.at&lt;float&gt;(1) = fSettings[&quot;Camera.k2&quot;];
    DistCoef.at&lt;float&gt;(2) = fSettings[&quot;Camera.p1&quot;];
    DistCoef.at&lt;float&gt;(3) = fSettings[&quot;Camera.p2&quot;];
    const float k3 = fSettings[&quot;Camera.k3&quot;];
    if(k3!=0)
    {
        DistCoef.resize(5);
        DistCoef.at&lt;float&gt;(4) = k3;
    }
    DistCoef.copyTo(mDistCoef);

    mbf = fSettings[&quot;Camera.bf&quot;];

    float fps = fSettings[&quot;Camera.fps&quot;];
    if(fps==0)
        fps=30;

    // Max/Min Frames to insert keyframes and to check relocalisation
    mMinFrames = 0;
    mMaxFrames = fps;

    int nRGB = fSettings[&quot;Camera.RGB&quot;];
    mbRGB = nRGB;

    if(mbRGB)
        cout &lt;&lt; &quot;- color order: RGB (ignored if grayscale)&quot; &lt;&lt; endl;
    else
        cout &lt;&lt; &quot;- color order: BGR (ignored if grayscale)&quot; &lt;&lt; endl;

    // Load ORB parameters

    int nFeatures = fSettings[&quot;ORBextractor.nFeatures&quot;];
    if (pSys-&gt;opMode==System::MAPPING)
    	nFeatures *= 2;

    float fScaleFactor = fSettings[&quot;ORBextractor.scaleFactor&quot;];
    int nLevels = fSettings[&quot;ORBextractor.nLevels&quot;];
    int fIniThFAST = fSettings[&quot;ORBextractor.iniThFAST&quot;];
    int fMinThFAST = fSettings[&quot;ORBextractor.minThFAST&quot;];

    mpORBextractorLeft = new ORBextractor(nFeatures,fScaleFactor,nLevels,fIniThFAST,fMinThFAST);

    if(sensor==System::STEREO)
        mpORBextractorRight = new ORBextractor(nFeatures,fScaleFactor,nLevels,fIniThFAST,fMinThFAST);

    if(sensor==System::MONOCULAR)
        mpIniORBextractor = new ORBextractor(2*nFeatures,fScaleFactor,nLevels,fIniThFAST,fMinThFAST);

    cout &lt;&lt; endl  &lt;&lt; &quot;ORB Extractor Parameters: &quot; &lt;&lt; endl;
    cout &lt;&lt; &quot;- Number of Features: &quot; &lt;&lt; nFeatures &lt;&lt; endl;
    cout &lt;&lt; &quot;- Scale Levels: &quot; &lt;&lt; nLevels &lt;&lt; endl;
    cout &lt;&lt; &quot;- Scale Factor: &quot; &lt;&lt; fScaleFactor &lt;&lt; endl;
    cout &lt;&lt; &quot;- Initial Fast Threshold: &quot; &lt;&lt; fIniThFAST &lt;&lt; endl;
    cout &lt;&lt; &quot;- Minimum Fast Threshold: &quot; &lt;&lt; fMinThFAST &lt;&lt; endl;

    if(sensor==System::STEREO || sensor==System::RGBD)
    {
        mThDepth = mbf*(float)fSettings[&quot;ThDepth&quot;]/fx;
        cout &lt;&lt; endl &lt;&lt; &quot;Depth Threshold (Close/Far Points): &quot; &lt;&lt; mThDepth &lt;&lt; endl;
    }

    if(sensor==System::RGBD)
    {
        mDepthMapFactor = fSettings[&quot;DepthMapFactor&quot;];
        if(mDepthMapFactor==0)
            mDepthMapFactor=1;
        else
            mDepthMapFactor = 1.0f/mDepthMapFactor;
    }

}


void Tracking::setMapLoaded()
{
	mState = MAP_OPEN;
	mvpLocalMapPoints = mpMap-&gt;GetReferenceMapPoints();
}


void Tracking::SetLocalMapper(LocalMapping *pLocalMapper)
{
    mpLocalMapper=pLocalMapper;
}

void Tracking::SetLoopClosing(LoopClosing *pLoopClosing)
{
    mpLoopClosing=pLoopClosing;
}

void Tracking::SetViewer(Viewer *pViewer)
{
    mpViewer=pViewer;
}


cv::Mat Tracking::GrabImageStereo(const cv::Mat &amp;imRectLeft, const cv::Mat &amp;imRectRight, const double &amp;timestamp)
{
    mImGray = imRectLeft;
    cv::Mat imGrayRight = imRectRight;

    if(mImGray.channels()==3)
    {
        if(mbRGB)
        {
            cvtColor(mImGray,mImGray,CV_RGB2GRAY);
            cvtColor(imGrayRight,imGrayRight,CV_RGB2GRAY);
        }
        else
        {
            cvtColor(mImGray,mImGray,CV_BGR2GRAY);
            cvtColor(imGrayRight,imGrayRight,CV_BGR2GRAY);
        }
    }
    else if(mImGray.channels()==4)
    {
        if(mbRGB)
        {
            cvtColor(mImGray,mImGray,CV_RGBA2GRAY);
            cvtColor(imGrayRight,imGrayRight,CV_RGBA2GRAY);
        }
        else
        {
            cvtColor(mImGray,mImGray,CV_BGRA2GRAY);
            cvtColor(imGrayRight,imGrayRight,CV_BGRA2GRAY);
        }
    }

    mCurrentFrame = Frame(mImGray,imGrayRight,timestamp,mpORBextractorLeft,mpORBextractorRight,mpORBVocabulary,mK,mDistCoef,mbf,mThDepth);

    Track();

    return mCurrentFrame.mTcw.clone();
}


cv::Mat Tracking::GrabImageRGBD(const cv::Mat &amp;imRGB,const cv::Mat &amp;imD, const double &amp;timestamp)
{
    mImGray = imRGB;
    cv::Mat imDepth = imD;

    if(mImGray.channels()==3)
    {
        if(mbRGB)
            cvtColor(mImGray,mImGray,CV_RGB2GRAY);
        else
            cvtColor(mImGray,mImGray,CV_BGR2GRAY);
    }
    else if(mImGray.channels()==4)
    {
        if(mbRGB)
            cvtColor(mImGray,mImGray,CV_RGBA2GRAY);
        else
            cvtColor(mImGray,mImGray,CV_BGRA2GRAY);
    }

    if(mDepthMapFactor!=1 || imDepth.type()!=CV_32F);
    imDepth.convertTo(imDepth,CV_32F,mDepthMapFactor);

    mCurrentFrame = Frame(mImGray,imDepth,timestamp,mpORBextractorLeft,mpORBVocabulary,mK,mDistCoef,mbf,mThDepth);

    Track();

    return mCurrentFrame.mTcw.clone();
}


cv::Mat Tracking::GrabImageMonocular(const cv::Mat &amp;im, const double &amp;timestamp)
{
    mImGray = im;

    if(mImGray.channels()==3)
    {
        if(mbRGB)
            cvtColor(mImGray,mImGray,CV_RGB2GRAY);
        else
            cvtColor(mImGray,mImGray,CV_BGR2GRAY);
    }
    else if(mImGray.channels()==4)
    {
        if(mbRGB)
            cvtColor(mImGray,mImGray,CV_RGBA2GRAY);
        else
            cvtColor(mImGray,mImGray,CV_BGRA2GRAY);
    }

    if(mState==NOT_INITIALIZED || mState==NO_IMAGES_YET)
        mCurrentFrame = Frame(mImGray,timestamp,mpIniORBextractor,mpORBVocabulary,mK,mDistCoef,mbf,mThDepth);
    else
        mCurrentFrame = Frame(mImGray,timestamp,mpORBextractorLeft,mpORBVocabulary,mK,mDistCoef,mbf,mThDepth);

    Track();

    return mCurrentFrame.mTcw.clone();
}


void Tracking::Track()
{
//	printf (&quot;fx: %f, fy: %f, cx: %f, cy: %f\n&quot;, mK.at&lt;float&gt;(0,0), mK.at&lt;float&gt;(1,1), mK.at&lt;float&gt;(0,2), mK.at&lt;float&gt;(1,2));

    if(mState==NO_IMAGES_YET)
    {
        mState = NOT_INITIALIZED;
    }

    mLastProcessedState=mState;

    // Get Map Mutex -&gt; Map cannot be changed
    unique_lock&lt;mutex&gt; lock(mpMap-&gt;mMutexMapUpdate);

    if(mState==NOT_INITIALIZED)
    {
        if(mSensor==System::STEREO || mSensor==System::RGBD)
            StereoInitialization();
        else
            MonocularInitialization();

        if (mpFrameDrawer != NULL)
        	mpFrameDrawer-&gt;Update(this);

        if(mState!=OK)
            return;
    }
    else
    {
        // System is initialized. Track Frame.
        bool bOK;

        // Initial camera pose estimation using motion model or relocalization (if tracking is lost)
        if(!mbOnlyTracking)
        {
            // Local Mapping is activated. This is the normal behaviour, unless
            // you explicitly activate the &quot;only tracking&quot; mode.

            if(mState==OK)
            {
                // Local Mapping might have changed some MapPoints tracked in last frame
                CheckReplacedInLastFrame();

                if(mVelocity.empty() || mCurrentFrame.mnId&lt;mnLastRelocFrameId+2)
                {
                    bOK = TrackReferenceKeyFrame();
                }
                else
                {
                    bOK = TrackWithMotionModel();
                    if(!bOK)
                        bOK = TrackReferenceKeyFrame();
                }
            }
            else
            {
                bOK = Relocalization();
            }

            if (mState==MAP_OPEN) {
            	MapOpenMonocularInitialization();
            }

        }
        else
        {
            // Only Tracking: Local Mapping is deactivated

            if(mState==LOST || mState==MAP_OPEN)
            {
                bOK = Relocalization();
            }
            else
            {
                if(!mbVO)
                {
                    // In last frame we tracked enough MapPoints in the map

                    if(!mVelocity.empty())
                    {
                        bOK = TrackWithMotionModel();
                    }
                    else
                    {
                        bOK = TrackReferenceKeyFrame();
                    }
                }
                else
                {
                    // In last frame we tracked mainly &quot;visual odometry&quot; points.

                    // We compute two camera poses, one from motion model and one doing relocalization.
                    // If relocalization is successful we choose that solution, otherwise we retain
                    // the &quot;visual odometry&quot; solution.

                    bool bOKMM = false;
                    bool bOKReloc = false;
                    vector&lt;MapPoint*&gt; vpMPsMM;
                    vector&lt;bool&gt; vbOutMM;
                    cv::Mat TcwMM;
                    if(!mVelocity.empty())
                    {
                        bOKMM = TrackWithMotionModel();
                        vpMPsMM = mCurrentFrame.mvpMapPoints;
                        vbOutMM = mCurrentFrame.mvbOutlier;
                        TcwMM = mCurrentFrame.mTcw.clone();
                    }
                    bOKReloc = Relocalization();

                    if(bOKMM &amp;&amp; !bOKReloc)
                    {
                        mCurrentFrame.SetPose(TcwMM);
                        mCurrentFrame.mvpMapPoints = vpMPsMM;
                        mCurrentFrame.mvbOutlier = vbOutMM;

                        if(mbVO)
                        {
                            for(int i =0; i&lt;mCurrentFrame.N; i++)
                            {
                                if(mCurrentFrame.mvpMapPoints[i] &amp;&amp; !mCurrentFrame.mvbOutlier[i])
                                {
                                    mCurrentFrame.mvpMapPoints[i]-&gt;IncreaseFound();
                                }
                            }
                        }
                    }
                    else if(bOKReloc)
                    {
                        mbVO = false;
                    }

                    bOK = bOKReloc || bOKMM;
                }
            }
        }

        mCurrentFrame.mpReferenceKF = mpReferenceKF;

        // If we have an initial estimation of the camera pose and matching. Track the local map.
        if(!mbOnlyTracking)
        {
            if(bOK)
                bOK = TrackLocalMap();
        }
        else
        {
            // mbVO true means that there are few matches to MapPoints in the map. We cannot retrieve
            // a local map and therefore we do not perform TrackLocalMap(). Once the system relocalizes
            // the camera we will use the local map again.
            if(bOK &amp;&amp; !mbVO)
                bOK = TrackLocalMap();
        }

        if(bOK)
            mState = OK;
        else
            mState=LOST;

        // Update drawer
        if (mpFrameDrawer != NULL)
        	mpFrameDrawer-&gt;Update(this);

        // If tracking were good, check if we insert a keyframe
        if(bOK)
        {
            // Update motion model
            if(!mLastFrame.mTcw.empty())
            {
                cv::Mat LastTwc = cv::Mat::eye(4,4,CV_32F);
                mLastFrame.GetRotationInverse().copyTo(LastTwc.rowRange(0,3).colRange(0,3));
                mLastFrame.GetCameraCenter().copyTo(LastTwc.rowRange(0,3).col(3));
                mVelocity = mCurrentFrame.mTcw*LastTwc;
            }
            else
                mVelocity = cv::Mat();

            if (mpMapDrawer != NULL)
            	mpMapDrawer-&gt;SetCurrentCameraPose(mCurrentFrame.mTcw);

            // Clean temporal point matches
            for(int i=0; i&lt;mCurrentFrame.N; i++)
            {
                MapPoint* pMP = mCurrentFrame.mvpMapPoints[i];
                if(pMP)
                    if(pMP-&gt;Observations()&lt;1)
                    {
                        mCurrentFrame.mvbOutlier[i] = false;
                        mCurrentFrame.mvpMapPoints[i]=static_cast&lt;MapPoint*&gt;(NULL);
                    }
            }

            // Delete temporal MapPoints
            for(list&lt;MapPoint*&gt;::iterator lit = mlpTemporalPoints.begin(), lend =  mlpTemporalPoints.end(); lit!=lend; lit++)
            {
                MapPoint* pMP = *lit;
                delete pMP;
            }
            mlpTemporalPoints.clear();

            // Check if we need to insert a new keyframe
            if(NeedNewKeyFrame()) {
                CreateNewKeyFrame();
            }

            // We allow points with high innovation (considered outliers by the Huber Function)
            // pass to the new keyframe, so that bundle adjustment will finally decide
            // if they are outliers or not. We don't want next frame to estimate its position
            // with those points so we discard them in the frame.
            for(int i=0; i&lt;mCurrentFrame.N;i++)
            {
                if(mCurrentFrame.mvpMapPoints[i] &amp;&amp; mCurrentFrame.mvbOutlier[i])
                    mCurrentFrame.mvpMapPoints[i]=static_cast&lt;MapPoint*&gt;(NULL);
            }
        }

        // Reset if the camera get lost soon after initialization
        if(mState==LOST)
        {
            if(mpMap-&gt;KeyFramesInMap()&lt;=5)
            {
                cout &lt;&lt; &quot;Track lost soon after initialization, resetting...&quot; &lt;&lt; endl;
                mpSystem-&gt;Reset();
                return;
            }
        }

        if(!mCurrentFrame.mpReferenceKF)
            mCurrentFrame.mpReferenceKF = mpReferenceKF;

        mLastFrame = Frame(mCurrentFrame);
    }

    // Store frame pose information to retrieve the complete camera trajectory afterwards.
    if(!mCurrentFrame.mTcw.empty())
    {
    	// XXX: We found some occurences of empty pose from mpReferenceKF
		if (mCurrentFrame.mpReferenceKF-&gt;GetPose().empty()==true)
			cout &lt;&lt; &quot;XXX: KF pose is empty&quot; &lt;&lt; endl;
		cv::Mat Tcr = mCurrentFrame.mTcw*mCurrentFrame.mpReferenceKF-&gt;GetPoseInverse();
//		cout &lt;&lt; mCurrentFrame.mpReferenceKF &lt;&lt; endl;
		mlRelativeFramePoses.push_back(Tcr);
		mlpReferences.push_back(mpReferenceKF);
		mlFrameTimes.push_back(mCurrentFrame.mTimeStamp);
		mlbLost.push_back(mState==LOST);
    }
    else
    {
        // This can happen if tracking is lost
    	if (!mlRelativeFramePoses.empty())
    		mlRelativeFramePoses.push_back(mlRelativeFramePoses.back());
    	if (!mlpReferences.empty())
    		mlpReferences.push_back(mlpReferences.back());
    	if (!mlFrameTimes.empty())
    		mlFrameTimes.push_back(mlFrameTimes.back());
    	if (mlbLost.empty())
    		mlbLost.push_back(mState==LOST);
    }

}


void Tracking::StereoInitialization()
{
    if(mCurrentFrame.N&gt;500)
    {
        // Set Frame pose to the origin
        mCurrentFrame.SetPose(cv::Mat::eye(4,4,CV_32F));

        // Create KeyFrame
        KeyFrame* pKFini = new KeyFrame(mCurrentFrame,mpMap,mpKeyFrameDB);

        // Insert KeyFrame in the map
        mpMap-&gt;AddKeyFrame(pKFini);

        // Create MapPoints and asscoiate to KeyFrame
        for(int i=0; i&lt;mCurrentFrame.N;i++)
        {
            float z = mCurrentFrame.mvDepth[i];
            if(z&gt;0)
            {
                cv::Mat x3D = mCurrentFrame.UnprojectStereo(i);
                MapPoint* pNewMP = new MapPoint(x3D,pKFini,mpMap);
                pNewMP-&gt;AddObservation(pKFini,i);
                pKFini-&gt;AddMapPoint(pNewMP,i);
                pNewMP-&gt;ComputeDistinctiveDescriptors();
                pNewMP-&gt;UpdateNormalAndDepth();
                mpMap-&gt;AddMapPoint(pNewMP);

                mCurrentFrame.mvpMapPoints[i]=pNewMP;
            }
        }

        cout &lt;&lt; &quot;New map created with &quot; &lt;&lt; mpMap-&gt;MapPointsInMap() &lt;&lt; &quot; points&quot; &lt;&lt; endl;

        mpLocalMapper-&gt;InsertKeyFrame(pKFini);

        mLastFrame = Frame(mCurrentFrame);
        mnLastKeyFrameId=mCurrentFrame.mnId;
        mpLastKeyFrame = pKFini;

        mvpLocalKeyFrames.push_back(pKFini);
        mvpLocalMapPoints=mpMap-&gt;GetAllMapPoints();
        mpReferenceKF = pKFini;
        mCurrentFrame.mpReferenceKF = pKFini;

        mpMap-&gt;SetReferenceMapPoints(mvpLocalMapPoints);

        mpMap-&gt;mvpKeyFrameOrigins.push_back(pKFini);

        mpMapDrawer-&gt;SetCurrentCameraPose(mCurrentFrame.mTcw);

        mState=OK;
    }
}


void Tracking::MapOpenMonocularInitialization ()
{
	mnLastKeyFrameId = mCurrentFrame.mnId;
}


void Tracking::MonocularInitialization()
{

    if(!mpInitializer)
    {
        // Set Reference Frame
        if(mCurrentFrame.mvKeys.size()&gt;100)
        {
            mInitialFrame = Frame(mCurrentFrame);
            mLastFrame = Frame(mCurrentFrame);
            mvbPrevMatched.resize(mCurrentFrame.mvKeysUn.size());
            for(size_t i=0; i&lt;mCurrentFrame.mvKeysUn.size(); i++)
                mvbPrevMatched[i]=mCurrentFrame.mvKeysUn[i].pt;

            if(mpInitializer)
                delete mpInitializer;

            mpInitializer =  new Initializer(mCurrentFrame,1.0,200);

            fill(mvIniMatches.begin(),mvIniMatches.end(),-1);

            return;
        }
    }
    else
    {
        // Try to initialize
        if((int)mCurrentFrame.mvKeys.size()&lt;=100)
        {
            delete mpInitializer;
            mpInitializer = static_cast&lt;Initializer*&gt;(NULL);
            fill(mvIniMatches.begin(),mvIniMatches.end(),-1);
            return;
        }

        // Find correspondences
        ORBmatcher matcher(0.9,true);
        int nmatches = matcher.SearchForInitialization(mInitialFrame,mCurrentFrame,mvbPrevMatched,mvIniMatches,100);

        // Check if there are enough correspondences
        if(nmatches&lt;100)
        {
            delete mpInitializer;
            mpInitializer = static_cast&lt;Initializer*&gt;(NULL);
            return;
        }

        cv::Mat Rcw; // Current Camera Rotation
        cv::Mat tcw; // Current Camera Translation
        vector&lt;bool&gt; vbTriangulated; // Triangulated Correspondences (mvIniMatches)

        if(mpInitializer-&gt;Initialize(mCurrentFrame, mvIniMatches, Rcw, tcw, mvIniP3D, vbTriangulated))
        {
            for(size_t i=0, iend=mvIniMatches.size(); i&lt;iend;i++)
            {
                if(mvIniMatches[i]&gt;=0 &amp;&amp; !vbTriangulated[i])
                {
                    mvIniMatches[i]=-1;
                    nmatches--;
                }
            }

            // Set Frame Poses
            mInitialFrame.SetPose(cv::Mat::eye(4,4,CV_32F));
            cv::Mat Tcw = cv::Mat::eye(4,4,CV_32F);
            Rcw.copyTo(Tcw.rowRange(0,3).colRange(0,3));
            tcw.copyTo(Tcw.rowRange(0,3).col(3));
            mCurrentFrame.SetPose(Tcw);

            cerr &lt;&lt; Tcw &lt;&lt; endl;

            CreateInitialMapMonocular();
        }
    }
}

void Tracking::CreateInitialMapMonocular()
{
    // Create KeyFrames
    KeyFrame* pKFini = new KeyFrame(mInitialFrame,mpMap,mpKeyFrameDB);
    KeyFrame* pKFcur = new KeyFrame(mCurrentFrame,mpMap,mpKeyFrameDB);


    pKFini-&gt;ComputeBoW();
    pKFcur-&gt;ComputeBoW();

    // Insert KFs in the map
    mpMap-&gt;AddKeyFrame(pKFini);
    mpMap-&gt;AddKeyFrame(pKFcur);

    // Create MapPoints and asscoiate to keyframes
    for(size_t i=0; i&lt;mvIniMatches.size();i++)
    {
        if(mvIniMatches[i]&lt;0)
            continue;

        //Create MapPoint.
        cv::Mat worldPos(mvIniP3D[i]);

        MapPoint* pMP = new MapPoint(worldPos,pKFcur,mpMap);

        pKFini-&gt;AddMapPoint(pMP,i);
        pKFcur-&gt;AddMapPoint(pMP,mvIniMatches[i]);

        pMP-&gt;AddObservation(pKFini,i);
        pMP-&gt;AddObservation(pKFcur,mvIniMatches[i]);

        pMP-&gt;ComputeDistinctiveDescriptors();
        pMP-&gt;UpdateNormalAndDepth();

        //Fill Current Frame structure
        mCurrentFrame.mvpMapPoints[mvIniMatches[i]] = pMP;
        mCurrentFrame.mvbOutlier[mvIniMatches[i]] = false;

        //Add to Map
        mpMap-&gt;AddMapPoint(pMP);
    }

    // Update Connections
    pKFini-&gt;UpdateConnections();
    pKFcur-&gt;UpdateConnections();

    // Bundle Adjustment
    cout &lt;&lt; &quot;New Map created with &quot; &lt;&lt; mpMap-&gt;MapPointsInMap() &lt;&lt; &quot; points&quot; &lt;&lt; endl;

    Optimizer::GlobalBundleAdjustemnt(mpMap,20);

    // Set median depth to 1
    float medianDepth = pKFini-&gt;ComputeSceneMedianDepth(2);
    float invMedianDepth = 1.0f/medianDepth;

    if(medianDepth&lt;0 || pKFcur-&gt;TrackedMapPoints(1)&lt;100)
    {
        cout &lt;&lt; &quot;Wrong initialization, reseting...&quot; &lt;&lt; endl;
        Reset();
        return;
    }

    // Scale initial baseline
    cv::Mat Tc2w = pKFcur-&gt;GetPose();
    Tc2w.col(3).rowRange(0,3) = Tc2w.col(3).rowRange(0,3)*invMedianDepth;
    pKFcur-&gt;SetPose(Tc2w);

    // Scale points
    vector&lt;MapPoint*&gt; vpAllMapPoints = pKFini-&gt;GetMapPointMatches();
    for(size_t iMP=0; iMP&lt;vpAllMapPoints.size(); iMP++)
    {
        if(vpAllMapPoints[iMP])
        {
            MapPoint* pMP = vpAllMapPoints[iMP];
            pMP-&gt;SetWorldPos(pMP-&gt;GetWorldPos()*invMedianDepth);
        }
    }

    mpLocalMapper-&gt;InsertKeyFrame(pKFini);
    mpLocalMapper-&gt;InsertKeyFrame(pKFcur);

    mCurrentFrame.SetPose(pKFcur-&gt;GetPose());
    mnLastKeyFrameId=mCurrentFrame.mnId;
    mpLastKeyFrame = pKFcur;

    mvpLocalKeyFrames.push_back(pKFcur);
    mvpLocalKeyFrames.push_back(pKFini);
    mvpLocalMapPoints=mpMap-&gt;GetAllMapPoints();
    mpReferenceKF = pKFcur;
    mCurrentFrame.mpReferenceKF = pKFcur;

    mLastFrame = Frame(mCurrentFrame);

    mpMap-&gt;SetReferenceMapPoints(mvpLocalMapPoints);

    mpMapDrawer-&gt;SetCurrentCameraPose(pKFcur-&gt;GetPose());

    mpMap-&gt;mvpKeyFrameOrigins.push_back(pKFini);

    mState=OK;
}

void Tracking::CheckReplacedInLastFrame()
{
    for(int i =0; i&lt;mLastFrame.N; i++)
    {
        MapPoint* pMP = mLastFrame.mvpMapPoints[i];

        if(pMP)
        {
            MapPoint* pRep = pMP-&gt;GetReplaced();
            if(pRep)
            {
                mLastFrame.mvpMapPoints[i] = pRep;
            }
        }
    }
}


bool Tracking::TrackReferenceKeyFrame()
{
#ifdef DEBUG_TRACKING
//	cout &lt;&lt; &quot;Tracking Mode: TrackReferenceKeyFrame()&quot; &lt;&lt; endl;
	lastTrackingMode = TRACK_REFERENCE_KEYFRAME;
#endif
    // Compute Bag of Words vector
    mCurrentFrame.ComputeBoW();

    // We perform first an ORB matching with the reference keyframe
    // If enough matches are found we setup a PnP solver
    ORBmatcher matcher(0.7,true);
    vector&lt;MapPoint*&gt; vpMapPointMatches;

    int nmatches = matcher.SearchByBoW(mpReferenceKF,mCurrentFrame,vpMapPointMatches);

    if(nmatches&lt;15)
        return false;

    mCurrentFrame.mvpMapPoints = vpMapPointMatches;
    mCurrentFrame.SetPose(mLastFrame.mTcw);

    Optimizer::PoseOptimization(&amp;mCurrentFrame);

    // Discard outliers
    int nmatchesMap = 0;
    for(int i =0; i&lt;mCurrentFrame.N; i++)
    {
        if(mCurrentFrame.mvpMapPoints[i])
        {
            if(mCurrentFrame.mvbOutlier[i])
            {
                MapPoint* pMP = mCurrentFrame.mvpMapPoints[i];

                mCurrentFrame.mvpMapPoints[i]=static_cast&lt;MapPoint*&gt;(NULL);
                mCurrentFrame.mvbOutlier[i]=false;
                pMP-&gt;mbTrackInView = false;
                pMP-&gt;mnLastFrameSeen = mCurrentFrame.mnId;
                nmatches--;
            }
            else if(mCurrentFrame.mvpMapPoints[i]-&gt;Observations()&gt;0)
                nmatchesMap++;
        }
    }

    return nmatchesMap&gt;=10;
}

void Tracking::UpdateLastFrame()
{
    // Update pose according to reference keyframe
    KeyFrame* pRef = mLastFrame.mpReferenceKF;
    cv::Mat Tlr = mlRelativeFramePoses.back();

    mLastFrame.SetPose(Tlr*pRef-&gt;GetPose());

    if(mnLastKeyFrameId==mLastFrame.mnId || mSensor==System::MONOCULAR)
        return;

    // Create &quot;visual odometry&quot; MapPoints
    // We sort points according to their measured depth by the stereo/RGB-D sensor
    vector&lt;pair&lt;float,int&gt; &gt; vDepthIdx;
    vDepthIdx.reserve(mLastFrame.N);
    for(int i=0; i&lt;mLastFrame.N;i++)
    {
        float z = mLastFrame.mvDepth[i];
        if(z&gt;0)
        {
            vDepthIdx.push_back(make_pair(z,i));
        }
    }

    if(vDepthIdx.empty())
        return;

    sort(vDepthIdx.begin(),vDepthIdx.end());

    // We insert all close points (depth&lt;mThDepth)
    // If less than 100 close points, we insert the 100 closest ones.
    int nPoints = 0;
    for(size_t j=0; j&lt;vDepthIdx.size();j++)
    {
        int i = vDepthIdx[j].second;

        bool bCreateNew = false;

        MapPoint* pMP = mLastFrame.mvpMapPoints[i];
        if(!pMP)
            bCreateNew = true;
        else if(pMP-&gt;Observations()&lt;1)
        {
            bCreateNew = true;
        }

        if(bCreateNew)
        {
            cv::Mat x3D = mLastFrame.UnprojectStereo(i);
            MapPoint* pNewMP = new MapPoint(x3D,mpMap,&amp;mLastFrame,i);

            mLastFrame.mvpMapPoints[i]=pNewMP;

            mlpTemporalPoints.push_back(pNewMP);
            nPoints++;
        }
        else
        {
            nPoints++;
        }

        if(vDepthIdx[j].first&gt;mThDepth &amp;&amp; nPoints&gt;100)
            break;
    }
}

bool Tracking::TrackWithMotionModel()
{
#ifdef DEBUG_TRACKING
//	cout &lt;&lt; &quot;Tracking Mode: TrackWithMotionModel()&quot; &lt;&lt; endl;
	lastTrackingMode = TRACK_WITH_MOTION_MODEL;
#endif

    ORBmatcher matcher(0.9,true);

    // Update last frame pose according to its reference keyframe
    // Create &quot;visual odometry&quot; points
    UpdateLastFrame();

    mCurrentFrame.SetPose(mVelocity*mLastFrame.mTcw);

    fill(mCurrentFrame.mvpMapPoints.begin(),mCurrentFrame.mvpMapPoints.end(),static_cast&lt;MapPoint*&gt;(NULL));

    // Project points seen in previous frame
    int th;
    if(mSensor!=System::STEREO)
        th=15;
    else
        th=7;
    int nmatches = matcher.SearchByProjection(mCurrentFrame,mLastFrame,th,mSensor==System::MONOCULAR);

    // If few matches, uses a wider window search
    if(nmatches&lt;20)
    {
        fill(mCurrentFrame.mvpMapPoints.begin(),mCurrentFrame.mvpMapPoints.end(),static_cast&lt;MapPoint*&gt;(NULL));
        nmatches = matcher.SearchByProjection(mCurrentFrame,mLastFrame,2*th,mSensor==System::MONOCULAR);
    }

    if(nmatches&lt;20)
        return false;

    // Optimize frame pose with all matches
    Optimizer::PoseOptimization(&amp;mCurrentFrame);

    // Discard outliers
    int nmatchesMap = 0;
    for(int i =0; i&lt;mCurrentFrame.N; i++)
    {
        if(mCurrentFrame.mvpMapPoints[i])
        {
            if(mCurrentFrame.mvbOutlier[i])
            {
                MapPoint* pMP = mCurrentFrame.mvpMapPoints[i];

                mCurrentFrame.mvpMapPoints[i]=static_cast&lt;MapPoint*&gt;(NULL);
                mCurrentFrame.mvbOutlier[i]=false;
                pMP-&gt;mbTrackInView = false;
                pMP-&gt;mnLastFrameSeen = mCurrentFrame.mnId;
                nmatches--;
            }
            else if(mCurrentFrame.mvpMapPoints[i]-&gt;Observations()&gt;0)
                nmatchesMap++;
        }
    }    

    if(mbOnlyTracking)
    {
        mbVO = nmatchesMap&lt;10;
        return nmatches&gt;20;
    }

    return nmatchesMap&gt;=10;
}

//bool Tracking::TrackLocalMap()
//{
//#ifdef DEBUG_TRACKING
//	cout &lt;&lt; &quot;Tracking Mode: TrackLocalMap()&quot; &lt;&lt; endl;
//#endif
//
//    // We have an estimation of the camera pose and some map points tracked in the frame.
//    // We retrieve the local map and try to find matches to points in the local map.
//
//    UpdateLocalMap();
//
//    SearchLocalPoints();
//
//    // Optimize Pose
//    Optimizer::PoseOptimization(&amp;mCurrentFrame);
//    mnMatchesInliers = 0;
//
//    // Update MapPoints Statistics
//    for(int i=0; i&lt;mCurrentFrame.N; i++)
//    {
//        if(mCurrentFrame.mvpMapPoints[i])
//        {
//            if(!mCurrentFrame.mvbOutlier[i])
//            {
//                mCurrentFrame.mvpMapPoints[i]-&gt;IncreaseFound();
//                if(!mbOnlyTracking)
//                {
//                    if(mCurrentFrame.mvpMapPoints[i]-&gt;Observations()&gt;0)
//                        mnMatchesInliers++;
//                }
//                else
//                    mnMatchesInliers++;
//            }
//            else if(mSensor==System::STEREO)
//                mCurrentFrame.mvpMapPoints[i] = static_cast&lt;MapPoint*&gt;(NULL);
//
//        }
//    }
//
//    // Decide if the tracking was successful
//    // More restrictive if there was a relocalization recently
//    if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+mMaxFrames &amp;&amp; mnMatchesInliers&lt;50) {
////    	cerr &lt;&lt; &quot;TrackLocalMap Failure: A&quot; &lt;&lt; endl;
//        return false;
//    }
//
//    if(mnMatchesInliers&lt;30) {
////    	cerr &lt;&lt; &quot;TrackLocalMap Failure: B&quot; &lt;&lt; endl;
//        return false;
//    }
//    else
//        return true;
//}

// This is taken from ORB-SLAM v1
bool Tracking::TrackLocalMap()
{
	UpdateLocalMap();
	SearchLocalPoints();
	mnMatchesInliers = Optimizer::PoseOptimization(&amp;mCurrentFrame);
#ifdef DEBUG_TRACKING
//	cout &lt;&lt; &quot;Tracking Mode: TrackLocalMap(), matches: &quot; &lt;&lt; mnMatchesInliers &lt;&lt; endl;
	lastTrackingMode = TRACK_LOCAL_MAP;
#endif

	for (size_t i=0; i&lt;mCurrentFrame.mvpMapPoints.size(); i++) {
		if (mCurrentFrame.mvpMapPoints[i]) {
			if (!mCurrentFrame.mvbOutlier[i])
				mCurrentFrame.mvpMapPoints[i]-&gt;IncreaseFound();
		}
	}

	if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+mMaxFrames &amp;&amp; mnMatchesInliers&lt;50)
		return false;

	if(mnMatchesInliers&lt;30)
		return false;
	else
		return true;
}


bool Tracking::NeedNewKeyFrame()
{
    if(mbOnlyTracking)
        return false;

    // If Local Mapping is freezed by a Loop Closure do not insert keyframes
    if(mpLocalMapper-&gt;isStopped() || mpLocalMapper-&gt;stopRequested())
        return false;

    const int nKFs = mpMap-&gt;KeyFramesInMap();

    // Do not insert keyframes if not enough frames have passed from last relocalisation
    if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+mMaxFrames &amp;&amp; nKFs&gt;mMaxFrames)
        return false;

    // Tracked MapPoints in the reference keyframe
    int nMinObs = 3;
    if(nKFs&lt;=2)
        nMinObs=2;
    int nRefMatches = mpReferenceKF-&gt;TrackedMapPoints(nMinObs);

    // Local Mapping accept keyframes?
    bool bLocalMappingIdle = mpLocalMapper-&gt;AcceptKeyFrames();

#ifdef DEBUG_TRACKING
//	cout &lt;&lt; &quot;Checking if we need new keyframe&quot; &lt;&lt; endl;
#endif


    // Stereo &amp; RGB-D: Ratio of close &quot;matches to map&quot;/&quot;total matches&quot;
    // &quot;total matches = matches to map + visual odometry matches&quot;
    // Visual odometry matches will become MapPoints if we insert a keyframe.
    // This ratio measures how many MapPoints we could create if we insert a keyframe.
    int nMap = 0;
    int nTotal= 0;
    if(mSensor!=System::MONOCULAR)
    {
        for(int i =0; i&lt;mCurrentFrame.N; i++)
        {
            if(mCurrentFrame.mvDepth[i]&gt;0 &amp;&amp; mCurrentFrame.mvDepth[i]&lt;mThDepth)
            {
                nTotal++;
                if(mCurrentFrame.mvpMapPoints[i])
                    if(mCurrentFrame.mvpMapPoints[i]-&gt;Observations()&gt;0)
                        nMap++;
            }
        }
    }
    else
    {
        // There are no visual odometry matches in the monocular case
        nMap=1;
        nTotal=1;
    }

    const float ratioMap = (float)nMap/fmax(1.0f,nTotal);

    // Thresholds
    float thRefRatio = 0.75f;
    if(nKFs&lt;2)
        thRefRatio = 0.4f;

    if(mSensor==System::MONOCULAR)
        thRefRatio = 0.9f;

    float thMapRatio = 0.35f;
    if(mnMatchesInliers&gt;300)
        thMapRatio = 0.20f;

    // Condition 1a: More than &quot;MaxFrames&quot; have passed from last keyframe insertion
    const bool c1a = mCurrentFrame.mnId&gt;=mnLastKeyFrameId+mMaxFrames;
    // Condition 1b: More than &quot;MinFrames&quot; have passed and Local Mapping is idle
    const bool c1b = (mCurrentFrame.mnId&gt;=mnLastKeyFrameId+mMinFrames &amp;&amp; bLocalMappingIdle);
    //Condition 1c: tracking is weak
    const bool c1c =  mSensor!=System::MONOCULAR &amp;&amp; (mnMatchesInliers&lt;nRefMatches*0.25 || ratioMap&lt;0.3f) ;
    // Condition 2: Few tracked points compared to reference keyframe. Lots of visual odometry compared to map matches.
    const bool c2 = ((mnMatchesInliers&lt;nRefMatches*thRefRatio|| ratioMap&lt;thMapRatio) &amp;&amp; mnMatchesInliers&gt;15);
//    const bool c2 = mnMatchesInliers&lt;nRefMatches*0.78 and mnMatchesInliers&gt;15;

//    cout &lt;&lt; &quot;KF Need: &quot; &lt;&lt; (int)c1a &lt;&lt; &quot; &quot; &lt;&lt; (int)c1b &lt;&lt; &quot; &quot; &lt;&lt; (int)c2 &lt;&lt; endl;

    if((c1a||c1b||c1c)&amp;&amp;c2)
    {
        // If the mapping accepts keyframes, insert keyframe.
        // Otherwise send a signal to interrupt BA
        if(bLocalMappingIdle)
        {
            return true;
        }
        else
        {
            mpLocalMapper-&gt;InterruptBA();
            if(mSensor!=System::MONOCULAR)
            {
                if(mpLocalMapper-&gt;KeyframesInQueue()&lt;3)
                    return true;
                else
                    return false;
            }
            else
                return false;
        }
    }
    else
        return false;
}

void Tracking::CreateNewKeyFrame()
{
    if(!mpLocalMapper-&gt;SetNotStop(true))
        return;

    KeyFrame* pKF = new KeyFrame(mCurrentFrame,mpMap,mpKeyFrameDB);

    mpReferenceKF = pKF;
    mCurrentFrame.mpReferenceKF = pKF;

    if(mSensor!=System::MONOCULAR)
    {
        mCurrentFrame.UpdatePoseMatrices();

        // We sort points by the measured depth by the stereo/RGBD sensor.
        // We create all those MapPoints whose depth &lt; mThDepth.
        // If there are less than 100 close points we create the 100 closest.
        vector&lt;pair&lt;float,int&gt; &gt; vDepthIdx;
        vDepthIdx.reserve(mCurrentFrame.N);
        for(int i=0; i&lt;mCurrentFrame.N; i++)
        {
            float z = mCurrentFrame.mvDepth[i];
            if(z&gt;0)
            {
                vDepthIdx.push_back(make_pair(z,i));
            }
        }

        if(!vDepthIdx.empty())
        {
            sort(vDepthIdx.begin(),vDepthIdx.end());

            int nPoints = 0;
            for(size_t j=0; j&lt;vDepthIdx.size();j++)
            {
                int i = vDepthIdx[j].second;

                bool bCreateNew = false;

                MapPoint* pMP = mCurrentFrame.mvpMapPoints[i];
                if(!pMP)
                    bCreateNew = true;
                else if(pMP-&gt;Observations()&lt;1)
                {
                    bCreateNew = true;
                    mCurrentFrame.mvpMapPoints[i] = static_cast&lt;MapPoint*&gt;(NULL);
                }

                if(bCreateNew)
                {
                    cv::Mat x3D = mCurrentFrame.UnprojectStereo(i);
                    MapPoint* pNewMP = new MapPoint(x3D,pKF,mpMap);
                    pNewMP-&gt;AddObservation(pKF,i);
                    pKF-&gt;AddMapPoint(pNewMP,i);
                    pNewMP-&gt;ComputeDistinctiveDescriptors();
                    pNewMP-&gt;UpdateNormalAndDepth();
                    mpMap-&gt;AddMapPoint(pNewMP);

                    mCurrentFrame.mvpMapPoints[i]=pNewMP;
                    nPoints++;
                }
                else
                {
                    nPoints++;
                }

                if(vDepthIdx[j].first&gt;mThDepth &amp;&amp; nPoints&gt;100)
                    break;
            }
        }
    }

    mpLocalMapper-&gt;InsertKeyFrame(pKF);

    mpLocalMapper-&gt;SetNotStop(false);

    mnLastKeyFrameId = mCurrentFrame.mnId;
    mpLastKeyFrame = pKF;
}

void Tracking::SearchLocalPoints()
{
    // Do not search map points already matched
    for(vector&lt;MapPoint*&gt;::iterator vit=mCurrentFrame.mvpMapPoints.begin(), vend=mCurrentFrame.mvpMapPoints.end(); vit!=vend; vit++)
    {
        MapPoint* pMP = *vit;
        if(pMP)
        {
            if(pMP-&gt;isBad())
            {
                *vit = static_cast&lt;MapPoint*&gt;(NULL);
            }
            else
            {
                pMP-&gt;IncreaseVisible();
                pMP-&gt;mnLastFrameSeen = mCurrentFrame.mnId;
                pMP-&gt;mbTrackInView = false;
            }
        }
    }

    int nToMatch=0;

    // Project points in frame and check its visibility
    for(vector&lt;MapPoint*&gt;::iterator vit=mvpLocalMapPoints.begin(), vend=mvpLocalMapPoints.end(); vit!=vend; vit++)
    {
        MapPoint* pMP = *vit;
        if(pMP-&gt;mnLastFrameSeen == mCurrentFrame.mnId)
            continue;
        if(pMP-&gt;isBad())
            continue;
        // Project (this fills MapPoint variables for matching)
        if(mCurrentFrame.isInFrustum(pMP,0.5))
        {
            pMP-&gt;IncreaseVisible();
            nToMatch++;
        }
    }

    if(nToMatch&gt;0)
    {
        ORBmatcher matcher(0.8);
        int th = 1;
        if(mSensor==System::RGBD)
            th=3;
        // If the camera has been relocalised recently, perform a coarser search
        if(mCurrentFrame.mnId&lt;mnLastRelocFrameId+2)
            th=5;
        matcher.SearchByProjection(mCurrentFrame,mvpLocalMapPoints,th);
    }
}

void Tracking::UpdateLocalMap()
{
    // This is for visualization
    mpMap-&gt;SetReferenceMapPoints(mvpLocalMapPoints);

    // Update
    UpdateLocalKeyFrames();
    UpdateLocalPoints();
}

void Tracking::UpdateLocalPoints()
{
    mvpLocalMapPoints.clear();

    for(vector&lt;KeyFrame*&gt;::const_iterator itKF=mvpLocalKeyFrames.begin(), itEndKF=mvpLocalKeyFrames.end(); itKF!=itEndKF; itKF++)
    {
        KeyFrame* pKF = *itKF;
        const vector&lt;MapPoint*&gt; vpMPs = pKF-&gt;GetMapPointMatches();

        for(vector&lt;MapPoint*&gt;::const_iterator itMP=vpMPs.begin(), itEndMP=vpMPs.end(); itMP!=itEndMP; itMP++)
        {
            MapPoint* pMP = *itMP;
            if(!pMP)
                continue;
            if(pMP-&gt;mnTrackReferenceForFrame==mCurrentFrame.mnId)
                continue;
            if(!pMP-&gt;isBad())
            {
                mvpLocalMapPoints.push_back(pMP);
                pMP-&gt;mnTrackReferenceForFrame=mCurrentFrame.mnId;
            }
        }
    }
}


void Tracking::UpdateLocalKeyFrames()
{
    // Each map point vote for the keyframes in which it has been observed
    map&lt;KeyFrame*,int&gt; keyframeCounter;
    for(int i=0; i&lt;mCurrentFrame.N; i++)
    {
        if(mCurrentFrame.mvpMapPoints[i])
        {
            MapPoint* pMP = mCurrentFrame.mvpMapPoints[i];
            if(!pMP-&gt;isBad())
            {
                const map&lt;KeyFrame*,size_t&gt; observations = pMP-&gt;GetObservations();
                for(map&lt;KeyFrame*,size_t&gt;::const_iterator it=observations.begin(), itend=observations.end(); it!=itend; it++)
                    keyframeCounter[it-&gt;first]++;
            }
            else
            {
                mCurrentFrame.mvpMapPoints[i]=NULL;
            }
        }
    }

    if(keyframeCounter.empty())
        return;

    int max=0;
    KeyFrame* pKFmax= static_cast&lt;KeyFrame*&gt;(NULL);

    mvpLocalKeyFrames.clear();
    mvpLocalKeyFrames.reserve(3*keyframeCounter.size());

    // All keyframes that observe a map point are included in the local map. Also check which keyframe shares most points
    for(map&lt;KeyFrame*,int&gt;::const_iterator it=keyframeCounter.begin(), itEnd=keyframeCounter.end(); it!=itEnd; it++)
    {
        KeyFrame* pKF = it-&gt;first;

        if(pKF==NULL || pKF-&gt;isBad())
            continue;

        if(it-&gt;second&gt;max)
        {
            max=it-&gt;second;
            pKFmax=pKF;
        }

        mvpLocalKeyFrames.push_back(it-&gt;first);
        pKF-&gt;mnTrackReferenceForFrame = mCurrentFrame.mnId;
    }


    // Include also some not-already-included keyframes that are neighbors to already-included keyframes
    for(vector&lt;KeyFrame*&gt;::const_iterator itKF=mvpLocalKeyFrames.begin(), itEndKF=mvpLocalKeyFrames.end(); itKF!=itEndKF; itKF++)
    {
        // Limit the number of keyframes
        if(mvpLocalKeyFrames.size()&gt;80)
            break;

        KeyFrame* pKF = *itKF;

        const vector&lt;KeyFrame*&gt; vNeighs = pKF-&gt;GetBestCovisibilityKeyFrames(10);

        for(vector&lt;KeyFrame*&gt;::const_iterator itNeighKF=vNeighs.begin(), itEndNeighKF=vNeighs.end(); itNeighKF!=itEndNeighKF; itNeighKF++)
        {
            KeyFrame* pNeighKF = *itNeighKF;
            if(!pNeighKF-&gt;isBad())
            {
                if(pNeighKF-&gt;mnTrackReferenceForFrame!=mCurrentFrame.mnId)
                {
                    mvpLocalKeyFrames.push_back(pNeighKF);
                    pNeighKF-&gt;mnTrackReferenceForFrame=mCurrentFrame.mnId;
                    break;
                }
            }
        }

        const set&lt;KeyFrame*&gt; spChilds = pKF-&gt;GetChilds();
        for(set&lt;KeyFrame*&gt;::const_iterator sit=spChilds.begin(), send=spChilds.end(); sit!=send; sit++)
        {
            KeyFrame* pChildKF = *sit;
            if(!pChildKF-&gt;isBad())
            {
                if(pChildKF-&gt;mnTrackReferenceForFrame!=mCurrentFrame.mnId)
                {
                    mvpLocalKeyFrames.push_back(pChildKF);
                    pChildKF-&gt;mnTrackReferenceForFrame=mCurrentFrame.mnId;
                    break;
                }
            }
        }

        KeyFrame* pParent = pKF-&gt;GetParent();
        if(pParent)
        {
            if(pParent-&gt;mnTrackReferenceForFrame!=mCurrentFrame.mnId)
            {
                mvpLocalKeyFrames.push_back(pParent);
                pParent-&gt;mnTrackReferenceForFrame=mCurrentFrame.mnId;
                break;
            }
        }

    }

    if(pKFmax)
    {
        mpReferenceKF = pKFmax;
        mCurrentFrame.mpReferenceKF = mpReferenceKF;
    }
}

bool Tracking::Relocalization()
{
#ifdef DEBUG_TRACKING
//	cout &lt;&lt; &quot;Tracking Mode: Relocalization()&quot; &lt;&lt; endl;
	lastTrackingMode = RELOCALIZATION;
#endif

    // Compute Bag of Words Vector
    mCurrentFrame.ComputeBoW();

    // Relocalization is performed when tracking is lost
    // Track Lost: Query KeyFrame Database for keyframe candidates for relocalisation
    vector&lt;KeyFrame*&gt; vpCandidateKFs = mpKeyFrameDB-&gt;DetectRelocalizationCandidates(&amp;mCurrentFrame);

    if(vpCandidateKFs.empty())
        return false;

    const int nKFs = vpCandidateKFs.size();

    // We perform first an ORB matching with each candidate
    // If enough matches are found we setup a PnP solver
    ORBmatcher matcher(0.75,true);

    vector&lt;PnPsolver*&gt; vpPnPsolvers;
    vpPnPsolvers.resize(nKFs);

    vector&lt;vector&lt;MapPoint*&gt; &gt; vvpMapPointMatches;
    vvpMapPointMatches.resize(nKFs);

    vector&lt;bool&gt; vbDiscarded;
    vbDiscarded.resize(nKFs);

    int nCandidates=0;

    for(int i=0; i&lt;nKFs; i++)
    {
        KeyFrame* pKF = vpCandidateKFs[i];
        if(pKF-&gt;isBad())
            vbDiscarded[i] = true;
        else
        {
            int nmatches = matcher.SearchByBoW(pKF,mCurrentFrame,vvpMapPointMatches[i]);
            if(nmatches&lt;15)
            {
                vbDiscarded[i] = true;
                continue;
            }
            else
            {
                PnPsolver* pSolver = new PnPsolver(mCurrentFrame,vvpMapPointMatches[i]);
                pSolver-&gt;SetRansacParameters(0.99,10,300,4,0.5,5.991);
                vpPnPsolvers[i] = pSolver;
                nCandidates++;
            }
        }
    }

    // Alternatively perform some iterations of P4P RANSAC
    // Until we found a camera pose supported by enough inliers
    bool bMatch = false;
    ORBmatcher matcher2(0.9,true);

    while(nCandidates&gt;0 &amp;&amp; !bMatch)
    {
        for(int i=0; i&lt;nKFs; i++)
        {
            if(vbDiscarded[i])
                continue;

            // Perform 5 Ransac Iterations
            vector&lt;bool&gt; vbInliers;
            int nInliers;
            bool bNoMore;

            PnPsolver* pSolver = vpPnPsolvers[i];
            cv::Mat Tcw = pSolver-&gt;iterate(5,bNoMore,vbInliers,nInliers);

            // If Ransac reachs max. iterations discard keyframe
            if(bNoMore)
            {
                vbDiscarded[i]=true;
                nCandidates--;
            }

            // If a Camera Pose is computed, optimize
            if(!Tcw.empty())
            {
                Tcw.copyTo(mCurrentFrame.mTcw);

                set&lt;MapPoint*&gt; sFound;

                const int np = vbInliers.size();

                for(int j=0; j&lt;np; j++)
                {
                    if(vbInliers[j])
                    {
                        mCurrentFrame.mvpMapPoints[j]=vvpMapPointMatches[i][j];
                        sFound.insert(vvpMapPointMatches[i][j]);
                    }
                    else
                        mCurrentFrame.mvpMapPoints[j]=NULL;
                }

                int nGood = Optimizer::PoseOptimization(&amp;mCurrentFrame);

                if(nGood&lt;10)
                    continue;

                for(int io =0; io&lt;mCurrentFrame.N; io++)
                    if(mCurrentFrame.mvbOutlier[io])
                        mCurrentFrame.mvpMapPoints[io]=static_cast&lt;MapPoint*&gt;(NULL);

                // If few inliers, search by projection in a coarse window and optimize again
                if(nGood&lt;50)
                {
                    int nadditional =matcher2.SearchByProjection(mCurrentFrame,vpCandidateKFs[i],sFound,10,100);

                    if(nadditional+nGood&gt;=50)
                    {
                        nGood = Optimizer::PoseOptimization(&amp;mCurrentFrame);

                        // If many inliers but still not enough, search by projection again in a narrower window
                        // the camera has been already optimized with many points
                        if(nGood&gt;30 &amp;&amp; nGood&lt;50)
                        {
                            sFound.clear();
                            for(int ip =0; ip&lt;mCurrentFrame.N; ip++)
                                if(mCurrentFrame.mvpMapPoints[ip])
                                    sFound.insert(mCurrentFrame.mvpMapPoints[ip]);
                            nadditional =matcher2.SearchByProjection(mCurrentFrame,vpCandidateKFs[i],sFound,3,64);

                            // Final optimization
                            if(nGood+nadditional&gt;=50)
                            {
                                nGood = Optimizer::PoseOptimization(&amp;mCurrentFrame);

                                for(int io =0; io&lt;mCurrentFrame.N; io++)
                                    if(mCurrentFrame.mvbOutlier[io])
                                        mCurrentFrame.mvpMapPoints[io]=NULL;
                            }
                        }
                    }
                }


                // If the pose is supported by enough inliers stop ransacs and continue
                if(nGood&gt;=50)
                {
                    bMatch = true;
//                    cout &lt;&lt; &quot;Relocalization successful&quot; &lt;&lt; endl;
//                    mpReferenceKF = vpCandidateKFs[i];
                    break;
                }
            }
        }
    }

    if(!bMatch)
    {
        return false;
    }
    else
    {
        mnLastRelocFrameId = mCurrentFrame.mnId;
        return true;
    }

}

void Tracking::Reset()
{
    mpViewer-&gt;RequestStop();

    cout &lt;&lt; &quot;System Reseting&quot; &lt;&lt; endl;
    while(!mpViewer-&gt;isStopped())
        usleep(3000);

	// Reset Local Mapping
	cout &lt;&lt; &quot;Reseting Local Mapper...&quot;;
	mpLocalMapper-&gt;RequestReset();
	cout &lt;&lt; &quot; done&quot; &lt;&lt; endl;

	// Reset Loop Closing
	cout &lt;&lt; &quot;Reseting Loop Closing...&quot;;
	mpLoopClosing-&gt;RequestReset();
	cout &lt;&lt; &quot; done&quot; &lt;&lt; endl;


    // Clear BoW Database
    cout &lt;&lt; &quot;Reseting Database...&quot;;
    mpKeyFrameDB-&gt;clear();
    cout &lt;&lt; &quot; done&quot; &lt;&lt; endl;

    // Clear Map (this erase MapPoints and KeyFrames)
    mpMap-&gt;clear();

    KeyFrame::nNextId = 0;
    Frame::nNextId = 0;
    mState = NO_IMAGES_YET;

    if(mpInitializer)
    {
        delete mpInitializer;
        mpInitializer = static_cast&lt;Initializer*&gt;(NULL);
    }

    mlRelativeFramePoses.clear();
    mlpReferences.clear();
    mlFrameTimes.clear();
    mlbLost.clear();

    mpViewer-&gt;Release();
}

void Tracking::ChangeCalibration(const string &amp;strSettingPath)
{
    cv::FileStorage fSettings(strSettingPath, cv::FileStorage::READ);
    float fx = fSettings[&quot;Camera.fx&quot;];
    float fy = fSettings[&quot;Camera.fy&quot;];
    float cx = fSettings[&quot;Camera.cx&quot;];
    float cy = fSettings[&quot;Camera.cy&quot;];

    cv::Mat K = cv::Mat::eye(3,3,CV_32F);
    K.at&lt;float&gt;(0,0) = fx;
    K.at&lt;float&gt;(1,1) = fy;
    K.at&lt;float&gt;(0,2) = cx;
    K.at&lt;float&gt;(1,2) = cy;
    K.copyTo(mK);

    cv::Mat DistCoef(4,1,CV_32F);
    DistCoef.at&lt;float&gt;(0) = fSettings[&quot;Camera.k1&quot;];
    DistCoef.at&lt;float&gt;(1) = fSettings[&quot;Camera.k2&quot;];
    DistCoef.at&lt;float&gt;(2) = fSettings[&quot;Camera.p1&quot;];
    DistCoef.at&lt;float&gt;(3) = fSettings[&quot;Camera.p2&quot;];
    const float k3 = fSettings[&quot;Camera.k3&quot;];
    if(k3!=0)
    {
        DistCoef.resize(5);
        DistCoef.at&lt;float&gt;(4) = k3;
    }
    DistCoef.copyTo(mDistCoef);

    mbf = fSettings[&quot;Camera.bf&quot;];

    Frame::mbInitialComputations = true;
}


void Tracking::ChangeCalibration(const double fx, const double fy, const double cx, const double cy)
{
    cv::Mat K = cv::Mat::eye(3,3,CV_32F);
    K.at&lt;float&gt;(0,0) = fx;
    K.at&lt;float&gt;(1,1) = fy;
    K.at&lt;float&gt;(0,2) = cx;
    K.at&lt;float&gt;(1,2) = cy;
    K.copyTo(mK);
    printf (&quot;IntrinsicMatrix changed to %f,%f,%f,%f\n&quot;, fx, fy, cx, cy);
}


void Tracking::InformOnlyTracking(const bool &amp;flag)
{
    mbOnlyTracking = flag;
}



} //namespace ORB_SLAM
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/ImageGrabber.cc" new_path="">
				<diff>@@ -1,473 +0,0 @@
-/*
- * ImageGrabber.cc
- *
- *  Created on: May 31, 2016
- *      Author: sujiwo
- */
-
-#include &quot;../__nodes/ImageGrabber.h&quot;
-
-#include &lt;std_msgs/UInt32.h&gt;
-#include &lt;std_msgs/Float64.h&gt;
-
-#include &quot;boost/date_time/posix_time/posix_time.hpp&quot;
-
-
-using namespace std;
-using namespace boost::posix_time;
-
-using ORB_SLAM2::Frame;
-namespace enc = sensor_msgs::image_encodings;
-
-
-// define debugging topics to broadcast to
-const char
-	*framebufferDebugTopic		=	&quot;/orbslamdebug/framebuffer&quot;,
-	*internalTopic				=	&quot;/orbslamdebug&quot;;
-
-
-void tf2positiondirection (const tf::Transform &amp;pose, float positiondirection[6])
-{
-	// position
-	positiondirection[0] = pose.getOrigin().x();
-	positiondirection[1] = pose.getOrigin().y();
-	positiondirection[2] = pose.getOrigin().z();
-	float fdirx = pose.getRotation().x(),
-		fdiry = pose.getRotation().y(),
-		fdirz = pose.getRotation().z(),
-		fdirnorm;
-	fdirnorm = sqrtf(fdirx*fdirx + fdiry*fdiry + fdirz*fdirz);
-	fdirx /= fdirnorm;
-	fdiry /= fdirnorm;
-	fdirz /= fdirnorm;
-	positiondirection[3] = fdirx;
-	positiondirection[4] = fdiry;
-	positiondirection[5] = fdirz;
-}
-
-
-ImageGrabber::ImageGrabber(ORB_SLAM2::System* pSLAM, ros::NodeHandle *nh, bool runOffline) :
-	mpSLAM(pSLAM),
-	rosNode (nh),
-	doStop (false),
-	doDebayer (false),
-	offlineMode (runOffline),
-	mTfBr (NULL),
-	extListener (NULL),
-	imageTransport (NULL)
-{
-	// External localization
-	extFrame1 = (string)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.frame1&quot;];
-	extFrame2 = (string)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.frame2&quot;];
-	cout &lt;&lt; &quot;External Reference: from &quot; &lt;&lt; extFrame1 &lt;&lt; &quot; to &quot; &lt;&lt; extFrame2 &lt;&lt; endl;
-
-	offsetKeyframe = (int)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.OffsetKeyframes&quot;];
-
-	// Initialize TF
-	if (offlineMode==false) {
-		tf::Transform tfT;
-		tfT.setIdentity();
-		mTfBr = new tf::TransformBroadcaster();
-
-		mTfBr-&gt;sendTransform(tf::StampedTransform(tfT,ros::Time::now(), &quot;/ORB_SLAM/World&quot;, &quot;/ORB_SLAM/Camera&quot;));
-	}
-
-	// start of debug preparation
-
-	cout &lt;&lt; std::fixed &lt;&lt; setprecision(7);
-
-	if (pSLAM-&gt;opMode==ORB_SLAM2::System::LOCALIZATION) {
-		imageTransport = new image_transport::ImageTransport (*rosNode);
-		visualDebugView = imageTransport-&gt;advertise(framebufferDebugTopic, 1);
-		debugMsgPublisher = rosNode-&gt;advertise&lt;orb_localizer::debug&gt; (internalTopic, 1);
-	}
-}
-
-
-ImageGrabber::~ImageGrabber()
-{
-	if (mTfBr != NULL)
-		delete (mTfBr);
-	if (extListener != NULL)
-		delete (extListener);
-	if (imageTransport != NULL)
-		delete (imageTransport);
-
-//	debugBag.close();
-}
-
-
-void ImageGrabber::GrabImage(const sensor_msgs::ImageConstPtr&amp; msg)
-{
-	// Activate this timer if you need time logging
-	ptime rT1, rT2;
-	rT1 = microsec_clock::local_time();
-
-	// Copy the ros image message to cv::Mat.
-	cv_bridge::CvImageConstPtr cv_ptr;
-	try
-	{
-		cv_ptr = cv_bridge::toCvShare(msg);
-	}
-	catch (cv_bridge::Exception&amp; e)
-	{
-		ROS_ERROR(&quot;cv_bridge exception: %s&quot;, e.what());
-		return;
-	}
-
-	cv::Mat image;
-	// Check if we need debayering
-	if (enc::isBayer(msg-&gt;encoding)) {
-		int code=-1;
-		if (msg-&gt;encoding == enc::BAYER_RGGB8 ||
-			msg-&gt;encoding == enc::BAYER_RGGB16) {
-//			cout &lt;&lt; &quot;BGR2BGR&quot; &lt;&lt; endl;
-			code = cv::COLOR_BayerBG2BGR;
-		}
-		else if (msg-&gt;encoding == enc::BAYER_BGGR8 ||
-				 msg-&gt;encoding == enc::BAYER_BGGR16) {
-			code = cv::COLOR_BayerRG2BGR;
-		}
-		else if (msg-&gt;encoding == enc::BAYER_GBRG8 ||
-				 msg-&gt;encoding == enc::BAYER_GBRG16) {
-			code = cv::COLOR_BayerGR2BGR;
-		}
-		else if (msg-&gt;encoding == enc::BAYER_GRBG8 ||
-				 msg-&gt;encoding == enc::BAYER_GRBG16) {
-			code = cv::COLOR_BayerGB2BGR;
-		}
-		cv::cvtColor(cv_ptr-&gt;image, image, code);
-	}
-	else
-		image = cv_ptr-&gt;image;
-
-	const double imageTime = msg-&gt;header.stamp.toSec();
-	lastImageTimestamp = imageTime;
-
-	// Do Resizing and cropping here
-	cv::resize(image, image,
-		cv::Size(
-			(int)mpSLAM-&gt;fsSettings[&quot;Camera.WorkingResolution.Width&quot;],
-			(int)mpSLAM-&gt;fsSettings[&quot;Camera.WorkingResolution.Height&quot;]
-		));
-	image = image(
-		cv::Rect(
-			(int)mpSLAM-&gt;fsSettings[&quot;Camera.ROI.x0&quot;],
-			(int)mpSLAM-&gt;fsSettings[&quot;Camera.ROI.y0&quot;],
-			(int)mpSLAM-&gt;fsSettings[&quot;Camera.ROI.width&quot;],
-			(int)mpSLAM-&gt;fsSettings[&quot;Camera.ROI.height&quot;]
-		)).clone();
-
-	cv::Mat tmpRs = mpSLAM-&gt;TrackMonocular(image, imageTime);
-
-	// Reinsert TF publisher, but only for localization. Original ORB-SLAM2 removes it.
-	bool tfOk = false;
-	tf::Transform locRef;
-
-	tf::StampedTransform tfMsg;
-	tfMsg.stamp_ = ros::Time(imageTime);
-	tfMsg.frame_id_ = (string)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.frame1&quot;];
-	tfMsg.child_frame_id_ = (string)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.frame2&quot;];
-
-	Frame &amp;cframe = mpSLAM-&gt;getTracker()-&gt;mCurrentFrame;
-	if (mpSLAM-&gt;opMode==ORB_SLAM2::System::LOCALIZATION and
-		mpSLAM-&gt;getTracker()-&gt;trackingIsGood() and
-		offlineMode == false
-	) {
-
-//		cout &lt;&lt; &quot;Got Tracking: Client&quot; &lt;&lt; endl;
-//		cout &lt;&lt; tmpRs &lt;&lt; endl &lt;&lt; &quot;XXX\n&quot;;
-
-		tf::Transform tfTcw = FramePose(&amp;cframe);
-		mTfBr-&gt;sendTransform(tf::StampedTransform(tfTcw, ros::Time(imageTime), &quot;/ORB_SLAM/World&quot;, &quot;/ORB_SLAM/Camera&quot;));
-
-//		 Here, we use offset of external localization from the keyframe
-		if (mpSLAM-&gt;getTracker()-&gt;mbOnlyTracking==true) {
-//			ORB_SLAM2::KeyFrame *kfRef = cframe.mpReferenceKF;
-			try {
-				locRef = localizeByReference(tfTcw);
-				tfMsg.setData(locRef);
-				mTfBr-&gt;sendTransform(tfMsg);
-				tfOk = true;
-			} catch (...) {}
-		}
-
-	} else {
-//		cout &lt;&lt; &quot;Got Lost&quot; &lt;&lt; endl;
-	}
-
-	rT2 = microsec_clock::local_time();
-	cputimeDebug = (rT2-rT1).total_microseconds() * 1e-6;
-
-	publishDebug();
-}
-
-
-void ImageGrabber::publishDebug ()
-{
-	if (mpSLAM-&gt;opMode==ORB_SLAM2::System::LOCALIZATION) {
-		mpSLAM-&gt;getFrameDrawer()-&gt;DrawFrame();
-		framebufferDebug = mpSLAM-&gt;getFrameDrawer()-&gt;getLastFrame();
-
-		cv_bridge::CvImage bagImage;
-		bagImage.image = framebufferDebug;
-		bagImage.header.stamp = ros::Time(lastImageTimestamp);
-		bagImage.encoding = &quot;bgr8&quot;;
-		visualDebugView.publish(bagImage.toImageMsg());
-
-		orb_localizer::debug internalDebugMsg;
-		internalDebugMsg.header.stamp = ros::Time (lastImageTimestamp);
-		internalDebugMsg.header.frame_id = &quot;ORB_SLAM2&quot;;
-		internalDebugMsg.keyframe_id = lastKeyframeId;
-		internalDebugMsg.cputime = cputimeDebug;
-		internalDebugMsg.tracking = mpSLAM-&gt;getTracker()-&gt;trackingIsGood();
-		debugMsgPublisher.publish (internalDebugMsg);
-	}
-}
-
-
-void ImageGrabber::externalLocalizerGrab()
-{
-	if (extListener==NULL)
-		extListener = new tf::TransformListener ();
-
-	ros::Rate fps((int)mpSLAM-&gt;fsSettings[&quot;Camera.fps&quot;] * 2);
-
-	while (ros::ok()) {
-
-		if (doStop == true)
-			break;
-
-		try {
-
-			extListener-&gt;lookupTransform (extFrame1, extFrame2, ros::Time(0), extPose);
-			unique_lock&lt;mutex&gt; lock(ORB_SLAM2::KeyFrame::extPoseMutex);
-			tfToCV (extPose, ORB_SLAM2::KeyFrame::extEgoPosition, ORB_SLAM2::KeyFrame::extEgoOrientation);
-
-		} catch (tf::TransformException &amp;e) {
-
-			unique_lock&lt;mutex&gt; lock(ORB_SLAM2::KeyFrame::extPoseMutex);
-			ORB_SLAM2::KeyFrame::extEgoPosition.release();
-			ORB_SLAM2::KeyFrame::extEgoOrientation.release();
-
-		}
-
-		fps.sleep();
-	}
-}
-
-
-tf::Transform ImageGrabber::localizeByReference (const tf::Transform &amp;tfOrb, ORB_SLAM2::KeyFrame *kf)
-{
-	lastKeyframeId = kf-&gt;mnId;
-
-	ORB_SLAM2::KeyFrame *kOffset = mpSLAM-&gt;getMap()-&gt;offsetKeyframe(kf, offsetKeyframe);
-	if (kOffset==NULL)
-		throw std::out_of_range(&quot;No offset keyframe found&quot;);
-
-	if (kf-&gt;extPosition.empty() or kOffset-&gt;extPosition.empty())
-		throw std::out_of_range(&quot;External reference of keyframe not found&quot;);
-
-	tf::Transform kfTr = KeyFramePoseToTf(kf);
-	tf::Transform extRef = getKeyFrameExtPose(kf);
-
-	tf::Transform kfTrOffset = KeyFramePoseToTf(kOffset);
-	tf::Transform extRefOffset = getKeyFrameExtPose(kOffset);
-	return localizeByReference (tfOrb, kfTr, kfTrOffset, extRef, extRefOffset);
-}
-
-
-/*
- * Main routine for localization by reference
- */
-tf::Transform ImageGrabber::localizeByReference (
-    	const tf::Transform &amp;tfOrb,
-		const tf::Transform &amp;tfOrbMap, const tf::Transform &amp;tfOrbMapOffset,
-    	const tf::Transform &amp;realMapPose, const tf::Transform &amp;realMapOffset)
-{
-	double offDistO = cv::norm(
-		ImageGrabber::tfToCv(tfOrbMap.getOrigin()) -
-		ImageGrabber::tfToCv(tfOrbMapOffset.getOrigin()));
-	double offDistE = cv::norm(
-		ImageGrabber::tfToCv(realMapPose.getOrigin()) -
-		ImageGrabber::tfToCv(realMapOffset.getOrigin()));
-	double scale = offDistE / offDistO;
-
-	// change orientation from camera to velodyne
-	tf::Transform flipAxes;
-	flipAxes.setOrigin(tf::Vector3(0, 0, 0));
-	tf::Quaternion fpq;
-	fpq.setRPY(M_PI/2,0,0);
-	fpq.normalize();
-	flipAxes.setRotation(fpq);
-//	flipAxes.setRotation (tf::Quaternion(-M_PI/2, M_PI/2, 0).normalize());
-
-	tf::Transform orbRel = tfOrbMap.inverse() * tfOrb;
-
-	tf::Transform scaledRel = orbRel;
-	scaledRel.setOrigin(orbRel.getOrigin() * scale);
-
-	tf::Transform tfResult = realMapPose * scaledRel;
-	return tfResult*flipAxes;
-}
-
-
-tf::Transform ImageGrabber::localizeByReference(const tf::Transform &amp;tfOrb)
-{
-	float fdirx = tfOrb.getRotation().x(),
-		fdiry = tfOrb.getRotation().y(),
-		fdirz = tfOrb.getRotation().z(),
-		fdirnorm;
-	fdirnorm = sqrtf(fdirx*fdirx + fdiry*fdiry + fdirz*fdirz);
-	fdirx /= fdirnorm;
-	fdiry /= fdirnorm;
-	fdirz /= fdirnorm;
-
-	ORB_SLAM2::KeyFrame *kfNear = mpSLAM-&gt;getMap()-&gt;getNearestKeyFrame(
-		tfOrb.getOrigin().x(),
-		tfOrb.getOrigin().y(),
-		tfOrb.getOrigin().z(),
-		fdirx, fdiry, fdirz);
-	if (kfNear==NULL)
-		throw std::out_of_range(&quot;No keyframe found&quot;);
-
-	lastKeyframeId = kfNear-&gt;mnId;
-	return localizeByReference (tfOrb, kfNear);
-}
-
-
-tf::Transform ImageGrabber::localizeByReference(Frame *sframe)
-{
-//	const tf::Transform
-}
-
-
-tf::Transform ImageGrabber::localizeByReference(const tf::Transform &amp;tfOrb, ORB_SLAM2::Map *mapsrc, const int offsetNum)
-{
-	float positiondir[6];
-	tf2positiondirection(tfOrb, positiondir);
-
-	ORB_SLAM2::KeyFrame *kfNear = mapsrc-&gt;getNearestKeyFrame(
-		positiondir[0], positiondir[1], positiondir[2],
-		positiondir[3], positiondir[4], positiondir[5]);
-	if (kfNear==NULL)
-		throw std::out_of_range(&quot;No keyframe found&quot;);
-	ORB_SLAM2::KeyFrame *kOffset = mapsrc-&gt;offsetKeyframe(kfNear, offsetNum);
-	if (kOffset==NULL)
-		throw std::out_of_range(&quot;No offset keyframe found&quot;);
-
-	tf::Transform kfTr = KeyFramePoseToTf(kfNear);
-	tf::Transform extRef = getKeyFrameExtPose(kfNear);
-
-	tf::Transform kfTrOffset = KeyFramePoseToTf(kOffset);
-	tf::Transform extRefOffset = getKeyFrameExtPose(kOffset);
-
-	return localizeByReference (tfOrb, kfTr, kfTrOffset, extRef, extRefOffset);
-}
-
-
-tf2_msgs::TFMessage ImageGrabber::createTfMessage (const tf::Transform &amp;srcTransform,
-	const string &amp;frameSrc, const string &amp;frameTarget,
-	double timestamp=-1)
-{
-	ros::Time msgTime;
-	tf2_msgs::TFMessage tfretval;
-
-	if (timestamp&gt;0)
-		msgTime = ros::Time(timestamp);
-	else msgTime = ros::Time::now();
-
-	geometry_msgs::TransformStamped newTransform;
-	newTransform.header.stamp = msgTime;
-	newTransform.header.frame_id = frameSrc;
-	newTransform.child_frame_id = frameTarget;
-	newTransform.transform.translation.x = srcTransform.getOrigin().x();
-	newTransform.transform.translation.y = srcTransform.getOrigin().y();
-	newTransform.transform.translation.z = srcTransform.getOrigin().z();
-	newTransform.transform.rotation.x = srcTransform.getRotation().x();
-	newTransform.transform.rotation.y = srcTransform.getRotation().y();
-	newTransform.transform.rotation.z = srcTransform.getRotation().z();
-	newTransform.transform.rotation.w = srcTransform.getRotation().w();
-	tfretval.transforms.push_back (newTransform);
-
-	return tfretval;
-}
-
-
-tf::Transform ImageGrabber::getKeyFrameExtPose (const KeyFrame *kf)
-{
-	tf::Transform Ext;
-
-	if (kf-&gt;extPosition.empty() or kf-&gt;extOrientation.empty()) {
-		Ext.setOrigin(tf::Vector3(NAN, NAN, NAN));
-		Ext.setRotation(tf::Quaternion(NAN, NAN, NAN, NAN));
-	}
-
-	else {
-		Ext.setOrigin (tf::Vector3(
-			kf-&gt;extPosition.at&lt;double&gt;(0),
-			kf-&gt;extPosition.at&lt;double&gt;(1),
-			kf-&gt;extPosition.at&lt;double&gt;(2) ));
-		Ext.setRotation(tf::Quaternion(
-			kf-&gt;extOrientation.at&lt;double&gt;(0),
-			kf-&gt;extOrientation.at&lt;double&gt;(1),
-			kf-&gt;extOrientation.at&lt;double&gt;(2),
-			kf-&gt;extOrientation.at&lt;double&gt;(3) ));
-	}
-	return Ext;
-}
-
-
-tf::Transform ImageGrabber::KeyFramePoseToTf (KeyFrame *kf)
-{
-	tf::Transform kfpose;
-
-	cv::Mat t = kf-&gt;GetCameraCenter();
-	cv::Mat orient = kf-&gt;GetRotation().t();
-	vector&lt;float&gt; q = ORB_SLAM2::Converter::toQuaternion(orient);
-
-	kfpose.setOrigin(tf::Vector3(t.at&lt;float&gt;(0), t.at&lt;float&gt;(1), t.at&lt;float&gt;(2)));
-	kfpose.setRotation(tf::Quaternion(q[0], q[1], q[2], q[3]));
-
-	return kfpose;
-}
-
-
-tf::Transform ImageGrabber::FramePose (Frame *cframe)
-{
-	cv::Mat Rwc = cframe-&gt;mTcw.rowRange(0,3).colRange(0,3).t();
-	cv::Mat twc = -Rwc * cframe-&gt;mTcw.rowRange(0,3).col(3);
-	tf::Matrix3x3 M(Rwc.at&lt;float&gt;(0,0),Rwc.at&lt;float&gt;(0,1),Rwc.at&lt;float&gt;(0,2),
-					Rwc.at&lt;float&gt;(1,0),Rwc.at&lt;float&gt;(1,1),Rwc.at&lt;float&gt;(1,2),
-					Rwc.at&lt;float&gt;(2,0),Rwc.at&lt;float&gt;(2,1),Rwc.at&lt;float&gt;(2,2));
-	tf::Vector3 V(twc.at&lt;float&gt;(0), twc.at&lt;float&gt;(1), twc.at&lt;float&gt;(2));
-
-	return tf::Transform(M, V);
-}
-
-
-cv::Vec3d ImageGrabber::tfToCv (const tf::Vector3 &amp;pos)
-{
-	cv::Vec3d cvVec;
-	cvVec[0] = pos.x();
-	cvVec[1] = pos.y();
-	cvVec[2] = pos.z();
-	return cvVec;
-}
-
-
-cv::Mat ImageGrabber::tfToCv (const tf::Transform &amp;tfsrc)
-{
-	cv::Mat rtval = cv::Mat::eye(4,4, CV_32F);
-	rtval.rowRange(0, 3).col(3).at&lt;float&gt;(0) = tfsrc.getOrigin().x();
-	rtval.rowRange(0, 3).col(3).at&lt;float&gt;(1) = tfsrc.getOrigin().y();
-	rtval.rowRange(0, 3).col(3).at&lt;float&gt;(2) = tfsrc.getOrigin().z();
-
-	tf::Matrix3x3 rot (tfsrc.getRotation());
-	for (int i=0; i&lt;3; i++) {
-		for (int j=0; j&lt;3; j++) {
-			rtval.at&lt;float&gt;(i,j) = rot[i][j];
-		}
-	}
-	return rtval;
-}
</diff>
				<old_file>/*
 * ImageGrabber.cc
 *
 *  Created on: May 31, 2016
 *      Author: sujiwo
 */

#include &quot;../__nodes/ImageGrabber.h&quot;

#include &lt;std_msgs/UInt32.h&gt;
#include &lt;std_msgs/Float64.h&gt;

#include &quot;boost/date_time/posix_time/posix_time.hpp&quot;


using namespace std;
using namespace boost::posix_time;

using ORB_SLAM2::Frame;
namespace enc = sensor_msgs::image_encodings;


// define debugging topics to broadcast to
const char
	*framebufferDebugTopic		=	&quot;/orbslamdebug/framebuffer&quot;,
	*internalTopic				=	&quot;/orbslamdebug&quot;;


void tf2positiondirection (const tf::Transform &amp;pose, float positiondirection[6])
{
	// position
	positiondirection[0] = pose.getOrigin().x();
	positiondirection[1] = pose.getOrigin().y();
	positiondirection[2] = pose.getOrigin().z();
	float fdirx = pose.getRotation().x(),
		fdiry = pose.getRotation().y(),
		fdirz = pose.getRotation().z(),
		fdirnorm;
	fdirnorm = sqrtf(fdirx*fdirx + fdiry*fdiry + fdirz*fdirz);
	fdirx /= fdirnorm;
	fdiry /= fdirnorm;
	fdirz /= fdirnorm;
	positiondirection[3] = fdirx;
	positiondirection[4] = fdiry;
	positiondirection[5] = fdirz;
}


ImageGrabber::ImageGrabber(ORB_SLAM2::System* pSLAM, ros::NodeHandle *nh, bool runOffline) :
	mpSLAM(pSLAM),
	rosNode (nh),
	doStop (false),
	doDebayer (false),
	offlineMode (runOffline),
	mTfBr (NULL),
	extListener (NULL),
	imageTransport (NULL)
{
	// External localization
	extFrame1 = (string)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.frame1&quot;];
	extFrame2 = (string)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.frame2&quot;];
	cout &lt;&lt; &quot;External Reference: from &quot; &lt;&lt; extFrame1 &lt;&lt; &quot; to &quot; &lt;&lt; extFrame2 &lt;&lt; endl;

	offsetKeyframe = (int)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.OffsetKeyframes&quot;];

	// Initialize TF
	if (offlineMode==false) {
		tf::Transform tfT;
		tfT.setIdentity();
		mTfBr = new tf::TransformBroadcaster();

		mTfBr-&gt;sendTransform(tf::StampedTransform(tfT,ros::Time::now(), &quot;/ORB_SLAM/World&quot;, &quot;/ORB_SLAM/Camera&quot;));
	}

	// start of debug preparation

	cout &lt;&lt; std::fixed &lt;&lt; setprecision(7);

	if (pSLAM-&gt;opMode==ORB_SLAM2::System::LOCALIZATION) {
		imageTransport = new image_transport::ImageTransport (*rosNode);
		visualDebugView = imageTransport-&gt;advertise(framebufferDebugTopic, 1);
		debugMsgPublisher = rosNode-&gt;advertise&lt;orb_localizer::debug&gt; (internalTopic, 1);
	}
}


ImageGrabber::~ImageGrabber()
{
	if (mTfBr != NULL)
		delete (mTfBr);
	if (extListener != NULL)
		delete (extListener);
	if (imageTransport != NULL)
		delete (imageTransport);

//	debugBag.close();
}


void ImageGrabber::GrabImage(const sensor_msgs::ImageConstPtr&amp; msg)
{
	// Activate this timer if you need time logging
	ptime rT1, rT2;
	rT1 = microsec_clock::local_time();

	// Copy the ros image message to cv::Mat.
	cv_bridge::CvImageConstPtr cv_ptr;
	try
	{
		cv_ptr = cv_bridge::toCvShare(msg);
	}
	catch (cv_bridge::Exception&amp; e)
	{
		ROS_ERROR(&quot;cv_bridge exception: %s&quot;, e.what());
		return;
	}

	cv::Mat image;
	// Check if we need debayering
	if (enc::isBayer(msg-&gt;encoding)) {
		int code=-1;
		if (msg-&gt;encoding == enc::BAYER_RGGB8 ||
			msg-&gt;encoding == enc::BAYER_RGGB16) {
//			cout &lt;&lt; &quot;BGR2BGR&quot; &lt;&lt; endl;
			code = cv::COLOR_BayerBG2BGR;
		}
		else if (msg-&gt;encoding == enc::BAYER_BGGR8 ||
				 msg-&gt;encoding == enc::BAYER_BGGR16) {
			code = cv::COLOR_BayerRG2BGR;
		}
		else if (msg-&gt;encoding == enc::BAYER_GBRG8 ||
				 msg-&gt;encoding == enc::BAYER_GBRG16) {
			code = cv::COLOR_BayerGR2BGR;
		}
		else if (msg-&gt;encoding == enc::BAYER_GRBG8 ||
				 msg-&gt;encoding == enc::BAYER_GRBG16) {
			code = cv::COLOR_BayerGB2BGR;
		}
		cv::cvtColor(cv_ptr-&gt;image, image, code);
	}
	else
		image = cv_ptr-&gt;image;

	const double imageTime = msg-&gt;header.stamp.toSec();
	lastImageTimestamp = imageTime;

	// Do Resizing and cropping here
	cv::resize(image, image,
		cv::Size(
			(int)mpSLAM-&gt;fsSettings[&quot;Camera.WorkingResolution.Width&quot;],
			(int)mpSLAM-&gt;fsSettings[&quot;Camera.WorkingResolution.Height&quot;]
		));
	image = image(
		cv::Rect(
			(int)mpSLAM-&gt;fsSettings[&quot;Camera.ROI.x0&quot;],
			(int)mpSLAM-&gt;fsSettings[&quot;Camera.ROI.y0&quot;],
			(int)mpSLAM-&gt;fsSettings[&quot;Camera.ROI.width&quot;],
			(int)mpSLAM-&gt;fsSettings[&quot;Camera.ROI.height&quot;]
		)).clone();

	cv::Mat tmpRs = mpSLAM-&gt;TrackMonocular(image, imageTime);

	// Reinsert TF publisher, but only for localization. Original ORB-SLAM2 removes it.
	bool tfOk = false;
	tf::Transform locRef;

	tf::StampedTransform tfMsg;
	tfMsg.stamp_ = ros::Time(imageTime);
	tfMsg.frame_id_ = (string)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.frame1&quot;];
	tfMsg.child_frame_id_ = (string)mpSLAM-&gt;fsSettings[&quot;ExternalLocalization.frame2&quot;];

	Frame &amp;cframe = mpSLAM-&gt;getTracker()-&gt;mCurrentFrame;
	if (mpSLAM-&gt;opMode==ORB_SLAM2::System::LOCALIZATION and
		mpSLAM-&gt;getTracker()-&gt;trackingIsGood() and
		offlineMode == false
	) {

//		cout &lt;&lt; &quot;Got Tracking: Client&quot; &lt;&lt; endl;
//		cout &lt;&lt; tmpRs &lt;&lt; endl &lt;&lt; &quot;XXX\n&quot;;

		tf::Transform tfTcw = FramePose(&amp;cframe);
		mTfBr-&gt;sendTransform(tf::StampedTransform(tfTcw, ros::Time(imageTime), &quot;/ORB_SLAM/World&quot;, &quot;/ORB_SLAM/Camera&quot;));

//		 Here, we use offset of external localization from the keyframe
		if (mpSLAM-&gt;getTracker()-&gt;mbOnlyTracking==true) {
//			ORB_SLAM2::KeyFrame *kfRef = cframe.mpReferenceKF;
			try {
				locRef = localizeByReference(tfTcw);
				tfMsg.setData(locRef);
				mTfBr-&gt;sendTransform(tfMsg);
				tfOk = true;
			} catch (...) {}
		}

	} else {
//		cout &lt;&lt; &quot;Got Lost&quot; &lt;&lt; endl;
	}

	rT2 = microsec_clock::local_time();
	cputimeDebug = (rT2-rT1).total_microseconds() * 1e-6;

	publishDebug();
}


void ImageGrabber::publishDebug ()
{
	if (mpSLAM-&gt;opMode==ORB_SLAM2::System::LOCALIZATION) {
		mpSLAM-&gt;getFrameDrawer()-&gt;DrawFrame();
		framebufferDebug = mpSLAM-&gt;getFrameDrawer()-&gt;getLastFrame();

		cv_bridge::CvImage bagImage;
		bagImage.image = framebufferDebug;
		bagImage.header.stamp = ros::Time(lastImageTimestamp);
		bagImage.encoding = &quot;bgr8&quot;;
		visualDebugView.publish(bagImage.toImageMsg());

		orb_localizer::debug internalDebugMsg;
		internalDebugMsg.header.stamp = ros::Time (lastImageTimestamp);
		internalDebugMsg.header.frame_id = &quot;ORB_SLAM2&quot;;
		internalDebugMsg.keyframe_id = lastKeyframeId;
		internalDebugMsg.cputime = cputimeDebug;
		internalDebugMsg.tracking = mpSLAM-&gt;getTracker()-&gt;trackingIsGood();
		debugMsgPublisher.publish (internalDebugMsg);
	}
}


void ImageGrabber::externalLocalizerGrab()
{
	if (extListener==NULL)
		extListener = new tf::TransformListener ();

	ros::Rate fps((int)mpSLAM-&gt;fsSettings[&quot;Camera.fps&quot;] * 2);

	while (ros::ok()) {

		if (doStop == true)
			break;

		try {

			extListener-&gt;lookupTransform (extFrame1, extFrame2, ros::Time(0), extPose);
			unique_lock&lt;mutex&gt; lock(ORB_SLAM2::KeyFrame::extPoseMutex);
			tfToCV (extPose, ORB_SLAM2::KeyFrame::extEgoPosition, ORB_SLAM2::KeyFrame::extEgoOrientation);

		} catch (tf::TransformException &amp;e) {

			unique_lock&lt;mutex&gt; lock(ORB_SLAM2::KeyFrame::extPoseMutex);
			ORB_SLAM2::KeyFrame::extEgoPosition.release();
			ORB_SLAM2::KeyFrame::extEgoOrientation.release();

		}

		fps.sleep();
	}
}


tf::Transform ImageGrabber::localizeByReference (const tf::Transform &amp;tfOrb, ORB_SLAM2::KeyFrame *kf)
{
	lastKeyframeId = kf-&gt;mnId;

	ORB_SLAM2::KeyFrame *kOffset = mpSLAM-&gt;getMap()-&gt;offsetKeyframe(kf, offsetKeyframe);
	if (kOffset==NULL)
		throw std::out_of_range(&quot;No offset keyframe found&quot;);

	if (kf-&gt;extPosition.empty() or kOffset-&gt;extPosition.empty())
		throw std::out_of_range(&quot;External reference of keyframe not found&quot;);

	tf::Transform kfTr = KeyFramePoseToTf(kf);
	tf::Transform extRef = getKeyFrameExtPose(kf);

	tf::Transform kfTrOffset = KeyFramePoseToTf(kOffset);
	tf::Transform extRefOffset = getKeyFrameExtPose(kOffset);
	return localizeByReference (tfOrb, kfTr, kfTrOffset, extRef, extRefOffset);
}


/*
 * Main routine for localization by reference
 */
tf::Transform ImageGrabber::localizeByReference (
    	const tf::Transform &amp;tfOrb,
		const tf::Transform &amp;tfOrbMap, const tf::Transform &amp;tfOrbMapOffset,
    	const tf::Transform &amp;realMapPose, const tf::Transform &amp;realMapOffset)
{
	double offDistO = cv::norm(
		ImageGrabber::tfToCv(tfOrbMap.getOrigin()) -
		ImageGrabber::tfToCv(tfOrbMapOffset.getOrigin()));
	double offDistE = cv::norm(
		ImageGrabber::tfToCv(realMapPose.getOrigin()) -
		ImageGrabber::tfToCv(realMapOffset.getOrigin()));
	double scale = offDistE / offDistO;

	// change orientation from camera to velodyne
	tf::Transform flipAxes;
	flipAxes.setOrigin(tf::Vector3(0, 0, 0));
	tf::Quaternion fpq;
	fpq.setRPY(M_PI/2,0,0);
	fpq.normalize();
	flipAxes.setRotation(fpq);
//	flipAxes.setRotation (tf::Quaternion(-M_PI/2, M_PI/2, 0).normalize());

	tf::Transform orbRel = tfOrbMap.inverse() * tfOrb;

	tf::Transform scaledRel = orbRel;
	scaledRel.setOrigin(orbRel.getOrigin() * scale);

	tf::Transform tfResult = realMapPose * scaledRel;
	return tfResult*flipAxes;
}


tf::Transform ImageGrabber::localizeByReference(const tf::Transform &amp;tfOrb)
{
	float fdirx = tfOrb.getRotation().x(),
		fdiry = tfOrb.getRotation().y(),
		fdirz = tfOrb.getRotation().z(),
		fdirnorm;
	fdirnorm = sqrtf(fdirx*fdirx + fdiry*fdiry + fdirz*fdirz);
	fdirx /= fdirnorm;
	fdiry /= fdirnorm;
	fdirz /= fdirnorm;

	ORB_SLAM2::KeyFrame *kfNear = mpSLAM-&gt;getMap()-&gt;getNearestKeyFrame(
		tfOrb.getOrigin().x(),
		tfOrb.getOrigin().y(),
		tfOrb.getOrigin().z(),
		fdirx, fdiry, fdirz);
	if (kfNear==NULL)
		throw std::out_of_range(&quot;No keyframe found&quot;);

	lastKeyframeId = kfNear-&gt;mnId;
	return localizeByReference (tfOrb, kfNear);
}


tf::Transform ImageGrabber::localizeByReference(Frame *sframe)
{
//	const tf::Transform
}


tf::Transform ImageGrabber::localizeByReference(const tf::Transform &amp;tfOrb, ORB_SLAM2::Map *mapsrc, const int offsetNum)
{
	float positiondir[6];
	tf2positiondirection(tfOrb, positiondir);

	ORB_SLAM2::KeyFrame *kfNear = mapsrc-&gt;getNearestKeyFrame(
		positiondir[0], positiondir[1], positiondir[2],
		positiondir[3], positiondir[4], positiondir[5]);
	if (kfNear==NULL)
		throw std::out_of_range(&quot;No keyframe found&quot;);
	ORB_SLAM2::KeyFrame *kOffset = mapsrc-&gt;offsetKeyframe(kfNear, offsetNum);
	if (kOffset==NULL)
		throw std::out_of_range(&quot;No offset keyframe found&quot;);

	tf::Transform kfTr = KeyFramePoseToTf(kfNear);
	tf::Transform extRef = getKeyFrameExtPose(kfNear);

	tf::Transform kfTrOffset = KeyFramePoseToTf(kOffset);
	tf::Transform extRefOffset = getKeyFrameExtPose(kOffset);

	return localizeByReference (tfOrb, kfTr, kfTrOffset, extRef, extRefOffset);
}


tf2_msgs::TFMessage ImageGrabber::createTfMessage (const tf::Transform &amp;srcTransform,
	const string &amp;frameSrc, const string &amp;frameTarget,
	double timestamp=-1)
{
	ros::Time msgTime;
	tf2_msgs::TFMessage tfretval;

	if (timestamp&gt;0)
		msgTime = ros::Time(timestamp);
	else msgTime = ros::Time::now();

	geometry_msgs::TransformStamped newTransform;
	newTransform.header.stamp = msgTime;
	newTransform.header.frame_id = frameSrc;
	newTransform.child_frame_id = frameTarget;
	newTransform.transform.translation.x = srcTransform.getOrigin().x();
	newTransform.transform.translation.y = srcTransform.getOrigin().y();
	newTransform.transform.translation.z = srcTransform.getOrigin().z();
	newTransform.transform.rotation.x = srcTransform.getRotation().x();
	newTransform.transform.rotation.y = srcTransform.getRotation().y();
	newTransform.transform.rotation.z = srcTransform.getRotation().z();
	newTransform.transform.rotation.w = srcTransform.getRotation().w();
	tfretval.transforms.push_back (newTransform);

	return tfretval;
}


tf::Transform ImageGrabber::getKeyFrameExtPose (const KeyFrame *kf)
{
	tf::Transform Ext;

	if (kf-&gt;extPosition.empty() or kf-&gt;extOrientation.empty()) {
		Ext.setOrigin(tf::Vector3(NAN, NAN, NAN));
		Ext.setRotation(tf::Quaternion(NAN, NAN, NAN, NAN));
	}

	else {
		Ext.setOrigin (tf::Vector3(
			kf-&gt;extPosition.at&lt;double&gt;(0),
			kf-&gt;extPosition.at&lt;double&gt;(1),
			kf-&gt;extPosition.at&lt;double&gt;(2) ));
		Ext.setRotation(tf::Quaternion(
			kf-&gt;extOrientation.at&lt;double&gt;(0),
			kf-&gt;extOrientation.at&lt;double&gt;(1),
			kf-&gt;extOrientation.at&lt;double&gt;(2),
			kf-&gt;extOrientation.at&lt;double&gt;(3) ));
	}
	return Ext;
}


tf::Transform ImageGrabber::KeyFramePoseToTf (KeyFrame *kf)
{
	tf::Transform kfpose;

	cv::Mat t = kf-&gt;GetCameraCenter();
	cv::Mat orient = kf-&gt;GetRotation().t();
	vector&lt;float&gt; q = ORB_SLAM2::Converter::toQuaternion(orient);

	kfpose.setOrigin(tf::Vector3(t.at&lt;float&gt;(0), t.at&lt;float&gt;(1), t.at&lt;float&gt;(2)));
	kfpose.setRotation(tf::Quaternion(q[0], q[1], q[2], q[3]));

	return kfpose;
}


tf::Transform ImageGrabber::FramePose (Frame *cframe)
{
	cv::Mat Rwc = cframe-&gt;mTcw.rowRange(0,3).colRange(0,3).t();
	cv::Mat twc = -Rwc * cframe-&gt;mTcw.rowRange(0,3).col(3);
	tf::Matrix3x3 M(Rwc.at&lt;float&gt;(0,0),Rwc.at&lt;float&gt;(0,1),Rwc.at&lt;float&gt;(0,2),
					Rwc.at&lt;float&gt;(1,0),Rwc.at&lt;float&gt;(1,1),Rwc.at&lt;float&gt;(1,2),
					Rwc.at&lt;float&gt;(2,0),Rwc.at&lt;float&gt;(2,1),Rwc.at&lt;float&gt;(2,2));
	tf::Vector3 V(twc.at&lt;float&gt;(0), twc.at&lt;float&gt;(1), twc.at&lt;float&gt;(2));

	return tf::Transform(M, V);
}


cv::Vec3d ImageGrabber::tfToCv (const tf::Vector3 &amp;pos)
{
	cv::Vec3d cvVec;
	cvVec[0] = pos.x();
	cvVec[1] = pos.y();
	cvVec[2] = pos.z();
	return cvVec;
}


cv::Mat ImageGrabber::tfToCv (const tf::Transform &amp;tfsrc)
{
	cv::Mat rtval = cv::Mat::eye(4,4, CV_32F);
	rtval.rowRange(0, 3).col(3).at&lt;float&gt;(0) = tfsrc.getOrigin().x();
	rtval.rowRange(0, 3).col(3).at&lt;float&gt;(1) = tfsrc.getOrigin().y();
	rtval.rowRange(0, 3).col(3).at&lt;float&gt;(2) = tfsrc.getOrigin().z();

	tf::Matrix3x3 rot (tfsrc.getRotation());
	for (int i=0; i&lt;3; i++) {
		for (int j=0; j&lt;3; j++) {
			rtval.at&lt;float&gt;(i,j) = rot[i][j];
		}
	}
	return rtval;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/ImageGrabber.h" new_path="">
				<diff>@@ -1,104 +0,0 @@
-/*
- * ImageGrabber.h
- *
- *  Created on: May 31, 2016
- *      Author: sujiwo
- */
-
-#ifndef _IMAGEGRABBER_H_
-#define _IMAGEGRABBER_H_
-
-
-#include &lt;string&gt;
-
-
-#include &quot;System.h&quot;
-#include &quot;Map.h&quot;
-#include &quot;Frame.h&quot;
-#include &quot;KeyFrame.h&quot;
-#include &quot;Converter.h&quot;
-#include &lt;ros/ros.h&gt;
-#include &lt;cv_bridge/cv_bridge.h&gt;
-#include &lt;image_transport/image_transport.h&gt;
-#include &lt;sensor_msgs/Image.h&gt;
-#include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;tf/transform_broadcaster.h&gt;
-#include &lt;tf/transform_listener.h&gt;
-#include &lt;thread&gt;
-
-// I Know this is unstable
-#include &lt;tf2_msgs/TFMessage.h&gt;
-#include &lt;orb_localizer/debug.h&gt;
-#include &quot;../__nodes/utils.h&quot;
-
-using namespace std;
-using ORB_SLAM2::KeyFrame;
-using ORB_SLAM2::Frame;
-
-
-class ImageGrabber
-{
-public:
-	ImageGrabber(ORB_SLAM2::System* pSLAM, ros::NodeHandle *nh, bool runOffline=false);
-	~ImageGrabber ();
-
-    void GrabImage(const sensor_msgs::ImageConstPtr&amp; msg);
-
-    // This function runs in separate thread
-    void externalLocalizerGrab ();
-
-    ORB_SLAM2::System* mpSLAM;
-    ros::NodeHandle *rosNode;
-
-    // External localization
-    tf::TransformBroadcaster *mTfBr;
-    tf::TransformListener *extListener;
-    tf::StampedTransform extPose;
-    string extFrame1, extFrame2;
-    bool doStop;
-    bool doDebayer;
-    bool offlineMode;
-    int offsetKeyframe;
-
-
-    tf::Transform localizeByReference (const tf::Transform &amp;tfOrb, KeyFrame *kf);
-    tf::Transform localizeByReference (const tf::Transform &amp;tfOrb);
-    tf::Transform localizeByReference (Frame *sframe);
-
-    static tf::Transform localizeByReference (
-    	const tf::Transform &amp;tfOrb,
-		const tf::Transform &amp;tfOrbMap, const tf::Transform &amp;tfOrbMapOffset,
-    	const tf::Transform &amp;realMapPose, const tf::Transform &amp;realMapOffset);
-
-    static tf::Transform localizeByReference (const tf::Transform &amp;tfOrb, ORB_SLAM2::Map *mapsrc, const int offsetNum);
-
-	static tf::Transform getKeyFrameExtPose (const KeyFrame *kf);
-
-	static tf::Transform KeyFramePoseToTf (KeyFrame *kf);
-
-	static tf::Transform FramePose (Frame *cframe);
-
-	static cv::Vec3d tfToCv (const tf::Vector3 &amp;pos);
-
-	static cv::Mat tfToCv (const tf::Transform &amp;tfsrc);
-
-	// I Know this is unstable
-	static tf2_msgs::TFMessage createTfMessage (const tf::Transform &amp;srcTransform, const string &amp;frameSrc, const string &amp;frameTarget, double timestamp);
-
-
-	// Logging
-	image_transport::ImageTransport *imageTransport;
-	image_transport::Publisher visualDebugView;
-	ros::Publisher debugMsgPublisher;
-
-	cv::Mat framebufferDebug;
-	uint32_t lastKeyframeId;
-	double cputimeDebug;
-	double lastImageTimestamp;
-
-private:
-	void publishDebug ();
-};
-
-
-#endif /* _IMAGEGRABBER_H_ */
</diff>
				<old_file>/*
 * ImageGrabber.h
 *
 *  Created on: May 31, 2016
 *      Author: sujiwo
 */

#ifndef _IMAGEGRABBER_H_
#define _IMAGEGRABBER_H_


#include &lt;string&gt;


#include &quot;System.h&quot;
#include &quot;Map.h&quot;
#include &quot;Frame.h&quot;
#include &quot;KeyFrame.h&quot;
#include &quot;Converter.h&quot;
#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;image_transport/image_transport.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;thread&gt;

// I Know this is unstable
#include &lt;tf2_msgs/TFMessage.h&gt;
#include &lt;orb_localizer/debug.h&gt;
#include &quot;../__nodes/utils.h&quot;

using namespace std;
using ORB_SLAM2::KeyFrame;
using ORB_SLAM2::Frame;


class ImageGrabber
{
public:
	ImageGrabber(ORB_SLAM2::System* pSLAM, ros::NodeHandle *nh, bool runOffline=false);
	~ImageGrabber ();

    void GrabImage(const sensor_msgs::ImageConstPtr&amp; msg);

    // This function runs in separate thread
    void externalLocalizerGrab ();

    ORB_SLAM2::System* mpSLAM;
    ros::NodeHandle *rosNode;

    // External localization
    tf::TransformBroadcaster *mTfBr;
    tf::TransformListener *extListener;
    tf::StampedTransform extPose;
    string extFrame1, extFrame2;
    bool doStop;
    bool doDebayer;
    bool offlineMode;
    int offsetKeyframe;


    tf::Transform localizeByReference (const tf::Transform &amp;tfOrb, KeyFrame *kf);
    tf::Transform localizeByReference (const tf::Transform &amp;tfOrb);
    tf::Transform localizeByReference (Frame *sframe);

    static tf::Transform localizeByReference (
    	const tf::Transform &amp;tfOrb,
		const tf::Transform &amp;tfOrbMap, const tf::Transform &amp;tfOrbMapOffset,
    	const tf::Transform &amp;realMapPose, const tf::Transform &amp;realMapOffset);

    static tf::Transform localizeByReference (const tf::Transform &amp;tfOrb, ORB_SLAM2::Map *mapsrc, const int offsetNum);

	static tf::Transform getKeyFrameExtPose (const KeyFrame *kf);

	static tf::Transform KeyFramePoseToTf (KeyFrame *kf);

	static tf::Transform FramePose (Frame *cframe);

	static cv::Vec3d tfToCv (const tf::Vector3 &amp;pos);

	static cv::Mat tfToCv (const tf::Transform &amp;tfsrc);

	// I Know this is unstable
	static tf2_msgs::TFMessage createTfMessage (const tf::Transform &amp;srcTransform, const string &amp;frameSrc, const string &amp;frameTarget, double timestamp);


	// Logging
	image_transport::ImageTransport *imageTransport;
	image_transport::Publisher visualDebugView;
	ros::Publisher debugMsgPublisher;

	cv::Mat framebufferDebug;
	uint32_t lastKeyframeId;
	double cputimeDebug;
	double lastImageTimestamp;

private:
	void publishDebug ();
};


#endif /* _IMAGEGRABBER_H_ */
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/bag_mapper.cc" new_path="">
				<diff>@@ -1,140 +0,0 @@
-/*
- * bag_mapper.cc
- *
- *  Created on: Jun 3, 2016
- *      Author: sujiwo
- */
-
-#include &lt;cstdlib&gt;
-#include &lt;signal.h&gt;
-#include &lt;iostream&gt;
-#include &lt;string&gt;
-#include &lt;rosbag/bag.h&gt;
-#include &lt;rosbag/view.h&gt;
-#include &lt;sensor_msgs/Image.h&gt;
-#include &lt;sensor_msgs/CompressedImage.h&gt;
-
-#include &lt;boost/foreach.hpp&gt;
-#include &quot;../__nodes/ImageGrabber.h&quot;
-#include &quot;../__nodes/utils.h&quot;
-
-
-using namespace std;
-
-
-#define foreach BOOST_FOREACH
-
-
-bool doStop = false;
-
-
-void stopHandler (int signum)
-{
-	cout &lt;&lt; &quot;Stopping...&quot; &lt;&lt; endl;
-	doStop = true;
-}
-
-
-
-int main (int argc, char *argv[])
-{
-	if (argc &lt; 4) {
-		cerr &lt;&lt; &quot;\nUsage: bag_mapper path_to_settings image_bag ground_truth [second_skip] [path_to_map]\n&quot; &lt;&lt; endl;
-		exit(1);
-	}
-
-	// Set signal handler
-	signal (SIGINT, stopHandler);
-	signal (SIGTERM, stopHandler);
-
-	string mapPath = (argc&gt;=6 ? argv[5] : string());
-	double secondToSkip = argc&gt;=5 ? atof(argv[4]) : 0.0;
-	string bagPath (argv[2]);
-	string groundTruth (argv[3]);
-	string orbVocabFile (ORB_SLAM_VOCABULARY);
-
-	// Necessary Resource
-	ORB_SLAM2::System SLAM (orbVocabFile,
-		argv[1],
-		ORB_SLAM2::System::MONOCULAR,
-		true,
-		mapPath,
-		ORB_SLAM2::System::MAPPING);
-	ImageGrabber GrabBag (&amp;SLAM, NULL, true);
-	TfTimeTree TfSource (groundTruth, SLAM.fsSettings[&quot;ExternalLocalization.frame1&quot;], SLAM.fsSettings[&quot;ExternalLocalization.frame2&quot;]);
-
-	// Build ROSBag Query
-	rosbag::Bag bagSrc;
-	bagSrc.open (bagPath, rosbag::bagmode::Read);
-	const string imageTopic (SLAM.fsSettings[&quot;Camera.topic&quot;]);
-	rosbag::View viewx(bagSrc, rosbag::TopicQuery(imageTopic));
-	ros::Time startTime = viewx.getBeginTime();
-	startTime.sec += secondToSkip;
-	rosbag::View view(bagSrc, rosbag::TopicQuery(imageTopic), startTime);
-
-	const double mappingStartTime = view.getBeginTime().toSec(),
-		mappingStopTime = view.getEndTime().toSec();
-	cout &lt;&lt; &quot;Starting at &quot; &lt;&lt; mappingStartTime &lt;&lt; &quot;, ending at &quot; &lt;&lt; mappingStopTime &lt;&lt; endl;
-
-	bool tracked = false;
-	uint32_t frameCounter = 0;
-	SLAM.getTracker()-&gt;setFps(10);
-
-	foreach (rosbag::MessageInstance const msg, view) {
-
-		frameCounter ++;
-		if (frameCounter % 2 == 1)
-			continue;
-
-		double timestamp;
-
-		if (doStop==true)
-			break;
-
-		// Put mutual exclusion from here ...
-		// We intend to pause LoopClosing and LocalMapper
-		// Until frame processing is done.
-		// Also, we pause frame input until LoopClosing and LocalMapper finish their rounds
-		std::lock (SLAM.getLocalMapper()-&gt;localMappingRunMutex, SLAM.getLoopCloser()-&gt;loopCloserRunMutex);
-
-		if ((int)SLAM.fsSettings[&quot;Camera.compressed&quot;]==1) {
-			sensor_msgs::CompressedImageConstPtr imgc = msg.instantiate&lt;sensor_msgs::CompressedImage&gt;();
-			// XXX: Not finished!
-		}
-
-		else {
-			sensor_msgs::ImageConstPtr img = msg.instantiate&lt;sensor_msgs::Image&gt;();
-			timestamp = img-&gt;header.stamp.toSec();
-			GrabBag.GrabImage(img);
-		}
-		// to here
-		SLAM.getLocalMapper()-&gt;localMappingRunMutex.unlock();
-		SLAM.getLoopCloser()-&gt;loopCloserRunMutex.unlock();
-
-		// put ground truth
-		tf::Transform currentNdtPose;
-		Frame &amp;cframe = SLAM.getTracker()-&gt;mCurrentFrame;
-
-		if (cframe.mTcw.empty()==false)
-			tracked = true;
-		else {
-			if (tracked==true) {
-//				cout &lt;&lt; &quot;Frame Counter: &quot; &lt;&lt; frameCounter &lt;&lt; endl;
-				cout &lt;&lt; &quot;Stopping due to lost after &quot; &lt;&lt; frameCounter &lt;&lt; &quot; frames, timestamp: &quot; &lt;&lt; timestamp &lt;&lt; endl;
-				break;
-			}
-		}
-
-		try {
-			currentNdtPose = TfSource.search(timestamp);
-			tfToCV(currentNdtPose, cframe.mpReferenceKF-&gt;extPosition, cframe.mpReferenceKF-&gt;extOrientation);
-		} catch (const std::out_of_range &amp;e) {
-			currentNdtPose.setOrigin (tf::Vector3());
-			currentNdtPose.setRotation (tf::Quaternion());
-		}
-
-		frameCounter ++;
-	}
-
-	SLAM.Shutdown();
-}
</diff>
				<old_file>/*
 * bag_mapper.cc
 *
 *  Created on: Jun 3, 2016
 *      Author: sujiwo
 */

#include &lt;cstdlib&gt;
#include &lt;signal.h&gt;
#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;rosbag/bag.h&gt;
#include &lt;rosbag/view.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/CompressedImage.h&gt;

#include &lt;boost/foreach.hpp&gt;
#include &quot;../__nodes/ImageGrabber.h&quot;
#include &quot;../__nodes/utils.h&quot;


using namespace std;


#define foreach BOOST_FOREACH


bool doStop = false;


void stopHandler (int signum)
{
	cout &lt;&lt; &quot;Stopping...&quot; &lt;&lt; endl;
	doStop = true;
}



int main (int argc, char *argv[])
{
	if (argc &lt; 4) {
		cerr &lt;&lt; &quot;\nUsage: bag_mapper path_to_settings image_bag ground_truth [second_skip] [path_to_map]\n&quot; &lt;&lt; endl;
		exit(1);
	}

	// Set signal handler
	signal (SIGINT, stopHandler);
	signal (SIGTERM, stopHandler);

	string mapPath = (argc&gt;=6 ? argv[5] : string());
	double secondToSkip = argc&gt;=5 ? atof(argv[4]) : 0.0;
	string bagPath (argv[2]);
	string groundTruth (argv[3]);
	string orbVocabFile (ORB_SLAM_VOCABULARY);

	// Necessary Resource
	ORB_SLAM2::System SLAM (orbVocabFile,
		argv[1],
		ORB_SLAM2::System::MONOCULAR,
		true,
		mapPath,
		ORB_SLAM2::System::MAPPING);
	ImageGrabber GrabBag (&amp;SLAM, NULL, true);
	TfTimeTree TfSource (groundTruth, SLAM.fsSettings[&quot;ExternalLocalization.frame1&quot;], SLAM.fsSettings[&quot;ExternalLocalization.frame2&quot;]);

	// Build ROSBag Query
	rosbag::Bag bagSrc;
	bagSrc.open (bagPath, rosbag::bagmode::Read);
	const string imageTopic (SLAM.fsSettings[&quot;Camera.topic&quot;]);
	rosbag::View viewx(bagSrc, rosbag::TopicQuery(imageTopic));
	ros::Time startTime = viewx.getBeginTime();
	startTime.sec += secondToSkip;
	rosbag::View view(bagSrc, rosbag::TopicQuery(imageTopic), startTime);

	const double mappingStartTime = view.getBeginTime().toSec(),
		mappingStopTime = view.getEndTime().toSec();
	cout &lt;&lt; &quot;Starting at &quot; &lt;&lt; mappingStartTime &lt;&lt; &quot;, ending at &quot; &lt;&lt; mappingStopTime &lt;&lt; endl;

	bool tracked = false;
	uint32_t frameCounter = 0;
	SLAM.getTracker()-&gt;setFps(10);

	foreach (rosbag::MessageInstance const msg, view) {

		frameCounter ++;
		if (frameCounter % 2 == 1)
			continue;

		double timestamp;

		if (doStop==true)
			break;

		// Put mutual exclusion from here ...
		// We intend to pause LoopClosing and LocalMapper
		// Until frame processing is done.
		// Also, we pause frame input until LoopClosing and LocalMapper finish their rounds
		std::lock (SLAM.getLocalMapper()-&gt;localMappingRunMutex, SLAM.getLoopCloser()-&gt;loopCloserRunMutex);

		if ((int)SLAM.fsSettings[&quot;Camera.compressed&quot;]==1) {
			sensor_msgs::CompressedImageConstPtr imgc = msg.instantiate&lt;sensor_msgs::CompressedImage&gt;();
			// XXX: Not finished!
		}

		else {
			sensor_msgs::ImageConstPtr img = msg.instantiate&lt;sensor_msgs::Image&gt;();
			timestamp = img-&gt;header.stamp.toSec();
			GrabBag.GrabImage(img);
		}
		// to here
		SLAM.getLocalMapper()-&gt;localMappingRunMutex.unlock();
		SLAM.getLoopCloser()-&gt;loopCloserRunMutex.unlock();

		// put ground truth
		tf::Transform currentNdtPose;
		Frame &amp;cframe = SLAM.getTracker()-&gt;mCurrentFrame;

		if (cframe.mTcw.empty()==false)
			tracked = true;
		else {
			if (tracked==true) {
//				cout &lt;&lt; &quot;Frame Counter: &quot; &lt;&lt; frameCounter &lt;&lt; endl;
				cout &lt;&lt; &quot;Stopping due to lost after &quot; &lt;&lt; frameCounter &lt;&lt; &quot; frames, timestamp: &quot; &lt;&lt; timestamp &lt;&lt; endl;
				break;
			}
		}

		try {
			currentNdtPose = TfSource.search(timestamp);
			tfToCV(currentNdtPose, cframe.mpReferenceKF-&gt;extPosition, cframe.mpReferenceKF-&gt;extOrientation);
		} catch (const std::out_of_range &amp;e) {
			currentNdtPose.setOrigin (tf::Vector3());
			currentNdtPose.setRotation (tf::Quaternion());
		}

		frameCounter ++;
	}

	SLAM.Shutdown();
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/mapper.cc" new_path="">
				<diff>@@ -1,106 +0,0 @@
-/**
-* This file is part of ORB-SLAM2.
-*
-* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
-* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
-*
-* ORB-SLAM2 is free software: you can redistribute it and/or modify
-* it under the terms of the GNU General Public License as published by
-* the Free Software Foundation, either version 3 of the License, or
-* (at your option) any later version.
-*
-* ORB-SLAM2 is distributed in the hope that it will be useful,
-* but WITHOUT ANY WARRANTY; without even the implied warranty of
-* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
-* GNU General Public License for more details.
-*
-* You should have received a copy of the GNU General Public License
-* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
-*/
-
-
-#include &lt;iostream&gt;
-#include &lt;string&gt;
-
-#include &quot;../__nodes/ImageGrabber.h&quot;
-
-
-
-using namespace std;
-using ORB_SLAM2::Frame;
-namespace enc = sensor_msgs::image_encodings;
-
-
-
-
-
-int main(int argc, char **argv)
-{
-	string myname (basename(argv[0]));
-	ORB_SLAM2::System::operationMode opMode;
-	// Which name was we called by ?
-	if (myname.compare(myname.size()-7, 7, &quot;mapping&quot;)==0) {
-		opMode = ORB_SLAM2::System::MAPPING;
-		cout &lt;&lt; &quot;Mode: Mapper&quot; &lt;&lt; endl;
-	}
-	else {  // == &quot;matching&quot;
-		opMode = ORB_SLAM2::System::LOCALIZATION;
-		cout &lt;&lt; &quot;Mode: Localizer&quot; &lt;&lt; endl;
-	}
-
-    ros::init(argc, argv, &quot;orb_slam_mapper&quot;);
-    ros::start();
-    ros::NodeHandle nodeHandler;
-
-    if(argc &lt; 2)
-    {
-        cerr &lt;&lt; endl &lt;&lt; &quot;Usage: &quot; &lt;&lt; myname &lt;&lt; &quot; path_to_settings [path_to_map]\n&quot; &lt;&lt; endl;
-        ros::shutdown();
-        return 1;
-    }
-
-    // Create SLAM system. It initializes all system threads and gets ready to process frames.
-    string mapPath = (argc==3) ? argv[2] : string();
-
-    // This macro should be set by Cmake
-    string orbVocabFile (ORB_SLAM_VOCABULARY);
-    const bool useVisualization = opMode==ORB_SLAM2::System::MAPPING ? true : false;
-    ORB_SLAM2::System SLAM(orbVocabFile,
-    	argv[1],
-		ORB_SLAM2::System::MONOCULAR,
-		useVisualization,
-		mapPath,
-    	opMode);
-
-    std::thread* tExtLocalizer;
-    ImageGrabber igb(&amp;SLAM, &amp;nodeHandler);
-    if (opMode==ORB_SLAM2::System::MAPPING)
-    	tExtLocalizer = new std::thread (&amp;ImageGrabber::externalLocalizerGrab, &amp;igb);
-    else
-    	tExtLocalizer = NULL;
-
-    image_transport::TransportHints th;
-    if ((int)SLAM.fsSettings[&quot;Camera.compressed&quot;]==0) {
-    	th = image_transport::TransportHints (&quot;raw&quot;);
-    }
-    else if ((int)SLAM.fsSettings[&quot;Camera.compressed&quot;]==1) {
-    	th = image_transport::TransportHints (&quot;compressed&quot;);
-    }
-    image_transport::ImageTransport it (nodeHandler);
-    image_transport::Subscriber sub = it.subscribe ((string)SLAM.fsSettings[&quot;Camera.topic&quot;], 1, &amp;ImageGrabber::GrabImage, &amp;igb, th);
-
-    cout &lt;&lt; endl &lt;&lt; &quot;Mono Camera topic: &quot; &lt;&lt; (string)SLAM.fsSettings[&quot;Camera.topic&quot;] &lt;&lt; endl;
-    cout &lt;&lt; &quot;Compressed images? &quot; &lt;&lt; ((int)SLAM.fsSettings[&quot;Camera.compressed&quot;]==1 ? &quot;True&quot; : &quot;False&quot;) &lt;&lt; endl;
-
-    ros::spin();
-
-    // Stop all threads
-    SLAM.Shutdown();
-    igb.doStop = true;
-    if (tExtLocalizer != NULL)
-    	tExtLocalizer-&gt;join();
-
-    ros::shutdown();
-
-    return 0;
-}
</diff>
				<old_file>/**
* This file is part of ORB-SLAM2.
*
* Copyright (C) 2014-2016 Raúl Mur-Artal &lt;raulmur at unizar dot es&gt; (University of Zaragoza)
* For more information see &lt;https://github.com/raulmur/ORB_SLAM2&gt;
*
* ORB-SLAM2 is free software: you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* ORB-SLAM2 is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with ORB-SLAM2. If not, see &lt;http://www.gnu.org/licenses/&gt;.
*/


#include &lt;iostream&gt;
#include &lt;string&gt;

#include &quot;../__nodes/ImageGrabber.h&quot;



using namespace std;
using ORB_SLAM2::Frame;
namespace enc = sensor_msgs::image_encodings;





int main(int argc, char **argv)
{
	string myname (basename(argv[0]));
	ORB_SLAM2::System::operationMode opMode;
	// Which name was we called by ?
	if (myname.compare(myname.size()-7, 7, &quot;mapping&quot;)==0) {
		opMode = ORB_SLAM2::System::MAPPING;
		cout &lt;&lt; &quot;Mode: Mapper&quot; &lt;&lt; endl;
	}
	else {  // == &quot;matching&quot;
		opMode = ORB_SLAM2::System::LOCALIZATION;
		cout &lt;&lt; &quot;Mode: Localizer&quot; &lt;&lt; endl;
	}

    ros::init(argc, argv, &quot;orb_slam_mapper&quot;);
    ros::start();
    ros::NodeHandle nodeHandler;

    if(argc &lt; 2)
    {
        cerr &lt;&lt; endl &lt;&lt; &quot;Usage: &quot; &lt;&lt; myname &lt;&lt; &quot; path_to_settings [path_to_map]\n&quot; &lt;&lt; endl;
        ros::shutdown();
        return 1;
    }

    // Create SLAM system. It initializes all system threads and gets ready to process frames.
    string mapPath = (argc==3) ? argv[2] : string();

    // This macro should be set by Cmake
    string orbVocabFile (ORB_SLAM_VOCABULARY);
    const bool useVisualization = opMode==ORB_SLAM2::System::MAPPING ? true : false;
    ORB_SLAM2::System SLAM(orbVocabFile,
    	argv[1],
		ORB_SLAM2::System::MONOCULAR,
		useVisualization,
		mapPath,
    	opMode);

    std::thread* tExtLocalizer;
    ImageGrabber igb(&amp;SLAM, &amp;nodeHandler);
    if (opMode==ORB_SLAM2::System::MAPPING)
    	tExtLocalizer = new std::thread (&amp;ImageGrabber::externalLocalizerGrab, &amp;igb);
    else
    	tExtLocalizer = NULL;

    image_transport::TransportHints th;
    if ((int)SLAM.fsSettings[&quot;Camera.compressed&quot;]==0) {
    	th = image_transport::TransportHints (&quot;raw&quot;);
    }
    else if ((int)SLAM.fsSettings[&quot;Camera.compressed&quot;]==1) {
    	th = image_transport::TransportHints (&quot;compressed&quot;);
    }
    image_transport::ImageTransport it (nodeHandler);
    image_transport::Subscriber sub = it.subscribe ((string)SLAM.fsSettings[&quot;Camera.topic&quot;], 1, &amp;ImageGrabber::GrabImage, &amp;igb, th);

    cout &lt;&lt; endl &lt;&lt; &quot;Mono Camera topic: &quot; &lt;&lt; (string)SLAM.fsSettings[&quot;Camera.topic&quot;] &lt;&lt; endl;
    cout &lt;&lt; &quot;Compressed images? &quot; &lt;&lt; ((int)SLAM.fsSettings[&quot;Camera.compressed&quot;]==1 ? &quot;True&quot; : &quot;False&quot;) &lt;&lt; endl;

    ros::spin();

    // Stop all threads
    SLAM.Shutdown();
    igb.doStop = true;
    if (tExtLocalizer != NULL)
    	tExtLocalizer-&gt;join();

    ros::shutdown();

    return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/mt/DebugMT.cc" new_path="">
				<diff>@@ -1,63 +0,0 @@
-/*
- * DebugMT.cpp
- *
- *  Created on: Jul 28, 2016
- *      Author: sujiwo
- */
-
-#include &quot;../../__nodes/mt/DebugMT.h&quot;
-
-#include &quot;../../__nodes/mt/TrackingThread.h&quot;
-
-
-
-extern const char
-	*framebufferDebugTopic,
-	*internalTopic;
-
-
-
-DebugMT::DebugMT (TrackingThread *t, ros::NodeHandle &amp;nh, const string &amp;sid) :
-
-	node (nh),
-	identifier (sid),
-	proc (t)
-
-{
-	imageTransport = new image_transport::ImageTransport (node);
-	visualDebugView = imageTransport-&gt;advertise(string(framebufferDebugTopic) + &quot;/map&quot; + identifier, 1);
-	debugMsgPublisher = node.advertise&lt;orb_localizer::debug&gt; (string(internalTopic) + &quot;/map&quot; + identifier, 1);
-}
-
-
-DebugMT::~DebugMT()
-{}
-
-
-void DebugMT::notify()
-{
-	mTfBr.sendTransform(tf::StampedTransform(
-		proc-&gt;getCurrent(),
-		ros::Time (proc-&gt;getLastTime()),
-		proc-&gt;parentFrame,
-		proc-&gt;targetFrame
-	));
-
-	proc-&gt;framedraw-&gt;DrawFrame();
-	framebufferDebug = proc-&gt;framedraw-&gt;getLastFrame();
-
-	cv_bridge::CvImage bagImage;
-	bagImage.image = framebufferDebug;
-	bagImage.header.stamp = ros::Time(lastImageTimestamp);
-	bagImage.header.frame_id = identifier;
-	bagImage.encoding = &quot;bgr8&quot;;
-	visualDebugView.publish(bagImage.toImageMsg());
-
-//	orb_localizer::debug internalDebugMsg;
-//	internalDebugMsg.header.stamp = ros::Time (lastImageTimestamp);
-//	internalDebugMsg.header.frame_id = identifier;
-//	internalDebugMsg.keyframe_id = lastKeyframeId;
-//	internalDebugMsg.cputime = cputimeDebug;
-//	debugMsgPublisher.publish (internalDebugMsg);
-
-}
</diff>
				<old_file>/*
 * DebugMT.cpp
 *
 *  Created on: Jul 28, 2016
 *      Author: sujiwo
 */

#include &quot;../../__nodes/mt/DebugMT.h&quot;

#include &quot;../../__nodes/mt/TrackingThread.h&quot;



extern const char
	*framebufferDebugTopic,
	*internalTopic;



DebugMT::DebugMT (TrackingThread *t, ros::NodeHandle &amp;nh, const string &amp;sid) :

	node (nh),
	identifier (sid),
	proc (t)

{
	imageTransport = new image_transport::ImageTransport (node);
	visualDebugView = imageTransport-&gt;advertise(string(framebufferDebugTopic) + &quot;/map&quot; + identifier, 1);
	debugMsgPublisher = node.advertise&lt;orb_localizer::debug&gt; (string(internalTopic) + &quot;/map&quot; + identifier, 1);
}


DebugMT::~DebugMT()
{}


void DebugMT::notify()
{
	mTfBr.sendTransform(tf::StampedTransform(
		proc-&gt;getCurrent(),
		ros::Time (proc-&gt;getLastTime()),
		proc-&gt;parentFrame,
		proc-&gt;targetFrame
	));

	proc-&gt;framedraw-&gt;DrawFrame();
	framebufferDebug = proc-&gt;framedraw-&gt;getLastFrame();

	cv_bridge::CvImage bagImage;
	bagImage.image = framebufferDebug;
	bagImage.header.stamp = ros::Time(lastImageTimestamp);
	bagImage.header.frame_id = identifier;
	bagImage.encoding = &quot;bgr8&quot;;
	visualDebugView.publish(bagImage.toImageMsg());

//	orb_localizer::debug internalDebugMsg;
//	internalDebugMsg.header.stamp = ros::Time (lastImageTimestamp);
//	internalDebugMsg.header.frame_id = identifier;
//	internalDebugMsg.keyframe_id = lastKeyframeId;
//	internalDebugMsg.cputime = cputimeDebug;
//	debugMsgPublisher.publish (internalDebugMsg);

}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/mt/DebugMT.h" new_path="">
				<diff>@@ -1,57 +0,0 @@
-/*
- * DebugMT.h
- *
- *  Created on: Jul 28, 2016
- *      Author: sujiwo
- */
-
-#ifndef _DEBUGMT_H_
-#define _DEBUGMT_H_
-
-
-#include &lt;string&gt;
-#include &lt;mutex&gt;
-
-#include &lt;ros/ros.h&gt;
-#include &lt;cv_bridge/cv_bridge.h&gt;
-#include &lt;image_transport/image_transport.h&gt;
-#include &lt;sensor_msgs/Image.h&gt;
-#include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;tf/transform_broadcaster.h&gt;
-#include &lt;tf/transform_listener.h&gt;
-#include &lt;orb_localizer/debug.h&gt;
-
-
-using namespace std;
-
-
-class TrackingThread;
-
-
-class DebugMT {
-public:
-	DebugMT (TrackingThread *th, ros::NodeHandle &amp;nh, const string &amp;sid);
-	virtual ~DebugMT();
-
-	void notify ();
-
-	void publishParticles ();
-
-private:
-	TrackingThread *proc;
-	ros::NodeHandle &amp;node;
-	const string &amp;identifier;
-	tf::TransformBroadcaster mTfBr;
-
-	image_transport::ImageTransport *imageTransport;
-	image_transport::Publisher visualDebugView;
-	ros::Publisher debugMsgPublisher;
-
-	cv::Mat framebufferDebug;
-	uint32_t lastKeyframeId;
-	double cputimeDebug;
-	double lastImageTimestamp;
-
-};
-
-#endif /* _DEBUGMT_H_ */
</diff>
				<old_file>/*
 * DebugMT.h
 *
 *  Created on: Jul 28, 2016
 *      Author: sujiwo
 */

#ifndef _DEBUGMT_H_
#define _DEBUGMT_H_


#include &lt;string&gt;
#include &lt;mutex&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;image_transport/image_transport.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;orb_localizer/debug.h&gt;


using namespace std;


class TrackingThread;


class DebugMT {
public:
	DebugMT (TrackingThread *th, ros::NodeHandle &amp;nh, const string &amp;sid);
	virtual ~DebugMT();

	void notify ();

	void publishParticles ();

private:
	TrackingThread *proc;
	ros::NodeHandle &amp;node;
	const string &amp;identifier;
	tf::TransformBroadcaster mTfBr;

	image_transport::ImageTransport *imageTransport;
	image_transport::Publisher visualDebugView;
	ros::Publisher debugMsgPublisher;

	cv::Mat framebufferDebug;
	uint32_t lastKeyframeId;
	double cputimeDebug;
	double lastImageTimestamp;

};

#endif /* _DEBUGMT_H_ */
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/mt/SystemMT.cc" new_path="">
				<diff>@@ -1,215 +0,0 @@
-/*
- * SystemMT.cpp
- *
- *  Created on: Jul 22, 2016
- *      Author: sujiwo
- */
-
-#include &quot;../../__nodes/mt/SystemMT.h&quot;
-
-#include &lt;string&gt;
-
-
-
-
-using namespace std;
-using ORB_SLAM2::ORBVocabulary;
-
-
-const double orbError = 0.5;
-
-
-SystemMT::SystemMT (ros::NodeHandle &amp;nh, const vector&lt;string&gt; &amp;mapPaths, const string &amp;vocabPath, const string &amp;_settingsPath) :
-
-	settingPath (_settingsPath),
-
-	imgIsNew (false),
-
-	rosnode (nh),
-
-	// XXX: we silently assume that map loading is always successful
-	readyCheck (mapPaths.size()+1)
-
-{
-	fSetting = cv::FileStorage (settingPath.c_str(), cv::FileStorage::READ);
-
-	sVocab = new ORBVocabulary();
-    if (vocabPath.empty() == false) {
-    	cout &lt;&lt; &quot;Loading vocabulary ... &quot;;
-		bool bVocLoad = sVocab-&gt;loadFromTextFile(vocabPath);
-		if(!bVocLoad)
-		{
-			cerr &lt;&lt; &quot;Wrong path to vocabulary. &quot; &lt;&lt; endl;
-			cerr &lt;&lt; &quot;Failed to open at: &quot; &lt;&lt; vocabPath &lt;&lt; endl;
-			exit(-1);
-		}
-		cout &lt;&lt; &quot;Done&quot; &lt;&lt; endl &lt;&lt; endl;
-    }
-
-    int i = 1;
-    for (auto mp: mapPaths) {
-    	string ids = std::to_string (i);
-    	TrackingThread *pth = new TrackingThread (mp, this, ids);
-    	children.push_back(pth);
-    	i += 1;
-    }
-
-    pfilter = new PF::ParticleFilter&lt;CamState, tf::Transform, double&gt; (NUMBER_OF_PARTICLE, vehicleModel);
-
-    // Wait until all workers ready
-    cout &lt;&lt; &quot;Waiting for all workers to be ready... &quot; &lt;&lt; endl;
-    readyCheck.wait();
-    cout &lt;&lt; &quot;All workers ready&quot; &lt;&lt; endl;
-}
-
-
-/*
- * XXX: this destructor does not work correctly
- */
-SystemMT::~SystemMT ()
-{
-	{
-		boost::lock_guard&lt;boost::mutex&gt; lock (imgLock);
-		for (auto proct: children)
-			proct-&gt;stop();
-	}
-	imgMon.notify_all();
-
-	for (auto proct: children)
-		delete (proct);
-//	for (auto proct: children) {
-//		proct-&gt;stop();
-//		cout &lt;&lt; &quot;Stopping worker #&quot; &lt;&lt; proct-&gt;identity &lt;&lt; endl;
-//		delete (proct);
-//	}
-
-	delete (pfilter);
-}
-
-
-/*
- * We expect colorful image, unbayered
- */
-void SystemMT::Track (const cv::Mat &amp;srcImage, const double timestamp)
-{
-	currentTimestamp = timestamp;
-
-	{
-		boost::lock_guard&lt;boost::mutex&gt; lock (imgLock);
-
-		currentImage = srcImage.clone();
-		// resize and crop
-		// Do Resizing and cropping here
-		cv::resize(currentImage, currentImage,
-			cv::Size(
-				(int)fSetting[&quot;Camera.WorkingResolution.Width&quot;],
-				(int)fSetting[&quot;Camera.WorkingResolution.Height&quot;]
-			));
-		currentImage = currentImage(
-			cv::Rect(
-				(int)fSetting[&quot;Camera.ROI.x0&quot;],
-				(int)fSetting[&quot;Camera.ROI.y0&quot;],
-				(int)fSetting[&quot;Camera.ROI.width&quot;],
-				(int)fSetting[&quot;Camera.ROI.height&quot;]
-			)).clone();
-
-		imgIsNew = true;
-		currentTimestamp = timestamp;
-	}
-	// notify worker threads to begin
-	imgMon.notify_all();
-
-//	filter ();
-
-	readyCheck.wait();
-	imgIsNew = false;
-
-}
-
-
-void SystemMT::filter()
-{
-	if (!vehicleModel.isInitialized()) {
-		for (auto proct: children) {
-			if (!proct-&gt;poseIsValid())
-				continue;
-			// we found valid pose; set this as particle initialization
-			vehicleModel.preinitialize(proct-&gt;getCurrent(), currentTimestamp);
-			break;
-		}
-		pfilter-&gt;initializeParticles();
-		return;
-	}
-//	prev
-
-}
-
-
-OrbMapFusion::OrbMapFusion() :
-	initialized (false),
-	prevTimestamp (0)
-{}
-
-
-void OrbMapFusion::preinitialize(const tf::Transform &amp;iPose, const double ts)
-{
-	prevTimestamp = ts;
-	initPose = iPose;
-	initialized = true;
-}
-
-
-CamState OrbMapFusion::initializeParticleState() const
-{
-	CamState m0 (initPose);
-	double ds = PF::nrand(orbError),
-		xn = m0.getOrigin().x(),
-		yn = m0.getOrigin().y(),
-		zn = m0.getOrigin().z();
-	m0.setOrigin(tf::Vector3(xn, yn, zn));
-	return m0;
-}
-
-
-/*
- * XXX: this motion model is untested !
- * Need to initialize velocity
- */
-CamState OrbMapFusion::motionModel(const CamState &amp;vstate, const double &amp;t) const
-{
-	CamState nstate;
-
-	double dt = t - prevTimestamp;
-	double x = vstate.getOrigin().x() + vstate.velocity.x()*dt + PF::nrand(orbError);
-	double y = vstate.getOrigin().y() + vstate.velocity.y()*dt + PF::nrand(orbError);
-	double z = vstate.getOrigin().z() + vstate.velocity.z()*dt + PF::nrand(orbError);
-	double vx = (x-vstate.getOrigin().x()) / dt;
-	double vy = (y-vstate.getOrigin().y()) / dt;
-	double vz = (z-vstate.getOrigin().z()) / dt;
-
-	nstate.setOrigin(tf::Vector3(x, y, z));
-	nstate.velocity = tf::Vector3 (vx, vy, vz);
-	return nstate;
-}
-
-
-double OrbMapFusion::measurementModel(const CamState &amp;state, const vector&lt;tf::Transform&gt; &amp;observations) const
-{
-	vector&lt;double&gt; obsWeight;
-
-	for (const auto &amp;pose: observations) {
-		double wo,
-			xt = pose.getOrigin().x(),
-			yt = pose.getOrigin().y(),
-			zt = pose.getOrigin().z(),
-			xs = state.getOrigin().x(),
-			ys = state.getOrigin().y(),
-			zs = state.getOrigin().z();
-		wo = exp (-(pow(xt-xs,2) / (2*orbError*orbError) +
-			pow(yt-ys,2) / (2*orbError*orbError)));
-		obsWeight.push_back(wo);
-	}
-
-	double w = *std::max_element(obsWeight.begin(), obsWeight.end());
-	return max(w, 0.01);
-}
</diff>
				<old_file>/*
 * SystemMT.cpp
 *
 *  Created on: Jul 22, 2016
 *      Author: sujiwo
 */

#include &quot;../../__nodes/mt/SystemMT.h&quot;

#include &lt;string&gt;




using namespace std;
using ORB_SLAM2::ORBVocabulary;


const double orbError = 0.5;


SystemMT::SystemMT (ros::NodeHandle &amp;nh, const vector&lt;string&gt; &amp;mapPaths, const string &amp;vocabPath, const string &amp;_settingsPath) :

	settingPath (_settingsPath),

	imgIsNew (false),

	rosnode (nh),

	// XXX: we silently assume that map loading is always successful
	readyCheck (mapPaths.size()+1)

{
	fSetting = cv::FileStorage (settingPath.c_str(), cv::FileStorage::READ);

	sVocab = new ORBVocabulary();
    if (vocabPath.empty() == false) {
    	cout &lt;&lt; &quot;Loading vocabulary ... &quot;;
		bool bVocLoad = sVocab-&gt;loadFromTextFile(vocabPath);
		if(!bVocLoad)
		{
			cerr &lt;&lt; &quot;Wrong path to vocabulary. &quot; &lt;&lt; endl;
			cerr &lt;&lt; &quot;Failed to open at: &quot; &lt;&lt; vocabPath &lt;&lt; endl;
			exit(-1);
		}
		cout &lt;&lt; &quot;Done&quot; &lt;&lt; endl &lt;&lt; endl;
    }

    int i = 1;
    for (auto mp: mapPaths) {
    	string ids = std::to_string (i);
    	TrackingThread *pth = new TrackingThread (mp, this, ids);
    	children.push_back(pth);
    	i += 1;
    }

    pfilter = new PF::ParticleFilter&lt;CamState, tf::Transform, double&gt; (NUMBER_OF_PARTICLE, vehicleModel);

    // Wait until all workers ready
    cout &lt;&lt; &quot;Waiting for all workers to be ready... &quot; &lt;&lt; endl;
    readyCheck.wait();
    cout &lt;&lt; &quot;All workers ready&quot; &lt;&lt; endl;
}


/*
 * XXX: this destructor does not work correctly
 */
SystemMT::~SystemMT ()
{
	{
		boost::lock_guard&lt;boost::mutex&gt; lock (imgLock);
		for (auto proct: children)
			proct-&gt;stop();
	}
	imgMon.notify_all();

	for (auto proct: children)
		delete (proct);
//	for (auto proct: children) {
//		proct-&gt;stop();
//		cout &lt;&lt; &quot;Stopping worker #&quot; &lt;&lt; proct-&gt;identity &lt;&lt; endl;
//		delete (proct);
//	}

	delete (pfilter);
}


/*
 * We expect colorful image, unbayered
 */
void SystemMT::Track (const cv::Mat &amp;srcImage, const double timestamp)
{
	currentTimestamp = timestamp;

	{
		boost::lock_guard&lt;boost::mutex&gt; lock (imgLock);

		currentImage = srcImage.clone();
		// resize and crop
		// Do Resizing and cropping here
		cv::resize(currentImage, currentImage,
			cv::Size(
				(int)fSetting[&quot;Camera.WorkingResolution.Width&quot;],
				(int)fSetting[&quot;Camera.WorkingResolution.Height&quot;]
			));
		currentImage = currentImage(
			cv::Rect(
				(int)fSetting[&quot;Camera.ROI.x0&quot;],
				(int)fSetting[&quot;Camera.ROI.y0&quot;],
				(int)fSetting[&quot;Camera.ROI.width&quot;],
				(int)fSetting[&quot;Camera.ROI.height&quot;]
			)).clone();

		imgIsNew = true;
		currentTimestamp = timestamp;
	}
	// notify worker threads to begin
	imgMon.notify_all();

//	filter ();

	readyCheck.wait();
	imgIsNew = false;

}


void SystemMT::filter()
{
	if (!vehicleModel.isInitialized()) {
		for (auto proct: children) {
			if (!proct-&gt;poseIsValid())
				continue;
			// we found valid pose; set this as particle initialization
			vehicleModel.preinitialize(proct-&gt;getCurrent(), currentTimestamp);
			break;
		}
		pfilter-&gt;initializeParticles();
		return;
	}
//	prev

}


OrbMapFusion::OrbMapFusion() :
	initialized (false),
	prevTimestamp (0)
{}


void OrbMapFusion::preinitialize(const tf::Transform &amp;iPose, const double ts)
{
	prevTimestamp = ts;
	initPose = iPose;
	initialized = true;
}


CamState OrbMapFusion::initializeParticleState() const
{
	CamState m0 (initPose);
	double ds = PF::nrand(orbError),
		xn = m0.getOrigin().x(),
		yn = m0.getOrigin().y(),
		zn = m0.getOrigin().z();
	m0.setOrigin(tf::Vector3(xn, yn, zn));
	return m0;
}


/*
 * XXX: this motion model is untested !
 * Need to initialize velocity
 */
CamState OrbMapFusion::motionModel(const CamState &amp;vstate, const double &amp;t) const
{
	CamState nstate;

	double dt = t - prevTimestamp;
	double x = vstate.getOrigin().x() + vstate.velocity.x()*dt + PF::nrand(orbError);
	double y = vstate.getOrigin().y() + vstate.velocity.y()*dt + PF::nrand(orbError);
	double z = vstate.getOrigin().z() + vstate.velocity.z()*dt + PF::nrand(orbError);
	double vx = (x-vstate.getOrigin().x()) / dt;
	double vy = (y-vstate.getOrigin().y()) / dt;
	double vz = (z-vstate.getOrigin().z()) / dt;

	nstate.setOrigin(tf::Vector3(x, y, z));
	nstate.velocity = tf::Vector3 (vx, vy, vz);
	return nstate;
}


double OrbMapFusion::measurementModel(const CamState &amp;state, const vector&lt;tf::Transform&gt; &amp;observations) const
{
	vector&lt;double&gt; obsWeight;

	for (const auto &amp;pose: observations) {
		double wo,
			xt = pose.getOrigin().x(),
			yt = pose.getOrigin().y(),
			zt = pose.getOrigin().z(),
			xs = state.getOrigin().x(),
			ys = state.getOrigin().y(),
			zs = state.getOrigin().z();
		wo = exp (-(pow(xt-xs,2) / (2*orbError*orbError) +
			pow(yt-ys,2) / (2*orbError*orbError)));
		obsWeight.push_back(wo);
	}

	double w = *std::max_element(obsWeight.begin(), obsWeight.end());
	return max(w, 0.01);
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/mt/SystemMT.h" new_path="">
				<diff>@@ -1,136 +0,0 @@
-/*
- * SystemMT.h
- *
- *  Created on: Jul 22, 2016
- *      Author: sujiwo
- */
-
-#ifndef _SYSTEMMT_H_
-#define _SYSTEMMT_H_
-
-
-#include &lt;string&gt;
-#include &lt;vector&gt;
-#include &lt;mutex&gt;
-#include &lt;boost/thread.hpp&gt;
-
-#include &lt;tf/tf.h&gt;
-
-//#include &quot;System.h&quot;
-#include &quot;KeyFrameDatabase.h&quot;
-#include &quot;ORBVocabulary.h&quot;
-#include &quot;ParticleFilter.h&quot;
-#include &quot;../../__nodes/mt/TrackingThread.h&quot;
-
-//#include &lt;sensor_msgs/Image.h&gt;
-//#include &lt;sensor_msgs/image_encodings.h&gt;
-
-
-using namespace std;
-
-#define frameTimeout 0.1		// seconds
-#define NUMBER_OF_PARTICLE 500
-
-
-struct CamState : public tf::Transform
-{
-	CamState (const tf::Transform &amp;tfsc)
-	{
-		setOrigin(tfsc.getOrigin());
-		setRotation(tfsc.getRotation());
-		velocity.setX(0.0); velocity.setY(0.0); velocity.setZ(0.0);
-	}
-
-	CamState () {}
-
-	CamState (float dt[8])
-	{
-		setOrigin(tf::Vector3(dt[0], dt[1], dt[2]));
-		setRotation(tf::Quaternion(dt[3], dt[4], dt[5], dt[6]));
-		velocity.setX(0.0); velocity.setY(0.0); velocity.setZ(0.0);
-	}
-
-//	tfScalar&amp; x() { return getOrigin().m_floats[0]; }
-//	tfScalar&amp; y() { return getOrigin().m_floats[1]; }
-//	tfScalar&amp; z() { return getOrigin().m_floats[2]; }
-//	tfScalar&amp; qx() { return getRotation().m_floats[0]; }
-//	tfScalar&amp; qx() { return getRotation().m_floats[0]; }
-//	tfScalar&amp; qx() { return getRotation().m_floats[0]; }
-//	tfScalar&amp; qx() { return getRotation().m_floats[0]; }
-
-	// Velocity vector
-	tf::Vector3 velocity;
-};
-
-
-struct Motion: public tf::Vector3
-{
-Motion()
-{}
-
-public:
-	double timestamp;
-};
-
-
-class OrbMapFusion :
-	public PF::VehicleBase&lt;CamState, tf::Transform, double&gt;
-{
-public:
-	OrbMapFusion ();
-	void preinitialize (const tf::Transform &amp;initialPose, const double t);
-
-	CamState initializeParticleState () const;
-
-	CamState motionModel (const CamState &amp;vstate, const double &amp;v) const;
-
-	double measurementModel (const CamState &amp;state, const vector&lt;tf::Transform&gt; &amp;observations) const;
-
-	bool isInitialized () const { return initialized; }
-
-private:
-	tf::Transform initPose;
-	bool initialized;
-	double prevTimestamp;
-};
-
-
-
-class SystemMT
-{
-public:
-
-	SystemMT (ros::NodeHandle &amp;nh, const vector&lt;string&gt; &amp;mapPaths, const string &amp;vocabPath, const string &amp;settingsPath);
-	~SystemMT ();
-
-	void Track (const cv::Mat &amp;srcImage, const double timestamp);
-
-	const cv::FileStorage *getSettings () { return &amp;fSetting; }
-
-	friend class TrackingThread;
-
-private:
-	ros::NodeHandle &amp;rosnode;
-	vector&lt;TrackingThread*&gt; children;
-	ORB_SLAM2::ORBVocabulary *sVocab;
-	const string &amp;settingPath;
-
-	cv::FileStorage fSetting;
-
-	boost::barrier readyCheck;
-
-	// Monitor for localizer threads
-	boost::condition_variable imgMon;
-	boost::mutex imgLock;
-	volatile bool imgIsNew;
-
-	cv::Mat currentImage;
-	double currentTimestamp;
-
-	void filter ();
-
-	PF::ParticleFilter&lt;CamState, tf::Transform, double&gt; *pfilter;
-	OrbMapFusion vehicleModel;
-};
-
-#endif /* _SYSTEMMT_H_ */
</diff>
				<old_file>/*
 * SystemMT.h
 *
 *  Created on: Jul 22, 2016
 *      Author: sujiwo
 */

#ifndef _SYSTEMMT_H_
#define _SYSTEMMT_H_


#include &lt;string&gt;
#include &lt;vector&gt;
#include &lt;mutex&gt;
#include &lt;boost/thread.hpp&gt;

#include &lt;tf/tf.h&gt;

//#include &quot;System.h&quot;
#include &quot;KeyFrameDatabase.h&quot;
#include &quot;ORBVocabulary.h&quot;
#include &quot;ParticleFilter.h&quot;
#include &quot;../../__nodes/mt/TrackingThread.h&quot;

//#include &lt;sensor_msgs/Image.h&gt;
//#include &lt;sensor_msgs/image_encodings.h&gt;


using namespace std;

#define frameTimeout 0.1		// seconds
#define NUMBER_OF_PARTICLE 500


struct CamState : public tf::Transform
{
	CamState (const tf::Transform &amp;tfsc)
	{
		setOrigin(tfsc.getOrigin());
		setRotation(tfsc.getRotation());
		velocity.setX(0.0); velocity.setY(0.0); velocity.setZ(0.0);
	}

	CamState () {}

	CamState (float dt[8])
	{
		setOrigin(tf::Vector3(dt[0], dt[1], dt[2]));
		setRotation(tf::Quaternion(dt[3], dt[4], dt[5], dt[6]));
		velocity.setX(0.0); velocity.setY(0.0); velocity.setZ(0.0);
	}

//	tfScalar&amp; x() { return getOrigin().m_floats[0]; }
//	tfScalar&amp; y() { return getOrigin().m_floats[1]; }
//	tfScalar&amp; z() { return getOrigin().m_floats[2]; }
//	tfScalar&amp; qx() { return getRotation().m_floats[0]; }
//	tfScalar&amp; qx() { return getRotation().m_floats[0]; }
//	tfScalar&amp; qx() { return getRotation().m_floats[0]; }
//	tfScalar&amp; qx() { return getRotation().m_floats[0]; }

	// Velocity vector
	tf::Vector3 velocity;
};


struct Motion: public tf::Vector3
{
Motion()
{}

public:
	double timestamp;
};


class OrbMapFusion :
	public PF::VehicleBase&lt;CamState, tf::Transform, double&gt;
{
public:
	OrbMapFusion ();
	void preinitialize (const tf::Transform &amp;initialPose, const double t);

	CamState initializeParticleState () const;

	CamState motionModel (const CamState &amp;vstate, const double &amp;v) const;

	double measurementModel (const CamState &amp;state, const vector&lt;tf::Transform&gt; &amp;observations) const;

	bool isInitialized () const { return initialized; }

private:
	tf::Transform initPose;
	bool initialized;
	double prevTimestamp;
};



class SystemMT
{
public:

	SystemMT (ros::NodeHandle &amp;nh, const vector&lt;string&gt; &amp;mapPaths, const string &amp;vocabPath, const string &amp;settingsPath);
	~SystemMT ();

	void Track (const cv::Mat &amp;srcImage, const double timestamp);

	const cv::FileStorage *getSettings () { return &amp;fSetting; }

	friend class TrackingThread;

private:
	ros::NodeHandle &amp;rosnode;
	vector&lt;TrackingThread*&gt; children;
	ORB_SLAM2::ORBVocabulary *sVocab;
	const string &amp;settingPath;

	cv::FileStorage fSetting;

	boost::barrier readyCheck;

	// Monitor for localizer threads
	boost::condition_variable imgMon;
	boost::mutex imgLock;
	volatile bool imgIsNew;

	cv::Mat currentImage;
	double currentTimestamp;

	void filter ();

	PF::ParticleFilter&lt;CamState, tf::Transform, double&gt; *pfilter;
	OrbMapFusion vehicleModel;
};

#endif /* _SYSTEMMT_H_ */
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/mt/TrackingThread.cc" new_path="">
				<diff>@@ -1,125 +0,0 @@
-#include &quot;../../__nodes/mt/TrackingThread.h&quot;
-
-#include &quot;System.h&quot;
-// XXX: Refactor ImageGrabber.{cc,h}
-#include &lt;tf/tf.h&gt;
-#include &quot;../../__nodes/ImageGrabber.h&quot;
-#include &quot;../../__nodes/mt/DebugMT.h&quot;
-#include &quot;../../__nodes/mt/SystemMT.h&quot;
-
-
-using ORB_SLAM2::Map;
-using ORB_SLAM2::KeyFrameDatabase;
-using ORB_SLAM2::Tracking;
-using ORB_SLAM2::System;
-using ORB_SLAM2::FrameDrawer;
-
-
-
-TrackingThread::TrackingThread (const string &amp;mappath, SystemMT *sysmt, const string &amp;ids) :
-	sysParent (sysmt),
-	doStop (false),
-	mapFilename (mappath),
-	identity (ids),
-
-	parentFrame ((string)(sysmt-&gt;fSetting[&quot;ExternalLocalization.frame1&quot;])),
-	targetFrame ((string)(sysmt-&gt;fSetting[&quot;ExternalLocalization.frame2&quot;]) + &quot;/map&quot;+ids),
-
-	offsetKeyframeNum ( (int)sysmt-&gt;fSetting[&quot;ExternalLocalization.OffsetKeyframes&quot;] )
-{
-	tMap = new Map ();
-	kfdb = new KeyFrameDatabase (*sysParent-&gt;sVocab);
-	framedraw = new FrameDrawer (tMap);
-
-	debugger = new DebugMT (this, sysParent-&gt;rosnode, identity);
-
-	// start map loading from here
-	proc = new thread (&amp;TrackingThread::run, this);
-}
-
-
-TrackingThread::~TrackingThread()
-{
-	doStop = true;
-	proc-&gt;join ();
-	cout &lt;&lt; &quot;Localizer &quot; &lt;&lt; identity &lt;&lt; &quot; ended\n&quot;;
-}
-
-
-void TrackingThread::run ()
-{
-	tMap-&gt;loadFromDisk(mapFilename, kfdb);
-
-	tTrack = new Tracking (NULL, sysParent-&gt;sVocab, framedraw, NULL, tMap, kfdb, sysParent-&gt;settingPath, System::MONOCULAR);
-	tTrack-&gt;setMapLoaded();
-	tTrack-&gt;InformOnlyTracking(true);
-
-	cout &lt;&lt; &quot;Worker &quot; &lt;&lt; identity &lt;&lt; &quot; ready&quot; &lt;&lt; endl;
-	sysParent-&gt;readyCheck.wait();
-
-	while (true) {
-
-		{
-			boost::unique_lock&lt;boost::mutex&gt; lock (sysParent-&gt;imgLock);
-			while (sysParent-&gt;imgIsNew==false and doStop==false)
-				sysParent-&gt;imgMon.wait(lock);
-			if (doStop==true) {
-				cout &lt;&lt; &quot;Worker &quot; &lt;&lt; identity &lt;&lt; &quot; quit&quot; &lt;&lt; endl;
-				break;
-			}
-		}
-
-		tTrack-&gt;GrabImageMonocular(sysParent-&gt;currentImage, sysParent-&gt;currentTimestamp);
-		Frame &amp;cframe = tTrack-&gt;mCurrentFrame;
-		if (tTrack-&gt;mLastProcessedState==Tracking::OK) {
-
-			tf::Transform orbCPose = ImageGrabber::FramePose(&amp;cframe);
-			try {
-				tf::Transform cp = ImageGrabber::localizeByReference(orbCPose, tMap, offsetKeyframeNum);
-				currentPose.x = cp.getOrigin().x();
-				currentPose.y = cp.getOrigin().y();
-				currentPose.z = cp.getOrigin().z();
-				currentPose.qx = cp.getRotation().x();
-				currentPose.qy = cp.getRotation().y();
-				currentPose.qz = cp.getRotation().z();
-				currentPose.qw = cp.getRotation().w();
-			} catch (...) {
-				invalidPose;
-			}
-		}
-		else {
-			invalidPose;
-		}
-
-		// XXX: Do something useful here
-		debugger-&gt;notify();
-//		usleep(50000);
-
-		sysParent-&gt;readyCheck.wait();
-	}
-}
-
-
-void TrackingThread::stop()
-{
-	doStop = true;
-}
-
-
-void TrackingThread::output(cv::Mat &amp;out)
-{
-
-}
-
-
-double TrackingThread::getLastTime()
-{ return sysParent-&gt;currentTimestamp; }
-
-
-tf::Transform TrackingThread::getCurrent ()
-{
-	tf::Transform p;
-	p.setOrigin (tf::Vector3(currentPose.x, currentPose.y, currentPose.z));
-	p.setRotation(tf::Quaternion(currentPose.qx, currentPose.qy, currentPose.qz, currentPose.qw));
-	return p;
-}
</diff>
				<old_file>#include &quot;../../__nodes/mt/TrackingThread.h&quot;

#include &quot;System.h&quot;
// XXX: Refactor ImageGrabber.{cc,h}
#include &lt;tf/tf.h&gt;
#include &quot;../../__nodes/ImageGrabber.h&quot;
#include &quot;../../__nodes/mt/DebugMT.h&quot;
#include &quot;../../__nodes/mt/SystemMT.h&quot;


using ORB_SLAM2::Map;
using ORB_SLAM2::KeyFrameDatabase;
using ORB_SLAM2::Tracking;
using ORB_SLAM2::System;
using ORB_SLAM2::FrameDrawer;



TrackingThread::TrackingThread (const string &amp;mappath, SystemMT *sysmt, const string &amp;ids) :
	sysParent (sysmt),
	doStop (false),
	mapFilename (mappath),
	identity (ids),

	parentFrame ((string)(sysmt-&gt;fSetting[&quot;ExternalLocalization.frame1&quot;])),
	targetFrame ((string)(sysmt-&gt;fSetting[&quot;ExternalLocalization.frame2&quot;]) + &quot;/map&quot;+ids),

	offsetKeyframeNum ( (int)sysmt-&gt;fSetting[&quot;ExternalLocalization.OffsetKeyframes&quot;] )
{
	tMap = new Map ();
	kfdb = new KeyFrameDatabase (*sysParent-&gt;sVocab);
	framedraw = new FrameDrawer (tMap);

	debugger = new DebugMT (this, sysParent-&gt;rosnode, identity);

	// start map loading from here
	proc = new thread (&amp;TrackingThread::run, this);
}


TrackingThread::~TrackingThread()
{
	doStop = true;
	proc-&gt;join ();
	cout &lt;&lt; &quot;Localizer &quot; &lt;&lt; identity &lt;&lt; &quot; ended\n&quot;;
}


void TrackingThread::run ()
{
	tMap-&gt;loadFromDisk(mapFilename, kfdb);

	tTrack = new Tracking (NULL, sysParent-&gt;sVocab, framedraw, NULL, tMap, kfdb, sysParent-&gt;settingPath, System::MONOCULAR);
	tTrack-&gt;setMapLoaded();
	tTrack-&gt;InformOnlyTracking(true);

	cout &lt;&lt; &quot;Worker &quot; &lt;&lt; identity &lt;&lt; &quot; ready&quot; &lt;&lt; endl;
	sysParent-&gt;readyCheck.wait();

	while (true) {

		{
			boost::unique_lock&lt;boost::mutex&gt; lock (sysParent-&gt;imgLock);
			while (sysParent-&gt;imgIsNew==false and doStop==false)
				sysParent-&gt;imgMon.wait(lock);
			if (doStop==true) {
				cout &lt;&lt; &quot;Worker &quot; &lt;&lt; identity &lt;&lt; &quot; quit&quot; &lt;&lt; endl;
				break;
			}
		}

		tTrack-&gt;GrabImageMonocular(sysParent-&gt;currentImage, sysParent-&gt;currentTimestamp);
		Frame &amp;cframe = tTrack-&gt;mCurrentFrame;
		if (tTrack-&gt;mLastProcessedState==Tracking::OK) {

			tf::Transform orbCPose = ImageGrabber::FramePose(&amp;cframe);
			try {
				tf::Transform cp = ImageGrabber::localizeByReference(orbCPose, tMap, offsetKeyframeNum);
				currentPose.x = cp.getOrigin().x();
				currentPose.y = cp.getOrigin().y();
				currentPose.z = cp.getOrigin().z();
				currentPose.qx = cp.getRotation().x();
				currentPose.qy = cp.getRotation().y();
				currentPose.qz = cp.getRotation().z();
				currentPose.qw = cp.getRotation().w();
			} catch (...) {
				invalidPose;
			}
		}
		else {
			invalidPose;
		}

		// XXX: Do something useful here
		debugger-&gt;notify();
//		usleep(50000);

		sysParent-&gt;readyCheck.wait();
	}
}


void TrackingThread::stop()
{
	doStop = true;
}


void TrackingThread::output(cv::Mat &amp;out)
{

}


double TrackingThread::getLastTime()
{ return sysParent-&gt;currentTimestamp; }


tf::Transform TrackingThread::getCurrent ()
{
	tf::Transform p;
	p.setOrigin (tf::Vector3(currentPose.x, currentPose.y, currentPose.z));
	p.setRotation(tf::Quaternion(currentPose.qx, currentPose.qy, currentPose.qz, currentPose.qw));
	return p;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/mt/TrackingThread.h" new_path="">
				<diff>@@ -1,85 +0,0 @@
-#ifndef _TRACKING_THREAD_H
-#define _TRACKING_THREAD_H
-
-#include &lt;vector&gt;
-#include &lt;string&gt;
-#include &lt;thread&gt;
-#include &lt;condition_variable&gt;
-
-
-#include &quot;Tracking.h&quot;
-#include &quot;FrameDrawer.h&quot;
-
-#include &quot;../../__nodes/mt/DebugMT.h&quot;
-
-
-using namespace std;
-
-
-class SystemMT;
-
-
-class TrackingThread
-{
-public:
-
-	TrackingThread (const string &amp;mapFilename, SystemMT *_sysmt, const string &amp;ids);
-	~TrackingThread ();
-
-	void trackImage ();
-
-	void run ();
-	void stop ();
-
-	friend class SystemMT;
-	friend class DebugMT;
-
-private:
-	ORB_SLAM2::Map *tMap;
-	ORB_SLAM2::KeyFrameDatabase *kfdb;
-	ORB_SLAM2::Tracking *tTrack;
-	ORB_SLAM2::FrameDrawer *framedraw;
-
-	DebugMT *debugger;
-
-	const string mapFilename;
-	string identity;
-	const int offsetKeyframeNum;
-
-	const string parentFrame;
-	const string targetFrame;
-
-	SystemMT *sysParent;
-	volatile bool doStop;
-	thread *proc;
-
-	void output (cv::Mat &amp;trackOutput);
-
-	union {
-		struct {
-			float x, y, z, qx, qy, qz, qw;
-		};
-		float data[8];
-	} currentPose;
-
-	inline bool poseIsValid()
-	{
-		return !isnanf(currentPose.x)
-			and !isnanf(currentPose.y)
-			and !isnanf(currentPose.z)
-			and !isnanf(currentPose.qx)
-			and !isnanf(currentPose.qy)
-			and !isnanf(currentPose.qz)
-			and !isnanf(currentPose.qw);
-	}
-
-	tf::Transform getCurrent ();
-	double getLastTime ();
-};
-
-
-#define invalidPose \
-	for (auto __i=0; __i&lt;8; __i++) currentPose.data[__i] = NAN;
-
-
-#endif
</diff>
				<old_file>#ifndef _TRACKING_THREAD_H
#define _TRACKING_THREAD_H

#include &lt;vector&gt;
#include &lt;string&gt;
#include &lt;thread&gt;
#include &lt;condition_variable&gt;


#include &quot;Tracking.h&quot;
#include &quot;FrameDrawer.h&quot;

#include &quot;../../__nodes/mt/DebugMT.h&quot;


using namespace std;


class SystemMT;


class TrackingThread
{
public:

	TrackingThread (const string &amp;mapFilename, SystemMT *_sysmt, const string &amp;ids);
	~TrackingThread ();

	void trackImage ();

	void run ();
	void stop ();

	friend class SystemMT;
	friend class DebugMT;

private:
	ORB_SLAM2::Map *tMap;
	ORB_SLAM2::KeyFrameDatabase *kfdb;
	ORB_SLAM2::Tracking *tTrack;
	ORB_SLAM2::FrameDrawer *framedraw;

	DebugMT *debugger;

	const string mapFilename;
	string identity;
	const int offsetKeyframeNum;

	const string parentFrame;
	const string targetFrame;

	SystemMT *sysParent;
	volatile bool doStop;
	thread *proc;

	void output (cv::Mat &amp;trackOutput);

	union {
		struct {
			float x, y, z, qx, qy, qz, qw;
		};
		float data[8];
	} currentPose;

	inline bool poseIsValid()
	{
		return !isnanf(currentPose.x)
			and !isnanf(currentPose.y)
			and !isnanf(currentPose.z)
			and !isnanf(currentPose.qx)
			and !isnanf(currentPose.qy)
			and !isnanf(currentPose.qz)
			and !isnanf(currentPose.qw);
	}

	tf::Transform getCurrent ();
	double getLastTime ();
};


#define invalidPose \
	for (auto __i=0; __i&lt;8; __i++) currentPose.data[__i] = NAN;


#endif
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/mt/matching_mt.cc" new_path="">
				<diff>@@ -1,113 +0,0 @@
-#include &lt;vector&gt;
-#include &lt;thread&gt;
-#include &lt;string&gt;
-#include &lt;iostream&gt;
-
-#include &quot;Map.h&quot;
-#include &lt;ros/ros.h&gt;
-#include &lt;sensor_msgs/Image.h&gt;
-#include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;cv_bridge/cv_bridge.h&gt;
-#include &lt;image_transport/image_transport.h&gt;
-#include &quot;../../__nodes/mt/SystemMT.h&quot;
-#include &quot;../../__nodes/mt/TrackingThread.h&quot;
-
-
-
-using namespace std;
-namespace enc = sensor_msgs::image_encodings;
-
-
-
-SystemMT *localizer;
-
-
-
-
-
-void imageProcess (const sensor_msgs::ImageConstPtr&amp; msg)
-{
-	cv::Mat image;
-
-	// Copy the ros image message to cv::Mat.
-	cv_bridge::CvImageConstPtr cv_ptr;
-	try
-	{
-		cv_ptr = cv_bridge::toCvShare(msg);
-	}
-	catch (cv_bridge::Exception&amp; e)
-	{
-		ROS_ERROR(&quot;cv_bridge exception: %s&quot;, e.what());
-		return;
-	}
-
-	if (enc::isBayer(msg-&gt;encoding)) {
-		int code=-1;
-		if (msg-&gt;encoding == enc::BAYER_RGGB8 ||
-			msg-&gt;encoding == enc::BAYER_RGGB16) {
-			code = cv::COLOR_BayerBG2BGR;
-		}
-		else if (msg-&gt;encoding == enc::BAYER_BGGR8 ||
-				 msg-&gt;encoding == enc::BAYER_BGGR16) {
-			code = cv::COLOR_BayerRG2BGR;
-		}
-		else if (msg-&gt;encoding == enc::BAYER_GBRG8 ||
-				 msg-&gt;encoding == enc::BAYER_GBRG16) {
-			code = cv::COLOR_BayerGR2BGR;
-		}
-		else if (msg-&gt;encoding == enc::BAYER_GRBG8 ||
-				 msg-&gt;encoding == enc::BAYER_GRBG16) {
-			code = cv::COLOR_BayerGB2BGR;
-		}
-		cv::cvtColor(cv_ptr-&gt;image, image, code);
-	}
-	else
-		image = cv_ptr-&gt;image;
-
-	localizer-&gt;Track(image, msg-&gt;header.stamp.toSec());
-}
-
-
-
-int main (int argc, char *argv[])
-{
-	if (argc &lt; 3) {
-		cerr &lt;&lt; &quot;Usage: orb_matching_mt setting_file map1 &lt;map2&gt; ... &lt;map_n&gt;&quot; &lt;&lt; endl;
-		exit (-1);
-	}
-
-	const string settingPath = argv[1];
-	vector&lt;string&gt; mapPaths;
-	for (int i=2; i&lt;argc; i++) {
-		string mp = argv[i];
-		mapPaths.push_back(mp);
-	}
-
-    ros::init(argc, argv, &quot;orb_matching_mt&quot;);
-    ros::start();
-    ros::NodeHandle nodeHandler;
-
-    // This macro should be set by Cmake
-	string orbVocabFile (ORB_SLAM_VOCABULARY);
-
-	localizer = new SystemMT (nodeHandler, mapPaths, orbVocabFile, settingPath);
-
-	image_transport::TransportHints th;
-	const cv::FileStorage &amp;fsetting = *(localizer-&gt;getSettings());
-	if ((int)fsetting[&quot;Camera.compressed&quot;]==0) {
-		th = image_transport::TransportHints (&quot;raw&quot;);
-	}
-	else if ((int)fsetting[&quot;Camera.compressed&quot;]==1) {
-		th = image_transport::TransportHints (&quot;compressed&quot;);
-	}
-	image_transport::ImageTransport it (nodeHandler);
-	image_transport::Subscriber sub = it.subscribe ((string)fsetting[&quot;Camera.topic&quot;], 1, imageProcess, th);
-	cout &lt;&lt; endl &lt;&lt; &quot;Mono Camera topic: &quot; &lt;&lt; (string)fsetting[&quot;Camera.topic&quot;] &lt;&lt; endl;
-	cout &lt;&lt; &quot;Compressed images? &quot; &lt;&lt; ((int)fsetting[&quot;Camera.compressed&quot;]==1 ? &quot;True&quot; : &quot;False&quot;) &lt;&lt; endl;
-
-	ros::spin();
-	cout &lt;&lt; &quot;... Done&quot; &lt;&lt; endl;
-
-	delete (localizer);
-	return 0;
-}
</diff>
				<old_file>#include &lt;vector&gt;
#include &lt;thread&gt;
#include &lt;string&gt;
#include &lt;iostream&gt;

#include &quot;Map.h&quot;
#include &lt;ros/ros.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;image_transport/image_transport.h&gt;
#include &quot;../../__nodes/mt/SystemMT.h&quot;
#include &quot;../../__nodes/mt/TrackingThread.h&quot;



using namespace std;
namespace enc = sensor_msgs::image_encodings;



SystemMT *localizer;





void imageProcess (const sensor_msgs::ImageConstPtr&amp; msg)
{
	cv::Mat image;

	// Copy the ros image message to cv::Mat.
	cv_bridge::CvImageConstPtr cv_ptr;
	try
	{
		cv_ptr = cv_bridge::toCvShare(msg);
	}
	catch (cv_bridge::Exception&amp; e)
	{
		ROS_ERROR(&quot;cv_bridge exception: %s&quot;, e.what());
		return;
	}

	if (enc::isBayer(msg-&gt;encoding)) {
		int code=-1;
		if (msg-&gt;encoding == enc::BAYER_RGGB8 ||
			msg-&gt;encoding == enc::BAYER_RGGB16) {
			code = cv::COLOR_BayerBG2BGR;
		}
		else if (msg-&gt;encoding == enc::BAYER_BGGR8 ||
				 msg-&gt;encoding == enc::BAYER_BGGR16) {
			code = cv::COLOR_BayerRG2BGR;
		}
		else if (msg-&gt;encoding == enc::BAYER_GBRG8 ||
				 msg-&gt;encoding == enc::BAYER_GBRG16) {
			code = cv::COLOR_BayerGR2BGR;
		}
		else if (msg-&gt;encoding == enc::BAYER_GRBG8 ||
				 msg-&gt;encoding == enc::BAYER_GRBG16) {
			code = cv::COLOR_BayerGB2BGR;
		}
		cv::cvtColor(cv_ptr-&gt;image, image, code);
	}
	else
		image = cv_ptr-&gt;image;

	localizer-&gt;Track(image, msg-&gt;header.stamp.toSec());
}



int main (int argc, char *argv[])
{
	if (argc &lt; 3) {
		cerr &lt;&lt; &quot;Usage: orb_matching_mt setting_file map1 &lt;map2&gt; ... &lt;map_n&gt;&quot; &lt;&lt; endl;
		exit (-1);
	}

	const string settingPath = argv[1];
	vector&lt;string&gt; mapPaths;
	for (int i=2; i&lt;argc; i++) {
		string mp = argv[i];
		mapPaths.push_back(mp);
	}

    ros::init(argc, argv, &quot;orb_matching_mt&quot;);
    ros::start();
    ros::NodeHandle nodeHandler;

    // This macro should be set by Cmake
	string orbVocabFile (ORB_SLAM_VOCABULARY);

	localizer = new SystemMT (nodeHandler, mapPaths, orbVocabFile, settingPath);

	image_transport::TransportHints th;
	const cv::FileStorage &amp;fsetting = *(localizer-&gt;getSettings());
	if ((int)fsetting[&quot;Camera.compressed&quot;]==0) {
		th = image_transport::TransportHints (&quot;raw&quot;);
	}
	else if ((int)fsetting[&quot;Camera.compressed&quot;]==1) {
		th = image_transport::TransportHints (&quot;compressed&quot;);
	}
	image_transport::ImageTransport it (nodeHandler);
	image_transport::Subscriber sub = it.subscribe ((string)fsetting[&quot;Camera.topic&quot;], 1, imageProcess, th);
	cout &lt;&lt; endl &lt;&lt; &quot;Mono Camera topic: &quot; &lt;&lt; (string)fsetting[&quot;Camera.topic&quot;] &lt;&lt; endl;
	cout &lt;&lt; &quot;Compressed images? &quot; &lt;&lt; ((int)fsetting[&quot;Camera.compressed&quot;]==1 ? &quot;True&quot; : &quot;False&quot;) &lt;&lt; endl;

	ros::spin();
	cout &lt;&lt; &quot;... Done&quot; &lt;&lt; endl;

	delete (localizer);
	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/offline_offset.cc" new_path="">
				<diff>@@ -1,252 +0,0 @@
-/*
- * offline_offset.cc
- *
- *  Created on: Jun 5, 2016
- *      Author: sujiwo
- */
-
-
-#include &lt;iostream&gt;
-#include &lt;vector&gt;
-#include &lt;cstdlib&gt;
-#include &lt;cstdio&gt;
-
-#include &lt;rosbag/bag.h&gt;
-#include &lt;rosbag/view.h&gt;
-#include &lt;tf/tf.h&gt;
-#include &lt;tf/tfMessage.h&gt;
-#include &lt;tf/transform_datatypes.h&gt;
-#include &lt;boost/foreach.hpp&gt;
-
-#define PCL_NO_PRECOMPILE
-#include &lt;pcl/point_cloud.h&gt;
-#include &lt;pcl/octree/octree.h&gt;
-#include &lt;pcl/octree/impl/octree_search.hpp&gt;
-
-#include &quot;System.h&quot;
-#include &quot;Map.h&quot;
-#include &quot;KeyFrame.h&quot;
-#include &quot;../__nodes/ImageGrabber.h&quot;
-
-
-using namespace std;
-using ORB_SLAM2::System;
-using ORB_SLAM2::Map;
-using ORB_SLAM2::KeyFrame;
-
-
-#define foreach BOOST_FOREACH
-
-
-struct MapPt {
-	PCL_ADD_POINT4D;
-	uint32_t kfId;
-	EIGEN_MAKE_ALIGNED_OPERATOR_NEW
-} EIGEN_ALIGN16 ;
-
-
-struct FakeMap
-{
-    pcl::PointCloud&lt;MapPt&gt;::Ptr kfCloud;
-    pcl::octree::OctreePointCloudSearch&lt;MapPt&gt;::Ptr kfOctree;
-
-    vector&lt;tf::Transform&gt; orbPoints;
-    vector&lt;tf::Transform&gt; realPoints;
-
-	FakeMap (const string &amp;csvPath)
-	{
-		FILE *mapfd;
-		mapfd = fopen (csvPath.c_str(), &quot;r&quot;);
-		double
-			timestamp,
-			xo,
-			yo,
-			zo,
-			qxo,
-			qyo,
-			qzo,
-			qwo,
-			xr,
-			yr,
-			zr,
-			qxr,
-			qyr,
-			qzr,
-			qwr;
-		uint32_t pos = 0;
-
-		while (fscanf(mapfd, &quot;%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf&quot;,
-			&amp;timestamp,
-			&amp;xo,
-			&amp;yo,
-			&amp;zo,
-			&amp;qxo,
-			&amp;qyo,
-			&amp;qzo,
-			&amp;qwo,
-			&amp;xr,
-			&amp;yr,
-			&amp;zr,
-			&amp;qxr,
-			&amp;qyr,
-			&amp;qzr,
-			&amp;qwr) != EOF) {
-
-			tf::Transform orbPt, realMapPt;
-			orbPt.setOrigin(tf::Vector3(xo, yo, zo));
-			orbPt.setRotation(tf::Quaternion(qxo, qyo, qzo, qwo));
-			realMapPt.setOrigin(tf::Vector3(xr, yr, zr));
-			realMapPt.setRotation(tf::Quaternion(qxr, qyr, qzr, qwr));
-
-			orbPoints.push_back(orbPt);
-			realPoints.push_back(realMapPt);
-		}
-
-		fclose (mapfd);
-
-		kfCloud = pcl::PointCloud&lt;MapPt&gt;::Ptr (new pcl::PointCloud&lt;MapPt&gt;);
-		kfCloud-&gt;width = orbPoints.size();
-		kfCloud-&gt;height = 1;
-		kfCloud-&gt;resize(kfCloud-&gt;width);
-		for (int p=0; p&lt;orbPoints.size(); p++) {
-			const tf::Transform &amp;kf = orbPoints[p];
-			kfCloud-&gt;at(p).x = kf.getOrigin().x();
-			kfCloud-&gt;at(p).y = kf.getOrigin().y();
-			kfCloud-&gt;at(p).z = kf.getOrigin().z();
-			kfCloud-&gt;at(p).kfId = p;
-		}
-		kfOctree = pcl::octree::OctreePointCloudSearch&lt;MapPt&gt;::Ptr (new pcl::octree::OctreePointCloudSearch&lt;MapPt&gt; (1.0));
-		kfOctree-&gt;setInputCloud(kfCloud);
-		kfOctree-&gt;addPointsFromInputCloud();
-	}
-
-	int search (const double x, const double y, const double z,
-		tf::Transform &amp;orbMapPos, tf::Transform &amp;realMapPos)
-	{
-		MapPt queryPoint;
-		queryPoint.x = x, queryPoint.y = y, queryPoint.z = z;
-
-		const int k = 2;
-		vector&lt;int&gt; idcs;
-		vector&lt;float&gt; sqrDist;
-		idcs.resize(k);
-		sqrDist.resize(k);
-
-		int r = kfOctree-&gt;nearestKSearch(queryPoint, k, idcs, sqrDist);
-		if (r==0)
-			return -1;
-		uint32_t ptId = kfCloud-&gt;at(idcs[0]).kfId;
-		orbMapPos = orbMapAt (ptId);
-		realMapPos = realMapAt (ptId);
-		return ptId;
-	}
-
-	tf::Transform orbMapAt (const uint32_t &amp;i)
-	{ return orbPoints.at(i); }
-
-	tf::Transform realMapAt (const uint32_t &amp;i)
-	{ return realPoints.at(i); }
-
-};
-
-
-
-int main (int argc, char *argv[])
-{
-	FakeMap *fakeMap = NULL;
-	double secondToSkip = 0.0;
-
-	if (argc&lt;3) {
-		cout &lt;&lt; &quot;\nUsage:\n&quot;;
-		cout &lt;&lt; &quot;offline_offset path_to_settings orb_result_bag map_file [secondToSkip]\n&quot; &lt;&lt; endl;
-		exit(1);
-	}
-
-	string emptyStr;
-	System SLAM(emptyStr, argv[1], System::MONOCULAR,true, argv[3], System::LOCALIZATION);
-	Map *mapSrc = SLAM.getMap();
-	int offsetKeyframe = (int)SLAM.fsSettings[&quot;ExternalLocalization.OffsetKeyframes&quot;];
-
-	if (mapSrc-&gt;KeyFramesInMap()==0) {
-		fakeMap = new FakeMap (argv[3]);
-	}
-
-	if (argc&gt;=4)
-		secondToSkip = atof (argv[4]);
-
-	// Build ROSBag Query
-	rosbag::Bag bagSrc;
-	bagSrc.open (argv[2], rosbag::bagmode::Read);
-	rosbag::View viewx(bagSrc, rosbag::TopicQuery(&quot;/tf&quot;));
-	ros::Time startTime = viewx.getBeginTime();
-	startTime.sec += secondToSkip;
-	rosbag::View view(bagSrc, rosbag::TopicQuery(&quot;/tf&quot;), startTime);
-	cout &lt;&lt; &quot;Fetching...&quot; &lt;&lt; endl;
-
-	const string orbSrcFrame = &quot;/ORB_SLAM/World&quot;,
-		orbTgFrame = &quot;/ORB_SLAM/Camera&quot;;
-
-	// prepare Stdout
-    cout &lt;&lt; std::fixed &lt;&lt; setprecision(6);
-
-	foreach (rosbag::MessageInstance const msg, view) {
-
-		// take current position from bag
-		tf::tfMessageConstPtr curPosMsg = msg.instantiate&lt;tf::tfMessage&gt;();
-		const double timestamp = curPosMsg-&gt;transforms[0].header.stamp.toSec();
-
-		if (curPosMsg-&gt;transforms[0].header.frame_id != orbSrcFrame or
-				curPosMsg-&gt;transforms[0].child_frame_id != orbTgFrame)
-			continue;
-
-		// find keyframe position in map
-		tf::Transform
-			orbPos,
-			orbMapPos,
-			realMapPos,
-			realPos;
-
-		geometry_msgs::Transform pose = curPosMsg-&gt;transforms[0].transform;
-		double x = pose.translation.x,
-			y = pose.translation.y,
-			z = pose.translation.z;
-		orbPos.setOrigin(tf::Vector3(x, y, z));
-		orbPos.setRotation(tf::Quaternion(
-			pose.rotation.x,
-			pose.rotation.y,
-			pose.rotation.z,
-			pose.rotation.w));
-
-		if (fakeMap != NULL) {
-			int ptId = fakeMap-&gt;search(x, y, z, orbMapPos, realMapPos);
-			ptId -= offsetKeyframe;
-			if (ptId&lt;0)
-				continue;
-			tf::Transform orbMapOff = fakeMap-&gt;orbMapAt(ptId);
-			tf::Transform realMapOff = fakeMap-&gt;realMapAt(ptId);
-			realPos = ImageGrabber::localizeByReference(
-				orbPos,
-				orbMapPos, orbMapOff,
-				realMapPos, realMapOff);
-		}
-		else {
-			KeyFrame *kfReference = SLAM.getMap()-&gt;getNearestKeyFrame(x, y, z),
-				*kfOffset = SLAM.getMap()-&gt;offsetKeyframe(kfReference, offsetKeyframe);
-
-			orbMapPos = ImageGrabber::KeyFramePoseToTf(kfReference);
-			realMapPos = ImageGrabber::getKeyFrameExtPose(kfReference);
-			tf::Transform orbMapOff = ImageGrabber::KeyFramePoseToTf(kfOffset);
-		}
-
-		cout &lt;&lt; timestamp &lt;&lt; &quot; &quot; &lt;&lt; realPos.getOrigin().x() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getOrigin().y() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getOrigin().z() &lt;&lt; &quot; &quot;;
-		cout &lt;&lt; realPos.getRotation().x() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getRotation().y() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getRotation().z() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getRotation().w() &lt;&lt; endl;
-	}
-
-	SLAM.Shutdown();
-	if (fakeMap != NULL)
-		delete (fakeMap);
-	cout &lt;&lt; &quot;Done&quot; &lt;&lt; endl;
-	exit(0);
-}
-
-
</diff>
				<old_file>/*
 * offline_offset.cc
 *
 *  Created on: Jun 5, 2016
 *      Author: sujiwo
 */


#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;cstdlib&gt;
#include &lt;cstdio&gt;

#include &lt;rosbag/bag.h&gt;
#include &lt;rosbag/view.h&gt;
#include &lt;tf/tf.h&gt;
#include &lt;tf/tfMessage.h&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;boost/foreach.hpp&gt;

#define PCL_NO_PRECOMPILE
#include &lt;pcl/point_cloud.h&gt;
#include &lt;pcl/octree/octree.h&gt;
#include &lt;pcl/octree/impl/octree_search.hpp&gt;

#include &quot;System.h&quot;
#include &quot;Map.h&quot;
#include &quot;KeyFrame.h&quot;
#include &quot;../__nodes/ImageGrabber.h&quot;


using namespace std;
using ORB_SLAM2::System;
using ORB_SLAM2::Map;
using ORB_SLAM2::KeyFrame;


#define foreach BOOST_FOREACH


struct MapPt {
	PCL_ADD_POINT4D;
	uint32_t kfId;
	EIGEN_MAKE_ALIGNED_OPERATOR_NEW
} EIGEN_ALIGN16 ;


struct FakeMap
{
    pcl::PointCloud&lt;MapPt&gt;::Ptr kfCloud;
    pcl::octree::OctreePointCloudSearch&lt;MapPt&gt;::Ptr kfOctree;

    vector&lt;tf::Transform&gt; orbPoints;
    vector&lt;tf::Transform&gt; realPoints;

	FakeMap (const string &amp;csvPath)
	{
		FILE *mapfd;
		mapfd = fopen (csvPath.c_str(), &quot;r&quot;);
		double
			timestamp,
			xo,
			yo,
			zo,
			qxo,
			qyo,
			qzo,
			qwo,
			xr,
			yr,
			zr,
			qxr,
			qyr,
			qzr,
			qwr;
		uint32_t pos = 0;

		while (fscanf(mapfd, &quot;%lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf %lf&quot;,
			&amp;timestamp,
			&amp;xo,
			&amp;yo,
			&amp;zo,
			&amp;qxo,
			&amp;qyo,
			&amp;qzo,
			&amp;qwo,
			&amp;xr,
			&amp;yr,
			&amp;zr,
			&amp;qxr,
			&amp;qyr,
			&amp;qzr,
			&amp;qwr) != EOF) {

			tf::Transform orbPt, realMapPt;
			orbPt.setOrigin(tf::Vector3(xo, yo, zo));
			orbPt.setRotation(tf::Quaternion(qxo, qyo, qzo, qwo));
			realMapPt.setOrigin(tf::Vector3(xr, yr, zr));
			realMapPt.setRotation(tf::Quaternion(qxr, qyr, qzr, qwr));

			orbPoints.push_back(orbPt);
			realPoints.push_back(realMapPt);
		}

		fclose (mapfd);

		kfCloud = pcl::PointCloud&lt;MapPt&gt;::Ptr (new pcl::PointCloud&lt;MapPt&gt;);
		kfCloud-&gt;width = orbPoints.size();
		kfCloud-&gt;height = 1;
		kfCloud-&gt;resize(kfCloud-&gt;width);
		for (int p=0; p&lt;orbPoints.size(); p++) {
			const tf::Transform &amp;kf = orbPoints[p];
			kfCloud-&gt;at(p).x = kf.getOrigin().x();
			kfCloud-&gt;at(p).y = kf.getOrigin().y();
			kfCloud-&gt;at(p).z = kf.getOrigin().z();
			kfCloud-&gt;at(p).kfId = p;
		}
		kfOctree = pcl::octree::OctreePointCloudSearch&lt;MapPt&gt;::Ptr (new pcl::octree::OctreePointCloudSearch&lt;MapPt&gt; (1.0));
		kfOctree-&gt;setInputCloud(kfCloud);
		kfOctree-&gt;addPointsFromInputCloud();
	}

	int search (const double x, const double y, const double z,
		tf::Transform &amp;orbMapPos, tf::Transform &amp;realMapPos)
	{
		MapPt queryPoint;
		queryPoint.x = x, queryPoint.y = y, queryPoint.z = z;

		const int k = 2;
		vector&lt;int&gt; idcs;
		vector&lt;float&gt; sqrDist;
		idcs.resize(k);
		sqrDist.resize(k);

		int r = kfOctree-&gt;nearestKSearch(queryPoint, k, idcs, sqrDist);
		if (r==0)
			return -1;
		uint32_t ptId = kfCloud-&gt;at(idcs[0]).kfId;
		orbMapPos = orbMapAt (ptId);
		realMapPos = realMapAt (ptId);
		return ptId;
	}

	tf::Transform orbMapAt (const uint32_t &amp;i)
	{ return orbPoints.at(i); }

	tf::Transform realMapAt (const uint32_t &amp;i)
	{ return realPoints.at(i); }

};



int main (int argc, char *argv[])
{
	FakeMap *fakeMap = NULL;
	double secondToSkip = 0.0;

	if (argc&lt;3) {
		cout &lt;&lt; &quot;\nUsage:\n&quot;;
		cout &lt;&lt; &quot;offline_offset path_to_settings orb_result_bag map_file [secondToSkip]\n&quot; &lt;&lt; endl;
		exit(1);
	}

	string emptyStr;
	System SLAM(emptyStr, argv[1], System::MONOCULAR,true, argv[3], System::LOCALIZATION);
	Map *mapSrc = SLAM.getMap();
	int offsetKeyframe = (int)SLAM.fsSettings[&quot;ExternalLocalization.OffsetKeyframes&quot;];

	if (mapSrc-&gt;KeyFramesInMap()==0) {
		fakeMap = new FakeMap (argv[3]);
	}

	if (argc&gt;=4)
		secondToSkip = atof (argv[4]);

	// Build ROSBag Query
	rosbag::Bag bagSrc;
	bagSrc.open (argv[2], rosbag::bagmode::Read);
	rosbag::View viewx(bagSrc, rosbag::TopicQuery(&quot;/tf&quot;));
	ros::Time startTime = viewx.getBeginTime();
	startTime.sec += secondToSkip;
	rosbag::View view(bagSrc, rosbag::TopicQuery(&quot;/tf&quot;), startTime);
	cout &lt;&lt; &quot;Fetching...&quot; &lt;&lt; endl;

	const string orbSrcFrame = &quot;/ORB_SLAM/World&quot;,
		orbTgFrame = &quot;/ORB_SLAM/Camera&quot;;

	// prepare Stdout
    cout &lt;&lt; std::fixed &lt;&lt; setprecision(6);

	foreach (rosbag::MessageInstance const msg, view) {

		// take current position from bag
		tf::tfMessageConstPtr curPosMsg = msg.instantiate&lt;tf::tfMessage&gt;();
		const double timestamp = curPosMsg-&gt;transforms[0].header.stamp.toSec();

		if (curPosMsg-&gt;transforms[0].header.frame_id != orbSrcFrame or
				curPosMsg-&gt;transforms[0].child_frame_id != orbTgFrame)
			continue;

		// find keyframe position in map
		tf::Transform
			orbPos,
			orbMapPos,
			realMapPos,
			realPos;

		geometry_msgs::Transform pose = curPosMsg-&gt;transforms[0].transform;
		double x = pose.translation.x,
			y = pose.translation.y,
			z = pose.translation.z;
		orbPos.setOrigin(tf::Vector3(x, y, z));
		orbPos.setRotation(tf::Quaternion(
			pose.rotation.x,
			pose.rotation.y,
			pose.rotation.z,
			pose.rotation.w));

		if (fakeMap != NULL) {
			int ptId = fakeMap-&gt;search(x, y, z, orbMapPos, realMapPos);
			ptId -= offsetKeyframe;
			if (ptId&lt;0)
				continue;
			tf::Transform orbMapOff = fakeMap-&gt;orbMapAt(ptId);
			tf::Transform realMapOff = fakeMap-&gt;realMapAt(ptId);
			realPos = ImageGrabber::localizeByReference(
				orbPos,
				orbMapPos, orbMapOff,
				realMapPos, realMapOff);
		}
		else {
			KeyFrame *kfReference = SLAM.getMap()-&gt;getNearestKeyFrame(x, y, z),
				*kfOffset = SLAM.getMap()-&gt;offsetKeyframe(kfReference, offsetKeyframe);

			orbMapPos = ImageGrabber::KeyFramePoseToTf(kfReference);
			realMapPos = ImageGrabber::getKeyFrameExtPose(kfReference);
			tf::Transform orbMapOff = ImageGrabber::KeyFramePoseToTf(kfOffset);
		}

		cout &lt;&lt; timestamp &lt;&lt; &quot; &quot; &lt;&lt; realPos.getOrigin().x() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getOrigin().y() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getOrigin().z() &lt;&lt; &quot; &quot;;
		cout &lt;&lt; realPos.getRotation().x() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getRotation().y() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getRotation().z() &lt;&lt; &quot; &quot; &lt;&lt; realPos.getRotation().w() &lt;&lt; endl;
	}

	SLAM.Shutdown();
	if (fakeMap != NULL)
		delete (fakeMap);
	cout &lt;&lt; &quot;Done&quot; &lt;&lt; endl;
	exit(0);
}


</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/utils.cc" new_path="">
				<diff>@@ -1,155 +0,0 @@
-#include &quot;../__nodes/utils.h&quot;
-
-#include &lt;boost/foreach.hpp&gt;
-#include &lt;rosbag/view.h&gt;
-#include &lt;tf/tfMessage.h&gt;
-#include &lt;geometry_msgs/TransformStamped.h&gt;
-#include &lt;iostream&gt;
-
-
-#define foreach BOOST_FOREACH
-
-
-using std::cout;
-using std::endl;
-
-
-void tfToCV(const tf::Transform &amp;src, cv::Mat &amp;position, cv::Mat &amp;orientation)
-{
-	position = cv::Mat (3,1,CV_64F);
-	tf::Vector3 p = src.getOrigin();
-	position.at&lt;double&gt;(0) = p.x(),
-		position.at&lt;double&gt;(1) = p.y(),
-		position.at&lt;double&gt;(2) = p.z();
-
-	orientation = cv::Mat (4,1,CV_64F);
-	tf::Quaternion otn = src.getRotation();
-	orientation.at&lt;double&gt;(0) = otn.x(),
-		orientation.at&lt;double&gt;(1) = otn.y(),
-		orientation.at&lt;double&gt;(2) = otn.z(),
-		orientation.at&lt;double&gt;(3) = otn.w();
-}
-
-
-TfTimeTree::TfTimeTree(const string &amp;bagSrcPath, const string &amp;fromFrame, const string &amp;toFrame, const tf::Transform &amp;shift) :
-	curpoint(INT_MAX),
-	root (NULL)
-{
-	rosbag::Bag bfg(bagSrcPath);
-	rosbag::View view(bfg, rosbag::TopicQuery(string(&quot;/tf&quot;)));
-
-	foreach (rosbag::MessageInstance m, view) {
-		tf::tfMessageConstPtr tfm = m.instantiate&lt;tf::tfMessage&gt;();
-
-		if (tfm-&gt;transforms[0].header.frame_id != fromFrame or
-			tfm-&gt;transforms[0].child_frame_id != toFrame)
-			continue;
-
-		double timeMsg = tfm-&gt;transforms[0].header.stamp.toSec();
-
-		tf::Transform ctf;
-		ctf.setOrigin(tf::Vector3(
-			tfm-&gt;transforms[0].transform.translation.x,
-			tfm-&gt;transforms[0].transform.translation.y,
-			tfm-&gt;transforms[0].transform.translation.z
-		));
-		ctf.setRotation(tf::Quaternion(
-			tfm-&gt;transforms[0].transform.rotation.x,
-			tfm-&gt;transforms[0].transform.rotation.y,
-			tfm-&gt;transforms[0].transform.rotation.z,
-			tfm-&gt;transforms[0].transform.rotation.w
-		));
-
-		Node cn(ctf, timeMsg);
-		allNodes.push_back(cn);
-//		insert (ctf, timeMsg);
-//		i ++;
-	}
-
-	cout &lt;&lt; std::fixed &lt;&lt; &quot;From: &quot; &lt;&lt; std::setprecision(7) &lt;&lt; allNodes[0].timevalue &lt;&lt; &quot; to &quot; &lt;&lt; allNodes.back().timevalue &lt;&lt; endl;
-	cout &lt;&lt; &quot;Length: &quot; &lt;&lt; allNodes.size() &lt;&lt; endl;
-}
-
-
-const tf::Transform&amp; TfTimeTree::search(const double timestamp, float timeTolerance)
-{
-//	Node *cnode = root;
-//	while (cnode != NULL) {
-//		if (abs(cnode-&gt;timevalue-timeTolerance)&lt;timeTolerance)
-//			return cnode-&gt;transform;
-//		else if (cnode-&gt;timevalue &lt; timestamp)
-//			cnode = cnode-&gt;right;
-//		else
-//			cnode = cnode-&gt;left;
-//	}
-//	if (cnode==NULL)
-//		throw std::out_of_range(&quot;Outside range&quot;);
-
-	if (timestamp &lt; allNodes[0].timevalue)
-		throw std::out_of_range(&quot;Less than minimum&quot;);
-	if (timestamp &gt; allNodes.back().timevalue)
-		throw std::out_of_range(&quot;Outside maximum&quot;);
-
-	uint32_t start = (curpoint==INT_MAX ? 0 : curpoint);
-
-	for (uint32_t i=start; i&lt;allNodes.size(); i++) {
-		Node &amp;n = allNodes[i];
-		if (n.timevalue &gt; timestamp) {
-			if (abs(allNodes[i-1].timevalue - timestamp) &lt; abs(n.timevalue-timestamp)) {
-				curpoint = i-1;
-			}
-			else {
-				curpoint = i;
-			}
-			break;
-		}
-	}
-	return allNodes[curpoint].transform;
-}
-
-
-const tf::Transform&amp; TfTimeTree::search(const ros::Time &amp;time, float timeTolerance)
-{
-	double ts = time.toSec();
-	return search(ts, timeTolerance);
-}
-
-
-void TfTimeTree::insert (const tf::Transform &amp;n, double &amp;ts)
-{
-	Node _cnode(n, ts);
-	allNodes.push_back(_cnode);
-	Node *cnode = &amp;(allNodes.back());
-
-	if (root==NULL) {
-		root = cnode;
-		return;
-	}
-
-	Node *current = root;
-	while (current != NULL) {
-
-		if (cnode-&gt;timevalue &lt; current-&gt;timevalue) {
-			if (current-&gt;left==NULL) {
-				current-&gt;left = cnode;
-				cnode-&gt;left = NULL;
-				cnode-&gt;right = NULL;
-				current = NULL;
-			}
-			else {
-				current = current-&gt;left;
-			}
-		}
-		else {
-			if (current-&gt;right==NULL) {
-				current-&gt;right = cnode;
-				cnode-&gt;left = NULL;
-				cnode-&gt;right = NULL;
-				current = NULL;
-			}
-			else {
-				current = current-&gt;right;
-			}
-		}
-	}
-}
</diff>
				<old_file>#include &quot;../__nodes/utils.h&quot;

#include &lt;boost/foreach.hpp&gt;
#include &lt;rosbag/view.h&gt;
#include &lt;tf/tfMessage.h&gt;
#include &lt;geometry_msgs/TransformStamped.h&gt;
#include &lt;iostream&gt;


#define foreach BOOST_FOREACH


using std::cout;
using std::endl;


void tfToCV(const tf::Transform &amp;src, cv::Mat &amp;position, cv::Mat &amp;orientation)
{
	position = cv::Mat (3,1,CV_64F);
	tf::Vector3 p = src.getOrigin();
	position.at&lt;double&gt;(0) = p.x(),
		position.at&lt;double&gt;(1) = p.y(),
		position.at&lt;double&gt;(2) = p.z();

	orientation = cv::Mat (4,1,CV_64F);
	tf::Quaternion otn = src.getRotation();
	orientation.at&lt;double&gt;(0) = otn.x(),
		orientation.at&lt;double&gt;(1) = otn.y(),
		orientation.at&lt;double&gt;(2) = otn.z(),
		orientation.at&lt;double&gt;(3) = otn.w();
}


TfTimeTree::TfTimeTree(const string &amp;bagSrcPath, const string &amp;fromFrame, const string &amp;toFrame, const tf::Transform &amp;shift) :
	curpoint(INT_MAX),
	root (NULL)
{
	rosbag::Bag bfg(bagSrcPath);
	rosbag::View view(bfg, rosbag::TopicQuery(string(&quot;/tf&quot;)));

	foreach (rosbag::MessageInstance m, view) {
		tf::tfMessageConstPtr tfm = m.instantiate&lt;tf::tfMessage&gt;();

		if (tfm-&gt;transforms[0].header.frame_id != fromFrame or
			tfm-&gt;transforms[0].child_frame_id != toFrame)
			continue;

		double timeMsg = tfm-&gt;transforms[0].header.stamp.toSec();

		tf::Transform ctf;
		ctf.setOrigin(tf::Vector3(
			tfm-&gt;transforms[0].transform.translation.x,
			tfm-&gt;transforms[0].transform.translation.y,
			tfm-&gt;transforms[0].transform.translation.z
		));
		ctf.setRotation(tf::Quaternion(
			tfm-&gt;transforms[0].transform.rotation.x,
			tfm-&gt;transforms[0].transform.rotation.y,
			tfm-&gt;transforms[0].transform.rotation.z,
			tfm-&gt;transforms[0].transform.rotation.w
		));

		Node cn(ctf, timeMsg);
		allNodes.push_back(cn);
//		insert (ctf, timeMsg);
//		i ++;
	}

	cout &lt;&lt; std::fixed &lt;&lt; &quot;From: &quot; &lt;&lt; std::setprecision(7) &lt;&lt; allNodes[0].timevalue &lt;&lt; &quot; to &quot; &lt;&lt; allNodes.back().timevalue &lt;&lt; endl;
	cout &lt;&lt; &quot;Length: &quot; &lt;&lt; allNodes.size() &lt;&lt; endl;
}


const tf::Transform&amp; TfTimeTree::search(const double timestamp, float timeTolerance)
{
//	Node *cnode = root;
//	while (cnode != NULL) {
//		if (abs(cnode-&gt;timevalue-timeTolerance)&lt;timeTolerance)
//			return cnode-&gt;transform;
//		else if (cnode-&gt;timevalue &lt; timestamp)
//			cnode = cnode-&gt;right;
//		else
//			cnode = cnode-&gt;left;
//	}
//	if (cnode==NULL)
//		throw std::out_of_range(&quot;Outside range&quot;);

	if (timestamp &lt; allNodes[0].timevalue)
		throw std::out_of_range(&quot;Less than minimum&quot;);
	if (timestamp &gt; allNodes.back().timevalue)
		throw std::out_of_range(&quot;Outside maximum&quot;);

	uint32_t start = (curpoint==INT_MAX ? 0 : curpoint);

	for (uint32_t i=start; i&lt;allNodes.size(); i++) {
		Node &amp;n = allNodes[i];
		if (n.timevalue &gt; timestamp) {
			if (abs(allNodes[i-1].timevalue - timestamp) &lt; abs(n.timevalue-timestamp)) {
				curpoint = i-1;
			}
			else {
				curpoint = i;
			}
			break;
		}
	}
	return allNodes[curpoint].transform;
}


const tf::Transform&amp; TfTimeTree::search(const ros::Time &amp;time, float timeTolerance)
{
	double ts = time.toSec();
	return search(ts, timeTolerance);
}


void TfTimeTree::insert (const tf::Transform &amp;n, double &amp;ts)
{
	Node _cnode(n, ts);
	allNodes.push_back(_cnode);
	Node *cnode = &amp;(allNodes.back());

	if (root==NULL) {
		root = cnode;
		return;
	}

	Node *current = root;
	while (current != NULL) {

		if (cnode-&gt;timevalue &lt; current-&gt;timevalue) {
			if (current-&gt;left==NULL) {
				current-&gt;left = cnode;
				cnode-&gt;left = NULL;
				cnode-&gt;right = NULL;
				current = NULL;
			}
			else {
				current = current-&gt;left;
			}
		}
		else {
			if (current-&gt;right==NULL) {
				current-&gt;right = cnode;
				cnode-&gt;left = NULL;
				cnode-&gt;right = NULL;
				current = NULL;
			}
			else {
				current = current-&gt;right;
			}
		}
	}
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/orb_localizer/src/__nodes/utils.h" new_path="">
				<diff>@@ -1,57 +0,0 @@
-
-#ifndef _ORB_UTILS_H
-#define _ORB_UTILS_H 1
-
-#include &lt;tf/tf.h&gt;
-#include &lt;opencv2/core/core.hpp&gt;
-#include &lt;rosbag/bag.h&gt;
-#include &lt;string&gt;
-#include &lt;vector&gt;
-#include &lt;exception&gt;
-
-
-using std::string;
-using std::vector;
-using std::exception;
-
-
-void tfToCV(const tf::Transform &amp;src, cv::Mat &amp;position, cv::Mat &amp;orientation);
-
-
-
-class TfTimeTree
-{
-public:
-	TfTimeTree (const string &amp;bagSrcPath, const string &amp;fromFrame, const string &amp;toFrame, const tf::Transform &amp;shift=tf::Transform());
-	const tf::Transform&amp; search(const double timestamp, float timeTolerance=0.1);
-	const tf::Transform&amp; search(const ros::Time &amp;time, float timeTolerance=0.1);
-
-	class time_not_found: public std::out_of_range {};
-
-private:
-
-	void insert (const tf::Transform &amp;n, double &amp;ts);
-
-	struct Node {
-		tf::Transform transform;
-		double timevalue;
-		Node *left, *right;
-
-//		Node (tf::Transform &amp;tsrc, double t) :
-//			transform(tsrc),
-//			timevalue(t),
-//			left(NULL), right(NULL) {}
-
-		Node (const tf::Transform &amp;tsrc, double t, Node *l=NULL, Node *r=NULL) :
-			transform(tsrc),
-			timevalue(t),
-			left(l), right(r) {}
-	};
-	vector&lt;Node&gt; allNodes;
-	uint32_t curpoint;
-
-	Node *root;
-};
-
-
-#endif /* _ORB_UTILS_H */
</diff>
				<old_file>
#ifndef _ORB_UTILS_H
#define _ORB_UTILS_H 1

#include &lt;tf/tf.h&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;rosbag/bag.h&gt;
#include &lt;string&gt;
#include &lt;vector&gt;
#include &lt;exception&gt;


using std::string;
using std::vector;
using std::exception;


void tfToCV(const tf::Transform &amp;src, cv::Mat &amp;position, cv::Mat &amp;orientation);



class TfTimeTree
{
public:
	TfTimeTree (const string &amp;bagSrcPath, const string &amp;fromFrame, const string &amp;toFrame, const tf::Transform &amp;shift=tf::Transform());
	const tf::Transform&amp; search(const double timestamp, float timeTolerance=0.1);
	const tf::Transform&amp; search(const ros::Time &amp;time, float timeTolerance=0.1);

	class time_not_found: public std::out_of_range {};

private:

	void insert (const tf::Transform &amp;n, double &amp;ts);

	struct Node {
		tf::Transform transform;
		double timevalue;
		Node *left, *right;

//		Node (tf::Transform &amp;tsrc, double t) :
//			transform(tsrc),
//			timevalue(t),
//			left(NULL), right(NULL) {}

		Node (const tf::Transform &amp;tsrc, double t, Node *l=NULL, Node *r=NULL) :
			transform(tsrc),
			timevalue(t),
			left(l), right(r) {}
	};
	vector&lt;Node&gt; allNodes;
	uint32_t curpoint;

	Node *root;
};


#endif /* _ORB_UTILS_H */
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="152d4202cc625d5a33842f74afad674ffe906f98" fix_time="38,2970">
		<msg>Fix compile error regarding kitty_player

* Change compile flag from `-std=c++0x` to `-std=c++11` as `c++0x` seems to be deprecated later than GCC ver4.7
* Fix `ROS_ERROR_STREAM` usages as `&lt;&lt;` operator in `ROS_ERROR_STREAM` doesn't seem to be able to use with ifstream directly</msg>
		<modified_files>
			<file old_path="ros/src/util/packages/kitti_pkg/kitti_player/src/kitti_player.cpp" new_path="ros/src/util/packages/kitti_pkg/kitti_player/src/kitti_player.cpp">
				<diff>@@ -1073,7 +1073,9 @@ int main(int argc, char **argv)
                 ifstream timestamps(str_support.c_str());
                 if (!timestamps.is_open())
                 {
-                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
+                    string timestamps_string;
+                    timestamps &gt;&gt; timestamps_string;
+                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps_string);
                     node.shutdown();
                     return -1;
                 }
@@ -1097,7 +1099,9 @@ int main(int argc, char **argv)
                 ifstream timestamps(str_support.c_str());
                 if (!timestamps.is_open())
                 {
-                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
+                    string timestamps_string;
+                    timestamps &gt;&gt; timestamps_string;
+                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps_string);
                     node.shutdown();
                     return -1;
                 }
@@ -1154,7 +1158,9 @@ int main(int argc, char **argv)
                 ifstream timestamps(str_support.c_str());
                 if (!timestamps.is_open())
                 {
-                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
+                    string timestamps_string;
+                    timestamps &gt;&gt; timestamps_string;
+                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps_string);
                     node.shutdown();
                     return -1;
                 }
@@ -1178,7 +1184,9 @@ int main(int argc, char **argv)
                 ifstream timestamps(str_support.c_str());
                 if (!timestamps.is_open())
                 {
-                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
+                    string timestamps_string;
+                    timestamps &gt;&gt; timestamps_string;
+                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps_string);
                     node.shutdown();
                     return -1;
                 }
@@ -1208,7 +1216,9 @@ int main(int argc, char **argv)
                 ifstream timestamps(str_support.c_str());
                 if (!timestamps.is_open())
                 {
-                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
+                    string timestamps_string;
+                    timestamps &gt;&gt; timestamps_string;
+                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps_string);
                     node.shutdown();
                     return -1;
                 }
@@ -1230,7 +1240,9 @@ int main(int argc, char **argv)
                 ifstream timestamps(str_support.c_str());
                 if (!timestamps.is_open())
                 {
-                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
+                    string timestamps_string;
+                    timestamps &gt;&gt; timestamps_string;
+                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps_string);
                     node.shutdown();
                     return -1;
                 }
@@ -1269,7 +1281,9 @@ int main(int argc, char **argv)
                 ifstream timestamps(str_support.c_str());
                 if (!timestamps.is_open())
                 {
-                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
+                    string timestamps_string;
+                    timestamps &gt;&gt; timestamps_string;
+                     ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps_string);
                     node.shutdown();
                     return -1;
                 }
</diff>
				<old_file>// redmine usage: This commit refs #388 @2h

// ###############################################################################################
// ###############################################################################################
// ###############################################################################################

/*
 * KITTI_PLAYER v2.
 *
 * Augusto Luis Ballardini, ballardini@disco.unimib.it
 *
 * https://github.com/iralabdisco/kitti_player
 *
 * WARNING: this package is using some C++11
 *
 */

// ###############################################################################################
// ###############################################################################################
// ###############################################################################################

#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;limits&gt;
#include &lt;sstream&gt;
#include &lt;string&gt;
#include &lt;ros/ros.h&gt;
#include &lt;boost/algorithm/string.hpp&gt;
#include &lt;boost/lexical_cast.hpp&gt;
//#include &lt;boost/locale.hpp&gt;
#include &lt;boost/program_options.hpp&gt;
#include &lt;boost/progress.hpp&gt;
#include &lt;boost/tokenizer.hpp&gt;
#include &lt;boost/tokenizer.hpp&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;image_transport/image_transport.h&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl_ros/point_cloud.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;sensor_msgs/distortion_models.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;sensor_msgs/Imu.h&gt;
#include &lt;sensor_msgs/NavSatFix.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;stereo_msgs/DisparityImage.h&gt;
#include &lt;tf/LinearMath/Transform.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;time.h&gt;

/// EXTRA messages, not from KITTI
/// Inser here further detectors &amp; features to be published
//#include &lt;road_layout_estimation/msg_lines.h&gt;
//#include &lt;road_layout_estimation/msg_lineInfo.h&gt;

using namespace std;
using namespace pcl;
using namespace ros;
using namespace tf;

namespace po = boost::program_options;

struct kitti_player_options
{
    string  path;
    float   frequency;        // publisher frequency. 1 &gt; Kitti default 10Hz
    bool    all_data;         // publish everything
    bool    velodyne;         // publish velodyne point clouds /as PCL
    bool    gps;              // publish GPS sensor_msgs/NavSatFix    message
    bool    imu;              // publish IMU sensor_msgs/Imu Message  message
    bool    grayscale;        // publish
    bool    color;            // publish
    bool    viewer;           // enable CV viewer
    bool    timestamps;       // use KITTI timestamps;
    bool    sendTransform;    // publish velodyne TF IMU 3DOF orientation wrt fixed frame
    bool    stereoDisp;       // use precalculated stereoDisparities
    bool    viewDisparities;  // view use precalculated stereoDisparities
    unsigned int startFrame;  // start the replay at frame ...

    /// Extra parameters
    bool    laneDetections;   // send laneDetections;
};

/**
 * @brief publish_velodyne
 * @param pub The ROS publisher as reference
 * @param infile file with data to publish
 * @param header Header to use to publish the message
 * @return 1 if file is correctly readed, 0 otherwise
 */
int publish_velodyne(ros::Publisher &amp;pub, string infile, std_msgs::Header *header)
{
    fstream input(infile.c_str(), ios::in | ios::binary);
    if(!input.good())
    {
        ROS_ERROR_STREAM ( &quot;Could not read file: &quot; &lt;&lt; infile );
        return 0;
    }
    else
    {
        ROS_DEBUG_STREAM (&quot;reading &quot; &lt;&lt; infile);
        input.seekg(0, ios::beg);

        pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr points (new pcl::PointCloud&lt;pcl::PointXYZI&gt;);

        int i;
        for (i=0; input.good() &amp;&amp; !input.eof(); i++) {
            pcl::PointXYZI point;
            input.read((char *) &amp;point.x, 3*sizeof(float));
            input.read((char *) &amp;point.intensity, sizeof(float));
            points-&gt;push_back(point);
        }
        input.close();

        //workaround for the PCL headers... http://wiki.ros.org/hydro/Migration#PCL
        sensor_msgs::PointCloud2 pc2;

        pc2.header.frame_id= &quot;velodyne&quot;; //ros::this_node::getName();
        pc2.header.stamp=header-&gt;stamp;
        points-&gt;header = pcl_conversions::toPCL(pc2.header);
        pub.publish(points);

        return 1;
    }
}

/**
 * @brief getCalibration
 * @param dir_root
 * @param camera_name
 * @param K double K[9]  - Calibration Matrix
 * @param D double D[5]  - Distortion Coefficients
 * @param R double R[9]  - Rectification Matrix
 * @param P double P[12] - Projection Matrix Rectified (u,v,w) = P * R * (x,y,z,q)
 * @return 1: file found, 0: file not found
 *
 *  from: http://kitti.is.tue.mpg.de/kitti/devkit_raw_data.zip
 *  calib_cam_to_cam.txt: Camera-to-camera calibration
 *
 *    - S_xx: 1x2 size of image xx before rectification
 *    - K_xx: 3x3 calibration matrix of camera xx before rectification
 *    - D_xx: 1x5 distortion vector of camera xx before rectification
 *    - R_xx: 3x3 rotation matrix of camera xx (extrinsic)
 *    - T_xx: 3x1 translation vector of camera xx (extrinsic)
 *    - S_rect_xx: 1x2 size of image xx after rectification
 *    - R_rect_xx: 3x3 rectifying rotation to make image planes co-planar
 *    - P_rect_xx: 3x4 projection matrix after rectification
 */
int getCalibration(string dir_root, string camera_name, double* K,std::vector&lt;double&gt; &amp; D,double *R,double* P){

    string calib_cam_to_cam=dir_root+&quot;calib_cam_to_cam.txt&quot;;
    ifstream file_c2c(calib_cam_to_cam.c_str());
    if (!file_c2c.is_open())
        return false;

    ROS_INFO_STREAM(&quot;Reading camera&quot; &lt;&lt; camera_name &lt;&lt; &quot; calibration from &quot; &lt;&lt; calib_cam_to_cam);

    typedef boost::tokenizer&lt;boost::char_separator&lt;char&gt; &gt; tokenizer;
    boost::char_separator&lt;char&gt; sep{&quot; &quot;};

    string line=&quot;&quot;;
    char index=0;
    tokenizer::iterator token_iterator;

    while (getline(file_c2c,line))
    {
        // Parse string phase 1, tokenize it using Boost.
        tokenizer tok(line,sep);

        // Move the iterator at the beginning of the tokenize vector and check for K/D/R/P matrices.
        token_iterator=tok.begin();
        if (strcmp((*token_iterator).c_str(),((string)(string(&quot;K_&quot;)+camera_name+string(&quot;:&quot;))).c_str())==0) //Calibration Matrix
        {
            index=0; //should be 9 at the end
            ROS_DEBUG_STREAM(&quot;K_&quot; &lt;&lt; camera_name);
            for (token_iterator++; token_iterator != tok.end(); token_iterator++)
            {
                //std::cout &lt;&lt; *token_iterator &lt;&lt; '\n';
                K[index++]=boost::lexical_cast&lt;double&gt;(*token_iterator);
            }
        }

        // EXPERIMENTAL: use with unrectified images

        //        token_iterator=tok.begin();
        //        if (strcmp((*token_iterator).c_str(),((string)(string(&quot;D_&quot;)+camera_name+string(&quot;:&quot;))).c_str())==0) //Distortion Coefficients
        //        {
        //            index=0; //should be 5 at the end
        //            ROS_DEBUG_STREAM(&quot;D_&quot; &lt;&lt; camera_name);
        //            for (token_iterator++; token_iterator != tok.end(); token_iterator++)
        //            {
        ////                std::cout &lt;&lt; *token_iterator &lt;&lt; '\n';
        //                D[index++]=boost::lexical_cast&lt;double&gt;(*token_iterator);
        //            }
        //        }

        token_iterator=tok.begin();
        if (strcmp((*token_iterator).c_str(),((string)(string(&quot;R_&quot;)+camera_name+string(&quot;:&quot;))).c_str())==0) //Rectification Matrix
        {
            index=0; //should be 12 at the end
            ROS_DEBUG_STREAM(&quot;R_&quot; &lt;&lt; camera_name);
            for (token_iterator++; token_iterator != tok.end(); token_iterator++)
            {
                //std::cout &lt;&lt; *token_iterator &lt;&lt; '\n';
                R[index++]=boost::lexical_cast&lt;double&gt;(*token_iterator);
            }
        }

        token_iterator=tok.begin();
        if (strcmp((*token_iterator).c_str(),((string)(string(&quot;P_rect_&quot;)+camera_name+string(&quot;:&quot;))).c_str())==0) //Projection Matrix Rectified
        {
            index=0; //should be 12 at the end
            ROS_DEBUG_STREAM(&quot;P_rect_&quot; &lt;&lt; camera_name);
            for (token_iterator++; token_iterator != tok.end(); token_iterator++)
            {
                //std::cout &lt;&lt; *token_iterator &lt;&lt; '\n';
                P[index++]=boost::lexical_cast&lt;double&gt;(*token_iterator);
            }
        }

    }
    ROS_INFO_STREAM(&quot;... ok&quot;);
    return true;
}

int getGPS(string filename, sensor_msgs::NavSatFix *ros_msgGpsFix, std_msgs::Header *header)
{
    ifstream file_oxts(filename.c_str());
    if (!file_oxts.is_open()){
        ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; filename);
        return 0;
    }

    ROS_DEBUG_STREAM(&quot;Reading GPS data from oxts file: &quot; &lt;&lt; filename );

    typedef boost::tokenizer&lt;boost::char_separator&lt;char&gt; &gt; tokenizer;
    boost::char_separator&lt;char&gt; sep{&quot; &quot;};

    string line=&quot;&quot;;

    getline(file_oxts,line);
    tokenizer tok(line,sep);
    vector&lt;string&gt; s(tok.begin(), tok.end());

    ros_msgGpsFix-&gt;header.frame_id = ros::this_node::getName();
    ros_msgGpsFix-&gt;header.stamp = header-&gt;stamp;

    ros_msgGpsFix-&gt;latitude  = boost::lexical_cast&lt;double&gt;(s[0]);
    ros_msgGpsFix-&gt;longitude = boost::lexical_cast&lt;double&gt;(s[1]);
    ros_msgGpsFix-&gt;altitude  = boost::lexical_cast&lt;double&gt;(s[2]);

    ros_msgGpsFix-&gt;position_covariance_type = sensor_msgs::NavSatFix::COVARIANCE_TYPE_APPROXIMATED;
    for (int i=0;i&lt;9;i++)
        ros_msgGpsFix-&gt;position_covariance[i] = 0.0f;

    ros_msgGpsFix-&gt;position_covariance[0] = boost::lexical_cast&lt;double&gt;(s[23]);
    ros_msgGpsFix-&gt;position_covariance[4] = boost::lexical_cast&lt;double&gt;(s[23]);
    ros_msgGpsFix-&gt;position_covariance[8] = boost::lexical_cast&lt;double&gt;(s[23]);

    ros_msgGpsFix-&gt;status.service = sensor_msgs::NavSatStatus::SERVICE_GPS;
    ros_msgGpsFix-&gt;status.status  = sensor_msgs::NavSatStatus::STATUS_GBAS_FIX;

    return 1;
}

int getIMU(string filename, sensor_msgs::Imu *ros_msgImu, std_msgs::Header *header)
{
    ifstream file_oxts(filename.c_str());
    if (!file_oxts.is_open())
    {
        ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; filename);
        return 0;
    }

    ROS_DEBUG_STREAM(&quot;Reading IMU data from oxts file: &quot; &lt;&lt; filename );

    typedef boost::tokenizer&lt;boost::char_separator&lt;char&gt; &gt; tokenizer;
    boost::char_separator&lt;char&gt; sep{&quot; &quot;};

    string line=&quot;&quot;;

    getline(file_oxts,line);
    tokenizer tok(line,sep);
    vector&lt;string&gt; s(tok.begin(), tok.end());

    ros_msgImu-&gt;header.frame_id = ros::this_node::getName();
    ros_msgImu-&gt;header.stamp = header-&gt;stamp;

    //    - ax:      acceleration in x, i.e. in direction of vehicle front (m/s^2)
    //    - ay:      acceleration in y, i.e. in direction of vehicle left (m/s^2)
    //    - az:      acceleration in z, i.e. in direction of vehicle top (m/s^2)
    ros_msgImu-&gt;linear_acceleration.x = boost::lexical_cast&lt;double&gt;(s[11]);
    ros_msgImu-&gt;linear_acceleration.y = boost::lexical_cast&lt;double&gt;(s[12]);
    ros_msgImu-&gt;linear_acceleration.z = boost::lexical_cast&lt;double&gt;(s[13]);

    //    - vf:      forward velocity, i.e. parallel to earth-surface (m/s)
    //    - vl:      leftward velocity, i.e. parallel to earth-surface (m/s)
    //    - vu:      upward velocity, i.e. perpendicular to earth-surface (m/s)
    ros_msgImu-&gt;angular_velocity.x = boost::lexical_cast&lt;double&gt;(s[8]);
    ros_msgImu-&gt;angular_velocity.y = boost::lexical_cast&lt;double&gt;(s[9]);
    ros_msgImu-&gt;angular_velocity.z = boost::lexical_cast&lt;double&gt;(s[10]);

    //    - roll:    roll angle (rad),  0 = level, positive = left side up (-pi..pi)
    //    - pitch:   pitch angle (rad), 0 = level, positive = front down (-pi/2..pi/2)
    //    - yaw:     heading (rad),     0 = east,  positive = counter clockwise (-pi..pi)
    tf::Quaternion q=tf::createQuaternionFromRPY(   boost::lexical_cast&lt;double&gt;(s[3]),
                                                    boost::lexical_cast&lt;double&gt;(s[4]),
                                                    boost::lexical_cast&lt;double&gt;(s[5])
                                                    );
    ros_msgImu-&gt;orientation.x = q.getX();
    ros_msgImu-&gt;orientation.y = q.getY();
    ros_msgImu-&gt;orientation.z = q.getZ();
    ros_msgImu-&gt;orientation.w = q.getW();

    return 1;
}


/**
 * @brief parseTime
 * @param timestamp in Epoch
 * @return std_msgs::Header with input timpestamp converted from file input
 *
 * Epoch time conversion
 * http://www.epochconverter.com/programming/functions-c.php
 */
std_msgs::Header parseTime(string timestamp)
{

    std_msgs::Header header;

    typedef boost::tokenizer&lt;boost::char_separator&lt;char&gt; &gt; tokenizer;

    // example: 2011-09-26 13:21:35.134391552
    //          01234567891111111111222222222
    //                    0123456789012345678
    struct tm t = {0};  // Initalize to all 0's
    t.tm_year = boost::lexical_cast&lt;int&gt;(timestamp.substr(0,4)) - 1900;
    t.tm_mon  = boost::lexical_cast&lt;int&gt;(timestamp.substr(5,2)) - 1;
    t.tm_mday = boost::lexical_cast&lt;int&gt;(timestamp.substr(8,2));
    t.tm_hour = boost::lexical_cast&lt;int&gt;(timestamp.substr(11,2));
    t.tm_min  = boost::lexical_cast&lt;int&gt;(timestamp.substr(14,2));
    t.tm_sec  = boost::lexical_cast&lt;int&gt;(timestamp.substr(17,2));
    t.tm_isdst = -1;
    time_t timeSinceEpoch = mktime(&amp;t);

    header.stamp.sec  = timeSinceEpoch;
    header.stamp.nsec = boost::lexical_cast&lt;int&gt;(timestamp.substr(20,8));

    return header;
}

/**
 * @brief getLaneDetection
 * @param infile
 * @param msg_lines
 * @return
 */
/*
int getLaneDetection(string infile, road_layout_estimation::msg_lines *msg_lines)
{
    ROS_DEBUG_STREAM(&quot;Reading lane detections from &quot; &lt;&lt; infile);

    ifstream detection_file(infile);
    if (!detection_file.is_open())
        return false;

    msg_lines-&gt;number_of_lines = 0;
    msg_lines-&gt;goodLines       = 0;
    msg_lines-&gt;width           = 0;
    msg_lines-&gt;oneway          = 0;    
    msg_lines-&gt;naive_width     = 0;
    msg_lines-&gt;lines.clear();

    typedef boost::tokenizer&lt;boost::char_separator&lt;char&gt; &gt; tokenizer;
    boost::char_separator&lt;char&gt; sep{&quot;\t&quot;};  // TAB

    string  line=&quot;&quot;;
    char    index = 0;
    double  last_right_detection = std::numeric_limits&lt;double&gt;::min();          //uses *ONLY* the valid lines
    double  last_left_detection  = std::numeric_limits&lt;double&gt;::max();          //uses *ONLY* the valid lines
    double  naive_last_right_detection = std::numeric_limits&lt;double&gt;::min();    //uses all values, even if the line is not valid
    double  naive_last_left_detection  = std::numeric_limits&lt;double&gt;::max();    //uses all values, even if the line is not valid

    while (getline(detection_file,line))
    {
        // Parse string phase 1, tokenize it using Boost.
        tokenizer tok(line,sep);

        if (index==0)
        {
            vector&lt;string&gt; s(tok.begin(), tok.end());
            msg_lines-&gt;goodLines = boost::lexical_cast&lt;int&gt;(s[0]);

            index++;
        }
        else
        {
            road_layout_estimation::msg_lineInfo line;

            vector&lt;string&gt; s(tok.begin(), tok.end());

            if (s.size()!=3)
            {
                ROS_WARN_STREAM(&quot;Unexpected file format, can't read&quot;);
                return false;
            }

            line.isValid = boost::lexical_cast&lt;bool&gt;  (s[0]);
            line.counter = boost::lexical_cast&lt;int&gt;   (s[1]);
            line.offset  = boost::lexical_cast&lt;float&gt; (s[2]);

            msg_lines-&gt;lines.push_back(line);

            if (line.isValid)
            {
                if (line.offset  &gt; last_right_detection)
                    last_right_detection = line.offset;

                if (line.offset  &lt; last_left_detection)
                    last_left_detection = line.offset;
            }

            if (line.offset  &gt; naive_last_right_detection)
                naive_last_right_detection = line.offset;
            if (line.offset  &lt; naive_last_left_detection)
                naive_last_left_detection = line.offset;

            index++;
        }
    }

    // Number of lines in the file, 1 line 'in the picture' is one row in the file, minus
    // one, the first, that is the number of &quot;good&quot; (current tracked in good state) lines.
    msg_lines-&gt;number_of_lines = index -1 ;

    if (msg_lines-&gt;goodLines &gt; 1)
        msg_lines-&gt;width = abs(last_left_detection) + abs(last_right_detection);
    else
        msg_lines-&gt;width = abs(last_left_detection);

    msg_lines-&gt;naive_width = abs(naive_last_left_detection) + abs(naive_last_right_detection);
    msg_lines-&gt;way_id = 0; ///WARNING this value is not used yet.

    if (msg_lines-&gt;width == std::numeric_limits&lt;double&gt;::max())
        msg_lines-&gt;width = 0.0f;

    if (msg_lines-&gt;naive_width == std::numeric_limits&lt;double&gt;::max())
        msg_lines-&gt;naive_width = 0.0f;

    ROS_DEBUG_STREAM(&quot;Number of LANEs: &quot; &lt;&lt; msg_lines-&gt;number_of_lines &lt;&lt; &quot;\tNumber of good LINEs &quot;&lt;&lt;msg_lines-&gt;goodLines);
    ROS_DEBUG_STREAM(&quot;... getLaneDetection ok&quot;);
    return true;
}
*/

/**
 * @brief main Kitti_player, a player for KITTI raw datasets
 * @param argc
 * @param argv
 * @return 0 and ros::shutdown at the end of the dataset, -1 if errors
 *
 * Allowed options:
 *   -h [ --help ]                       help message
 *   -d [ --directory  ] arg             *required* - path to the kitti dataset Directory
 *   -f [ --frequency  ] arg (=1)        set replay Frequency
 *   -a [ --all        ] [=arg(=1)] (=0) replay All data
 *   -v [ --velodyne   ] [=arg(=1)] (=0) replay Velodyne data
 *   -g [ --gps        ] [=arg(=1)] (=0) replay Gps data
 *   -i [ --imu        ] [=arg(=1)] (=0) replay Imu data
 *   -G [ --grayscale  ] [=arg(=1)] (=0) replay Stereo Grayscale images
 *   -C [ --color      ] [=arg(=1)] (=0) replay Stereo Color images
 *   -V [ --viewer     ] [=arg(=1)] (=0) enable image viewer
 *   -T [ --timestamps ] [=arg(=1)] (=0) use KITTI timestamps
 *   -s [ --stereoDisp ] [=arg(=1)] (=0) use pre-calculated disparities
 *   -D [ --viewDisp   ] [=arg(=1)] (=0) view loaded disparity images
 *   -l [ --laneDetect ] [=arg(=1)] (=0) send extra lanes message
 *   -F [ --frame      ] [=arg(=0)] (=0) start playing at frame ...
 *
 * Datasets can be downloaded from: http://www.cvlibs.net/datasets/kitti/raw_data.php
 */
int main(int argc, char **argv)
{
    kitti_player_options options;
    po::variables_map vm;

    po::options_description desc(&quot;Kitti_player, a player for KITTI raw datasets\nDatasets can be downloaded from: http://www.cvlibs.net/datasets/kitti/raw_data.php\n\nAllowed options&quot;,200);
    desc.add_options()
        (&quot;help,h&quot;                                                                                                    ,  &quot;help message&quot;)
        (&quot;directory ,d&quot;,  po::value&lt;string&gt;       (&amp;options.path)-&gt;required()                                        ,  &quot;*required* - path to the kitti dataset Directory&quot;)
        (&quot;frequency ,f&quot;,  po::value&lt;float&gt;        (&amp;options.frequency)      -&gt;default_value(1.0)                     ,  &quot;set replay Frequency&quot;)
        (&quot;all       ,a&quot;,  po::value&lt;bool&gt;         (&amp;options.all_data)       -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;replay All data&quot;)
        (&quot;velodyne  ,v&quot;,  po::value&lt;bool&gt;         (&amp;options.velodyne)       -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;replay Velodyne data&quot;)
        (&quot;gps       ,g&quot;,  po::value&lt;bool&gt;         (&amp;options.gps)            -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;replay Gps data&quot;)
        (&quot;imu       ,i&quot;,  po::value&lt;bool&gt;         (&amp;options.imu)            -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;replay Imu data&quot;)
        (&quot;grayscale ,G&quot;,  po::value&lt;bool&gt;         (&amp;options.grayscale)      -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;replay Stereo Grayscale images&quot;)
        (&quot;color     ,C&quot;,  po::value&lt;bool&gt;         (&amp;options.color)          -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;replay Stereo Color images&quot;)
        (&quot;viewer    ,V&quot;,  po::value&lt;bool&gt;         (&amp;options.viewer)         -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;enable image viewer&quot;)
        (&quot;timestamps,T&quot;,  po::value&lt;bool&gt;         (&amp;options.timestamps)     -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;use KITTI timestamps&quot;)
        (&quot;stereoDisp,s&quot;,  po::value&lt;bool&gt;         (&amp;options.stereoDisp)     -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;use pre-calculated disparities&quot;)
        (&quot;viewDisp  ,D &quot;, po::value&lt;bool&gt;         (&amp;options.viewDisparities)-&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;view loaded disparity images&quot;)
        (&quot;laneDetect,l&quot;,  po::value&lt;bool&gt;         (&amp;options.laneDetections) -&gt;default_value(0) -&gt;implicit_value(1)   ,  &quot;send extra lanes message&quot;)
        (&quot;frame     ,F&quot;,  po::value&lt;unsigned int&gt; (&amp;options.startFrame)     -&gt;default_value(0) -&gt;implicit_value(0)   ,  &quot;start playing at frame...&quot;)
    ;

    try // parse options
    {
        po::parsed_options parsed = po::command_line_parser(argc-2, argv).options(desc).allow_unregistered().run();
        po::store(parsed, vm);
        po::notify(vm);

        vector&lt;string&gt; to_pass_further = po::collect_unrecognized(parsed.options, po::include_positional);

        // Can't handle __ros (ROS parameters ... )
        //        if (to_pass_further.size()&gt;0)
        //        {
        //            ROS_WARN_STREAM(&quot;Unknown Options Detected, shutting down node\n&quot;);
        //            cerr &lt;&lt; desc &lt;&lt; endl;
        //            return 1;
        //        }
    }
    catch(...)
    {
        cerr &lt;&lt; desc &lt;&lt; endl;

        cout &lt;&lt; &quot;kitti_player needs a directory tree like the following:&quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;└── 2011_09_26_drive_0001_sync&quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── image_00              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── image_01              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── image_02              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── image_03              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── oxts                  &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── velodyne_points       &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │     └ timestamps.txt    &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    └── calib_cam_to_cam.txt  &quot; &lt;&lt; endl &lt;&lt; endl;

        ROS_WARN_STREAM(&quot;Parse error, shutting down node\n&quot;);
        return -1;
    }

    ros::init(argc, argv, &quot;kitti_player&quot;);
    ros::NodeHandle node(&quot;kitti_player&quot;);
    ros::Rate loop_rate(options.frequency);

    /// This sets the logger level; use this to disable all ROS prints
    if( ros::console::set_logger_level(ROSCONSOLE_DEFAULT_NAME, ros::console::levels::Debug) )
        ros::console::notifyLoggerLevelsChanged();
    else
        std::cout &lt;&lt; &quot;Error while setting the logger level!&quot; &lt;&lt; std::endl;

    DIR *dir;
    struct dirent *ent;
    unsigned int total_entries = 0;        //number of elements to be played
    unsigned int entries_played  = 0;      //number of elements played until now
    unsigned int len = 0;                   //counting elements support variable
    string dir_root             ;
    string dir_image00          ;string full_filename_image00;   string dir_timestamp_image00;
    string dir_image01          ;string full_filename_image01;   string dir_timestamp_image01;
    string dir_image02          ;string full_filename_image02;   string dir_timestamp_image02;
    string dir_image03          ;string full_filename_image03;   string dir_timestamp_image03;
    string dir_image04          ;string full_filename_image04;
    string dir_laneDetections   ;string full_filename_laneDetections;
    string dir_laneProjected    ;string full_filename_laneProjected;
    string dir_oxts             ;string full_filename_oxts;      string dir_timestamp_oxts;
    string dir_velodyne_points  ;string full_filename_velodyne;  string dir_timestamp_velodyne; //average of start&amp;end (time of scan)
    string str_support;
    cv::Mat cv_image00;
    cv::Mat cv_image01;
    cv::Mat cv_image02;
    cv::Mat cv_image03;
    cv::Mat cv_image04;
    cv::Mat cv_laneProjected;
    std_msgs::Header header_support;

    image_transport::ImageTransport it(node);
    image_transport::CameraPublisher pub00 = it.advertiseCamera(&quot;grayscale/left/image_rect&quot;, 1);
    image_transport::CameraPublisher pub01 = it.advertiseCamera(&quot;grayscale/right/image_rect&quot;, 1);
    image_transport::CameraPublisher pub02 = it.advertiseCamera(&quot;color/left/image_rect&quot;, 1);
    image_transport::CameraPublisher pub03 = it.advertiseCamera(&quot;color/right/image_rect&quot;, 1);

    sensor_msgs::Image ros_msg00;
    sensor_msgs::Image ros_msg01;
    sensor_msgs::Image ros_msg02;
    sensor_msgs::Image ros_msg03;


//    sensor_msgs::CameraInfo ros_cameraInfoMsg;
    sensor_msgs::CameraInfo ros_cameraInfoMsg_camera00;
    sensor_msgs::CameraInfo ros_cameraInfoMsg_camera01;
    sensor_msgs::CameraInfo ros_cameraInfoMsg_camera02;
    sensor_msgs::CameraInfo ros_cameraInfoMsg_camera03;

    cv_bridge::CvImage cv_bridge_img;

    ros::Publisher map_pub           = node.advertise&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt; &gt;  (&quot;hdl64e&quot;, 1, true);
    ros::Publisher gps_pub           = node.advertise&lt;sensor_msgs::NavSatFix&gt;           (&quot;oxts/gps&quot;, 1, true);
    ros::Publisher gps_pub_initial   = node.advertise&lt;sensor_msgs::NavSatFix&gt;           (&quot;oxts/gps_initial&quot;, 1, true);
    ros::Publisher imu_pub           = node.advertise&lt;sensor_msgs::Imu&gt;                 (&quot;oxts/imu&quot;, 1, true);
    ros::Publisher disp_pub          = node.advertise&lt;stereo_msgs::DisparityImage&gt;      (&quot;preprocessed_disparity&quot;,1,true);
    //ros::Publisher lanes_pub         = node.advertise&lt;road_layout_estimation::msg_lines&gt;(&quot;lanes&quot;,1,true);

    sensor_msgs::NavSatFix  ros_msgGpsFix;
    sensor_msgs::NavSatFix  ros_msgGpsFixInitial;   // This message contains the first reading of the file
    bool                    firstGpsData = true;    // Flag to store the ros_msgGpsFixInitial message
    sensor_msgs::Imu        ros_msgImu;

    //road_layout_estimation::msg_lines    msgLanes;

    if (vm.count(&quot;help&quot;)) {
        cout &lt;&lt; desc &lt;&lt; endl;

        cout &lt;&lt; &quot;kitti_player needs a directory tree like the following:&quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;└── 2011_09_26_drive_0001_sync&quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── image_00              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── image_01              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── image_02              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── image_03              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── oxts                  &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └ timestamps.txt      &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    ├── velodyne_points       &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │   └── data              &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    │     └ timestamps.txt    &quot; &lt;&lt; endl;
        cout &lt;&lt; &quot;    └── calib_cam_to_cam.txt  &quot; &lt;&lt; endl &lt;&lt; endl;

        return 1;
    }

    if (!(options.all_data || options.color || options.gps || options.grayscale || options.imu || options.velodyne))
    {
        ROS_WARN_STREAM(&quot;Job finished without playing the dataset. No 'publishing' parameters provided&quot;);
        node.shutdown();
        return 1;
    }

    dir_root             = options.path;
    dir_image00          = options.path;
    dir_image01          = options.path;
    dir_image02          = options.path;
    dir_image03          = options.path;
    dir_image04          = options.path;
    dir_oxts             = options.path;
    dir_velodyne_points  = options.path;
    dir_image04          = options.path;

    (*(options.path.end()-1) != '/' ? dir_root            = options.path+&quot;/&quot;                      : dir_root            = options.path);
    (*(options.path.end()-1) != '/' ? dir_image00         = options.path+&quot;/image_00/data/&quot;        : dir_image00         = options.path+&quot;image_00/data/&quot;);
    (*(options.path.end()-1) != '/' ? dir_image01         = options.path+&quot;/image_01/data/&quot;        : dir_image01         = options.path+&quot;image_01/data/&quot;);
    (*(options.path.end()-1) != '/' ? dir_image02         = options.path+&quot;/image_02/data/&quot;        : dir_image02         = options.path+&quot;image_02/data/&quot;);
    (*(options.path.end()-1) != '/' ? dir_image03         = options.path+&quot;/image_03/data/&quot;        : dir_image03         = options.path+&quot;image_03/data/&quot;);
    (*(options.path.end()-1) != '/' ? dir_image04         = options.path+&quot;/disparities/&quot;          : dir_image04         = options.path+&quot;disparities/&quot;);
    (*(options.path.end()-1) != '/' ? dir_oxts            = options.path+&quot;/oxts/data/&quot;            : dir_oxts            = options.path+&quot;oxts/data/&quot;);
    (*(options.path.end()-1) != '/' ? dir_velodyne_points = options.path+&quot;/velodyne_points/data/&quot; : dir_velodyne_points = options.path+&quot;velodyne_points/data/&quot;);

    (*(options.path.end()-1) != '/' ? dir_timestamp_image00    = options.path+&quot;/image_00/&quot;            : dir_timestamp_image00   = options.path+&quot;image_00/&quot;);
    (*(options.path.end()-1) != '/' ? dir_timestamp_image01    = options.path+&quot;/image_01/&quot;            : dir_timestamp_image01   = options.path+&quot;image_01/&quot;);
    (*(options.path.end()-1) != '/' ? dir_timestamp_image02    = options.path+&quot;/image_02/&quot;            : dir_timestamp_image02   = options.path+&quot;image_02/&quot;);
    (*(options.path.end()-1) != '/' ? dir_timestamp_image03    = options.path+&quot;/image_03/&quot;            : dir_timestamp_image03   = options.path+&quot;image_03/&quot;);
    (*(options.path.end()-1) != '/' ? dir_timestamp_oxts       = options.path+&quot;/oxts/&quot;                : dir_timestamp_oxts      = options.path+&quot;oxts/&quot;);
    (*(options.path.end()-1) != '/' ? dir_timestamp_velodyne   = options.path+&quot;/velodyne_points/&quot;     : dir_timestamp_velodyne  = options.path+&quot;velodyne_points/&quot;);

    (*(options.path.end()-1) != '/' ? dir_timestamp_velodyne   = options.path+&quot;/velodyne_points/&quot;     : dir_timestamp_velodyne  = options.path+&quot;velodyne_points/&quot;);

    /// EXTRA
    /// 01. Lane detections
    (*(options.path.end()-1) != '/' ? dir_laneDetections       = options.path+&quot;/lane/&quot;         : dir_laneDetections         = options.path+&quot;lane/&quot;);
    (*(options.path.end()-1) != '/' ? dir_laneProjected        = options.path+&quot;/all/&quot;          : dir_laneProjected          = options.path+&quot;all/&quot;);

    // Check all the directories
    if (
            (options.all_data       &amp;&amp; (   (opendir(dir_image00.c_str())            == NULL) ||
                                           (opendir(dir_image01.c_str())            == NULL) ||
                                           (opendir(dir_image02.c_str())            == NULL) ||
                                           (opendir(dir_image03.c_str())            == NULL) ||
                                           (opendir(dir_oxts.c_str())               == NULL) ||
                                           (opendir(dir_velodyne_points.c_str())    == NULL)))
            ||
            (options.color          &amp;&amp; (   (opendir(dir_image02.c_str())            == NULL) ||
                                           (opendir(dir_image03.c_str())            == NULL)))
            ||
            (options.grayscale      &amp;&amp; (   (opendir(dir_image00.c_str())            == NULL) ||
                                           (opendir(dir_image01.c_str())            == NULL)))
            ||
            (options.imu            &amp;&amp; (   (opendir(dir_oxts.c_str())               == NULL)))
            ||
            (options.gps            &amp;&amp; (   (opendir(dir_oxts.c_str())               == NULL)))
            //||
            //(options.stereoDisp     &amp;&amp; (   (opendir(dir_image04.c_str())            == NULL)))
            ||
            (options.velodyne       &amp;&amp; (   (opendir(dir_velodyne_points.c_str())    == NULL)))
            //||
            //(options.laneDetections &amp;&amp; (   (opendir(dir_laneDetections.c_str())    == NULL)))
            ||
            (options.timestamps     &amp;&amp; (   (opendir(dir_timestamp_image00.c_str())      == NULL) ||
                                           (opendir(dir_timestamp_image01.c_str())      == NULL) ||
                                           (opendir(dir_timestamp_image02.c_str())      == NULL) ||
                                           (opendir(dir_timestamp_image03.c_str())      == NULL) ||
                                           (opendir(dir_timestamp_oxts.c_str())         == NULL) ||
                                           (opendir(dir_timestamp_velodyne.c_str())     == NULL)))

        )
    {
        ROS_ERROR(&quot;Incorrect tree directory , use --help for details&quot;);
        node.shutdown();
        return -1;
    }
    else
    {
        ROS_INFO_STREAM (&quot;Checking directories...&quot;);
        ROS_INFO_STREAM (options.path &lt;&lt; &quot;\t[OK]&quot;);
    }

    //count elements in the folder

    if (options.all_data)
    {
        dir = opendir(dir_image02.c_str());
        while(ent = readdir(dir))
        {
            //skip . &amp; ..
            len = strlen (ent-&gt;d_name);
            //skip . &amp; ..
            if (len&gt;2)
                total_entries++;
        }
        closedir (dir);
    }
    else
    {
        bool done=false;
        if (!done &amp;&amp; options.color)
        {
            total_entries=0;
            dir = opendir(dir_image02.c_str());
            while(ent = readdir(dir))
            {
                //skip . &amp; ..
                len = strlen (ent-&gt;d_name);
                //skip . &amp; ..
                if (len&gt;2)
                    total_entries++;
            }            closedir (dir);
            done=true;
        }
        if (!done &amp;&amp; options.grayscale)
        {
            total_entries=0;
            dir = opendir(dir_image00.c_str());
            while(ent = readdir(dir))
            {
                //skip . &amp; ..
                len = strlen (ent-&gt;d_name);
                //skip . &amp; ..
                if (len&gt;2)
                    total_entries++;
            }
            closedir (dir);
            done=true;
        }
        if (!done &amp;&amp; options.gps)
        {
            total_entries=0;
            dir = opendir(dir_oxts.c_str());
            while(ent = readdir(dir))
            {
                //skip . &amp; ..
                len = strlen (ent-&gt;d_name);
                //skip . &amp; ..
                if (len&gt;2)
                    total_entries++;
            }
            closedir (dir);
            done=true;
        }
        if (!done &amp;&amp; options.imu)
        {
            total_entries=0;
            dir = opendir(dir_oxts.c_str());
            while(ent = readdir(dir))
            {
                //skip . &amp; ..
                len = strlen (ent-&gt;d_name);
                //skip . &amp; ..
                if (len&gt;2)
                    total_entries++;
            }
            closedir (dir);
            done=true;
        }
        if (!done &amp;&amp; options.velodyne)
        {
            total_entries=0;
            dir = opendir(dir_oxts.c_str());            
            while(ent = readdir(dir))
            {
                //skip . &amp; ..
                len = strlen (ent-&gt;d_name);
                //skip . &amp; ..
                if (len&gt;2)
                    total_entries++;
            }
            closedir (dir);
            done=true;
        }
        if (!done &amp;&amp; options.stereoDisp)
        {
            total_entries=0;
            dir = opendir(dir_image04.c_str());
            while(ent = readdir(dir))
            {
                //skip . &amp; ..
                len = strlen (ent-&gt;d_name);
                //skip . &amp; ..
                if (len&gt;2)
                    total_entries++;
            }
            closedir (dir);
            done=true;
        }
        if (!done &amp;&amp; options.laneDetections)
        {
            total_entries=0;
            dir = opendir(dir_laneDetections.c_str());
            while(ent = readdir(dir))
            {
                //skip . &amp; ..
                len = strlen (ent-&gt;d_name);
                //skip . &amp; ..
                if (len&gt;2)
                    total_entries++;
            }
            closedir (dir);
            done=true;
        }
    }

    // Check options.startFrame and total_entries
    if (options.startFrame &gt; total_entries)
    {
        ROS_ERROR(&quot;Error, start number &gt; total entries in the dataset&quot;);
        node.shutdown();
        return -1;
    }
    else
    {
        entries_played = options.startFrame;
        ROS_INFO_STREAM(&quot;The entry point (frame number) is: &quot; &lt;&lt; entries_played);
    }

    if(options.viewer)
    {
        ROS_INFO_STREAM(&quot;Opening CV viewer(s)&quot;);
        if(options.color || options.all_data)
        {
            ROS_DEBUG_STREAM(&quot;color||all &quot; &lt;&lt; options.color &lt;&lt; &quot; &quot; &lt;&lt; options.all_data);
            cv::namedWindow(&quot;CameraSimulator Color Viewer&quot;,CV_WINDOW_AUTOSIZE);
            full_filename_image02 = dir_image02 + boost::str(boost::format(&quot;%010d&quot;) % 0 ) + &quot;.png&quot;;
            cv_image02 = cv::imread(full_filename_image02, CV_LOAD_IMAGE_UNCHANGED);
            cv::waitKey(5);
        }
        if(options.grayscale || options.all_data)
        {
            ROS_DEBUG_STREAM(&quot;grayscale||all &quot; &lt;&lt; options.grayscale &lt;&lt; &quot; &quot; &lt;&lt; options.all_data);
            cv::namedWindow(&quot;CameraSimulator Grayscale Viewer&quot;,CV_WINDOW_AUTOSIZE);
            full_filename_image00 = dir_image00 + boost::str(boost::format(&quot;%010d&quot;) % 0 ) + &quot;.png&quot;;
            cv_image00 = cv::imread(full_filename_image00, CV_LOAD_IMAGE_UNCHANGED);
            cv::waitKey(5);
        }
        if (options.viewDisparities || options.all_data)
        {
            ROS_DEBUG_STREAM(&quot;viewDisparities||all &quot; &lt;&lt; options.grayscale &lt;&lt; &quot; &quot; &lt;&lt; options.all_data);
            cv::namedWindow(&quot;Reprojection of Detected Lines&quot;,CV_WINDOW_AUTOSIZE);
            full_filename_laneProjected = dir_laneProjected + boost::str(boost::format(&quot;%010d&quot;) % 0 ) + &quot;.png&quot;;
            cv_laneProjected = cv::imread(full_filename_laneProjected, CV_LOAD_IMAGE_UNCHANGED);
            cv::waitKey(5);
        }
        ROS_INFO_STREAM(&quot;Opening CV viewer(s)... OK&quot;);
    }

    // CAMERA INFO SECTION: read one for all

    ros_cameraInfoMsg_camera00.header.stamp = ros::Time::now();
    ros_cameraInfoMsg_camera00.header.frame_id = ros::this_node::getName();
    ros_cameraInfoMsg_camera00.height = 0;
    ros_cameraInfoMsg_camera00.width  = 0;
    //ros_cameraInfoMsg_camera00.D.resize(5);
    //ros_cameraInfoMsg_camera00.distortion_model=sensor_msgs::distortion_models::PLUMB_BOB;

    ros_cameraInfoMsg_camera01.header.stamp = ros::Time::now();
    ros_cameraInfoMsg_camera01.header.frame_id = ros::this_node::getName();
    ros_cameraInfoMsg_camera01.height = 0;
    ros_cameraInfoMsg_camera01.width  = 0;
    //ros_cameraInfoMsg_camera01.D.resize(5);
    //ros_cameraInfoMsg_camera00.distortion_model=sensor_msgs::distortion_models::PLUMB_BOB;

    ros_cameraInfoMsg_camera02.header.stamp = ros::Time::now();
    ros_cameraInfoMsg_camera02.header.frame_id = ros::this_node::getName();
    ros_cameraInfoMsg_camera02.height = 0;
    ros_cameraInfoMsg_camera02.width  = 0;
    //ros_cameraInfoMsg_camera02.D.resize(5);
    //ros_cameraInfoMsg_camera02.distortion_model=sensor_msgs::distortion_models::PLUMB_BOB;

    ros_cameraInfoMsg_camera03.header.stamp = ros::Time::now();
    ros_cameraInfoMsg_camera03.header.frame_id = ros::this_node::getName();
    ros_cameraInfoMsg_camera03.height = 0;
    ros_cameraInfoMsg_camera03.width  = 0;
    //ros_cameraInfoMsg_camera03.D.resize(5);
    //ros_cameraInfoMsg_camera03.distortion_model=sensor_msgs::distortion_models::PLUMB_BOB;

    if(options.color || options.all_data)
    {
        if(
           !(getCalibration(dir_root,&quot;02&quot;,ros_cameraInfoMsg_camera02.K.data(),ros_cameraInfoMsg_camera02.D,ros_cameraInfoMsg_camera02.R.data(),ros_cameraInfoMsg_camera02.P.data()) &amp;&amp;
           getCalibration(dir_root,&quot;03&quot;,ros_cameraInfoMsg_camera03.K.data(),ros_cameraInfoMsg_camera03.D,ros_cameraInfoMsg_camera03.R.data(),ros_cameraInfoMsg_camera03.P.data()))
          )
        {
            ROS_ERROR_STREAM(&quot;Error reading CAMERA02/CAMERA03 calibration&quot;);
            //node.shutdown();
            //return -1;
        }
        //Assume same height/width for the camera pair
        full_filename_image02 = dir_image02 + boost::str(boost::format(&quot;%010d&quot;) % 0 ) + &quot;.png&quot;;
        cv_image02 = cv::imread(full_filename_image02, CV_LOAD_IMAGE_UNCHANGED);
        cv::waitKey(5);
        ros_cameraInfoMsg_camera03.height = ros_cameraInfoMsg_camera02.height = cv_image02.rows;// -1;TODO: CHECK, qui potrebbe essere -1
        ros_cameraInfoMsg_camera03.width  = ros_cameraInfoMsg_camera02.width  = cv_image02.cols;// -1;
    }

    if(options.grayscale || options.all_data)
    {
        if(
           !(getCalibration(dir_root,&quot;00&quot;,ros_cameraInfoMsg_camera00.K.data(),ros_cameraInfoMsg_camera00.D,ros_cameraInfoMsg_camera00.R.data(),ros_cameraInfoMsg_camera00.P.data()) &amp;&amp;
           getCalibration(dir_root,&quot;01&quot;,ros_cameraInfoMsg_camera01.K.data(),ros_cameraInfoMsg_camera01.D,ros_cameraInfoMsg_camera01.R.data(),ros_cameraInfoMsg_camera01.P.data()))
          )
        {
            ROS_ERROR_STREAM(&quot;Error reading CAMERA00/CAMERA01 calibration&quot;);
            //node.shutdown();
            //return -1;
        }
        //Assume same height/width for the camera pair
        full_filename_image00 = dir_image00 + boost::str(boost::format(&quot;%010d&quot;) % 0 ) + &quot;.png&quot;;
        cv_image00 = cv::imread(full_filename_image00, CV_LOAD_IMAGE_UNCHANGED);
        cv::waitKey(5);
        ros_cameraInfoMsg_camera01.height = ros_cameraInfoMsg_camera00.height = cv_image00.rows;// -1; TODO: CHECK -1?
        ros_cameraInfoMsg_camera01.width  = ros_cameraInfoMsg_camera00.width  = cv_image00.cols;// -1;
    }

    boost::progress_display progress(total_entries) ;
    double cv_min, cv_max=0.0f;

    // This is the main KITTI_PLAYER Loop
    do
    {
        // single timestamp for all published stuff
        Time current_timestamp=ros::Time::now();

        if(options.stereoDisp)
        {
            // Allocate new disparity image message
            stereo_msgs::DisparityImagePtr disp_msg = boost::make_shared&lt;stereo_msgs::DisparityImage&gt;();

            full_filename_image04 = dir_image04 + boost::str(boost::format(&quot;%010d&quot;) % entries_played ) + &quot;.png&quot;;
            cv_image04 = cv::imread(full_filename_image04, CV_LOAD_IMAGE_GRAYSCALE);

            cv::minMaxLoc(cv_image04,&amp;cv_min,&amp;cv_max);

            disp_msg-&gt;min_disparity = (int)cv_min;
            disp_msg-&gt;max_disparity = (int)cv_max;

            disp_msg-&gt;valid_window.x_offset = 0;  // should be safe, checked!
            disp_msg-&gt;valid_window.y_offset = 0;  // should be safe, checked!
            disp_msg-&gt;valid_window.width    = 0;  // should be safe, checked!
            disp_msg-&gt;valid_window.height   = 0;  // should be safe, checked!
            disp_msg-&gt;T                     = 0;  // should be safe, checked!
            disp_msg-&gt;f                     = 0;  // should be safe, checked!
            disp_msg-&gt;delta_d               = 0;  // should be safe, checked!
            disp_msg-&gt;header.stamp          = current_timestamp;
            disp_msg-&gt;header.frame_id       = ros::this_node::getName();
            disp_msg-&gt;header.seq            = progress.count();

            sensor_msgs::Image&amp; dimage = disp_msg-&gt;image;
            dimage.width  = cv_image04.size().width ;
            dimage.height = cv_image04.size().height ;
            dimage.encoding = sensor_msgs::image_encodings::TYPE_32FC1;
            dimage.step = dimage.width * sizeof(float);
            dimage.data.resize(dimage.step * dimage.height);
            cv::Mat_&lt;float&gt; dmat(dimage.height, dimage.width, reinterpret_cast&lt;float*&gt;(&amp;dimage.data[0]), dimage.step);

            cv_image04.convertTo(dmat,dmat.type());

            disp_pub.publish(disp_msg);

        }
/*
        if(options.laneDetections)
        {
            //msgLanes;
            //msgSingleLaneInfo;
            string file=dir_laneDetections+boost::str(boost::format(&quot;%010d&quot;) % entries_played )+&quot;.txt&quot;;
            if(getLaneDetection(file,&amp;msgLanes))
            {
                msgLanes.header.stamp    = current_timestamp;
                msgLanes.header.frame_id = ros::this_node::getName();
                lanes_pub.publish(msgLanes);
            }

            if (options.viewDisparities)
            {
                full_filename_laneProjected = dir_laneProjected + boost::str(boost::format(&quot;%010d&quot;) % entries_played ) + &quot;.png&quot;;
                cv_laneProjected = cv::imread(full_filename_laneProjected, CV_LOAD_IMAGE_UNCHANGED);
                cv::imshow(&quot;Reprojection of Detected Lines&quot;,cv_laneProjected);
                cv::waitKey(5);
            }
        }
*/
        if(options.color || options.all_data)
        {
            full_filename_image02 = dir_image02 + boost::str(boost::format(&quot;%010d&quot;) % entries_played ) + &quot;.png&quot;;
            full_filename_image03 = dir_image03 + boost::str(boost::format(&quot;%010d&quot;) % entries_played ) + &quot;.png&quot;;
            ROS_DEBUG_STREAM ( full_filename_image02 &lt;&lt; endl &lt;&lt; full_filename_image03 &lt;&lt; endl &lt;&lt; endl);

            cv_image02 = cv::imread(full_filename_image02, CV_LOAD_IMAGE_UNCHANGED);
            cv_image03 = cv::imread(full_filename_image03, CV_LOAD_IMAGE_UNCHANGED);

            if ( (cv_image02.data == NULL) || (cv_image03.data == NULL) ){
                ROS_ERROR_STREAM(&quot;Error reading color images (02 &amp; 03)&quot;);
                ROS_ERROR_STREAM(full_filename_image02 &lt;&lt; endl &lt;&lt; full_filename_image03);
                node.shutdown();
                return -1;
            }

            if(options.viewer)
            {
                //display the left image only
                cv::imshow(&quot;CameraSimulator Color Viewer&quot;,cv_image02);
                //give some time to draw images
                cv::waitKey(5);
            }

            cv_bridge_img.encoding = sensor_msgs::image_encodings::BGR8;
            cv_bridge_img.header.frame_id = &quot;camera&quot;; //ros::this_node::getName();

            if (!options.timestamps)
            {
                cv_bridge_img.header.stamp = current_timestamp ;
                ros_msg02.header.stamp = ros_cameraInfoMsg_camera02.header.stamp = cv_bridge_img.header.stamp;
            }
            else
            {

                str_support = dir_timestamp_image02 + &quot;timestamps.txt&quot;;
                ifstream timestamps(str_support.c_str());
                if (!timestamps.is_open())
                {
                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
                    node.shutdown();
                    return -1;
                }
                timestamps.seekg(30*entries_played);
                getline(timestamps,str_support);
                cv_bridge_img.header.stamp = parseTime(str_support).stamp;
                ros_msg02.header.stamp = ros_cameraInfoMsg_camera02.header.stamp = cv_bridge_img.header.stamp;
            }
            cv_bridge_img.image = cv_image02;
            cv_bridge_img.toImageMsg(ros_msg02);

            if (!options.timestamps)
            {
                cv_bridge_img.header.stamp = current_timestamp;
                ros_msg03.header.stamp = ros_cameraInfoMsg_camera03.header.stamp = cv_bridge_img.header.stamp;
            }
            else
            {

                str_support = dir_timestamp_image03 + &quot;timestamps.txt&quot;;
                ifstream timestamps(str_support.c_str());
                if (!timestamps.is_open())
                {
                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
                    node.shutdown();
                    return -1;
                }
                timestamps.seekg(30*entries_played);
                getline(timestamps,str_support);
                cv_bridge_img.header.stamp = parseTime(str_support).stamp;
                ros_msg03.header.stamp = ros_cameraInfoMsg_camera03.header.stamp = cv_bridge_img.header.stamp;
            }

            cv_bridge_img.image = cv_image03;
            cv_bridge_img.toImageMsg(ros_msg03);

            pub02.publish(ros_msg02,ros_cameraInfoMsg_camera02);
            pub03.publish(ros_msg03,ros_cameraInfoMsg_camera03);

        }

        if(options.grayscale || options.all_data)
        {
            full_filename_image00 = dir_image00 + boost::str(boost::format(&quot;%010d&quot;) % entries_played ) + &quot;.png&quot;;
            full_filename_image01 = dir_image01 + boost::str(boost::format(&quot;%010d&quot;) % entries_played ) + &quot;.png&quot;;
            ROS_DEBUG_STREAM ( full_filename_image00 &lt;&lt; endl &lt;&lt; full_filename_image01 &lt;&lt; endl &lt;&lt; endl);

            cv_image00 = cv::imread(full_filename_image00, CV_LOAD_IMAGE_UNCHANGED);
            cv_image01 = cv::imread(full_filename_image01, CV_LOAD_IMAGE_UNCHANGED);

            if ( (cv_image00.data == NULL) || (cv_image01.data == NULL) ){
                ROS_ERROR_STREAM(&quot;Error reading color images (00 &amp; 01)&quot;);
                ROS_ERROR_STREAM(full_filename_image00 &lt;&lt; endl &lt;&lt; full_filename_image01);
                node.shutdown();
                return -1;
            }

            if(options.viewer)
            {
                //display the left image only
                cv::imshow(&quot;CameraSimulator Grayscale Viewer&quot;,cv_image00);
                //give some time to draw images
                cv::waitKey(5);
            }

            cv_bridge_img.encoding = sensor_msgs::image_encodings::MONO8;
            cv_bridge_img.header.frame_id = &quot;camera&quot;; //ros::this_node::getName();

            if (!options.timestamps)
            {
                cv_bridge_img.header.stamp = current_timestamp;
                ros_msg00.header.stamp = ros_cameraInfoMsg_camera00.header.stamp = cv_bridge_img.header.stamp;
            }
            else
            {

                str_support = dir_timestamp_image02 + &quot;timestamps.txt&quot;;
                ifstream timestamps(str_support.c_str());
                if (!timestamps.is_open())
                {
                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
                    node.shutdown();
                    return -1;
                }
                timestamps.seekg(30*entries_played);
                getline(timestamps,str_support);
                cv_bridge_img.header.stamp = parseTime(str_support).stamp;
                ros_msg00.header.stamp = ros_cameraInfoMsg_camera00.header.stamp = cv_bridge_img.header.stamp;
            }
            cv_bridge_img.image = cv_image00;
            cv_bridge_img.toImageMsg(ros_msg00);

            if (!options.timestamps)
            {
                cv_bridge_img.header.stamp = current_timestamp;
                ros_msg01.header.stamp = ros_cameraInfoMsg_camera01.header.stamp = cv_bridge_img.header.stamp;
            }
            else
            {

                str_support = dir_timestamp_image02 + &quot;timestamps.txt&quot;;
                ifstream timestamps(str_support.c_str());
                if (!timestamps.is_open())
                {
                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
                    node.shutdown();
                    return -1;
                }
                timestamps.seekg(30*entries_played);
                getline(timestamps,str_support);
                cv_bridge_img.header.stamp = parseTime(str_support).stamp;
                ros_msg01.header.stamp = ros_cameraInfoMsg_camera01.header.stamp = cv_bridge_img.header.stamp;
            }
            cv_bridge_img.image = cv_image01;
            cv_bridge_img.toImageMsg(ros_msg01);

            pub00.publish(ros_msg00,ros_cameraInfoMsg_camera00);
            pub01.publish(ros_msg01,ros_cameraInfoMsg_camera01);

        }

        if(options.velodyne || options.all_data)
        {            
            header_support.stamp = current_timestamp;
            full_filename_velodyne = dir_velodyne_points + boost::str(boost::format(&quot;%010d&quot;) % entries_played ) + &quot;.bin&quot;;

            if (!options.timestamps)
                publish_velodyne(map_pub, full_filename_velodyne,&amp;header_support);
            else
            {
                str_support = dir_timestamp_velodyne + &quot;timestamps.txt&quot;;
                ifstream timestamps(str_support.c_str());
                if (!timestamps.is_open())
                {
                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
                    node.shutdown();
                    return -1;
                }
                timestamps.seekg(30*entries_played);
                getline(timestamps,str_support);
                header_support.stamp = parseTime(str_support).stamp;
                publish_velodyne(map_pub, full_filename_velodyne,&amp;header_support);
            }


        }

        if(options.gps || options.all_data)
        {
            header_support.stamp = current_timestamp; //ros::Time::now();
            if (options.timestamps)
            {
                str_support = dir_timestamp_oxts + &quot;timestamps.txt&quot;;
                ifstream timestamps(str_support.c_str());
                if (!timestamps.is_open())
                {
                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
                    node.shutdown();
                    return -1;
                }
                timestamps.seekg(30*entries_played);
                getline(timestamps,str_support);
                header_support.stamp = parseTime(str_support).stamp;
            }

            full_filename_oxts = dir_oxts + boost::str(boost::format(&quot;%010d&quot;) % entries_played ) + &quot;.txt&quot;;
            if (!getGPS(full_filename_oxts,&amp;ros_msgGpsFix,&amp;header_support))
            {
                ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; full_filename_oxts);
                node.shutdown();
                return -1;
            }

            if (firstGpsData)
            {
                ROS_DEBUG_STREAM(&quot;Setting initial GPS fix at &quot; &lt;&lt; endl &lt;&lt; ros_msgGpsFix);
                firstGpsData = false;
                ros_msgGpsFixInitial = ros_msgGpsFix;
                ros_msgGpsFixInitial.header.frame_id = &quot;/local_map&quot;;
                ros_msgGpsFixInitial.altitude = 0.0f;
            }

            gps_pub.publish(ros_msgGpsFix);
            gps_pub_initial.publish(ros_msgGpsFixInitial);
        }

        if(options.imu || options.all_data)
        {
            header_support.stamp = current_timestamp; //ros::Time::now();
            if (options.timestamps)
            {
                str_support = dir_timestamp_oxts + &quot;timestamps.txt&quot;;
                ifstream timestamps(str_support.c_str());
                if (!timestamps.is_open())
                {
                    ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; timestamps);
                    node.shutdown();
                    return -1;
                }
                timestamps.seekg(30*entries_played);
                getline(timestamps,str_support);
                header_support.stamp = parseTime(str_support).stamp;
            }


            full_filename_oxts = dir_oxts + boost::str(boost::format(&quot;%010d&quot;) % entries_played ) + &quot;.txt&quot;;
            if (!getIMU(full_filename_oxts,&amp;ros_msgImu,&amp;header_support))
            {
                ROS_ERROR_STREAM(&quot;Fail to open &quot; &lt;&lt; full_filename_oxts);
                node.shutdown();
                return -1;
            }
            imu_pub.publish(ros_msgImu);

        }

        ++progress;
        entries_played++;
        loop_rate.sleep();
    }
    while(entries_played&lt;=total_entries-1 &amp;&amp; ros::ok());


    if(options.viewer)
    {
        ROS_INFO_STREAM(&quot; Closing CV viewer(s)&quot;);
        if(options.color || options.all_data)
            cv::destroyWindow(&quot;CameraSimulator Color Viewer&quot;);
        if(options.grayscale || options.all_data)
            cv::destroyWindow(&quot;CameraSimulator Grayscale Viewer&quot;);
        if (options.viewDisparities)
            cv::destroyWindow(&quot;Reprojection of Detected Lines&quot;);
        ROS_INFO_STREAM(&quot; Closing CV viewer(s)... OK&quot;);
    }


    ROS_INFO_STREAM(&quot;Done!&quot;);
    node.shutdown();

    return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="e7e31a9c58bb04453903895c17fdbb6edde90d82" fix_time="4,30059">
		<msg>ndt_matching debug end (ndt_mapping not yet)</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_mapping/ndt_mapping.cpp" new_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_mapping/ndt_mapping.cpp">
				<diff>@@ -840,8 +840,8 @@ int main(int argc, char** argv)
   ros::Subscriber param_sub = nh.subscribe(&quot;config/ndt_mapping&quot;, 10, param_callback);
   ros::Subscriber output_sub = nh.subscribe(&quot;config/ndt_mapping_output&quot;, 10, output_callback);
   ros::Subscriber points_sub = nh.subscribe(&quot;points_raw&quot;, 100000, points_callback);
-  ros::Subscriber odom_sub = nh.subscribe(&quot;odom_pose&quot;, 100000, odom_callback);
-  ros::Subscriber imu_sub = nh.subscribe(&quot;imu_raw&quot;, 100000, imu_callback);
+  ros::Subscriber odom_sub = nh.subscribe(&quot;/odom_pose&quot;, 100000, odom_callback);
+  ros::Subscriber imu_sub = nh.subscribe(&quot;/imu_raw&quot;, 100000, imu_callback);
 
   ros::spin();
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

/*
 Localization and mapping program using Normal Distributions Transform

 Yuki KITSUKAWA
 */

#define OUTPUT  // If you want to output &quot;position_log.txt&quot;, &quot;#define OUTPUT&quot;.

#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;fstream&gt;
#include &lt;string&gt;

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/Bool.h&gt;
#include &lt;std_msgs/Float32.h&gt;
#include &lt;nav_msgs/Odometry.h&gt;
#include &lt;sensor_msgs/Imu.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;velodyne_pointcloud/point_types.h&gt;
#include &lt;velodyne_pointcloud/rawdata.h&gt;

#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_datatypes.h&gt;

#include &lt;pcl/io/io.h&gt;
#include &lt;pcl/io/pcd_io.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;

#ifdef USE_FAST_PCL
#include &lt;fast_pcl/registration/ndt.h&gt;
#include &lt;fast_pcl/filters/voxel_grid.h&gt;
#else
#include &lt;pcl/registration/ndt.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;
#endif

#include &lt;runtime_manager/ConfigNdtMapping.h&gt;
#include &lt;runtime_manager/ConfigNdtMappingOutput.h&gt;

struct pose
{
  double x;
  double y;
  double z;
  double roll;
  double pitch;
  double yaw;
};

// global variables
static pose previous_pose, guess_pose, guess_pose_imu, guess_pose_odom, guess_pose_imu_odom,current_pose, current_pose_imu, current_pose_odom, current_pose_imu_odom, ndt_pose, added_pose, localizer_pose;

static ros::Time current_scan_time;
static ros::Time previous_scan_time;
static ros::Duration scan_duration;

static double diff = 0.0;
static double diff_x = 0.0, diff_y = 0.0, diff_z = 0.0, diff_yaw; // current_pose - previous_pose
static double offset_x, offset_y, offset_z, offset_roll, offset_pitch, offset_yaw;
static double offset_imu_x, offset_imu_y, offset_imu_z, offset_imu_roll, offset_imu_pitch, offset_imu_yaw;
static double offset_odom_x, offset_odom_y, offset_odom_z, offset_odom_roll, offset_odom_pitch, offset_odom_yaw;
static double offset_imu_odom_x, offset_imu_odom_y, offset_imu_odom_z, offset_imu_odom_roll, offset_imu_odom_pitch, offset_imu_odom_yaw;

static double current_velocity_x = 0.0;
static double current_velocity_y = 0.0;
static double current_velocity_z = 0.0;

static double current_velocity_imu_x = 0.0;
static double current_velocity_imu_y = 0.0;
static double current_velocity_imu_z = 0.0;

static pcl::PointCloud&lt;pcl::PointXYZI&gt; map;

static pcl::NormalDistributionsTransform&lt;pcl::PointXYZI, pcl::PointXYZI&gt; ndt;
// Default values
static int max_iter = 30;            // Maximum iterations
static float ndt_res = 1.0;      // Resolution
static double step_size = 0.1;   // Step size
static double trans_eps = 0.01;  // Transformation epsilon

// Leaf size of VoxelGrid filter.
static double voxel_leaf_size = 2.0;

static ros::Time callback_start, callback_end, t1_start, t1_end, t2_start, t2_end, t3_start, t3_end, t4_start, t4_end,
    t5_start, t5_end;
static ros::Duration d_callback, d1, d2, d3, d4, d5;

static ros::Publisher ndt_map_pub;
static ros::Publisher current_pose_pub;
static ros::Publisher guess_pose_linaer_pub;
static geometry_msgs::PoseStamped current_pose_msg, guess_pose_msg;

static ros::Publisher ndt_stat_pub;
static std_msgs::Bool ndt_stat_msg;

static int initial_scan_loaded = 0;

static Eigen::Matrix4f gnss_transform = Eigen::Matrix4f::Identity();

static double min_scan_range = 5.0;
static double min_add_scan_shift = 1.0;

static double _tf_x, _tf_y, _tf_z, _tf_roll, _tf_pitch, _tf_yaw;
static Eigen::Matrix4f tf_btol, tf_ltob;

static bool isMapUpdate = true;
static bool _use_openmp = false;
static bool _use_imu = false;
static bool _use_odom = false;

static double fitness_score;

static sensor_msgs::Imu imu;
static nav_msgs::Odometry odom;

static void param_callback(const runtime_manager::ConfigNdtMapping::ConstPtr&amp; input)
{

  ndt_res = input-&gt;resolution;
  step_size = input-&gt;step_size;
  trans_eps = input-&gt;trans_epsilon;
  max_iter = input-&gt;max_iterations;
  voxel_leaf_size = input-&gt;leaf_size;
  min_scan_range = input-&gt;min_scan_range;
  min_add_scan_shift = input-&gt;min_add_scan_shift;

  std::cout &lt;&lt; &quot;param_callback&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;ndt_res: &quot; &lt;&lt; ndt_res &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;step_size: &quot; &lt;&lt; step_size &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;trans_epsilon: &quot; &lt;&lt; trans_eps &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;max_iter: &quot; &lt;&lt; max_iter &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;voxel_leaf_size: &quot; &lt;&lt; voxel_leaf_size &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;min_scan_range: &quot; &lt;&lt; min_scan_range &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;min_add_scan_shift: &quot; &lt;&lt; min_add_scan_shift &lt;&lt; std::endl;
}

static void output_callback(const runtime_manager::ConfigNdtMappingOutput::ConstPtr&amp; input)
{
  double filter_res = input-&gt;filter_res;
  std::string filename = input-&gt;filename;
  std::cout &lt;&lt; &quot;output_callback&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;filter_res: &quot; &lt;&lt; filter_res &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;filename: &quot; &lt;&lt; filename &lt;&lt; std::endl;

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(map));
  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr map_filtered(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());
  map_ptr-&gt;header.frame_id = &quot;map&quot;;
  map_filtered-&gt;header.frame_id = &quot;map&quot;;
  sensor_msgs::PointCloud2::Ptr map_msg_ptr(new sensor_msgs::PointCloud2);

  // Apply voxelgrid filter
  if (filter_res == 0.0)
  {
    std::cout &lt;&lt; &quot;Original: &quot; &lt;&lt; map_ptr-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    pcl::toROSMsg(*map_ptr, *map_msg_ptr);
  }
  else
  {
    pcl::VoxelGrid&lt;pcl::PointXYZI&gt; voxel_grid_filter;
    voxel_grid_filter.setLeafSize(filter_res, filter_res, filter_res);
    voxel_grid_filter.setInputCloud(map_ptr);
    voxel_grid_filter.filter(*map_filtered);
    std::cout &lt;&lt; &quot;Original: &quot; &lt;&lt; map_ptr-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Filtered: &quot; &lt;&lt; map_filtered-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    pcl::toROSMsg(*map_filtered, *map_msg_ptr);
  }

  ndt_map_pub.publish(*map_msg_ptr);

  // Writing Point Cloud data to PCD file
  if (filter_res == 0.0)
  {
    pcl::io::savePCDFileASCII(filename, *map_ptr);
    std::cout &lt;&lt; &quot;Saved &quot; &lt;&lt; map_ptr-&gt;points.size() &lt;&lt; &quot; data points to &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
  }
  else
  {
    pcl::io::savePCDFileASCII(filename, *map_filtered);
    std::cout &lt;&lt; &quot;Saved &quot; &lt;&lt; map_filtered-&gt;points.size() &lt;&lt; &quot; data points to &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
  }
}

static void imu_odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu_odom.roll  += diff_imu_roll;
  current_pose_imu_odom.pitch += diff_imu_pitch;
  current_pose_imu_odom.yaw   += diff_imu_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_imu_odom_x += diff_distance*cos(-current_pose_imu_odom.pitch)*cos(current_pose_imu_odom.yaw);
  offset_imu_odom_y += diff_distance*cos(-current_pose_imu_odom.pitch)*sin(current_pose_imu_odom.yaw);
  offset_imu_odom_z += diff_distance*sin(-current_pose_imu_odom.pitch);

  offset_imu_odom_roll  += diff_imu_roll;
  offset_imu_odom_pitch += diff_imu_pitch;
  offset_imu_odom_yaw   += diff_imu_yaw;

  guess_pose_imu_odom.x     = previous_pose.x     + offset_imu_odom_x;
  guess_pose_imu_odom.y     = previous_pose.y     + offset_imu_odom_y;
  guess_pose_imu_odom.z     = previous_pose.z     + offset_imu_odom_z;
  guess_pose_imu_odom.roll  = previous_pose.roll  + offset_imu_odom_roll;
  guess_pose_imu_odom.pitch = previous_pose.pitch + offset_imu_odom_pitch;
  guess_pose_imu_odom.yaw   = previous_pose.yaw   + offset_imu_odom_yaw;
 
  previous_time = current_time;
}


static void odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_odom_roll  = odom.twist.twist.angular.x * diff_time;
  double diff_odom_pitch = odom.twist.twist.angular.y * diff_time;
  double diff_odom_yaw   = odom.twist.twist.angular.z * diff_time;

  current_pose_odom.roll  += diff_odom_roll;
  current_pose_odom.pitch += diff_odom_pitch;
  current_pose_odom.yaw   += diff_odom_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_odom_x += diff_distance*cos(-current_pose_odom.pitch)*cos(current_pose_odom.yaw);
  offset_odom_y += diff_distance*cos(-current_pose_odom.pitch)*sin(current_pose_odom.yaw);
  offset_odom_z += diff_distance*sin(-current_pose_odom.pitch);

  offset_odom_roll  += diff_odom_roll;
  offset_odom_pitch += diff_odom_pitch;
  offset_odom_yaw   += diff_odom_yaw;

  guess_pose_odom.x     = previous_pose.x     + offset_odom_x;
  guess_pose_odom.y     = previous_pose.y     + offset_odom_y;
  guess_pose_odom.z     = previous_pose.z     + offset_odom_z;
  guess_pose_odom.roll  = previous_pose.roll  + offset_odom_roll;
  guess_pose_odom.pitch = previous_pose.pitch + offset_odom_pitch;
  guess_pose_odom.yaw   = previous_pose.yaw   + offset_odom_yaw;
 
  previous_time = current_time;
}

static void imu_calc(ros::Time current_time)
{

  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu.roll += diff_imu_roll;
  current_pose_imu.pitch += diff_imu_pitch;
  current_pose_imu.yaw += diff_imu_yaw;

  double accX1 = imu.linear_acceleration.x;
  double accY1 = std::cos(current_pose_imu.roll) * imu.linear_acceleration.y
                -std::sin(current_pose_imu.roll) * imu.linear_acceleration.z;
  double accZ1 = std::sin(current_pose_imu.roll) * imu.linear_acceleration.y
                +std::cos(current_pose_imu.roll) * imu.linear_acceleration.z;

  double accX2 = std::sin(current_pose_imu.pitch) * accZ1 + std::cos(current_pose_imu.pitch) * accX1;
  double accY2 = accY1;
  double accZ2 = std::cos(current_pose_imu.pitch) * accZ1 - std::sin(current_pose_imu.pitch) * accX1;

  double accX = std::cos(current_pose_imu.yaw) * accX2 - std::sin(current_pose_imu.yaw) * accY2;
  double accY = std::sin(current_pose_imu.yaw) * accX2 + std::cos(current_pose_imu.yaw) * accY2;
  double accZ = accZ2;

  offset_imu_x += current_velocity_imu_x * diff_time + accX * diff_time * diff_time / 2.0;
  offset_imu_y += current_velocity_imu_y * diff_time + accY * diff_time * diff_time / 2.0;
  offset_imu_z += current_velocity_imu_z * diff_time + accZ * diff_time * diff_time / 2.0;

  current_velocity_imu_x += accX * diff_time;
  current_velocity_imu_y += accY * diff_time;
  current_velocity_imu_z += accZ * diff_time;

  offset_imu_roll  += diff_imu_roll;
  offset_imu_pitch += diff_imu_pitch;
  offset_imu_yaw   += diff_imu_yaw;

  guess_pose_imu.x     = previous_pose.x     + offset_imu_x;
  guess_pose_imu.y     = previous_pose.y     + offset_imu_y;
  guess_pose_imu.z     = previous_pose.z     + offset_imu_z;
  guess_pose_imu.roll  = previous_pose.roll  + offset_imu_roll;
  guess_pose_imu.pitch = previous_pose.pitch + offset_imu_pitch;
  guess_pose_imu.yaw   = previous_pose.yaw   + offset_imu_yaw;  

  previous_time = current_time;
}


static double wrapToPm(double a_num, const double a_max)
{
    if (a_num &gt;= a_max)
    {
        a_num -= 2.0 * a_max;
    }
    return a_num;
}

static double wrapToPmPi(double a_angle_rad)
{
    return wrapToPm(a_angle_rad, M_PI);
}

static void odom_callback(const nav_msgs::Odometry::ConstPtr&amp; input)
{
  odom = *input;
  odom_calc(input-&gt;header.stamp);
}

static void imu_callback(const sensor_msgs::Imu::ConstPtr&amp; input)
{
  const ros::Time current_time = input-&gt;header.stamp;
  static ros::Time previous_time = current_time;
  const double diff_time =  (current_time - previous_time).toSec();

  double imu_roll, imu_pitch, imu_yaw;
  tf::Quaternion imu_orientation;
  tf::quaternionMsgToTF(input-&gt;orientation, imu_orientation);
  tf::Matrix3x3(imu_orientation).getRPY(imu_roll, imu_pitch, imu_yaw);

  imu_roll = wrapToPmPi(imu_roll);
  imu_pitch = wrapToPmPi(imu_pitch);
  imu_yaw = wrapToPmPi(imu_yaw);

  static double previous_imu_roll = imu_roll, previous_imu_pitch = imu_pitch, previous_imu_yaw = imu_yaw;
  const double diff_imu_roll  = imu_roll  - previous_imu_roll;

  const double diff_imu_pitch = imu_pitch - previous_imu_pitch;

  double diff_imu_yaw;
  if(fabs(imu_yaw - previous_imu_yaw) &gt; M_PI)
  {
    if(imu_yaw &gt; 0)
      diff_imu_yaw = (imu_yaw - previous_imu_yaw) - M_PI*2;
    else
      diff_imu_yaw = -M_PI*2 - (imu_yaw - previous_imu_yaw);
  }
  else
  diff_imu_yaw = imu_yaw - previous_imu_yaw;

  imu.header = input-&gt;header;
  imu.linear_acceleration.x = input-&gt;linear_acceleration.x;
  imu.linear_acceleration.y = input-&gt;linear_acceleration.y;
  imu.linear_acceleration.z = input-&gt;linear_acceleration.z;

  if(diff_time != 0)
  {
    imu.angular_velocity.x = diff_imu_roll  / diff_time;
    imu.angular_velocity.y = diff_imu_pitch / diff_time;
    imu.angular_velocity.z = diff_imu_yaw   / diff_time;
  }
  else
  {
    imu.angular_velocity.x = 0;
    imu.angular_velocity.y = 0;
    imu.angular_velocity.z = 0;
  }

  imu_calc(input-&gt;header.stamp);

  previous_time = current_time;
  previous_imu_roll  = imu_roll;
  previous_imu_pitch = imu_pitch;
  previous_imu_yaw   = imu_yaw;
}


static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  double r;
  pcl::PointXYZI p;
  pcl::PointCloud&lt;pcl::PointXYZI&gt; tmp, scan;
  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());
  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr transformed_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());
  tf::Quaternion q;

  Eigen::Matrix4f t_localizer(Eigen::Matrix4f::Identity());
  Eigen::Matrix4f t_base_link(Eigen::Matrix4f::Identity());
  tf::TransformBroadcaster br;
  tf::Transform transform;

  current_scan_time = input-&gt;header.stamp;

  pcl::fromROSMsg(*input, tmp);

  for (pcl::PointCloud&lt;pcl::PointXYZI&gt;::const_iterator item = tmp.begin(); item != tmp.end(); item++)
  {
    p.x = (double)item-&gt;x;
    p.y = (double)item-&gt;y;
    p.z = (double)item-&gt;z;
    p.intensity = (double)item-&gt;intensity;

    r = sqrt(pow(p.x, 2.0) + pow(p.y, 2.0));
    if (r &gt; min_scan_range)
    {
      scan.push_back(p);
    }
  }

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(scan));

  // Add initial point cloud to velodyne_map
  if (initial_scan_loaded == 0)
  {
    pcl::transformPointCloud(*scan_ptr, *transformed_scan_ptr, tf_btol);
    map += *transformed_scan_ptr;
    initial_scan_loaded = 1;
  }

  // Apply voxelgrid filter
  pcl::VoxelGrid&lt;pcl::PointXYZI&gt; voxel_grid_filter;
  voxel_grid_filter.setLeafSize(voxel_leaf_size, voxel_leaf_size, voxel_leaf_size);
  voxel_grid_filter.setInputCloud(scan_ptr);
  voxel_grid_filter.filter(*filtered_scan_ptr);

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(map));
  
  ndt.setTransformationEpsilon(trans_eps);
  ndt.setStepSize(step_size);
  ndt.setResolution(ndt_res);
  ndt.setMaximumIterations(max_iter);
  ndt.setInputSource(filtered_scan_ptr);

  if (isMapUpdate == true)
  {
    ndt.setInputTarget(map_ptr);
    isMapUpdate = false;
  }

  guess_pose.x = previous_pose.x + diff_x;
  guess_pose.y = previous_pose.y + diff_y;
  guess_pose.z = previous_pose.z + diff_z;
  guess_pose.roll = previous_pose.roll;
  guess_pose.pitch = previous_pose.pitch;
  guess_pose.yaw = previous_pose.yaw + diff_yaw;


  if (_use_imu == true &amp;&amp; _use_odom == true)
    imu_odom_calc(current_scan_time);
  if(_use_imu == true &amp;&amp; _use_odom == true)
    imu_calc(current_scan_time);
  if (_use_imu == false &amp;&amp; _use_odom == true)
    odom_calc(current_scan_time);

  pose guess_pose_for_ndt;
  if(_use_imu == true &amp;&amp; _use_odom == true)
    guess_pose_for_ndt = guess_pose_imu_odom;
  else if(_use_imu == true &amp;&amp; _use_odom == false)
    guess_pose_for_ndt = guess_pose_imu;
  else if(_use_imu == false &amp;&amp; _use_odom == true)
    guess_pose_for_ndt = guess_pose_odom;
  else
    guess_pose_for_ndt = guess_pose;

  Eigen::AngleAxisf init_rotation_x(guess_pose_for_ndt.roll, Eigen::Vector3f::UnitX());
  Eigen::AngleAxisf init_rotation_y(guess_pose_for_ndt.pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf init_rotation_z(guess_pose_for_ndt.yaw, Eigen::Vector3f::UnitZ());

  Eigen::Translation3f init_translation(guess_pose_for_ndt.x, guess_pose_for_ndt.y, guess_pose_for_ndt.z);

  Eigen::Matrix4f init_guess =
      (init_translation * init_rotation_z * init_rotation_y * init_rotation_x).matrix() * tf_btol;

  t3_end = ros::Time::now();
  d3 = t3_end - t3_start;

  t4_start = ros::Time::now();

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZI&gt;);
#ifdef USE_FAST_PCL
  if (_use_openmp == true)
  {
    ndt.omp_align(*output_cloud, init_guess);
    fitness_score = ndt.omp_getFitnessScore();
  }
  else
  {
#endif
    ndt.align(*output_cloud, init_guess);
    fitness_score = ndt.getFitnessScore();
#ifdef USE_FAST_PCL
  }
#endif

  t_localizer = ndt.getFinalTransformation();
  t_base_link = t_localizer * tf_ltob;

  pcl::transformPointCloud(*scan_ptr, *transformed_scan_ptr, t_localizer);

  tf::Matrix3x3 mat_l, mat_b;

  mat_l.setValue(static_cast&lt;double&gt;(t_localizer(0, 0)), static_cast&lt;double&gt;(t_localizer(0, 1)),
                 static_cast&lt;double&gt;(t_localizer(0, 2)), static_cast&lt;double&gt;(t_localizer(1, 0)),
                 static_cast&lt;double&gt;(t_localizer(1, 1)), static_cast&lt;double&gt;(t_localizer(1, 2)),
                 static_cast&lt;double&gt;(t_localizer(2, 0)), static_cast&lt;double&gt;(t_localizer(2, 1)),
                 static_cast&lt;double&gt;(t_localizer(2, 2)));

  mat_b.setValue(static_cast&lt;double&gt;(t_base_link(0, 0)), static_cast&lt;double&gt;(t_base_link(0, 1)),
                 static_cast&lt;double&gt;(t_base_link(0, 2)), static_cast&lt;double&gt;(t_base_link(1, 0)),
                 static_cast&lt;double&gt;(t_base_link(1, 1)), static_cast&lt;double&gt;(t_base_link(1, 2)),
                 static_cast&lt;double&gt;(t_base_link(2, 0)), static_cast&lt;double&gt;(t_base_link(2, 1)),
                 static_cast&lt;double&gt;(t_base_link(2, 2)));

  // Update localizer_pose.
  localizer_pose.x = t_localizer(0, 3);
  localizer_pose.y = t_localizer(1, 3);
  localizer_pose.z = t_localizer(2, 3);
  mat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1);

  // Update ndt_pose.
  ndt_pose.x = t_base_link(0, 3);
  ndt_pose.y = t_base_link(1, 3);
  ndt_pose.z = t_base_link(2, 3);
  mat_b.getRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw, 1);

  current_pose.x = ndt_pose.x;
  current_pose.y = ndt_pose.y;
  current_pose.z = ndt_pose.z;
  current_pose.roll = ndt_pose.roll;
  current_pose.pitch = ndt_pose.pitch;
  current_pose.yaw = ndt_pose.yaw;

  transform.setOrigin(tf::Vector3(current_pose.x, current_pose.y, current_pose.z));
  q.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);
  transform.setRotation(q);

  br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;map&quot;, &quot;base_link&quot;));

  scan_duration = current_scan_time - previous_scan_time;
  double secs = scan_duration.toSec();

  // Calculate the offset (curren_pos - previous_pos)
  diff_x = current_pose.x - previous_pose.x;
  diff_y = current_pose.y - previous_pose.y;
  diff_z = current_pose.z - previous_pose.z;
  diff_yaw = current_pose.yaw - previous_pose.yaw;
  diff = sqrt(diff_x * diff_x + diff_y * diff_y + diff_z * diff_z);

  current_velocity_x = diff_x / secs;
  current_velocity_y = diff_y / secs;
  current_velocity_z = diff_z / secs;

  current_pose_imu.x = current_pose.x;
  current_pose_imu.y = current_pose.y;
  current_pose_imu.z = current_pose.z;
  current_pose_imu.roll = current_pose.roll;
  current_pose_imu.pitch = current_pose.pitch;
  current_pose_imu.yaw = current_pose.yaw;

  current_pose_odom.x = current_pose.x;
  current_pose_odom.y = current_pose.y;
  current_pose_odom.z = current_pose.z;
  current_pose_odom.roll = current_pose.roll;
  current_pose_odom.pitch = current_pose.pitch;
  current_pose_odom.yaw = current_pose.yaw;

  current_pose_imu_odom.x = current_pose.x;
  current_pose_imu_odom.y = current_pose.y;
  current_pose_imu_odom.z = current_pose.z;
  current_pose_imu_odom.roll = current_pose.roll;
  current_pose_imu_odom.pitch = current_pose.pitch;
  current_pose_imu_odom.yaw = current_pose.yaw;

  current_velocity_imu_x = current_velocity_x;
  current_velocity_imu_y = current_velocity_y;
  current_velocity_imu_z = current_velocity_z;

  // Update position and posture. current_pos -&gt; previous_pos
  previous_pose.x = current_pose.x;
  previous_pose.y = current_pose.y;
  previous_pose.z = current_pose.z;
  previous_pose.roll = current_pose.roll;
  previous_pose.pitch = current_pose.pitch;
  previous_pose.yaw = current_pose.yaw;

  previous_scan_time.sec = current_scan_time.sec;
  previous_scan_time.nsec = current_scan_time.nsec;
  
  offset_x = 0.0;
  offset_y = 0.0;
  offset_z = 0.0;
  offset_roll = 0.0;
  offset_pitch = 0.0;
  offset_yaw = 0.0;

  offset_imu_x = 0.0;
  offset_imu_y = 0.0;
  offset_imu_z = 0.0;
  offset_imu_roll = 0.0;
  offset_imu_pitch = 0.0;
  offset_imu_yaw = 0.0;

  offset_odom_x = 0.0;
  offset_odom_y = 0.0;
  offset_odom_z = 0.0;
  offset_odom_roll = 0.0;
  offset_odom_pitch = 0.0;
  offset_odom_yaw = 0.0;

  offset_imu_odom_x = 0.0;
  offset_imu_odom_y = 0.0;
  offset_imu_odom_z = 0.0;
  offset_imu_odom_roll = 0.0;
  offset_imu_odom_pitch = 0.0;
  offset_imu_odom_yaw = 0.0;
  
  // Calculate the shift between added_pos and current_pos
  double shift = sqrt(pow(current_pose.x - added_pose.x, 2.0) + pow(current_pose.y - added_pose.y, 2.0));
  if (shift &gt;= min_add_scan_shift)
  {
    map += *transformed_scan_ptr;
    added_pose.x = current_pose.x;
    added_pose.y = current_pose.y;
    added_pose.z = current_pose.z;
    added_pose.roll = current_pose.roll;
    added_pose.pitch = current_pose.pitch;
    added_pose.yaw = current_pose.yaw;
    isMapUpdate = true;
  }

  sensor_msgs::PointCloud2::Ptr map_msg_ptr(new sensor_msgs::PointCloud2);
  pcl::toROSMsg(*map_ptr, *map_msg_ptr);
  ndt_map_pub.publish(*map_msg_ptr);

  q.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);
  current_pose_msg.header.frame_id = &quot;map&quot;;
  current_pose_msg.header.stamp = current_scan_time;
  current_pose_msg.pose.position.x = current_pose.x;
  current_pose_msg.pose.position.y = current_pose.y;
  current_pose_msg.pose.position.z = current_pose.z;
  current_pose_msg.pose.orientation.x = q.x();
  current_pose_msg.pose.orientation.y = q.y();
  current_pose_msg.pose.orientation.z = q.z();
  current_pose_msg.pose.orientation.w = q.w();

  current_pose_pub.publish(current_pose_msg);


  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Sequence number: &quot; &lt;&lt; input-&gt;header.seq &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Number of scan points: &quot; &lt;&lt; scan_ptr-&gt;size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Number of filtered scan points: &quot; &lt;&lt; filtered_scan_ptr-&gt;size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;transformed_scan_ptr: &quot; &lt;&lt; transformed_scan_ptr-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;map: &quot; &lt;&lt; map.points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;NDT has converged: &quot; &lt;&lt; ndt.hasConverged() &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Fitness score: &quot; &lt;&lt; fitness_score &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Number of iteration: &quot; &lt;&lt; ndt.getFinalNumIteration() &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;(x,y,z,roll,pitch,yaw):&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;(&quot; &lt;&lt; current_pose.x &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.y &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.z &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.roll
            &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.pitch &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Transformation Matrix:&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; t_localizer &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;shift: &quot; &lt;&lt; shift &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
}

int main(int argc, char** argv)
{
  previous_pose.x = 0.0;
  previous_pose.y = 0.0;
  previous_pose.z = 0.0;
  previous_pose.roll = 0.0;
  previous_pose.pitch = 0.0;
  previous_pose.yaw = 0.0;

  ndt_pose.x = 0.0;
  ndt_pose.y = 0.0;
  ndt_pose.z = 0.0;
  ndt_pose.roll = 0.0;
  ndt_pose.pitch = 0.0;
  ndt_pose.yaw = 0.0;

  current_pose.x = 0.0;
  current_pose.y = 0.0;
  current_pose.z = 0.0;
  current_pose.roll = 0.0;
  current_pose.pitch = 0.0;
  current_pose.yaw = 0.0;

  current_pose_imu.x = 0.0;
  current_pose_imu.y = 0.0;
  current_pose_imu.z = 0.0;
  current_pose_imu.roll = 0.0;
  current_pose_imu.pitch = 0.0;
  current_pose_imu.yaw = 0.0;

  guess_pose.x = 0.0;
  guess_pose.y = 0.0;
  guess_pose.z = 0.0;
  guess_pose.roll = 0.0;
  guess_pose.pitch = 0.0;
  guess_pose.yaw = 0.0;

  guess_pose_imu.x = 0.0;
  guess_pose_imu.y = 0.0;
  guess_pose_imu.z = 0.0;
  guess_pose_imu.roll = 0.0;
  guess_pose_imu.pitch = 0.0;
  guess_pose_imu.yaw = 0.0;

  added_pose.x = 0.0;
  added_pose.y = 0.0;
  added_pose.z = 0.0;
  added_pose.roll = 0.0;
  added_pose.pitch = 0.0;
  added_pose.yaw = 0.0;

  offset_x = 0.0;
  offset_y = 0.0;
  offset_z = 0.0;
  offset_roll = 0.0;
  offset_pitch = 0.0;
  offset_yaw = 0.0;

  offset_imu_x = 0.0;
  offset_imu_y = 0.0;
  offset_imu_z = 0.0;
  offset_imu_roll = 0.0;
  offset_imu_pitch = 0.0;
  offset_imu_yaw = 0.0;

  offset_odom_x = 0.0;
  offset_odom_y = 0.0;
  offset_odom_z = 0.0;
  offset_odom_roll = 0.0;
  offset_odom_pitch = 0.0;
  offset_odom_yaw = 0.0;

  offset_imu_odom_x = 0.0;
  offset_imu_odom_y = 0.0;
  offset_imu_odom_z = 0.0;
  offset_imu_odom_roll = 0.0;
  offset_imu_odom_pitch = 0.0;
  offset_imu_odom_yaw = 0.0;

  ros::init(argc, argv, &quot;ndt_mapping&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  // setting parameters
  private_nh.getParam(&quot;use_openmp&quot;, _use_openmp);
  private_nh.getParam(&quot;use_imu&quot;, _use_imu);
  private_nh.getParam(&quot;use_odom&quot;, _use_odom);

  std::cout &lt;&lt; &quot;use_openmp: &quot; &lt;&lt; _use_openmp &lt;&lt; std::endl;

  if (nh.getParam(&quot;tf_x&quot;, _tf_x) == false)
  {
    std::cout &lt;&lt; &quot;tf_x is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_y&quot;, _tf_y) == false)
  {
    std::cout &lt;&lt; &quot;tf_y is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_z&quot;, _tf_z) == false)
  {
    std::cout &lt;&lt; &quot;tf_z is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_roll&quot;, _tf_roll) == false)
  {
    std::cout &lt;&lt; &quot;tf_roll is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_pitch&quot;, _tf_pitch) == false)
  {
    std::cout &lt;&lt; &quot;tf_pitch is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_yaw&quot;, _tf_yaw) == false)
  {
    std::cout &lt;&lt; &quot;tf_yaw is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }

  std::cout &lt;&lt; &quot;(tf_x,tf_y,tf_z,tf_roll,tf_pitch,tf_yaw): (&quot; &lt;&lt; _tf_x &lt;&lt; &quot;, &quot; &lt;&lt; _tf_y &lt;&lt; &quot;, &quot; &lt;&lt; _tf_z &lt;&lt; &quot;, &quot;
            &lt;&lt; _tf_roll &lt;&lt; &quot;, &quot; &lt;&lt; _tf_pitch &lt;&lt; &quot;, &quot; &lt;&lt; _tf_yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;

  Eigen::Translation3f tl_btol(_tf_x, _tf_y, _tf_z);                 // tl: translation
  Eigen::AngleAxisf rot_x_btol(_tf_roll, Eigen::Vector3f::UnitX());  // rot: rotation
  Eigen::AngleAxisf rot_y_btol(_tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_btol(_tf_yaw, Eigen::Vector3f::UnitZ());
  tf_btol = (tl_btol * rot_z_btol * rot_y_btol * rot_x_btol).matrix();

  Eigen::Translation3f tl_ltob((-1.0) * _tf_x, (-1.0) * _tf_y, (-1.0) * _tf_z);  // tl: translation
  Eigen::AngleAxisf rot_x_ltob((-1.0) * _tf_roll, Eigen::Vector3f::UnitX());     // rot: rotation
  Eigen::AngleAxisf rot_y_ltob((-1.0) * _tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_ltob((-1.0) * _tf_yaw, Eigen::Vector3f::UnitZ());
  tf_ltob = (tl_ltob * rot_z_ltob * rot_y_ltob * rot_x_ltob).matrix();

  map.header.frame_id = &quot;map&quot;;

  ndt_map_pub = nh.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/ndt_map&quot;, 1000);
  current_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/current_pose&quot;, 1000);

  ros::Subscriber param_sub = nh.subscribe(&quot;config/ndt_mapping&quot;, 10, param_callback);
  ros::Subscriber output_sub = nh.subscribe(&quot;config/ndt_mapping_output&quot;, 10, output_callback);
  ros::Subscriber points_sub = nh.subscribe(&quot;points_raw&quot;, 100000, points_callback);
  ros::Subscriber odom_sub = nh.subscribe(&quot;odom_pose&quot;, 100000, odom_callback);
  ros::Subscriber imu_sub = nh.subscribe(&quot;imu_raw&quot;, 100000, imu_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_matching/ndt_matching.cpp" new_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_matching/ndt_matching.cpp">
				<diff>@@ -609,12 +609,16 @@ static const double wrapToPmPi(double a_angle_rad)
 
 static void odom_callback(const nav_msgs::Odometry::ConstPtr&amp; input)
 {
+  std::cout &lt;&lt; __func__ &lt;&lt; std::endl;
+
   odom = *input;
   odom_calc(input-&gt;header.stamp);
 }
 
 static void imu_callback(const sensor_msgs::Imu::ConstPtr&amp; input)
 {
+  std::cout &lt;&lt; __func__ &lt;&lt; std::endl;
+
   const ros::Time current_time = input-&gt;header.stamp;
   static ros::Time previous_time = current_time;
   const double diff_time =  (current_time - previous_time).toSec();
@@ -1242,8 +1246,6 @@ int main(int argc, char** argv)
   private_nh.getParam(&quot;use_imu&quot;, _use_imu);
   private_nh.getParam(&quot;use_odom&quot;, _use_odom);
 
-  _tf_x = _tf_y = _tf_z = _tf_roll = _tf_pitch = _tf_yaw = 0;
-
   if (nh.getParam(&quot;localizer&quot;, _localizer) == false)
   {
     std::cout &lt;&lt; &quot;localizer is not set.&quot; &lt;&lt; std::endl;
@@ -1337,8 +1339,8 @@ int main(int argc, char** argv)
   ros::Subscriber map_sub = nh.subscribe(&quot;points_map&quot;, 10, map_callback);
   ros::Subscriber initialpose_sub = nh.subscribe(&quot;initialpose&quot;, 1000, initialpose_callback);
   ros::Subscriber points_sub = nh.subscribe(&quot;filtered_points&quot;, _queue_size, points_callback);
-  ros::Subscriber odom_sub = nh.subscribe(&quot;odom_pose&quot;, _queue_size*10, odom_callback);
-  ros::Subscriber imu_sub = nh.subscribe(&quot;imu_raw&quot;, _queue_size*10, imu_callback);
+  ros::Subscriber odom_sub = nh.subscribe(&quot;/odom_pose&quot;, _queue_size*10, odom_callback);
+  ros::Subscriber imu_sub = nh.subscribe(&quot;/imu_raw&quot;, _queue_size*10, imu_callback);
 
   ros::spin();
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

/*
 Localization program using Normal Distributions Transform

 Yuki KITSUKAWA
 */

#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;fstream&gt;
#include &lt;string&gt;
#include &lt;chrono&gt;

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/Float32.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;std_msgs/Bool.h&gt;
#include &lt;nav_msgs/Odometry.h&gt;
#include &lt;sensor_msgs/Imu.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;velodyne_pointcloud/point_types.h&gt;
#include &lt;velodyne_pointcloud/rawdata.h&gt;

#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;

#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;tf/transform_listener.h&gt;

#include &lt;pcl/io/io.h&gt;
#include &lt;pcl/io/pcd_io.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#ifdef USE_FAST_PCL
#include &lt;fast_pcl/registration/ndt.h&gt;
#else
#include &lt;pcl/registration/ndt.h&gt;
#endif

#include &lt;pcl_ros/point_cloud.h&gt;
#include &lt;pcl_ros/transforms.h&gt;

#include &lt;runtime_manager/ConfigNdt.h&gt;

#include &lt;ndt_localizer/ndt_stat.h&gt;

#define PREDICT_POSE_THRESHOLD 0.5

#define Wa 0.4
#define Wb 0.3
#define Wc 0.3

struct pose
{
  double x;
  double y;
  double z;
  double roll;
  double pitch;
  double yaw;
};

static pose initial_pose, predict_pose, predict_pose_imu, predict_pose_odom, predict_pose_imu_odom, previous_pose, ndt_pose, current_pose, current_pose_imu, current_pose_odom, current_pose_imu_odom, localizer_pose, previous_gnss_pose,
    current_gnss_pose;

static double offset_x, offset_y, offset_z, offset_yaw;  // current_pos - previous_pose
static double offset_imu_x, offset_imu_y, offset_imu_z, offset_imu_roll, offset_imu_pitch, offset_imu_yaw; 
static double offset_odom_x, offset_odom_y, offset_odom_z, offset_odom_roll, offset_odom_pitch, offset_odom_yaw;
static double offset_imu_odom_x, offset_imu_odom_y, offset_imu_odom_z, offset_imu_odom_roll, offset_imu_odom_pitch, offset_imu_odom_yaw;

// Can't load if typed &quot;pcl::PointCloud&lt;pcl::PointXYZRGB&gt; map, add;&quot;
static pcl::PointCloud&lt;pcl::PointXYZ&gt; map, add;

// If the map is loaded, map_loaded will be 1.
static int map_loaded = 0;
static int _use_gnss = 1;
static int init_pos_set = 0;

static pcl::NormalDistributionsTransform&lt;pcl::PointXYZ, pcl::PointXYZ&gt; ndt;
// Default values
static int max_iter = 30;        // Maximum iterations
static float ndt_res = 1.0;      // Resolution
static double step_size = 0.1;   // Step size
static double trans_eps = 0.01;  // Transformation epsilon

static ros::Publisher predict_pose_pub;
static geometry_msgs::PoseStamped predict_pose_msg;

static ros::Publisher predict_pose_imu_pub;
static geometry_msgs::PoseStamped predict_pose_imu_msg;

static ros::Publisher predict_pose_odom_pub;
static geometry_msgs::PoseStamped predict_pose_odom_msg;

static ros::Publisher predict_pose_imu_odom_pub;
static geometry_msgs::PoseStamped predict_pose_imu_odom_msg;

static ros::Publisher ndt_pose_pub;
static geometry_msgs::PoseStamped ndt_pose_msg;

// current_pose is published by vel_pose_mux
/*
static ros::Publisher current_pose_pub;
static geometry_msgs::PoseStamped current_pose_msg;
*/

static ros::Publisher localizer_pose_pub;
static geometry_msgs::PoseStamped localizer_pose_msg;

static ros::Publisher estimate_twist_pub;
static geometry_msgs::TwistStamped estimate_twist_msg;

static ros::Time current_scan_time;
static ros::Time previous_scan_time;
static ros::Duration scan_duration;

static double exe_time = 0.0;
static int iteration = 0;
static double fitness_score = 0.0;
static double trans_probability = 0.0;

static double diff = 0.0;
static double diff_x = 0.0, diff_y = 0.0, diff_z = 0.0, diff_yaw;

static double current_velocity = 0.0, previous_velocity = 0.0, previous_previous_velocity = 0.0;  // [m/s]
static double current_velocity_x = 0.0, previous_velocity_x = 0.0;
static double current_velocity_y = 0.0, previous_velocity_y = 0.0;
static double current_velocity_z = 0.0, previous_velocity_z = 0.0;
// static double current_velocity_yaw = 0.0, previous_velocity_yaw = 0.0;
static double current_velocity_smooth = 0.0;

static double current_velocity_imu_x = 0.0;
static double current_velocity_imu_y = 0.0;
static double current_velocity_imu_z = 0.0;

static double current_accel = 0.0, previous_accel = 0.0;  // [m/s^2]
static double current_accel_x = 0.0;
static double current_accel_y = 0.0;
static double current_accel_z = 0.0;
// static double current_accel_yaw = 0.0;

static double angular_velocity = 0.0;

static int use_predict_pose = 0;

static ros::Publisher estimated_vel_mps_pub, estimated_vel_kmph_pub, estimated_vel_pub;
static std_msgs::Float32 estimated_vel_mps, estimated_vel_kmph, previous_estimated_vel_kmph;

static std::chrono::time_point&lt;std::chrono::system_clock&gt; matching_start, matching_end;

static ros::Publisher time_ndt_matching_pub;
static std_msgs::Float32 time_ndt_matching;

static int _queue_size = 1000;

static ros::Publisher ndt_stat_pub;
static ndt_localizer::ndt_stat ndt_stat_msg;

static double predict_pose_error = 0.0;

static double _tf_x, _tf_y, _tf_z, _tf_roll, _tf_pitch, _tf_yaw;
static Eigen::Matrix4f tf_btol, tf_ltob;

static std::string _localizer = &quot;velodyne&quot;;
static std::string _offset = &quot;linear&quot;;  // linear, zero, quadratic

static ros::Publisher ndt_reliability_pub;
static std_msgs::Float32 ndt_reliability;

static bool _use_openmp = false;
static bool _get_height = false;
static bool _use_local_transform = false;
static bool _use_imu = false;
static bool _use_odom = false;

static std::ofstream ofs;
static std::string filename;

static sensor_msgs::Imu imu;
static nav_msgs::Odometry odom;


// static tf::TransformListener local_transform_listener;
static tf::StampedTransform local_transform;

static void param_callback(const runtime_manager::ConfigNdt::ConstPtr&amp; input)
{
  if (_use_gnss != input-&gt;init_pos_gnss)
  {
    init_pos_set = 0;
  }
  else if (_use_gnss == 0 &amp;&amp;
           (initial_pose.x != input-&gt;x || initial_pose.y != input-&gt;y || initial_pose.z != input-&gt;z ||
            initial_pose.roll != input-&gt;roll || initial_pose.pitch != input-&gt;pitch || initial_pose.yaw != input-&gt;yaw))
  {
    init_pos_set = 0;
  }

  _use_gnss = input-&gt;init_pos_gnss;

  // Setting parameters
  if (input-&gt;resolution != ndt_res)
  {
    ndt_res = input-&gt;resolution;
    ndt.setResolution(ndt_res);
  }
  if (input-&gt;step_size != step_size)
  {
    step_size = input-&gt;step_size;
    ndt.setStepSize(step_size);
  }
  if (input-&gt;trans_epsilon != trans_eps)
  {
    trans_eps = input-&gt;trans_epsilon;
    ndt.setTransformationEpsilon(trans_eps);
  }
  if (input-&gt;max_iterations != max_iter)
  {
    max_iter = input-&gt;max_iterations;
    ndt.setMaximumIterations(max_iter);
  }

  if (_use_gnss == 0 &amp;&amp; init_pos_set == 0)
  {
    initial_pose.x = input-&gt;x;
    initial_pose.y = input-&gt;y;
    initial_pose.z = input-&gt;z;
    initial_pose.roll = input-&gt;roll;
    initial_pose.pitch = input-&gt;pitch;
    initial_pose.yaw = input-&gt;yaw;

    if (_use_local_transform == true)
    {
      tf::Vector3 v(input-&gt;x, input-&gt;y, input-&gt;z);
      tf::Quaternion q;
      q.setRPY(input-&gt;roll, input-&gt;pitch, input-&gt;yaw);
      tf::Transform transform(q, v);
      initial_pose.x = (local_transform.inverse() * transform).getOrigin().getX();
      initial_pose.y = (local_transform.inverse() * transform).getOrigin().getY();
      initial_pose.z = (local_transform.inverse() * transform).getOrigin().getZ();

      tf::Matrix3x3 m(q);
      m.getRPY(initial_pose.roll, initial_pose.pitch, initial_pose.yaw);

      std::cout &lt;&lt; &quot;initial_pose.x: &quot; &lt;&lt; initial_pose.x &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.y: &quot; &lt;&lt; initial_pose.y &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.z: &quot; &lt;&lt; initial_pose.z &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.roll: &quot; &lt;&lt; initial_pose.roll &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.pitch: &quot; &lt;&lt; initial_pose.pitch &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.yaw: &quot; &lt;&lt; initial_pose.yaw &lt;&lt; std::endl;
    }

    // Setting position and posture for the first time.
    localizer_pose.x = initial_pose.x;
    localizer_pose.y = initial_pose.y;
    localizer_pose.z = initial_pose.z;
    localizer_pose.roll = initial_pose.roll;
    localizer_pose.pitch = initial_pose.pitch;
    localizer_pose.yaw = initial_pose.yaw;

    previous_pose.x = initial_pose.x;
    previous_pose.y = initial_pose.y;
    previous_pose.z = initial_pose.z;
    previous_pose.roll = initial_pose.roll;
    previous_pose.pitch = initial_pose.pitch;
    previous_pose.yaw = initial_pose.yaw;

    current_pose.x = initial_pose.x;
    current_pose.y = initial_pose.y;
    current_pose.z = initial_pose.z;
    current_pose.roll = initial_pose.roll;
    current_pose.pitch = initial_pose.pitch;
    current_pose.yaw = initial_pose.yaw;

    init_pos_set = 1;
  }
}

static void map_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  if (map_loaded == 0)
  {
    // Convert the data type(from sensor_msgs to pcl).
    pcl::fromROSMsg(*input, map);

    if (_use_local_transform == true)
    {
      tf::TransformListener local_transform_listener;
      try
      {
        ros::Time now = ros::Time(0);
        local_transform_listener.waitForTransform(&quot;/map&quot;, &quot;/world&quot;, now, ros::Duration(10.0));
        local_transform_listener.lookupTransform(&quot;/map&quot;, &quot;world&quot;, now, local_transform);
      }
      catch (tf::TransformException&amp; ex)
      {
        ROS_ERROR(&quot;%s&quot;, ex.what());
      }

      pcl_ros::transformPointCloud(map, map, local_transform.inverse());
    }

    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(map));
    // Setting point cloud to be aligned to.
    ndt.setInputTarget(map_ptr);

    // Setting NDT parameters to default values
    ndt.setMaximumIterations(max_iter);
    ndt.setResolution(ndt_res);
    ndt.setStepSize(step_size);
    ndt.setTransformationEpsilon(trans_eps);

    map_loaded = 1;
  }
}

static void gnss_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; input)
{
  tf::Quaternion gnss_q(input-&gt;pose.orientation.x, input-&gt;pose.orientation.y, input-&gt;pose.orientation.z,
                        input-&gt;pose.orientation.w);
  tf::Matrix3x3 gnss_m(gnss_q);
  current_gnss_pose.x = input-&gt;pose.position.x;
  current_gnss_pose.y = input-&gt;pose.position.y;
  current_gnss_pose.z = input-&gt;pose.position.z;
  gnss_m.getRPY(current_gnss_pose.roll, current_gnss_pose.pitch, current_gnss_pose.yaw);

  if ((_use_gnss == 1 &amp;&amp; init_pos_set == 0) || fitness_score &gt;= 500.0)
  {
    previous_pose.x = previous_gnss_pose.x;
    previous_pose.y = previous_gnss_pose.y;
    previous_pose.z = previous_gnss_pose.z;
    previous_pose.roll = previous_gnss_pose.roll;
    previous_pose.pitch = previous_gnss_pose.pitch;
    previous_pose.yaw = previous_gnss_pose.yaw;

    current_pose.x = current_gnss_pose.x;
    current_pose.y = current_gnss_pose.y;
    current_pose.z = current_gnss_pose.z;
    current_pose.roll = current_gnss_pose.roll;
    current_pose.pitch = current_gnss_pose.pitch;
    current_pose.yaw = current_gnss_pose.yaw;

    offset_x = current_pose.x - previous_pose.x;
    offset_y = current_pose.y - previous_pose.y;
    offset_z = current_pose.z - previous_pose.z;
    offset_yaw = current_pose.yaw - previous_pose.yaw;

    //TODO: add imu and odom

    init_pos_set = 1;
  }

  previous_gnss_pose.x = current_gnss_pose.x;
  previous_gnss_pose.y = current_gnss_pose.y;
  previous_gnss_pose.z = current_gnss_pose.z;
  previous_gnss_pose.roll = current_gnss_pose.roll;
  previous_gnss_pose.pitch = current_gnss_pose.pitch;
  previous_gnss_pose.yaw = current_gnss_pose.yaw;
}

static void initialpose_callback(const geometry_msgs::PoseWithCovarianceStamped::ConstPtr&amp; input)
{
  tf::TransformListener listener;
  tf::StampedTransform transform;
  try
  {
    ros::Time now = ros::Time(0);
    listener.waitForTransform(&quot;/map&quot;, &quot;/world&quot;, now, ros::Duration(10.0));
    listener.lookupTransform(&quot;/map&quot;, &quot;world&quot;, now, transform);
  }
  catch (tf::TransformException&amp; ex)
  {
    ROS_ERROR(&quot;%s&quot;, ex.what());
  }

  tf::Quaternion q(input-&gt;pose.pose.orientation.x, input-&gt;pose.pose.orientation.y, input-&gt;pose.pose.orientation.z,
                   input-&gt;pose.pose.orientation.w);
  tf::Matrix3x3 m(q);

  //TODO: add imu and odom

  if (_use_local_transform == true)
  {
    current_pose.x = input-&gt;pose.pose.position.x;
    current_pose.y = input-&gt;pose.pose.position.y;
    current_pose.z = input-&gt;pose.pose.position.z;
  }
  else
  {
    current_pose.x = input-&gt;pose.pose.position.x + transform.getOrigin().x();
    current_pose.y = input-&gt;pose.pose.position.y + transform.getOrigin().y();
    current_pose.z = input-&gt;pose.pose.position.z + transform.getOrigin().z();
  }
  m.getRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);

  if (_get_height == true &amp;&amp; map_loaded == 1)
  {
    double min_distance = DBL_MAX;
    double nearest_z = current_pose.z;
    for (const auto&amp; p : map)
    {
      double distance = hypot(current_pose.x - p.x, current_pose.y - p.y);
      if (distance &lt; min_distance)
      {
        min_distance = distance;
        nearest_z = p.z;
      }
    }
    current_pose.z = nearest_z;
  }
  
  current_pose_imu = current_pose_odom = current_pose_imu_odom = current_pose;
  previous_pose.x = current_pose.x;
  previous_pose.y = current_pose.y;
  previous_pose.z = current_pose.z;
  previous_pose.roll = current_pose.roll;
  previous_pose.pitch = current_pose.pitch;
  previous_pose.yaw = current_pose.yaw;

  offset_x = 0.0;
  offset_y = 0.0;
  offset_z = 0.0;
  offset_yaw = 0.0;

  offset_imu_x = 0.0;
  offset_imu_y = 0.0;
  offset_imu_z = 0.0;
  offset_imu_roll = 0.0;
  offset_imu_pitch = 0.0;
  offset_imu_yaw = 0.0;

  offset_odom_x = 0.0;
  offset_odom_y = 0.0;
  offset_odom_z = 0.0;
  offset_odom_roll = 0.0;
  offset_odom_pitch = 0.0;
  offset_odom_yaw = 0.0;

  offset_imu_odom_x = 0.0;
  offset_imu_odom_y = 0.0;
  offset_imu_odom_z = 0.0;
  offset_imu_odom_roll = 0.0;
  offset_imu_odom_pitch = 0.0;
  offset_imu_odom_yaw = 0.0;

}

static void imu_odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu_odom.roll  += diff_imu_roll;
  current_pose_imu_odom.pitch += diff_imu_pitch;
  current_pose_imu_odom.yaw   += diff_imu_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_imu_odom_x += diff_distance*cos(-current_pose_imu_odom.pitch)*cos(current_pose_imu_odom.yaw);
  offset_imu_odom_y += diff_distance*cos(-current_pose_imu_odom.pitch)*sin(current_pose_imu_odom.yaw);
  offset_imu_odom_z += diff_distance*sin(-current_pose_imu_odom.pitch);

  offset_imu_odom_roll  += diff_imu_roll;
  offset_imu_odom_pitch += diff_imu_pitch;
  offset_imu_odom_yaw   += diff_imu_yaw;

  predict_pose_imu_odom.x     = previous_pose.x     + offset_imu_odom_x;
  predict_pose_imu_odom.y     = previous_pose.y     + offset_imu_odom_y;
  predict_pose_imu_odom.z     = previous_pose.z     + offset_imu_odom_z;
  predict_pose_imu_odom.roll  = previous_pose.roll  + offset_imu_odom_roll;
  predict_pose_imu_odom.pitch = previous_pose.pitch + offset_imu_odom_pitch;
  predict_pose_imu_odom.yaw   = previous_pose.yaw   + offset_imu_odom_yaw;
 
  previous_time = current_time;
}


static void odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_odom_roll  = odom.twist.twist.angular.x * diff_time;
  double diff_odom_pitch = odom.twist.twist.angular.y * diff_time;
  double diff_odom_yaw   = odom.twist.twist.angular.z * diff_time;

  current_pose_odom.roll  += diff_odom_roll;
  current_pose_odom.pitch += diff_odom_pitch;
  current_pose_odom.yaw   += diff_odom_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_odom_x += diff_distance*cos(-current_pose_odom.pitch)*cos(current_pose_odom.yaw);
  offset_odom_y += diff_distance*cos(-current_pose_odom.pitch)*sin(current_pose_odom.yaw);
  offset_odom_z += diff_distance*sin(-current_pose_odom.pitch);

  offset_odom_roll  += diff_odom_roll;
  offset_odom_pitch += diff_odom_pitch;
  offset_odom_yaw   += diff_odom_yaw;

  predict_pose_odom.x     = previous_pose.x     + offset_odom_x;
  predict_pose_odom.y     = previous_pose.y     + offset_odom_y;
  predict_pose_odom.z     = previous_pose.z     + offset_odom_z;
  predict_pose_odom.roll  = previous_pose.roll  + offset_odom_roll;
  predict_pose_odom.pitch = previous_pose.pitch + offset_odom_pitch;
  predict_pose_odom.yaw   = previous_pose.yaw   + offset_odom_yaw;
 
  previous_time = current_time;

}

static void imu_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu.roll += diff_imu_roll;
  current_pose_imu.pitch += diff_imu_pitch;
  current_pose_imu.yaw += diff_imu_yaw;

  double accX1 = imu.linear_acceleration.x;
  double accY1 = std::cos(current_pose_imu.roll) * imu.linear_acceleration.y
                -std::sin(current_pose_imu.roll) * imu.linear_acceleration.z;
  double accZ1 = std::sin(current_pose_imu.roll) * imu.linear_acceleration.y
                +std::cos(current_pose_imu.roll) * imu.linear_acceleration.z;

  double accX2 = std::sin(current_pose_imu.pitch) * accZ1 + std::cos(current_pose_imu.pitch) * accX1;
  double accY2 = accY1;
  double accZ2 = std::cos(current_pose_imu.pitch) * accZ1 - std::sin(current_pose_imu.pitch) * accX1;

  double accX = std::cos(current_pose_imu.yaw) * accX2 - std::sin(current_pose_imu.yaw) * accY2;
  double accY = std::sin(current_pose_imu.yaw) * accX2 + std::cos(current_pose_imu.yaw) * accY2;
  double accZ = accZ2;

  offset_imu_x += current_velocity_imu_x * diff_time + accX * diff_time * diff_time / 2.0;
  offset_imu_y += current_velocity_imu_y * diff_time + accY * diff_time * diff_time / 2.0;
  offset_imu_z += current_velocity_imu_z * diff_time + accZ * diff_time * diff_time / 2.0;

  current_velocity_imu_x += accX * diff_time;
  current_velocity_imu_y += accY * diff_time;
  current_velocity_imu_z += accZ * diff_time;

  offset_imu_roll  += diff_imu_roll;
  offset_imu_pitch += diff_imu_pitch;
  offset_imu_yaw   += diff_imu_yaw;

  predict_pose_imu.x     = previous_pose.x     + offset_imu_x;
  predict_pose_imu.y     = previous_pose.y     + offset_imu_y;
  predict_pose_imu.z     = previous_pose.z     + offset_imu_z;
  predict_pose_imu.roll  = previous_pose.roll  + offset_imu_roll;
  predict_pose_imu.pitch = previous_pose.pitch + offset_imu_pitch;
  predict_pose_imu.yaw   = previous_pose.yaw   + offset_imu_yaw;  

  previous_time = current_time;
}


static const double wrapToPm(double a_num, const double a_max)
{
    if (a_num &gt;= a_max)
    {
        a_num -= 2.0 * a_max;
    }
    return a_num;
}

static const double wrapToPmPi(double a_angle_rad)
{
    return wrapToPm(a_angle_rad, M_PI);
}


static void odom_callback(const nav_msgs::Odometry::ConstPtr&amp; input)
{
  odom = *input;
  odom_calc(input-&gt;header.stamp);
}

static void imu_callback(const sensor_msgs::Imu::ConstPtr&amp; input)
{
  const ros::Time current_time = input-&gt;header.stamp;
  static ros::Time previous_time = current_time;
  const double diff_time =  (current_time - previous_time).toSec();

  double imu_roll, imu_pitch, imu_yaw;
  tf::Quaternion imu_orientation;
  tf::quaternionMsgToTF(input-&gt;orientation, imu_orientation);
  tf::Matrix3x3(imu_orientation).getRPY(imu_roll, imu_pitch, imu_yaw);

  imu_roll = wrapToPmPi(imu_roll);
  imu_pitch = wrapToPmPi(imu_pitch);
  imu_yaw = wrapToPmPi(imu_yaw);

  static double previous_imu_roll = imu_roll, previous_imu_pitch = imu_pitch, previous_imu_yaw = imu_yaw;
  const double diff_imu_roll  = imu_roll  - previous_imu_roll;

  const double diff_imu_pitch = imu_pitch - previous_imu_pitch;

  double diff_imu_yaw;
  if(fabs(imu_yaw - previous_imu_yaw) &gt; M_PI)
  {
    if(imu_yaw &gt; 0)
      diff_imu_yaw = (imu_yaw - previous_imu_yaw) - M_PI*2;
    else
      diff_imu_yaw = -M_PI*2 - (imu_yaw - previous_imu_yaw);
  }
  else
  diff_imu_yaw = imu_yaw - previous_imu_yaw;

  imu.header = input-&gt;header;
  imu.linear_acceleration.x = input-&gt;linear_acceleration.x;
  imu.linear_acceleration.y = input-&gt;linear_acceleration.y;
  imu.linear_acceleration.z = input-&gt;linear_acceleration.z;

  if(diff_time != 0)
  {
    imu.angular_velocity.x = diff_imu_roll  / diff_time;
    imu.angular_velocity.y = diff_imu_pitch / diff_time;
    imu.angular_velocity.z = diff_imu_yaw   / diff_time;
  }
  else
  {
    imu.angular_velocity.x = 0;
    imu.angular_velocity.y = 0;
    imu.angular_velocity.z = 0;
  }

  imu_calc(input-&gt;header.stamp);

  previous_time = current_time;
  previous_imu_roll  = imu_roll;
  previous_imu_pitch = imu_pitch;
  previous_imu_yaw   = imu_yaw;
}

static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  if (map_loaded == 1 &amp;&amp; init_pos_set == 1)
  {
    matching_start = std::chrono::system_clock::now();

    static tf::TransformBroadcaster br;
    tf::Transform transform;
    tf::Quaternion predict_q, ndt_q, current_q, localizer_q;

    pcl::PointXYZ p;
    pcl::PointCloud&lt;pcl::PointXYZ&gt; filtered_scan;

    current_scan_time = input-&gt;header.stamp;

    pcl::fromROSMsg(*input, filtered_scan);
    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(filtered_scan));
    int scan_points_num = filtered_scan_ptr-&gt;size();

    Eigen::Matrix4f t(Eigen::Matrix4f::Identity());   // base_link
    Eigen::Matrix4f t2(Eigen::Matrix4f::Identity());  // localizer

    std::chrono::time_point&lt;std::chrono::system_clock&gt; align_start, align_end, getFitnessScore_start,
        getFitnessScore_end;
    static double align_time, getFitnessScore_time = 0.0;

    // Setting point cloud to be aligned.
    ndt.setInputSource(filtered_scan_ptr);

    // Guess the initial gross estimation of the transformation
    predict_pose.x = previous_pose.x + offset_x;
    predict_pose.y = previous_pose.y + offset_y;
    predict_pose.z = previous_pose.z + offset_z;
    predict_pose.roll = previous_pose.roll;
    predict_pose.pitch = previous_pose.pitch;
    predict_pose.yaw = previous_pose.yaw + offset_yaw;


    if (_use_imu == true &amp;&amp; _use_odom == true)
      imu_odom_calc(current_scan_time);
    if(_use_imu == true &amp;&amp; _use_odom == true)
      imu_calc(current_scan_time);
    if (_use_imu == false &amp;&amp; _use_odom == true)
      odom_calc(current_scan_time);
    
    pose predict_pose_for_ndt;
    if (_use_imu == true &amp;&amp; _use_odom == true)
      predict_pose_for_ndt = predict_pose_imu_odom;
    else if (_use_imu == true &amp;&amp; _use_odom == false)
      predict_pose_for_ndt = predict_pose_imu;
    else if (_use_imu == false &amp;&amp; _use_odom == true)
      predict_pose_for_ndt = predict_pose_odom;
    else
      predict_pose_for_ndt = predict_pose;

    Eigen::Translation3f init_translation(predict_pose_for_ndt.x, predict_pose_for_ndt.y, predict_pose_for_ndt.z);
    Eigen::AngleAxisf init_rotation_x(predict_pose_for_ndt.roll, Eigen::Vector3f::UnitX());
    Eigen::AngleAxisf init_rotation_y(predict_pose_for_ndt.pitch, Eigen::Vector3f::UnitY());
    Eigen::AngleAxisf init_rotation_z(predict_pose_for_ndt.yaw, Eigen::Vector3f::UnitZ());
    Eigen::Matrix4f init_guess = (init_translation * init_rotation_z * init_rotation_y * init_rotation_x) * tf_btol;




    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
#ifdef USE_FAST_PCL
    if (_use_openmp == true)
    {
      align_start = std::chrono::system_clock::now();
      ndt.omp_align(*output_cloud, init_guess);
      align_end = std::chrono::system_clock::now();
    }
    else
    {
#endif
      align_start = std::chrono::system_clock::now();
      ndt.align(*output_cloud, init_guess);
      align_end = std::chrono::system_clock::now();
#ifdef USE_FAST_PCL
    }
#endif

    align_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(align_end - align_start).count() / 1000.0;


    t = ndt.getFinalTransformation();  // localizer
    t2 = t * tf_ltob;                  // base_link

    iteration = ndt.getFinalNumIteration();
#ifdef USE_FAST_PCL
    if (_use_openmp == true)
    {
      getFitnessScore_start = std::chrono::system_clock::now();
      fitness_score = ndt.omp_getFitnessScore();
      getFitnessScore_end = std::chrono::system_clock::now();
    }
    else
    {
#endif
      getFitnessScore_start = std::chrono::system_clock::now();
      fitness_score = ndt.getFitnessScore();
      getFitnessScore_end = std::chrono::system_clock::now();
#ifdef USE_FAST_PCL
    }
#endif
    getFitnessScore_time =
        std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(getFitnessScore_end - getFitnessScore_start).count() /
        1000.0;


    trans_probability = ndt.getTransformationProbability();

    tf::Matrix3x3 mat_l;  // localizer
    mat_l.setValue(static_cast&lt;double&gt;(t(0, 0)), static_cast&lt;double&gt;(t(0, 1)), static_cast&lt;double&gt;(t(0, 2)),
                   static_cast&lt;double&gt;(t(1, 0)), static_cast&lt;double&gt;(t(1, 1)), static_cast&lt;double&gt;(t(1, 2)),
                   static_cast&lt;double&gt;(t(2, 0)), static_cast&lt;double&gt;(t(2, 1)), static_cast&lt;double&gt;(t(2, 2)));

    // Update localizer_pose
    localizer_pose.x = t(0, 3);
    localizer_pose.y = t(1, 3);
    localizer_pose.z = t(2, 3);
    mat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1);

    tf::Matrix3x3 mat_b;  // base_link
    mat_b.setValue(static_cast&lt;double&gt;(t2(0, 0)), static_cast&lt;double&gt;(t2(0, 1)), static_cast&lt;double&gt;(t2(0, 2)),
                   static_cast&lt;double&gt;(t2(1, 0)), static_cast&lt;double&gt;(t2(1, 1)), static_cast&lt;double&gt;(t2(1, 2)),
                   static_cast&lt;double&gt;(t2(2, 0)), static_cast&lt;double&gt;(t2(2, 1)), static_cast&lt;double&gt;(t2(2, 2)));

    // Update ndt_pose
    ndt_pose.x = t2(0, 3);
    ndt_pose.y = t2(1, 3);
    ndt_pose.z = t2(2, 3);
    mat_b.getRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw, 1);

    // Calculate the difference between ndt_pose and predict_pose
    predict_pose_error = sqrt((ndt_pose.x - predict_pose_for_ndt.x) * (ndt_pose.x - predict_pose_for_ndt.x) +
                              (ndt_pose.y - predict_pose_for_ndt.y) * (ndt_pose.y - predict_pose_for_ndt.y) +
                              (ndt_pose.z - predict_pose_for_ndt.z) * (ndt_pose.z - predict_pose_for_ndt.z));

    if (predict_pose_error &lt;= PREDICT_POSE_THRESHOLD)
    {
      use_predict_pose = 0;
    }
    else
    {
      use_predict_pose = 1;
    }
    use_predict_pose = 0;


    if (use_predict_pose == 0)
    {
      current_pose.x = ndt_pose.x;
      current_pose.y = ndt_pose.y;
      current_pose.z = ndt_pose.z;
      current_pose.roll = ndt_pose.roll;
      current_pose.pitch = ndt_pose.pitch;
      current_pose.yaw = ndt_pose.yaw;
    }
    else
    {
      current_pose.x = predict_pose_for_ndt.x;
      current_pose.y = predict_pose_for_ndt.y;
      current_pose.z = predict_pose_for_ndt.z;
      current_pose.roll = predict_pose_for_ndt.roll;
      current_pose.pitch = predict_pose_for_ndt.pitch;
      current_pose.yaw = predict_pose_for_ndt.yaw;
    }


    // Compute the velocity and acceleration
    scan_duration = current_scan_time - previous_scan_time;
    double secs = scan_duration.toSec();
    diff_x = current_pose.x - previous_pose.x;
    diff_y = current_pose.y - previous_pose.y;
    diff_z = current_pose.z - previous_pose.z;
    diff_yaw = current_pose.yaw - previous_pose.yaw;
    diff = sqrt(diff_x * diff_x + diff_y * diff_y + diff_z * diff_z);

    current_velocity = diff / secs;
    current_velocity_x = diff_x / secs;
    current_velocity_y = diff_y / secs;
    current_velocity_z = diff_z / secs;
    angular_velocity = diff_yaw / secs;

    current_pose_imu.x = current_pose.x;
    current_pose_imu.y = current_pose.y;
    current_pose_imu.z = current_pose.z;
    current_pose_imu.roll = current_pose.roll;
    current_pose_imu.pitch = current_pose.pitch;
    current_pose_imu.yaw = current_pose.yaw;

    current_velocity_imu_x = current_velocity_x;
    current_velocity_imu_y = current_velocity_y;
    current_velocity_imu_z = current_velocity_z;


    current_pose_odom.x = current_pose.x;
    current_pose_odom.y = current_pose.y;
    current_pose_odom.z = current_pose.z;
    current_pose_odom.roll = current_pose.roll;
    current_pose_odom.pitch = current_pose.pitch;
    current_pose_odom.yaw = current_pose.yaw;

    current_pose_imu_odom.x = current_pose.x;
    current_pose_imu_odom.y = current_pose.y;
    current_pose_imu_odom.z = current_pose.z;
    current_pose_imu_odom.roll = current_pose.roll;
    current_pose_imu_odom.pitch = current_pose.pitch;
    current_pose_imu_odom.yaw = current_pose.yaw;

    current_velocity_smooth = (current_velocity + previous_velocity + previous_previous_velocity) / 3.0;
    if (current_velocity_smooth &lt; 0.2)
    {
      current_velocity_smooth = 0.0;
    }

    current_accel = (current_velocity - previous_velocity) / secs;
    current_accel_x = (current_velocity_x - previous_velocity_x) / secs;
    current_accel_y = (current_velocity_y - previous_velocity_y) / secs;
    current_accel_z = (current_velocity_z - previous_velocity_z) / secs;

    estimated_vel_mps.data = current_velocity;
    estimated_vel_kmph.data = current_velocity * 3.6;

    estimated_vel_mps_pub.publish(estimated_vel_mps);
    estimated_vel_kmph_pub.publish(estimated_vel_kmph);

    // Set values for publishing pose
    predict_q.setRPY(predict_pose.roll, predict_pose.pitch, predict_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(predict_pose.x, predict_pose.y, predict_pose.z);
      tf::Transform transform(predict_q, v);
      predict_pose_msg.header.frame_id = &quot;/map&quot;;
      predict_pose_msg.header.stamp = current_scan_time;
      predict_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      predict_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      predict_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      predict_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      predict_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      predict_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      predict_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      predict_pose_msg.header.frame_id = &quot;/map&quot;;
      predict_pose_msg.header.stamp = current_scan_time;
      predict_pose_msg.pose.position.x = predict_pose.x;
      predict_pose_msg.pose.position.y = predict_pose.y;
      predict_pose_msg.pose.position.z = predict_pose.z;
      predict_pose_msg.pose.orientation.x = predict_q.x();
      predict_pose_msg.pose.orientation.y = predict_q.y();
      predict_pose_msg.pose.orientation.z = predict_q.z();
      predict_pose_msg.pose.orientation.w = predict_q.w();
    }

    tf::Quaternion predict_q_imu;
    predict_q_imu.setRPY(predict_pose_imu.roll, predict_pose_imu.pitch, predict_pose_imu.yaw);
    predict_pose_imu_msg.header.frame_id = &quot;map&quot;;
    predict_pose_imu_msg.header.stamp = input-&gt;header.stamp;
    predict_pose_imu_msg.pose.position.x = predict_pose_imu.x;
    predict_pose_imu_msg.pose.position.y = predict_pose_imu.y;
    predict_pose_imu_msg.pose.position.z = predict_pose_imu.z;
    predict_pose_imu_msg.pose.orientation.x = predict_q_imu.x();
    predict_pose_imu_msg.pose.orientation.y = predict_q_imu.y();
    predict_pose_imu_msg.pose.orientation.z = predict_q_imu.z();
    predict_pose_imu_msg.pose.orientation.w = predict_q_imu.w();
    predict_pose_imu_pub.publish(predict_pose_imu_msg);

    tf::Quaternion predict_q_odom;
    predict_q_odom.setRPY(predict_pose_odom.roll, predict_pose_odom.pitch, predict_pose_odom.yaw);
    predict_pose_odom_msg.header.frame_id = &quot;map&quot;;
    predict_pose_odom_msg.header.stamp = input-&gt;header.stamp;
    predict_pose_odom_msg.pose.position.x = predict_pose_odom.x;
    predict_pose_odom_msg.pose.position.y = predict_pose_odom.y;
    predict_pose_odom_msg.pose.position.z = predict_pose_odom.z;
    predict_pose_odom_msg.pose.orientation.x = predict_q_odom.x();
    predict_pose_odom_msg.pose.orientation.y = predict_q_odom.y();
    predict_pose_odom_msg.pose.orientation.z = predict_q_odom.z();
    predict_pose_odom_msg.pose.orientation.w = predict_q_odom.w();
    predict_pose_odom_pub.publish(predict_pose_odom_msg);


    tf::Quaternion predict_q_imu_odom;
    predict_q_odom.setRPY(predict_pose_imu_odom.roll, predict_pose_imu_odom.pitch, predict_pose_imu_odom.yaw);
    predict_pose_imu_odom_msg.header.frame_id = &quot;map&quot;;
    predict_pose_imu_odom_msg.header.stamp = input-&gt;header.stamp;
    predict_pose_imu_odom_msg.pose.position.x = predict_pose_imu_odom.x;
    predict_pose_imu_odom_msg.pose.position.y = predict_pose_imu_odom.y;
    predict_pose_imu_odom_msg.pose.position.z = predict_pose_imu_odom.z;
    predict_pose_imu_odom_msg.pose.orientation.x = predict_q_imu_odom.x();
    predict_pose_imu_odom_msg.pose.orientation.y = predict_q_imu_odom.y();
    predict_pose_imu_odom_msg.pose.orientation.z = predict_q_imu_odom.z();
    predict_pose_imu_odom_msg.pose.orientation.w = predict_q_imu_odom.w();
    predict_pose_imu_odom_pub.publish(predict_pose_imu_odom_msg);

    ndt_q.setRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw);
	    if (_use_local_transform == true)
    {
      tf::Vector3 v(ndt_pose.x, ndt_pose.y, ndt_pose.z);
      tf::Transform transform(ndt_q, v);
      ndt_pose_msg.header.frame_id = &quot;/map&quot;;
      ndt_pose_msg.header.stamp = current_scan_time;
      ndt_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      ndt_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      ndt_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      ndt_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      ndt_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      ndt_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      ndt_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      ndt_pose_msg.header.frame_id = &quot;/map&quot;;
      ndt_pose_msg.header.stamp = current_scan_time;
      ndt_pose_msg.pose.position.x = ndt_pose.x;
      ndt_pose_msg.pose.position.y = ndt_pose.y;
      ndt_pose_msg.pose.position.z = ndt_pose.z;
      ndt_pose_msg.pose.orientation.x = ndt_q.x();
      ndt_pose_msg.pose.orientation.y = ndt_q.y();
      ndt_pose_msg.pose.orientation.z = ndt_q.z();
      ndt_pose_msg.pose.orientation.w = ndt_q.w();
    }

    current_q.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);
    // current_pose is published by vel_pose_mux
    /*
    current_pose_msg.header.frame_id = &quot;/map&quot;;
    current_pose_msg.header.stamp = current_scan_time;
    current_pose_msg.pose.position.x = current_pose.x;
    current_pose_msg.pose.position.y = current_pose.y;
    current_pose_msg.pose.position.z = current_pose.z;
    current_pose_msg.pose.orientation.x = current_q.x();
    current_pose_msg.pose.orientation.y = current_q.y();
    current_pose_msg.pose.orientation.z = current_q.z();
    current_pose_msg.pose.orientation.w = current_q.w();
    */

    localizer_q.setRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(localizer_pose.x, localizer_pose.y, localizer_pose.z);
      tf::Transform transform(localizer_q, v);
      localizer_pose_msg.header.frame_id = &quot;/map&quot;;
      localizer_pose_msg.header.stamp = current_scan_time;
      localizer_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      localizer_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      localizer_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      localizer_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      localizer_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      localizer_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      localizer_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      localizer_pose_msg.header.frame_id = &quot;/map&quot;;
      localizer_pose_msg.header.stamp = current_scan_time;
      localizer_pose_msg.pose.position.x = localizer_pose.x;
      localizer_pose_msg.pose.position.y = localizer_pose.y;
      localizer_pose_msg.pose.position.z = localizer_pose.z;
      localizer_pose_msg.pose.orientation.x = localizer_q.x();
      localizer_pose_msg.pose.orientation.y = localizer_q.y();
      localizer_pose_msg.pose.orientation.z = localizer_q.z();
      localizer_pose_msg.pose.orientation.w = localizer_q.w();
    }

    predict_pose_pub.publish(predict_pose_msg);
    ndt_pose_pub.publish(ndt_pose_msg);
    // current_pose is published by vel_pose_mux
    //    current_pose_pub.publish(current_pose_msg);
    localizer_pose_pub.publish(localizer_pose_msg);

    // Send TF &quot;/base_link&quot; to &quot;/map&quot;
    transform.setOrigin(tf::Vector3(current_pose.x, current_pose.y, current_pose.z));
    transform.setRotation(current_q);
    //    br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    if (_use_local_transform == true)
    {
      br.sendTransform(tf::StampedTransform(local_transform * transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    }
    else
    {
      br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    }

    matching_end = std::chrono::system_clock::now();
    exe_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(matching_end - matching_start).count() / 1000.0;
    time_ndt_matching.data = exe_time;
    time_ndt_matching_pub.publish(time_ndt_matching);

    // Set values for /estimate_twist
    estimate_twist_msg.header.stamp = current_scan_time;
    estimate_twist_msg.header.frame_id = &quot;/base_link&quot;;
    estimate_twist_msg.twist.linear.x = current_velocity;
    estimate_twist_msg.twist.linear.y = 0.0;
    estimate_twist_msg.twist.linear.z = 0.0;
    estimate_twist_msg.twist.angular.x = 0.0;
    estimate_twist_msg.twist.angular.y = 0.0;
    estimate_twist_msg.twist.angular.z = angular_velocity;

    estimate_twist_pub.publish(estimate_twist_msg);

    geometry_msgs::Vector3Stamped estimate_vel_msg;
    estimate_vel_msg.header.stamp = current_scan_time;
    estimate_vel_msg.vector.x = current_velocity;
    estimated_vel_pub.publish(estimate_vel_msg);

    // Set values for /ndt_stat
    ndt_stat_msg.header.stamp = current_scan_time;
    ndt_stat_msg.exe_time = time_ndt_matching.data;
    ndt_stat_msg.iteration = iteration;
    ndt_stat_msg.score = fitness_score;
    ndt_stat_msg.velocity = current_velocity;
    ndt_stat_msg.acceleration = current_accel;
    ndt_stat_msg.use_predict_pose = 0;

    ndt_stat_pub.publish(ndt_stat_msg);

    /* Compute NDT_Reliability */
    ndt_reliability.data = Wa * (exe_time / 100.0) * 100.0 + Wb * (iteration / 10.0) * 100.0 +
                           Wc * ((2.0 - trans_probability) / 2.0) * 100.0;
    ndt_reliability_pub.publish(ndt_reliability);


    // Write log
    if (!ofs)
    {
      std::cerr &lt;&lt; &quot;Could not open &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
      exit(1);
    }
    static ros::Time start_time = input-&gt;header.stamp;
    ofs &lt;&lt; input-&gt;header.seq &lt;&lt; &quot;,&quot; &lt;&lt; input-&gt;header.stamp &lt;&lt; &quot;,&quot; &lt;&lt; input-&gt;header.stamp - start_time &lt;&lt; scan_points_num &lt;&lt; &quot;,&quot; &lt;&lt; step_size &lt;&lt; &quot;,&quot; &lt;&lt; trans_eps &lt;&lt; &quot;,&quot; &lt;&lt; std::fixed
        &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; std::fixed &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.y &lt;&lt; &quot;,&quot;
        &lt;&lt; std::fixed &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.pitch
        &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.y &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.z &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose.roll &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.pitch &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.x - predict_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.y - predict_pose.y &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.z - predict_pose.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll - predict_pose.roll &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.pitch - predict_pose.pitch &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw - predict_pose.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose_error &lt;&lt; &quot;,&quot; &lt;&lt; iteration &lt;&lt; &quot;,&quot; &lt;&lt; fitness_score &lt;&lt; &quot;,&quot; &lt;&lt; trans_probability &lt;&lt; &quot;,&quot;
        &lt;&lt; ndt_reliability.data &lt;&lt; &quot;,&quot; &lt;&lt; current_velocity &lt;&lt; &quot;,&quot; &lt;&lt; current_velocity_smooth &lt;&lt; &quot;,&quot; &lt;&lt; current_accel
        &lt;&lt; &quot;,&quot; &lt;&lt; angular_velocity &lt;&lt; &quot;,&quot; &lt;&lt; time_ndt_matching.data &lt;&lt; &quot;,&quot; &lt;&lt; align_time &lt;&lt; &quot;,&quot; &lt;&lt; getFitnessScore_time 
        &lt;&lt;&quot;,&quot; &lt;&lt; predict_pose_imu.x &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose_imu.y &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose_imu.z &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose_imu.roll &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose_imu.pitch &lt;&lt; &quot;,&quot;  &lt;&lt; predict_pose_imu.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.x - predict_pose_imu.x &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.y - predict_pose_imu.y &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.z - predict_pose_imu.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll - predict_pose_imu.roll &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.pitch - predict_pose_imu.pitch &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw - predict_pose_imu.yaw &lt;&lt; &quot;,&quot;

        &lt;&lt;&quot;,&quot; &lt;&lt; predict_pose_odom.x &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose_odom.y &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose_odom.z &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose_odom.roll &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose_odom.pitch &lt;&lt; &quot;,&quot;  &lt;&lt; predict_pose_odom.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.x - predict_pose_odom.x &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.y - predict_pose_odom.y &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.z - predict_pose_odom.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll - predict_pose_odom.roll &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.pitch - predict_pose_odom.pitch &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw - predict_pose_odom.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt;&quot;,&quot; &lt;&lt; predict_pose_imu_odom.x &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose_imu_odom.y &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose_imu_odom.z &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose_imu_odom.roll &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose_imu_odom.pitch &lt;&lt; &quot;,&quot;  &lt;&lt; predict_pose_imu_odom.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.x - predict_pose_imu_odom.x &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.y - predict_pose_imu_odom.y &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.z - predict_pose_imu_odom.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll - predict_pose_imu_odom.roll &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.pitch - predict_pose_imu_odom.pitch &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw - predict_pose_imu_odom.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; std::endl;


    std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Sequence: &quot; &lt;&lt; input-&gt;header.seq &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Timestamp: &quot; &lt;&lt; input-&gt;header.stamp &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Frame ID: &quot; &lt;&lt; input-&gt;header.frame_id &lt;&lt; std::endl;
    //		std::cout &lt;&lt; &quot;Number of Scan Points: &quot; &lt;&lt; scan_ptr-&gt;size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Number of Filtered Scan Points: &quot; &lt;&lt; scan_points_num &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;NDT has converged: &quot; &lt;&lt; ndt.hasConverged() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Fitness Score: &quot; &lt;&lt; fitness_score &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Transformation Probability: &quot; &lt;&lt; ndt.getTransformationProbability() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Execution Time: &quot; &lt;&lt; exe_time &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Number of Iterations: &quot; &lt;&lt; ndt.getFinalNumIteration() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;NDT Reliability: &quot; &lt;&lt; ndt_reliability.data &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;(x,y,z,roll,pitch,yaw): &quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;(&quot; &lt;&lt; current_pose.x &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.y &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.z &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.roll
              &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.pitch &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Transformation Matrix: &quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; t &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;

    // Update offset
    if (_offset == &quot;linear&quot;)
    {
      offset_x = diff_x;
      offset_y = diff_y;
      offset_z = diff_z;
      offset_yaw = diff_yaw;
    }
    else if (_offset == &quot;quadratic&quot;)
    {
      offset_x = (current_velocity_x + current_accel_x * secs) * secs;
      offset_y = (current_velocity_y + current_accel_y * secs) * secs;
      offset_z = diff_z;
      offset_yaw = diff_yaw;
    }
    else if (_offset == &quot;zero&quot;)
    {
      offset_x = 0.0;
      offset_y = 0.0;
      offset_z = 0.0;
      offset_yaw = 0.0;
    }
   
    offset_imu_x = 0.0;
    offset_imu_y = 0.0;
    offset_imu_z = 0.0;
    offset_imu_roll = 0.0;
    offset_imu_pitch = 0.0;
    offset_imu_yaw = 0.0;

    offset_odom_x = 0.0;
    offset_odom_y = 0.0;
    offset_odom_z = 0.0;
    offset_odom_roll = 0.0;
    offset_odom_pitch = 0.0;
    offset_odom_yaw = 0.0;

    offset_imu_odom_x = 0.0;
    offset_imu_odom_y = 0.0;
    offset_imu_odom_z = 0.0;
    offset_imu_odom_roll = 0.0;
    offset_imu_odom_pitch = 0.0;
    offset_imu_odom_yaw = 0.0;

    // Update previous_***
    previous_pose.x = current_pose.x;
    previous_pose.y = current_pose.y;
    previous_pose.z = current_pose.z;
    previous_pose.roll = current_pose.roll;
    previous_pose.pitch = current_pose.pitch;
    previous_pose.yaw = current_pose.yaw;

    previous_scan_time.sec = current_scan_time.sec;
    previous_scan_time.nsec = current_scan_time.nsec;

    previous_previous_velocity = previous_velocity;
    previous_velocity = current_velocity;
    previous_velocity_x = current_velocity_x;
    previous_velocity_y = current_velocity_y;
    previous_velocity_z = current_velocity_z;
    previous_accel = current_accel;

    previous_estimated_vel_kmph.data = estimated_vel_kmph.data;
  }
}

int main(int argc, char** argv)
{
  ros::init(argc, argv, &quot;ndt_matching&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  // Set log file name.
  char buffer[80];
  std::time_t now = std::time(NULL);
  std::tm* pnow = std::localtime(&amp;now);
  std::strftime(buffer, 80, &quot;%Y%m%d_%H%M%S&quot;, pnow);
  filename = &quot;ndt_matching_&quot; + std::string(buffer) + &quot;.csv&quot;;
  ofs.open(filename.c_str(), std::ios::app);

  // Geting parameters
  private_nh.getParam(&quot;use_gnss&quot;, _use_gnss);
  private_nh.getParam(&quot;queue_size&quot;, _queue_size);
  private_nh.getParam(&quot;offset&quot;, _offset);
  private_nh.getParam(&quot;use_openmp&quot;, _use_openmp);
  private_nh.getParam(&quot;get_height&quot;, _get_height);
  private_nh.getParam(&quot;use_local_transform&quot;, _use_local_transform);
  private_nh.getParam(&quot;use_imu&quot;, _use_imu);
  private_nh.getParam(&quot;use_odom&quot;, _use_odom);

  _tf_x = _tf_y = _tf_z = _tf_roll = _tf_pitch = _tf_yaw = 0;

  if (nh.getParam(&quot;localizer&quot;, _localizer) == false)
  {
    std::cout &lt;&lt; &quot;localizer is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_x&quot;, _tf_x) == false)
  {
    std::cout &lt;&lt; &quot;tf_x is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_y&quot;, _tf_y) == false)
  {
    std::cout &lt;&lt; &quot;tf_y is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_z&quot;, _tf_z) == false)
  {
    std::cout &lt;&lt; &quot;tf_z is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_roll&quot;, _tf_roll) == false)
  {
    std::cout &lt;&lt; &quot;tf_roll is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_pitch&quot;, _tf_pitch) == false)
  {
    std::cout &lt;&lt; &quot;tf_pitch is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_yaw&quot;, _tf_yaw) == false)
  {
    std::cout &lt;&lt; &quot;tf_yaw is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }

  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Log file: &quot; &lt;&lt; filename &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_gnss: &quot; &lt;&lt; _use_gnss &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;queue_size: &quot; &lt;&lt; _queue_size &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;offset: &quot; &lt;&lt; _offset &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_openmp: &quot; &lt;&lt; _use_openmp &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;get_height: &quot; &lt;&lt; _get_height &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_local_transform: &quot; &lt;&lt; _use_local_transform &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_imu: &quot; &lt;&lt; _use_imu &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_odom: &quot; &lt;&lt; _use_odom &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;localizer: &quot; &lt;&lt; _localizer &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;(tf_x,tf_y,tf_z,tf_roll,tf_pitch,tf_yaw): (&quot; &lt;&lt; _tf_x &lt;&lt; &quot;, &quot; &lt;&lt; _tf_y &lt;&lt; &quot;, &quot; &lt;&lt; _tf_z &lt;&lt; &quot;, &quot;
            &lt;&lt; _tf_roll &lt;&lt; &quot;, &quot; &lt;&lt; _tf_pitch &lt;&lt; &quot;, &quot; &lt;&lt; _tf_yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;

  Eigen::Translation3f tl_btol(_tf_x, _tf_y, _tf_z);                 // tl: translation
  Eigen::AngleAxisf rot_x_btol(_tf_roll, Eigen::Vector3f::UnitX());  // rot: rotation
  Eigen::AngleAxisf rot_y_btol(_tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_btol(_tf_yaw, Eigen::Vector3f::UnitZ());
  tf_btol = (tl_btol * rot_z_btol * rot_y_btol * rot_x_btol).matrix();

  Eigen::Translation3f tl_ltob((-1.0) * _tf_x, (-1.0) * _tf_y, (-1.0) * _tf_z);  // tl: translation
  Eigen::AngleAxisf rot_x_ltob((-1.0) * _tf_roll, Eigen::Vector3f::UnitX());     // rot: rotation
  Eigen::AngleAxisf rot_y_ltob((-1.0) * _tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_ltob((-1.0) * _tf_yaw, Eigen::Vector3f::UnitZ());
  tf_ltob = (tl_ltob * rot_z_ltob * rot_y_ltob * rot_x_ltob).matrix();

  // Updated in initialpose_callback or gnss_callback
  initial_pose.x = 0.0;
  initial_pose.y = 0.0;
  initial_pose.z = 0.0;
  initial_pose.roll = 0.0;
  initial_pose.pitch = 0.0;
  initial_pose.yaw = 0.0;

  // Publishers
  predict_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose&quot;, 1000);
  predict_pose_imu_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose_imu&quot;, 1000);
  predict_pose_odom_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose_odom&quot;, 1000);
  predict_pose_imu_odom_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose_imu_odom&quot;, 1000);
  ndt_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/ndt_pose&quot;, 1000);
  // current_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/current_pose&quot;, 1000);
  localizer_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/localizer_pose&quot;, 1000);
  estimate_twist_pub = nh.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;/estimate_twist&quot;, 1000);
  estimated_vel_mps_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/estimated_vel_mps&quot;, 1000);
  estimated_vel_kmph_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/estimated_vel_kmph&quot;, 1000);
  estimated_vel_pub = nh.advertise&lt;geometry_msgs::Vector3Stamped&gt;(&quot;/estimated_vel&quot;, 1000);
  time_ndt_matching_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/time_ndt_matching&quot;, 1000);
  ndt_stat_pub = nh.advertise&lt;ndt_localizer::ndt_stat&gt;(&quot;/ndt_stat&quot;, 1000);
  ndt_reliability_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/ndt_reliability&quot;, 1000);

  // Subscribers
  ros::Subscriber param_sub = nh.subscribe(&quot;config/ndt&quot;, 10, param_callback);
  ros::Subscriber gnss_sub = nh.subscribe(&quot;gnss_pose&quot;, 10, gnss_callback);
  ros::Subscriber map_sub = nh.subscribe(&quot;points_map&quot;, 10, map_callback);
  ros::Subscriber initialpose_sub = nh.subscribe(&quot;initialpose&quot;, 1000, initialpose_callback);
  ros::Subscriber points_sub = nh.subscribe(&quot;filtered_points&quot;, _queue_size, points_callback);
  ros::Subscriber odom_sub = nh.subscribe(&quot;odom_pose&quot;, _queue_size*10, odom_callback);
  ros::Subscriber imu_sub = nh.subscribe(&quot;imu_raw&quot;, _queue_size*10, imu_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="4a39ea095b60d74f40ca3f3bae0715c14b294a66" fix_time="0,15956">
		<msg>fix a math library compatibility</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/MappingHelpers.h" new_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/MappingHelpers.h">
				<diff>@@ -8,7 +8,7 @@
 #ifndef MAPPINGHELPERS_H_
 #define MAPPINGHELPERS_H_
 
-#include &lt;cmath&gt;
+#include &lt;math.h&gt;
 #include &quot;RoadNetwork.h&quot;
 #include &quot;UtilityH.h&quot;
 #include &quot;DataRW.h&quot;
</diff>
				<old_file>/*
 * MappingHelpers.h
 *
 *  Created on: Jul 2, 2016
 *      Author: Hatem
 */

#ifndef MAPPINGHELPERS_H_
#define MAPPINGHELPERS_H_

#include &lt;cmath&gt;
#include &quot;RoadNetwork.h&quot;
#include &quot;UtilityH.h&quot;
#include &quot;DataRW.h&quot;
#include &quot;tinyxml.h&quot;


namespace PlannerHNS {


class MappingHelpers {
public:
	MappingHelpers();
	virtual ~MappingHelpers();

	static void ConstructRoadNetworkFromRosMessage(const std::vector&lt;UtilityHNS::AisanLanesFileReader::AisanLane&gt;&amp; lanes_data,
			const std::vector&lt;UtilityHNS::AisanPointsFileReader::AisanPoints&gt;&amp; points_data,
			const std::vector&lt;UtilityHNS::AisanCenterLinesFileReader::AisanCenterLine&gt;&amp; dt_data,
			const std::vector&lt;UtilityHNS::AisanIntersectionFileReader::AisanIntersection&gt;&amp; intersection_data,
			const std::vector&lt;UtilityHNS::AisanAreasFileReader::AisanArea&gt;&amp; area_data,
			const std::vector&lt;UtilityHNS::AisanLinesFileReader::AisanLine&gt;&amp; line_data,
			const std::vector&lt;UtilityHNS::AisanStopLineFileReader::AisanStopLine&gt;&amp; stop_line_data,
			const std::vector&lt;UtilityHNS::AisanSignalFileReader::AisanSignal&gt;&amp; signal_data,
			const std::vector&lt;UtilityHNS::AisanVectorFileReader::AisanVector&gt;&amp; vector_data,
			const std::vector&lt;UtilityHNS::AisanDataConnFileReader::DataConn&gt;&amp; conn_data,
			const GPSPoint&amp; origin, RoadNetwork&amp; map, const bool&amp; bSpecialFlag = false);

	static void ConstructRoadNetworkFromDataFiles(const std::string vectoMapPath, RoadNetwork&amp; map, const bool&amp; bZeroOrigin = false);

	static void SaveTrajectoryLonLatToKMLFile(const std::string&amp; fileName, const std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; trajectory);

	static void GetWayPoint(const int&amp; pid, const std::vector&lt;UtilityHNS::AisanPointsFileReader::AisanPoints&gt;&amp; points, std::vector&lt;WayPoint&gt;&amp; path);
	static bool GetWayPoint(const int&amp; id, const int&amp; laneID,const double&amp; refVel, const int&amp; did,
			const std::vector&lt;UtilityHNS::AisanCenterLinesFileReader::AisanCenterLine&gt;&amp; dtpoints,
			const std::vector&lt;UtilityHNS::AisanPointsFileReader::AisanPoints&gt;&amp; points,
			const GPSPoint&amp; origin, WayPoint&amp; way_point);

	static void WriteKML(const std::string&amp; kmlFile, const std::string&amp; kmlTemplat, RoadNetwork&amp; ap);
	static void LoadKML(const std::string&amp; kmlMap, RoadNetwork&amp; map);

	static void SetRoadLinksList(TiXmlElement* pElem, std::vector&lt;RoadSegment&gt;&amp; roadSegments);
	static void SetLaneLinksList(TiXmlElement* pElem, std::vector&lt;Lane&gt;&amp; lanes);
	static void SetStopLinesList(TiXmlElement* pElem, std::vector&lt;StopLine&gt;&amp; stopLines);
	static void SetTrafficLightsList(TiXmlElement* pElem, std::vector&lt;TrafficLight&gt;&amp; trafficLights);
	static void SetTrafficSignsList(TiXmlElement* pElem, std::vector&lt;TrafficSign&gt;&amp; trafficSignes);

	static TiXmlElement* GetHeadElement(TiXmlElement* pMainElem);
	static TiXmlElement* GetDataFolder(const std::string&amp; folderName, TiXmlElement* pMainElem);


	static Lane* GetClosestLaneFromMap(const WayPoint&amp; pos, RoadNetwork&amp; map, const double&amp; distance = 5.0);
	static Lane* GetClosestLaneFromMapDirectionBased(const WayPoint&amp; pos, RoadNetwork&amp; map, const double&amp; distance = 5.0);
	static std::vector&lt;Lane*&gt; GetClosestMultipleLanesFromMap(const WayPoint&amp; pos, RoadNetwork&amp; map, const double&amp; distance = 5.0);
	static WayPoint* GetClosestWaypointFromMap(const WayPoint&amp; pos, RoadNetwork&amp; map);
	static WayPoint* GetClosestBackWaypointFromMap(const WayPoint&amp; pos, RoadNetwork&amp; map);
	static WayPoint GetFirstWaypoint(RoadNetwork&amp; map);
	static WayPoint* GetLastWaypoint(RoadNetwork&amp; map);


	static void llaToxyz(GPSPoint&amp; lla_p, const GPSPoint&amp; origin);
	static void llaToxyzSpecial(GPSPoint&amp; lla_p, const GPSPoint&amp; netOffset);
	static void xyzTolla(GPSPoint&amp; xyz_p, const GPSPoint&amp; origin);
	static void xyzTollaSpecial(GPSPoint&amp; lla_p, const GPSPoint&amp; netOffset);

	static void GetUniqueNextLanes(const Lane* l,  const std::vector&lt;Lane*&gt;&amp; traversed_lanes, std::vector&lt;Lane*&gt;&amp; lanes_list);

	static GPSPoint GetTransformationOrigin(const int&amp; bToyotaCityMap = 0);

	static Lane* GetLaneFromPath(const WayPoint&amp; currPos, const std::vector&lt;WayPoint&gt;&amp; currPath);
	static Lane* GetLaneById(const int&amp; id,RoadNetwork&amp; map);
	static int GetLaneIdByWaypointId(const int&amp; id,std::vector&lt;Lane&gt;&amp; lanes);

	static WayPoint* FindWaypoint(const int&amp; id, RoadNetwork&amp; map);


	static std::vector&lt;TrafficLight&gt; GetTrafficLightsList(TiXmlElement* pElem);
	static std::vector&lt;StopLine&gt; GetStopLinesList(TiXmlElement* pElem);
	static std::vector&lt;Lane&gt; GetLanesList(TiXmlElement* pElem);
	static std::vector&lt;RoadSegment&gt; GetRoadSegmentsList(TiXmlElement* pElem);
	static std::vector&lt;int&gt; GetIDsFromPrefix(const std::string&amp; str, const std::string&amp; prefix, const std::string&amp; postfix);
	static std::vector&lt;double&gt; GetDoubleFromPrefix(const std::string&amp; str, const std::string&amp; prefix, const std::string&amp; postfix);
	static std::pair&lt;ACTION_TYPE, double&gt; GetActionPairFromPrefix(const std::string&amp; str, const std::string&amp; prefix, const std::string&amp; postfix);
	static std::vector&lt;WayPoint&gt; GetCenterLaneData(TiXmlElement* pElem, const int&amp; currLaneID);
	static std::vector&lt;WayPoint&gt; GetCenterLaneDataVer0(TiXmlElement* pElem, const int&amp; currLaneID);
	static std::vector&lt;GPSPoint&gt; GetPointsData(TiXmlElement* pElem);
	static std::vector&lt;std::string&gt; SplitString(const std::string&amp; str, const std::string&amp; token);

	static void CreateKmlFromLocalizationPathFile(const std::string&amp; pathFileName,const double&amp; maxLaneDistance, const double&amp; density,const std::vector&lt;TrafficLight&gt;&amp; trafficLights, const std::vector&lt;GPSPoint&gt;&amp; stopLines);

	static int ReplaceMyID(int&amp; id, const std::vector&lt;std::pair&lt;int,int&gt; &gt;&amp; rep_list);

	static double m_USING_VER_ZERO;

};

} /* namespace PlannerHNS */

#endif /* MAPPINGHELPERS_H_ */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/MatrixOperations.h" new_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/MatrixOperations.h">
				<diff>@@ -9,7 +9,7 @@
 #define MATRIXOPERATIONS_H_
 
 #include &quot;RoadNetwork.h&quot;
-#include &lt;cmath&gt;
+#include &lt;math.h&gt;
 
 
 namespace PlannerHNS {
</diff>
				<old_file>/*
 * MatrixOperations.h
 *
 *  Created on: Jun 19, 2016
 *      Author: hatem
 */

#ifndef MATRIXOPERATIONS_H_
#define MATRIXOPERATIONS_H_

#include &quot;RoadNetwork.h&quot;
#include &lt;cmath&gt;


namespace PlannerHNS {


class Mat3
{
	double m11, m12, m13;
	double m21, m22, m23;
	double m31, m32, m33;

	double m[3][3];

public:
	Mat3()
	{
		//initialize Identity by default
		m11 = m22 = m33 = 1;
		m12 = m13 = m21 = m23 = m31 = m32 = 0;
	}

	Mat3(double angle, POINT2D trans)
	{
		//Initialize Rotation Matrix
		double c = cos(angle);
		double s = sin(angle);
		m11 = c;
		m12 = s;
		m21 = -s;
		m22 = c;
		m31 = trans.x;
		m32 = trans.y;
		m13 = m23= 0;
		m33 = 1;
	}

	Mat3(double transX, double transY, bool mirrorX, bool mirrorY )
	{
		m11 = m22 = m33 = 1;
		m12 = m13 = m21 = m23 = m31 = m32 = 0;
		m[0][0] = (mirrorX == true ) ? -1 : 1; m[0][1] =  0; m[0][2] =  transX;
		m[1][0] = 0; m[1][1] =  (mirrorY==true) ? -1 : 1; m[1][2] =  transY;
		m[2][0] = 0; m[2][1] =  0; m[2][2] =  1;
	}

	Mat3(double transX, double transY)
	{
		m11 = m22 = m33 = 1;
		m12 = m13 = m21 = m23 = m31 = m32 = 0;
		m[0][0] = 1; m[0][1] =  0; m[0][2] =  transX;
		m[1][0] = 0; m[1][1] =  1; m[1][2] =  transY;
		m[2][0] = 0; m[2][1] =  0; m[2][2] =  1;
	}

	Mat3(double rotation_angle)
	{
		m11 = m22 = m33 = 1;
		m12 = m13 = m21 = m23 = m31 = m32 = 0;
		double c = cos(rotation_angle);
		double s = sin(rotation_angle);
		m[0][0] = c; m[0][1] = -s; m[0][2] =  0;
		m[1][0] = s; m[1][1] =  c; m[1][2] =  0;
		m[2][0] = 0; m[2][1] =  0; m[2][2] =  1;
	}

	Mat3(GPSPoint rotationCenter)
	{
		m11 = m22 = m33 = 1;
		m12 = m13 = m21 = m23 = m31 = m32 = 0;
		double c = cos(rotationCenter.a);
		double s = sin(rotationCenter.a);
		double u = rotationCenter.x;
		double v = rotationCenter.y;
		m[0][0] = c; m[0][1] = -s; m[0][2] = -u*c + v*s + u;
		m[1][0] = s; m[1][1] =  c; m[1][2] = -u*s - v*c + v;
		m[2][0] = 0; m[2][1] =  0; m[2][2] =  1;
	}


	GPSPoint operator * (GPSPoint v)
	{
		GPSPoint _v = v;
		v.x = m[0][0]*_v.x + m[0][1]*_v.y + m[0][2]*1;
		v.y = m[1][0]*_v.x + m[1][1]*_v.y + m[1][2]*1;
		return v;
	}

	POINT2D operator * (POINT2D v)
	{
		Mat3 m = *this;
		POINT2D r;
		r.x = m.m11 * v.x + m.m21 * v.y + m.m31 * 1;
		r.y = m.m12 * v.x + m.m22 * v.y + m.m32 * 1;
		return r;
	}

	Mat3 operator *(Mat3 m2)
	{
		Mat3 m1 = *this;
		Mat3 r;
		r.m11 = m1.m11 * m2.m11 + m1.m12 * m2.m21 + m1.m13 * m2.m31;
		r.m12 = m1.m11 * m2.m12 + m1.m12 * m2.m22 + m1.m13 * m2.m32;
		r.m13 = m1.m11 * m2.m13 + m1.m12 * m2.m23 + m1.m13 * m2.m33;

		r.m21 = m1.m21 * m2.m11 + m1.m22 * m2.m21 + m1.m23 * m2.m31;
		r.m22 = m1.m21 * m2.m12 + m1.m22 * m2.m22 + m1.m23 * m2.m32;
		r.m23 = m1.m21 * m2.m13 + m1.m22 * m2.m23 + m1.m23 * m2.m33;

		r.m31 = m1.m31 * m2.m11 + m1.m32 * m2.m21 + m1.m33 * m2.m31;
		r.m32 = m1.m31 * m2.m12 + m1.m32 * m2.m22 + m1.m33 * m2.m32;
		r.m33 = m1.m31 * m2.m13 + m1.m32 * m2.m23 + m1.m33 * m2.m33;

		return r;
	}
};

} /* namespace PlannerHNS */

#endif /* MATRIXOPERATIONS_H_ */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/PlannerCommonDef.h" new_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/PlannerCommonDef.h">
				<diff>@@ -8,7 +8,7 @@
 #ifndef PLANNERCOMMONDEF_H_
 #define PLANNERCOMMONDEF_H_
 
-#include &lt;cmath&gt;
+#include &lt;math.h&gt;
 #include &lt;string&gt;
 
 namespace PlannerHNS
</diff>
				<old_file>/*
 * PlannerCommonDef.h
 *
 *  Created on: Dec 14, 2016
 *      Author: hatem
 */

#ifndef PLANNERCOMMONDEF_H_
#define PLANNERCOMMONDEF_H_

#include &lt;cmath&gt;
#include &lt;string&gt;

namespace PlannerHNS
{

enum CAR_TYPE
{
  Mv2Car, //!&lt; Mv2Car
  PHVCar, //!&lt; PHVCar
  HVCar,  //!&lt; HVCar
  RoboCar,//!&lt; RoboCar
  SimulationCar
};

class PID_CONST
{
public:
	double kP;
	double kI;
	double kD;

	PID_CONST()
	{
		kP = kI = kD = 0;
	}

	PID_CONST(const double&amp; p, const double&amp; i, const double&amp; d)
	{
		kP = p;
		kI = i;
		kD = d;
	}
};

class ControllerParams
{
public:
	double SimulationSteeringDelay;
	double SteeringDelay;
	double minPursuiteDistance;
	PID_CONST Steering_Gain;
	PID_CONST Velocity_Gain;
	double Acceleration;
	double Deceleration;
	double FollowDistance;
	double LowpassSteerCutoff;
	double maxAccel;
	double maxDecel;


	ControllerParams()
	{
		SimulationSteeringDelay = 0.0;
		SteeringDelay 		= 0.8;
		Acceleration		= 0.5;
		Deceleration		= -0.8;
		FollowDistance		= 8.0;
		LowpassSteerCutoff	= 5.0;
		maxAccel			= 0.9;
		minPursuiteDistance = 2.0;
		maxDecel 			= -1.5;
	}
};

class CAR_BASIC_INFO
{
public:
  CAR_TYPE model;

  double turning_radius;
  double wheel_base;
  double max_speed_forward;
  double min_speed_forward;
  double max_speed_backword;
  double max_steer_value;
  double min_steer_value;
  double max_brake_value;
  double min_brake_value;
  double max_steer_angle;
  double min_steer_angle;
  double length;
  double width;
  double max_acceleration;
  double max_deceleration;

  CAR_BASIC_INFO()
  {
	  model 				= SimulationCar;
	  turning_radius 		= 5.2;
	  wheel_base			= 2.7;
	  max_speed_forward		= 3.0;
	  min_speed_forward		= 0.0;
	  max_speed_backword	= 1.0;
	  max_steer_value		= 660;
	  min_steer_value		= -660;
	  max_brake_value		= 0;
	  min_brake_value		= 0;
	  max_steer_angle		= 0.42;
	  min_steer_angle		= 0.42;
	  length				= 4.3;
	  width					= 1.82;
	  max_acceleration		= 1.5; // m/s2
	  max_deceleration		= -1.5; // 1/3 G
  }

  double CalcMaxSteeringAngle()
  {
    return  max_steer_angle;//asin(wheel_base/turning_radius);
  }

  double BoundSpeed(double s)
  {
	if(s &gt; 0 &amp;&amp; s &gt; max_speed_forward)
		return max_speed_forward;
	if(s &lt; 0 &amp;&amp; s &lt; max_speed_backword)
		return max_speed_backword;
	return s;
  }

  double BoundSteerAngle(double a)
  {
	if(a &gt; max_steer_angle)
		return max_steer_angle;
	if(a &lt; min_steer_angle)
		return min_steer_angle;

	return a;
  }

  double BoundSteerValue(double v)
  {
	  if(v &gt;= max_steer_value)
		return max_steer_value;
	if(v &lt;= min_steer_value)
		return min_steer_value;

	return v;
  }

};


} /* namespace PlannerHNS */

#endif /* PLANNERCOMMONDEF_H_ */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/PlanningHelpers.h" new_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/PlanningHelpers.h">
				<diff>@@ -8,7 +8,7 @@
 #ifndef PLANNINGHELPERS_H_
 #define PLANNINGHELPERS_H_
 
-#include &lt;cmath&gt;
+#include &lt;math.h&gt;
 #include &quot;RoadNetwork.h&quot;
 #include &quot;UtilityH.h&quot;
 #include &quot;DataRW.h&quot;
</diff>
				<old_file>/*
 * PlanningHelpers.h
 *
 *  Created on: Jun 16, 2016
 *      Author: hatem
 */

#ifndef PLANNINGHELPERS_H_
#define PLANNINGHELPERS_H_

#include &lt;cmath&gt;
#include &quot;RoadNetwork.h&quot;
#include &quot;UtilityH.h&quot;
#include &quot;DataRW.h&quot;
#include &quot;tinyxml.h&quot;


namespace PlannerHNS {

#define distance2points(from , to) sqrt(pow(to.x - from.x, 2) + pow(to.y - from.y, 2))
#define distance2pointsSqr(from , to) pow(to.x - from.x, 2) + pow(to.y - from.y, 2)
#define pointNorm(v) sqrt(v.x*v.x + v.y*v.y)
#define angle2points(from , to) atan2(to.y - from.y, to.x - from.x )
#define LANE_CHANGE_SPEED_FACTOR 0.5
#define LANE_CHANGE_COST 3.0 // meters
#define BACKUP_STRAIGHT_PLAN_DISTANCE 60 //meters

class PlanningHelpers {
public:
	PlanningHelpers();
	virtual ~PlanningHelpers();

	/**
	 * @brief Find all relative information from the point p to the trajectory such as (perpendicular distance , closest next point , closest back point, distance from perpendicular intersection point to next point, distance from perpendicular intersection point to previous point)
	 * @param trajectory list of waypoints
	 * @param p query point
	 * @param info collection of calculated information
	 * @param prevIndex initial search index
	 * @return true if success without errors, false otherwise
	 */
	static bool GetRelativeInfo(const std::vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p, RelativeInfo&amp; info, const int&amp; prevIndex = 0);

	static bool GetRelativeInfoRange(const std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; trajectories, const WayPoint&amp; p, const double&amp; searchDistance, RelativeInfo&amp; info);

	/**
	 * @brief Find point on the trajectory after initial relative point with specific distance
	 * @param trajectory list of waypoints
	 * @param init_p initial relative point on trajectory
	 * @param distance distance from initial relative point to follow point
	 * @return point on trajectory
	 */
	static WayPoint GetFollowPointOnTrajectory(const std::vector&lt;WayPoint&gt;&amp; trajectory, const RelativeInfo&amp; init_p, const double&amp; distance, unsigned int&amp; point_index);

	/**
	 * @brief Calculate the precise distance from projection of point p2 (relative) to projection of point 1 (relative)
	 * @param trajectory list of waypoints
	 * @param p1 first relative point
	 * @param p2 second relative point
	 * @return distance on trajectory
	 */
	static double GetExactDistanceOnTrajectory(const std::vector&lt;WayPoint&gt;&amp; trajectory, const RelativeInfo&amp; p1,const RelativeInfo&amp; p2);

	/**
	 * @brief Find the closest next point on the trajectory index
	 * @param trajectory list of waypoints
	 * @param p query point
	 * @param prevIndex initial search index
	 * @return index of the closest next point from trajectory
	 */
	static int GetClosestNextPointIndex(const std::vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p, const int&amp; prevIndex = 0);

	static int GetClosestNextPointIndexDirection(const std::vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p, const int&amp; prevIndex = 0);


	static int GetClosestPointIndex_obsolete(const std::vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p,const int&amp; prevIndex = 0 );
	static WayPoint GetPerpendicularOnTrajectory_obsolete(const std::vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p, double&amp; distance, const int&amp; prevIndex = 0);
	static double GetPerpDistanceToTrajectorySimple_obsolete(const std::vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p, const int&amp; prevIndex = 0);
	static double GetPerpDistanceToVectorSimple_obsolete(const WayPoint&amp; p1, const WayPoint&amp; p2, const WayPoint&amp; pose);
	static WayPoint GetNextPointOnTrajectory_obsolete(const std::vector&lt;WayPoint&gt;&amp; trajectory, const double&amp; distance, const int&amp; currIndex = 0);
	static double GetDistanceOnTrajectory_obsolete(const std::vector&lt;WayPoint&gt;&amp; path, const int&amp; start_index, const WayPoint&amp; p);


	static void FixPathDensity(std::vector&lt;WayPoint&gt;&amp; path, const double&amp; distanceDensity);
	static void SmoothPath(std::vector&lt;WayPoint&gt;&amp; path, double weight_data =0.25,double weight_smooth = 0.25,double tolerance = 0.01);
	static double CalcCircle(const GPSPoint&amp; pt1, const GPSPoint&amp; pt2, const GPSPoint&amp; pt3, GPSPoint&amp; center);
	static double CalcAngleAndCost(std::vector&lt;WayPoint&gt;&amp; path, const double&amp; lastCost = 0, const bool&amp; bSmooth = true );
	//static double CalcAngleAndCostSimple(std::vector&lt;WayPoint&gt;&amp; path, const double&amp; lastCost = 0);
	static double CalcAngleAndCostAndCurvatureAnd2D(std::vector&lt;WayPoint&gt;&amp; path, const double&amp; lastCost = 0);

	static double GetAccurateDistanceOnTrajectory(std::vector&lt;WayPoint&gt;&amp; path, const int&amp; start_index, const WayPoint&amp; p);

	static void ExtractPartFromPointToDistance(const std::vector&lt;WayPoint&gt;&amp; originalPath, const WayPoint&amp; pos, const double&amp; minDistance,
			const double&amp; pathDensity, std::vector&lt;WayPoint&gt;&amp; extractedPath, const double&amp; SmoothDataWeight, const double&amp; SmoothWeight, const double&amp; SmoothTolerance);

	static void CalculateRollInTrajectories(const WayPoint&amp; carPos, const double&amp; speed, const std::vector&lt;WayPoint&gt;&amp; originalCenter, int&amp; start_index,
			int&amp; end_index, std::vector&lt;double&gt;&amp; end_laterals ,
			std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; rollInPaths, const double&amp; max_roll_distance,
			const double&amp; maxSpeed, const double&amp;  carTipMargin, const double&amp; rollInMargin,
			const double&amp; rollInSpeedFactor, const double&amp; pathDensity, const double&amp; rollOutDensity,
			const int&amp; rollOutNumber, const double&amp; SmoothDataWeight, const double&amp; SmoothWeight,
			const double&amp; SmoothTolerance, const bool&amp; bHeadingSmooth,
			std::vector&lt;WayPoint&gt;&amp; sampledPoints);


	static void SmoothSpeedProfiles(std::vector&lt;WayPoint&gt;&amp; path_in, double weight_data, double weight_smooth, double tolerance	= 0.1);
	static void SmoothCurvatureProfiles(std::vector&lt;WayPoint&gt;&amp; path_in, double weight_data, double weight_smooth, double tolerance = 0.1);
	static void SmoothWayPointsDirections(std::vector&lt;WayPoint&gt;&amp; path_in, double weight_data, double weight_smooth, double tolerance	= 0.1);

	static void GenerateRecommendedSpeed(std::vector&lt;WayPoint&gt;&amp; path, const double&amp; max_speed, const double&amp; speedProfileFactor);
//	static WayPoint* BuildPlanningSearchTree(Lane* l, const WayPoint&amp; prevWayPointIndex,
//			const WayPoint&amp; startPos, const WayPoint&amp; goalPos,
//			const std::vector&lt;int&gt;&amp; globalPath, const double&amp; DistanceLimit,
//			int&amp; nMaxLeftBranches, int&amp; nMaxRightBranches,
//			std::vector&lt;WayPoint*&gt;&amp; all_cells_to_delete );

	static WayPoint* BuildPlanningSearchTreeV2(WayPoint* pStart,
			const WayPoint&amp; goalPos,
			const std::vector&lt;int&gt;&amp; globalPath, const double&amp; DistanceLimit,
			const bool&amp; bEnableLaneChange,
			std::vector&lt;WayPoint*&gt;&amp; all_cells_to_delete );

	static WayPoint* BuildPlanningSearchTreeStraight(WayPoint* pStart,
			const double&amp; DistanceLimit,
			std::vector&lt;WayPoint*&gt;&amp; all_cells_to_delete );

	static int PredictiveDP(WayPoint* pStart, const double&amp; DistanceLimit,
			std::vector&lt;WayPoint*&gt;&amp; all_cells_to_delete, std::vector&lt;WayPoint*&gt;&amp; end_waypoints);

	static bool CheckLaneIdExits(const std::vector&lt;int&gt;&amp; lanes, const Lane* pL);
	static WayPoint* CheckLaneExits(const std::vector&lt;WayPoint*&gt;&amp; nodes, const Lane* pL);
	static WayPoint* CheckNodeExits(const std::vector&lt;WayPoint*&gt;&amp; nodes, const WayPoint* pL);

	static WayPoint* CreateLaneHeadCell(Lane* pLane, WayPoint* pLeft, WayPoint* pRight,
			WayPoint* pBack);
	static double GetLanePoints(Lane* l, const WayPoint&amp; prevWayPointIndex,
			const double&amp; minDistance , const double&amp; prevCost, std::vector&lt;WayPoint&gt;&amp; points);

	static WayPoint* GetMinCostCell(const std::vector&lt;WayPoint*&gt;&amp; cells, const std::vector&lt;int&gt;&amp; globalPathIds);

	static void TraversePathTreeBackwards(WayPoint* pHead, WayPoint* pStartWP, const std::vector&lt;int&gt;&amp; globalPathIds,
			std::vector&lt;WayPoint&gt;&amp; localPath, std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; localPaths);

	static void ExtractPlanAlernatives(const std::vector&lt;WayPoint&gt;&amp; singlePath, std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; allPaths);

	static std::vector&lt;int&gt; GetUniqueLeftRightIds(const std::vector&lt;WayPoint&gt;&amp; path);

	static bool FindInList(const std::vector&lt;int&gt;&amp; list,const int&amp; x);
	static void RemoveWithValue(std::vector&lt;int&gt;&amp; list,const int&amp; x);

	static ACTION_TYPE GetBranchingDirection(WayPoint&amp; currWP, WayPoint&amp; nextWP);

	static void CalcContourPointsForDetectedObjects(const WayPoint&amp; currPose, std::vector&lt;DetectedObject&gt;&amp; obj_list, const double&amp; filterDistance = 100);

	static double GetVelocityAhead(const std::vector&lt;WayPoint&gt;&amp; path, const WayPoint&amp; pose, const double&amp; distance);
	static bool CompareTrajectories(const std::vector&lt;WayPoint&gt;&amp; path1, const std::vector&lt;WayPoint&gt;&amp; path2);

	static double GetDistanceToClosestStopLineAndCheck(const std::vector&lt;WayPoint&gt;&amp; path, const WayPoint&amp; p, int&amp; stopLineID,int&amp; stopSignID, int&amp; trafficLightID, const int&amp; prevIndex = 0);

	static void WritePathToFile(const std::string&amp; fileName, const std::vector&lt;WayPoint&gt;&amp; path);

	static void TestQuadraticSpline(const std::vector&lt;WayPoint&gt;&amp; center_line, std::vector&lt;WayPoint&gt;&amp; path);
	static double frunge ( double x );
	static double fprunge ( double x );
	static double fpprunge ( double x );

};

} /* namespace PlannerHNS */

#endif /* PLANNINGHELPERS_H_ */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/geo_pos_conv.hh" new_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/include/geo_pos_conv.hh">
				<diff>@@ -1,7 +1,7 @@
 #ifndef __GEO_POS_CONV__
 #define __GEO_POS_CONV__
 
-#include &lt;cmath&gt;
+#include &lt;math.h&gt;
 
 class geo_pos_conv {
 private:
</diff>
				<old_file>#ifndef __GEO_POS_CONV__
#define __GEO_POS_CONV__

#include &lt;cmath&gt;

class geo_pos_conv {
private:
	double m_x;  //m
	double m_y;  //m
	double m_z;  //m

	double m_lat;  //latitude
	double m_lon; //longitude
	double m_h;
  
	double m_PLato;        //plane lat
	double m_PLo;          //plane lon

public:
	double x() const;
	double y() const;
	double z() const;
  
	void set_plane(double lat,   double lon);
	void set_plane(int num);
	void set_xyz(double cx,   double cy,   double cz);

	//set llh in radians
	void set_llh(double lat, double lon, double h);

	//set llh in nmea degrees
	void set_llh_nmea_degrees(double latd,double lond, double h);

        void llh_to_xyz(double lat, double lon, double ele);

	void conv_llh2xyz(void);
	void conv_xyz2llh(void);
};

#endif
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/src/LocalPlannerH.cpp" new_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/src/LocalPlannerH.cpp">
				<diff>@@ -159,7 +159,7 @@ void LocalPlannerH::InitPolygons()
 		 double diff = desiredSteerDeg - currSteerDeg;
 		 double diffSign = UtilityH::GetSign(diff);
 		 double inc = 1.0*diffSign;
-		 if(abs(diff) &lt; 1.0 )
+		 if(fabs(diff) &lt; 1.0 )
 			 inc = diff;
 
 //		 std::cout &lt;&lt; &quot;Delay: &quot; &lt;&lt; m_SimulationSteeringDelayFactor
@@ -515,7 +515,7 @@ bool LocalPlannerH::CalculateIntersectionVelocities(std::vector&lt;PlannerHNS::WayP
 				{
 					double collision_distance = hypot(ego_path.at(i).pos.x-predctedPath.at(k).at(j).pos.x, ego_path.at(i).pos.y-predctedPath.at(k).at(j).pos.y);
 					double contact_distance = hypot(state.pos.x - ego_path.at(i).pos.x,state.pos.y - ego_path.at(i).pos.y);
-					if(collision_distance &lt;= m_CarInfo.width  &amp;&amp; abs(ego_path.at(i).timeCost - predctedPath.at(k).at(j).timeCost)&lt;4.0)
+					if(collision_distance &lt;= m_CarInfo.width  &amp;&amp; fabs(ego_path.at(i).timeCost - predctedPath.at(k).at(j).timeCost)&lt;4.0)
 					{
 						ego_path.at(i).collisionCost = 1;
 						double a = UtilityH::AngleBetweenTwoAnglesPositive(ego_path.at(i).pos.a, predctedPath.at(k).at(j).pos.a);
</diff>
				<old_file>/*
 * CarState.cpp
 *
 *  Created on: Jun 20, 2016
 *      Author: hatem
 */

#include &quot;LocalPlannerH.h&quot;
#include &quot;UtilityH.h&quot;
#include &quot;PlanningHelpers.h&quot;
#include &quot;MappingHelpers.h&quot;
#include &quot;MatrixOperations.h&quot;
#include &quot;PlannerH.h&quot;

using namespace UtilityHNS;

namespace PlannerHNS
{

LocalPlannerH::LocalPlannerH()
{
	m_iSafeTrajectory = 0;
	m_iCurrentTotalPathId = 0;
	pLane = 0;
	m_CurrentVelocity =  m_CurrentVelocityD =0;
	m_CurrentSteering = m_CurrentSteeringD =0;
	m_CurrentShift 		=  m_CurrentShiftD = SHIFT_POS_NN;
	m_CurrentAccSteerAngle = m_CurrentAccVelocity = 0;
	m_pCurrentBehaviorState = 0;
	m_pGoToGoalState = 0;
	m_pStopState= 0;
	m_pWaitState= 0;
	m_pMissionCompleteState= 0;
	m_pAvoidObstacleState = 0;
	m_pTrafficLightStopState = 0;
	m_pTrafficLightWaitState = 0;
	m_pStopSignStopState = 0;
	m_pStopSignWaitState = 0;
	m_pFollowState = 0;
	m_SimulationSteeringDelayFactor = 0.1;
	UtilityH::GetTickCount(m_SteerDelayTimer);
	m_PredictionTime = 0;
	InitBehaviorStates();
}

LocalPlannerH::~LocalPlannerH()
{

}

void LocalPlannerH::Init(const ControllerParams&amp; ctrlParams, const PlannerHNS::PlanningParams&amp; params,const CAR_BASIC_INFO&amp; carInfo)
 	{
 		m_CarInfo = carInfo;
 		m_ControlParams = ctrlParams;
 		m_CurrentVelocity =  m_CurrentVelocityD =0;
 		m_CurrentSteering = m_CurrentSteeringD =0;
 		m_CurrentShift 		=  m_CurrentShiftD = SHIFT_POS_NN;
 		m_CurrentAccSteerAngle = m_CurrentAccVelocity = 0;
 		m_params = params;

 		if(m_pCurrentBehaviorState)
 			m_pCurrentBehaviorState-&gt;SetBehaviorsParams(&amp;m_params);
 	}

void LocalPlannerH::InitBehaviorStates()
{

	m_pStopState 				= new StopState(&amp;m_params, 0, 0);
	m_pMissionCompleteState 	= new MissionAccomplishedState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), 0);
	m_pGoalState				= new GoalState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pMissionCompleteState);
	m_pGoToGoalState 			= new ForwardState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pGoalState);
	m_pWaitState 				= new WaitState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pGoToGoalState);
	m_pInitState 				= new InitState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pGoToGoalState);
	m_pFollowState				= new FollowState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pGoToGoalState);
	m_pAvoidObstacleState		= new SwerveState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pGoToGoalState);
	m_pTrafficLightStopState	= new TrafficLightStopState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pGoToGoalState);
	m_pTrafficLightWaitState	= new TrafficLightWaitState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pGoToGoalState);
	m_pStopSignWaitState		= new StopSignWaitState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pGoToGoalState);
	m_pStopSignStopState		= new StopSignStopState(m_pStopState-&gt;m_pParams, m_pStopState-&gt;GetCalcParams(), m_pStopSignWaitState);

	m_pGoToGoalState-&gt;InsertNextState(m_pStopState);
	m_pGoToGoalState-&gt;InsertNextState(m_pWaitState);
	m_pGoToGoalState-&gt;InsertNextState(m_pFollowState);
	m_pGoToGoalState-&gt;InsertNextState(m_pAvoidObstacleState);
	m_pGoToGoalState-&gt;InsertNextState(m_pTrafficLightStopState);
	m_pGoToGoalState-&gt;InsertNextState(m_pStopSignStopState);

	m_pStopState-&gt;InsertNextState(m_pGoToGoalState);

	m_pTrafficLightStopState-&gt;InsertNextState(m_pTrafficLightWaitState);
	m_pTrafficLightWaitState-&gt;InsertNextState(m_pTrafficLightStopState);

	m_pStopSignWaitState-&gt;decisionMakingTime = 5.0;
	m_pStopSignWaitState-&gt;InsertNextState(m_pStopSignStopState);

	m_pCurrentBehaviorState = m_pInitState;
}

void LocalPlannerH::InitPolygons()
{
	double l2 = m_CarInfo.length/2.0;
	double w2 = m_CarInfo.width/2.0;

	m_CarShapePolygon.push_back(GPSPoint(-w2, -l2, 0,0));
	m_CarShapePolygon.push_back(GPSPoint(w2, -l2, 0,0));
	m_CarShapePolygon.push_back(GPSPoint(w2, l2, 0,0));
	m_CarShapePolygon.push_back(GPSPoint(-w2, l2, 0,0));
}

 void LocalPlannerH::FirstLocalizeMe(const WayPoint&amp; initCarPos)
 {
	pLane = initCarPos.pLane;
	state = initCarPos;
	m_OdometryState.pos.a = initCarPos.pos.a;
	m_OdometryState.pos.x = initCarPos.pos.x + (m_CarInfo.wheel_base/2.0 * cos(initCarPos.pos.a));
	m_OdometryState.pos.y = initCarPos.pos.y + (m_CarInfo.wheel_base/2.0 * sin(initCarPos.pos.a));
 }

 void LocalPlannerH::LocalizeMe(const double&amp; dt)
{
	//calculate the new x, y ,
	 WayPoint currPose = state;

	if(m_CurrentShift == SHIFT_POS_DD)
	{
		m_OdometryState.pos.x	 +=  m_CurrentVelocity * dt * cos(currPose.pos.a);
		m_OdometryState.pos.y	 +=  m_CurrentVelocity * dt * sin(currPose.pos.a);
		m_OdometryState.pos.a	 +=  m_CurrentVelocity * dt * tan(m_CurrentSteering)  / m_CarInfo.wheel_base;

	}
	else if(m_CurrentShift == SHIFT_POS_RR )
	{
		m_OdometryState.pos.x	 +=  -m_CurrentVelocity * dt * cos(currPose.pos.a);
		m_OdometryState.pos.y	 +=  -m_CurrentVelocity * dt * sin(currPose.pos.a);
		m_OdometryState.pos.a	 +=  -m_CurrentVelocity * dt * tan(m_CurrentSteering);
	}

	m_OdometryState.pos.a = atan2(sin(m_OdometryState.pos.a), cos(m_OdometryState.pos.a));
	m_OdometryState.pos.a = UtilityH::FixNegativeAngle(m_OdometryState.pos.a);

	state.pos.a = m_OdometryState.pos.a;
	state.pos.x = m_OdometryState.pos.x	 - (m_CurrentVelocity*dt* (m_CarInfo.wheel_base) * cos (m_OdometryState.pos.a));
	state.pos.y = m_OdometryState.pos.y	 - (m_CurrentVelocity*dt* (m_CarInfo.wheel_base/2.0) * sin (m_OdometryState.pos.a));
}

 void LocalPlannerH::UpdateState(const PlannerHNS::VehicleState&amp; state, const bool&amp; bUseDelay)
  {
	 if(!bUseDelay)
	 {
		 m_CurrentSteering 	= m_CurrentSteeringD;
		// std::cout &lt;&lt; &quot; No Delay &quot; &lt;&lt; std::endl;
	 }
	 else
	 {
		 double currSteerDeg = RAD2DEG * m_CurrentSteering;
		 double desiredSteerDeg = RAD2DEG * m_CurrentSteeringD;

		 double mFact = UtilityH::GetMomentumScaleFactor(state.speed);
		 double diff = desiredSteerDeg - currSteerDeg;
		 double diffSign = UtilityH::GetSign(diff);
		 double inc = 1.0*diffSign;
		 if(abs(diff) &lt; 1.0 )
			 inc = diff;

//		 std::cout &lt;&lt; &quot;Delay: &quot; &lt;&lt; m_SimulationSteeringDelayFactor
//				 &lt;&lt; &quot;, Fact: &quot; &lt;&lt; mFact
//				 &lt;&lt; &quot;, Diff: &quot; &lt;&lt; diff
//				 &lt;&lt; &quot;, inc: &quot; &lt;&lt; inc &lt;&lt; std::endl;
		 if(UtilityH::GetTimeDiffNow(m_SteerDelayTimer) &gt; m_SimulationSteeringDelayFactor*mFact)
		 {
			 UtilityH::GetTickCount(m_SteerDelayTimer);
			 currSteerDeg += inc;
		 }

		 m_CurrentSteering = DEG2RAD * currSteerDeg;
	 }

	 m_CurrentShift 	= m_CurrentShiftD;
	 m_CurrentVelocity = m_CurrentVelocityD;
  }

 void LocalPlannerH::AddAndTransformContourPoints(const PlannerHNS::DetectedObject&amp; obj, std::vector&lt;PlannerHNS::WayPoint&gt;&amp; contourPoints)
 {
	 contourPoints.clear();
	 WayPoint  p, p_center = obj.center;
	 p_center.pos.a += M_PI_2;
	 for(unsigned int i=0; i&lt; obj.contour.size(); i++)
	 {
		 p.pos = obj.contour.at(i);
		 //TransformPoint(p_center, p.pos);
		 contourPoints.push_back(p);
	 }

	 contourPoints.push_back(obj.center);
 }

 void LocalPlannerH::TransformPoint(const PlannerHNS::WayPoint&amp; refPose, PlannerHNS::GPSPoint&amp; p)
 {
 	PlannerHNS::Mat3 rotationMat(refPose.pos.a);
 	PlannerHNS::Mat3 translationMat(refPose.pos.x, refPose.pos.y);
	p = rotationMat*p;
	p = translationMat*p;
 }

 bool LocalPlannerH::GetNextTrafficLight(const int&amp; prevTrafficLightId, const std::vector&lt;PlannerHNS::TrafficLight&gt;&amp; trafficLights, PlannerHNS::TrafficLight&amp; trafficL)
 {
	 for(unsigned int i = 0; i &lt; trafficLights.size(); i++)
	 {
		 double d = hypot(trafficLights.at(i).pos.y - state.pos.y, trafficLights.at(i).pos.x - state.pos.x);
		 if(d &lt;= trafficLights.at(i).stoppingDistance)
		 {
			 //double a = UtilityH::FixNegativeAngle(atan2(trafficLights.at(i).pos.y - state.pos.y, trafficLights.at(i).pos.x - state.pos.x));
			 double a_diff = UtilityH::AngleBetweenTwoAnglesPositive(UtilityH::FixNegativeAngle(trafficLights.at(i).pos.a) , UtilityH::FixNegativeAngle(state.pos.a));

			 if(a_diff &lt; M_PI_2 &amp;&amp; trafficLights.at(i).id != prevTrafficLightId)
			 {
				 //std::cout &lt;&lt; &quot;Detected Light, ID = &quot; &lt;&lt; trafficLights.at(i).id &lt;&lt; &quot;, Distance = &quot; &lt;&lt; d &lt;&lt; &quot;, Angle = &quot; &lt;&lt; trafficLights.at(i).pos.a*RAD2DEG &lt;&lt; &quot;, Car Heading = &quot; &lt;&lt; state.pos.a*RAD2DEG &lt;&lt; &quot;, Diff = &quot; &lt;&lt; a_diff*RAD2DEG &lt;&lt; std::endl;
				 trafficL = trafficLights.at(i);
				 return true;
			 }
		 }
	 }

	 return false;
 }

 void LocalPlannerH::CalculateImportantParameterForDecisionMaking(const PlannerHNS::VehicleState&amp; car_state,
		 const int&amp; goalID, const bool&amp; bEmergencyStop, const bool&amp; bGreenTrafficLight,
		 const TrajectoryCost&amp; bestTrajectory)
 {
 	PreCalculatedConditions* pValues = m_pCurrentBehaviorState-&gt;GetCalcParams();

 	double critical_long_front_distance =  m_CarInfo.wheel_base/2.0 + m_CarInfo.length/2.0 + m_params.verticalSafetyDistance;
	//double critical_long_back_distance =  m_CarInfo.length/2.0 + m_params.verticalSafetyDistance - m_CarInfo.wheel_base/2.0;

 	pValues-&gt;minStoppingDistance = -pow(car_state.speed, 2)/m_CarInfo.max_deceleration;

 	pValues-&gt;iCentralTrajectory		= m_pCurrentBehaviorState-&gt;m_pParams-&gt;rollOutNumber/2;

 	if(pValues-&gt;iCurrSafeTrajectory &lt; 0)
 			pValues-&gt;iCurrSafeTrajectory = pValues-&gt;iCentralTrajectory;

	if(pValues-&gt;iPrevSafeTrajectory &lt; 0)
		pValues-&gt;iPrevSafeTrajectory = pValues-&gt;iCentralTrajectory;

 	pValues-&gt;stoppingDistances.clear();
 	pValues-&gt;currentVelocity 		= car_state.speed;
 	pValues-&gt;bTrafficIsRed 			= false;
 	pValues-&gt;currentTrafficLightID 	= -1;
// 	pValues-&gt;currentStopSignID		= -1;
 	pValues-&gt;bRePlan 				= false;
 	pValues-&gt;bFullyBlock 			= false;


 	pValues-&gt;distanceToNext = bestTrajectory.closest_obj_distance;
 	pValues-&gt;velocityOfNext = bestTrajectory.closest_obj_velocity;

 	if(pValues-&gt;distanceToNext &gt; m_params.minDistanceToAvoid)
 		pValues-&gt;iCurrSafeTrajectory = pValues-&gt;iCentralTrajectory;
 	else if(bestTrajectory.index&gt;=0)
 		pValues-&gt;iCurrSafeTrajectory = bestTrajectory.index;

	pValues-&gt;bFullyBlock = bestTrajectory.bBlocked;

 	if(bestTrajectory.lane_index &gt;=0)
 		pValues-&gt;iCurrSafeLane = bestTrajectory.lane_index;
 	else
 	{
 		PlannerHNS::RelativeInfo info;
 		PlannerHNS::PlanningHelpers::GetRelativeInfoRange(m_TotalPath, state, m_params.rollOutDensity*m_params.rollOutNumber/2.0 + 0.1, info);
 		pValues-&gt;iCurrSafeLane = info.iGlobalPath;
 	}


	if(NoWayTest(pValues-&gt;minStoppingDistance, pValues-&gt;iCurrSafeLane))
		pValues-&gt;currentGoalID = -1;
	else
		pValues-&gt;currentGoalID = goalID;

 	m_iSafeTrajectory = pValues-&gt;iCurrSafeTrajectory;
 	m_iCurrentTotalPathId = pValues-&gt;iCurrSafeLane;


// 	if(bestTrajectory.index == -1 &amp;&amp; pValues-&gt;distanceToNext &lt; m_pCurrentBehaviorState-&gt;m_pParams-&gt;minFollowingDistance)
// 		pValues-&gt;bFullyBlock = true;



 	int stopLineID = -1;
 	int stopSignID = -1;
 	int trafficLightID = -1;
 	double distanceToClosestStopLine = 0;

 	if(m_TotalPath.size()&gt;0)
 		distanceToClosestStopLine = PlanningHelpers::GetDistanceToClosestStopLineAndCheck(m_TotalPath.at(pValues-&gt;iCurrSafeLane), state, stopLineID, stopSignID, trafficLightID) - critical_long_front_distance;

 	if(distanceToClosestStopLine &gt; 0 &amp;&amp; distanceToClosestStopLine &lt; pValues-&gt;minStoppingDistance)
 	{
 		if(m_pCurrentBehaviorState-&gt;m_pParams-&gt;enableTrafficLightBehavior)
 			pValues-&gt;currentTrafficLightID = trafficLightID;

 		if(m_pCurrentBehaviorState-&gt;m_pParams-&gt;enableStopSignBehavior)
 			pValues-&gt;currentStopSignID = stopSignID;

		pValues-&gt;stoppingDistances.push_back(distanceToClosestStopLine);
		//std::cout &lt;&lt; &quot;From Local Planner =&gt; D: &quot; &lt;&lt; pValues-&gt;distanceToStop() &lt;&lt; &quot;, Prev SignID: &quot; &lt;&lt; pValues-&gt;prevStopSignID &lt;&lt; &quot;, Curr SignID: &quot; &lt;&lt; pValues-&gt;currentStopSignID &lt;&lt; endl;
 	}


// 	cout &lt;&lt; &quot;Distance To Closest: &quot; &lt;&lt; distanceToClosestStopLine &lt;&lt; &quot;, Stop LineID: &quot; &lt;&lt; stopLineID &lt;&lt; &quot;, Stop SignID: &quot; &lt;&lt; stopSignID &lt;&lt; &quot;, TFID: &quot; &lt;&lt; trafficLightID &lt;&lt; endl;

 	pValues-&gt;bTrafficIsRed = !bGreenTrafficLight;

 	if(bEmergencyStop)
	{
		pValues-&gt;bFullyBlock = true;
		pValues-&gt;distanceToNext = 1;
		pValues-&gt;velocityOfNext = 0;
	}
 	//cout &lt;&lt; &quot;Distances: &quot; &lt;&lt; pValues-&gt;stoppingDistances.size() &lt;&lt; &quot;, Distance To Stop : &quot; &lt;&lt; pValues-&gt;distanceToStop &lt;&lt; endl;
 }

double LocalPlannerH::PredictTimeCostForTrajectory(std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path, const PlannerHNS::VehicleState&amp; vstatus, const PlannerHNS::WayPoint&amp; currState)
{
	PlanningParams* pParams = m_pCurrentBehaviorState-&gt;m_pParams;

		//1- Calculate time prediction for each trajectory
	if(path.size() == 0) return 0;

//	SimulatedTrajectoryFollower predControl;
//	ControllerParams params;
//	params.Steering_Gain = PID_CONST(1.5, 0.0, 0.0);
//	params.Velocity_Gain = PID_CONST(0.2, 0.01, 0.1);
//	params.minPursuiteDistance = 3.0;
//
//	predControl.Init(params, m_CarInfo);
//	//double totalDistance = 0;
//	VehicleState CurrentState = vstatus;
//	VehicleState CurrentSteeringD;
//	bool bNewPath = true;
//	WayPoint localState = currState;
//	WayPoint prevState = currState;
//	int iPrevIndex = 0;
	double accum_time = 0;
//	double pred_max_time = 10.0;
//	double endDistance = pParams-&gt;microPlanDistance/2.0;
//
//	for(unsigned int i = 0 ; i &lt; path.size(); i++)
//	{
//		path.at(i).collisionCost = 0;
//		path.at(i).timeCost = -1;
//	}
//
//	int startIndex = PlanningHelpers::GetClosestPointIndex(path, state);
//	double total_distance = 0;
//	path.at(startIndex).timeCost = 0;
//	for(unsigned int i=startIndex+1; i&lt;path.size(); i++)
//	{
//		total_distance += hypot(path.at(i).pos.x- path.at(i-1).pos.x,path.at(i).pos.y- path.at(i-1).pos.y);
//		if(m_CurrentVelocity &gt; 0.1 &amp;&amp; total_distance &gt; 0.1)
//			accum_time = total_distance/m_CurrentVelocity;
//		path.at(i).timeCost = accum_time;
//		if(total_distance &gt; endDistance)
//			break;
//	}

//	while(totalDistance &lt; pParams-&gt;microPlanDistance/2.0 &amp;&amp; accum_time &lt; pred_max_time)
//	{
//		double dt = 0.05;
//		PlannerHNS::BehaviorState currMessage;
//		currMessage.state = FORWARD_STATE;
//		currMessage.maxVelocity = PlannerHNS::PlanningHelpers::GetVelocityAhead(m_Path, state, 1.5*CurrentState.speed*3.6);
//
//		ControllerParams c_params = m_ControlParams;
//		c_params.SteeringDelay = m_ControlParams.SteeringDelay / (1.0-UtilityH::GetMomentumScaleFactor(CurrentState.speed));
//		predControl.Init(c_params, m_CarInfo);
//		CurrentSteeringD = predControl.DoOneStep(dt, currMessage, path, localState, CurrentState, bNewPath);
//
//		if(bNewPath) // first call
//		{
//			if(predControl.m_iCalculatedIndex &gt; 0)
//			{
//				for(unsigned int j=0; j &lt; predControl.m_iCalculatedIndex; j++)
//					path.at(j).timeCost = -1;
//			}
//		}
//		else
//		{
//			if(predControl.m_iCalculatedIndex != iPrevIndex)
//				path.at(iPrevIndex).timeCost = accum_time;
//		}
//
//		accum_time+=dt;
//		bNewPath = false;
//
//		//Update State
//		CurrentState = CurrentSteeringD;
//
//		//Localize Me
//		localState.pos.x	 +=  CurrentState.speed * dt * cos(localState.pos.a);
//		localState.pos.y	 +=  CurrentState.speed * dt * sin(localState.pos.a);
//		localState.pos.a	 +=  CurrentState.speed * dt * tan(CurrentState.steer)  / m_CarInfo.wheel_base;
//
//		totalDistance += distance2points(prevState.pos, localState.pos);
//
//		prevState = localState;
//		iPrevIndex = predControl.m_iCalculatedIndex;
//	}

	return accum_time;
}

void LocalPlannerH::PredictObstacleTrajectory(PlannerHNS::RoadNetwork&amp; map, const PlannerHNS::WayPoint&amp; pos, const double&amp; predTime, std::vector&lt;std::vector&lt;PlannerHNS::WayPoint&gt; &gt;&amp; paths)
{
	PlannerHNS::PlanningParams planningDefaultParams;
	planningDefaultParams.rollOutNumber = 0;
	planningDefaultParams.microPlanDistance = predTime*pos.v;

	planningDefaultParams.pathDensity = 0.5;
	//PlannerHNS::Lane* pMapLane  = MappingHelpers::GetClosestLaneFromMapDirectionBased(pos, map, 3.0);
	std::vector&lt;PlannerHNS::Lane*&gt; pMapLanes = MappingHelpers::GetClosestMultipleLanesFromMap(pos, map, 1.5);

	PlannerHNS::PlannerH planner;
	std::vector&lt;int&gt; LanesIds;
	std::vector&lt; std::vector&lt;PlannerHNS::WayPoint&gt; &gt;  rollOuts;
	std::vector&lt;std::vector&lt;PlannerHNS::WayPoint&gt; &gt; generatedPath;

	if(planningDefaultParams.microPlanDistance &gt; 0)
	{
		for(unsigned int i = 0; i &lt; pMapLanes.size(); i++)
		{
			std::vector&lt;std::vector&lt;PlannerHNS::WayPoint&gt; &gt; loca_generatedPath;
			planner.PredictPlanUsingDP(pMapLanes.at(i), pos, planningDefaultParams.microPlanDistance, loca_generatedPath);
			if(loca_generatedPath.size() &gt; 0)
				generatedPath.insert(generatedPath.begin(),loca_generatedPath.begin(), loca_generatedPath.end());
		}
	}

//	planner.GenerateRunoffTrajectory(generatedPath, pos,
//			planningDefaultParams.enableLaneChange,
//			pos.v,
//			planningDefaultParams.microPlanDistance,
//			m_CarInfo.max_speed_forward,
//			planningDefaultParams.minSpeed,
//			planningDefaultParams.carTipMargin,
//			planningDefaultParams.rollInMargin,
//			planningDefaultParams.rollInSpeedFactor,
//			planningDefaultParams.pathDensity,
//			planningDefaultParams.rollOutDensity,
//			planningDefaultParams.rollOutNumber,
//			planningDefaultParams.smoothingDataWeight,
//			planningDefaultParams.smoothingSmoothWeight,
//			planningDefaultParams.smoothingToleranceError,
//			planningDefaultParams.speedProfileFactor,
//			planningDefaultParams.enableHeadingSmoothing,
//			rollOuts);

	if(generatedPath.size() &gt; 0)
	{
		//path = rollOuts.at(0);
		paths = generatedPath;

//		PlanningHelpers::GenerateRecommendedSpeed(path,
//				m_CarInfo.max_speed_forward,
//				planningDefaultParams.speedProfileFactor);
//		PlanningHelpers::SmoothSpeedProfiles(path, 0.15,0.35, 0.1);
	}

	if(pMapLanes.size() ==0 || paths.size() == 0)
	{
		paths.clear();
		generatedPath.clear();
	}
	else
	{
		//std::cout &lt;&lt; &quot;------------------------------------------------&quot; &lt;&lt;  std::endl;
		//std::cout &lt;&lt; &quot;Predicted Trajectories for Distance : &quot; &lt;&lt;  planningDefaultParams.microPlanDistance &lt;&lt; std::endl;
		for(unsigned int j=0; j &lt; paths.size(); j++)
		{
			if(paths.at(j).size()==0)
				continue;

			double timeDelay = 0;
			double total_distance = 0;
			paths.at(j).at(0).timeCost = 0;
			paths.at(j).at(0).v = pos.v;
			for(unsigned int i=1; i&lt;paths.at(j).size(); i++)
			{
				paths.at(j).at(i).v = pos.v;
				paths.at(j).at(i).pos.a = atan2(paths.at(j).at(i).pos.y - paths.at(j).at(i-1).pos.y, paths.at(j).at(i).pos.x - paths.at(j).at(i-1).pos.x);
				total_distance += distance2points(paths.at(j).at(i).pos, paths.at(j).at(i-1).pos);
				if(pos.v &gt; 0.1 &amp;&amp; total_distance &gt; 0.1)
					timeDelay = total_distance/pos.v;
				paths.at(j).at(i).timeCost = timeDelay;
			}

			//std::cout &lt;&lt; &quot;ID : &quot; &lt;&lt;  j &lt;&lt; &quot;, timeDelay : &quot; &lt;&lt; timeDelay &lt;&lt; &quot;, Distance : &quot; &lt;&lt; total_distance &lt;&lt; std::endl;
		}

		//std::cout &lt;&lt; &quot;------------------------------------------------&quot; &lt;&lt;  std::endl;
	}
}

bool LocalPlannerH::CalculateIntersectionVelocities(std::vector&lt;PlannerHNS::WayPoint&gt;&amp; ego_path, std::vector&lt;std::vector&lt;PlannerHNS::WayPoint&gt; &gt;&amp; predctedPath, const PlannerHNS::DetectedObject&amp; obj)
{
	bool bCollisionDetected = false;
	for(unsigned int k = 0; k &lt; predctedPath.size(); k++)
	{
		for(unsigned int j = 0; j &lt; predctedPath.at(k).size(); j++)
		{
			bool bCollisionFound =false;
			for(unsigned int i = 0; i &lt; ego_path.size(); i++)
			{
				if(ego_path.at(i).timeCost &gt; 0.0)
				{
					double collision_distance = hypot(ego_path.at(i).pos.x-predctedPath.at(k).at(j).pos.x, ego_path.at(i).pos.y-predctedPath.at(k).at(j).pos.y);
					double contact_distance = hypot(state.pos.x - ego_path.at(i).pos.x,state.pos.y - ego_path.at(i).pos.y);
					if(collision_distance &lt;= m_CarInfo.width  &amp;&amp; abs(ego_path.at(i).timeCost - predctedPath.at(k).at(j).timeCost)&lt;4.0)
					{
						ego_path.at(i).collisionCost = 1;
						double a = UtilityH::AngleBetweenTwoAnglesPositive(ego_path.at(i).pos.a, predctedPath.at(k).at(j).pos.a);
						if(a &lt; M_PI_4/2.0)
							ego_path.at(i).v = obj.center.v;
						else
							ego_path.at(i).v = 0;
						predctedPath.at(k).at(j).collisionCost = 1;
						bCollisionFound = true;
						bCollisionDetected = true;
						break;
					}
				}
			}

			if(bCollisionFound)
				break;
		}
	}

	return bCollisionDetected;
}

bool LocalPlannerH::CalculateObstacleCosts(PlannerHNS::RoadNetwork&amp; map, const PlannerHNS::VehicleState&amp; vstatus, const std::vector&lt;PlannerHNS::DetectedObject&gt;&amp; obj_list)
{
	double predTime = PredictTimeCostForTrajectory(m_Path, vstatus, state);
	m_PredictedPath.clear();
	bool bObstacleDetected = false;
	for(unsigned int i = 0; i &lt; obj_list.size(); i++)
	{
		//std::vector&lt;WayPoint&gt; predPath;
		PredictObstacleTrajectory(map, obj_list.at(i).center, 10.0, m_PredictedPath);
		bool bObstacle = CalculateIntersectionVelocities(m_Path, m_PredictedPath, obj_list.at(i));
		if(bObstacle)
			bObstacleDetected = true;
	}

	return bObstacleDetected;
}

 void LocalPlannerH::UpdateCurrentLane(PlannerHNS::RoadNetwork&amp; map, const double&amp; search_distance)
 {
	 PlannerHNS::Lane* pMapLane = 0;
	PlannerHNS::Lane* pPathLane = 0;
	pPathLane = MappingHelpers::GetLaneFromPath(state, m_Path);
	if(!pPathLane)
		pMapLane  = MappingHelpers::GetClosestLaneFromMap(state, map, search_distance);

	if(pPathLane)
		pLane = pPathLane;
	else if(pMapLane)
		pLane = pMapLane;
	else
		pLane = 0;
 }

 void LocalPlannerH::SimulateOdoPosition(const double&amp; dt, const PlannerHNS::VehicleState&amp; vehicleState)
 {
	SetSimulatedTargetOdometryReadings(vehicleState.speed, vehicleState.steer, vehicleState.shift);
	UpdateState(vehicleState, true);
	LocalizeMe(dt);
 }

 bool LocalPlannerH::NoWayTest(const double&amp; min_distance, const int&amp; iGlobalPathIndex)
 {
	 if(m_TotalPath.size()==0) return false;

	 PlannerHNS::RelativeInfo info;
	 PlanningHelpers::GetRelativeInfo(m_TotalPath.at(iGlobalPathIndex), state, info);

	 double d = 0;
	 for(unsigned int i = info.iFront; i &lt; m_TotalPath.at(iGlobalPathIndex).size()-1; i++)
	 {
		 d+= hypot(m_TotalPath.at(iGlobalPathIndex).at(i+1).pos.y - m_TotalPath.at(iGlobalPathIndex).at(i).pos.y, m_TotalPath.at(iGlobalPathIndex).at(i+1).pos.x - m_TotalPath.at(iGlobalPathIndex).at(i).pos.x);
		 if(d &gt; min_distance)
			 return false;
	 }

	 return true;
 }

 bool LocalPlannerH::SelectSafeTrajectoryAndSpeedProfile(const PlannerHNS::VehicleState&amp; vehicleState)
 {
	 PlannerHNS::PreCalculatedConditions *preCalcPrams = m_pCurrentBehaviorState-&gt;GetCalcParams();

	bool bNewTrajectory = false;

	if(m_TotalPath.size()&gt;0)
	{
		int currIndex = PlannerHNS::PlanningHelpers::GetClosestNextPointIndex(m_Path, state);
		int index_limit = 0;//m_Path.size() - 20;
		if(index_limit&lt;=0)
			index_limit =  m_Path.size()/2.0;
		if(m_RollOuts.size() == 0
				|| currIndex &gt; index_limit
				|| m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;bRePlan
				|| m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;bNewGlobalPath
				|| m_pCurrentBehaviorState-&gt;m_Behavior == OBSTACLE_AVOIDANCE_STATE)
		{
			PlannerHNS::PlannerH planner;
			planner.GenerateRunoffTrajectory(m_TotalPath, state,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;enableLaneChange,
					vehicleState.speed,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;microPlanDistance,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;maxSpeed,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;minSpeed,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;carTipMargin,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;rollInMargin,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;rollInSpeedFactor,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;pathDensity,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;rollOutDensity,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;rollOutNumber,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;smoothingDataWeight,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;smoothingSmoothWeight,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;smoothingToleranceError,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;speedProfileFactor,
					m_pCurrentBehaviorState-&gt;m_pParams-&gt;enableHeadingSmoothing,
					preCalcPrams-&gt;iCurrSafeLane , preCalcPrams-&gt;iCurrSafeTrajectory,
					m_RollOuts, m_PathSection, m_SampledPoints);

			m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;bRePlan = false;
			m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;bNewGlobalPath = false;

			//cout &lt;&lt; &quot;Generating New Trajectories ! iPrev: &quot; &lt;&lt; preCalcPrams-&gt;iPrevSafeTrajectory &lt;&lt; &quot; , iSafe: &quot; &lt;&lt; preCalcPrams-&gt;iCurrSafeTrajectory &lt;&lt; endl;

			if(m_pCurrentBehaviorState-&gt;m_Behavior == OBSTACLE_AVOIDANCE_STATE)
				preCalcPrams-&gt;iPrevSafeTrajectory = preCalcPrams-&gt;iCurrSafeTrajectory;
			else
				preCalcPrams-&gt;iPrevSafeTrajectory = preCalcPrams-&gt;iCentralTrajectory;

			preCalcPrams-&gt;iPrevSafeLane = preCalcPrams-&gt;iCurrSafeLane;

			if(preCalcPrams-&gt;iPrevSafeLane &gt;= 0
					&amp;&amp; preCalcPrams-&gt;iPrevSafeLane &lt; m_RollOuts.size()
					&amp;&amp; preCalcPrams-&gt;iPrevSafeTrajectory &gt;= 0
					&amp;&amp; preCalcPrams-&gt;iPrevSafeTrajectory &lt; m_RollOuts.at(preCalcPrams-&gt;iPrevSafeLane).size())
			{
				//cout &lt;&lt; &quot;Select New Trajectories ! iPrev: &quot; &lt;&lt; preCalcPrams-&gt;iPrevSafeTrajectory &lt;&lt; &quot; , iSafe: &quot; &lt;&lt; preCalcPrams-&gt;iCurrSafeTrajectory &lt;&lt; endl;

				m_Path = m_RollOuts.at(preCalcPrams-&gt;iPrevSafeLane).at(preCalcPrams-&gt;iPrevSafeTrajectory);
//				PlanningHelpers::GenerateRecommendedSpeed(m_Path,
//						m_pCurrentBehaviorState-&gt;m_pParams-&gt;maxSpeed,
//						m_pCurrentBehaviorState-&gt;m_pParams-&gt;speedProfileFactor);
				bNewTrajectory = true;
			}
		}
	}

	return bNewTrajectory;
 }

 PlannerHNS::BehaviorState LocalPlannerH::GenerateBehaviorState(const PlannerHNS::VehicleState&amp; vehicleState)
 {
	PlannerHNS::PreCalculatedConditions *preCalcPrams = m_pCurrentBehaviorState-&gt;GetCalcParams();

	m_pCurrentBehaviorState = m_pCurrentBehaviorState-&gt;GetNextState();
	PlannerHNS::BehaviorState currentBehavior;

	currentBehavior.state = m_pCurrentBehaviorState-&gt;m_Behavior;
	//if(currentBehavior.state == PlannerHNS::FOLLOW_STATE)
		currentBehavior.followDistance = preCalcPrams-&gt;distanceToNext;
	//else
	//	currentBehavior.followDistance = 0;

	if(preCalcPrams-&gt;bUpcomingRight)
		currentBehavior.indicator = PlannerHNS::INDICATOR_RIGHT;
	else if(preCalcPrams-&gt;bUpcomingLeft)
		currentBehavior.indicator = PlannerHNS::INDICATOR_LEFT;
	else
		currentBehavior.indicator = PlannerHNS::INDICATOR_NONE;
	currentBehavior.maxVelocity 	= PlannerHNS::PlanningHelpers::GetVelocityAhead(m_Path, state, vehicleState.speed*3.6);
	currentBehavior.minVelocity		= 0;
	currentBehavior.stopDistance 	= preCalcPrams-&gt;distanceToStop();
	currentBehavior.followVelocity 	= preCalcPrams-&gt;velocityOfNext;

	return currentBehavior;
 }

 void LocalPlannerH::UpdateVelocityDirectlyToTrajectory(const BehaviorState&amp; beh, const VehicleState&amp; CurrStatus, const double&amp; dt)
 {

	 RelativeInfo info;
	PlanningHelpers::GetRelativeInfo(m_Path, state, info);
	unsigned int point_index = 0;
	double critical_long_front_distance = 2.0;
	for(unsigned int i = 0; i &lt; m_Path.size(); i++)
		m_Path.at(i).v = m_CarInfo.min_speed_forward;

	if(beh.state == TRAFFIC_LIGHT_STOP_STATE || beh.state == STOP_SIGN_STOP_STATE)
	{
		PlanningHelpers::GetFollowPointOnTrajectory(m_Path, info, beh.stopDistance - critical_long_front_distance, point_index);

		double inc = CurrStatus.speed;
		int iRange = point_index - info.iBack;
		//cout &lt;&lt; &quot;Range : &quot; &lt;&lt; iRange;
		if(iRange &gt; 0)
			inc = inc / (double)iRange;
		else
			inc = 0;

	//	cout &lt;&lt; &quot;Target Stopping Velocity: &quot;  &lt;&lt;  endl ;
		double target_velocity = CurrStatus.speed - inc;
		for(unsigned int i =  info.iBack; i &lt; point_index; i++)
		{
			if(target_velocity &gt; m_CarInfo.max_speed_forward)
				target_velocity = m_CarInfo.max_speed_forward;

			if(target_velocity &lt; m_CarInfo.min_speed_forward)
				target_velocity = m_CarInfo.min_speed_forward;

			 if(i &lt; m_Path.size() &amp;&amp; i &gt;= 0)
			 {
			//	 cout &lt;&lt; target_velocity &lt;&lt; &quot;, &quot; ;
				 m_Path.at(i).v = target_velocity;
			 }

			 target_velocity -= inc;
		}

		//cout &lt;&lt; endl &lt;&lt; endl;
	}
	else if(beh.state == FOLLOW_STATE)
	{
		double targe_acceleration = -pow(CurrStatus.speed, 2)/(2.0*(beh.followDistance - critical_long_front_distance));
		if(targe_acceleration &lt;= 0 &amp;&amp;  targe_acceleration &gt; m_CarInfo.max_deceleration/2.0)
		{
			PlanningHelpers::GenerateRecommendedSpeed(m_Path, m_pCurrentBehaviorState-&gt;m_pParams-&gt;maxSpeed, m_pCurrentBehaviorState-&gt;m_pParams-&gt;speedProfileFactor);

			double follow_distance = fabs(CurrStatus.speed) * (m_ControlParams.SteeringDelay+1);
			if(follow_distance &lt; m_ControlParams.minPursuiteDistance)
				follow_distance = m_ControlParams.minPursuiteDistance;

			RelativeInfo info;
			PlanningHelpers::GetRelativeInfo(m_Path, state, info);
			unsigned int point_index = 0;
			WayPoint pursuite_point = PlanningHelpers::GetFollowPointOnTrajectory(m_Path, info, follow_distance, point_index);
			double target_velocity = pursuite_point.v;
			if(target_velocity &gt; m_CarInfo.max_speed_forward)
				target_velocity = m_CarInfo.max_speed_forward;


			for(unsigned int i = 0; i &lt; m_Path.size(); i++)
			{
				if(m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCurrSafeTrajectory == m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCentralTrajectory)
					m_Path.at(i).v = target_velocity;
				else
					m_Path.at(i).v = target_velocity*0.75;
			}
		}
		else
		{
			PlanningHelpers::GenerateRecommendedSpeed(m_Path, m_pCurrentBehaviorState-&gt;m_pParams-&gt;maxSpeed, m_pCurrentBehaviorState-&gt;m_pParams-&gt;speedProfileFactor);

			WayPoint pursuite_point = PlanningHelpers::GetFollowPointOnTrajectory(m_Path, info, beh.followDistance - critical_long_front_distance, point_index);

			double inc = CurrStatus.speed;
			int iRange = point_index - info.iBack;
			//cout &lt;&lt; &quot;Range : &quot; &lt;&lt; iRange;
			if(iRange &gt; 0)
				inc = inc / (double)iRange;
			else
				inc = 0;

			//cout &lt;&lt; &quot;Target Follow Velocity: &quot; &lt;&lt;  endl ;
			double target_velocity = CurrStatus.speed - inc;
			for(unsigned int i =  info.iBack; i &lt; point_index; i++)
			{
				if(target_velocity &gt; m_CarInfo.max_speed_forward)
					target_velocity = m_CarInfo.max_speed_forward;

				if(target_velocity &lt; m_CarInfo.min_speed_forward)
					target_velocity = m_CarInfo.min_speed_forward;

				 if(i &lt; m_Path.size() &amp;&amp; i &gt;= 0)
				 {
				//	 cout &lt;&lt; target_velocity &lt;&lt; &quot;, &quot; ;
					 if(m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCurrSafeTrajectory == m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCentralTrajectory)
						 m_Path.at(i).v = target_velocity;
					 else
						 m_Path.at(i).v = target_velocity*0.75;
				 }

				 target_velocity -= inc;
			}
		}
	}
	else if(beh.state == FORWARD_STATE || beh.state == OBSTACLE_AVOIDANCE_STATE )
	{
		PlanningHelpers::GenerateRecommendedSpeed(m_Path, m_pCurrentBehaviorState-&gt;m_pParams-&gt;maxSpeed, m_pCurrentBehaviorState-&gt;m_pParams-&gt;speedProfileFactor);

		double follow_distance = fabs(CurrStatus.speed) * (m_ControlParams.SteeringDelay+1);
		if(follow_distance &lt; m_ControlParams.minPursuiteDistance)
			follow_distance = m_ControlParams.minPursuiteDistance;

		RelativeInfo info;
		PlanningHelpers::GetRelativeInfo(m_Path, state, info);
		unsigned int point_index = 0;
		WayPoint pursuite_point = PlanningHelpers::GetFollowPointOnTrajectory(m_Path, info, follow_distance, point_index);
		double target_velocity = pursuite_point.v;
		if(target_velocity &gt; m_CarInfo.max_speed_forward)
			target_velocity = m_CarInfo.max_speed_forward;

		for(unsigned int i = 0; i &lt; m_Path.size(); i++)
		{
			if(m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCurrSafeTrajectory == m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCentralTrajectory)
				m_Path.at(i).v = target_velocity;
			else
				m_Path.at(i).v = target_velocity*0.75;

		}
	}
	else
	{
		double target_velocity = 0;
		for(unsigned int i = 0; i &lt; m_Path.size(); i++)
			m_Path.at(i).v = target_velocity;
	}
 }

 PlannerHNS::BehaviorState LocalPlannerH::DoOneStep(
		 const double&amp; dt,
		const PlannerHNS::VehicleState&amp; vehicleState,
		const std::vector&lt;PlannerHNS::DetectedObject&gt;&amp; obj_list,
		const int&amp; goalID, PlannerHNS::RoadNetwork&amp; map	,
		const bool&amp; bEmergencyStop,
		const bool&amp; bGreenTrafficLight,
		const bool&amp; bLive)
{

	 if(!bLive)
		 SimulateOdoPosition(dt, vehicleState);

	UpdateCurrentLane(map, 3.0);

	timespec costTimer;
	UtilityH::GetTickCount(costTimer);
	TrajectoryCost tc = m_TrajectoryCostsCalculatotor.DoOneStep(m_RollOuts, m_TotalPath, state,
			m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCurrSafeTrajectory, m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCurrSafeLane, *m_pCurrentBehaviorState-&gt;m_pParams,
			m_CarInfo,vehicleState, obj_list);
	m_CostCalculationTime = UtilityH::GetTimeDiffNow(costTimer);


	timespec behTimer;
	UtilityH::GetTickCount(behTimer);
	CalculateImportantParameterForDecisionMaking(vehicleState, goalID, bEmergencyStop, bGreenTrafficLight, tc);

	PlannerHNS::BehaviorState beh = GenerateBehaviorState(vehicleState);
	m_BehaviorGenTime = UtilityH::GetTimeDiffNow(behTimer);

	timespec t;
	UtilityH::GetTickCount(t);
	beh.bNewPlan = SelectSafeTrajectoryAndSpeedProfile(vehicleState);
	m_RollOutsGenerationTime = UtilityH::GetTimeDiffNow(t);

	if(m_pCurrentBehaviorState-&gt;m_pParams-&gt;enabTrajectoryVelocities)
	{
		UpdateVelocityDirectlyToTrajectory(beh, vehicleState, dt);
	}
	else if(beh.bNewPlan == true)
	{
		if(m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCurrSafeTrajectory == m_pCurrentBehaviorState-&gt;GetCalcParams()-&gt;iCentralTrajectory)
			PlanningHelpers::GenerateRecommendedSpeed(m_Path, m_pCurrentBehaviorState-&gt;m_pParams-&gt;maxSpeed, m_pCurrentBehaviorState-&gt;m_pParams-&gt;speedProfileFactor);
		else
			PlanningHelpers::GenerateRecommendedSpeed(m_Path, m_pCurrentBehaviorState-&gt;m_pParams-&gt;maxSpeed*0.25, m_pCurrentBehaviorState-&gt;m_pParams-&gt;speedProfileFactor);
	}

/**
 * Usage of predictive planning
 */
//	timespec predictionTime;
//	UtilityH::GetTickCount(predictionTime);
//	if(UtilityH::GetTimeDiffNow(m_PredictionTimer) &gt; 0.5 || beh.bNewPlan)
//	{
//		CalculateObstacleCosts(map, vehicleState, obj_list);
//		m_PredictionTime = UtilityH::GetTimeDiffNow(predictionTime);
//	}
//	bool bCollision = false;
//	int wp_id = -1;
//	for(unsigned int i=0; i &lt; m_Path.size(); i++)
//	{
//		if(m_Path.at(i).collisionCost &gt; 0)
//		{
//			bCollision = true;
//			wp_id = i;
//			beh.maxVelocity = m_Path.at(i).v;//PlannerHNS::PlanningHelpers::GetVelocityAhead(m_Path, state, 1.5*vehicleState.speed*3.6);
//			break;
//		}
//	}
//	std::cout &lt;&lt; &quot;------------------------------------------------&quot; &lt;&lt;  std::endl;
//	std::cout &lt;&lt; &quot;Max Velocity = &quot; &lt;&lt; beh.maxVelocity &lt;&lt; &quot;, New Plan : &quot; &lt;&lt; beh.bNewPlan &lt;&lt;  std::endl;
//	std::cout &lt;&lt; &quot;Collision = &quot; &lt;&lt; bCollision &lt;&lt; &quot;, @ WayPoint : &quot; &lt;&lt; wp_id &lt;&lt;  std::endl;
//	std::cout &lt;&lt; &quot;------------------------------------------------&quot; &lt;&lt;  std::endl;

	return beh;
 }

} /* namespace PlannerHNS */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/src/PlanningHelpers.cpp" new_path="ros/src/computing/planning/common/lib/openplanner/op_plannerh/src/PlanningHelpers.cpp">
				<diff>@@ -15,8 +15,6 @@
 using namespace UtilityHNS;
 using namespace std;
 
-
-
 namespace PlannerHNS {
 
 
</diff>
				<old_file>/*
 * PlanningHelpers.cpp
 *
 *  Created on: Jun 16, 2016
 *      Author: hatem
 */

#include &quot;PlanningHelpers.h&quot;
#include &quot;MatrixOperations.h&quot;
#include &lt;string&gt;
//#include &quot;spline.hpp&quot;



using namespace UtilityHNS;
using namespace std;



namespace PlannerHNS {



PlanningHelpers::PlanningHelpers()
{
}

PlanningHelpers::~PlanningHelpers()
{
}

bool PlanningHelpers::GetRelativeInfoRange(const std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; trajectories, const WayPoint&amp; p,const double&amp; searchDistance, RelativeInfo&amp; info)
{
	if(trajectories.size() == 0) return false;

	vector&lt;RelativeInfo&gt; infos;
	for(unsigned int i=0; i &lt; trajectories.size(); i++)
	{
		RelativeInfo info_item;
		GetRelativeInfo(trajectories.at(i), p, info_item);
		double angle_diff = UtilityH::AngleBetweenTwoAnglesPositive(info_item.perp_point.pos.a, p.pos.a)*RAD2DEG;
		if(angle_diff &lt; 75)
		{
			info_item.iGlobalPath = i;
			infos.push_back(info_item);
		}
	}

	if(infos.size() == 0)
		return false;
	else if(infos.size() == 1)
	{
		info = infos.at(0);
		return true;
	}

	double minCost = 9999999999;
	int min_index = 0;

	for(unsigned int i=0 ; i&lt; infos.size(); i++)
	{
		if(searchDistance &gt; 0)
		{
			double laneChangeCost = trajectories.at(infos.at(i).iGlobalPath).at(infos.at(i).iFront).laneChangeCost;
			if(fabs(infos.at(i).perp_distance) &lt; searchDistance &amp;&amp; laneChangeCost &lt; minCost)
			{
				min_index = i;
				minCost = laneChangeCost;
			}
		}
		else
		{
			if(fabs(infos.at(i).perp_distance) &lt; minCost)
			{
				min_index = i;
				minCost = infos.at(i).perp_distance;
			}
		}
	}

	info = infos.at(min_index);

	return true;
}

bool PlanningHelpers::GetRelativeInfo(const std::vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p, RelativeInfo&amp; info, const int&amp; prevIndex )
{
	if(trajectory.size() &lt; 2) return false;

	WayPoint p0, p1;
	if(trajectory.size()==2)
	{
		p0 = trajectory.at(0);
		p1 = WayPoint((trajectory.at(0).pos.x+trajectory.at(1).pos.x)/2.0,
					  (trajectory.at(0).pos.y+trajectory.at(1).pos.y)/2.0,
					  (trajectory.at(0).pos.z+trajectory.at(1).pos.z)/2.0, trajectory.at(0).pos.a);
		info.iFront = 1;
		info.iBack = 0;
	}
	else
	{
		info.iFront = GetClosestNextPointIndex(trajectory, p, prevIndex);

		if(info.iFront &gt; 0)
			info.iBack = info.iFront -1;
		else
			info.iBack = 0;

		if(info.iFront == 0)
		{
			p0 = trajectory.at(info.iFront);
			p1 = trajectory.at(info.iFront+1);
		}
		else if(info.iFront &gt; 0 &amp;&amp; info.iFront &lt; trajectory.size()-1)
		{
			p0 = trajectory.at(info.iFront-1);
			p1 = trajectory.at(info.iFront);
		}
		else
		{
			p0 = trajectory.at(info.iFront-1);
			p1 = WayPoint((p0.pos.x+trajectory.at(info.iFront).pos.x)/2.0, (p0.pos.y+trajectory.at(info.iFront).pos.y)/2.0, (p0.pos.z+trajectory.at(info.iFront).pos.z)/2.0, p0.pos.a);
		}
	}

	WayPoint prevWP = p0;
	Mat3 rotationMat(-p1.pos.a);
	Mat3 translationMat(-p.pos.x, -p.pos.y);
	Mat3 invRotationMat(p1.pos.a);
	Mat3 invTranslationMat(p.pos.x, p.pos.y);

	p0.pos = translationMat*p0.pos;
	p0.pos = rotationMat*p0.pos;

	p1.pos = translationMat*p1.pos;
	p1.pos = rotationMat*p1.pos;

	double m = (p1.pos.y-p0.pos.y)/(p1.pos.x-p0.pos.x);
	info.perp_distance = p1.pos.y - m*p1.pos.x; // solve for x = 0

	if(isnan(info.perp_distance) || isinf(info.perp_distance)) info.perp_distance = 0;

	info.to_front_distance = fabs(p1.pos.x); // distance on the x axes


	info.perp_point = p1;
	info.perp_point.pos.x = 0; // on the same y axis of the car
	info.perp_point.pos.y = info.perp_distance; //perp distance between the car and the trajectory

	info.perp_point.pos = invRotationMat  * info.perp_point.pos;
	info.perp_point.pos = invTranslationMat  * info.perp_point.pos;

	info.from_back_distance = hypot(info.perp_point.pos.y - prevWP.pos.y, info.perp_point.pos.x - prevWP.pos.x);

	info.angle_diff = UtilityH::AngleBetweenTwoAnglesPositive(p1.pos.a, p.pos.a)*RAD2DEG;

	return true;
}

WayPoint PlanningHelpers::GetFollowPointOnTrajectory(const std::vector&lt;WayPoint&gt;&amp; trajectory, const RelativeInfo&amp; init_p, const double&amp; distance, unsigned int&amp; point_index)
{
	WayPoint follow_point;

	if(trajectory.size()==0) return follow_point;

	//condition 1, if far behind the first point on the trajectory
	int local_i = init_p.iFront;

	if(init_p.iBack == 0 &amp;&amp; init_p.iBack == init_p.iFront &amp;&amp; init_p.from_back_distance &gt; distance)
	{
		follow_point = trajectory.at(init_p.iFront);
		follow_point.pos.x = init_p.perp_point.pos.x + distance * cos(follow_point.pos.a);
		follow_point.pos.y = init_p.perp_point.pos.y + distance * sin(follow_point.pos.a);
	}
	//condition 2, if far after the last point on the trajectory
	else if(init_p.iFront == trajectory.size() -1)
	{
		follow_point = trajectory.at(init_p.iFront);
		follow_point.pos.x = init_p.perp_point.pos.x + distance * cos(follow_point.pos.a);
		follow_point.pos.y = init_p.perp_point.pos.y + distance * sin(follow_point.pos.a);
	}
	else
	{
		double d = init_p.to_front_distance;
		while(local_i &lt; trajectory.size()-1 &amp;&amp; d &lt; distance)
		{
			local_i++;
			d += hypot(trajectory.at(local_i).pos.y - trajectory.at(local_i-1).pos.y, trajectory.at(local_i).pos.x - trajectory.at(local_i-1).pos.x);
		}

		double d_part = distance - d;

		follow_point = trajectory.at(local_i);
		follow_point.pos.x = follow_point.pos.x + d_part * cos(follow_point.pos.a);
		follow_point.pos.y = follow_point.pos.y + d_part * sin(follow_point.pos.a);
	}

	point_index = local_i;

	return follow_point;
}

double PlanningHelpers::GetExactDistanceOnTrajectory(const std::vector&lt;WayPoint&gt;&amp; trajectory, const RelativeInfo&amp; p1,const RelativeInfo&amp; p2)
{
	if(trajectory.size() == 0) return 0;

	if(p2.iFront == p1.iFront &amp;&amp; p2.iBack == p1.iBack)
	{
		return p2.to_front_distance - p1.to_front_distance;
	}
	else if(p2.iBack &gt;= p1.iFront)
	{
		double d_on_path = p1.to_front_distance + p2.from_back_distance;
		for(unsigned int i = p1.iFront; i &lt; p2.iBack; i++)
			d_on_path += hypot(trajectory.at(i+1).pos.y - trajectory.at(i).pos.y, trajectory.at(i+1).pos.x - trajectory.at(i).pos.x);

		return d_on_path;
	}
	else if(p2.iFront &lt;= p1.iBack)
	{
		double d_on_path = p1.from_back_distance + p2.to_front_distance;
		for(unsigned int i = p2.iFront; i &lt; p1.iBack; i++)
			d_on_path += hypot(trajectory.at(i+1).pos.y - trajectory.at(i).pos.y, trajectory.at(i+1).pos.x - trajectory.at(i).pos.x);

		return -d_on_path;
	}
	else
	{
		return 0;
	}
}

int PlanningHelpers::GetClosestNextPointIndex(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p,const int&amp; prevIndex )
{
	if(trajectory.size() == 0 || prevIndex &lt; 0) return 0;

	double d = 0, minD = 9999999999;
	int min_index  = prevIndex;

	for(unsigned int i=prevIndex; i&lt; trajectory.size(); i++)
	{
		d  = distance2pointsSqr(trajectory.at(i).pos, p.pos);
		if(d &lt; minD)
		{
			min_index = i;
			minD = d;
		}
	}

	if(min_index &lt; (int)trajectory.size()-2)
	{
		GPSPoint curr, next;
		curr = trajectory.at(min_index).pos;
		next = trajectory.at(min_index+1).pos;
		POINT2D v_1(p.pos.x - curr.x   ,p.pos.y - curr.y);
		double norm1 = pointNorm(v_1);
		POINT2D v_2(next.x - curr.x,next.y - curr.y);
		double norm2 = pointNorm(v_2);
		double dot_pro = v_1.x*v_2.x + v_1.y*v_2.y;
		double a = UtilityH::FixNegativeAngle(acos(dot_pro/(norm1*norm2)));
		if(a &lt;= M_PI_2)
			min_index = min_index+1;
	}

	return min_index;
}

int PlanningHelpers::GetClosestNextPointIndexDirection(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p,const int&amp; prevIndex )
{
	if(trajectory.size() == 0 || prevIndex &lt; 0) return 0;

	double d = 0, minD = 9999999999;
	int min_index  = prevIndex;

	for(unsigned int i=prevIndex; i&lt; trajectory.size(); i++)
	{
		d  = distance2pointsSqr(trajectory.at(i).pos, p.pos);
		double angle_diff = UtilityH::AngleBetweenTwoAnglesPositive(trajectory.at(i).pos.a, p.pos.a)*RAD2DEG;

		if(d &lt; minD &amp;&amp; angle_diff &lt; 45)
		{
			min_index = i;
			minD = d;
		}
	}

	if(min_index &lt; (int)trajectory.size()-2)
	{
		GPSPoint curr, next;
		curr = trajectory.at(min_index).pos;
		next = trajectory.at(min_index+1).pos;
		POINT2D v_1(p.pos.x - curr.x   ,p.pos.y - curr.y);
		double norm1 = pointNorm(v_1);
		POINT2D v_2(next.x - curr.x,next.y - curr.y);
		double norm2 = pointNorm(v_2);
		double dot_pro = v_1.x*v_2.x + v_1.y*v_2.y;
		double a = UtilityH::FixNegativeAngle(acos(dot_pro/(norm1*norm2)));
		if(a &lt;= M_PI_2)
			min_index = min_index+1;
	}

	return min_index;
}

int PlanningHelpers::GetClosestPointIndex_obsolete(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p,const int&amp; prevIndex )
{
	if(trajectory.size() == 0 || prevIndex &lt; 0) return 0;

	double d = 0, minD = 9999999999;
	int min_index  = prevIndex;

	for(unsigned int i=prevIndex; i&lt; trajectory.size(); i++)
	{
		d  = distance2pointsSqr(trajectory.at(i).pos, p.pos);
		if(d &lt; minD)
		{
			min_index = i;
			minD = d;
		}
	}

	return min_index;
}

WayPoint PlanningHelpers::GetPerpendicularOnTrajectory_obsolete(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p, double&amp; distance, const int&amp; prevIndex )
{
	if(trajectory.size() &lt; 2) return p;

	WayPoint p0, p1, p2, perp;
	if(trajectory.size()==2)
	{
		p0 = trajectory.at(0);
		p1 = WayPoint((trajectory.at(0).pos.x+trajectory.at(1).pos.x)/2.0,
					  (trajectory.at(0).pos.y+trajectory.at(1).pos.y)/2.0,
					  (trajectory.at(0).pos.z+trajectory.at(1).pos.z)/2.0, trajectory.at(0).pos.a);
		p2 = trajectory.at(1);
	}
	else
	{
		int next_index = GetClosestNextPointIndex(trajectory, p, prevIndex);

		if(next_index == 0)
		{
			p0 = trajectory[next_index];
			p1 = trajectory[next_index+1];
			p2 = trajectory[next_index+2];
		}
		else if(next_index &gt; 0 &amp;&amp; next_index &lt; trajectory.size()-1)
		{
			p0 = trajectory[next_index-1];
			p1 = trajectory[next_index];
			p2 = trajectory[next_index+1];
		}
		else
		{
			p0 = trajectory[next_index-1];
			p2 = trajectory[next_index];

			p1 = WayPoint((p0.pos.x+p2.pos.x)/2.0, (p0.pos.y+p2.pos.y)/2.0, (p0.pos.z+p2.pos.z)/2.0, p0.pos.a);

		}
	}

	Mat3 rotationMat(-p1.pos.a);
	Mat3 translationMat(-p.pos.x, -p.pos.y);
	Mat3 invRotationMat(p1.pos.a);
	Mat3 invTranslationMat(p.pos.x, p.pos.y);

	p0.pos = translationMat*p0.pos;
	p0.pos = rotationMat*p0.pos;

	p1.pos = translationMat*p1.pos;
	p1.pos = rotationMat*p1.pos;

	p2.pos = translationMat*p2.pos;
	p2.pos= rotationMat*p2.pos;

	double m = (p1.pos.y-p0.pos.y)/(p1.pos.x-p0.pos.x);
	double d = p1.pos.y - m*p1.pos.x; // solve for x = 0
	distance = p1.pos.x; // distance on the x axes

	perp = p1;
	perp.pos.x = 0; // on the same y axis of the car
	perp.pos.y = d; //perp distance between the car and the trajectory

	perp.pos = invRotationMat  * perp.pos;
	perp.pos = invTranslationMat  * perp.pos;

	return perp;
}

double PlanningHelpers::GetPerpDistanceToTrajectorySimple_obsolete(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p,const int&amp; prevIndex)
{

	if(trajectory.size() &lt; 2)
		return 0;

	WayPoint p0, p1, p2;
	int next_index = 0;
	if(trajectory.size()==2)
	{
		p0 = trajectory.at(0);
		p2 = trajectory.at(1);
		p1 = WayPoint((p0.pos.x+p2.pos.x)/2.0, (p0.pos.y+p2.pos.y)/2.0, (p0.pos.z+p2.pos.z)/2.0, p0.pos.a);

	}
	else
	{
		next_index = GetClosestNextPointIndex(trajectory, p, prevIndex);
		if(next_index == 0)
		{
			p0 = trajectory[next_index];
			p1 = trajectory[next_index+1];
			p2 = trajectory[next_index+2];
		}
		else if(next_index &gt; 0 &amp;&amp; next_index &lt; trajectory.size()-1)
		{
			p0 = trajectory[next_index-1];
			p1 = trajectory[next_index];
			p2 = trajectory[next_index+1];
		}
		else
		{
			p0 = trajectory[next_index-1];
			p2 = trajectory[next_index];

			p1 = WayPoint((p0.pos.x+p2.pos.x)/2.0, (p0.pos.y+p2.pos.y)/2.0, (p0.pos.z+p2.pos.z)/2.0, p0.pos.a);

		}

	}


	Mat3 rotationMat(-p1.pos.a);
	Mat3 translationMat(-p.pos.x, -p.pos.y);

	p0.pos = translationMat*p0.pos;
	p0.pos = rotationMat*p0.pos;

	p1.pos = translationMat*p1.pos;
	p1.pos = rotationMat*p1.pos;

	p2.pos = translationMat*p2.pos;
	p2.pos = rotationMat*p2.pos;

	double m = (p1.pos.y-p0.pos.y)/(p1.pos.x-p0.pos.x);
	double d = p1.pos.y - m*p1.pos.x;

	if(isnan(d) || isinf(d))
	{
	  //assert(false);
	  d = 0;
	}

	return d;
}

double PlanningHelpers::GetPerpDistanceToVectorSimple_obsolete(const WayPoint&amp; point1, const WayPoint&amp; point2, const WayPoint&amp; pose)
{
	WayPoint p1 = point1, p2 = point2;
	Mat3 rotationMat(-p1.pos.a);
	Mat3 translationMat(-pose.pos.x, -pose.pos.y);

	p1.pos = translationMat*p1.pos;
	p1.pos = rotationMat*p1.pos;

	p2.pos = translationMat*p2.pos;
	p2.pos = rotationMat*p2.pos;

	double m = (p2.pos.y-p1.pos.y)/(p2.pos.x-p1.pos.x);
	double d = p2.pos.y - m*p2.pos.x;

	if(isnan(d) || isinf(d))
	{
	  //assert(false);
	  d = 0;
	}

	return d;
}

WayPoint PlanningHelpers::GetNextPointOnTrajectory_obsolete(const vector&lt;WayPoint&gt;&amp; trajectory, const double&amp; distance, const int&amp; currIndex)
{
	assert(trajectory.size()&gt;0);

	int local_currIndex = currIndex;

	if(local_currIndex &lt; 0 || local_currIndex &gt;= trajectory.size())
		return trajectory.at(0);

	WayPoint p1 = trajectory.at(local_currIndex);
	WayPoint p2;

	double d = 0;
	while(local_currIndex &lt; (trajectory.size()-1) &amp;&amp; d &lt; distance)
	{
		local_currIndex++;
		p2 = p1;
		p1 = trajectory.at(local_currIndex);
		d += distance2points(p1.pos, p2.pos);
	}

	if(local_currIndex &gt;= trajectory.size()-1)
	  return p1;

	double distance_diff = distance -  d;

	p2 = trajectory.at(local_currIndex);
	p1 = trajectory.at(local_currIndex+1);

	POINT2D uv(p1.pos.x - p2.pos.x, p1.pos.y - p2.pos.y);
	double v_norm = pointNorm(uv);

	assert(v_norm != 0);

	uv.x = (uv.x / v_norm) * distance_diff;
	uv.y = (uv.y / v_norm) * distance_diff;

	double ydiff = p1.pos.y-p2.pos.y;
	double xdiff = p1.pos.x-p2.pos.x;
	double a =  atan2(ydiff,xdiff);

	WayPoint abs_waypoint = p2;

	abs_waypoint.pos.x = p2.pos.x + uv.x;
	abs_waypoint.pos.y = p2.pos.y + uv.y;
	abs_waypoint.pos.a = a;

	return abs_waypoint;
}

double PlanningHelpers::GetDistanceOnTrajectory_obsolete(const std::vector&lt;WayPoint&gt;&amp; path, const int&amp; start_index, const WayPoint&amp; p)
{

	int end_point_index = GetClosestPointIndex_obsolete(path, p);
	if(end_point_index &gt; 0)
		end_point_index--;

	double padding_distance = distance2points(path.at(end_point_index).pos, p.pos);

	double d_on_path = 0;
	if(end_point_index &gt;= start_index)
	{
		for(unsigned int i = start_index; i &lt; end_point_index; i++)
			d_on_path += distance2points(path.at(i).pos, path.at(i+1).pos);

		d_on_path += padding_distance;
	}
	else
	{
		for(unsigned int i = start_index; i &gt; end_point_index; i--)
			d_on_path -= distance2points(path.at(i).pos, path.at(i-1).pos);
	}

	return d_on_path;
}

bool PlanningHelpers::CompareTrajectories(const std::vector&lt;WayPoint&gt;&amp; path1, const std::vector&lt;WayPoint&gt;&amp; path2)
{
	if(path1.size() != path2.size())
		return false;

	for(unsigned int i=0; i&lt; path1.size(); i++)
	{
		if(path1.at(i).v != path2.at(i).v || path1.at(i).pos.x != path2.at(i).pos.x || path1.at(i).pos.y != path2.at(i).pos.y || path1.at(i).pos.alt != path2.at(i).pos.alt || path1.at(i).pos.lon != path2.at(i).pos.lon)
			return false;
	}

	return true;
}

double PlanningHelpers::GetDistanceToClosestStopLineAndCheck(const std::vector&lt;WayPoint&gt;&amp; path, const WayPoint&amp; p, int&amp; stopLineID, int&amp; stopSignID, int&amp; trafficLightID, const int&amp; prevIndex)
{

//	trafficLightID = stopSignID = stopLineID = -1;
//
//	RelativeInfo info;
//	GetRelativeInfo(path, p, info);
//
//	for(unsigned int i=info.iBack; i&lt;path.size(); i++)
//	{
//		if(path.at(i).pLane &amp;&amp; path.at(i).pLane-&gt;stopLines.size() &gt; 0)
//		{
//			stopSignID = path.at(i).pLane-&gt;stopLines.at(0).stopSignID;
//			trafficLightID = path.at(i).pLane-&gt;stopLines.at(0).trafficLightID;
//			return 1;
////			for(unsigned int j = 0; j &lt; path.at(i).pLane-&gt;stopLines.size(); j++)
////			{
////				RelativeInfo local_info;
////				WayPoint stopLineWP;
////				stopLineWP.pos = path.at(i).pLane-&gt;stopLines.at(j).points.at(0);
////
////				GetRelativeInfo(path, stopLineWP, local_info, i);
////
////				double d = GetExactDistanceOnTrajectory(path, info, local_info);
////				if(d &gt; 0)
////				{
////						stopSignID = path.at(i).pLane-&gt;stopLines.at(j).stopSignID;
////						trafficLightID = path.at(i).pLane-&gt;stopLines.at(j).trafficLightID;
////						return d;
////				}
////			}
//		}
//	}

	trafficLightID = stopSignID = stopLineID = -1;

	RelativeInfo info;
	GetRelativeInfo(path, p, info, prevIndex);

	for(unsigned int i=info.iBack; i&lt;path.size(); i++)
	{
		if(path.at(i).stopLineID &gt; 0 &amp;&amp; path.at(i).pLane)
		{
			for(unsigned int j = 0; j &lt; path.at(i).pLane-&gt;stopLines.size(); j++)
			{
				if(path.at(i).pLane-&gt;stopLines.at(j).id == path.at(i).stopLineID)
				{
					stopLineID = path.at(i).stopLineID;

					RelativeInfo stop_info;
					WayPoint stopLineWP ;
					stopLineWP.pos = path.at(i).pLane-&gt;stopLines.at(j).points.at(0);
					GetRelativeInfo(path, stopLineWP, stop_info);
					double localDistance = GetExactDistanceOnTrajectory(path, info, stop_info);

					if(localDistance&gt;0)
					{
						stopSignID = path.at(i).pLane-&gt;stopLines.at(j).stopSignID;
						trafficLightID = path.at(i).pLane-&gt;stopLines.at(j).trafficLightID;
						return localDistance;
					}
				}
			}
		}
	}

	return -1;
}

void PlanningHelpers::FixPathDensity(vector&lt;WayPoint&gt;&amp; path, const double&amp; distanceDensity)
{
	if(path.size() == 0 || distanceDensity==0) return;

	double d = 0, a = 0;
	double margin = distanceDensity*0.01;
	double remaining = 0;
	int nPoints = 0;
	vector&lt;WayPoint&gt; fixedPath;
	fixedPath.push_back(path.at(0));
	for(unsigned int si = 0, ei=1; ei &lt; path.size(); )
	{
		d += hypot(path.at(ei).pos.x- path.at(ei-1).pos.x, path.at(ei).pos.y- path.at(ei-1).pos.y) + remaining;
		a = atan2(path.at(ei).pos.y - path.at(si).pos.y, path.at(ei).pos.x - path.at(si).pos.x);

		if(d &lt; distanceDensity - margin ) // skip
		{
			ei++;
			remaining = 0;
		}
		else if(d &gt; (distanceDensity +  margin)) // skip
		{
			WayPoint pm = path.at(si);
			nPoints = d  / distanceDensity;
			for(int k = 0; k &lt; nPoints; k++)
			{
				pm.pos.x = pm.pos.x + distanceDensity * cos(a);
				pm.pos.y = pm.pos.y + distanceDensity * sin(a);
				fixedPath.push_back(pm);
			}
			remaining = d - nPoints*distanceDensity;
			si++;
			path.at(si).pos = pm.pos;
			d = 0;
			ei++;
		}
		else
		{
			d = 0;
			remaining = 0;
			fixedPath.push_back(path.at(ei));
			ei++;
			si = ei - 1;
		}
	}

	path = fixedPath;
}

void PlanningHelpers::SmoothPath(vector&lt;WayPoint&gt;&amp; path, double weight_data,
		double weight_smooth, double tolerance)
{

	if (path.size() &lt;= 2 )
	{
		cout &lt;&lt; &quot;Can't Smooth Path, Path_in Size=&quot; &lt;&lt; path.size() &lt;&lt; endl;
		return;
	}

	const vector&lt;WayPoint&gt;&amp; path_in = path;
	vector&lt;WayPoint&gt; smoothPath_out =  path_in;

	double change = tolerance;
	double xtemp, ytemp;
	int nIterations = 0;

	int size = path_in.size();

	while (change &gt;= tolerance)
	{
		change = 0.0;
		for (int i = 1; i &lt; size - 1; i++)
		{
//			if (smoothPath_out[i].pos.a != smoothPath_out[i - 1].pos.a)
//				continue;

			xtemp = smoothPath_out[i].pos.x;
			ytemp = smoothPath_out[i].pos.y;

			smoothPath_out[i].pos.x += weight_data
					* (path_in[i].pos.x - smoothPath_out[i].pos.x);
			smoothPath_out[i].pos.y += weight_data
					* (path_in[i].pos.y - smoothPath_out[i].pos.y);

			smoothPath_out[i].pos.x += weight_smooth
					* (smoothPath_out[i - 1].pos.x + smoothPath_out[i + 1].pos.x
							- (2.0 * smoothPath_out[i].pos.x));
			smoothPath_out[i].pos.y += weight_smooth
					* (smoothPath_out[i - 1].pos.y + smoothPath_out[i + 1].pos.y
							- (2.0 * smoothPath_out[i].pos.y));

			change += fabs(xtemp - smoothPath_out[i].pos.x);
			change += fabs(ytemp - smoothPath_out[i].pos.y);

		}
		nIterations++;
	}

	path = smoothPath_out;
}

//double PlanningHelpers::CalcAngleAndCostSimple(vector&lt;WayPoint&gt;&amp; path, const double&amp; lastCost)
//{
//	if(path.size() &lt;= 2) return 0;
//
//	path[0].pos.a = atan2(path[1].pos.y - path[0].pos.y, path[1].pos.x - path[0].pos.x );
//	path[0].cost = lastCost;
//
//	for(int j = 1; j &lt; path.size()-1; j++)
//	{
//		path[j].pos.a 	= atan2(path[j+1].pos.y - path[j].pos.y, path[j+1].pos.x - path[j].pos.x );
//		path[j].cost 	= path[j-1].cost +  hypot(path[j-1].pos.y- path[j].pos.y, path[j-1].pos.x- path[j].pos.x);
//	}
//
//	int j = (int)path.size()-1;
//
//	path[j].pos.a 	= path[j-1].pos.a;
//	path[j].cost 	= path[j-1].cost + hypot(path[j-1].pos.y- path[j].pos.y, path[j-1].pos.x- path[j].pos.x);
//
//	for(int j = 0; j &lt; path.size()-1; j++)
//	{
//		if(path.at(j).pos.x == path.at(j+1).pos.x &amp;&amp; path.at(j).pos.y == path.at(j+1).pos.y)
//			path.at(j).pos.a = path.at(j+1).pos.a;
//	}
//
//	return path[j].cost;
//}

double PlanningHelpers::CalcAngleAndCost(vector&lt;WayPoint&gt;&amp; path, const double&amp; lastCost, const bool&amp; bSmooth)
{
	if(path.size() &lt;= 2) return 0;

	path[0].pos.a = UtilityH::FixNegativeAngle(atan2(path[1].pos.y - path[0].pos.y, path[1].pos.x - path[0].pos.x ));
	path[0].cost = lastCost;

	for(int j = 1; j &lt; path.size()-1; j++)
	{
		path[j].pos.a 		= UtilityH::FixNegativeAngle(atan2(path[j+1].pos.y - path[j].pos.y, path[j+1].pos.x - path[j].pos.x ));
		path[j].cost 	= path[j-1].cost +  distance2points(path[j-1].pos, path[j].pos);
	}

	int j = (int)path.size()-1;

	path[j].pos.a 		= path[j-1].pos.a;
	path[j].cost 	= path[j-1].cost + distance2points(path[j-1].pos, path[j].pos);

	for(int j = 0; j &lt; path.size()-1; j++)
	{
		if(path.at(j).pos.x == path.at(j+1).pos.x &amp;&amp; path.at(j).pos.y == path.at(j+1).pos.y)
			path.at(j).pos.a = path.at(j+1).pos.a;
	}

	return path[j].cost;
}

double PlanningHelpers::CalcAngleAndCostAndCurvatureAnd2D(vector&lt;WayPoint&gt;&amp; path, const double&amp; lastCost)
{
	path[0].pos.a 	= atan2(path[1].pos.y - path[0].pos.y, path[1].pos.x - path[0].pos.x );
	path[0].cost 	= lastCost;

	double k = 0;
	GPSPoint center;

	for(unsigned int j = 1; j &lt; path.size()-1; j++)
	{
		k =  CalcCircle(path[j-1].pos,path[j].pos, path[j+1].pos, center);
		if(k &gt; 150.0 || isnan(k))
			k = 150.0;

		if(k&lt;1.0)
			path[j].cost = 0;
		else
			path[j].cost = 1.0-1.0/k;

		path[j].pos.a 	= atan2(path[j+1].pos.y - path[j].pos.y, path[j+1].pos.x - path[j].pos.x );
	}
	unsigned int j = path.size()-1;

	path[0].cost    = path[1].cost;
	path[j].cost 	= path[j-1].cost;
	path[j].pos.a 	= path[j-1].pos.a;
	path[j].cost 	= path[j-1].cost ;

	return path[j].cost;
}

double PlanningHelpers::CalcCircle(const GPSPoint&amp; pt1, const GPSPoint&amp; pt2, const GPSPoint&amp; pt3, GPSPoint&amp; center)
{
	double yDelta_a= pt2.y - pt1.y;
	double xDelta_a= pt2.x - pt1.x;
	double yDelta_b= pt3.y - pt2.y;
	double xDelta_b= pt3.x - pt2.x;

	if (fabs(xDelta_a) &lt;= 0.000000000001 &amp;&amp; fabs(yDelta_b) &lt;= 0.000000000001)
	{
		center.x= 0.5*(pt2.x + pt3.x);
		center.y= 0.5*(pt1.y + pt2.y);
		return distance2points(center,pt1);
	}

	double aSlope=yDelta_a/xDelta_a;
	double bSlope=yDelta_b/xDelta_b;
	if (fabs(aSlope-bSlope) &lt;= 0.000000000001)
	{
		return 100000;
	}

	center.x= (aSlope*bSlope*(pt1.y - pt3.y) + bSlope*(pt1.x + pt2 .x) - aSlope*(pt2.x+pt3.x) )/(2.0* (bSlope-aSlope) );
	center.y = -1.0*(center.x - (pt1.x+pt2.x)/2.0)/aSlope +  (pt1.y+pt2.y)/2.0;

	return  distance2points(center,pt1);
}

void PlanningHelpers::ExtractPartFromPointToDistance(const vector&lt;WayPoint&gt;&amp; originalPath, const WayPoint&amp; pos, const double&amp; minDistance,
		const double&amp; pathDensity, vector&lt;WayPoint&gt;&amp; extractedPath, const double&amp; SmoothDataWeight, const double&amp; SmoothWeight, const double&amp; SmoothTolerance)
{
	extractedPath.clear();
	unsigned int close_index = GetClosestNextPointIndexDirection(originalPath, pos);
	vector&lt;WayPoint&gt; tempPath;
	double d_limit = 0;
	if(close_index &gt;= 5) close_index -=5;
	else close_index = 0;

	for(unsigned int i=close_index; i&lt; originalPath.size(); i++)
	{
		tempPath.push_back(originalPath.at(i));

		if(i&gt;0)
			d_limit += hypot(originalPath.at(i).pos.y - originalPath.at(i-1).pos.y, originalPath.at(i).pos.x - originalPath.at(i-1).pos.x);

		if(d_limit &gt; minDistance)
			break;
	}

	if(tempPath.size() &lt; 2)
	{
		cout &lt;&lt; endl &lt;&lt; &quot;### Planner Z . Extracted Rollout Path is too Small, Size = &quot; &lt;&lt; tempPath.size() &lt;&lt; endl;
		return;
	}

	FixPathDensity(tempPath, pathDensity);
	SmoothPath(tempPath, SmoothDataWeight, SmoothWeight , SmoothTolerance);
	CalcAngleAndCost(tempPath);

	extractedPath = tempPath;
	//tempPath.clear();
	//TestQuadraticSpline(extractedPath, tempPath);
}

void PlanningHelpers::CalculateRollInTrajectories(const WayPoint&amp; carPos, const double&amp; speed, const vector&lt;WayPoint&gt;&amp; originalCenter, int&amp; start_index,
		int&amp; end_index, vector&lt;double&gt;&amp; end_laterals ,
		vector&lt;vector&lt;WayPoint&gt; &gt;&amp; rollInPaths, const double&amp; max_roll_distance,
		const double&amp; maxSpeed, const double&amp;  carTipMargin, const double&amp; rollInMargin,
		const double&amp; rollInSpeedFactor, const double&amp; pathDensity, const double&amp; rollOutDensity,
		const int&amp; rollOutNumber, const double&amp; SmoothDataWeight, const double&amp; SmoothWeight,
		const double&amp; SmoothTolerance, const bool&amp; bHeadingSmooth,
		std::vector&lt;WayPoint&gt;&amp; sampledPoints)
{
	WayPoint p;
	double dummyd = 0;

	int iLimitIndex = (carTipMargin/0.3)/pathDensity;
	if(iLimitIndex &gt;= originalCenter.size())
		iLimitIndex = originalCenter.size() - 1;

	//Get Closest Index
	RelativeInfo info;
	GetRelativeInfo(originalCenter, carPos, info);
	double remaining_distance = 0;
	int close_index = info.iBack;
	for(unsigned int i=close_index; i&lt; originalCenter.size()-1; i++)
	  {
		if(i&gt;0)
			remaining_distance += distance2points(originalCenter[i].pos, originalCenter[i+1].pos);
	  }

	double initial_roll_in_distance = info.perp_distance ; //GetPerpDistanceToTrajectorySimple(originalCenter, carPos, close_index);


	vector&lt;WayPoint&gt; RollOutStratPath;
	///***   Smoothing From Car Heading Section ***///
//	if(bHeadingSmooth)
//	{
//		unsigned int num_of_strait_points = carTipMargin / pathDensity;
//		int closest_for_each_iteration = 0;
//		WayPoint np = GetPerpendicularOnTrajectory(originalCenter, rearPos, dummyd, closest_for_each_iteration);
//		np.pos = rearPos.pos;
//
//		RollOutStratPath.push_back(np);
//		for(unsigned int i = 0; i &lt; num_of_strait_points; i++)
//		{
//			p = RollOutStratPath.at(i);
//			p.pos.x = p.pos.x +  pathDensity*cos(p.pos.a);
//			p.pos.y = p.pos.y +  pathDensity*sin(p.pos.a);
//			np = GetPerpendicularOnTrajectory(originalCenter, p, dummyd, closest_for_each_iteration);
//			np.pos = p.pos;
//			RollOutStratPath.push_back(np);
//		}
//
//		initial_roll_in_distance = GetPerpDistanceToTrajectorySimple(originalCenter, RollOutStratPath.at(RollOutStratPath.size()-1), close_index);
//	}
	///***   -------------------------------- ***///


	//printf(&quot;\n Lateral Distance: %f&quot; , initial_roll_in_distance);

	//calculate the starting index
	double d_limit = 0;
	unsigned int far_index = close_index;

	//calculate end index
	double start_distance = rollInSpeedFactor*speed+rollInMargin;
	if(start_distance &gt; remaining_distance)
		start_distance = remaining_distance;

	d_limit = 0;
	for(unsigned int i=close_index; i&lt; originalCenter.size(); i++)
	  {
		  if(i&gt;0)
			  d_limit += distance2points(originalCenter[i].pos, originalCenter[i-1].pos);

		  if(d_limit &gt;= start_distance)
		  {
			  far_index = i;
			  break;
		  }
	  }

	int centralTrajectoryIndex = rollOutNumber/2;
	vector&lt;double&gt; end_distance_list;
	for(int i=0; i&lt; rollOutNumber+1; i++)
	  {
		  double end_roll_in_distance = rollOutDensity*(i - centralTrajectoryIndex);
		  end_distance_list.push_back(end_roll_in_distance);
	  }

	start_index = close_index;
	end_index = far_index;
	end_laterals = end_distance_list;

	//calculate the actual calculation starting index
	d_limit = 0;
	unsigned int smoothing_start_index = start_index;
	unsigned int smoothing_end_index = end_index;

	for(unsigned int i=smoothing_start_index; i&lt; originalCenter.size(); i++)
	{
		if(i &gt; 0)
			d_limit += distance2points(originalCenter[i].pos, originalCenter[i-1].pos);
		if(d_limit &gt; carTipMargin)
			break;

		smoothing_start_index++;
	}

	d_limit = 0;
	for(unsigned int i=end_index; i&lt; originalCenter.size(); i++)
	{
		if(i &gt; 0)
			d_limit += distance2points(originalCenter[i].pos, originalCenter[i-1].pos);
		if(d_limit &gt; carTipMargin)
			break;

		smoothing_end_index++;
	}

	int nSteps = end_index - smoothing_start_index;


	vector&lt;double&gt; inc_list;
	rollInPaths.clear();
	vector&lt;double&gt; inc_list_inc;
	for(int i=0; i&lt; rollOutNumber+1; i++)
	{
		double diff = end_laterals.at(i)-initial_roll_in_distance;
		inc_list.push_back(diff/(double)nSteps);
		rollInPaths.push_back(vector&lt;WayPoint&gt;());
		inc_list_inc.push_back(0);
	}



	vector&lt;vector&lt;WayPoint&gt; &gt; execluded_from_smoothing;
	for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
		execluded_from_smoothing.push_back(vector&lt;WayPoint&gt;());



	//Insert First strait points within the tip of the car range
	for(unsigned int j = start_index; j &lt; smoothing_start_index; j++)
	{
		p = originalCenter.at(j);
		double original_speed = p.v;
	  for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
	  {
		  p.pos.x = originalCenter.at(j).pos.x -  initial_roll_in_distance*cos(p.pos.a + M_PI_2);
		  p.pos.y = originalCenter.at(j).pos.y -  initial_roll_in_distance*sin(p.pos.a + M_PI_2);
		  if(i!=centralTrajectoryIndex)
			  p.v = original_speed * LANE_CHANGE_SPEED_FACTOR;
		  else
			  p.v = original_speed ;

		  if(j &lt; iLimitIndex)
			  execluded_from_smoothing.at(i).push_back(p);
		  else
			  rollInPaths.at(i).push_back(p);

		  sampledPoints.push_back(p);
	  }
	}

	for(unsigned int j = smoothing_start_index; j &lt; end_index; j++)
	  {
		  p = originalCenter.at(j);
		  double original_speed = p.v;
		  for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
		  {
			  inc_list_inc[i] += inc_list[i];
			  double d = inc_list_inc[i];
			  p.pos.x = originalCenter.at(j).pos.x -  initial_roll_in_distance*cos(p.pos.a + M_PI_2) - d*cos(p.pos.a+ M_PI_2);
			  p.pos.y = originalCenter.at(j).pos.y -  initial_roll_in_distance*sin(p.pos.a + M_PI_2) - d*sin(p.pos.a+ M_PI_2);
			  if(i!=centralTrajectoryIndex)
				  p.v = original_speed * LANE_CHANGE_SPEED_FACTOR;
			  else
				  p.v = original_speed ;

			  rollInPaths.at(i).push_back(p);

			  sampledPoints.push_back(p);
		  }
	  }

	//Insert last strait points to make better smoothing
	for(unsigned int j = end_index; j &lt; smoothing_end_index; j++)
	{
		p = originalCenter.at(j);
		double original_speed = p.v;
	  for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
	  {
		  double d = end_laterals.at(i);
		  p.pos.x  = originalCenter.at(j).pos.x - d*cos(p.pos.a + M_PI_2);
		  p.pos.y  = originalCenter.at(j).pos.y - d*sin(p.pos.a + M_PI_2);
		  if(i!=centralTrajectoryIndex)
			  p.v = original_speed * LANE_CHANGE_SPEED_FACTOR;
		  else
			  p.v = original_speed ;
		  rollInPaths.at(i).push_back(p);

		  sampledPoints.push_back(p);
	  }
	}

	for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
		rollInPaths.at(i).insert(rollInPaths.at(i).begin(), execluded_from_smoothing.at(i).begin(), execluded_from_smoothing.at(i).end());

	///***   Smoothing From Car Heading Section ***///
//	if(bHeadingSmooth)
//	{
//		for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
//		{
//			unsigned int cut_index = GetClosestNextPointIndex(rollInPaths.at(i), RollOutStratPath.at(RollOutStratPath.size()-1));
//			rollInPaths.at(i).erase(rollInPaths.at(i).begin(), rollInPaths.at(i).begin()+cut_index);
//			rollInPaths.at(i).insert(rollInPaths.at(i).begin(), RollOutStratPath.begin(), RollOutStratPath.end());
//		}
//	}
	///***   -------------------------------- ***///

	for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
	{
		SmoothPath(rollInPaths.at(i), SmoothDataWeight, SmoothWeight, SmoothTolerance);
	}

	d_limit = 0;
	for(unsigned int j = smoothing_end_index; j &lt; originalCenter.size(); j++)
	  {
		if(j &gt; 0)
			d_limit += distance2points(originalCenter.at(j).pos, originalCenter.at(j-1).pos);

		if(d_limit &gt; max_roll_distance)
			break;

			p = originalCenter.at(j);
			double original_speed = p.v;
		  for(unsigned int i=0; i&lt; rollInPaths.size() ; i++)
		  {
			  double d = end_laterals.at(i);
			  p.pos.x  = originalCenter.at(j).pos.x - d*cos(p.pos.a + M_PI_2);
			  p.pos.y  = originalCenter.at(j).pos.y - d*sin(p.pos.a + M_PI_2);

			  if(i!=centralTrajectoryIndex)
				  p.v = original_speed * LANE_CHANGE_SPEED_FACTOR;
			  else
				  p.v = original_speed ;

			  rollInPaths.at(i).push_back(p);

			  sampledPoints.push_back(p);
		  }
	  }

//	for(unsigned int i=0; i&lt; rollInPaths.size(); i++)
//		CalcAngleAndCost(rollInPaths.at(i));
}

bool PlanningHelpers::FindInList(const std::vector&lt;int&gt;&amp; list,const int&amp; x)
{
	for(unsigned int i = 0 ; i &lt; list.size(); i++)
	{
		if(list.at(i) == x)
			return true;
	}
	return false;
}

void PlanningHelpers::RemoveWithValue(std::vector&lt;int&gt;&amp; list,const int&amp; x)
{
	for(unsigned int i = 0 ; i &lt; list.size(); i++)
	{
		if(list.at(i) == x)
		{
			list.erase(list.begin()+i);
		}
	}
}

std::vector&lt;int&gt; PlanningHelpers::GetUniqueLeftRightIds(const std::vector&lt;WayPoint&gt;&amp; path)
{
	 vector&lt;int&gt; sideLanes;
	for(unsigned int iwp = 0; iwp &lt; path.size(); iwp++)
	 {
		 if(path.at(iwp).LeftLaneId&gt;0)
		 {
			 bool bFound = false;
			 for(unsigned int is = 0 ; is &lt; sideLanes.size(); is++)
			 {
				 if(sideLanes.at(is) == path.at(iwp).LeftLaneId)
				 {
					 bFound = true;
					 break;
				 }
			 }

			 if(!bFound)
				 sideLanes.push_back(path.at(iwp).LeftLaneId);
		 }

		 if(path.at(iwp).RightLaneId&gt;0)
		 {
			 bool bFound = false;
			 for(unsigned int is = 0 ; is &lt; sideLanes.size(); is++)
			 {
				 if(sideLanes.at(is) == path.at(iwp).RightLaneId)
				 {
					 bFound = true;
					 break;
				 }
			 }

			 if(!bFound)
				 sideLanes.push_back(path.at(iwp).RightLaneId);
		 }

		 //RemoveWithValue(sideLanes, path.at(iwp).laneId);
	 }
	return sideLanes;
}

void PlanningHelpers::SmoothSpeedProfiles(vector&lt;WayPoint&gt;&amp; path_in, double weight_data, double weight_smooth, double tolerance	)
{

	if (path_in.size() &lt;= 1)
		return;
	vector&lt;WayPoint&gt; newpath = path_in;

	double change = tolerance;
	double xtemp;
	int nIterations = 0;
	int size = newpath.size();

	while (change &gt;= tolerance)
	{
		change = 0.0;
		for (int i = 1; i &lt; size -1; i++)
		{
			xtemp = newpath[i].v;
			newpath[i].v += weight_data * (path_in[i].v - newpath[i].v);
			newpath[i].v += weight_smooth * (newpath[i - 1].v + newpath[i + 1].v - (2.0 * newpath[i].v));
			change += fabs(xtemp - newpath[i].v);

		}
		nIterations++;
	}

	path_in = newpath;
}

void PlanningHelpers::SmoothCurvatureProfiles(vector&lt;WayPoint&gt;&amp; path_in, double weight_data, double weight_smooth, double tolerance)
{
	if (path_in.size() &lt;= 1)
			return;
	vector&lt;WayPoint&gt; newpath = path_in;

	double change = tolerance;
	double xtemp;
	int nIterations = 0;
	int size = newpath.size();

	while (change &gt;= tolerance)
	{
		change = 0.0;
		for (int i = 1; i &lt; size -1; i++)
		{
			xtemp = newpath[i].cost;
			newpath[i].cost += weight_data * (path_in[i].cost - newpath[i].cost);
			newpath[i].cost += weight_smooth * (newpath[i - 1].cost + newpath[i + 1].cost - (2.0 * newpath[i].cost));
			change += fabs(xtemp - newpath[i].cost);

		}
		nIterations++;
	}
	path_in = newpath;
}

void PlanningHelpers::SmoothWayPointsDirections(vector&lt;WayPoint&gt;&amp; path_in, double weight_data, double weight_smooth, double tolerance	)
{

	if (path_in.size() &lt;= 1)
		return;

	vector&lt;WayPoint&gt; newpath = path_in;

	double change = tolerance;
	double xtemp;
	int nIterations = 0;
	int size = newpath.size();

	while (change &gt;= tolerance)
	{
		change = 0.0;
		for (int i = 1; i &lt; size -1; i++)
		{
			xtemp = newpath[i].pos.a;
			newpath[i].pos.a += weight_data * (path_in[i].pos.a - newpath[i].pos.a);
			newpath[i].pos.a += weight_smooth * (newpath[i - 1].pos.a + newpath[i + 1].pos.a - (2.0 * newpath[i].pos.a));
			change += fabs(xtemp - newpath[i].pos.a);

		}
		nIterations++;
	}
	path_in = newpath;
}

void PlanningHelpers::GenerateRecommendedSpeed(vector&lt;WayPoint&gt;&amp; path, const double&amp; max_speed, const double&amp; speedProfileFactor)
{
	FixPathDensity(path, 0.5);

	CalcAngleAndCostAndCurvatureAnd2D(path);

	SmoothCurvatureProfiles(path, 0.3, 0.49, 0.01);

	for(unsigned int i = 0 ; i &lt; path.size(); i++)
	{
		double k_ratio = path.at(i).cost*10.0;

		if(k_ratio &gt;= 9.5)
			path.at(i).v = max_speed;
		else if(k_ratio &lt;= 8.5)
			path.at(i).v = 1.0*speedProfileFactor;
		else
		{
			k_ratio = k_ratio - 8.5;
			path.at(i).v = (max_speed - 1.0) * k_ratio + 1.0;
			path.at(i).v = path.at(i).v*speedProfileFactor;
		}

		if(path.at(i).v &gt; max_speed)
			path.at(i).v = max_speed;

	}

	//SmoothSpeedProfiles(path, 0.15,0.45, 0.1);
}

WayPoint* PlanningHelpers::BuildPlanningSearchTreeV2(WayPoint* pStart,
		const WayPoint&amp; goalPos,
		const vector&lt;int&gt;&amp; globalPath,
		const double&amp; DistanceLimit,
		const bool&amp; bEnableLaneChange,
		vector&lt;WayPoint*&gt;&amp; all_cells_to_delete)
{
	if(!pStart) return NULL;

	vector&lt;pair&lt;WayPoint*, WayPoint*&gt; &gt;nextLeafToTrace;

	WayPoint* pZero = 0;
	WayPoint* wp    = new WayPoint();
	*wp = *pStart;
	nextLeafToTrace.push_back(make_pair(pZero, wp));
	all_cells_to_delete.push_back(wp);

	double 		distance 		= 0;
	WayPoint* 	pGoalCell 		= 0;
	double 		nCounter 		= 0;


	while(nextLeafToTrace.size()&gt;0)
	{
		nCounter++;

		unsigned int min_cost_index = 0;
		double min_cost = 99999999999;

		for(unsigned int i=0; i &lt; nextLeafToTrace.size(); i++)
		{
			if(nextLeafToTrace.at(i).second-&gt;cost &lt; min_cost)
			{
				min_cost = nextLeafToTrace.at(i).second-&gt;cost;
				min_cost_index = i;
			}
		}

		WayPoint* pH 	= nextLeafToTrace.at(min_cost_index).second;

		assert(pH != 0);

		nextLeafToTrace.erase(nextLeafToTrace.begin()+min_cost_index);

		double distance_to_goal = distance2points(pH-&gt;pos, goalPos.pos);
		double angle_to_goal = UtilityH::AngleBetweenTwoAnglesPositive(UtilityH::FixNegativeAngle(pH-&gt;pos.a), UtilityH::FixNegativeAngle(goalPos.pos.a));
		if( distance_to_goal &lt;= 0.1 &amp;&amp; angle_to_goal &lt; M_PI_4)
		{
			cout &lt;&lt; &quot;Goal Found, LaneID: &quot; &lt;&lt; pH-&gt;laneId &lt;&lt;&quot;, Distance : &quot; &lt;&lt; distance_to_goal &lt;&lt; &quot;, Angle: &quot; &lt;&lt; angle_to_goal*RAD2DEG &lt;&lt; endl;
			pGoalCell = pH;
			break;
		}
		else
		{

			if(pH-&gt;pLeft &amp;&amp; !CheckLaneExits(all_cells_to_delete, pH-&gt;pLeft-&gt;pLane) &amp;&amp; bEnableLaneChange)
			{
				wp = new WayPoint();
				*wp = *pH-&gt;pLeft;
				double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
				distance += d;

				for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
				{
					//if(wp-&gt;actionCost.at(a).first == LEFT_TURN_ACTION)
						d += wp-&gt;actionCost.at(a).second;
				}

				wp-&gt;cost = pH-&gt;cost + d;
				wp-&gt;pRight = pH;
				wp-&gt;pRight = 0;

				nextLeafToTrace.push_back(make_pair(pH, wp));
				all_cells_to_delete.push_back(wp);
			}

			if(pH-&gt;pRight &amp;&amp; !CheckLaneExits(all_cells_to_delete, pH-&gt;pRight-&gt;pLane) &amp;&amp; bEnableLaneChange)
			{
				wp = new WayPoint();
				*wp = *pH-&gt;pRight;
				double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
				distance += d;

				for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
				{
					//if(wp-&gt;actionCost.at(a).first == RIGHT_TURN_ACTION)
						d += wp-&gt;actionCost.at(a).second;
				}

				wp-&gt;cost = pH-&gt;cost + d ;
				wp-&gt;pLeft = pH;
				wp-&gt;pRight = 0;
				nextLeafToTrace.push_back(make_pair(pH, wp));
				all_cells_to_delete.push_back(wp);
			}

			for(unsigned int i =0; i&lt; pH-&gt;pFronts.size(); i++)
			{
				if(CheckLaneIdExits(globalPath, pH-&gt;pLane) &amp;&amp; pH-&gt;pFronts.at(i) &amp;&amp; !CheckNodeExits(all_cells_to_delete, pH-&gt;pFronts.at(i)))
				{
					wp = new WayPoint();
					*wp = *pH-&gt;pFronts.at(i);

					double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
					distance += d;

					for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
					{
						//if(wp-&gt;actionCost.at(a).first == FORWARD_ACTION)
							d += wp-&gt;actionCost.at(a).second;
					}

					wp-&gt;cost = pH-&gt;cost + d;
					wp-&gt;pBacks.push_back(pH);

					nextLeafToTrace.push_back(make_pair(pH, wp));
					all_cells_to_delete.push_back(wp);
				}
			}
		}

		if(distance &gt; DistanceLimit &amp;&amp; globalPath.size()==0)
		{
			//if(!pGoalCell)
			cout &lt;&lt; &quot;Goal Not Found, LaneID: &quot; &lt;&lt; pH-&gt;laneId &lt;&lt;&quot;, Distance : &quot; &lt;&lt; distance &lt;&lt; endl;
			pGoalCell = pH;
			break;
		}

		//pGoalCell = pH;
	}

	while(nextLeafToTrace.size()!=0)
		nextLeafToTrace.pop_back();
	//closed_nodes.clear();

	return pGoalCell;
}

WayPoint* PlanningHelpers::BuildPlanningSearchTreeStraight(WayPoint* pStart,
		const double&amp; DistanceLimit,
		vector&lt;WayPoint*&gt;&amp; all_cells_to_delete)
{
	if(!pStart) return NULL;

	vector&lt;pair&lt;WayPoint*, WayPoint*&gt; &gt;nextLeafToTrace;

	WayPoint* pZero = 0;
	WayPoint* wp    = new WayPoint();
	*wp = *pStart;
	nextLeafToTrace.push_back(make_pair(pZero, wp));
	all_cells_to_delete.push_back(wp);

	double 		distance 		= 0;
	WayPoint* 	pGoalCell 		= 0;
	double 		nCounter 		= 0;

	while(nextLeafToTrace.size()&gt;0)
	{
		nCounter++;

		unsigned int min_cost_index = 0;
		double min_cost = 99999999999;

		for(unsigned int i=0; i &lt; nextLeafToTrace.size(); i++)
		{
			if(nextLeafToTrace.at(i).second-&gt;cost &lt; min_cost)
			{
				min_cost = nextLeafToTrace.at(i).second-&gt;cost;
				min_cost_index = i;
			}
		}

		WayPoint* pH 	= nextLeafToTrace.at(min_cost_index).second;
		assert(pH != 0);

		nextLeafToTrace.erase(nextLeafToTrace.begin()+min_cost_index);

		for(unsigned int i =0; i&lt; pH-&gt;pFronts.size(); i++)
		{
			if(pH-&gt;pFronts.at(i) &amp;&amp; !CheckNodeExits(all_cells_to_delete, pH-&gt;pFronts.at(i)))
			{
				wp = new WayPoint();
				*wp = *pH-&gt;pFronts.at(i);

				double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
				distance += d;

				for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
				{
					//if(wp-&gt;actionCost.at(a).first == FORWARD_ACTION)
						d += wp-&gt;actionCost.at(a).second;
				}

				wp-&gt;cost = pH-&gt;cost + d;
				wp-&gt;pBacks.push_back(pH);
				if(wp-&gt;cost &lt; DistanceLimit)
				{
					nextLeafToTrace.push_back(make_pair(pH, wp));
					all_cells_to_delete.push_back(wp);
				}
				else
					delete wp;
			}
		}

//		if(pH-&gt;pLeft &amp;&amp; !CheckLaneExits(all_cells_to_delete, pH-&gt;pLeft-&gt;pLane))
//		{
//			wp = new WayPoint();
//			*wp = *pH-&gt;pLeft;
//			double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
//
//			for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
//			{
//				//if(wp-&gt;actionCost.at(a).first == LEFT_TURN_ACTION)
//					d += wp-&gt;actionCost.at(a).second;
//			}
//
//			wp-&gt;cost = pH-&gt;cost + d + LANE_CHANGE_COST;
//			wp-&gt;pRight = pH;
//			wp-&gt;pRight = 0;
//
//			nextLeafToTrace.push_back(make_pair(pH, wp));
//			all_cells_to_delete.push_back(wp);
//		}
//
//		if(pH-&gt;pRight &amp;&amp; !CheckLaneExits(all_cells_to_delete, pH-&gt;pRight-&gt;pLane))
//		{
//			wp = new WayPoint();
//			*wp = *pH-&gt;pRight;
//			double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);;
//
//			for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
//			{
//				//if(wp-&gt;actionCost.at(a).first == RIGHT_TURN_ACTION)
//					d += wp-&gt;actionCost.at(a).second;
//			}
//
//			wp-&gt;cost = pH-&gt;cost + d + LANE_CHANGE_COST;
//			wp-&gt;pLeft = pH;
//			wp-&gt;pRight = 0;
//			nextLeafToTrace.push_back(make_pair(pH, wp));
//			all_cells_to_delete.push_back(wp);
//		}

		pGoalCell = pH;
	}

	while(nextLeafToTrace.size()!=0)
		nextLeafToTrace.pop_back();

	return pGoalCell;
}

int PlanningHelpers::PredictiveDP(WayPoint* pStart, const double&amp; DistanceLimit,
		vector&lt;WayPoint*&gt;&amp; all_cells_to_delete,vector&lt;WayPoint*&gt;&amp; end_waypoints)
{
	if(!pStart) return 0;

	vector&lt;pair&lt;WayPoint*, WayPoint*&gt; &gt;nextLeafToTrace;

	WayPoint* pZero = 0;
	WayPoint* wp    = new WayPoint();
	*wp = *pStart;
	wp-&gt;pLeft = 0;
	wp-&gt;pRight = 0;
	nextLeafToTrace.push_back(make_pair(pZero, wp));
	all_cells_to_delete.push_back(wp);

	double 		distance 		= 0;
	end_waypoints.clear();
	double 		nCounter 		= 0;

	while(nextLeafToTrace.size()&gt;0)
	{
		nCounter++;

		WayPoint* pH 	= nextLeafToTrace.at(0).second;

		assert(pH != 0);

		nextLeafToTrace.erase(nextLeafToTrace.begin()+0);

		for(unsigned int i =0; i&lt; pH-&gt;pFronts.size(); i++)
		{
			if(pH-&gt;pFronts.at(i) &amp;&amp; !CheckNodeExits(all_cells_to_delete, pH-&gt;pFronts.at(i)))
			{
				if(pH-&gt;cost &lt; DistanceLimit)
				{
					wp = new WayPoint();
					*wp = *pH-&gt;pFronts.at(i);

					double d = distance2points(wp-&gt;pos, pH-&gt;pos);
					distance += d;
					wp-&gt;cost = pH-&gt;cost + d;
					wp-&gt;pBacks.push_back(pH);
					wp-&gt;pLeft = 0;
					wp-&gt;pRight = 0;

					nextLeafToTrace.push_back(make_pair(pH, wp));
					all_cells_to_delete.push_back(wp);
				}
				else
				{
					end_waypoints.push_back(pH);
				}
			}
		}
	}

	while(nextLeafToTrace.size()!=0)
		nextLeafToTrace.pop_back();
	//closed_nodes.clear();

	return end_waypoints.size();
}

bool PlanningHelpers::CheckLaneIdExits(const std::vector&lt;int&gt;&amp; lanes, const Lane* pL)
{
	if(lanes.size()==0) return true;

	for(unsigned int i=0; i&lt; lanes.size(); i++)
	{
		if(lanes.at(i) == pL-&gt;id)
			return true;
	}

	return false;
}

WayPoint* PlanningHelpers::CheckLaneExits(const vector&lt;WayPoint*&gt;&amp; nodes, const Lane* pL)
{
	if(nodes.size()==0) return 0;

	for(unsigned int i=0; i&lt; nodes.size(); i++)
	{
		if(nodes.at(i)-&gt;pLane == pL)
			return nodes.at(i);
	}

	return 0;
}

WayPoint* PlanningHelpers::CheckNodeExits(const vector&lt;WayPoint*&gt;&amp; nodes, const WayPoint* pL)
{
	if(nodes.size()==0) return 0;

	for(unsigned int i=0; i&lt; nodes.size(); i++)
	{
		if(nodes.at(i)-&gt;id == pL-&gt;id)
			return nodes.at(i);
	}

	return 0;
}

WayPoint* PlanningHelpers::CreateLaneHeadCell(Lane* pLane, WayPoint* pLeft, WayPoint* pRight,
		WayPoint* pBack)
{
	if(!pLane) return 0;
	if(pLane-&gt;points.size()==0) return 0;

	WayPoint* c = new WayPoint;
	c-&gt;pLane 		= pLane;
	c-&gt;pos 			= pLane-&gt;points.at(0).pos;
	c-&gt;v			= pLane-&gt;speed;
	c-&gt;laneId  		= pLane-&gt;id;
	c-&gt;pLeft 		= pLeft;
	if(pLeft)
		c-&gt;cost		= pLeft-&gt;cost;

	c-&gt;pRight		= pRight;
	if(pRight)
		c-&gt;cost = pRight-&gt;cost;

	if(pBack)
	{
		pBack-&gt;pFronts.push_back(c);
		c-&gt;pBacks.push_back(pBack);
		c-&gt;cost = pBack-&gt;cost + distance2points(c-&gt;pos, pBack-&gt;pos);

		for(unsigned int i=0; i&lt; c-&gt;pBacks.size(); i++)
		{
				if(c-&gt;pBacks.at(i)-&gt;cost &lt; c-&gt;cost)
					c-&gt;cost = c-&gt;pBacks.at(i)-&gt;cost;
		}
	}
	return c;
}

double PlanningHelpers::GetLanePoints(Lane* l, const WayPoint&amp; prevWayPointIndex,
		const double&amp; minDistance , const double&amp; prevCost, vector&lt;WayPoint&gt;&amp; points)
{
	if(l == NULL || minDistance&lt;=0) return 0;

	int index = 0;
	WayPoint  p1, p2;
	WayPoint idx;

	p2 = p1 = l-&gt;points.at(index);
	p1.pLane = l;
	p1.cost = prevCost;
	p2.cost = p1.cost + distance2points(p1.pos, p2.pos);

	points.push_back(p1);

	for(unsigned int i=index+1; i&lt;l-&gt;points.size(); i++)
	{

		p2 = l-&gt;points.at(i);
		p2.pLane = l;
		p2.cost = p1.cost + distance2points(p1.pos, p2.pos);
		points.push_back(p2);

		if(p2.cost &gt;= minDistance)
				break;
		p1 = p2;
	}
	return p2.cost;
}

WayPoint* PlanningHelpers::GetMinCostCell(const vector&lt;WayPoint*&gt;&amp; cells, const vector&lt;int&gt;&amp; globalPathIds)
{
	if(cells.size() == 1)
	{
//		for(unsigned int j = 0; j &lt; cells.at(0)-&gt;actionCost.size(); j++)
//			cout &lt;&lt; &quot;Cost (&quot; &lt;&lt; cells.at(0)-&gt;laneId &lt;&lt; &quot;) of going : &quot; &lt;&lt; cells.at(0)-&gt;actionCost.at(j).first &lt;&lt; &quot;, is : &quot; &lt;&lt; cells.at(0)-&gt;actionCost.at(j).second &lt;&lt; endl;
		return cells.at(0);
	}

	WayPoint* pC = cells.at(0); //cost is distance
	for(unsigned int i=1; i &lt; cells.size(); i++)
	{
		bool bFound = false;
		if(globalPathIds.size()==0)
			bFound = true;

		int iLaneID = cells.at(i)-&gt;id;
		for(unsigned int j=0; j &lt; globalPathIds.size(); j++)
		{
			if(globalPathIds.at(j) == iLaneID)
			{
				bFound = true;
				break;
			}
		}

//		for(unsigned int j = 0; j &lt; cells.at(0)-&gt;actionCost.size(); j++)
//			cout &lt;&lt; &quot;Cost (&quot;&lt;&lt; i &lt;&lt;&quot;) of going : &quot; &lt;&lt; cells.at(0)-&gt;actionCost.at(j).first &lt;&lt; &quot;, is : &quot; &lt;&lt; cells.at(0)-&gt;actionCost.at(j).second &lt;&lt; endl;


		if(cells.at(i)-&gt;cost &lt; pC-&gt;cost &amp;&amp; bFound == true)
			pC = cells.at(i);
	}


	return pC;
}

void PlanningHelpers::ExtractPlanAlernatives(const std::vector&lt;WayPoint&gt;&amp; singlePath, std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; allPaths)
{
	allPaths.clear();
	std::vector&lt;WayPoint&gt; path;
	path.push_back(singlePath.at(0));
	double skip_distance = 8;
	double d = 0;
	bool bStartSkip = false;
	for(unsigned int i= 1; i &lt; singlePath.size(); i++)
	{
		if(singlePath.at(i).bDir != FORWARD_DIR &amp;&amp; singlePath.at(i).pLane &amp;&amp; singlePath.at(i).pFronts.size() &gt; 0)
		{

			bStartSkip = true;
			WayPoint start_point = singlePath.at(i-1);

			cout &lt;&lt; &quot;Current Velocity = &quot; &lt;&lt; start_point.v &lt;&lt; endl;

			RelativeInfo start_info;
			PlanningHelpers::GetRelativeInfo(start_point.pLane-&gt;points, start_point, start_info);
			vector&lt;WayPoint*&gt; local_cell_to_delete;
			PlannerHNS::WayPoint* pStart = &amp;start_point.pLane-&gt;points.at(start_info.iFront);
			WayPoint* pLaneCell =  PlanningHelpers::BuildPlanningSearchTreeStraight(pStart, BACKUP_STRAIGHT_PLAN_DISTANCE, local_cell_to_delete);
			if(pLaneCell)
			{
				vector&lt;WayPoint&gt; straight_path;
				vector&lt;vector&lt;WayPoint&gt; &gt; tempCurrentForwardPathss;
				vector&lt;int&gt; globalPathIds;
				PlanningHelpers::TraversePathTreeBackwards(pLaneCell, pStart, globalPathIds, straight_path, tempCurrentForwardPathss);
				if(straight_path.size() &gt; 2)
				{
					straight_path.insert(straight_path.begin(), path.begin(), path.end());
					for(unsigned int ic = 0; ic &lt; straight_path.size(); ic++)
						straight_path.at(ic).laneChangeCost = 1;
					allPaths.push_back(straight_path);
				}
			}
		}

		if(bStartSkip)
		{
			d += hypot(singlePath.at(i).pos.y - singlePath.at(i-1).pos.y, singlePath.at(i).pos.x - singlePath.at(i-1).pos.x);
			if(d &gt; skip_distance)
			{
				d = 0;
				bStartSkip = false;
			}
		}

		if(!bStartSkip)
			path.push_back(singlePath.at(i));
	}

	allPaths.push_back(path);
}

void PlanningHelpers::TraversePathTreeBackwards(WayPoint* pHead, WayPoint* pStartWP,const vector&lt;int&gt;&amp; globalPathIds,
		vector&lt;WayPoint&gt;&amp; localPath, std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; localPaths)
{
	if(pHead != NULL &amp;&amp; pHead != pStartWP)
	{
		if(pHead-&gt;pBacks.size()&gt;0)
		{
			localPaths.push_back(localPath);
			TraversePathTreeBackwards(GetMinCostCell(pHead-&gt;pBacks, globalPathIds),pStartWP, globalPathIds, localPath, localPaths);
			pHead-&gt;bDir = FORWARD_DIR;
			localPath.push_back(*pHead);
		}
		else if(pHead-&gt;pLeft &amp;&amp; pHead-&gt;cost &gt; 0)
		{
			//vector&lt;Vector2D&gt; forward_path;
			//TravesePathTreeForwards(pHead-&gt;pLeft, forward_path, FORWARD_RIGHT);
			//localPaths.push_back(forward_path);
			cout &lt;&lt; &quot;Global Lane Change  Right &quot; &lt;&lt; endl;
			TraversePathTreeBackwards(pHead-&gt;pLeft,pStartWP, globalPathIds, localPath, localPaths);
			pHead-&gt;bDir = FORWARD_RIGHT_DIR;
			localPath.push_back(*pHead);
		}
		else if(pHead-&gt;pRight &amp;&amp; pHead-&gt;cost &gt; 0)
		{
			//vector&lt;Vector2D&gt; forward_path;
			//TravesePathTreeForwards(pHead-&gt;pRight, forward_path, FORWARD_LEFT);
			//localPaths.push_back(forward_path);

			cout &lt;&lt; &quot;Global Lane Change  Left &quot; &lt;&lt; endl;
			TraversePathTreeBackwards(pHead-&gt;pRight,pStartWP, globalPathIds, localPath, localPaths);
			pHead-&gt;bDir = FORWARD_LEFT_DIR;
			localPath.push_back(*pHead);
		}
//		else
//			cout &lt;&lt; &quot;Err: PlannerZ -&gt; NULL Back Pointer &quot; &lt;&lt; pHead;
	}
	else
		assert(pHead);
}

ACTION_TYPE PlanningHelpers::GetBranchingDirection(WayPoint&amp; currWP, WayPoint&amp; nextWP)
{
	ACTION_TYPE t = FORWARD_ACTION;

//	//first Get the average of the next 3 waypoint directions
//	double angle = 0;
//	if(nextWP.pLane-&gt;id == 487)
//		angle = 11;
//
//	int counter = 0;
//	angle = 0;
//
//	for(unsigned int i=0; i &lt; nextWP.pLane-&gt;points.size() &amp;&amp; counter &lt; 10; i++, counter++)
//	{
//		angle += nextWP.pLane-&gt;points.at(i).pos.a;
//	}
//	angle = angle / counter;
//
//	//Get Circular angle for correct subtraction
//	double circle_angle = UtilityH::GetCircularAngle(currWP.pos.a, angle);
//
//	if( currWP.pos.a - circle_angle &gt; (7.5*DEG2RAD))
//	{
//		t = RIGHT_TURN_ACTION;
//		cout &lt;&lt; &quot;Right Lane, Average Angle = &quot; &lt;&lt; angle*RAD2DEG &lt;&lt; &quot;, Circle Angle = &quot; &lt;&lt; circle_angle*RAD2DEG &lt;&lt; &quot;, currAngle = &quot; &lt;&lt; currWP.pos.a*RAD2DEG &lt;&lt; endl;
//	}
//	else if( currWP.pos.a - circle_angle &lt; (-7.5*DEG2RAD))
//	{
//		t = LEFT_TURN_ACTION;
//		cout &lt;&lt; &quot;Left Lane, Average Angle = &quot; &lt;&lt; angle*RAD2DEG &lt;&lt; &quot;, Circle Angle = &quot; &lt;&lt; circle_angle*RAD2DEG &lt;&lt; &quot;, currAngle = &quot; &lt;&lt; currWP.pos.a*RAD2DEG &lt;&lt; endl;
//	}

	return t;
}

void PlanningHelpers::CalcContourPointsForDetectedObjects(const WayPoint&amp; currPose, vector&lt;DetectedObject&gt;&amp; obj_list, const double&amp; filterDistance)
{
	vector&lt;DetectedObject&gt; res_list;
	for(unsigned int i = 0; i &lt; obj_list.size(); i++)
	{
		GPSPoint center = obj_list.at(i).center.pos;
		double distance = distance2points(center, currPose.pos);

		if(distance &lt; filterDistance)
		{
			DetectedObject obj = obj_list.at(i);

			Mat3 rotationMat(center.a);
			Mat3 translationMat(center.x, center.y);
			double w2 = obj.w/2.0;
			double h2 = obj.l/2.0;
			double z = center.z + obj.h/2.0;

			GPSPoint left_bottom(-w2, -h2, z,0);
			GPSPoint right_bottom(w2,-h2, z,0);
			GPSPoint right_top(w2,h2, z,0);
			GPSPoint left_top(-w2,h2, z,0);

			left_bottom 	= rotationMat * left_bottom;
			right_bottom 	= rotationMat * right_bottom;
			right_top 		= rotationMat * right_top;
			left_top 		= rotationMat * left_top;

			left_bottom 	= translationMat * left_bottom;
			right_bottom 	= translationMat * right_bottom;
			right_top 		= translationMat * right_top;
			left_top 		= translationMat * left_top;

			obj.contour.clear();
			obj.contour.push_back(left_bottom);
			obj.contour.push_back(right_bottom);
			obj.contour.push_back(right_top);
			obj.contour.push_back(left_top);

			res_list.push_back(obj);
		}
	}

	obj_list = res_list;
}

double PlanningHelpers::GetVelocityAhead(const std::vector&lt;WayPoint&gt;&amp; path, const WayPoint&amp; pose, const double&amp; distance)
{
	int iStart = GetClosestNextPointIndex(path, pose);

	double d = 0;
	double min_v = 99999;
	for(unsigned int i=iStart; i&lt; path.size(); i++)
	{
		d  += distance2points(path.at(i).pos, pose.pos);

		if(path.at(i).v &lt; min_v)
			min_v = path.at(i).v;

		if(d &gt;= distance)
			return min_v;
	}
	return 0;
}

void PlanningHelpers::WritePathToFile(const string&amp; fileName, const vector&lt;WayPoint&gt;&amp; path)
{
	DataRW  dataFile;
	ostringstream str_header;
	str_header &lt;&lt; &quot;laneID&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;wpID&quot;  &lt;&lt; &quot;,&quot; &quot;x&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;y&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;a&quot;&lt;&lt;&quot;,&quot;&lt;&lt; &quot;cost&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;Speed&quot; &lt;&lt; &quot;,&quot; ;
	vector&lt;string&gt; dataList;
	 for(unsigned int i=0; i&lt;path.size(); i++)
	 {
		 ostringstream strwp;
		 strwp &lt;&lt; path.at(i).laneId &lt;&lt; &quot;,&quot; &lt;&lt; path.at(i).id &lt;&lt;&quot;,&quot;&lt;&lt;path.at(i).pos.x&lt;&lt;&quot;,&quot;&lt;&lt; path.at(i).pos.y
				 &lt;&lt;&quot;,&quot;&lt;&lt; path.at(i).pos.a &lt;&lt; &quot;,&quot; &lt;&lt; path.at(i).cost &lt;&lt; &quot;,&quot; &lt;&lt; path.at(i).v &lt;&lt; &quot;,&quot;;
		 dataList.push_back(strwp.str());
	 }

	 dataFile.WriteLogData(&quot;&quot;, fileName, str_header.str(), dataList);
}

void PlanningHelpers::TestQuadraticSpline (const std::vector&lt;WayPoint&gt;&amp; center_line, std::vector&lt;WayPoint&gt;&amp; path)
{

//  int N = center_line.size();
//  int i;
//	int ibcbeg;
//	int ibcend;
//	int j;
//	int jhi;
//	int k;
//	double t[N];
//	double tval;
//	double y[N];
//	double ybcbeg;
//	double ybcend;
//	double *ypp;
//	double yppval;
//	double ypval;
//	double yval;
//
//  cout &lt;&lt; &quot;\n&quot;;
//  cout &lt;&lt; &quot;TEST24\n&quot;;
//  cout &lt;&lt; &quot;  SPLINE_QUADRATIC_VAL evaluates a\n&quot;;
//  cout &lt;&lt; &quot;    quadratic spline.\n&quot;;
//  cout &lt;&lt; &quot;\n&quot;;
//  cout &lt;&lt; &quot;  Runge''s function, evenly spaced knots.\n&quot;;
//
//  for ( i = 0; i &lt; N; i++ )
//  {
//    t[i] =  center_line.at(i).pos.x;
//    y[i] =  center_line.at(i).pos.y;
//  }
//
//  //
//  //  Try various boundary conditions.
//  //
//    for ( k = 0; k &lt;= 4; k++ )
//    {
//      if ( k == 0 )
//      {
//        ibcbeg = 0;
//        ybcbeg = 0.0;
//
//        ibcend = 0;
//        ybcend = 0.0;
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Boundary condition 0 at both ends:\n&quot;;
//        cout &lt;&lt; &quot;  Spline is quadratic in boundary intervals.\n&quot;;
//      }
//      else if ( k == 1 )
//      {
//        ibcbeg = 1;
//        ybcbeg = t[0];
//
//        ibcend = 1;
//        ybcend = t[N-1] ;
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Boundary condition 1 at both ends:\n&quot;;
//        cout &lt;&lt; &quot;  Y'(left) =  &quot; &lt;&lt; ybcbeg &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Y'(right) = &quot; &lt;&lt; ybcend &lt;&lt; &quot;\n&quot;;
//
//      }
//      else if ( k == 2 )
//      {
//        ibcbeg = 2;
//        ybcbeg = fpprunge ( t[0] );
//
//        ibcend = 2;
//        ybcend = fpprunge ( t[N-1] );
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Boundary condition 2 at both ends:\n&quot;;
//        cout &lt;&lt; &quot;  YP''(left) =  &quot; &lt;&lt; ybcbeg &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  YP''(right) = &quot; &lt;&lt; ybcend &lt;&lt; &quot;\n&quot;;
//      }
//      else if ( k == 3 )
//      {
//        ibcbeg = 2;
//        ybcbeg = 0.0;
//
//        ibcend = 2;
//        ybcend = 0.0;
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Natural spline:\n&quot;;
//        cout &lt;&lt; &quot;  YP''(left) =  &quot; &lt;&lt; ybcbeg &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  YP''(right) = &quot; &lt;&lt; ybcend &lt;&lt; &quot;\n&quot;;
//      }
//      else if ( k == 4 )
//      {
//        ibcbeg = 3;
//        ibcend = 3;
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  \&quot;Not-a-knot\&quot; spline:\n&quot;;
//      }
//
//      ypp = spline_cubic_set ( N, t, y, ibcbeg, ybcbeg, ibcend, ybcend );
//
//      cout &lt;&lt; &quot;\n&quot;;
//      cout &lt;&lt; &quot;  SPLINE''(T), F''(T):\n&quot;;
//      cout &lt;&lt; &quot;\n&quot;;
//      for ( i = 0; i &lt; N; i++ )
//      {
//        cout &lt;&lt; ypp[i] &lt;&lt; &quot;  &quot;
//             &lt;&lt; fpprunge ( t[i] ) &lt;&lt; &quot;\n&quot;;
//      }
//
//      cout &lt;&lt; &quot;\n&quot;;
//      cout &lt;&lt; &quot;  T, SPLINE(T), F(T)\n&quot;;
//      cout &lt;&lt; &quot;\n&quot;;
//
//      for ( i = 0; i &lt;= N; i++ )
//      {
//        if ( i == 0 )
//        {
//          jhi = 1;
//        }
//        else if ( i &lt; N )
//        {
//          jhi = 2;
//        }
//        else
//        {
//          jhi = 2;
//        }
//
//        for ( j = 1; j &lt;= jhi; j++ )
//        {
//          if ( i == 0 )
//          {
//            tval = t[0] - 1.0;
//          }
//          else if ( i &lt; N )
//          {
//            tval = (
//                ( double ) ( jhi - j + 1 ) * t[i-1]
//              + ( double ) (       j - 1 ) * t[i] )
//              / ( double ) ( jhi         );
//          }
//          else
//          {
//            if ( j == 1 )
//            {
//              tval = t[N-1];
//            }
//            else
//            {
//              tval = t[N-1] + 1.0;
//            }
//          }
//
//          yval = spline_cubic_val ( N, t, y, ypp, tval, &amp;ypval, &amp;yppval );
//
//          cout &lt;&lt; tval &lt;&lt; &quot;  &quot;
//               &lt;&lt; yval &lt;&lt; &quot;  &quot;
//               &lt;&lt; frunge ( tval ) &lt;&lt; &quot;\n&quot;;
//        }
//      }
//      delete [] ypp;
//    }
//
//    return;
}

double PlanningHelpers::frunge ( double x )
{
  double fx;

  fx = 1.0 / ( 1.0 + 25.0 * x * x );

  return fx;
}

double PlanningHelpers::fprunge ( double x )
{
  double bot;
  double fx;

  bot = 1.0 + 25.0 * x * x;
  fx = -50.0 * x / ( bot * bot );

  return fx;
}

double PlanningHelpers::fpprunge ( double x )
{
  double bot;
  double fx;

  bot = 1.0 + 25.0 * x * x;
  fx = ( -50.0 + 3750.0 * x * x ) / ( bot * bot * bot );

  return fx;
}


} /* namespace PlannerHNS */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/include/SimpleTracker.h" new_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/include/SimpleTracker.h">
				<diff>@@ -12,7 +12,7 @@
 #include &quot;opencv2/video/tracking.hpp&quot;
 #include &lt;vector&gt;
 #include &quot;UtilityH.h&quot;
-#include &lt;cmath&gt;
+#include &lt;math.h&gt;
 #include &lt;iostream&gt;
 
 namespace SimulationNS
</diff>
				<old_file>/*
 * SimpleTracker.h
 *
 *  Created on: Aug 11, 2016
 *      Author: hatem
 */

#ifndef SimpleTracker_H_
#define SimpleTracker_H_

#include &quot;RoadNetwork.h&quot;
#include &quot;opencv2/video/tracking.hpp&quot;
#include &lt;vector&gt;
#include &quot;UtilityH.h&quot;
#include &lt;cmath&gt;
#include &lt;iostream&gt;

namespace SimulationNS
{

#define DEBUG_TRACKER 0
#define NEVER_GORGET_TIME -1000
#define MIN_EVIDENCE_NUMBER 3

struct Kalman1dState
{
    double MovCov; //double q; //moving noise covariance
    double MeasureCov; //double r; //measurement noise covariance
    double x; //value
    double p; //estimation error covariance
    double k; //kalman gain
};

class  kalmanFilter1D
{
public:

	Kalman1dState result;

    kalmanFilter1D()
	{

	}
    kalmanFilter1D(double MovCov, double MeasureCov, double p, double intial_value)
    {
        result.MovCov = MovCov;
        result.MeasureCov = MeasureCov;
        result.p = p;
        result.x = intial_value;
    }

    Kalman1dState Update(double measurement)
    {
    	//prediction update
		//omit x = x
		result.p = result.p + result.MovCov;

		//measurement update
		result.k = result.p / (result.p + result.MeasureCov);
		result.x = result.x + result.k * (measurement - result.x);
		result.p = (1 - result.k) * result.p;

		return result;
    }
};

class KFTrackV
{
private:
	cv::KalmanFilter m_filter;
	double prev_x, prev_y, prev_v, prev_a;
	long m_id;
	double dt;
	int nStates;
	int nMeasure;
	double circ_angle;

public:
	int region_id;
	double forget_time;
	int m_iLife;
	PlannerHNS::DetectedObject obj;
	kalmanFilter1D errorSmoother;

	long GetTrackID()
	{
		return m_id;
	}

	KFTrackV(double x, double y, double a, long id, double _dt)
	{
		circ_angle = 0;
		errorSmoother.result.MovCov = 0.125;
		errorSmoother.result.MeasureCov = 0.1;
		errorSmoother.result.p = 1;
		errorSmoother.result.x = 0;
		region_id = -1;
		forget_time = NEVER_GORGET_TIME; // this is very bad , dangerous
		m_iLife = 0;
		dt = _dt;
		prev_x = x;
		prev_y = y;
		prev_v = 0;
		prev_a = a;
		nStates = 4;
		nMeasure = 2;

		m_id = id;

		m_filter = cv::KalmanFilter(nStates,nMeasure);
#if (CV_MAJOR_VERSION == 2)
		m_filter.transitionMatrix = *(cv::Mat_&lt;float&gt;(nStates, nStates) &lt;&lt; 1	,0	,dt	,0  ,
				0	,1	,0	,dt	,
				0	,0	,1	,0	,
				0	,0	,0	,1	);
#elif (CV_MAJOR_VERSION == 3)
		m_filter.transitionMatrix = (cv::Mat_&lt;float&gt;(nStates, nStates) &lt;&lt; 1	,0	,dt	,0  ,
				0	,1	,0	,dt	,
				0	,0	,1	,0	,
				0	,0	,0	,1	);
#endif		

		m_filter.statePre.at&lt;float&gt;(0) = x;
		m_filter.statePre.at&lt;float&gt;(1) = y;
		m_filter.statePre.at&lt;float&gt;(2) = 0;
		m_filter.statePre.at&lt;float&gt;(3) = 0;

		m_filter.statePost = m_filter.statePre;

		setIdentity(m_filter.measurementMatrix);

		cv::setIdentity(m_filter.measurementNoiseCov, cv::Scalar::all(0.0001));
		cv::setIdentity(m_filter.processNoiseCov, cv::Scalar::all(0.0001));
		cv::setIdentity(m_filter.errorCovPost, cv::Scalar::all(0.075));

		m_filter.predict();

		errorSmoother.Update(a);
	}

	void UpdateTracking(double _dt, const double&amp; x, const double&amp; y, const double&amp; a, double&amp; x_new, double &amp; y_new , double&amp; a_new, double&amp; v)
	{
		dt = _dt;
#if (CV_MAJOR_VERSION == 2)
		m_filter.transitionMatrix = *(cv::Mat_&lt;float&gt;(nStates, nStates) &lt;&lt; 1	,0	,dt	,0  ,
				0	,1	,0	,dt	,
				0	,0	,1	,0	,
				0	,0	,0	,1	);
#elif (CV_MAJOR_VERSION == 3)
		m_filter.transitionMatrix = (cv::Mat_&lt;float&gt;(nStates, nStates) &lt;&lt; 1	,0	,dt	,0  ,
				0	,1	,0	,dt	,
				0	,0	,1	,0	,
				0	,0	,0	,1	);
#endif		
		double a_old = a;

		cv::Mat_&lt;float&gt; measurement(nMeasure,1);
		cv::Mat_&lt;float&gt; prediction(nStates,1);

		measurement(0) = x;
		measurement(1) = y;

		prediction = m_filter.correct(measurement);

		x_new = prediction.at&lt;float&gt;(0);
		y_new = prediction.at&lt;float&gt;(1);
		double vx  = prediction.at&lt;float&gt;(2);
		double vy  = prediction.at&lt;float&gt;(3);

		if(m_iLife &gt; 2)
		{
			v = sqrt(vx*vx+vy*vy);
			double diff_y = y_new - prev_y;
			double diff_x = x_new - prev_x;
			if(hypot(diff_y, diff_x) &gt; 0.5)
			{
				prev_y = y;
				prev_x = x;
				a_new = atan2(diff_y, diff_x);
			}
			else
				a_new = a;

		}
		else
		{
			v = 0;
			a_new = a;
		}

		circ_angle = UtilityHNS::UtilityH::GetCircularAngle(circ_angle, UtilityHNS::UtilityH::FixNegativeAngle(a_old), UtilityHNS::UtilityH::FixNegativeAngle(a_new));

		circ_angle =  errorSmoother.Update(circ_angle).x;

		a_new = UtilityHNS::UtilityH::SplitPositiveAngle(circ_angle);

		if(v &lt; 0.1)
			v = 0;

		//std::cout &lt;&lt; &quot;Track: Old (&quot; &lt;&lt; x &lt;&lt; &quot;, &quot; &lt;&lt; y &lt;&lt; &quot;), New (&quot; &lt;&lt; x_new &lt;&lt; &quot;, &quot; &lt;&lt; y_new &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
		//std::cout &lt;&lt; &quot;Track: &quot; &lt;&lt; m_id &lt;&lt; &quot;, A: &quot; &lt;&lt; a &lt;&lt; &quot;, A_new:(&quot; &lt;&lt; circ_angle &lt;&lt; &quot;,&quot; &lt;&lt;  a_new &lt;&lt; &quot;) , V&quot; &lt;&lt; v &lt;&lt; &quot;, dt: &quot; &lt;&lt; dt &lt;&lt; &quot;, forget_time: &quot; &lt;&lt; forget_time &lt;&lt; std::endl;

		m_filter.predict();
		m_filter.statePre.copyTo(m_filter.statePost);
		m_filter.errorCovPre.copyTo(m_filter.errorCovPost);

		forget_time -= dt;
		m_iLife++;
	}
	virtual ~KFTrackV(){}
};

class InterestCircle
{
public:
	int id;
	double radius;
	double forget_time;
	std::vector&lt;KFTrackV*&gt; pTrackers;
	InterestCircle* pPrevCircle;
	InterestCircle* pNextCircle;

	InterestCircle(int _id)
	{
		id = _id;
		radius = 0;
		forget_time = NEVER_GORGET_TIME; // never forget
		pPrevCircle = 0;
		pNextCircle = 0;
	}
};

class CostRecordSet
{
public:
	int currobj;
	int prevObj;
	double cost;
	CostRecordSet(int curr_id, int prev_id, double _cost)
	{
		currobj = curr_id;
		prevObj = prev_id;
		cost = _cost;
	}
};

class SimpleTracker
{
public:
	std::vector&lt;InterestCircle*&gt; m_InterestRegions;
	std::vector&lt;KFTrackV*&gt; m_Tracks;
	timespec m_TrackTimer;
	long iTracksNumber;
	PlannerHNS::WayPoint m_PrevState;
	std::vector&lt;PlannerHNS::DetectedObject&gt; m_PrevDetectedObjects;
	std::vector&lt;PlannerHNS::DetectedObject&gt; m_DetectedObjects;

	void CreateTrack(PlannerHNS::DetectedObject&amp; o);
	void CreateTrackV2(PlannerHNS::DetectedObject&amp; o);
	KFTrackV* FindTrack(long index);
	void Track(std::vector&lt;PlannerHNS::DetectedObject&gt;&amp; objects_list);
	void TrackV2();
	void CoordinateTransform(const PlannerHNS::WayPoint&amp; refCoordinate, PlannerHNS::DetectedObject&amp; obj);
	void CoordinateTransformPoint(const PlannerHNS::WayPoint&amp; refCoordinate, PlannerHNS::GPSPoint&amp; obj);
	void AssociateObjects();
	void InitializeInterestRegions(double horizon, double init_raduis, double init_time, std::vector&lt;InterestCircle*&gt;&amp; regions);
	void AssociateAndTrack();
	void AssociateToRegions(KFTrackV&amp; detectedObject);
	void CleanOldTracks();

	void DoOneStep(const PlannerHNS::WayPoint&amp; currPose, const std::vector&lt;PlannerHNS::DetectedObject&gt;&amp; obj_list);

	SimpleTracker(double horizon = 100);
	virtual ~SimpleTracker();

public:
	double m_DT;
	double m_MAX_ASSOCIATION_DISTANCE;
	int m_MAX_TRACKS_AFTER_LOSING;
	bool m_bUseCenterOnly;
	double m_MaxKeepTime;
	bool m_bFirstCall;
};

} /* namespace BehaviorsNS */

#endif /* SimpleTracker_H_ */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/src/DrawingHelpers.cpp" new_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/src/DrawingHelpers.cpp">
				<diff>@@ -8,7 +8,7 @@
 #include &quot;DrawingHelpers.h&quot;
 #include &lt;stdarg.h&gt;
 #include &lt;stdio.h&gt;
-#include &lt;math.h&gt;
+#include &lt;cmath&gt;
 #include &quot;UtilityH.h&quot;
 #include &quot;PlanningHelpers.h&quot;
 #include &lt;GL/freeglut.h&gt;
</diff>
				<old_file>/*
 * DrawingHelpers.cpp
 *
 *  Created on: May 31, 2016
 *      Author: hatem
 */

#include &quot;DrawingHelpers.h&quot;
#include &lt;stdarg.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include &quot;UtilityH.h&quot;
#include &quot;PlanningHelpers.h&quot;
#include &lt;GL/freeglut.h&gt;

using namespace std;
using namespace PlannerHNS;
using namespace UtilityHNS;

namespace Graphics
{

DrawingHelpers::DrawingHelpers() {
	// TODO Auto-generated constructor stub

}

DrawingHelpers::~DrawingHelpers() {
	// TODO Auto-generated destructor stub
}

void DrawingHelpers::DrawString(float x, float y, GLvoid* font_style, char* format, ...)
{
	glDisable(GL_LIGHTING);

	va_list args;
	char buffer[1000], *s;

	va_start(args, format);
	vsprintf(buffer, format, args);
	va_end(args);
	//GLuint ox = x;
	GLuint oy = y;

	glRasterPos2f(x, y);
	for (s = buffer; *s; s++)
	{
		if(*s == ',')
		{
			x += 220;
			y = oy;
			glRasterPos2f(x, y);
			continue;
		}
		else if(*s == '\n')
		{
			y+=12;
			glRasterPos2f(x, y);
			continue;
		}

		glutBitmapCharacter(font_style, *s);
	}
	glEnable(GL_LIGHTING);
}

void DrawingHelpers::DrawGrid(const double&amp; x, const double&amp; y, const double&amp; w, const double&amp; h, const double&amp; cell_l)
{
	glPushMatrix();
	int nVerticalLisne   = floor(w/cell_l);
	int nHorizontalLines = floor(h/cell_l);

	glBegin(GL_LINES);
	glColor3ub(210,210,210);
	double incr = y;
	for(int r=0; r&lt;= nHorizontalLines; r++)
	{
		glNormal3f(1.0, 1.0, 1.0);
		glVertex3f(x, incr, 0);
		glVertex3f(x+w, incr, 0);
		incr+=cell_l;
	}

	double incc = x;
	for(int r=0; r&lt;= nVerticalLisne; r++)
	{
		glNormal3f(1.0, 1.0, 1.0);
		glVertex3f(incc, y,  0);
		glVertex3f(incc, y + h, 0);
		incc+=cell_l;
	}
	glEnd();

	glPopMatrix();
}

void DrawingHelpers::DrawArrow(const double&amp; x, const double&amp; y, const double&amp; a)
{
	const int nSlicesStacks = 50;
	const double percent = 20.0;
	const double innerPercent = 15.0;
	double half_length = 10/2.0;

	glPushMatrix();
	//Draw one cylender and cone
	glTranslated(x, y, 0.5);
	glRotated(a*RAD2DEG, 0,0,1);

	//X Axis
	glPushMatrix();
	glColor3ub(200,200,200);
	glRotated(90, 0,1,0);
	glutSolidCylinder(half_length/percent, half_length,nSlicesStacks,nSlicesStacks);
	glTranslated(0,0,half_length);
	glColor3f(1,1,0);
	glutSolidCone(half_length/innerPercent, half_length/innerPercent,nSlicesStacks,nSlicesStacks);
	glPopMatrix();

	glPopMatrix();
}

void DrawingHelpers::DrawCustomOrigin(const double&amp; x, const double&amp; y, const double&amp; z, const int&amp; yaw, const int&amp; roll, const int&amp; pitch, const double&amp; length)
{
	const int nSlicesStacks = 50;
	const double percent = 20.0;
	const double innerPercent = 15.0;
	double half_length = length/2.0;

	glPushMatrix();
	//Draw one cylender and cone
	glTranslated(x, y, z);
	glRotated(yaw, 0,0,1);
	glRotated(roll, 1,0,0);
	glRotated(pitch, 0,1,0);

	//Z Axis
	glPushMatrix();
	glColor3f(0.65,0.65,0.65);
	glutSolidCylinder(half_length/percent, half_length,nSlicesStacks,nSlicesStacks);
	glTranslated(0,0,half_length);
	glColor3f(0,0,1);
	glutSolidCone(half_length/innerPercent, half_length/innerPercent,nSlicesStacks,nSlicesStacks);
	glPopMatrix();

	//X Axis
	glPushMatrix();
	glColor3f(0.65,0.65,0.65);
	glRotated(90, 0,1,0);
	glutSolidCylinder(half_length/percent, half_length,nSlicesStacks,nSlicesStacks);
	glTranslated(0,0,half_length);
	glColor3f(1,1,0);
	glutSolidCone(half_length/innerPercent, half_length/innerPercent,nSlicesStacks,nSlicesStacks);
	glPopMatrix();

//	//Y Axis
	glPushMatrix();
	glColor3f(0.65,0.65,0.65);
	glRotated(90, 1,0,0);
	glutSolidCylinder(half_length/percent, half_length, nSlicesStacks, nSlicesStacks);
	glTranslated(0,0,half_length);
	glColor3f(1,0,0);
	glutSolidCone(half_length/innerPercent, half_length/innerPercent, nSlicesStacks,nSlicesStacks);
	glPopMatrix();

	//glDisable(GL_LIGHTING);
	glPopMatrix();

}

vector&lt;vector&lt;float&gt; &gt; DrawingHelpers::PreparePathForDrawing(const std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path,
		std::vector&lt;std::vector&lt;PlannerHNS::WayPoint&gt; &gt;&amp; redyForDraw, double w, double resolution)
{
	vector&lt;vector&lt;float&gt; &gt; colorProfiles;
	if(path.size() &lt; 2) return colorProfiles;
	int size = path.size();
	WayPoint p1 = path[0];
	WayPoint p2 =p1;
	WayPoint prev_point = p1;
	WayPoint center, prev_center ,pa, pb, pc, pd;
	double a = 0;
	double prev_angle = 0;
	vector&lt;WayPoint&gt; four_temp;
	vector&lt;float&gt; color_vector;

	for(int i=0; i &lt; size ; i++)
	{

		color_vector.clear();
		four_temp.clear();

		pa = p2 = path[i];

		color_vector.push_back(p1.v/12.0);
		color_vector.push_back(p1.v/12.0);
		color_vector.push_back(p1.v/12.0);
		colorProfiles.push_back(color_vector);

		if(distance2points(p1.pos, p2.pos) &lt; resolution)
		  continue;

		center.pos.x = p1.pos.x + (p2.pos.x-p1.pos.x)/2.0;
		center.pos.y = p1.pos.y + (p2.pos.y-p1.pos.y)/2.0;

		a = atan2(p2.pos.y- p1.pos.y, p2.pos.x- p1.pos.x);

		pa.pos.x = p1.pos.x - w * cos(a - M_PI/2.0);
		pa.pos.y = p1.pos.y - w * sin(a - M_PI/2.0);
		pa.pos.z = p1.pos.z;

		pb.pos.x = p1.pos.x + w * cos(a - M_PI/2.0);
		pb.pos.y = p1.pos.y + w * sin(a - M_PI/2.0);
		pb.pos.z = p1.pos.z;


		pc.pos.x = p2.pos.x + w * cos(a - M_PI/2.0);
		pc.pos.y = p2.pos.y + w * sin(a - M_PI/2.0);
		pc.pos.z = p2.pos.z;

		pd.pos.x = p2.pos.x - w * cos(a - M_PI/2.0);
		pd.pos.y = p2.pos.y - w * sin(a - M_PI/2.0);
		pd.pos.z = p2.pos.z;

		if(!(prev_point.pos.x == p1.pos.x &amp;&amp;  prev_point.pos.y == p1.pos.y))
		{
			prev_angle = atan2(p1.pos.y- prev_point.pos.y, p1.pos.x- prev_point.pos.x);

			pa.pos.x = p1.pos.x - w * cos(prev_angle - M_PI/2.0);
			pa.pos.y = p1.pos.y - w * sin(prev_angle - M_PI/2.0);

			pb.pos.x = p1.pos.x + w * cos(prev_angle - M_PI/2.0);
			pb.pos.y = p1.pos.y + w * sin(prev_angle - M_PI/2.0);
		}

	  	four_temp.push_back(pa);
	  	four_temp.push_back(pb);
	  	four_temp.push_back(pc);
	  	four_temp.push_back(pd);

	  	redyForDraw.push_back(four_temp);

		prev_point = p1;
		p1 = p2;
	}
	  return colorProfiles;
}

void DrawingHelpers::DrawPrePreparedPolygons(std::vector&lt;std::vector&lt;PlannerHNS::WayPoint&gt; &gt;&amp; path,
		double z, float color[3],int nSkipPoints, const std::vector&lt;std::vector&lt;float&gt; &gt;* colorProfile)
{


	if(!colorProfile)
		glColor3f(color[0], color[1], color[2]);

	for(unsigned int i=0; i&lt; path.size(); i+=nSkipPoints)
	{
		if(path[i].size() == 4)
		{
			if(path[i][0].pLane &amp;&amp; (path[i][0].pLane-&gt;pRightLane || path[i][0].pLane-&gt;pLeftLane))
				glColor3f(1, 0, 0);
			else if(colorProfile)
			{
				glColor3f(color[0]*(*colorProfile)[i][0], color[1] * (*colorProfile)[i][1], color[2] * (*colorProfile)[i][2]);
			}

			 glBegin(GL_POLYGON);
				  glNormal3f(0.0, 0.0, 0.1);
//				  glVertex3f(path[i][0].p.x, path[i][0].p.y,path[i][0].p.z+z);
//				  glVertex3f(path[i][1].p.x, path[i][1].p.y,path[i][1].p.z+z);
//				  glVertex3f(path[i][2].p.x, path[i][2].p.y,path[i][2].p.z+z);
//				  glVertex3f(path[i][3].p.x, path[i][3].p.y,path[i][3].p.z+z);
				  glVertex3f(path[i][0].pos.x, path[i][0].pos.y,z);
				  glVertex3f(path[i][1].pos.x, path[i][1].pos.y,z);
				  glVertex3f(path[i][2].pos.x, path[i][2].pos.y,z);
				  //glVertex3f((path[i][2].p.x+path[i][1].p.x)/2.0, (path[i][2].p.y+path[i][1].p.y)/2.0,z);
				  glVertex3f(path[i][3].pos.x, path[i][3].pos.y,z);
			  glEnd();
		}
	}


}

void DrawingHelpers::DrawCostPath(const std::vector&lt;PlannerHNS::WayPoint*&gt;&amp; path_points, const double&amp; z, const double&amp; width)
{
	if(path_points.size()==0) return;

	WayPoint p1 = *path_points[0];
	float color[3] = {0,0,0};

	double max_cost = 0;
	for(unsigned int i=0; i &lt; path_points.size(); i++)
	{
		if(path_points.at(i)-&gt;cost &gt; max_cost)
			max_cost = path_points.at(i)-&gt;cost;
	}

	int size = path_points.size();

	for(int i=0; i &lt; size; i++)
	{
		p1 = *path_points[i];
		double norm_cost = path_points.at(i)-&gt;cost / max_cost * 2.0;
		if(norm_cost &lt;= 1.0)
		{
			color[0] = norm_cost;
			color[1] = 1.0;
		}
		else if(norm_cost &gt; 1.0)
		{
			color[0] = 1.0;
			color[1] = 2.0 - norm_cost;
		}

		glColor3f(color[0], color[1], color[2]);

		//DrawLinePoygonFromCenterX(p1, z, p2, z, width, 0, prev_point);
		DrawWideEllipse(p1.pos.x, p1.pos.y, z, 0.5, 0.5, 0.25, color);
	}
}

void DrawingHelpers::DrawWidePath(const std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path_points, const double&amp; z, const double&amp; width, float color[3], bool bGadient)
{
	if(path_points.size()==0) return;

	WayPoint p1 = path_points[0];
	WayPoint p2 = p1;

	float localColor[3] = {color[0],color[1],color[2]};

	int size = path_points.size();
	WayPoint prev_point = p1;

	for(int i=1; i &lt; size; i+=2)
	{
		p2 = path_points[i];
		if(bGadient)
		{
			localColor[0] = color[0] * (float)(i+20)*3/(float)size;
			localColor[1] = color[1] * (float)(i+20)*3/(float)size;
			localColor[2] = color[2] * (float)(i+20)*3/(float)size;
		}

		if(p2.bDir == BACKWARD_DIR)
			glColor3f(1,0, 0);
		else
			glColor3f(localColor[0],localColor[1],localColor[2]);

		DrawLinePoygonFromCenterX(p1, z, p2, z, width, 0, prev_point);

		prev_point = p1;

		p1 = p2;
	}
}

void DrawingHelpers::DrawLinePoygonline(const PlannerHNS::GPSPoint&amp; p1, const PlannerHNS::GPSPoint&amp; p2, const double&amp; w)
{
	POINT2D center, prev_center ,pa, pb, pc, pd, prev_pa,prev_pb;
	double a = 0;

	center.x = p1.x + (p2.x-p1.x)/2.0;
	center.y = p1.y + (p2.y-p1.y)/2.0;

	 a = atan2(p2.y- p1.y, p2.x- p1.x);

	pa.x = p1.x - w * cos(a - M_PI/2.0);
	pa.y = p1.y - w * sin(a - M_PI/2.0);

	pb.x = p1.x + w * cos(a - M_PI/2.0);
	pb.y = p1.y + w * sin(a - M_PI/2.0);


	pc.x = p2.x + w * cos(a - M_PI/2.0);
	pc.y = p2.y + w * sin(a - M_PI/2.0);

	pd.x = p2.x - w * cos(a - M_PI/2.0);
	pd.y = p2.y - w * sin(a - M_PI/2.0);

	glBegin(GL_POLYGON);
	  glNormal3f(0.1, 0.1, 0.1);
	  glVertex3f(pa.x, pa.y, p1.z);
	  glVertex3f(pb.x, pb.y, p1.z);
	  glVertex3f(pc.x, pc.y, p2.z);
	  glVertex3f(pd.x, pd.y, p2.z);
	glEnd();
}

void DrawingHelpers::DrawLinePoygonFromCenterX(const PlannerHNS::WayPoint&amp; p1, const double&amp; z,
		const PlannerHNS::WayPoint&amp; p2, const double&amp; z2, const double&amp; w, const double&amp; h,
		PlannerHNS::WayPoint&amp; prev_point)
{
	POINT2D center, prev_center ,pa, pb, pc, pd, prev_pa,prev_pb;
	double a = 0;
	double prev_angle = 0;

	center.x = p1.pos.x + (p2.pos.x-p1.pos.x)/2.0;
	center.y = p1.pos.y + (p2.pos.y-p1.pos.y)/2.0;

	 a = atan2(p2.pos.y- p1.pos.y, p2.pos.x- p1.pos.x);

	pa.x = p1.pos.x - w * cos(a - M_PI/2.0);
	pa.y = p1.pos.y - w * sin(a - M_PI/2.0);

	pb.x = p1.pos.x + w * cos(a - M_PI/2.0);
	pb.y = p1.pos.y + w * sin(a - M_PI/2.0);


	pc.x = p2.pos.x + w * cos(a - M_PI/2.0);
	pc.y = p2.pos.y + w * sin(a - M_PI/2.0);

	pd.x = p2.pos.x - w * cos(a - M_PI/2.0);
	pd.y = p2.pos.y - w * sin(a - M_PI/2.0);

	if(!(prev_point.pos.x == p1.pos.x &amp;&amp;  prev_point.pos.y == p1.pos.y))
	{
		prev_angle = atan2(p1.pos.y- prev_point.pos.y, p1.pos.x- prev_point.pos.x);

		pa.x = p1.pos.x - w * cos(prev_angle - M_PI/2.0);
		pa.y = p1.pos.y - w * sin(prev_angle - M_PI/2.0);

		pb.x = p1.pos.x + w * cos(prev_angle - M_PI/2.0);
		pb.y = p1.pos.y + w * sin(prev_angle - M_PI/2.0);

	}

	  glBegin(GL_POLYGON);
		  glNormal3f(0.1, 0.1, 0.1);
		  glVertex3f(pa.x, pa.y,z);
		  glVertex3f(pb.x, pb.y, z);
		  glVertex3f(pc.x, pc.y,z);
		  glVertex3f(pd.x, pd.y, z);
	  glEnd();

}

void DrawingHelpers::DrawCustomCarModel(const PlannerHNS::WayPoint&amp; pose,const double&amp; steeringAngle, const std::vector&lt;PlannerHNS::GPSPoint&gt;&amp; carPoints,float color[3], const double&amp; angleFix)
{
	if(carPoints.size() == 4)
	{
		double z_margin = 0.05;

		glPushMatrix();
		glTranslated(pose.pos.x, pose.pos.y, pose.pos.z);
		glRotated(pose.pos.a*RAD2DEG + angleFix, 0,0,1);
		for(unsigned  int i = 0; i &lt; 4; i++)
		{
			glBegin(GL_LINE_STRIP);
			//glColor3f(0,1,1);
			glColor3f(color[0],color[1],color[2]);
			glVertex3f(carPoints[i].x, carPoints[i].y, carPoints[i].z);
			glVertex3f(carPoints[i].x, carPoints[i].y, carPoints[i].z+1);

			glEnd();
		}

		glBegin(GL_POLYGON);
		//glColor3f(0,0,1);
		glColor3f(color[0],color[0],color[2]);
			glVertex3f(carPoints[0].x, carPoints[0].y, carPoints[0].z+z_margin);
			glVertex3f(carPoints[1].x, carPoints[1].y, carPoints[1].z+z_margin);
			glVertex3f(carPoints[2].x, carPoints[2].y, carPoints[2].z+z_margin);
			glVertex3f(carPoints[3].x, carPoints[3].y, carPoints[3].z+z_margin);
			glVertex3f(carPoints[0].x, carPoints[0].y, carPoints[0].z+z_margin);

			glVertex3f(carPoints[0].x, carPoints[0].y, carPoints[0].z+z_margin);
			glVertex3f(carPoints[2].x, carPoints[2].y, carPoints[2].z+z_margin);

			glVertex3f(carPoints[1].x, carPoints[1].y, carPoints[1].z+z_margin);
			glVertex3f(carPoints[3].x, carPoints[3].y, carPoints[3].z+z_margin);

		glEnd();

		glBegin(GL_LINE_LOOP);
		glColor3f(color[0],color[0],color[2]);
			glVertex3f(carPoints[0].x, carPoints[0].y, carPoints[0].z+1);
			glVertex3f(carPoints[1].x, carPoints[1].y, carPoints[1].z+1);
			glVertex3f(carPoints[2].x, carPoints[2].y, carPoints[2].z+1);
			glVertex3f(carPoints[3].x, carPoints[3].y, carPoints[3].z+1);
			glVertex3f(carPoints[0].x, carPoints[0].y, carPoints[0].z+1);

			glVertex3f(carPoints[0].x, carPoints[0].y, carPoints[0].z+1);
			glVertex3f(carPoints[2].x, carPoints[2].y, carPoints[2].z+1);

			glVertex3f(carPoints[1].x, carPoints[1].y, carPoints[1].z+1);
			glVertex3f(carPoints[3].x, carPoints[3].y, carPoints[3].z+1);

		glEnd();


		double width = fabs(carPoints[0].x - carPoints[2].x);
		double length = fabs(carPoints[0].y - carPoints[2].y);
		double innerRad = 1.0;
		double scale_factor = 0.1;
		glColor3f(0.05,0.05,0.05);

		glPushMatrix();
		glTranslated(width/2.0,length/2.0 - 0.5,0);
		glScaled(scale_factor, scale_factor, scale_factor);
		glRotated(90, 0,0,1);
		glRotated(90, 1,0,0);
		glutSolidTorus(innerRad, 3.0, 20, 20);
		glPopMatrix();

		glPushMatrix();
		glTranslated(-width/2.0,length/2.0 - 0.5,0);
		glScaled(scale_factor, scale_factor, scale_factor);
		glRotated(90, 0,0,1);
		glRotated(90, 1,0,0);
		glutSolidTorus(innerRad, 3.0, 20, 20);
		glPopMatrix();

		glPushMatrix();
		glTranslated(width/2.0,-length/2.0 + 0.5,0);
		glScaled(scale_factor, scale_factor, scale_factor);
		glRotated(90+steeringAngle*RAD2DEG, 0,0,1);
		glRotated(90, 1,0,0);
		glutSolidTorus(innerRad, 3.0, 20, 20);
		glPopMatrix();

		glPushMatrix();
		glTranslated(-width/2.0,-length/2.0 + 0.5,0);
		glScaled(scale_factor, scale_factor, scale_factor);
		glRotated(90+steeringAngle*RAD2DEG, 0,0,1);
		glRotated(90, 1,0,0);
		glutSolidTorus(innerRad, 3.0, 20, 20);
		glPopMatrix();




		glPopMatrix();
	}

	DrawCustomOrigin(pose.pos.x, pose.pos.y, pose.pos.z, pose.pos.a*RAD2DEG, 0,0, 2);
}

GLMmodel* DrawingHelpers::LoadModel(const char* fileName)
{
	GLMmodel* pmodel = glmReadOBJ((char*)fileName);
	if (!pmodel) exit(0);
	glmUnitize(pmodel);
	glmFacetNormals(pmodel);
	glmVertexNormals(pmodel, 90.0);

	return pmodel;
}

void DrawingHelpers::DrawModel(GLMmodel* pmod,double length, double width, double height, double x, double y,double z, double heading, double pitch , double roll )
{
	if (pmod)
	{
		if(!glIsEnabled(GL_LIGHTING))
			  glEnable(GL_LIGHTING);

		glPushMatrix();
		glTranslated(x,y,z);
		glRotated(heading*RAD2DEG,0.0, 0.0, 1.0);
		glRotated(pitch*RAD2DEG,0.0, 1.0, 0.0);
		glRotated(roll*RAD2DEG,1.0, 0.0, 0.0);

		glScaled(length, width, height);
		glmDraw(pmod, GLM_FLAT | GLM_MATERIAL );
		glPopMatrix();

		glDisable(GL_LIGHTING);
	}
}

void DrawingHelpers::DrawFilledEllipse(float x, float y, float z, float width, float height)
{
	glDisable(GL_LIGHTING);
	glBegin(GL_TRIANGLE_FAN);
		//All triangles fan out starting with this point
		glVertex3f (x,y,z);
		for (float i = 0; i &lt;=M_PI*2*RAD2DEG; i+=0.1)
		{
			glVertex3f(x + width*cos(i), y+height*sin(i), z);
		}
	glEnd();
	glEnable(GL_LIGHTING);
}

void DrawingHelpers::DrawWideEllipse(float x, float y, float z, float outer_width, float outer_height,
		float inner_width,float color[3])
{
	//std::vector&lt;WayPoint&gt; ellipse_points;
	glColor3f(color[0], color[1], color[2]);
	GPSPoint p1 = GPSPoint(x + outer_width*cos(0),y + outer_height*sin(0),z,0);
	GPSPoint p2 = p1;
	for (float i = 0.1; i &lt;= M_PI*2 + 0.1; i+=0.1)
	{
		//ellipse_points.push_back(WayPoint(x + outer_width*cos(i), y+outer_height*sin(i), z, 0));
		p2.x = x + outer_width*cos(i);
		p2.y = y + outer_height*sin(i);
		p2.z = z;

		DrawLinePoygonline(p1,p2, outer_width - inner_width);
		p1 = p2;

	}

	//DrawWidePath(ellipse_points, z, outer_width - inner_width,color);
}

void DrawingHelpers::DrawSimpleEllipse(float x, float y, float z, float outer_width, float outer_height)
{
	glBegin(GL_LINE_STRIP);
	for (float jj = 0; jj &lt;=M_PI*2.0; jj+=0.1)
	{
		glVertex3f(x + outer_width*cos(jj), y+ outer_height*sin(jj),z);
	}
	glEnd();
}

void DrawingHelpers::DrawPedal(float x, float y, float z, float width, float height, float inner_height, float color[3])
{
	POINT2D pa, pb, pc, pd;
	double w2 = width/2.0;
	double h2 = height/2.0;

	pa.x = x - w2;
	pa.y = y - h2;

	pb.x = x + w2;
	pb.y = y - h2;

	pc.x = x + w2;
	pc.y = y + h2;

	pd.x = x - w2;
	pd.y = y + h2;

	glBegin(GL_LINE_LOOP);
	  glVertex3f(pa.x, pa.y, z);
	  glVertex3f(pb.x, pb.y, z);
	  glVertex3f(pc.x, pc.y, z);
	  glVertex3f(pd.x, pd.y, z);
	glEnd();

	GPSPoint p1(x, y + h2, z, 0);
	GPSPoint p2(x, y + h2 - inner_height, z, 0);

	glColor3f(color[0], color[1], color[2]);
	DrawLinePoygonline(p1,p2,w2);

}

} /* namespace Graphics */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/src/MainWindowWrapper.cpp" new_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/src/MainWindowWrapper.cpp">
				<diff>@@ -8,7 +8,7 @@
 #include &quot;MainWindowWrapper.h&quot;
 #include &quot;DrawingHelpers.h&quot;
 #include &lt;iostream&gt;
-#include &lt;math.h&gt;
+#include &lt;cmath&gt;
 #include &quot;UtilityH.h&quot;
 #include &quot;GL/freeglut_ext.h&quot;
 
</diff>
				<old_file>/*
 * MainWindowWrapper.cpp
 *
 *  Created on: May 31, 2016
 *      Author: hatem
 */

#include &quot;MainWindowWrapper.h&quot;
#include &quot;DrawingHelpers.h&quot;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
#include &quot;UtilityH.h&quot;
#include &quot;GL/freeglut_ext.h&quot;

using namespace std;
using namespace UtilityHNS;
#include &quot;MatrixOperations.h&quot;

namespace Graphics {

WindowParams MainWindowWrapper::m_params;
DisplayParams MainWindowWrapper::m_DisplayParam;

WindowParams::WindowParams()
{
	title = &quot;Simple Simulator&quot;;

	x = 10;
	y = 10;
	w = 1200;
	h = 800;
	info_ratio = 0.25;

	UI_CONST.GAP = 20;
	UI_CONST.MAX_ZOOM = 600000.0;
	UI_CONST.MIN_ZOOM = 2.01;
	UI_CONST.INIT_ZOOM = 7.0;
	UI_CONST.FOLLOW_CONST_ZOOM = 2.5;

	ReCalcSimuWindow();

	bNew = true;
	bGPU = true;
}

void WindowParams::ReCalcSimuWindow()
{
	info_window.x = w*(1.0-info_ratio) - UI_CONST.GAP;
	info_window.y = UI_CONST.GAP;
	info_window.w = w*info_ratio;
	info_window.h = h - 2.0*UI_CONST.GAP;

	simu_window.x = UI_CONST.GAP;
	simu_window.y = UI_CONST.GAP;
	simu_window.w = w - UI_CONST.GAP * 3 - info_window.w;
	simu_window.h = h - UI_CONST.GAP * 2;
}

DisplayParams::DisplayParams()
{

	prev_x = prev_y = -999999;
	currRotationZ = currRotationX = currRotationY  = 0;

	zoom = 15;
	centerRotX = 5;
	centerRotY = 5;

	eye[0] = 0.0; eye[1] = 0.0; eye[2] = zoom;
	at[0] = 0.0; at[1] = 0.0; at[2] = 0.0;
	up[0] = 0.0; up[1] = 1.0; up[2] = 0.0;

	bDisplayMode = DISPLAY_TOP_FREE;

	bLeftDown =	bRightDown = bCenterDown = false;;

	prespective_z   = 100;
	prespective_fov = 45;

	translateX = 5;
	translateY = 5;

	actualViewX = 0;
	actualViewY = 0;

	bFullScreen = false;

	bSelectPosition = 0;
	StartPos[0] = StartPosFinal[0] = 0;
	StartPos[1] = StartPosFinal[1] = 0;
	StartPos[2] = StartPosFinal[2] = 0;
	GoalPos[0] = GoalPosFinal[0] = 0;
	GoalPos[1] = GoalPosFinal[1] = 0;
	GoalPos[2] = GoalPosFinal[1] = 0;
	SimulatedCarPos[0] = SimulatedCarPos[1] = SimulatedCarPos[2] = 0;

}

int MainWindowWrapper::m_MainWindow = 0;
int MainWindowWrapper::m_SimuWindow = 0;
int MainWindowWrapper::m_InfoWindow = 0;
int MainWindowWrapper::m_PopupMenu = 0;
DrawObjBase* MainWindowWrapper::m_DrawAndControl = 0;

MainWindowWrapper::MainWindowWrapper(DrawObjBase* pDraw)
{
	m_DrawAndControl = pDraw;
}

MainWindowWrapper::~MainWindowWrapper(){}

void MainWindowWrapper::CleanUp()
{
	if(m_DrawAndControl)
		delete m_DrawAndControl;
}

void MainWindowWrapper::InitOpenGLWindow(int argc, char** argv)
{
	if(m_params.bGPU)
		glutInitDisplayMode(GLUT_RGBA | GLUT_MULTISAMPLE);
	else
		glutInitDisplayMode(GLUT_RGB | GLUT_DEPTH | GLUT_SINGLE);
	glutInitWindowSize(m_params.w, m_params.h );
	glutInitWindowPosition(m_params.x, m_params.y);
	glutInit(&amp;argc, argv);




	m_MainWindow = glutCreateWindow(m_params.title.c_str());
	glutReshapeFunc(MainWindowWrapper::MainReshape);
	glutDisplayFunc(MainWindowWrapper::MainDisplay);
	glutKeyboardFunc(MainWindowWrapper::KeyboardExitCommand);


	m_SimuWindow = glutCreateSubWindow(m_MainWindow, m_params.simu_window.x, m_params.simu_window.y, m_params.simu_window.w, m_params.simu_window.h);
	glutReshapeFunc(MainWindowWrapper::SimuReshape);
	glutDisplayFunc(MainWindowWrapper::SimuDisplay);
	glutMotionFunc(MainWindowWrapper::MouseMove);
	glutMouseFunc(MainWindowWrapper::MouseCommand);
	glutKeyboardFunc(MainWindowWrapper::KeyboardCommand);
	glutSpecialFunc(MainWindowWrapper::KeyboardSpecialCommand);
	if(m_DrawAndControl)
		m_DrawAndControl-&gt;LoadMaterials();
	CreateRightClickMenu();

	m_InfoWindow = glutCreateSubWindow(m_MainWindow, m_params.info_window.x, m_params.info_window.y, m_params.info_window.w, m_params.info_window.h);
	glutReshapeFunc(MainWindowWrapper::InfoReshape);
	glutDisplayFunc(MainWindowWrapper::InfoDisplay);
	glutKeyboardFunc(MainWindowWrapper::KeyboardExitCommand);

	//RedisplayAll();
	glutPostRedisplay();

	KeyboardCommand('f', 0,0);

	atexit(CleanUp);

	glutMainLoop();
}

void MainWindowWrapper::InitLighting()
{
	float light_ambient[] = { 0.5,1.0, 0.5, 0.0 };
	float defuse[] = {1.0, 1.0, 1.0,1.0};
	float mat_specular[] = { 1.0, 1.0, 1.0, 0.0 };
	float mat_shininess[] = { 50.0 };
	//float light_position[4] = { 0.0, 0.0, 20.0, 0.0 };
	glMaterialfv(GL_FRONT_AND_BACK, GL_DIFFUSE, defuse);
	glMaterialfv(GL_FRONT_AND_BACK, GL_AMBIENT, light_ambient);
	glMaterialfv(GL_FRONT_AND_BACK, GL_SPECULAR, mat_specular);
	glMaterialfv(GL_FRONT_AND_BACK, GL_SHININESS, mat_shininess);
	//glLightfv(GL_LIGHT0, GL_POSITION, light_position);
	glEnable(GL_LIGHTING);
	glEnable(GL_LIGHT0);
	glEnable(GL_COLOR_MATERIAL);
	glEnable(GL_DEPTH_TEST);
	glShadeModel(GL_SMOOTH);
}

void MainWindowWrapper::UpdateParams(const WindowParams&amp; params, const DisplayParams&amp; display_params)
{
	m_params = params;
	m_DisplayParam = display_params;
	FromScreenToModelCoordinate(m_params.simu_window.w/2.0, m_params.simu_window.h/2.0,
				m_DisplayParam.initScreenToCenterMargin[0], m_DisplayParam.initScreenToCenterMargin[1]);
}

void MainWindowWrapper::MainReshape(int width,  int height)
{
	m_params.w = width;
	m_params.h = height;
	m_params.ReCalcSimuWindow();

	glViewport(0,0, m_params.w, m_params.h);
	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
	gluOrtho2D(0, m_params.w, m_params.h, 0);
	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();

	glutPostWindowRedisplay(m_InfoWindow);
	glutPostWindowRedisplay(m_SimuWindow);
}

void MainWindowWrapper::SimuReshape(int width,  int height)
{
	glutPositionWindow(m_params.simu_window.x, m_params.simu_window.y);
	glutReshapeWindow(m_params.simu_window.w, m_params.simu_window.h);

	glViewport(0,0, m_params.simu_window.w, m_params.simu_window.h);

	//this should rely on the map not the window
	double y_max = sqrt(pow(m_params.simu_window.w,2) + pow(m_params.simu_window.h,2))/2.0;
	if(y_max &gt; 0.05 &amp;&amp; y_max &lt; (m_params.simu_window.w*m_params.simu_window.h))
		m_DisplayParam.prespective_z = y_max;

	m_DisplayParam.prespective_z = 10000;

	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
	double aspect_ratio = (double)m_params.simu_window.w/(double)m_params.simu_window.h;
//	if(aspect_ratio &lt; m_params.simu_window.h/m_params.simu_window.w)
//		aspect_ratio = m_params.simu_window.h/m_params.simu_window.w;

	gluPerspective(m_DisplayParam.prespective_fov,aspect_ratio,0.05,m_DisplayParam.prespective_z);
	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();

	//double x = 0, y =0;

	if(m_DisplayParam.bDisplayMode == DISPLAY_FOLLOW &amp;&amp; m_DrawAndControl)
	{
//			m_DisplayParam.eye[0] = m_DrawAndControl-&gt;m_followX-m_DisplayParam.translateX;
//			m_DisplayParam.eye[1] = m_DrawAndControl-&gt;m_followY-m_DisplayParam.translateY;
//			m_DisplayParam.at[0] = m_DrawAndControl-&gt;m_followX-m_DisplayParam.translateX;
//			m_DisplayParam.at[1] = m_DrawAndControl-&gt;m_followY-m_DisplayParam.translateY;
		m_DisplayParam.eye[0] = m_DisplayParam.centerRotX;
		m_DisplayParam.eye[1] = m_DisplayParam.centerRotY;
		m_DisplayParam.at[0] = m_DisplayParam.centerRotX;
		m_DisplayParam.at[1] = m_DisplayParam.centerRotY;
	}


	gluLookAt(m_DisplayParam.eye[0], m_DisplayParam.eye[1], m_DisplayParam.zoom,
			m_DisplayParam.at[0], m_DisplayParam.at[1], m_DisplayParam.at[2],
			m_DisplayParam.up[0], m_DisplayParam.up[1],m_DisplayParam.up[2]);

	InitLighting();

}

void MainWindowWrapper::FromScreenToModelCoordinate(int sx, int sy, double&amp; modelX, double&amp; modelY)
{
	double whole = (double)(m_params.simu_window.w + m_params.simu_window.h)/2.0;
	double actualViewX = tan(m_DisplayParam.prespective_fov*DEG2RAD) * m_DisplayParam.zoom / whole;

	modelX = sx * actualViewX ;
	modelY = sy * actualViewX ;
}

void MainWindowWrapper::FromModelToScreenCoordinate(double modelX, double modelY, int&amp; sx, int&amp; sy)
{
	double actualViewX = tan(m_DisplayParam.prespective_fov*DEG2RAD) * m_DisplayParam.zoom / m_params.simu_window.w;

	sx = modelX / actualViewX ;
	sy = modelY / actualViewX ;
}

void MainWindowWrapper::SimuDisplay()
{

	//glClearColor(1,1,1,0);
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

	if(m_DisplayParam.bDisplayMode == DISPLAY_FOLLOW &amp;&amp; m_DrawAndControl)
	{
		//glTranslated(-m_DisplayParam.translateX, -m_DisplayParam.translateY, 0);
		m_DisplayParam.centerRotX = m_DrawAndControl-&gt;m_followX;
		m_DisplayParam.centerRotY = m_DrawAndControl-&gt;m_followY;


		int yaw = (m_DisplayParam.currRotationZ/8)%360;
		int roll = (m_DisplayParam.currRotationX/8)%360;
		int pitch = (m_DisplayParam.currRotationY/8)%360;

		glTranslated(m_DisplayParam.centerRotX, m_DisplayParam.centerRotY, 0);
		glRotated(yaw, 0,0,1);
		glRotated(roll, 1,0,0);
		glRotated(pitch, 0,1,0);
		glTranslated(-m_DisplayParam.centerRotX, -m_DisplayParam.centerRotY, 0);
	}
	else if(m_DisplayParam.bDisplayMode == DISPLAY_FREE)
	{
		glTranslated(-m_DisplayParam.translateX, -m_DisplayParam.translateY, 0);

		int yaw = (m_DisplayParam.currRotationZ/8)%360;
		int roll = (m_DisplayParam.currRotationX/8)%360;
		int pitch = (m_DisplayParam.currRotationY/8)%360;

		glTranslated(m_DisplayParam.centerRotX, m_DisplayParam.centerRotY, 0);
		glRotated(yaw, 0,0,1);
		glRotated(roll, 1,0,0);
		glRotated(pitch, 0,1,0);
		glTranslated(-m_DisplayParam.centerRotX, -m_DisplayParam.centerRotY, 0);
	}
	else if(m_DisplayParam.bDisplayMode == DISPLAY_TOP_FREE)
	{
		glTranslated(-m_DisplayParam.translateX, -m_DisplayParam.translateY, 0);

		int yaw = (m_DisplayParam.currRotationZ/8)%360;
		//int roll = (m_DisplayParam.currRotationX/8)%360;
		//int pitch = (m_DisplayParam.currRotationY/8)%360;


		glTranslated(m_DisplayParam.centerRotX, m_DisplayParam.centerRotY, 0);
		glRotated(yaw, 0,0,1);
		//glRotated(roll, 1,0,0);
		//glRotated(pitch, 0,1,0);
		glTranslated(-m_DisplayParam.centerRotX, -m_DisplayParam.centerRotY, 0);
	}


//	glPushMatrix();
//	glTranslated(5, 5, 0);
//	glutSolidTeapot(3);
//	glPopMatrix();

//

	DrawingHelpers::DrawCustomOrigin(m_DisplayParam.centerRotX, m_DisplayParam.centerRotY, 0, 0, 0, 0, 2.5 );

	if(m_DrawAndControl)
		m_DrawAndControl-&gt;DrawSimu();
	else
		DrawingHelpers::DrawGrid(m_DisplayParam.centerRotX-5, m_DisplayParam.centerRotY-5, 10, 10, 1);

	int yaw = (m_DisplayParam.currRotationZ/8)%360;
	PlannerHNS::Mat3 rotationMat(-yaw*DEG2RAD);
	PlannerHNS::Mat3 translationMat(m_DisplayParam.centerRotX, m_DisplayParam.centerRotY);
	PlannerHNS::Mat3 invTranslationMat(-m_DisplayParam.centerRotX, -m_DisplayParam.centerRotY);

	if(m_DisplayParam.bSelectPosition == 1)
	{
		double sx=0, sy=0;
		FromScreenToModelCoordinate(m_DisplayParam.StartPos[0]-m_params.simu_window.w/2.0,
				m_params.simu_window.h/2.0 - m_DisplayParam.StartPos[1],sx,sy);

		PlannerHNS::GPSPoint sp(sx+m_DisplayParam.translateX, sy+m_DisplayParam.translateY, 0, 0);
		sp = translationMat * sp;
		sp = rotationMat * sp;
		sp = invTranslationMat  * sp;
		m_DisplayParam.StartPosFinal[0] = sp.x;
		m_DisplayParam.StartPosFinal[1] = sp.y;
		m_DisplayParam.StartPosFinal[2] = m_DisplayParam.StartPos[2];

	}
	else if(m_DisplayParam.bSelectPosition == 2)
	{
		double gx=0,gy=0;
		FromScreenToModelCoordinate(m_DisplayParam.GoalPos[0]-m_params.simu_window.w/2.0,
						m_params.simu_window.h/2.0 - m_DisplayParam.GoalPos[1],gx,gy);

		PlannerHNS::GPSPoint gp(gx+m_DisplayParam.translateX, gy+m_DisplayParam.translateY, 0, m_DisplayParam.GoalPos[2]);
		gp = translationMat * gp;
		gp = rotationMat * gp;
		gp = invTranslationMat * gp;
		m_DisplayParam.GoalPosFinal[0] = gp.x;
		m_DisplayParam.GoalPosFinal[1] = gp.y;
		m_DisplayParam.GoalPosFinal[2] = m_DisplayParam.GoalPos[2];
	}
	else if(m_DisplayParam.bSelectPosition == 3)
	{
		double x=0,y=0;
		FromScreenToModelCoordinate(m_DisplayParam.SimulatedCarPos[0]-m_params.simu_window.w/2.0,
						m_params.simu_window.h/2.0 - m_DisplayParam.SimulatedCarPos[1],x,y);

		PlannerHNS::GPSPoint gp(x+m_DisplayParam.translateX, y+m_DisplayParam.translateY, 0, m_DisplayParam.SimulatedCarPos[2]);
		gp = translationMat * gp;
		gp = rotationMat * gp;
		gp = invTranslationMat * gp;
		m_DisplayParam.SimulatedCarPosFinal[0] = gp.x;
		m_DisplayParam.SimulatedCarPosFinal[1] = gp.y;
		m_DisplayParam.SimulatedCarPosFinal[2] = m_DisplayParam.SimulatedCarPos[2];
	}

	glPushMatrix();
	DrawingHelpers::DrawArrow(m_DisplayParam.StartPosFinal[0], m_DisplayParam.StartPosFinal[1], m_DisplayParam.StartPosFinal[2]);
	DrawingHelpers::DrawArrow(m_DisplayParam.GoalPosFinal[0], m_DisplayParam.GoalPosFinal[1], m_DisplayParam.GoalPosFinal[2]);
	DrawingHelpers::DrawArrow(m_DisplayParam.SimulatedCarPosFinal[0], m_DisplayParam.SimulatedCarPosFinal[1], m_DisplayParam.SimulatedCarPosFinal[2]);
	glPopMatrix();


	glutSwapBuffers();
}

void MainWindowWrapper::InfoReshape(int width,  int height)
{
	glutPositionWindow(m_params.info_window.x, m_params.info_window.y);
	glutReshapeWindow(m_params.info_window.w, m_params.info_window.h);

	glViewport(0,0, m_params.info_window.w, m_params.info_window.h);
	glMatrixMode(GL_PROJECTION);
	glLoadIdentity();
	gluOrtho2D(0, m_params.info_window.w, m_params.info_window.h, 0);
	glMatrixMode(GL_MODELVIEW);
	glLoadIdentity();

	//cout &lt;&lt; &quot;Info: width = &quot; &lt;&lt; width &lt;&lt; &quot;, height = &quot; &lt;&lt; height &lt;&lt; &quot;, x=&quot; &lt;&lt;m_params.info_window.x &lt;&lt; &quot;, y=&quot; &lt;&lt;m_params.info_window.y&lt;&lt;  endl;
}

void MainWindowWrapper::MainDisplay()
{

	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

	glDisable(GL_LIGHTING);
	glPushMatrix();
	glBegin(GL_POLYGON);
	glColor3f(0.1,0.1,0.1);
	glVertex2i(0, m_params.h);
	glVertex2i(m_params.w,m_params.h);
	glColor3f(0.9,0.9,0.9);
	glVertex2i(m_params.w, 0);
	glVertex2i(0,0);
	glEnd();
	glPopMatrix();
	glEnable(GL_LIGHTING);

	glPushMatrix();
	glColor3f(0.9, 0.2, 0.2);
	glTranslated(m_params.simu_window.x, m_params.UI_CONST.GAP-1, 0);
	DrawingHelpers::DrawString(0, 0, GLUT_BITMAP_TIMES_ROMAN_24, (char*)&quot;Simulation View&quot;);
	glPopMatrix();

	glPushMatrix();
	glColor3f(0.9, 0.2, 0.2);
	glTranslated(m_params.info_window.x, m_params.UI_CONST.GAP-1, 0);
	DrawingHelpers::DrawString(0, 0, GLUT_BITMAP_TIMES_ROMAN_24, (char*)&quot;Info View&quot;);
	glPopMatrix();

	glutSwapBuffers();
}

void MainWindowWrapper::InfoDisplay()
{
	glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

	glDisable(GL_LIGHTING);
	glPushMatrix();
	glBegin(GL_POLYGON);
	glColor3f(0.1,0.1,0.1);
	glVertex2i(0,0);
	glVertex2i(0,m_params.info_window.h);
	glColor3f(0.3,0.3,0.3);
	glVertex2i(m_params.info_window.w,m_params.info_window.h);
	glVertex2i(m_params.info_window.w,0);
	glEnd();
	glPopMatrix();
	glEnable(GL_LIGHTING);

	//cout &lt;&lt; &quot;InfoDisplay&quot; &lt;&lt; endl;

	if(m_DisplayParam.bSelectPosition == 1)
	{
		glPushMatrix();
		glColor3f(0.9, 0.2, 0.2);
		glTranslated(10, m_params.info_window.h - 40, 0);
		DrawingHelpers::DrawString(0, 0, GLUT_BITMAP_TIMES_ROMAN_24, (char*)&quot;Start Position&quot;);
		glPopMatrix();
	}
	else if(m_DisplayParam.bSelectPosition == 2)
	{
		glPushMatrix();
		glColor3f(0.9, 0.2, 0.2);
		glTranslated(10, m_params.info_window.h - 40, 0);
		DrawingHelpers::DrawString(0, 0, GLUT_BITMAP_TIMES_ROMAN_24, (char*)&quot;Goal Position&quot;);
		glPopMatrix();
	}
	else if(m_DisplayParam.bSelectPosition == 3)
	{
		glPushMatrix();
		glColor3f(0.9, 0.2, 0.2);
		glTranslated(10, m_params.info_window.h - 40, 0);
		DrawingHelpers::DrawString(0, 0, GLUT_BITMAP_TIMES_ROMAN_24, (char*)&quot;Simulation Positions&quot;);
		glPopMatrix();
	}

	if(m_DrawAndControl)
		m_DrawAndControl-&gt;DrawInfo(m_params.info_window.w/2, m_params.info_window.h/2, m_params.info_window.w, m_params.info_window.h);

	glutSwapBuffers();
}

void MainWindowWrapper::RedisplayAll()
{
//	glutSetWindow(m_InfoWindow);
//	glutPostRedisplay();
//	glutSetWindow(m_SimuWindow);
//	glutPostRedisplay();
//	glutSetWindow(m_MainWindow);
//	glutPostRedisplay();
}

void MainWindowWrapper::MouseMove(int x, int y)
{
	if(m_DisplayParam.bSelectPosition == 1)
	{
		if(m_DisplayParam.bLeftDown)
		{
			m_DisplayParam.StartPos[2] = atan2(m_DisplayParam.StartPos[1] - y, x - m_DisplayParam.StartPos[0]);
		}
	}
	else if(m_DisplayParam.bSelectPosition == 2)
	{
		if(m_DisplayParam.bLeftDown)
		{
			m_DisplayParam.GoalPos[2] = atan2(m_DisplayParam.GoalPos[1] - y, x - m_DisplayParam.GoalPos[0]);
		}
	}
	else if(m_DisplayParam.bSelectPosition == 3)
	{
		if(m_DisplayParam.bLeftDown)
		{
			m_DisplayParam.SimulatedCarPos[2] = atan2(m_DisplayParam.SimulatedCarPos[1] - y, x - m_DisplayParam.SimulatedCarPos[0]);
		}
	}
	else if(m_DisplayParam.bLeftDown)
	{
		m_DisplayParam.currRotationZ += x-m_DisplayParam.prev_x;
		m_DisplayParam.prev_x = x;

		//if(m_DisplayParam.bFreeDisplay)
		{
			double zdir = (m_DisplayParam.currRotationZ/8)%360 * DEG2RAD;
			double xRatio = cos(zdir);
			double yRatio = sin(zdir);

			m_DisplayParam.currRotationX += (y-m_DisplayParam.prev_y) * xRatio;
			m_DisplayParam.currRotationY += (m_DisplayParam.prev_y - y) * yRatio;

			m_DisplayParam.prev_y = y;
		}
	}
	else if (m_DisplayParam.bRightDown)
	{
	}
	else if (m_DisplayParam.bCenterDown)
	{

		m_DisplayParam.actualViewX = (tan(m_DisplayParam.prespective_fov/2.0*DEG2RAD) * m_DisplayParam.zoom * 2.0)/m_params.simu_window.w;
		m_DisplayParam.actualViewY = (tan(m_DisplayParam.prespective_fov/2.0*DEG2RAD) * m_DisplayParam.zoom * 2.0)/m_params.simu_window.h;

		m_DisplayParam.translateX += (m_DisplayParam.prev_x-x)*m_DisplayParam.actualViewX;
		m_DisplayParam.translateY += (y-m_DisplayParam.prev_y)*m_DisplayParam.actualViewY;

		m_DisplayParam.prev_x = x;
		m_DisplayParam.prev_y = y;

	}
	else
	{

	}

}

void MainWindowWrapper::MouseCommand(int button, int state, int x, int y)
{
	//cout &lt;&lt; x &lt;&lt; &quot;, &quot; &lt;&lt; y &lt;&lt; endl;
	if(m_DisplayParam.bSelectPosition == 1)
	{
		if(button == 0 &amp;&amp; state == 0 &amp;&amp; !m_DisplayParam.bLeftDown)
		{
			m_DisplayParam.bLeftDown = true;
			m_DisplayParam.StartPos[0] = x;
			m_DisplayParam.StartPos[1] = y;
			//cout &lt;&lt; &quot;Left Down&quot; &lt;&lt; endl;
		}
		else if(button == 0 &amp;&amp; state == 1)
		{
			m_DisplayParam.bLeftDown = false;
			m_DisplayParam.bSelectPosition = 0;
		}
	}
	else if(m_DisplayParam.bSelectPosition == 2)
	{
		if(button == 0 &amp;&amp; state == 0 &amp;&amp; !m_DisplayParam.bLeftDown)
		{
			m_DisplayParam.bLeftDown = true;
			m_DisplayParam.GoalPos[0] = x;
			m_DisplayParam.GoalPos[1] = y;
			//cout &lt;&lt; &quot;Left Down&quot; &lt;&lt; endl;
		}
		else if(button == 0 &amp;&amp; state == 1)
		{
			m_DisplayParam.bLeftDown = false;
			m_DisplayParam.bSelectPosition = 0;
			m_DrawAndControl-&gt;UpdatePlaneStartGoal(m_DisplayParam.StartPosFinal[0],
					m_DisplayParam.StartPosFinal[1], m_DisplayParam.StartPosFinal[2],
					m_DisplayParam.GoalPosFinal[0], m_DisplayParam.GoalPosFinal[1], m_DisplayParam.GoalPosFinal[2]);
		}
	}
	else if(m_DisplayParam.bSelectPosition == 3)
	{
//		if(button == 0 &amp;&amp; state == 1)
//		{
//			int yaw = (m_DisplayParam.currRotationZ/8)%360;
//			PlannerHNS::Mat3 rotationMat(-yaw*DEG2RAD);
//			PlannerHNS::Mat3 translationMat(m_DisplayParam.centerRotX, m_DisplayParam.centerRotY);
//			PlannerHNS::Mat3 invTranslationMat(-m_DisplayParam.centerRotX, -m_DisplayParam.centerRotY);
//
//			double gx=0,gy=0;
//			FromScreenToModelCoordinate(x-m_params.simu_window.w/2.0, m_params.simu_window.h/2.0 - y,gx,gy);
//
//			PlannerHNS::GPSPoint gp(gx+m_DisplayParam.translateX, gy+m_DisplayParam.translateY, 0, 0);
//			gp = translationMat * gp;
//			gp = rotationMat * gp;
//			gp = invTranslationMat * gp;
//
//			m_DisplayParam.bSelectPosition = 0;
//
//		}

		if(button == 0 &amp;&amp; state == 0 &amp;&amp; !m_DisplayParam.bLeftDown)
		{
			m_DisplayParam.bLeftDown = true;
			m_DisplayParam.SimulatedCarPos[0] = x;
			m_DisplayParam.SimulatedCarPos[1] = y;
			//cout &lt;&lt; &quot;Left Down&quot; &lt;&lt; endl;
		}
		else if(button == 0 &amp;&amp; state == 1)
		{
			m_DisplayParam.bLeftDown = false;
			m_DisplayParam.bSelectPosition = 0;
			m_DrawAndControl-&gt;AddSimulatedCarPos(m_DisplayParam.SimulatedCarPosFinal[0],
					m_DisplayParam.SimulatedCarPosFinal[1], m_DisplayParam.SimulatedCarPosFinal[2]);
		}
	}
	else if(button == 0 &amp;&amp; state == 0 &amp;&amp; !m_DisplayParam.bLeftDown)
	{
		m_DisplayParam.bLeftDown = true;
		m_DisplayParam.prev_x = x;
		m_DisplayParam.prev_y = y;
		//cout &lt;&lt; &quot;Left Down&quot; &lt;&lt; endl;
	}
	else if(button == 0 &amp;&amp; state == 1)
	{
		m_DisplayParam.bLeftDown = false;
	}
	else if(button == 2 &amp;&amp; state == 0 &amp;&amp; !m_DisplayParam.bRightDown)
	{
		m_DisplayParam.bRightDown = true;
		m_DisplayParam.prev_x = x;
		m_DisplayParam.prev_y = y;
		//cout &lt;&lt; &quot;Right Down&quot; &lt;&lt; endl;
	}
	else if(button == 2 &amp;&amp; state == 1)
	{
		m_DisplayParam.bRightDown = false;

	}
	else if(button == 1 &amp;&amp; state == 0 &amp;&amp; !m_DisplayParam.bCenterDown)
	{
		m_DisplayParam.bCenterDown = true;
		m_DisplayParam.prev_x = x;
		m_DisplayParam.prev_y = y;
		//cout &lt;&lt; &quot;Right Down&quot; &lt;&lt; endl;
	}
	else if(button == 1 &amp;&amp; state == 1)
	{
		m_DisplayParam.bCenterDown = false;

	}
	else if(button == 3)
	{
		m_DisplayParam.zoom-=1;
		if(m_DisplayParam.zoom &lt; 2)
			m_DisplayParam.zoom = 2;
	}
	else if (button == 4)
	{
		m_DisplayParam.zoom+=1;
		if(m_DisplayParam.zoom &gt; m_DisplayParam.prespective_z/10.0)
			m_DisplayParam.zoom = m_DisplayParam.prespective_z/10.0;
	}

	if(m_DrawAndControl)
		m_DrawAndControl-&gt;OnLeftClick(x,y);

}

void MainWindowWrapper::KeyboardExitCommand(unsigned char key, int x, int y)
{
	switch (key)
	{
	case 27:
		exit(0);
		break;
	}
}

void MainWindowWrapper::KeyboardCommand(unsigned char key, int x, int y)
{
	//cout &lt;&lt; &quot;Char : &quot; &lt;&lt; key &lt;&lt;  endl;
	switch (key)
	{
	case 27:
		exit(0);
		break;
	case 'e':
	{
			m_DisplayParam.bDisplayMode = DISPLAY_FREE;
			m_DisplayParam.translateX = 0;
			m_DisplayParam.translateY = 0;
	}
		break;
	case 'c':
	{
			m_DisplayParam.bDisplayMode = DISPLAY_FOLLOW;
	}
		break;
	case 't':
	{
			m_DisplayParam.bDisplayMode = DISPLAY_TOP_FREE;
	}
		break;
	case 'f':
	{
		if(m_DisplayParam.bFullScreen)
		{
			glutSetWindow(m_MainWindow);
			glutFullScreenToggle();
			m_DisplayParam.bFullScreen = false;
		}
		else
		{
			m_DisplayParam.bFullScreen = true;
		}
	}
		break;
	case 'r':
	{
		if(m_DrawAndControl)
			m_DrawAndControl-&gt;Reset();
	}
	break;
	case 'p':
	{
		if(m_DisplayParam.bSelectPosition == 1)
		{
			m_DisplayParam.bSelectPosition = 0;
		}
		else
		{
			m_DisplayParam.bSelectPosition = 1;
		}

	}
	break;
	case 'o':
	{
		if(m_DisplayParam.bSelectPosition == 2)
		{
			m_DisplayParam.bSelectPosition = 0;
		}
		else
		{
			m_DisplayParam.bSelectPosition = 2;
		}
	}
	break;
	case 'u':
	{
		if(m_DisplayParam.bSelectPosition == 3)
		{
			m_DisplayParam.bSelectPosition = 0;
		}
		else
		{
			m_DisplayParam.bSelectPosition = 3;
		}
	}
	break;
	}

	if(m_DrawAndControl)
		m_DrawAndControl-&gt;OnKeyboardPress(CHAR_KEY, key);
}

void MainWindowWrapper::KeyboardSpecialCommand(int key, int x, int y)
{
	//cout &lt;&lt; &quot;Control : &quot; &lt;&lt; key &lt;&lt; endl;
	switch (key)
	{
	case 101: // Up
	{
//		double prevAngle = angle;
//		angle += rand()%5;
//		//double a = circ_angle-&gt;CalcAngle(3.0*DEG2RAD);
//		angle = UtilityH::GetCircularAngle(prevAngle*DEG2RAD, angle*DEG2RAD) * RAD2DEG;
//		cout &lt;&lt; endl &lt;&lt; &quot;angle = &quot; &lt;&lt; angle &lt;&lt; endl;
	}
	break;
	case 103: //Down
	{
//		double prevAngle = angle;
//		angle -= rand()%5;
//		//double a = circ_angle-&gt;CalcAngle(357.0*DEG2RAD);
//		angle = UtilityH::GetCircularAngle(prevAngle*DEG2RAD, angle*DEG2RAD) * RAD2DEG;
//		cout &lt;&lt; &quot;angle = &quot; &lt;&lt; angle &lt;&lt; endl;
	}
	break;
	case 102: //Right
	{

	}
	break;
	case 100: //Left
	{

	}
	break;
	case 112: //left shift key
	{

	}
	break;
	case 114: //left Ctrl key
	{

	}
	break;
	case 113: //Right shift key
	{

	}
	break;
	case 115: // right Ctrl key
	{

	}
	break;
	case 116: //ALT key
	{

	}
	break;
	default:
		//m_RandomObstacle =0;
		break;
	}
}

void MainWindowWrapper::MenuCommand(int value)
{
	KeyboardCommand(value, 0,0);
}

void MainWindowWrapper::ProcessMenuStatus(int status, int x, int y)
{
	if (status != GLUT_MENU_IN_USE)
	{
		ModifyPopupMenu();
	}
}

void MainWindowWrapper::ModifyPopupMenu()
{
//	glutSetMenu(m_PopupMenu);
//
//	if(m_DisplayParam.bDisplayMode == DISPLAY_FOLLOW)
//		glutChangeToMenuEntry(5, &quot;&gt; Follow CAM(c)&quot;, 1004);
//	else if(m_DisplayParam.bDisplayMode == DISPLAY_TOP_FREE)
//		glutChangeToMenuEntry(6, &quot;&gt; Top CAM   (t)&quot;, 1005);
//	else if(m_DisplayParam.bDisplayMode == DISPLAY_FREE)
//		glutChangeToMenuEntry(7, &quot;&gt; Free CAM  (e)&quot;, 1006);

//	if(m_DisplayParam.bFullScreen)
//	{
//		glutChangeToMenuEntry(8, &quot;Hide V Window&quot;, 'h');
//	}
}

void MainWindowWrapper::CreateRightClickMenu()
{
	if(m_PopupMenu==0)
		m_PopupMenu = glutCreateMenu(MenuCommand);
	else
		glutSetMenu(m_PopupMenu);

	glutAddMenuEntry(&quot;Start/Stop  (s)&quot;, 's');
	glutAddMenuEntry(&quot;Restart     (r)&quot;, 'r');

	glutAddMenuEntry(&quot;------------&quot;, 0);

	glutAddMenuEntry(&quot;Full Screen (f)&quot;, 'f');
	glutAddMenuEntry(&quot;Follow CAM  (c)&quot;, 'c');
	glutAddMenuEntry(&quot;Top CAM     (t)&quot;, 't');
	glutAddMenuEntry(&quot;Free CAM    (e)&quot;, 'e');

	glutAddMenuEntry(&quot;------------&quot;, 0);

	glutAddMenuEntry(&quot;Start Pose  (p)&quot;, 0);
	glutAddMenuEntry(&quot;End   Pose  (o)&quot;, 0);
	glutAddMenuEntry(&quot;Add Sim Car (u)&quot;, 0);
	glutAddMenuEntry(&quot;Delete Sim Cars (n)&quot;, 0);
	glutAddMenuEntry(&quot;Save Sim Points(v)&quot;, 0);
	glutAddMenuEntry(&quot;Load Sim Points(l)&quot;, 0);

	glutAddMenuEntry(&quot;------------&quot;, 0);

	glutAddMenuEntry(&quot;Exit        (Esc)&quot;, 27);

	glutAttachMenu(GLUT_RIGHT_BUTTON);
	//glutMenuStatusFunc(ProcessMenuStatus);
}



} /* namespace Graphics */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/src/SimulatedTrajectoryFollower.cpp" new_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/src/SimulatedTrajectoryFollower.cpp">
				<diff>@@ -7,7 +7,7 @@
 
 #include &quot;SimulatedTrajectoryFollower.h&quot;
 #include &quot;PlanningHelpers.h&quot;
-#include &lt;math.h&gt;
+#include &lt;cmath&gt;
 #include &lt;stdlib.h&gt;
 #include &lt;iostream&gt;
 
</diff>
				<old_file>/*
 * SimulatedTrajectoryFollower.cpp
 *
 *  Created on: Jun 18, 2016
 *      Author: hatem
 */

#include &quot;SimulatedTrajectoryFollower.h&quot;
#include &quot;PlanningHelpers.h&quot;
#include &lt;math.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;iostream&gt;

using namespace PlannerHNS;
using namespace UtilityHNS;
using namespace std;


namespace SimulationNS
{

SimulatedTrajectoryFollower::SimulatedTrajectoryFollower()
{
	m_FollowingDistance = 0;
	m_LateralError 		= 0;
	m_PrevDesiredSteer	= 0;
	m_FollowAcceleration= 0;
	m_iPrevWayPoint 	= -1;
	m_iCalculatedIndex = 0;


	//m_pidSteer.Init(0.35, 0.01, 0.01); // for 5 m/s
	//m_pidSteer.Init(1.5, 0.00, 0.00); // for 3 m/s
	//m_pidSteer.Init(0.9, 0.1, 0.2); //for lateral error

}

void SimulatedTrajectoryFollower::Init(const ControllerParams&amp; params, const CAR_BASIC_INFO&amp; vehicleInfo)
{
	m_Params = params;
	m_VehicleInfo = vehicleInfo;
	m_pidSteer.Init(params.Steering_Gain.kP, params.Steering_Gain.kI, params.Steering_Gain.kD); // for 3 m/s
	m_pidSteer.Setlimit(vehicleInfo.max_steer_angle, -vehicleInfo.max_steer_angle);
	m_pidVelocity.Init(params.Velocity_Gain.kP, params.Velocity_Gain.kI, params.Velocity_Gain.kD);
}

SimulatedTrajectoryFollower::~SimulatedTrajectoryFollower()
{
}


void SimulatedTrajectoryFollower::PrepareNextWaypoint(const PlannerHNS::WayPoint&amp; CurPos, const double&amp; currVelocity, const double&amp; currSteering)
{
	m_CurrPos = CurPos;
	FindNextWayPoint(m_Path, m_CurrPos, currVelocity, m_FollowMePoint, m_PerpendicularPoint, m_LateralError, m_FollowingDistance);
}

void SimulatedTrajectoryFollower::UpdateCurrentPath(const std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path)
{
	m_Path = path;
}

bool SimulatedTrajectoryFollower::FindNextWayPoint(const std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path, const PlannerHNS::WayPoint&amp; state,
		const double&amp; velocity, PlannerHNS::WayPoint&amp; pursuite_point, PlannerHNS::WayPoint&amp; prep,
		double&amp; lateral_err, double&amp; follow_distance)
{
	if(path.size()==0) return false;

	follow_distance = m_Params.minPursuiteDistance;

//	int iWayPoint =  PlanningHelpers::GetClosestNextPointIndex(path, state);
//	m_iCalculatedIndex = iWayPoint;
////	if(m_iPrevWayPoint &gt;=0  &amp;&amp; m_iPrevWayPoint &lt; path.size() &amp;&amp; iWayPoint &lt; m_iPrevWayPoint)
////		iWayPoint = m_iPrevWayPoint;
//
//
//	m_iPrevWayPoint = iWayPoint;

	RelativeInfo info;
	PlanningHelpers::GetRelativeInfo(path, state, info);
	unsigned int point_index = 0;
	pursuite_point = PlanningHelpers::GetFollowPointOnTrajectory(path, info, follow_distance, point_index);
	prep = info.perp_point;
	lateral_err = info.perp_distance;
	m_iPrevWayPoint = info.iFront;

	return true;
}

int SimulatedTrajectoryFollower::SteerControllerUpdate(const PlannerHNS::VehicleState&amp; CurrStatus,
		const PlannerHNS::BehaviorState&amp; CurrBehavior, double&amp; desiredSteerAngle)
{
	if(m_Path.size()==0) return -1;

	//AdjustPID(CurrStatus.velocity, 18.0, m_Params.Gain);
	int ret = SteerControllerPart(m_CurrPos, m_FollowMePoint, m_LateralError, desiredSteerAngle);
	if(ret &lt; 0)
		desiredSteerAngle = m_PrevDesiredSteer;
	else
		m_PrevDesiredSteer = desiredSteerAngle;

	return ret;
}

int SimulatedTrajectoryFollower::SteerControllerPart(const PlannerHNS::WayPoint&amp; state, const PlannerHNS::WayPoint&amp; way_point,
		const double&amp; lateral_error, double&amp; steerd)
{
	double current_a = UtilityH::SplitPositiveAngle(state.pos.a);
	double target_a = atan2(way_point.pos.y - state.pos.y, way_point.pos.x - state.pos.x);

	double e =  UtilityH::SplitPositiveAngle(target_a - current_a);

	if(e &gt; M_PI_2 || e &lt; -M_PI_2)
		return -1;

	steerd = m_pidSteer.getPID(e);

	return 1;
}

int SimulatedTrajectoryFollower::VeclocityControllerUpdate(const double&amp; dt, const PlannerHNS::VehicleState&amp; CurrStatus,
		const PlannerHNS::BehaviorState&amp; CurrBehavior, double&amp; desiredVelocity)
{
	//desiredVelocity = CurrBehavior.maxVelocity;
	m_pidVelocity.Setlimit(CurrBehavior.maxVelocity, 0);
	double e = CurrBehavior.maxVelocity - CurrStatus.speed;

	desiredVelocity = m_pidVelocity.getPID(e);

	if(desiredVelocity &gt; CurrBehavior.maxVelocity)
		desiredVelocity = CurrBehavior.maxVelocity;
	else if (desiredVelocity &lt; 0)
		desiredVelocity = 0;
	return 1;
}


PlannerHNS::VehicleState SimulatedTrajectoryFollower::DoOneStep(const double&amp; dt, const PlannerHNS::BehaviorState&amp; behavior,
		const std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path, const PlannerHNS::WayPoint&amp; currPose,
		const PlannerHNS::VehicleState&amp; vehicleState, const bool&amp; bNewTrajectory)
{
	if(bNewTrajectory &amp;&amp; path.size() &gt; 0)
	{
		m_iPrevWayPoint = -1;
		UpdateCurrentPath(path);
	}

	PlannerHNS::VehicleState currState;

	if(behavior.state == PlannerHNS::FORWARD_STATE)
	{
		if(m_Path.size()&gt;0)
		{
			PrepareNextWaypoint(currPose, vehicleState.speed, vehicleState.steer);
			VeclocityControllerUpdate(dt, currState,behavior, currState.speed);
			SteerControllerUpdate(currState, behavior, currState.steer);

			//currState.speed = 5;
			//cout &lt;&lt; currState.speed &lt;&lt; endl;
			currState.shift = PlannerHNS::SHIFT_POS_DD;
		}
	}
	else if(behavior.state == PlannerHNS::STOPPING_STATE)
	{
		currState.speed = 0;
		currState.shift = PlannerHNS::SHIFT_POS_DD;
	}
	else
	{
		currState.speed = 0;
		currState.shift = PlannerHNS::SHIFT_POS_NN;
	}

	return currState;
}

} /* namespace SimulationNS */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/src/TrajectoryFollower.cpp" new_path="ros/src/computing/planning/common/lib/openplanner/op_simuh/src/TrajectoryFollower.cpp">
				<diff>@@ -7,7 +7,7 @@
 
 #include &quot;TrajectoryFollower.h&quot;
 #include &quot;PlanningHelpers.h&quot;
-#include &lt;math.h&gt;
+#include &lt;cmath&gt;
 #include &lt;stdlib.h&gt;
 #include &lt;iostream&gt;
 
</diff>
				<old_file>/*
 * TrajectoryFollower.cpp
 *
 *  Created on: Jun 18, 2016
 *      Author: hatem
 */

#include &quot;TrajectoryFollower.h&quot;
#include &quot;PlanningHelpers.h&quot;
#include &lt;math.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;iostream&gt;

using namespace PlannerHNS;
using namespace UtilityHNS;
using namespace std;


namespace SimulationNS
{

TrajectoryFollower::TrajectoryFollower()
{
	m_iNextTest = 0;
	m_bCalibrationMode = false;
	m_bEnableLog = false;
	m_WayPointsDensity = 1;
	m_bEndPath = false;
	m_FollowingDistance = 0;
	m_LateralError 		= 0;
	m_PrevDesiredSteer	= 0;
	m_FollowAcceleration= 0;
	m_iPrevWayPoint 	= -1;
	m_StartFollowDistance = 0;
	m_FollowAcc = 0.5;
	m_iCalculatedIndex = 0;
	UtilityH::GetTickCount(m_SteerDelayTimer);
	UtilityH::GetTickCount(m_VelocityDelayTimer);
}

void TrajectoryFollower::Init(const ControllerParams&amp; params, const CAR_BASIC_INFO&amp; vehicleInfo, bool bEnableLogs, bool bCalibration)
{
	m_bEnableLog = bEnableLogs;
	m_bCalibrationMode = bCalibration;
	if(m_bCalibrationMode)
		InitCalibration();

	m_Params = params;
	m_VehicleInfo = vehicleInfo;

	//m_pidSteer.Init(0.1, 0.005, 0.001); // for 5 m/s
	//m_pidSteer.Init(0.07, 0.02, 0.01); // for 3 m/s
	//m_pidSteer.Init(0.9, 0.1, 0.2); //for lateral error
	//m_pidVelocity.Init(0.1, 0.005, 0.1);
	m_lowpassSteer.Init(2, 100, 4);

	m_pidSteer.Init(params.Steering_Gain.kP, params.Steering_Gain.kI, params.Steering_Gain.kD); // for 3 m/s
	m_pidSteer.Setlimit(m_VehicleInfo.max_steer_angle, -m_VehicleInfo.max_steer_angle);
	m_pidVelocity.Init(params.Velocity_Gain.kP, params.Velocity_Gain.kI, params.Velocity_Gain.kD);
}

TrajectoryFollower::~TrajectoryFollower()
{
	if(m_bEnableLog)
	{
		DataRW::WriteLogData(UtilityH::GetHomeDirectory()+DataRW::LoggingMainfolderName+DataRW::ControlLogFolderName, &quot;ControlLog&quot;,
				&quot;time,X,Y,heading, Target, error,LateralError,SteerBeforLowPass,Steer,iIndex, pathSize&quot;,
				m_LogData);

		DataRW::WriteLogData(UtilityH::GetHomeDirectory()+DataRW::LoggingMainfolderName+DataRW::ControlLogFolderName, &quot;SteeringCalibrationLog&quot;,
				&quot;time, reset, start A, end A, desired A, dt, vel&quot;, m_SteerCalibrationData);

		DataRW::WriteLogData(UtilityH::GetHomeDirectory()+DataRW::LoggingMainfolderName+DataRW::ControlLogFolderName, &quot;VelocityCalibrationLog&quot;,
				&quot;time, reset, start V, end V, desired V, dt, steering&quot;, m_VelocityCalibrationData);

		DataRW::WriteLogData(UtilityH::GetHomeDirectory()+DataRW::LoggingMainfolderName+DataRW::ControlLogFolderName, &quot;SteeringPIDLog&quot;,m_pidSteer.ToStringHeader(), m_LogSteerPIDData );
		DataRW::WriteLogData(UtilityH::GetHomeDirectory()+DataRW::LoggingMainfolderName+DataRW::ControlLogFolderName, &quot;VelocityPIDLog&quot;,m_pidVelocity.ToStringHeader(), m_LogVelocityPIDData );
	}
}

void TrajectoryFollower::PrepareNextWaypoint(const PlannerHNS::WayPoint&amp; CurPos, const double&amp; currVelocity, const double&amp; currSteering)
{
	WayPoint pred_point = CurPos;
	m_ForwardSimulation = pred_point;

	double nIterations = m_Params.SteeringDelay/0.01; //angle error
	//double nIterations = 0.5/0.01; //lateral  error
	for(unsigned int i=0; i&lt; nIterations; i++)
	{
		PredictMotion(m_ForwardSimulation.pos.x, m_ForwardSimulation.pos.y, m_ForwardSimulation.pos.a, currSteering,currVelocity, m_VehicleInfo.wheel_base, 0.01);
	}

	m_CurrPos = m_ForwardSimulation;

	bool ret = FindNextWayPoint(m_Path, pred_point, currVelocity, m_FollowMePoint, m_PerpendicularPoint, m_LateralError, m_FollowingDistance);
	if(ret)
	{
		m_DesPos = m_FollowMePoint;
	//	m_DesPos.a = m_pDesAngCir-&gt;CalcAngle(m_DesPos.a);
	}
}

void TrajectoryFollower::UpdateCurrentPath(const std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path)
{
	//BehaviorsNS::MappingHelpers::ConvertFromWaypointsToVectorPath(path, m_Path);
	if(path.size()&gt;0)
		m_WayPointsDensity = hypot(path.at(1).pos.y - path.at(0).pos.y, path.at(1).pos.x - path.at(0).pos.x);

	m_Path = path;
}

bool TrajectoryFollower::FindNextWayPoint(const std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path, const PlannerHNS::WayPoint&amp; state,
		const double&amp; velocity, PlannerHNS::WayPoint&amp; pursuite_point, PlannerHNS::WayPoint&amp; prep,
		double&amp; lateral_err, double&amp; follow_distance)
{
	if(path.size()==0) return false;

	follow_distance = fabs(velocity) * (m_Params.SteeringDelay+0.5);
	if(follow_distance &lt; m_Params.minPursuiteDistance)
		follow_distance = m_Params.minPursuiteDistance;

	RelativeInfo info;
	PlanningHelpers::GetRelativeInfo(path, state, info);
	unsigned int point_index = 0;
	pursuite_point = PlanningHelpers::GetFollowPointOnTrajectory(path, info, follow_distance, point_index);
	prep = info.perp_point;
	lateral_err = info.perp_distance;
	m_iPrevWayPoint = info.iFront;

	double d_critical = (-velocity*velocity)/2.0*m_VehicleInfo.max_deceleration;
	int nPointToEnd = path.size() - m_iPrevWayPoint;
	double totalD = m_WayPointsDensity*nPointToEnd;

	if(totalD &lt;= 1 || totalD &lt;= d_critical)
	{
		m_bEndPath = true;
		cout &lt;&lt; &quot;Critical Distance: &quot; &lt;&lt; d_critical &lt;&lt; endl;
	}
	else
		m_bEndPath = false;

	return true;
}

int TrajectoryFollower::SteerControllerUpdate(const PlannerHNS::VehicleState&amp; CurrStatus,
		const PlannerHNS::BehaviorState&amp; CurrBehavior, double&amp; desiredSteerAngle)
{
	if(m_Path.size()==0) return -1;
	int ret = -1;
	//AdjustPID(CurrStatus.velocity, 18.0, m_Params.Gain);
	if(CurrBehavior.state == FORWARD_STATE || CurrBehavior.state == TRAFFIC_LIGHT_STOP_STATE || CurrBehavior.state == STOP_SIGN_STOP_STATE || CurrBehavior.state  == FOLLOW_STATE)
		ret = SteerControllerPart(m_CurrPos, m_DesPos, m_LateralError, desiredSteerAngle);

	if(ret &lt; 0)
		desiredSteerAngle = m_PrevDesiredSteer;
	else
		m_PrevDesiredSteer = desiredSteerAngle;

	return ret;
}

int TrajectoryFollower::SteerControllerPart(const PlannerHNS::WayPoint&amp; state, const PlannerHNS::WayPoint&amp; way_point,
		const double&amp; lateral_error, double&amp; steerd)
{
	double current_a = UtilityH::SplitPositiveAngle(state.pos.a);
	double target_a = atan2(way_point.pos.y - state.pos.y, way_point.pos.x - state.pos.x);

	double e =  UtilityH::SplitPositiveAngle(target_a - current_a);

//	if(e &gt; M_PI_2 || e &lt; -M_PI_2)
//		return -1;


	double before_lowpass = m_pidSteer.getPID(e);
	//cout &lt;&lt; m_pidSteer.ToString() &lt;&lt; endl;

	if(m_bEnableLog)
		m_LogSteerPIDData.push_back(m_pidSteer.ToString());

	//TODO use lateral error instead of angle error
	//double future_lateral_error = PlanningHelpers::GetPerpDistanceToTrajectorySimple(m_Path, m_ForwardSimulation,0);


	//steerd = m_pidSteer.getPID( future_lateral_error*-1, 0);

//	if(m_LateralError &lt; 0)
//		steerd = m_pidSteer.getPID(current_a+sqrt(abs(m_LateralError)), target_a);
//	else
//		steerd = m_pidSteer.getPID(current_a-sqrt(m_LateralError), target_a);


	//cout &lt;&lt; &quot;Error : &quot; &lt;&lt; e &lt;&lt; &quot;, Current A: &quot; &lt;&lt; current_a &lt;&lt; &quot;, Target A: &quot; &lt;&lt; target_a &lt;&lt;  &quot; Steeting Angle = &quot; &lt;&lt; steerd*RAD2DEG &lt;&lt; endl;
//	if(abs(before_lowpass) &lt; m_Params.MaxSteerAngle*0.5)
//		steerd = m_lowpassSteer.getFilter(before_lowpass);
//	else
		steerd = before_lowpass;

//	timespec t;
//	UtilityH::GetTickCount(t);
//	std::ostringstream dataLine;
//	dataLine &lt;&lt; UtilityH::GetLongTime(t) &lt;&lt; &quot;,&quot; &lt;&lt; state.pos.x &lt;&lt; &quot;,&quot; &lt;&lt; state.pos.y &lt;&lt; &quot;,&quot; &lt;&lt;  current_a &lt;&lt; &quot;,&quot; &lt;&lt;
//			target_a &lt;&lt; &quot;,&quot; &lt;&lt;  e &lt;&lt; &quot;,&quot; &lt;&lt;m_LateralError &lt;&lt; &quot;,&quot; &lt;&lt;  before_lowpass &lt;&lt; &quot;,&quot; &lt;&lt;  steerd &lt;&lt;  &quot;,&quot; &lt;&lt;
//			m_iPrevWayPoint &lt;&lt; &quot;,&quot; &lt;&lt; m_Path.size() &lt;&lt; &quot;,&quot;;
//	m_LogData.push_back(dataLine.str());

	return 1;
}

void TrajectoryFollower::PredictMotion(double&amp; x, double &amp;y, double&amp; heading, double steering, double velocity, double wheelbase, double time_elapsed)
{
	x += velocity * time_elapsed *  cos(heading);
	y += velocity * time_elapsed *  sin(heading);
	heading = heading + ((velocity*time_elapsed*tan(steering))  / (wheelbase) );
}

int TrajectoryFollower::VeclocityControllerUpdate(const double&amp; dt, const PlannerHNS::VehicleState&amp; CurrStatus,
		const PlannerHNS::BehaviorState&amp; CurrBehavior, double&amp; desiredVelocity, PlannerHNS::SHIFT_POS&amp; desiredShift)
{
	double critical_long_front_distance =  2.0;

	if(CurrBehavior.state == TRAFFIC_LIGHT_STOP_STATE || CurrBehavior.state == STOP_SIGN_STOP_STATE || m_bEndPath)
	{
		double deceleration_critical = m_VehicleInfo.max_deceleration;
		if(CurrBehavior.stopDistance != 0)
			deceleration_critical = (-CurrStatus.speed*CurrStatus.speed)/(2.0*CurrBehavior.stopDistance);

		desiredVelocity = (deceleration_critical * dt) + CurrStatus.speed;

		//desiredVelocity = m_PerpendicularPoint.v;
	}
	else if(CurrBehavior.state == FORWARD_STATE || CurrBehavior.state == OBSTACLE_AVOIDANCE_STATE )
	{

		double e = CurrBehavior.maxVelocity - CurrStatus.speed;

		//Using PID for velocity
		//m_pidVelocity.Setlimit(CurrBehavior.maxVelocity, 0);
		//desiredVelocity = m_pidVelocity.getPID(e);

		//Using constant acceleration for velocity
		if(e &gt;= 0)
			desiredVelocity = (m_VehicleInfo.max_acceleration * dt) + CurrStatus.speed;
		else
			desiredVelocity = (m_VehicleInfo.max_deceleration * dt) + CurrStatus.speed;

		if(desiredVelocity &gt; CurrBehavior.maxVelocity)
			desiredVelocity = CurrBehavior.maxVelocity;
		else if(desiredVelocity&lt;m_VehicleInfo.min_speed_forward)
			desiredVelocity = m_VehicleInfo.min_speed_forward;

		//std::cout &lt;&lt; &quot;Velocity from follower : dt=&quot; &lt;&lt; dt &lt;&lt; &quot;, e= &quot; &lt;&lt; e &lt;&lt; &quot;, acc_const=&quot; &lt;&lt; acc_const &lt;&lt; &quot;, desiredVelocity = &quot;&lt;&lt;desiredVelocity&lt;&lt;  std::endl;

		m_StartFollowDistance = 0;
	}
	else if(CurrBehavior.state == STOPPING_STATE || CurrBehavior.state == FINISH_STATE)
	{
		desiredVelocity = 0;
	}
	else if(CurrBehavior.state == FOLLOW_STATE)
	{
		double deceleration_critical = 0;
		double inv_time = 2.0*((CurrBehavior.followDistance-critical_long_front_distance)-CurrStatus.speed);
		if(inv_time == 0)
			deceleration_critical = MAX_ACCELERATION_2G;
		else
			deceleration_critical = CurrStatus.speed*CurrStatus.speed/inv_time;

		if(deceleration_critical &gt; 0) deceleration_critical = -deceleration_critical;
		if(deceleration_critical &lt; -MAX_ACCELERATION_2G) deceleration_critical = -MAX_ACCELERATION_2G;

		desiredVelocity = (deceleration_critical * dt) + CurrStatus.speed;

		if(desiredVelocity &gt; CurrBehavior.maxVelocity)
			desiredVelocity = CurrBehavior.maxVelocity;

		if((desiredVelocity &lt; 0.1 &amp;&amp; desiredVelocity &gt; -0.1) || CurrBehavior.followDistance &lt;= 0) //use only effective velocities
			desiredVelocity = 0;

		cout &lt;&lt; &quot;Follow State:  acceleration = &quot; &lt;&lt; deceleration_critical &lt;&lt; &quot;, speed = &quot; &lt;&lt; desiredVelocity &lt;&lt;  &quot;, Distance = &quot; &lt;&lt; CurrBehavior.followDistance&lt;&lt; endl;
	}
	else
	{
		desiredVelocity = 0;
	}

	if(desiredVelocity &gt; m_VehicleInfo.max_speed_forward)
		desiredVelocity = m_VehicleInfo.max_speed_forward;
	else if (desiredVelocity &lt; 0)
		desiredVelocity = 0;
	//desiredVelocity = 2.0;



	desiredShift = PlannerHNS::SHIFT_POS_DD;
	if(m_bEnableLog)
		m_LogVelocityPIDData.push_back(m_pidVelocity.ToString());
	return 1;
}

PlannerHNS::VehicleState TrajectoryFollower::DoOneStep(const double&amp; dt, const PlannerHNS::BehaviorState&amp; behavior,
		const std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path, const PlannerHNS::WayPoint&amp; currPose,
		const PlannerHNS::VehicleState&amp; vehicleState, const bool&amp; bNewTrajectory)
{
	if(bNewTrajectory &amp;&amp; path.size() &gt; 0)
	{
		UpdateCurrentPath(path);
		m_iPrevWayPoint = -1;
	}

	PlannerHNS::VehicleState desiredState;

	if(m_bCalibrationMode)
	{
		CalibrationStep(dt, vehicleState, desiredState.steer, desiredState.speed);
		desiredState.shift = PlannerHNS::SHIFT_POS_DD;
	}
	else if(m_Path.size()&gt;0 &amp;&amp; behavior.state != INITIAL_STATE )
	{
		PrepareNextWaypoint(currPose, vehicleState.speed, vehicleState.steer);
		VeclocityControllerUpdate(dt, vehicleState, behavior, desiredState.speed, desiredState.shift);
		SteerControllerUpdate(vehicleState, behavior, desiredState.steer);
	}
	else
	{
		desiredState.steer = 0;
		desiredState.speed = 0;
		desiredState.shift = PlannerHNS::SHIFT_POS_DD;
		//cout &lt;&lt; &quot;&gt;&gt;&gt; Error, Very Dangerous, Following No Path !!.&quot; &lt;&lt; endl;
	}

	if(m_bEnableLog)
		LogCalibrationData(vehicleState, desiredState);

	return desiredState;
}

void TrajectoryFollower::CalibrationStep(const double&amp; dt, const PlannerHNS::VehicleState&amp; CurrStatus, double&amp; desiredSteer, double&amp; desiredVelocity)
{
	if(m_iNextTest &gt;= (int)m_CalibrationRunList.size()-1)
	{
		desiredSteer = 0;
		desiredVelocity = 0;
		return;
	}

	if(fabs(CurrStatus.speed - m_CalibrationRunList.at(m_iNextTest).first)*3.6 &lt;= 1
			&amp;&amp; fabs(CurrStatus.steer - m_CalibrationRunList.at(m_iNextTest).second)*RAD2DEG &lt;=0.5)
		m_iNextTest++;

	desiredVelocity = m_CalibrationRunList.at(m_iNextTest).first;
	desiredSteer = m_CalibrationRunList.at(m_iNextTest).second;

	cout &lt;&lt; &quot;i:&quot; &lt;&lt; m_iNextTest &lt;&lt; &quot;, desVel:&quot; &lt;&lt; desiredVelocity &lt;&lt; &quot;, CurVel:&quot; &lt;&lt; CurrStatus.speed
			&lt;&lt; &quot;, desStr:&quot; &lt;&lt; desiredSteer &lt;&lt; &quot;, CurrStr:&quot; &lt;&lt; CurrStatus.steer &lt;&lt; endl;

//	double e = targetSpeed - CurrStatus.speed;
//	if(e &gt;= 0)
//		desiredVelocity = (m_VehicleInfo.max_acceleration * dt) + CurrStatus.speed;
//	else
//		desiredVelocity = (m_VehicleInfo.max_deceleration * dt) + CurrStatus.speed;
}

void TrajectoryFollower::LogCalibrationData(const PlannerHNS::VehicleState&amp; currState,const PlannerHNS::VehicleState&amp; desiredState)
{
	int startAngle=0, finishAngle=0, originalTargetAngle=0, currVelocity = 0;
	double t_FromStartToFinish_a = 0;
	bool bAngleReset = false;
	int startV=0, finishV=0, originalTargetV=0, currSteering = 0;
	double t_FromStartToFinish_v = 0;
	bool bVelocityReset = false;

	//1- decide reset
	if((int)(m_prevDesiredState_steer.steer*RAD2DEG) != (int)(desiredState.steer*RAD2DEG))
		bAngleReset = true;

	if((int)(m_prevDesiredState_vel.speed*3.6) != (int)(desiredState.speed*3.6))
		bVelocityReset = true;

	//2- calculate time and log
	if(bAngleReset)
	{
		startAngle = m_prevCurrState_steer.steer*RAD2DEG;
		finishAngle = currState.steer*RAD2DEG;
		originalTargetAngle = m_prevDesiredState_steer.steer*RAD2DEG;
		t_FromStartToFinish_a = UtilityH::GetTimeDiffNow(m_SteerDelayTimer);
		currVelocity = currState.speed*3.6;
		UtilityH::GetTickCount(m_SteerDelayTimer);

		std::ostringstream dataLine;
		dataLine &lt;&lt; UtilityH::GetLongTime(m_SteerDelayTimer) &lt;&lt; &quot;,&quot;
				&lt;&lt; bAngleReset &lt;&lt; &quot;,&quot;
				&lt;&lt; startAngle &lt;&lt; &quot;,&quot;
				&lt;&lt; finishAngle &lt;&lt; &quot;,&quot;
				&lt;&lt; originalTargetAngle &lt;&lt; &quot;,&quot;
				&lt;&lt; t_FromStartToFinish_a &lt;&lt; &quot;,&quot;
				&lt;&lt; currVelocity &lt;&lt; &quot;,&quot;;

		m_SteerCalibrationData.push_back(dataLine.str());

		if(bAngleReset)
		{
			bAngleReset = false;
			m_prevCurrState_steer = currState;
			m_prevDesiredState_steer = desiredState;
		}
	}

	if(bVelocityReset)
	{
		startV = m_prevCurrState_vel.speed*3.6;
		finishV = currState.speed*3.6;
		originalTargetV = m_prevDesiredState_vel.speed*3.6;
		t_FromStartToFinish_v = UtilityH::GetTimeDiffNow(m_VelocityDelayTimer);
		currSteering = currState.steer*RAD2DEG;
		UtilityH::GetTickCount(m_VelocityDelayTimer);

		std::ostringstream dataLine;
		dataLine &lt;&lt; UtilityH::GetLongTime(m_VelocityDelayTimer) &lt;&lt; &quot;,&quot;
				&lt;&lt; bVelocityReset &lt;&lt; &quot;,&quot;
				&lt;&lt; startV &lt;&lt; &quot;,&quot;
				&lt;&lt; finishV &lt;&lt; &quot;,&quot;
				&lt;&lt; originalTargetV &lt;&lt; &quot;,&quot;
				&lt;&lt; t_FromStartToFinish_v &lt;&lt; &quot;,&quot;
				&lt;&lt; currSteering &lt;&lt; &quot;,&quot;;

		m_VelocityCalibrationData.push_back(dataLine.str());

		if(bVelocityReset)
		{
			bVelocityReset = false;
			m_prevCurrState_vel = currState;
			m_prevDesiredState_vel = desiredState;
		}
	}
}

void TrajectoryFollower::InitCalibration()
{
	m_CalibrationRunList.push_back(make_pair(0,0));
	m_CalibrationRunList.push_back(make_pair(0,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(0,0.0));
	m_CalibrationRunList.push_back(make_pair(0,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(0,m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(0,0.0));
	m_CalibrationRunList.push_back(make_pair(0,-m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(0,m_VehicleInfo.max_steer_angle/1.5));
	m_CalibrationRunList.push_back(make_pair(0,0.0));
	m_CalibrationRunList.push_back(make_pair(0,-m_VehicleInfo.max_steer_angle/1.5));
	m_CalibrationRunList.push_back(make_pair(0,m_VehicleInfo.max_steer_angle/1.0));
	m_CalibrationRunList.push_back(make_pair(0,0.0));
	m_CalibrationRunList.push_back(make_pair(0,-m_VehicleInfo.max_steer_angle/1.0));

	m_CalibrationRunList.push_back(make_pair(1,0));
	m_CalibrationRunList.push_back(make_pair(1,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(1,0.0));
	m_CalibrationRunList.push_back(make_pair(1,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(1,m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(1,0.0));
	m_CalibrationRunList.push_back(make_pair(1,-m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(1,m_VehicleInfo.max_steer_angle/1.5));
	m_CalibrationRunList.push_back(make_pair(1,0.0));
	m_CalibrationRunList.push_back(make_pair(1,-m_VehicleInfo.max_steer_angle/1.5));
	m_CalibrationRunList.push_back(make_pair(1,m_VehicleInfo.max_steer_angle/1.0));
	m_CalibrationRunList.push_back(make_pair(1,0.0));
	m_CalibrationRunList.push_back(make_pair(1,-m_VehicleInfo.max_steer_angle/1.0));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(2,0));
	m_CalibrationRunList.push_back(make_pair(2,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(2,0.0));
	m_CalibrationRunList.push_back(make_pair(2,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(2,m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(2,0.0));
	m_CalibrationRunList.push_back(make_pair(2,-m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(2,m_VehicleInfo.max_steer_angle/1.5));
	m_CalibrationRunList.push_back(make_pair(2,0.0));
	m_CalibrationRunList.push_back(make_pair(2,-m_VehicleInfo.max_steer_angle/1.5));
	m_CalibrationRunList.push_back(make_pair(2,m_VehicleInfo.max_steer_angle/1.0));
	m_CalibrationRunList.push_back(make_pair(2,0.0));
	m_CalibrationRunList.push_back(make_pair(2,-m_VehicleInfo.max_steer_angle/1.0));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(3,0));
	m_CalibrationRunList.push_back(make_pair(3,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(3,0.0));
	m_CalibrationRunList.push_back(make_pair(3,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(3,m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(3,0.0));
	m_CalibrationRunList.push_back(make_pair(3,-m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(3,m_VehicleInfo.max_steer_angle/1.5));
	m_CalibrationRunList.push_back(make_pair(3,0.0));
	m_CalibrationRunList.push_back(make_pair(3,-m_VehicleInfo.max_steer_angle/1.5));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(4,0));
	m_CalibrationRunList.push_back(make_pair(4,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(4,0.0));
	m_CalibrationRunList.push_back(make_pair(4,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(4,m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(4,0.0));
	m_CalibrationRunList.push_back(make_pair(4,-m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(4,m_VehicleInfo.max_steer_angle/1.5));
	m_CalibrationRunList.push_back(make_pair(4,0.0));
	m_CalibrationRunList.push_back(make_pair(4,-m_VehicleInfo.max_steer_angle/1.5));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(5,0));
	m_CalibrationRunList.push_back(make_pair(5,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(5,0.0));
	m_CalibrationRunList.push_back(make_pair(5,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(5,m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(5,0.0));
	m_CalibrationRunList.push_back(make_pair(5,-m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(5,m_VehicleInfo.max_steer_angle/1.5));
	m_CalibrationRunList.push_back(make_pair(5,0.0));
	m_CalibrationRunList.push_back(make_pair(5,-m_VehicleInfo.max_steer_angle/1.5));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(6,0));
	m_CalibrationRunList.push_back(make_pair(6,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(6,0.0));
	m_CalibrationRunList.push_back(make_pair(6,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(6,m_VehicleInfo.max_steer_angle/3.0));
	m_CalibrationRunList.push_back(make_pair(6,0.0));
	m_CalibrationRunList.push_back(make_pair(6,-m_VehicleInfo.max_steer_angle/3.0));
	m_CalibrationRunList.push_back(make_pair(6,m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(6,0.0));
	m_CalibrationRunList.push_back(make_pair(6,-m_VehicleInfo.max_steer_angle/2.0));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(7,0));
	m_CalibrationRunList.push_back(make_pair(7,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(7,0.0));
	m_CalibrationRunList.push_back(make_pair(7,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(7,m_VehicleInfo.max_steer_angle/3.0));
	m_CalibrationRunList.push_back(make_pair(7,0.0));
	m_CalibrationRunList.push_back(make_pair(7,-m_VehicleInfo.max_steer_angle/3.0));
	m_CalibrationRunList.push_back(make_pair(7,m_VehicleInfo.max_steer_angle/2.0));
	m_CalibrationRunList.push_back(make_pair(7,0.0));
	m_CalibrationRunList.push_back(make_pair(7,-m_VehicleInfo.max_steer_angle/2.0));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(8,0));
	m_CalibrationRunList.push_back(make_pair(8,m_VehicleInfo.max_steer_angle/6.0));
	m_CalibrationRunList.push_back(make_pair(8,0.0));
	m_CalibrationRunList.push_back(make_pair(8,-m_VehicleInfo.max_steer_angle/6.0));
	m_CalibrationRunList.push_back(make_pair(8,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(8,0.0));
	m_CalibrationRunList.push_back(make_pair(8,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(8,m_VehicleInfo.max_steer_angle/3.0));
	m_CalibrationRunList.push_back(make_pair(8,0.0));
	m_CalibrationRunList.push_back(make_pair(8,-m_VehicleInfo.max_steer_angle/3.0));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(9,0));
	m_CalibrationRunList.push_back(make_pair(9,m_VehicleInfo.max_steer_angle/6.0));
	m_CalibrationRunList.push_back(make_pair(9,0.0));
	m_CalibrationRunList.push_back(make_pair(9,-m_VehicleInfo.max_steer_angle/6.0));
	m_CalibrationRunList.push_back(make_pair(9,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(9,0.0));
	m_CalibrationRunList.push_back(make_pair(9,-m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(9,m_VehicleInfo.max_steer_angle/3.0));
	m_CalibrationRunList.push_back(make_pair(9,0.0));
	m_CalibrationRunList.push_back(make_pair(9,-m_VehicleInfo.max_steer_angle/3.0));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(10,0));
	m_CalibrationRunList.push_back(make_pair(10,m_VehicleInfo.max_steer_angle/6.0));
	m_CalibrationRunList.push_back(make_pair(10,0.0));
	m_CalibrationRunList.push_back(make_pair(10,-m_VehicleInfo.max_steer_angle/6.0));
	m_CalibrationRunList.push_back(make_pair(10,m_VehicleInfo.max_steer_angle/5.0));
	m_CalibrationRunList.push_back(make_pair(10,0.0));
	m_CalibrationRunList.push_back(make_pair(10,-m_VehicleInfo.max_steer_angle/5.0));
	m_CalibrationRunList.push_back(make_pair(10,m_VehicleInfo.max_steer_angle/4.0));
	m_CalibrationRunList.push_back(make_pair(10,0.0));
	m_CalibrationRunList.push_back(make_pair(10,-m_VehicleInfo.max_steer_angle/4.0));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(11,0));
	m_CalibrationRunList.push_back(make_pair(11,m_VehicleInfo.max_steer_angle/8.0));
	m_CalibrationRunList.push_back(make_pair(11,0.0));
	m_CalibrationRunList.push_back(make_pair(11,-m_VehicleInfo.max_steer_angle/8.0));
	m_CalibrationRunList.push_back(make_pair(11,m_VehicleInfo.max_steer_angle/6.0));
	m_CalibrationRunList.push_back(make_pair(11,0.0));
	m_CalibrationRunList.push_back(make_pair(11,-m_VehicleInfo.max_steer_angle/6.0));
	m_CalibrationRunList.push_back(make_pair(11,m_VehicleInfo.max_steer_angle/5.0));
	m_CalibrationRunList.push_back(make_pair(11,0.0));
	m_CalibrationRunList.push_back(make_pair(11,-m_VehicleInfo.max_steer_angle/5.0));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(13,0));
	m_CalibrationRunList.push_back(make_pair(13,m_VehicleInfo.max_steer_angle/10.0));
	m_CalibrationRunList.push_back(make_pair(13,0.0));
	m_CalibrationRunList.push_back(make_pair(13,-m_VehicleInfo.max_steer_angle/10.0));
	m_CalibrationRunList.push_back(make_pair(13,m_VehicleInfo.max_steer_angle/9.0));
	m_CalibrationRunList.push_back(make_pair(13,0.0));
	m_CalibrationRunList.push_back(make_pair(13,-m_VehicleInfo.max_steer_angle/9.0));
	m_CalibrationRunList.push_back(make_pair(13,m_VehicleInfo.max_steer_angle/8.0));
	m_CalibrationRunList.push_back(make_pair(13,0.0));
	m_CalibrationRunList.push_back(make_pair(13,-m_VehicleInfo.max_steer_angle/8.0));

	m_CalibrationRunList.push_back(make_pair(0,0));

	m_CalibrationRunList.push_back(make_pair(15,0));
	m_CalibrationRunList.push_back(make_pair(15,m_VehicleInfo.max_steer_angle/15.0));
	m_CalibrationRunList.push_back(make_pair(15,0.0));
	m_CalibrationRunList.push_back(make_pair(15,-m_VehicleInfo.max_steer_angle/15.0));
	m_CalibrationRunList.push_back(make_pair(15,m_VehicleInfo.max_steer_angle/12.0));
	m_CalibrationRunList.push_back(make_pair(15,0.0));
	m_CalibrationRunList.push_back(make_pair(15,-m_VehicleInfo.max_steer_angle/12.0));
	m_CalibrationRunList.push_back(make_pair(15,m_VehicleInfo.max_steer_angle/10.0));
	m_CalibrationRunList.push_back(make_pair(15,0.0));
	m_CalibrationRunList.push_back(make_pair(15,-m_VehicleInfo.max_steer_angle/10.0));
	m_CalibrationRunList.push_back(make_pair(0,0));
}

} /* namespace SimulationNS */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_utilityh/src/UtilityH.cpp" new_path="ros/src/computing/planning/common/lib/openplanner/op_utilityh/src/UtilityH.cpp">
				<diff>@@ -6,7 +6,6 @@
  */
 
 #include &quot;UtilityH.h&quot;
-#include &lt;math.h&gt;
 #include &lt;iostream&gt;
 #include &lt;sstream&gt;
 #include &lt;string.h&gt;
</diff>
				<old_file>/*
 * UtilityH.cpp
 *
 *  Created on: May 14, 2016
 *      Author: hatem
 */

#include &quot;UtilityH.h&quot;
#include &lt;math.h&gt;
#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;pwd.h&gt;


using namespace std;


namespace UtilityHNS
{


UtilityH::UtilityH()
{
}

 UtilityH::~UtilityH()
{
}

 std::string UtilityH::GetHomeDirectory()
 {
	struct passwd *pw = getpwuid(getuid());
	const char *homedir = pw-&gt;pw_dir;
	return string(homedir);
 }

 double UtilityH::GetMomentumScaleFactor(const double&amp; v)
 {
 	if(v &lt; 0.3)
 		return 0.6;
 	else if(v &lt;6.4)
 		return 0.3;
 	else if(v &lt; 20)
 	{
 		double m = 0.7/3.6;
 		return m*(v - 6.4) + 0.3;
 	}
 	else
 		return 0.9;
 }

 int UtilityH::GetSign(double x)
 {
	 if(x &lt; 0 )
		 return -1;
	 else
		 return 1;
 }

 double UtilityH::FixNegativeAngle(const double&amp; a)
{
   double angle = 0;
   if (a &lt; -2.0*M_PI || a &gt; 2.0*M_PI)
	{
	   angle = fmod(a, 2.0*M_PI);
	}
   else
	   angle = a;


   if(angle &lt; 0)
   {
	   angle = 2.0*M_PI + angle;
   }

   return angle;
}

 double UtilityH::SplitPositiveAngle(const double&amp; a)
{
	 double angle = a;

	if (a &lt; -2.0*M_PI || a &gt; 2.0*M_PI)
	{
		angle = fmod(a, 2.0*M_PI);
	}

	if (angle &gt; M_PI)
	{
		angle -= 2.0*M_PI;
	}
	else if (angle &lt; -M_PI)
	{
		angle += 2.0*M_PI;
	}

	return angle;
}

double UtilityH::InverseAngle(const double&amp; a)
{

   double angle = 0;
   if(a &lt;= M_PI)
		angle =  a + M_PI;
	else
		angle = a - M_PI;

   return angle;
}

double UtilityH::AngleBetweenTwoAnglesPositive(const double&amp; a1, const double&amp; a2)
{
   double diff = a1 - a2;
   if(diff &lt; 0)
	   diff = a2 - a1;

   if(diff &gt; M_PI)
	   diff = 2.0*M_PI - diff;

   return diff;
}

double UtilityH::GetCircularAngle(const double&amp; prevContAngle, const double&amp; prevAngle, const double&amp; currAngle)
{

	double diff = currAngle - prevAngle;
	if(diff &gt; M_PI)
		diff = diff - 2.0*M_PI;
	if(diff &lt; -M_PI)
		diff = diff + 2.0*M_PI;

	double c_ang = 0;
	if(prevContAngle == 0 || fabs(diff) &lt; M_PI_2)
		 c_ang = prevContAngle + diff;
	else
		c_ang = prevContAngle;

	return c_ang;
}

void UtilityH::GetTickCount(struct timespec&amp; t)
{
	while(clock_gettime(0, &amp; t) == -1);
}

double UtilityH::GetTimeDiff(const struct timespec&amp; old_t,const struct timespec&amp; curr_t)
{
	return (curr_t.tv_sec - old_t.tv_sec) + ((double)(curr_t.tv_nsec - old_t.tv_nsec)/ 1000000000.0);
}

double UtilityH::GetTimeDiffNow(const struct timespec&amp; old_t)
{
	struct timespec curr_t;
	GetTickCount(curr_t);
	return (curr_t.tv_sec - old_t.tv_sec) + ((double)(curr_t.tv_nsec - old_t.tv_nsec)/ 1000000000.0);
}

string UtilityH::GetFilePrefixHourMinuteSeconds()
{
	struct timespec now_time;
	UtilityH::GetTickCount(now_time);
	tm *gmtm = localtime(&amp;now_time.tv_sec);
	ostringstream str;

	str &lt;&lt; &quot;Y&quot; &lt;&lt; gmtm-&gt;tm_year;
	str &lt;&lt; &quot;-&quot;;
	str &lt;&lt; &quot;M&quot; &lt;&lt; gmtm-&gt;tm_mon;
	str &lt;&lt; &quot;-&quot;;
	str &lt;&lt; &quot;D&quot; &lt;&lt; gmtm-&gt;tm_mday;
	str &lt;&lt; &quot;-&quot;;
	str &lt;&lt; &quot;H&quot; &lt;&lt; gmtm-&gt;tm_hour;
	str &lt;&lt; &quot;-&quot;;
	str &lt;&lt; &quot;M&quot; &lt;&lt; gmtm-&gt;tm_min;
	str &lt;&lt; &quot;-&quot;;
	str &lt;&lt; &quot;S&quot; &lt;&lt; gmtm-&gt;tm_sec;

	return str.str();
}

string UtilityH::GetDateTimeStr()
{
	time_t now = time(0);
	char* dateStr = ctime(&amp;now);
	string str(dateStr, strlen(dateStr)-1);
	int index = str.find(&quot; &quot;);
	while(index &gt; 0)
	{
		str.replace(index,1, &quot;_&quot;);
		index = str.find(&quot; &quot;);
	}

	index = str.find(&quot;:&quot;);
	while(index &gt; 0)
	{
		str.replace(index,1, &quot;-&quot;);
		index = str.find(&quot;:&quot;);
	}
	return str;
}

int  UtilityH::tsCompare (struct  timespec  time1,   struct  timespec  time2, int micro_tolerance)
{

    if (time1.tv_sec &lt; time2.tv_sec)
        return (-1) ;				/* Less than. */
    else if (time1.tv_sec &gt; time2.tv_sec)
        return (1) ;				/* Greater than. */

    long diff = time1.tv_nsec - time2.tv_nsec;
    if (diff &lt; -micro_tolerance)
        return (-1) ;				/* Less than. */
    else if (diff &gt; micro_tolerance)
        return (1) ;				/* Greater than. */
    else
        return (0) ;				/* Equal. */

}

timespec UtilityH::GetTimeSpec(const time_t&amp; srcT)
{
	timespec dstT;
	dstT.tv_sec = srcT/1000000000;
	dstT.tv_nsec = srcT - (dstT.tv_sec*1000000000);
	return dstT;
}

time_t UtilityH::GetLongTime(const struct timespec&amp; srcT)
{
	time_t dstT;
	dstT = srcT.tv_sec * 1000000000 + srcT.tv_nsec;
	return dstT;
}

PIDController::PIDController()
{
	kp = kp_v = 0;
	ki = ki_v = 0;
	kd = kd_v = 0;
	pid_lim = pid_v = 0;
	upper_limit = lower_limit = 0;
	bEnableLimit= false;
	accumErr = 0;
	prevErr = 0;
	bResetD = false;
	bResetI = false;
}

PIDController::PIDController(const double&amp; kp, const double&amp; ki, const double&amp; kd)
{
	Init(kp, ki, kd);
	upper_limit = lower_limit = 0;
	bEnableLimit= false;
	accumErr = 0;
	prevErr  = 0;
	bResetD = false;
	bResetI = false;

}

void PIDController::Setlimit(const double&amp; upper,const double&amp; lower)
{
	upper_limit = upper;
	lower_limit = lower;
	bEnableLimit = true;
}

double PIDController::getPID(const double&amp; currValue, const double&amp; targetValue)
{
	double e = targetValue - currValue;
	return getPID(e);
}

double PIDController::getPID(const double&amp; e)
{
	//TODO Remember to add sampling time and multiply the time elapsed by the error
	//complex PID error calculation
	//TODO //De = ( e(i) + 3*e(i-1) - 3*e(i-2) - e(i-3) ) / 6


	if(bResetI)
	{
		bResetI = false;
		accumErr = 0;
	}

	if(bResetD)
	{
		bResetD = false;
		prevErr = e;
	}

	if(pid_v &lt; upper_limit &amp;&amp; pid_v &gt; lower_limit)
		accumErr += e;

	double edot= e - prevErr;

	kp_v = kp * e;
	ki_v = ki *  accumErr;
	kd_v = kd * edot;

	pid_v = kp_v + ki_v + kd_v;
	pid_lim = pid_v;
	if(bEnableLimit)
	{
		if(pid_v &gt; upper_limit)
		{
			pid_lim = upper_limit;
		}
		else if ( pid_v &lt; lower_limit)
		{
			pid_lim = lower_limit;
		}
	}

	prevErr = e;

	return pid_lim;
}

std::string PIDController::ToStringHeader()
{
	std::ostringstream str_out;
	str_out &lt;&lt; &quot;Time&quot; &lt;&lt; &quot;,&quot; &lt;&lt;&quot;KP&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;KI&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;KD&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;KP_v&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;KI_v&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;KD_v&quot;
			&lt;&lt; &quot;,&quot; &lt;&lt; &quot;pid_v&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;pid_lim&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;prevErr&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;accumErr&quot; &lt;&lt; &quot;,&quot; ;
	return str_out.str();
}

std::string PIDController::ToString()
{
	std::ostringstream str_out;
	timespec t_stamp;
	UtilityH::GetTickCount(t_stamp);
	str_out &lt;&lt; UtilityH::GetLongTime(t_stamp) &lt;&lt; &quot;,&quot; &lt;&lt;kp &lt;&lt; &quot;,&quot; &lt;&lt; ki &lt;&lt; &quot;,&quot; &lt;&lt; kd &lt;&lt; &quot;,&quot; &lt;&lt; kp_v &lt;&lt; &quot;,&quot; &lt;&lt; ki_v &lt;&lt; &quot;,&quot; &lt;&lt; kd_v
				&lt;&lt; &quot;,&quot; &lt;&lt; pid_v &lt;&lt; &quot;,&quot; &lt;&lt; &quot;,&quot; &lt;&lt; pid_lim &lt;&lt; &quot;,&quot; &lt;&lt; &quot;,&quot; &lt;&lt; prevErr &lt;&lt; &quot;,&quot; &lt;&lt; accumErr &lt;&lt; &quot;,&quot; ;

	return str_out.str();

}

void PIDController::ResetD()
{
	bResetD = true;
}

void PIDController::ResetI()
{
	bResetI = true;
}

void PIDController::Init(const double&amp; kp, const double&amp; ki, const double&amp; kd)
{
	this-&gt;kp = kp;
	this-&gt;ki = ki;
	this-&gt;kd = kd;
}

LowpassFilter::LowpassFilter()
{
	A = 0;
	d1 = 0;
	d2 = 0;
	w0 = 0;
	w1 = 0;
	w2 = 0;

	m = 0;
	sampleF = 0;
	cutOffF = 0;
}

LowpassFilter::~LowpassFilter()
{
//	if(A)
//		delete A;
//	if(d1)
//		delete d1;
//	if(d2)
//		delete d2;
//	if(w0)
//		delete w0;
//	if(w1)
//		delete w1;
//	if(w2)
//		delete w2;
}

LowpassFilter::LowpassFilter(const int&amp; filterOrder, const double&amp; sampleFreq, const double&amp; cutOffFreq)
{
	Init(filterOrder, sampleFreq, cutOffFreq);
}

void LowpassFilter::Init(const int&amp; n, const double&amp; sampleFreq, const double&amp; cutOffFreq)
{
	if(!(n == 2 || n == 4 || n == 6 || n == 8))
	{
		cout &lt;&lt; &quot;Undefined LowpassFilter order ! &quot; &lt;&lt; endl;

		A = 0;
		d1 = 0;
		d2 = 0;
		w0 = 0;
		w1 = 0;
		w2 = 0;

		m = 0;
		sampleF = 0;
		cutOffF = 0;
	}
	else
	{
		m = n/2;
		sampleF = sampleFreq;
		cutOffF = cutOffFreq;
		double ep = 1;
		double s = sampleFreq;
		double f = cutOffFreq;
		double a = tan(M_PI*f/s);
		double a2 = a*a;
		double u = log((1.0+sqrt(1.0+ep*ep))/ep);
		double su = sinh(u/(double)n);
		double cu = cosh(u/(double)n);
		double b, c;

//		A  = new double[m];
//		d1 = new double[m];
//		d2 = new double[m];
//		w0 = new double[m];
//		w1 = new double[m];
//		w2 = new double[m];
//
//		for(int i=0; i &lt; m ; i++)
//		{
//			A[i]  = 0;
//			d1[i] = 0;
//			d2[i] = 0;
//			w0[i] = 0;
//			w1[i] = 0;
//			w2[i] = 0;
//		}

		for(int i=0; i&lt; m; ++i)
		{
		    b = sin(M_PI*(2.0*i+1.0)/(2.0*n))*su;
		    c = cos(M_PI*(2.0*i+1.0)/(2.0*n))*cu;
		    c = b*b + c*c;
		    s = a2*c + 2.0*a*b + 1.0;
		    A = a2/(4.0*s); // 4.0
		    d1 = 2.0*(1-a2*c)/s;
		    d2 = -(a2*c - 2.0*a*b + 1.0)/s;
		}
	}
}

double LowpassFilter::getFilter(const double&amp; value)
{
	double ep = 2.3/1.0; // used to normalize
	double x = value;
	for(int i=0; i&lt;m; ++i)
	{
		w0 = d1*w1 + d2*w2 + x;
		x = A*(w0 + 2.0*w1 + w2);
		w2 = w1;
		w1 = w0;
	}
	return ep*x;
}


}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/dp_planner/include/dp_planner_core.h" new_path="ros/src/computing/planning/motion/packages/dp_planner/include/dp_planner_core.h">
				<diff>@@ -64,11 +64,11 @@
 #include &quot;RosHelpers.h&quot;
 #include &quot;SimpleTracker.h&quot;
 
-#include &lt;cv.h&gt;
+#include &lt;opencv/cv.h&gt;
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;opencv2/core/core.hpp&gt;
 #include &lt;opencv2/objdetect/objdetect.hpp&gt;
-#include &lt;highgui.h&gt;
+#include &lt;opencv/highgui.h&gt;
 #include &lt;opencv2/imgproc/imgproc.hpp&gt;
 
 #if (CV_MAJOR_VERSION &lt; 3)
</diff>
				<old_file>/*
// *  Copyright (c) 2016, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef dp_planner_CORE_H
#define dp_planner_CORE_H

// ROS includes
#include &lt;ros/ros.h&gt;

#include &lt;geometry_msgs/Vector3Stamped.h&gt;
#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;geometry_msgs/PoseArray.h&gt;
#include &lt;nav_msgs/Odometry.h&gt;
#include &lt;nav_msgs/OccupancyGrid.h&gt;

#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;tf/tf.h&gt;
#include &lt;std_msgs/Int8.h&gt;
#include &lt;std_msgs/Int32.h&gt;
#include &quot;waypoint_follower/libwaypoint_follower.h&quot;
#include &quot;waypoint_follower_msgs/LaneArray.h&quot;
#include &quot;vehicle_socket/CanInfo.h&quot;

#include &lt;lidar_tracker/CloudCluster.h&gt;
#include &lt;lidar_tracker/CloudClusterArray.h&gt;

#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;

#include &quot;RoadNetwork.h&quot;
#include &quot;MappingHelpers.h&quot;
#include &quot;PlanningHelpers.h&quot;
//#include &quot;CarState.h&quot;
#include &quot;LocalPlannerH.h&quot;
#include &quot;RosHelpers.h&quot;
#include &quot;SimpleTracker.h&quot;

#include &lt;cv.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/objdetect/objdetect.hpp&gt;
#include &lt;highgui.h&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;

#if (CV_MAJOR_VERSION &lt; 3)
#include &lt;opencv2/contrib/contrib.hpp&gt;
#endif


namespace PlannerXNS
{

#define _DATASET_GENERATION_BLOCK
#define SIMU_OBSTACLE_WIDTH 3.5
#define SIMU_OBSTACLE_HEIGHT 0.5
#define SIMU_OBSTACLE_LENGTH 2.0

enum SIGNAL_TYPE{SIMULATION_SIGNAL, ROBOT_SIGNAL};
enum MAP_SOURCE_TYPE{MAP_AUTOWARE, MAP_FOLDER, MAP_KML_FILE};

class PlannerX
{
protected:
	//For Testing
	double m_TrackingTime;
	int m_nTrackObjects;
	int m_nContourPoints;
	int m_nOriginalPoints;

	timespec m_Timer;
	timespec m_TrafficLightTimer;
	int m_counter;
	int m_frequency;

protected:
	SimulationNS::SimpleTracker m_ObstacleTracking;
	//SimulationNS::CarState m_State;
	PlannerHNS::LocalPlannerH m_LocalPlanner;

	geometry_msgs::Pose m_OriginPos;

	PlannerHNS::WayPoint m_InitPos;
	bool bInitPos;

	PlannerHNS::WayPoint m_CurrentPos;
	bool bNewCurrentPos;

	std::vector&lt;PlannerHNS::DetectedObject&gt; m_OriginalClusters;
	std::vector&lt;PlannerHNS::DetectedObject&gt; m_TrackedClusters;
	std::vector&lt;PlannerHNS::DetectedObject&gt; m_DetectedBoxes;
	bool bNewClusters;
	jsk_recognition_msgs::BoundingBoxArray m_BoundingBoxes;
	bool bNewBoxes;

	PlannerHNS::VehicleState m_VehicleState;
	bool bVehicleState;

	bool bNewEmergency;
	int m_bEmergencyStop;

	bool bNewTrafficLigh;
	bool m_bGreenLight;

	bool bNewOutsideControl;
	int m_bOutsideControl;

	std::vector&lt;PlannerHNS::WayPoint&gt; m_AStarPath;
	bool bNewAStarPath;
	timespec m_AStartPlanningTimer;

	std::vector&lt;std::vector&lt;PlannerHNS::WayPoint&gt; &gt; m_WayPlannerPaths;
	bool bWayPlannerPath;


	//Planning Related variables
	PlannerHNS::BehaviorState m_CurrentBehavior;
	PlannerHNS::BehaviorState m_PrevBehavior;
	//PlannerHNS::WayPoint m_CurrentGoal;
	struct timespec m_PlanningTimer;
	AutowareRoadNetwork m_AwMap;
  	PlannerHNS::RoadNetwork m_Map;
  	MAP_SOURCE_TYPE	m_MapSource;
  	bool	bKmlMapLoaded;
  	std::string m_KmlMapPath;

  	bool m_bEnableTracking;
  	bool m_bEnableOutsideControl;

  	std::vector&lt;std::string&gt;    m_LogData;


protected:
	//ROS messages (topics)

	ros::NodeHandle nh;

	//define publishers
	ros::Publisher pub_LocalPath;
	ros::Publisher pub_LocalBasePath;
	ros::Publisher pub_ClosestIndex;
	ros::Publisher pub_BehaviorState;
	ros::Publisher pub_GlobalPlanNodes;
	ros::Publisher pub_StartPoint;
	ros::Publisher pub_GoalPoint;
	ros::Publisher pub_AStarStartPoint;
	ros::Publisher pub_AStarGoalPoint;

	ros::Publisher pub_DetectedPolygonsRviz;
	ros::Publisher pub_TrackedObstaclesRviz;
	ros::Publisher pub_LocalTrajectoriesRviz;
	ros::Publisher pub_TestLineRviz;
	ros::Publisher pub_BehaviorStateRviz;
	ros::Publisher pub_SafetyBorderRviz;
	ros::Publisher pub_cluster_cloud;
	ros::Publisher pub_SimuBoxPose;

	// define subscribers.
	ros::Subscriber sub_initialpose			;
	ros::Subscriber sub_current_pose 		;
	ros::Subscriber sub_current_velocity	;
	ros::Subscriber sub_cluster_cloud		;
	ros::Subscriber sub_bounding_boxs		;
	ros::Subscriber sub_vehicle_simu_status ;
	ros::Subscriber sub_robot_odom			;
	ros::Subscriber sub_can_info			;
	ros::Subscriber sub_EmergencyStop		;
	ros::Subscriber sub_TrafficLight		;
	ros::Subscriber sub_OutsideControl		;
	ros::Subscriber sub_AStarPath			;
	ros::Subscriber sub_WayPlannerPaths		;

	ros::Subscriber sub_CostMap				;

	//vector map subscription
	ros::Subscriber sub_map_points;
	ros::Subscriber sub_map_lanes;
	ros::Subscriber sub_map_nodes;
	ros::Subscriber sup_stop_lines;
	ros::Subscriber sub_dtlanes;

	ros::Subscriber sub_simulated_obstacle_pose_rviz;

	// Callback function for subscriber.
	void callbackGetInitPose(const geometry_msgs::PoseWithCovarianceStampedConstPtr &amp;input);
	void callbackGetCurrentPose(const geometry_msgs::PoseStampedConstPtr&amp; msg);
	void callbackGetCloudClusters(const lidar_tracker::CloudClusterArrayConstPtr&amp; msg);
	void callbackGetBoundingBoxes(const jsk_recognition_msgs::BoundingBoxArrayConstPtr&amp; msg);
	void callbackGetVehicleStatus(const geometry_msgs::TwistStampedConstPtr&amp; msg);
	void callbackGetCanInfo(const vehicle_socket::CanInfoConstPtr &amp;msg);
	void callbackGetRobotOdom(const nav_msgs::OdometryConstPtr&amp; msg);
	void callbackGetEmergencyStop(const std_msgs::Int8&amp; msg);
	void callbackGetTrafficLight(const std_msgs::Int8&amp; msg);
	void callbackGetOutsideControl(const std_msgs::Int8&amp; msg);
	void callbackGetAStarPath(const waypoint_follower_msgs::LaneArrayConstPtr&amp; msg);
	void callbackGetWayPlannerPath(const waypoint_follower_msgs::LaneArrayConstPtr&amp; msg);
	void callbackGetCostMap(const nav_msgs::OccupancyGrid&amp; msg);


	//Vector map callbacks
	void callbackGetVMPoints(const vector_map_msgs::PointArray&amp; msg);
	void callbackGetVMLanes(const vector_map_msgs::LaneArray&amp; msg);
	void callbackGetVMNodes(const vector_map_msgs::NodeArray&amp; msg);
	void callbackGetVMStopLines(const vector_map_msgs::StopLineArray&amp; msg);
	void callbackGetVMCenterLines(const vector_map_msgs::DTLaneArray&amp; msg);

	//for simulation
	void callbackGetRvizPoint(const geometry_msgs::PointStampedConstPtr&amp; msg);


public:
  PlannerX();
  ~PlannerX();
  void PlannerMainLoop();

protected:
  //Helper Functions
  void UpdatePlanningParams();

  lidar_tracker::CloudCluster GenerateSimulatedObstacleCluster(const double&amp; x_rand, const double&amp; y_rand, const double&amp; z_rand, const int&amp; nPoints, const geometry_msgs::PointStamped&amp; centerPose);

#ifdef DATASET_GENERATION_BLOCK
private:
  struct DataPairs
  {
	  cv::Mat image;
	  PlannerHNS::VehicleState vehicleState;
	  PlannerHNS::WayPoint currentPos;
	  std::vector&lt;PlannerHNS::WayPoint&gt; path;
	  std::vector&lt; std::vector&lt;PlannerHNS::WayPoint&gt; &gt; predictedPaths;
  };

  int m_iRecordNumber;
  cv::Mat m_CurrImage;
  std::vector&lt;DataPairs&gt; m_DrivePoints;

  //tf::TransformListener m_Transformation;
  std::ofstream m_ImagesVectors;
  std::ofstream m_TrajVectors;

  ros::Subscriber sub_image_reader;
  void callbackReadImage(const sensor_msgs::ImageConstPtr&amp; msg);
  void ExtractPathFromDriveData(double max_extraction = 50);
  void WritePathCSV(const std::string&amp; fName, std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path);
  void WriteImageAndPathCSV(cv::Mat img, std::vector&lt;PlannerHNS::WayPoint&gt;&amp; path);

#endif

};

}

#endif  // dp_planner_H
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="d341c9a7a8a2a1c63b790726a96458ec4cbb1a1f" fix_time="0,0">
		<msg>fix a build issue for kinetic</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/draw_lane.cpp" new_path="ros/src/computing/perception/detection/packages/integrated_viewer/node/image_viewer_plugin/draw_lane.cpp">
				<diff>@@ -1,10 +1,9 @@
 #include &quot;draw_lane.h&quot;
 
+#include &lt;opencv/cv.hpp&gt;
 #include &lt;opencv2/core/version.hpp&gt;
 
-#if (CV_MAJOR_VERSION == 3)
-#include &quot;gencolors.cpp&quot;
-#else
+#if (CV_MAJOR_VERSION != 3)
 #include &lt;opencv2/contrib/contrib.hpp&gt;
 #endif
 
</diff>
				<old_file>#include &quot;draw_lane.h&quot;

#include &lt;opencv2/core/version.hpp&gt;

#if (CV_MAJOR_VERSION == 3)
#include &quot;gencolors.cpp&quot;
#else
#include &lt;opencv2/contrib/contrib.hpp&gt;
#endif

namespace integrated_viewer
{
  const int DrawLane::kLineThickness = 3;
  const cv::Scalar DrawLane::kRed = CV_RGB(255, 0, 0);

  DrawLane::DrawLane(void) {
  }  // DrawLane::DrawLane()

  void DrawLane::Draw(const lane_detector::ImageLaneObjects::ConstPtr&amp; lane,
                      cv::Mat &amp;image) {
    if (lane == NULL) {
      return;
    }

    // Draw detected lane
    cv::Point left_lane_start(lane-&gt;lane_l_x1, lane-&gt;lane_l_y1);
    cv::Point left_lane_end(lane-&gt;lane_l_x2, lane-&gt;lane_l_y2);
    cv::Point right_lane_start(lane-&gt;lane_r_x1, lane-&gt;lane_r_y1);
    cv::Point right_lane_end(lane-&gt;lane_r_x2, lane-&gt;lane_r_y2);

    cv::line(image, left_lane_start, left_lane_end, kRed, kLineThickness);
    cv::line(image, right_lane_start, right_lane_end, kRed, kLineThickness);

  }  // void DrawLane::Draw()
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="96e02231a241f3e4aa736826b1ef6654bdba3f32" fix_time="0,0">
		<msg>fixed build issues</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp">
				<diff>@@ -26,7 +26,6 @@
 #include &lt;pcl/segmentation/sac_segmentation.h&gt;
 #include &lt;pcl/segmentation/extract_clusters.h&gt;
 #include &lt;pcl/segmentation/conditional_euclidean_clustering.h&gt;
-#include &lt;pcl/segmentation/progressive_morphological_filter.h&gt;
 
 #include &lt;pcl/common/common.h&gt;
 
</diff>
				<old_file>#include &lt;ros/ros.h&gt;

#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/PCLPointCloud2.h&gt;
#include &lt;pcl/conversions.h&gt;
#include &lt;pcl_ros/transforms.h&gt;
#include &lt;pcl_ros/point_cloud.h&gt;

#include &lt;pcl/ModelCoefficients.h&gt;
#include &lt;pcl/point_types.h&gt;

#include &lt;pcl/filters/extract_indices.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;
#include &lt;pcl/filters/conditional_removal.h&gt;

#include &lt;pcl/features/normal_3d.h&gt;
#include &lt;pcl/features/normal_3d_omp.h&gt;
#include &lt;pcl/features/don.h&gt;
#include &lt;pcl/features/fpfh_omp.h&gt;

#include &lt;pcl/kdtree/kdtree.h&gt;

#include &lt;pcl/sample_consensus/method_types.h&gt;
#include &lt;pcl/sample_consensus/model_types.h&gt;

#include &lt;pcl/segmentation/sac_segmentation.h&gt;
#include &lt;pcl/segmentation/extract_clusters.h&gt;
#include &lt;pcl/segmentation/conditional_euclidean_clustering.h&gt;
#include &lt;pcl/segmentation/progressive_morphological_filter.h&gt;

#include &lt;pcl/common/common.h&gt;

#include &lt;pcl/search/organized.h&gt;
#include &lt;pcl/search/kdtree.h&gt;

#include &lt;pcl/segmentation/extract_clusters.h&gt;

#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;

#include &lt;std_msgs/Float32MultiArray.h&gt;
#include &lt;std_msgs/MultiArrayLayout.h&gt;
#include &lt;std_msgs/MultiArrayDimension.h&gt;

#include &lt;lidar_tracker/centroids.h&gt;
#include &lt;lidar_tracker/CloudCluster.h&gt;
#include &lt;lidar_tracker/CloudClusterArray.h&gt;

#include &lt;vector_map_server/PositionState.h&gt;

#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;
#include &lt;jsk_rviz_plugins/Pictogram.h&gt;
#include &lt;jsk_rviz_plugins/PictogramArray.h&gt;

#include &lt;tf/tf.h&gt;

#include &lt;limits&gt;
#include &lt;cmath&gt;

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/contrib/contrib.hpp&gt;

#include &lt;chrono&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
#include &lt;sstream&gt;

#include &quot;Cluster.h&quot;

//#include &lt;vector_map/vector_map.h&gt;
//#include &lt;vector_map_server/GetSignal.h&gt;

using namespace cv;

std::vector&lt;cv::Scalar&gt; _colors;
ros::Publisher _pub_cluster_cloud;
ros::Publisher _pub_ground_cloud;
ros::Publisher _centroid_pub;
ros::Publisher _marker_pub;
ros::Publisher _pub_clusters_message;
ros::Publisher _pub_text_pictogram;
visualization_msgs::Marker _visualization_marker;

ros::Publisher _pub_points_lanes_cloud;
ros::Publisher _pub_jsk_boundingboxes;
ros::Publisher _pub_jsk_hulls;

ros::ServiceClient _vectormap_server;

std_msgs::Header _velodyne_header;

pcl::PointCloud&lt;pcl::PointXYZ&gt; _sensor_cloud;

std::vector&lt;double&gt; _clustering_thresholds;
std::vector&lt;double&gt; _clustering_distances;

tf::StampedTransform* _transform;
tf::StampedTransform* _velodyne_output_transform;
tf::TransformListener* _transform_listener;

std::string _output_frame;
std::string _vectormap_frame;
static bool _velodyne_transform_available;
static bool _downsample_cloud;
static bool _pose_estimation;
static double _leaf_size;
static int _cluster_size_min;
static int _cluster_size_max;

static bool _remove_ground;	//only ground

static bool _using_sensor_cloud;
static bool _use_diffnormals;
static bool _use_vector_map;

static double _clip_min_height;
static double _clip_max_height;

static bool _keep_lanes;
static double _keep_lane_left_distance;
static double _keep_lane_right_distance;

static double _max_boundingbox_side;
static double _remove_points_upto;
static double _cluster_merge_threshold;

void transformBoundingBox(const jsk_recognition_msgs::BoundingBox&amp; in_boundingbox, jsk_recognition_msgs::BoundingBox&amp; out_boundingbox, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	geometry_msgs::PoseStamped pose_in, pose_out;
	pose_in.header = in_header;
	pose_in.pose = in_boundingbox.pose;
	try
	{
		_transform_listener-&gt;transformPose(in_target_frame, ros::Time(), pose_in, in_header.frame_id,  pose_out);
	}
	catch (tf::TransformException &amp;ex)
	{
		ROS_ERROR(&quot;transformBoundingBox: %s&quot;,ex.what());
	}
	out_boundingbox.pose = pose_out.pose;
	out_boundingbox.header = in_header;
	out_boundingbox.header.frame_id = in_target_frame;
	out_boundingbox.dimensions = in_boundingbox.dimensions;
	out_boundingbox.value = in_boundingbox.value;
	out_boundingbox.label = in_boundingbox.label;
}

void publishCloudClusters(const ros::Publisher* in_publisher, const lidar_tracker::CloudClusterArray&amp; in_clusters, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		lidar_tracker::CloudClusterArray clusters_transformed;
		clusters_transformed.header = in_header;
		clusters_transformed.header.frame_id = in_target_frame;
		for (auto i=in_clusters.clusters.begin(); i!= in_clusters.clusters.end(); i++)
		{
			lidar_tracker::CloudCluster cluster_transformed;
			cluster_transformed.header = in_header;
			try
			{
				_transform_listener-&gt;lookupTransform(in_target_frame, _velodyne_header.frame_id,
										ros::Time(), *_transform);
				pcl_ros::transformPointCloud(in_target_frame, *_transform, i-&gt;cloud, cluster_transformed.cloud);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;min_point, in_header.frame_id, cluster_transformed.min_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;max_point, in_header.frame_id, cluster_transformed.max_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;avg_point, in_header.frame_id, cluster_transformed.avg_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;centroid_point, in_header.frame_id, cluster_transformed.centroid_point);

				cluster_transformed.dimensions = i-&gt;dimensions;
				cluster_transformed.eigen_values = i-&gt;eigen_values;
				cluster_transformed.eigen_vectors = i-&gt;eigen_vectors;

				transformBoundingBox(i-&gt;bounding_box, cluster_transformed.bounding_box, in_target_frame, in_header);

				clusters_transformed.clusters.push_back(cluster_transformed);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCloudClusters: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(clusters_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_clusters);
	}
}

void publishCentroids(const ros::Publisher* in_publisher, const lidar_tracker::centroids&amp; in_centroids, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		lidar_tracker::centroids centroids_transformed;
		centroids_transformed.header = in_header;
		centroids_transformed.header.frame_id = in_target_frame;
		for (auto i=centroids_transformed.points.begin(); i!= centroids_transformed.points.end(); i++)
		{
			geometry_msgs::PointStamped centroid_in, centroid_out;
			centroid_in.header = in_header;
			centroid_in.point = *i;
			try
			{
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), centroid_in, in_header.frame_id, centroid_out);

				centroids_transformed.points.push_back(centroid_out.point);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCentroids: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(centroids_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_centroids);
	}
}

void publishBoundingBoxArray(const ros::Publisher* in_publisher, const jsk_recognition_msgs::BoundingBoxArray&amp; in_boundingbox_array, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		jsk_recognition_msgs::BoundingBoxArray boundingboxes_transformed;
		boundingboxes_transformed.header = in_header;
		boundingboxes_transformed.header.frame_id = in_target_frame;
		for (auto i=in_boundingbox_array.boxes.begin(); i!= in_boundingbox_array.boxes.end(); i++)
		{
			jsk_recognition_msgs::BoundingBox boundingbox_transformed;
			transformBoundingBox(*i, boundingbox_transformed, in_target_frame, in_header);
			boundingboxes_transformed.boxes.push_back(boundingbox_transformed);
		}
		in_publisher-&gt;publish(boundingboxes_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_boundingbox_array);
	}
}

void publishCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void publishColorCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void keepLanePoints(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
					pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr,
					float in_left_lane_threshold = 1.5,
					float in_right_lane_threshold = 1.5)
{
	pcl::PointIndices::Ptr far_indices (new pcl::PointIndices);
	for(unsigned int i=0; i&lt; in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x=in_cloud_ptr-&gt;points[i].x;
		current_point.y=in_cloud_ptr-&gt;points[i].y;
		current_point.z=in_cloud_ptr-&gt;points[i].z;

		if (
				current_point.y &gt; (in_left_lane_threshold) || current_point.y &lt; -1.0*in_right_lane_threshold
			)
		{
			far_indices-&gt;indices.push_back(i);
		}
	}
	out_cloud_ptr-&gt;points.clear();
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(far_indices);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_cloud_ptr);
}

std::vector&lt;ClusterPtr&gt; clusterAndColor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		lidar_tracker::centroids&amp; in_out_centroids,
		double in_max_cluster_distance=0.5)
{
	pcl::search::KdTree&lt;pcl::PointXYZ&gt;::Ptr tree (new pcl::search::KdTree&lt;pcl::PointXYZ&gt;);

	//create 2d pc
	pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud_2d(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
	pcl::copyPointCloud(*in_cloud_ptr, *cloud_2d);
	//make it flat
	for (size_t i=0; i&lt;cloud_2d-&gt;points.size(); i++)
	{
		cloud_2d-&gt;points[i].z = 0;
	}

	if (cloud_2d-&gt;points.size() &gt; 0)
		tree-&gt;setInputCloud (cloud_2d);

	std::vector&lt;pcl::PointIndices&gt; cluster_indices;

	//perform clustering on 2d cloud
	pcl::EuclideanClusterExtraction&lt;pcl::PointXYZ&gt; ec;
	ec.setClusterTolerance (in_max_cluster_distance); //
	ec.setMinClusterSize (_cluster_size_min);
	ec.setMaxClusterSize (_cluster_size_max);
	ec.setSearchMethod(tree);
	ec.setInputCloud (cloud_2d);
	ec.extract (cluster_indices);
	//use indices on 3d cloud

	/*pcl::ConditionalEuclideanClustering&lt;pcl::PointXYZ&gt; cec (true);
	cec.setInputCloud (in_cloud_ptr);
	cec.setConditionFunction (&amp;independentDistance);
	cec.setMinClusterSize (cluster_size_min);
	cec.setMaxClusterSize (cluster_size_max);
	cec.setClusterTolerance (_distance*2.0f);
	cec.segment (cluster_indices);*/

	/////////////////////////////////
	//---	3. Color clustered points
	/////////////////////////////////
	unsigned int k = 0;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr final_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

	std::vector&lt;ClusterPtr&gt; clusters;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr cloud_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);//coord + color cluster
	for (auto it = cluster_indices.begin(); it != cluster_indices.end(); ++it)
	{
		ClusterPtr cluster(new Cluster());
		cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;indices, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		clusters.push_back(cluster);

		k++;
	}
	//std::cout &lt;&lt; &quot;Clusters: &quot; &lt;&lt; k &lt;&lt; std::endl;
	return clusters;

}

void checkClusterMerge(size_t in_cluster_id, std::vector&lt;ClusterPtr&gt;&amp; in_clusters, std::vector&lt;bool&gt;&amp; in_out_visited_clusters, std::vector&lt;size_t&gt;&amp; out_merge_indices, double in_merge_threshold)
{
	//std::cout &lt;&lt; &quot;checkClusterMerge&quot; &lt;&lt; std::endl;
	pcl::PointXYZ point_a = in_clusters[in_cluster_id]-&gt;GetCentroid();
	for(size_t i=0; i&lt; in_clusters.size(); i++)
	{
		if (i != in_cluster_id &amp;&amp; !in_out_visited_clusters[i])
		{
			pcl::PointXYZ point_b = in_clusters[i]-&gt;GetCentroid();
			double distance = sqrt( pow(point_b.x - point_a.x,2) + pow(point_b.y - point_a.y,2) );
			if (distance &lt;= in_merge_threshold)
			{
				in_out_visited_clusters[i] = true;
				out_merge_indices.push_back(i);
				//std::cout &lt;&lt; &quot;Merging &quot; &lt;&lt; in_cluster_id &lt;&lt; &quot; with &quot; &lt;&lt; i &lt;&lt; &quot; dist:&quot; &lt;&lt; distance &lt;&lt; std::endl;
				checkClusterMerge(i, in_clusters, in_out_visited_clusters, out_merge_indices, in_merge_threshold);
			}
		}
	}
}

void mergeClusters(const std::vector&lt;ClusterPtr&gt;&amp; in_clusters, std::vector&lt;ClusterPtr&gt;&amp; out_clusters, std::vector&lt;size_t&gt; in_merge_indices, const size_t&amp; current_index, std::vector&lt;bool&gt;&amp; in_out_merged_clusters)
{
	//std::cout &lt;&lt; &quot;mergeClusters:&quot; &lt;&lt; in_merge_indices.size() &lt;&lt; std::endl;
	pcl::PointCloud&lt;pcl::PointXYZRGB&gt; sum_cloud;
	pcl::PointCloud&lt;pcl::PointXYZ&gt; mono_cloud;
	ClusterPtr merged_cluster(new Cluster());
	for (size_t i=0; i&lt;in_merge_indices.size(); i++)
	{
		sum_cloud += *(in_clusters[in_merge_indices[i]]-&gt;GetCloud());
		in_out_merged_clusters[in_merge_indices[i]] = true;
	}
	std::vector&lt;int&gt; indices(sum_cloud.points.size(), 0);
	for (size_t i=0; i&lt;sum_cloud.points.size(); i++)
	{
		indices[i]=i;
	}

	if (sum_cloud.points.size() &gt; 0)
	{
		pcl::copyPointCloud(sum_cloud, mono_cloud);
		//std::cout &lt;&lt; &quot;mergedClusters &quot; &lt;&lt; sum_cloud.points.size() &lt;&lt; &quot; mono:&quot; &lt;&lt; mono_cloud.points.size() &lt;&lt; std::endl;
		//cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;indices, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		merged_cluster-&gt;SetCloud(mono_cloud.makeShared(), indices, _velodyne_header, current_index,(int)_colors[current_index].val[0], (int)_colors[current_index].val[1], (int)_colors[current_index].val[2], &quot;&quot;, _pose_estimation);
		out_clusters.push_back(merged_cluster);
	}
}

void checkAllForMerge(std::vector&lt;ClusterPtr&gt;&amp; in_clusters, std::vector&lt;ClusterPtr&gt;&amp; out_clusters, float in_merge_threshold)
{
	//std::cout &lt;&lt; &quot;checkAllForMerge&quot; &lt;&lt; std::endl;
	std::vector&lt;bool&gt; visited_clusters(in_clusters.size(), false);
	std::vector&lt;bool&gt; merged_clusters(in_clusters.size(), false);
	size_t current_index=0;
	for (size_t i = 0; i&lt; in_clusters.size(); i++)
	{
		if (!visited_clusters[i])
		{
			visited_clusters[i] = true;
			std::vector&lt;size_t&gt; merge_indices;
			checkClusterMerge(i, in_clusters, visited_clusters, merge_indices, in_merge_threshold);
			mergeClusters(in_clusters, out_clusters, merge_indices, current_index++, merged_clusters);
		}
	}
	for(size_t i =0; i&lt; in_clusters.size(); i++)
	{
		//check for clusters not merged, add them to the output
		if (!merged_clusters[i])
		{
			out_clusters.push_back(in_clusters[i]);
		}
	}

	//ClusterPtr cluster(new Cluster());
}

void segmentByDistance(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		lidar_tracker::centroids&amp; in_out_centroids,
		lidar_tracker::CloudClusterArray&amp; in_out_clusters,
		jsk_recognition_msgs::PolygonArray&amp; in_out_polygon_array,
		jsk_rviz_plugins::PictogramArray&amp; in_out_pictogram_array)
{
	//cluster the pointcloud according to the distance of the points using different thresholds (not only one for the entire pc)
	//in this way, the points farther in the pc will also be clustered

	//0 =&gt; 0-15m d=0.5
	//1 =&gt; 15-30 d=1
	//2 =&gt; 30-45 d=1.6
	//3 =&gt; 45-60 d=2.1
	//4 =&gt; &gt;60   d=2.6

	std::vector&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr&gt; cloud_segments_array(5);

	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr tmp_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		cloud_segments_array[i] = tmp_cloud;
	}

	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x = in_cloud_ptr-&gt;points[i].x;
		current_point.y = in_cloud_ptr-&gt;points[i].y;
		current_point.z = in_cloud_ptr-&gt;points[i].z;

		float origin_distance = sqrt( pow(current_point.x,2) + pow(current_point.y,2) );

		if 		(origin_distance &lt; _clustering_distances[0] )	{cloud_segments_array[0]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[1])		{cloud_segments_array[1]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[2])		{cloud_segments_array[2]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[3])		{cloud_segments_array[3]-&gt;points.push_back (current_point);}
		else													{cloud_segments_array[4]-&gt;points.push_back (current_point);}
	}

	std::vector &lt;ClusterPtr&gt; all_clusters;
	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
		std::vector&lt;ClusterPtr&gt; local_clusters = clusterAndColor(cloud_segments_array[i], out_cloud_ptr, in_out_boundingbox_array, in_out_centroids, _clustering_thresholds[i]);

		all_clusters.insert(all_clusters.end(), local_clusters.begin(), local_clusters.end());
	}

	//Clusters can be merged or checked in here
	//....
	//check for mergable clusters
	std::vector&lt;ClusterPtr&gt; mid_clusters;
	std::vector&lt;ClusterPtr&gt; final_clusters;

	if (all_clusters.size() &gt; 0)
		checkAllForMerge(all_clusters, mid_clusters, _cluster_merge_threshold);
	else
		mid_clusters = all_clusters;

	if (mid_clusters.size() &gt; 0)
			checkAllForMerge(mid_clusters, final_clusters, _cluster_merge_threshold);
	else
		final_clusters = mid_clusters;

	tf::StampedTransform vectormap_transform;
	if (_use_vector_map)
	{
		cv::TickMeter timer;

		try
		{
			//if the frame of the vectormap is different than the input, obtain transform
			if (_vectormap_frame != _velodyne_header.frame_id)
			{
				_transform_listener-&gt;lookupTransform(_vectormap_frame, _velodyne_header.frame_id, ros::Time(), vectormap_transform);
			}

			timer.reset();timer.start();

			//check if centroids are inside the drivable area
			for(unsigned int i=0; i&lt;final_clusters.size(); i++)
			{
				//transform centroid points to vectormap frame
				pcl::PointXYZ pcl_centroid = final_clusters[i]-&gt;GetCentroid();
				tf::Vector3 vector_centroid (pcl_centroid.x, pcl_centroid.y, pcl_centroid.z);
				tf::Vector3 transformed_centroid;

				if (_vectormap_frame != _velodyne_header.frame_id)
					transformed_centroid = vectormap_transform*vector_centroid;
				else
					transformed_centroid = vector_centroid;

				vector_map_server::PositionState position_state;
				position_state.request.position.x = transformed_centroid.getX();
				position_state.request.position.y = transformed_centroid.getY();
				position_state.request.position.z = transformed_centroid.getZ();


				if (_vectormap_server.call(position_state))
				{
					final_clusters[i]-&gt;SetValidity(position_state.response.state);
					/*std::cout &lt;&lt; &quot;Original:&quot; &lt;&lt; pcl_centroid.x &lt;&lt; &quot;,&quot; &lt;&lt; pcl_centroid.y &lt;&lt; &quot;,&quot; &lt;&lt; pcl_centroid.z &lt;&lt;
							&quot; Transformed:&quot; &lt;&lt; transformed_centroid.x() &lt;&lt; &quot;,&quot; &lt;&lt; transformed_centroid.y() &lt;&lt; &quot;,&quot; &lt;&lt; transformed_centroid.z() &lt;&lt;
							&quot; Validity:&quot; &lt;&lt; position_state.response.state &lt;&lt; std::endl;*/
				}
				else
				{
					ROS_INFO(&quot;vectormap_filtering: VectorMap Server Call failed. Make sure vectormap_server is running. No filtering performed.&quot;);
					final_clusters[i]-&gt;SetValidity(true);
				}
			}
			timer.stop();
			//std::cout &lt;&lt; &quot;vm server took &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot; ms to check &quot; &lt;&lt; final_clusters.size() &lt;&lt; std::endl;
		}
		catch(tf::TransformException &amp;ex)
		{
			ROS_INFO(&quot;vectormap_filtering: %s&quot;, ex.what());
		}
	}
	//Get final PointCloud to be published
	in_out_polygon_array.header = _velodyne_header;
	in_out_pictogram_array.header = _velodyne_header;
	for(unsigned int i=0; i&lt;final_clusters.size(); i++)
	{
		*out_cloud_ptr = *out_cloud_ptr + *(final_clusters[i]-&gt;GetCloud());

		jsk_recognition_msgs::BoundingBox bounding_box = final_clusters[i]-&gt;GetBoundingBox();
		geometry_msgs::PolygonStamped polygon = final_clusters[i]-&gt;GetPolygon();
		jsk_rviz_plugins::Pictogram pictogram_cluster;
		pictogram_cluster.header = _velodyne_header;

		//PICTO
		pictogram_cluster.mode = pictogram_cluster.STRING_MODE;
		pictogram_cluster.pose.position.x = final_clusters[i]-&gt;GetMaxPoint().x;
		pictogram_cluster.pose.position.y = final_clusters[i]-&gt;GetMaxPoint().y;
		pictogram_cluster.pose.position.z = final_clusters[i]-&gt;GetMaxPoint().z;
		tf::Quaternion quat(0.0, -0.7, 0.0, 0.7);
		tf::quaternionTFToMsg(quat, pictogram_cluster.pose.orientation);
		pictogram_cluster.size = 4;
		std_msgs::ColorRGBA color;
		color.a = 1; color.r = 1; color.g = 1; color.b = 1;
		pictogram_cluster.color = color;
		pictogram_cluster.character = std::to_string( i );
		//PICTO

		//pcl::PointXYZ min_point = final_clusters[i]-&gt;GetMinPoint();
		//pcl::PointXYZ max_point = final_clusters[i]-&gt;GetMaxPoint();
		pcl::PointXYZ center_point = final_clusters[i]-&gt;GetCentroid();
		geometry_msgs::Point centroid;
		centroid.x = center_point.x; centroid.y = center_point.y; centroid.z = center_point.z;
		bounding_box.header = _velodyne_header;
		polygon.header = _velodyne_header;

		if (	final_clusters[i]-&gt;IsValid()
				//&amp;&amp; bounding_box.dimensions.x &gt;0 &amp;&amp; bounding_box.dimensions.y &gt;0 &amp;&amp; bounding_box.dimensions.z &gt; 0
				//&amp;&amp;	bounding_box.dimensions.x &lt; _max_boundingbox_side &amp;&amp; bounding_box.dimensions.y &lt; _max_boundingbox_side
				)
		{
			in_out_boundingbox_array.boxes.push_back(bounding_box);
			in_out_centroids.points.push_back(centroid);
			_visualization_marker.points.push_back(centroid);

			in_out_polygon_array.polygons.push_back(polygon);
			in_out_pictogram_array.pictograms.push_back(pictogram_cluster);

			lidar_tracker::CloudCluster cloud_cluster;
			final_clusters[i]-&gt;ToRosMessage(_velodyne_header, cloud_cluster);
			in_out_clusters.clusters.push_back(cloud_cluster);
		}
	}

	for(size_t i=0; i&lt; in_out_polygon_array.polygons.size();i++)
	{
		in_out_polygon_array.labels.push_back(i);
	}

}

void removeFloor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_nofloor_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_onlyfloor_cloud_ptr, float in_max_height=0.2, float in_floor_max_angle=0.1)
{
	/*pcl::PointIndicesPtr ground (new pcl::PointIndices);
	// Create the filtering object
	pcl::ProgressiveMorphologicalFilter&lt;pcl::PointXYZ&gt; pmf;
	pmf.setInputCloud (in_cloud_ptr);
	pmf.setMaxWindowSize (20);
	pmf.setSlope (1.0f);
	pmf.setInitialDistance (0.5f);
	pmf.setMaxDistance (3.0f);
	pmf.extract (ground-&gt;indices);

	// Create the filtering object
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices (ground);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_nofloor_cloud_ptr);

	//EXTRACT THE FLOOR FROM THE CLOUD
	extract.setNegative(false);//true removes the indices, false leaves only the indices
	extract.filter(*out_onlyfloor_cloud_ptr);*/

	pcl::SACSegmentation&lt;pcl::PointXYZ&gt; seg;
	pcl::PointIndices::Ptr inliers (new pcl::PointIndices);
	pcl::ModelCoefficients::Ptr coefficients (new pcl::ModelCoefficients);

	seg.setOptimizeCoefficients (true);
	seg.setModelType(pcl::SACMODEL_PERPENDICULAR_PLANE);
	seg.setMethodType(pcl::SAC_RANSAC);
	seg.setMaxIterations(100);
	seg.setAxis(Eigen::Vector3f(0,0,1));
	seg.setEpsAngle(in_floor_max_angle);

	seg.setDistanceThreshold (in_max_height);//floor distance
	seg.setOptimizeCoefficients(true);
	seg.setInputCloud(in_cloud_ptr);
	seg.segment(*inliers, *coefficients);
	if (inliers-&gt;indices.size () == 0)
	{
		std::cout &lt;&lt; &quot;Could not estimate a planar model for the given dataset.&quot; &lt;&lt; std::endl;
	}

	//REMOVE THE FLOOR FROM THE CLOUD
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(inliers);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_nofloor_cloud_ptr);

	//EXTRACT THE FLOOR FROM THE CLOUD
	extract.setNegative(false);//true removes the indices, false leaves only the indices
	extract.filter(*out_onlyfloor_cloud_ptr);
}

void downsampleCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_leaf_size=0.2)
{
	pcl::VoxelGrid&lt;pcl::PointXYZ&gt; sor;
	sor.setInputCloud(in_cloud_ptr);
	sor.setLeafSize((float)in_leaf_size, (float)in_leaf_size, (float)in_leaf_size);
	sor.filter(*out_cloud_ptr);
}

void clipCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_min_height=-1.3, float in_max_height=0.5)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		if (in_cloud_ptr-&gt;points[i].z &gt;= in_min_height &amp;&amp;
				in_cloud_ptr-&gt;points[i].z &lt;= in_max_height)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void differenceNormalsSegmentation(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr)
{
	float small_scale=0.5;
	float large_scale=2.0;
	float angle_threshold=0.5;
	pcl::search::Search&lt;pcl::PointXYZ&gt;::Ptr tree;
	if (in_cloud_ptr-&gt;isOrganized ())
	{
		tree.reset (new pcl::search::OrganizedNeighbor&lt;pcl::PointXYZ&gt; ());
	}
	else
	{
		tree.reset (new pcl::search::KdTree&lt;pcl::PointXYZ&gt; (false));
	}

	// Set the input pointcloud for the search tree
	tree-&gt;setInputCloud (in_cloud_ptr);

	pcl::NormalEstimationOMP&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	//pcl::gpu::NormalEstimation&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	normal_estimation.setInputCloud (in_cloud_ptr);
	normal_estimation.setSearchMethod (tree);

	normal_estimation.setViewPoint (std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max ());

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_small_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_large_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	normal_estimation.setRadiusSearch (small_scale);
	normal_estimation.compute (*normals_small_scale);

	normal_estimation.setRadiusSearch (large_scale);
	normal_estimation.compute (*normals_large_scale);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::copyPointCloud&lt;pcl::PointXYZ, pcl::PointNormal&gt;(*in_cloud_ptr, *diffnormals_cloud);

	// Create DoN operator
	pcl::DifferenceOfNormalsEstimation&lt;pcl::PointXYZ, pcl::PointNormal, pcl::PointNormal&gt; diffnormals_estimator;
	diffnormals_estimator.setInputCloud (in_cloud_ptr);
	diffnormals_estimator.setNormalScaleLarge (normals_large_scale);
	diffnormals_estimator.setNormalScaleSmall (normals_small_scale);

	diffnormals_estimator.initCompute();

	diffnormals_estimator.computeFeature(*diffnormals_cloud);

	pcl::ConditionOr&lt;pcl::PointNormal&gt;::Ptr range_cond (new pcl::ConditionOr&lt;pcl::PointNormal&gt;() );
	range_cond-&gt;addComparison (pcl::FieldComparison&lt;pcl::PointNormal&gt;::ConstPtr (
			new pcl::FieldComparison&lt;pcl::PointNormal&gt; (&quot;curvature&quot;, pcl::ComparisonOps::GT, angle_threshold) )
			);
	// Build the filter
	pcl::ConditionalRemoval&lt;pcl::PointNormal&gt; cond_removal;
	cond_removal.setCondition(range_cond);
	cond_removal.setInputCloud (diffnormals_cloud);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud_filtered (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	// Apply filter
	cond_removal.filter (*diffnormals_cloud_filtered);

	pcl::copyPointCloud&lt;pcl::PointNormal, pcl::PointXYZ&gt;(*diffnormals_cloud, *out_cloud_ptr);
}

void removePointsUpTo(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, const double in_distance)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		float origin_distance = sqrt( pow(in_cloud_ptr-&gt;points[i].x,2) + pow(in_cloud_ptr-&gt;points[i].y,2) );
		if (origin_distance &gt; in_distance)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void velodyne_callback(const sensor_msgs::PointCloud2ConstPtr&amp; in_sensor_cloud)
{
	if (!_using_sensor_cloud)
	{
		_using_sensor_cloud = true;

		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr current_sensor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr removed_points_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr downsampled_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr inlanes_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr nofloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr onlyfloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr diffnormals_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr clipped_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr colored_clustered_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

		lidar_tracker::centroids centroids;
		lidar_tracker::CloudClusterArray cloud_clusters;
		jsk_recognition_msgs::BoundingBoxArray boundingbox_array;
		jsk_recognition_msgs::PolygonArray polygon_array;
		jsk_rviz_plugins::PictogramArray pictograms_array;

		pcl::fromROSMsg(*in_sensor_cloud, *current_sensor_cloud_ptr);

		_velodyne_header = in_sensor_cloud-&gt;header;

		cv::TickMeter timer;

		timer.reset();timer.start();

		if (_remove_points_upto &gt; 0.0)
		{
			removePointsUpTo(current_sensor_cloud_ptr, removed_points_cloud_ptr, _remove_points_upto);
		}
		else
			removed_points_cloud_ptr = current_sensor_cloud_ptr;

		//std::cout &lt;&lt; &quot;Downsample before: &quot; &lt;&lt;removed_points_cloud_ptr-&gt;points.size();
		if (_downsample_cloud)
			downsampleCloud(removed_points_cloud_ptr, downsampled_cloud_ptr, _leaf_size);
		else
			downsampled_cloud_ptr =removed_points_cloud_ptr;

		//std::cout &lt;&lt; &quot; after: &quot; &lt;&lt;downsampled_cloud_ptr-&gt;points.size();
		timer.stop(); //std::cout &lt;&lt; &quot;downsampleCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		clipCloud(downsampled_cloud_ptr, clipped_cloud_ptr, _clip_min_height, _clip_max_height);
		timer.stop(); //std::cout &lt;&lt; &quot;clipCloud:&quot; &lt;&lt; clipped_cloud_ptr-&gt;points.size() &lt;&lt; &quot;time &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		if(_keep_lanes)
			keepLanePoints(clipped_cloud_ptr, inlanes_cloud_ptr, _keep_lane_left_distance, _keep_lane_right_distance);
		else
			inlanes_cloud_ptr = clipped_cloud_ptr;
		timer.stop(); //std::cout &lt;&lt; &quot;keepLanePoints:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		if(_remove_ground)
		{
			removeFloor(inlanes_cloud_ptr, nofloor_cloud_ptr, onlyfloor_cloud_ptr);
			publishCloud(&amp;_pub_ground_cloud, onlyfloor_cloud_ptr);
		}
		else
			nofloor_cloud_ptr = inlanes_cloud_ptr;
		timer.stop(); //std::cout &lt;&lt; &quot;removeFloor:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		publishCloud(&amp;_pub_points_lanes_cloud, nofloor_cloud_ptr);

		timer.reset();timer.start();
		if (_use_diffnormals)
			differenceNormalsSegmentation(nofloor_cloud_ptr, diffnormals_cloud_ptr);
		else
			diffnormals_cloud_ptr = nofloor_cloud_ptr;
		timer.stop(); //std::cout &lt;&lt; &quot;differenceNormalsSegmentation:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		segmentByDistance(diffnormals_cloud_ptr, colored_clustered_cloud_ptr, boundingbox_array, centroids, cloud_clusters, polygon_array, pictograms_array);
		//timer.stop(); std::cout &lt;&lt; &quot;segmentByDistance:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		publishColorCloud(&amp;_pub_cluster_cloud, colored_clustered_cloud_ptr);
		timer.stop(); //std::cout &lt;&lt; &quot;publishColorCloud:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
		// Publish BB
		boundingbox_array.header = _velodyne_header;

		_pub_jsk_hulls.publish(polygon_array);//publish convex hulls
		_pub_text_pictogram.publish(pictograms_array);//publish_ids

		timer.reset();timer.start();
		publishBoundingBoxArray(&amp;_pub_jsk_boundingboxes, boundingbox_array, _output_frame, _velodyne_header);
		centroids.header = _velodyne_header;
		timer.stop(); //std::cout &lt;&lt; &quot;publishBoundingBoxArray:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		timer.reset();timer.start();
		publishCentroids(&amp;_centroid_pub, centroids, _output_frame, _velodyne_header);
		timer.stop(); //std::cout &lt;&lt; &quot;publishCentroids:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;

		_marker_pub.publish(_visualization_marker);
		_visualization_marker.points.clear();//transform? is it used?
		cloud_clusters.header = _velodyne_header;

		timer.reset();timer.start();
		publishCloudClusters(&amp;_pub_clusters_message, cloud_clusters, _output_frame, _velodyne_header);
		timer.stop(); //std::cout &lt;&lt; &quot;publishCloudClusters:&quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl &lt;&lt; std::endl;

		_using_sensor_cloud = false;
	}
}

/*
void vectormap_callback(const visualization_msgs::MarkerArray::Ptr in_vectormap_markers)
{
	float min_x=std::numeric_limits&lt;float&gt;::max();float max_x=-std::numeric_limits&lt;float&gt;::max();
	float min_y=std::numeric_limits&lt;float&gt;::max();float max_y=-std::numeric_limits&lt;float&gt;::max();
	pcl::PointXYZ min_point;
	pcl::PointXYZ max_point;
	std::vector&lt;geometry_msgs::Point&gt; vectormap_points;
	std::string marker_frame;
	double map_scale = -10.0;
	for(auto i=in_vectormap_markers-&gt;markers.begin(); i!= in_vectormap_markers-&gt;markers.end(); i++)
	{
		visualization_msgs::Marker current_marker = *i;
		marker_frame = current_marker.header.frame_id;
		if (current_marker.ns == &quot;road_edge&quot;)
		{
			for (unsigned int j=0; j&lt; current_marker.points.size(); j++)
			{
				geometry_msgs::Point p = current_marker.points[j];
				p.x*=map_scale;
				p.y*=map_scale;
				if(p.x&lt;min_x)	min_x = p.x;
				if(p.y&lt;min_y)	min_y = p.y;
				if(p.x&gt;max_x)	max_x = p.x;
				if(p.y&gt;max_y)	max_y = p.y;
				vectormap_points.push_back(p);
			}
		}
	}
	min_point.x = min_x;	min_point.y = min_y;
	max_point.x = max_x;	max_point.y = max_y;

	min_point.x*=-1.0;
	min_point.y*=-1.0;
	//translate the points to the minimum point
	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		(*i).x+=min_point.x;
		(*i).y+=min_point.y;
	}
	max_point.x+=min_point.x;
	max_point.y+=min_point.y;
	//get world tf
	std::string error_transform_msg;
	tf::Vector3 map_origin_point;
	if(_transform_listener-&gt;waitForTransform(&quot;/map&quot;, marker_frame, ros::Time(0), ros::Duration(5), ros::Duration(0.1), &amp;error_transform_msg))
	{
		_transform_listener-&gt;lookupTransform(&quot;/map&quot;, marker_frame, ros::Time(0), *_transform);
		map_origin_point = _transform-&gt;getOrigin();
		map_origin_point.setX( map_origin_point.x() - min_point.x);
		map_origin_point.setY( map_origin_point.y() - min_point.y);
	}
	else
	{
		ROS_INFO(&quot;Euclidean Cluster (vectormap_callback): %s&quot;, error_transform_msg.c_str());
	}

	cv::Mat map_image = cv::Mat::zeros(max_point.y, max_point.x, CV_8UC3);

	std::cout &lt;&lt; &quot;W,H:&quot; &lt;&lt; max_point &lt;&lt; std::endl;

	cv::Point image_start_point (vectormap_points[0].x, vectormap_points[0].y);
	cv::Point prev_point = image_start_point;
	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		cv::line(map_image, prev_point, cv::Point((int)(i-&gt;x), (int)(i-&gt;y)), cv::Scalar::all(255));

		prev_point.x = (int)(i-&gt;x);
		prev_point.y = (int)(i-&gt;y);
	}
	cv::circle(map_image, image_start_point, 3, cv::Scalar(255,0,0));
	cv::imshow(&quot;vectormap&quot;, map_image);
	cv::waitKey(0);
}*/

int main (int argc, char** argv)
{
	// Initialize ROS
	ros::init (argc, argv, &quot;euclidean_cluster&quot;);

	ros::NodeHandle h;
	ros::NodeHandle private_nh(&quot;~&quot;);

	tf::StampedTransform transform;
	tf::TransformListener listener;

	_transform = &amp;transform;
	_transform_listener = &amp;listener;

	cv::generateColors(_colors, 100);

	_pub_cluster_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_cluster&quot;,1);
	_pub_ground_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_ground&quot;,1);
	_centroid_pub = h.advertise&lt;lidar_tracker::centroids&gt;(&quot;/cluster_centroids&quot;,1);
	_marker_pub = h.advertise&lt;visualization_msgs::Marker&gt;(&quot;centroid_marker&quot;,1);

	_pub_points_lanes_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_lanes&quot;,1);
	_pub_jsk_boundingboxes = h.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(&quot;/bounding_boxes&quot;,1);
	_pub_jsk_hulls = h.advertise&lt;jsk_recognition_msgs::PolygonArray&gt;(&quot;/cluster_hulls&quot;,1);
	_pub_clusters_message = h.advertise&lt;lidar_tracker::CloudClusterArray&gt;(&quot;/cloud_clusters&quot;,1);
	_pub_text_pictogram = h.advertise&lt;jsk_rviz_plugins::PictogramArray&gt;(&quot;cluster_ids&quot;, 10); ROS_INFO(&quot;output pictograms topic: %s&quot;, &quot;cluster_id&quot;);

	std::string points_topic;

	_using_sensor_cloud = false;

	if (private_nh.getParam(&quot;points_node&quot;, points_topic))
	{
		ROS_INFO(&quot;euclidean_cluster &gt; Setting points node to %s&quot;, points_topic.c_str());
	}
	else
	{
		ROS_INFO(&quot;euclidean_cluster &gt; No points node received, defaulting to points_raw, you can use _points_node:=YOUR_TOPIC&quot;);
		points_topic = &quot;/points_raw&quot;;
	}

	_use_diffnormals = false;
	if (private_nh.getParam(&quot;use_diffnormals&quot;, _use_diffnormals))
	{
		if (_use_diffnormals)
			ROS_INFO(&quot;Euclidean Clustering: Applying difference of normals on clustering pipeline&quot;);
		else
			ROS_INFO(&quot;Euclidean Clustering: Difference of Normals will not be used.&quot;);
	}

	/* Initialize tuning parameter */
	private_nh.param(&quot;downsample_cloud&quot;, _downsample_cloud, false);	ROS_INFO(&quot;downsample_cloud: %d&quot;, _downsample_cloud);
	private_nh.param(&quot;remove_ground&quot;, _remove_ground, true);		ROS_INFO(&quot;remove_ground: %d&quot;, _remove_ground);
	private_nh.param(&quot;leaf_size&quot;, _leaf_size, 0.1);					ROS_INFO(&quot;leaf_size: %f&quot;, _leaf_size);
	private_nh.param(&quot;cluster_size_min&quot;, _cluster_size_min, 20);	ROS_INFO(&quot;cluster_size_min %d&quot;, _cluster_size_min);
	private_nh.param(&quot;cluster_size_max&quot;, _cluster_size_max, 100000);ROS_INFO(&quot;cluster_size_max: %d&quot;, _cluster_size_max);
	private_nh.param(&quot;pose_estimation&quot;, _pose_estimation, false);	ROS_INFO(&quot;pose_estimation: %d&quot;, _pose_estimation);
	private_nh.param(&quot;clip_min_height&quot;, _clip_min_height, -1.3);	ROS_INFO(&quot;clip_min_height: %f&quot;, _clip_min_height);
	private_nh.param(&quot;clip_max_height&quot;, _clip_max_height, 0.5);		ROS_INFO(&quot;clip_max_height: %f&quot;, _clip_max_height);
	private_nh.param(&quot;keep_lanes&quot;, _keep_lanes, false);				ROS_INFO(&quot;keep_lanes: %d&quot;, _keep_lanes);
	private_nh.param(&quot;keep_lane_left_distance&quot;, _keep_lane_left_distance, 5.0);		ROS_INFO(&quot;keep_lane_left_distance: %f&quot;, _keep_lane_left_distance);
	private_nh.param(&quot;keep_lane_right_distance&quot;, _keep_lane_right_distance, 5.0);	ROS_INFO(&quot;keep_lane_right_distance: %f&quot;, _keep_lane_right_distance);
	private_nh.param(&quot;clustering_thresholds&quot;, _clustering_thresholds);
	private_nh.param(&quot;clustering_distances&quot;, _clustering_distances);
	private_nh.param(&quot;max_boundingbox_side&quot;, _max_boundingbox_side, 10.0);				ROS_INFO(&quot;max_boundingbox_side: %f&quot;, _max_boundingbox_side);
	private_nh.param(&quot;cluster_merge_threshold&quot;, _cluster_merge_threshold, 1.5);			ROS_INFO(&quot;cluster_merge_threshold: %f&quot;, _cluster_merge_threshold);
	private_nh.param&lt;std::string&gt;(&quot;output_frame&quot;, _output_frame, &quot;velodyne&quot;);			ROS_INFO(&quot;output_frame: %s&quot;, _output_frame.c_str());

	private_nh.param(&quot;use_vector_map&quot;, _use_vector_map, false);							ROS_INFO(&quot;use_vector_map: %d&quot;, _use_vector_map);
	private_nh.param&lt;std::string&gt;(&quot;vectormap_frame&quot;, _vectormap_frame, &quot;map&quot;);			ROS_INFO(&quot;vectormap_frame: %s&quot;, _output_frame.c_str());

	private_nh.param(&quot;remove_points_upto&quot;, _remove_points_upto, 0.0);		ROS_INFO(&quot;remove_points_upto: %f&quot;, _remove_points_upto);


	_velodyne_transform_available = false;

	if (_clustering_distances.size()!=4)
	{
		_clustering_distances = {15, 30, 45, 60};//maximum distance from sensor origin to separate segments
	}
	if (_clustering_thresholds.size()!=5)
	{
		_clustering_thresholds = {0.5, 1.1, 1.6, 2.1, 2.6};//Nearest neighbor distance threshold for each segment
	}

	std::cout &lt;&lt; &quot;_clustering_thresholds: &quot;; for (auto i = _clustering_thresholds.begin(); i != _clustering_thresholds.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt; std::endl;
	std::cout &lt;&lt; &quot;_clustering_distances: &quot;;for (auto i = _clustering_distances.begin(); i != _clustering_distances.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt;std::endl;

	// Create a ROS subscriber for the input point cloud
	ros::Subscriber sub = h.subscribe (points_topic, 1, velodyne_callback);
	//ros::Subscriber sub_vectormap = h.subscribe (&quot;vector_map&quot;, 1, vectormap_callback);
	_vectormap_server = h.serviceClient&lt;vector_map_server::PositionState&gt;(&quot;vector_map_server/is_way_area&quot;);

	_visualization_marker.header.frame_id = &quot;velodyne&quot;;
	_visualization_marker.header.stamp = ros::Time();
	_visualization_marker.ns = &quot;my_namespace&quot;;
	_visualization_marker.id = 0;
	_visualization_marker.type = visualization_msgs::Marker::SPHERE_LIST;
	_visualization_marker.action = visualization_msgs::Marker::ADD;
	_visualization_marker.scale.x = 1.0;
	_visualization_marker.scale.y = 1.0;
	_visualization_marker.scale.z = 1.0;
	_visualization_marker.color.a = 1.0;
	_visualization_marker.color.r = 0.0;
	_visualization_marker.color.g = 0.0;
	_visualization_marker.color.b = 1.0;
	// marker.lifetime = ros::Duration(0.1);
	_visualization_marker.frame_locked = true;

	// Spin
	ros::spin ();
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/svm_lidar_detect/svm_lidar_detect.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/svm_lidar_detect/svm_lidar_detect.cpp">
				<diff>@@ -26,7 +26,10 @@
 
 #include &lt;opencv/cv.h&gt;
 #include &lt;opencv/highgui.h&gt;
+
+#if(CV_MAJOR_VERSION !=3)
 #include &lt;opencv2/contrib/contrib.hpp&gt;
+#endif
 
 class SvmDetect
 {
</diff>
				<old_file>/*
 * svm_detect.cpp
 *
 *  Created on: Nov 3, 2016
 *      Author: ne0
 */


#include &quot;ros/ros.h&quot;
#include &lt;sensor_msgs/point_cloud_conversion.h&gt;
#include &lt;sensor_msgs/PointCloud.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;

#include &lt;lidar_tracker/CloudCluster.h&gt;
#include &lt;lidar_tracker/CloudClusterArray.h&gt;

#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;
#include &lt;jsk_rviz_plugins/Pictogram.h&gt;
#include &lt;jsk_rviz_plugins/PictogramArray.h&gt;

#include &lt;tf/tf.h&gt;

#include &lt;stdio.h&gt;
#include &lt;string&gt;

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/contrib/contrib.hpp&gt;

class SvmDetect
{
public:
	SvmDetect();
	~SvmDetect();
	void Run();

private:

	ros::NodeHandle node_handle_;
	ros::Subscriber cloud_clusters_sub_;
	ros::Publisher cloud_clusters_pub_;
	ros::Publisher text_pictogram_pub_;

	std::string model_file_path_;

	FILE *model_file_handle_;

	void CloudClustersCallback(const lidar_tracker::CloudClusterArray::Ptr&amp; in_cloud_cluster_array_ptr);
	void ClassifyFpfhDescriptor(const std::vector&lt;float&gt;&amp; in_fpfh_descriptor, double&amp; out_label, std::vector&lt;double&gt;&amp; out_scores, double&amp; out_sum_scores);

	void CloseModel();
};

void SvmDetect::CloseModel()
{
	fclose(model_file_handle_);
}

SvmDetect::~SvmDetect()
{
}

SvmDetect::SvmDetect() :
		node_handle_(&quot;~&quot;)
{

}

void SvmDetect::Run()
{
	ros::NodeHandle private_node_handle(&quot;~&quot;);
	std::string clusters_node_name,
			out_clusters_topic_name = &quot;/cloud_clusters_class&quot;,
			out_pictograms_topic_name=&quot;/pictogram_clusters_class&quot;;

	private_node_handle.param&lt;std::string&gt;(&quot;svm_model_file_path&quot;, model_file_path_, &quot;models/svm.model&quot;);	ROS_INFO(&quot;svm_model_file_path: %s&quot;, model_file_path_.c_str());
	private_node_handle.param&lt;std::string&gt;(&quot;clusters_node_name&quot;, clusters_node_name, &quot;/cloud_clusters&quot;);	ROS_INFO(&quot;clusters_node_name: %s&quot;, clusters_node_name.c_str());

	cloud_clusters_sub_ = node_handle_.subscribe(clusters_node_name, 10, &amp;SvmDetect::CloudClustersCallback, this);
	cloud_clusters_pub_ = node_handle_.advertise&lt;lidar_tracker::CloudClusterArray&gt;(out_clusters_topic_name, 10); ROS_INFO(&quot;output clusters topic: %s&quot;, out_clusters_topic_name.c_str());

	/*text_pictogram_pub_ = node_handle_.advertise&lt;jsk_rviz_plugins::PictogramArray&gt;(out_pictograms_topic_name, 10); ROS_INFO(&quot;output pictograms topic: %s&quot;, out_pictograms_topic_name.c_str());

	model_ptr_ = LoadSvmModel(model_file_path_);

	if(model_ptr_ == NULL)
	{
		ROS_INFO(&quot;SvmDetect. Cannot perform classification. Invalid model file.&quot;);
	}
	else
	{
		ROS_INFO(&quot;SvmDetect. Ready, waiting for clusters...&quot;);
	}*/
	ros::spin();

}


void SvmDetect::CloudClustersCallback(const lidar_tracker::CloudClusterArray::Ptr&amp; in_cloud_cluster_array_ptr)
{
	cloud_clusters_pub_.publish(*in_cloud_cluster_array_ptr);
	return;
}

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;svm_lidar_detect&quot;);

	SvmDetect node;

	node.Run();

	return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="92a705c938b51894c255dc1a251df7e1f84c7d54" fix_time="10,77132">
		<msg>fix a typo</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_matching/ndt_matching.cpp" new_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_matching/ndt_matching.cpp">
				<diff>@@ -1004,7 +1004,7 @@ static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
 
 
     tf::Quaternion predict_q_imu_odom;
-    predict_q_odom.setRPY(predict_pose_imu_odom.roll, predict_pose_imu_odom.pitch, predict_pose_imu_odom.yaw);
+    predict_q_imu_odom.setRPY(predict_pose_imu_odom.roll, predict_pose_imu_odom.pitch, predict_pose_imu_odom.yaw);
     predict_pose_imu_odom_msg.header.frame_id = &quot;map&quot;;
     predict_pose_imu_odom_msg.header.stamp = input-&gt;header.stamp;
     predict_pose_imu_odom_msg.pose.position.x = predict_pose_imu_odom.x;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

/*
 Localization program using Normal Distributions Transform

 Yuki KITSUKAWA
 */

#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;fstream&gt;
#include &lt;string&gt;
#include &lt;chrono&gt;

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/Float32.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;std_msgs/Bool.h&gt;
#include &lt;nav_msgs/Odometry.h&gt;
#include &lt;sensor_msgs/Imu.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;velodyne_pointcloud/point_types.h&gt;
#include &lt;velodyne_pointcloud/rawdata.h&gt;

#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;

#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;tf/transform_listener.h&gt;

#include &lt;pcl/io/io.h&gt;
#include &lt;pcl/io/pcd_io.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#ifdef USE_FAST_PCL
#include &lt;fast_pcl/registration/ndt.h&gt;
#else
#include &lt;pcl/registration/ndt.h&gt;
#endif

#include &lt;pcl_ros/point_cloud.h&gt;
#include &lt;pcl_ros/transforms.h&gt;

#include &lt;runtime_manager/ConfigNdt.h&gt;

#include &lt;ndt_localizer/ndt_stat.h&gt;

#define PREDICT_POSE_THRESHOLD 0.5

#define Wa 0.4
#define Wb 0.3
#define Wc 0.3

struct pose
{
  double x;
  double y;
  double z;
  double roll;
  double pitch;
  double yaw;
};

static pose initial_pose, predict_pose, predict_pose_imu, predict_pose_odom, predict_pose_imu_odom, previous_pose, ndt_pose, current_pose, current_pose_imu, current_pose_odom, current_pose_imu_odom, localizer_pose, previous_gnss_pose,
    current_gnss_pose;

static double offset_x, offset_y, offset_z, offset_yaw;  // current_pos - previous_pose
static double offset_imu_x, offset_imu_y, offset_imu_z, offset_imu_roll, offset_imu_pitch, offset_imu_yaw; 
static double offset_odom_x, offset_odom_y, offset_odom_z, offset_odom_roll, offset_odom_pitch, offset_odom_yaw;
static double offset_imu_odom_x, offset_imu_odom_y, offset_imu_odom_z, offset_imu_odom_roll, offset_imu_odom_pitch, offset_imu_odom_yaw;

// Can't load if typed &quot;pcl::PointCloud&lt;pcl::PointXYZRGB&gt; map, add;&quot;
static pcl::PointCloud&lt;pcl::PointXYZ&gt; map, add;

// If the map is loaded, map_loaded will be 1.
static int map_loaded = 0;
static int _use_gnss = 1;
static int init_pos_set = 0;

static pcl::NormalDistributionsTransform&lt;pcl::PointXYZ, pcl::PointXYZ&gt; ndt;
// Default values
static int max_iter = 30;        // Maximum iterations
static float ndt_res = 1.0;      // Resolution
static double step_size = 0.1;   // Step size
static double trans_eps = 0.01;  // Transformation epsilon

static ros::Publisher predict_pose_pub;
static geometry_msgs::PoseStamped predict_pose_msg;

static ros::Publisher predict_pose_imu_pub;
static geometry_msgs::PoseStamped predict_pose_imu_msg;

static ros::Publisher predict_pose_odom_pub;
static geometry_msgs::PoseStamped predict_pose_odom_msg;

static ros::Publisher predict_pose_imu_odom_pub;
static geometry_msgs::PoseStamped predict_pose_imu_odom_msg;

static ros::Publisher ndt_pose_pub;
static geometry_msgs::PoseStamped ndt_pose_msg;

// current_pose is published by vel_pose_mux
/*
static ros::Publisher current_pose_pub;
static geometry_msgs::PoseStamped current_pose_msg;
*/

static ros::Publisher localizer_pose_pub;
static geometry_msgs::PoseStamped localizer_pose_msg;

static ros::Publisher estimate_twist_pub;
static geometry_msgs::TwistStamped estimate_twist_msg;

static ros::Time current_scan_time;
static ros::Time previous_scan_time;
static ros::Duration scan_duration;

static double exe_time = 0.0;
static int iteration = 0;
static double fitness_score = 0.0;
static double trans_probability = 0.0;

static double diff = 0.0;
static double diff_x = 0.0, diff_y = 0.0, diff_z = 0.0, diff_yaw;

static double current_velocity = 0.0, previous_velocity = 0.0, previous_previous_velocity = 0.0;  // [m/s]
static double current_velocity_x = 0.0, previous_velocity_x = 0.0;
static double current_velocity_y = 0.0, previous_velocity_y = 0.0;
static double current_velocity_z = 0.0, previous_velocity_z = 0.0;
// static double current_velocity_yaw = 0.0, previous_velocity_yaw = 0.0;
static double current_velocity_smooth = 0.0;

static double current_velocity_imu_x = 0.0;
static double current_velocity_imu_y = 0.0;
static double current_velocity_imu_z = 0.0;

static double current_accel = 0.0, previous_accel = 0.0;  // [m/s^2]
static double current_accel_x = 0.0;
static double current_accel_y = 0.0;
static double current_accel_z = 0.0;
// static double current_accel_yaw = 0.0;

static double angular_velocity = 0.0;

static int use_predict_pose = 0;

static ros::Publisher estimated_vel_mps_pub, estimated_vel_kmph_pub, estimated_vel_pub;
static std_msgs::Float32 estimated_vel_mps, estimated_vel_kmph, previous_estimated_vel_kmph;

static std::chrono::time_point&lt;std::chrono::system_clock&gt; matching_start, matching_end;

static ros::Publisher time_ndt_matching_pub;
static std_msgs::Float32 time_ndt_matching;

static int _queue_size = 1000;

static ros::Publisher ndt_stat_pub;
static ndt_localizer::ndt_stat ndt_stat_msg;

static double predict_pose_error = 0.0;

static double _tf_x, _tf_y, _tf_z, _tf_roll, _tf_pitch, _tf_yaw;
static Eigen::Matrix4f tf_btol, tf_ltob;

static std::string _localizer = &quot;velodyne&quot;;
static std::string _offset = &quot;linear&quot;;  // linear, zero, quadratic

static ros::Publisher ndt_reliability_pub;
static std_msgs::Float32 ndt_reliability;

static bool _use_openmp = false;
static bool _get_height = false;
static bool _use_local_transform = false;
static bool _use_imu = false;
static bool _use_odom = false;
static bool _imu_upside_down = false;

static std::string _imu_topic = &quot;/imu_raw&quot;;

static std::ofstream ofs;
static std::string filename;

static sensor_msgs::Imu imu;
static nav_msgs::Odometry odom;


// static tf::TransformListener local_transform_listener;
static tf::StampedTransform local_transform;

static void param_callback(const runtime_manager::ConfigNdt::ConstPtr&amp; input)
{
  if (_use_gnss != input-&gt;init_pos_gnss)
  {
    init_pos_set = 0;
  }
  else if (_use_gnss == 0 &amp;&amp;
           (initial_pose.x != input-&gt;x || initial_pose.y != input-&gt;y || initial_pose.z != input-&gt;z ||
            initial_pose.roll != input-&gt;roll || initial_pose.pitch != input-&gt;pitch || initial_pose.yaw != input-&gt;yaw))
  {
    init_pos_set = 0;
  }

  _use_gnss = input-&gt;init_pos_gnss;

  // Setting parameters
  if (input-&gt;resolution != ndt_res)
  {
    ndt_res = input-&gt;resolution;
    ndt.setResolution(ndt_res);
  }
  if (input-&gt;step_size != step_size)
  {
    step_size = input-&gt;step_size;
    ndt.setStepSize(step_size);
  }
  if (input-&gt;trans_epsilon != trans_eps)
  {
    trans_eps = input-&gt;trans_epsilon;
    ndt.setTransformationEpsilon(trans_eps);
  }
  if (input-&gt;max_iterations != max_iter)
  {
    max_iter = input-&gt;max_iterations;
    ndt.setMaximumIterations(max_iter);
  }

  if (_use_gnss == 0 &amp;&amp; init_pos_set == 0)
  {
    initial_pose.x = input-&gt;x;
    initial_pose.y = input-&gt;y;
    initial_pose.z = input-&gt;z;
    initial_pose.roll = input-&gt;roll;
    initial_pose.pitch = input-&gt;pitch;
    initial_pose.yaw = input-&gt;yaw;

    if (_use_local_transform == true)
    {
      tf::Vector3 v(input-&gt;x, input-&gt;y, input-&gt;z);
      tf::Quaternion q;
      q.setRPY(input-&gt;roll, input-&gt;pitch, input-&gt;yaw);
      tf::Transform transform(q, v);
      initial_pose.x = (local_transform.inverse() * transform).getOrigin().getX();
      initial_pose.y = (local_transform.inverse() * transform).getOrigin().getY();
      initial_pose.z = (local_transform.inverse() * transform).getOrigin().getZ();

      tf::Matrix3x3 m(q);
      m.getRPY(initial_pose.roll, initial_pose.pitch, initial_pose.yaw);

      std::cout &lt;&lt; &quot;initial_pose.x: &quot; &lt;&lt; initial_pose.x &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.y: &quot; &lt;&lt; initial_pose.y &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.z: &quot; &lt;&lt; initial_pose.z &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.roll: &quot; &lt;&lt; initial_pose.roll &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.pitch: &quot; &lt;&lt; initial_pose.pitch &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.yaw: &quot; &lt;&lt; initial_pose.yaw &lt;&lt; std::endl;
    }

    // Setting position and posture for the first time.
    localizer_pose.x = initial_pose.x;
    localizer_pose.y = initial_pose.y;
    localizer_pose.z = initial_pose.z;
    localizer_pose.roll = initial_pose.roll;
    localizer_pose.pitch = initial_pose.pitch;
    localizer_pose.yaw = initial_pose.yaw;

    previous_pose.x = initial_pose.x;
    previous_pose.y = initial_pose.y;
    previous_pose.z = initial_pose.z;
    previous_pose.roll = initial_pose.roll;
    previous_pose.pitch = initial_pose.pitch;
    previous_pose.yaw = initial_pose.yaw;

    current_pose.x = initial_pose.x;
    current_pose.y = initial_pose.y;
    current_pose.z = initial_pose.z;
    current_pose.roll = initial_pose.roll;
    current_pose.pitch = initial_pose.pitch;
    current_pose.yaw = initial_pose.yaw;

    current_velocity = 0;
    current_velocity_x = 0;
    current_velocity_y = 0;
    current_velocity_z = 0;
    angular_velocity = 0;

    current_pose_imu.x = 0;
    current_pose_imu.y = 0;
    current_pose_imu.z = 0;
    current_pose_imu.roll = 0;
    current_pose_imu.pitch = 0;
    current_pose_imu.yaw = 0;

    current_velocity_imu_x = current_velocity_x;
    current_velocity_imu_y = current_velocity_y;
    current_velocity_imu_z = current_velocity_z;
    init_pos_set = 1;
  }
}

static void map_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  if (map_loaded == 0)
  {
    // Convert the data type(from sensor_msgs to pcl).
    pcl::fromROSMsg(*input, map);

    if (_use_local_transform == true)
    {
      tf::TransformListener local_transform_listener;
      try
      {
        ros::Time now = ros::Time(0);
        local_transform_listener.waitForTransform(&quot;/map&quot;, &quot;/world&quot;, now, ros::Duration(10.0));
        local_transform_listener.lookupTransform(&quot;/map&quot;, &quot;world&quot;, now, local_transform);
      }
      catch (tf::TransformException&amp; ex)
      {
        ROS_ERROR(&quot;%s&quot;, ex.what());
      }

      pcl_ros::transformPointCloud(map, map, local_transform.inverse());
    }

    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(map));
    // Setting point cloud to be aligned to.
    ndt.setInputTarget(map_ptr);

    // Setting NDT parameters to default values
    ndt.setMaximumIterations(max_iter);
    ndt.setResolution(ndt_res);
    ndt.setStepSize(step_size);
    ndt.setTransformationEpsilon(trans_eps);

    map_loaded = 1;
  }
}

static void gnss_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; input)
{
  tf::Quaternion gnss_q(input-&gt;pose.orientation.x, input-&gt;pose.orientation.y, input-&gt;pose.orientation.z,
                        input-&gt;pose.orientation.w);
  tf::Matrix3x3 gnss_m(gnss_q);
  current_gnss_pose.x = input-&gt;pose.position.x;
  current_gnss_pose.y = input-&gt;pose.position.y;
  current_gnss_pose.z = input-&gt;pose.position.z;
  gnss_m.getRPY(current_gnss_pose.roll, current_gnss_pose.pitch, current_gnss_pose.yaw);

  if ((_use_gnss == 1 &amp;&amp; init_pos_set == 0) || fitness_score &gt;= 500.0)
  {
    previous_pose.x = previous_gnss_pose.x;
    previous_pose.y = previous_gnss_pose.y;
    previous_pose.z = previous_gnss_pose.z;
    previous_pose.roll = previous_gnss_pose.roll;
    previous_pose.pitch = previous_gnss_pose.pitch;
    previous_pose.yaw = previous_gnss_pose.yaw;

    current_pose.x = current_gnss_pose.x;
    current_pose.y = current_gnss_pose.y;
    current_pose.z = current_gnss_pose.z;
    current_pose.roll = current_gnss_pose.roll;
    current_pose.pitch = current_gnss_pose.pitch;
    current_pose.yaw = current_gnss_pose.yaw;

    current_pose_imu = current_pose_odom = current_pose_imu_odom = current_pose;

    offset_x = current_pose.x - previous_pose.x;
    offset_y = current_pose.y - previous_pose.y;
    offset_z = current_pose.z - previous_pose.z;
    offset_yaw = current_pose.yaw - previous_pose.yaw;

    init_pos_set = 1;
  }

  previous_gnss_pose.x = current_gnss_pose.x;
  previous_gnss_pose.y = current_gnss_pose.y;
  previous_gnss_pose.z = current_gnss_pose.z;
  previous_gnss_pose.roll = current_gnss_pose.roll;
  previous_gnss_pose.pitch = current_gnss_pose.pitch;
  previous_gnss_pose.yaw = current_gnss_pose.yaw;
}

static void initialpose_callback(const geometry_msgs::PoseWithCovarianceStamped::ConstPtr&amp; input)
{
  tf::TransformListener listener;
  tf::StampedTransform transform;
  try
  {
    ros::Time now = ros::Time(0);
    listener.waitForTransform(&quot;/map&quot;, &quot;/world&quot;, now, ros::Duration(10.0));
    listener.lookupTransform(&quot;/map&quot;, &quot;world&quot;, now, transform);
  }
  catch (tf::TransformException&amp; ex)
  {
    ROS_ERROR(&quot;%s&quot;, ex.what());
  }

  tf::Quaternion q(input-&gt;pose.pose.orientation.x, input-&gt;pose.pose.orientation.y, input-&gt;pose.pose.orientation.z,
                   input-&gt;pose.pose.orientation.w);
  tf::Matrix3x3 m(q);

  if (_use_local_transform == true)
  {
    current_pose.x = input-&gt;pose.pose.position.x;
    current_pose.y = input-&gt;pose.pose.position.y;
    current_pose.z = input-&gt;pose.pose.position.z;
  }
  else
  {
    current_pose.x = input-&gt;pose.pose.position.x + transform.getOrigin().x();
    current_pose.y = input-&gt;pose.pose.position.y + transform.getOrigin().y();
    current_pose.z = input-&gt;pose.pose.position.z + transform.getOrigin().z();
  }
  m.getRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);

  if (_get_height == true &amp;&amp; map_loaded == 1)
  {
    double min_distance = DBL_MAX;
    double nearest_z = current_pose.z;
    for (const auto&amp; p : map)
    {
      double distance = hypot(current_pose.x - p.x, current_pose.y - p.y);
      if (distance &lt; min_distance)
      {
        min_distance = distance;
        nearest_z = p.z;
      }
    }
    current_pose.z = nearest_z;
  }
  
  current_pose_imu = current_pose_odom = current_pose_imu_odom = current_pose;
  previous_pose.x = current_pose.x;
  previous_pose.y = current_pose.y;
  previous_pose.z = current_pose.z;
  previous_pose.roll = current_pose.roll;
  previous_pose.pitch = current_pose.pitch;
  previous_pose.yaw = current_pose.yaw;

  offset_x = 0.0;
  offset_y = 0.0;
  offset_z = 0.0;
  offset_yaw = 0.0;

  offset_imu_x = 0.0;
  offset_imu_y = 0.0;
  offset_imu_z = 0.0;
  offset_imu_roll = 0.0;
  offset_imu_pitch = 0.0;
  offset_imu_yaw = 0.0;

  offset_odom_x = 0.0;
  offset_odom_y = 0.0;
  offset_odom_z = 0.0;
  offset_odom_roll = 0.0;
  offset_odom_pitch = 0.0;
  offset_odom_yaw = 0.0;

  offset_imu_odom_x = 0.0;
  offset_imu_odom_y = 0.0;
  offset_imu_odom_z = 0.0;
  offset_imu_odom_roll = 0.0;
  offset_imu_odom_pitch = 0.0;
  offset_imu_odom_yaw = 0.0;

}

static void imu_odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu_odom.roll  += diff_imu_roll;
  current_pose_imu_odom.pitch += diff_imu_pitch;
  current_pose_imu_odom.yaw   += diff_imu_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_imu_odom_x += diff_distance*cos(-current_pose_imu_odom.pitch)*cos(current_pose_imu_odom.yaw);
  offset_imu_odom_y += diff_distance*cos(-current_pose_imu_odom.pitch)*sin(current_pose_imu_odom.yaw);
  offset_imu_odom_z += diff_distance*sin(-current_pose_imu_odom.pitch);

  offset_imu_odom_roll  += diff_imu_roll;
  offset_imu_odom_pitch += diff_imu_pitch;
  offset_imu_odom_yaw   += diff_imu_yaw;

  predict_pose_imu_odom.x     = previous_pose.x     + offset_imu_odom_x;
  predict_pose_imu_odom.y     = previous_pose.y     + offset_imu_odom_y;
  predict_pose_imu_odom.z     = previous_pose.z     + offset_imu_odom_z;
  predict_pose_imu_odom.roll  = previous_pose.roll  + offset_imu_odom_roll;
  predict_pose_imu_odom.pitch = previous_pose.pitch + offset_imu_odom_pitch;
  predict_pose_imu_odom.yaw   = previous_pose.yaw   + offset_imu_odom_yaw;
 
  previous_time = current_time;
}


static void odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_odom_roll  = odom.twist.twist.angular.x * diff_time;
  double diff_odom_pitch = odom.twist.twist.angular.y * diff_time;
  double diff_odom_yaw   = odom.twist.twist.angular.z * diff_time;

  current_pose_odom.roll  += diff_odom_roll;
  current_pose_odom.pitch += diff_odom_pitch;
  current_pose_odom.yaw   += diff_odom_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_odom_x += diff_distance*cos(-current_pose_odom.pitch)*cos(current_pose_odom.yaw);
  offset_odom_y += diff_distance*cos(-current_pose_odom.pitch)*sin(current_pose_odom.yaw);
  offset_odom_z += diff_distance*sin(-current_pose_odom.pitch);

  offset_odom_roll  += diff_odom_roll;
  offset_odom_pitch += diff_odom_pitch;
  offset_odom_yaw   += diff_odom_yaw;

  predict_pose_odom.x     = previous_pose.x     + offset_odom_x;
  predict_pose_odom.y     = previous_pose.y     + offset_odom_y;
  predict_pose_odom.z     = previous_pose.z     + offset_odom_z;
  predict_pose_odom.roll  = previous_pose.roll  + offset_odom_roll;
  predict_pose_odom.pitch = previous_pose.pitch + offset_odom_pitch;
  predict_pose_odom.yaw   = previous_pose.yaw   + offset_odom_yaw;
 
  previous_time = current_time;

}

static void imu_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu.roll += diff_imu_roll;
  current_pose_imu.pitch += diff_imu_pitch;
  current_pose_imu.yaw += diff_imu_yaw;

  double accX1 = imu.linear_acceleration.x;
  double accY1 = std::cos(current_pose_imu.roll) * imu.linear_acceleration.y
                -std::sin(current_pose_imu.roll) * imu.linear_acceleration.z;
  double accZ1 = std::sin(current_pose_imu.roll) * imu.linear_acceleration.y
                +std::cos(current_pose_imu.roll) * imu.linear_acceleration.z;

  double accX2 = std::sin(current_pose_imu.pitch) * accZ1 + std::cos(current_pose_imu.pitch) * accX1;
  double accY2 = accY1;
  double accZ2 = std::cos(current_pose_imu.pitch) * accZ1 - std::sin(current_pose_imu.pitch) * accX1;

  double accX = std::cos(current_pose_imu.yaw) * accX2 - std::sin(current_pose_imu.yaw) * accY2;
  double accY = std::sin(current_pose_imu.yaw) * accX2 + std::cos(current_pose_imu.yaw) * accY2;
  double accZ = accZ2;

  offset_imu_x += current_velocity_imu_x * diff_time + accX * diff_time * diff_time / 2.0;
  offset_imu_y += current_velocity_imu_y * diff_time + accY * diff_time * diff_time / 2.0;
  offset_imu_z += current_velocity_imu_z * diff_time + accZ * diff_time * diff_time / 2.0;

  current_velocity_imu_x += accX * diff_time;
  current_velocity_imu_y += accY * diff_time;
  current_velocity_imu_z += accZ * diff_time;

  offset_imu_roll  += diff_imu_roll;
  offset_imu_pitch += diff_imu_pitch;
  offset_imu_yaw   += diff_imu_yaw;

  predict_pose_imu.x     = previous_pose.x     + offset_imu_x;
  predict_pose_imu.y     = previous_pose.y     + offset_imu_y;
  predict_pose_imu.z     = previous_pose.z     + offset_imu_z;
  predict_pose_imu.roll  = previous_pose.roll  + offset_imu_roll;
  predict_pose_imu.pitch = previous_pose.pitch + offset_imu_pitch;
  predict_pose_imu.yaw   = previous_pose.yaw   + offset_imu_yaw;  

  previous_time = current_time;
}


static const double wrapToPm(double a_num, const double a_max)
{
    if (a_num &gt;= a_max)
    {
        a_num -= 2.0 * a_max;
    }
    return a_num;
}

static const double wrapToPmPi(double a_angle_rad)
{
    return wrapToPm(a_angle_rad, M_PI);
}


static void odom_callback(const nav_msgs::Odometry::ConstPtr&amp; input)
{
  //std::cout &lt;&lt; __func__ &lt;&lt; std::endl;

  odom = *input;
  odom_calc(input-&gt;header.stamp);
}

static void imuUpsideDown(const sensor_msgs::Imu::Ptr input)
{
  double input_roll, input_pitch, input_yaw;

  tf::Quaternion input_orientation;
  tf::quaternionMsgToTF(input-&gt;orientation, input_orientation);
  tf::Matrix3x3(input_orientation).getRPY(input_roll, input_pitch, input_yaw);

  input-&gt;angular_velocity.x *= -1;
  input-&gt;angular_velocity.y *= -1;
  input-&gt;angular_velocity.z *= -1;

  input-&gt;linear_acceleration.x *= -1;
  input-&gt;linear_acceleration.y *= -1;
  input-&gt;linear_acceleration.z *= -1;

  input_roll  *= -1;
  input_pitch *= -1;
  input_yaw   *= -1;

  input-&gt;orientation = tf::createQuaternionMsgFromRollPitchYaw(input_roll, input_pitch, input_yaw);
}

static void imu_callback(const sensor_msgs::Imu::Ptr&amp; input)
{
  //std::cout &lt;&lt; __func__ &lt;&lt; std::endl;

  if(_imu_upside_down)
    imuUpsideDown(input);

  const ros::Time current_time = input-&gt;header.stamp;
  static ros::Time previous_time = current_time;
  const double diff_time =  (current_time - previous_time).toSec();

  double imu_roll, imu_pitch, imu_yaw;
  tf::Quaternion imu_orientation;
  tf::quaternionMsgToTF(input-&gt;orientation, imu_orientation);
  tf::Matrix3x3(imu_orientation).getRPY(imu_roll, imu_pitch, imu_yaw);

  imu_roll = wrapToPmPi(imu_roll);
  imu_pitch = wrapToPmPi(imu_pitch);
  imu_yaw = wrapToPmPi(imu_yaw);

  static double previous_imu_roll = imu_roll, previous_imu_pitch = imu_pitch, previous_imu_yaw = imu_yaw;
  const double diff_imu_roll  = imu_roll  - previous_imu_roll;

  const double diff_imu_pitch = imu_pitch - previous_imu_pitch;

  double diff_imu_yaw;
  if(fabs(imu_yaw - previous_imu_yaw) &gt; M_PI)
  {
    if(imu_yaw &gt; 0)
      diff_imu_yaw = (imu_yaw - previous_imu_yaw) - M_PI*2;
    else
      diff_imu_yaw = -M_PI*2 - (imu_yaw - previous_imu_yaw);
  }
  else
  diff_imu_yaw = imu_yaw - previous_imu_yaw;

  imu.header = input-&gt;header;
  imu.linear_acceleration.x = input-&gt;linear_acceleration.x;
  //imu.linear_acceleration.y = input-&gt;linear_acceleration.y;
  //imu.linear_acceleration.z = input-&gt;linear_acceleration.z;
  imu.linear_acceleration.y = 0;
  imu.linear_acceleration.z = 0;

  if(diff_time != 0)
  {
    imu.angular_velocity.x = diff_imu_roll  / diff_time;
    imu.angular_velocity.y = diff_imu_pitch / diff_time;
    imu.angular_velocity.z = diff_imu_yaw   / diff_time;
  }
  else
  {
    imu.angular_velocity.x = 0;
    imu.angular_velocity.y = 0;
    imu.angular_velocity.z = 0;
  }

  imu_calc(input-&gt;header.stamp);

  previous_time = current_time;
  previous_imu_roll  = imu_roll;
  previous_imu_pitch = imu_pitch;
  previous_imu_yaw   = imu_yaw;
}

static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  if (map_loaded == 1 &amp;&amp; init_pos_set == 1)
  {
    matching_start = std::chrono::system_clock::now();

    static tf::TransformBroadcaster br;
    tf::Transform transform;
    tf::Quaternion predict_q, ndt_q, current_q, localizer_q;

    pcl::PointXYZ p;
    pcl::PointCloud&lt;pcl::PointXYZ&gt; filtered_scan;

    current_scan_time = input-&gt;header.stamp;

    pcl::fromROSMsg(*input, filtered_scan);
    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(filtered_scan));
    int scan_points_num = filtered_scan_ptr-&gt;size();

    Eigen::Matrix4f t(Eigen::Matrix4f::Identity());   // base_link
    Eigen::Matrix4f t2(Eigen::Matrix4f::Identity());  // localizer

    std::chrono::time_point&lt;std::chrono::system_clock&gt; align_start, align_end, getFitnessScore_start,
        getFitnessScore_end;
    static double align_time, getFitnessScore_time = 0.0;

    // Setting point cloud to be aligned.
    ndt.setInputSource(filtered_scan_ptr);

    // Guess the initial gross estimation of the transformation
    predict_pose.x = previous_pose.x + offset_x;
    predict_pose.y = previous_pose.y + offset_y;
    predict_pose.z = previous_pose.z + offset_z;
    predict_pose.roll = previous_pose.roll;
    predict_pose.pitch = previous_pose.pitch;
    predict_pose.yaw = previous_pose.yaw + offset_yaw;


    if (_use_imu == true &amp;&amp; _use_odom == true)
      imu_odom_calc(current_scan_time);
    if(_use_imu == true &amp;&amp; _use_odom == true)
      imu_calc(current_scan_time);
    if (_use_imu == false &amp;&amp; _use_odom == true)
      odom_calc(current_scan_time);
    
    pose predict_pose_for_ndt;
    if (_use_imu == true &amp;&amp; _use_odom == true)
      predict_pose_for_ndt = predict_pose_imu_odom;
    else if (_use_imu == true &amp;&amp; _use_odom == false)
      predict_pose_for_ndt = predict_pose_imu;
    else if (_use_imu == false &amp;&amp; _use_odom == true)
      predict_pose_for_ndt = predict_pose_odom;
    else
      predict_pose_for_ndt = predict_pose;

    Eigen::Translation3f init_translation(predict_pose_for_ndt.x, predict_pose_for_ndt.y, predict_pose_for_ndt.z);
    Eigen::AngleAxisf init_rotation_x(predict_pose_for_ndt.roll, Eigen::Vector3f::UnitX());
    Eigen::AngleAxisf init_rotation_y(predict_pose_for_ndt.pitch, Eigen::Vector3f::UnitY());
    Eigen::AngleAxisf init_rotation_z(predict_pose_for_ndt.yaw, Eigen::Vector3f::UnitZ());
    Eigen::Matrix4f init_guess = (init_translation * init_rotation_z * init_rotation_y * init_rotation_x) * tf_btol;




    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
#ifdef USE_FAST_PCL
    if (_use_openmp == true)
    {
      align_start = std::chrono::system_clock::now();
      ndt.omp_align(*output_cloud, init_guess);
      align_end = std::chrono::system_clock::now();
    }
    else
    {
#endif
      align_start = std::chrono::system_clock::now();
      ndt.align(*output_cloud, init_guess);
      align_end = std::chrono::system_clock::now();
#ifdef USE_FAST_PCL
    }
#endif

    align_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(align_end - align_start).count() / 1000.0;


    t = ndt.getFinalTransformation();  // localizer
    t2 = t * tf_ltob;                  // base_link

    iteration = ndt.getFinalNumIteration();
#ifdef USE_FAST_PCL
    if (_use_openmp == true)
    {
      getFitnessScore_start = std::chrono::system_clock::now();
      fitness_score = ndt.omp_getFitnessScore();
      getFitnessScore_end = std::chrono::system_clock::now();
    }
    else
    {
#endif
      getFitnessScore_start = std::chrono::system_clock::now();
      fitness_score = ndt.getFitnessScore();
      getFitnessScore_end = std::chrono::system_clock::now();
#ifdef USE_FAST_PCL
    }
#endif
    getFitnessScore_time =
        std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(getFitnessScore_end - getFitnessScore_start).count() /
        1000.0;


    trans_probability = ndt.getTransformationProbability();

    tf::Matrix3x3 mat_l;  // localizer
    mat_l.setValue(static_cast&lt;double&gt;(t(0, 0)), static_cast&lt;double&gt;(t(0, 1)), static_cast&lt;double&gt;(t(0, 2)),
                   static_cast&lt;double&gt;(t(1, 0)), static_cast&lt;double&gt;(t(1, 1)), static_cast&lt;double&gt;(t(1, 2)),
                   static_cast&lt;double&gt;(t(2, 0)), static_cast&lt;double&gt;(t(2, 1)), static_cast&lt;double&gt;(t(2, 2)));

    // Update localizer_pose
    localizer_pose.x = t(0, 3);
    localizer_pose.y = t(1, 3);
    localizer_pose.z = t(2, 3);
    mat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1);

    tf::Matrix3x3 mat_b;  // base_link
    mat_b.setValue(static_cast&lt;double&gt;(t2(0, 0)), static_cast&lt;double&gt;(t2(0, 1)), static_cast&lt;double&gt;(t2(0, 2)),
                   static_cast&lt;double&gt;(t2(1, 0)), static_cast&lt;double&gt;(t2(1, 1)), static_cast&lt;double&gt;(t2(1, 2)),
                   static_cast&lt;double&gt;(t2(2, 0)), static_cast&lt;double&gt;(t2(2, 1)), static_cast&lt;double&gt;(t2(2, 2)));

    // Update ndt_pose
    ndt_pose.x = t2(0, 3);
    ndt_pose.y = t2(1, 3);
    ndt_pose.z = t2(2, 3);
    mat_b.getRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw, 1);

    // Calculate the difference between ndt_pose and predict_pose
    predict_pose_error = sqrt((ndt_pose.x - predict_pose_for_ndt.x) * (ndt_pose.x - predict_pose_for_ndt.x) +
                              (ndt_pose.y - predict_pose_for_ndt.y) * (ndt_pose.y - predict_pose_for_ndt.y) +
                              (ndt_pose.z - predict_pose_for_ndt.z) * (ndt_pose.z - predict_pose_for_ndt.z));

    if (predict_pose_error &lt;= PREDICT_POSE_THRESHOLD)
    {
      use_predict_pose = 0;
    }
    else
    {
      use_predict_pose = 1;
    }
    use_predict_pose = 0;


    if (use_predict_pose == 0)
    {
      current_pose.x = ndt_pose.x;
      current_pose.y = ndt_pose.y;
      current_pose.z = ndt_pose.z;
      current_pose.roll = ndt_pose.roll;
      current_pose.pitch = ndt_pose.pitch;
      current_pose.yaw = ndt_pose.yaw;
    }
    else
    {
      current_pose.x = predict_pose_for_ndt.x;
      current_pose.y = predict_pose_for_ndt.y;
      current_pose.z = predict_pose_for_ndt.z;
      current_pose.roll = predict_pose_for_ndt.roll;
      current_pose.pitch = predict_pose_for_ndt.pitch;
      current_pose.yaw = predict_pose_for_ndt.yaw;
    }


    // Compute the velocity and acceleration
    scan_duration = current_scan_time - previous_scan_time;
    double secs = scan_duration.toSec();
    diff_x = current_pose.x - previous_pose.x;
    diff_y = current_pose.y - previous_pose.y;
    diff_z = current_pose.z - previous_pose.z;
    diff_yaw = current_pose.yaw - previous_pose.yaw;
    diff = sqrt(diff_x * diff_x + diff_y * diff_y + diff_z * diff_z);

    current_velocity = diff / secs;
    current_velocity_x = diff_x / secs;
    current_velocity_y = diff_y / secs;
    current_velocity_z = diff_z / secs;
    angular_velocity = diff_yaw / secs;

    current_pose_imu.x = current_pose.x;
    current_pose_imu.y = current_pose.y;
    current_pose_imu.z = current_pose.z;
    current_pose_imu.roll = current_pose.roll;
    current_pose_imu.pitch = current_pose.pitch;
    current_pose_imu.yaw = current_pose.yaw;

    current_velocity_imu_x = current_velocity_x;
    current_velocity_imu_y = current_velocity_y;
    current_velocity_imu_z = current_velocity_z;


    current_pose_odom.x = current_pose.x;
    current_pose_odom.y = current_pose.y;
    current_pose_odom.z = current_pose.z;
    current_pose_odom.roll = current_pose.roll;
    current_pose_odom.pitch = current_pose.pitch;
    current_pose_odom.yaw = current_pose.yaw;

    current_pose_imu_odom.x = current_pose.x;
    current_pose_imu_odom.y = current_pose.y;
    current_pose_imu_odom.z = current_pose.z;
    current_pose_imu_odom.roll = current_pose.roll;
    current_pose_imu_odom.pitch = current_pose.pitch;
    current_pose_imu_odom.yaw = current_pose.yaw;

    current_velocity_smooth = (current_velocity + previous_velocity + previous_previous_velocity) / 3.0;
    if (current_velocity_smooth &lt; 0.2)
    {
      current_velocity_smooth = 0.0;
    }

    current_accel = (current_velocity - previous_velocity) / secs;
    current_accel_x = (current_velocity_x - previous_velocity_x) / secs;
    current_accel_y = (current_velocity_y - previous_velocity_y) / secs;
    current_accel_z = (current_velocity_z - previous_velocity_z) / secs;

    estimated_vel_mps.data = current_velocity;
    estimated_vel_kmph.data = current_velocity * 3.6;

    estimated_vel_mps_pub.publish(estimated_vel_mps);
    estimated_vel_kmph_pub.publish(estimated_vel_kmph);

    // Set values for publishing pose
    predict_q.setRPY(predict_pose.roll, predict_pose.pitch, predict_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(predict_pose.x, predict_pose.y, predict_pose.z);
      tf::Transform transform(predict_q, v);
      predict_pose_msg.header.frame_id = &quot;/map&quot;;
      predict_pose_msg.header.stamp = current_scan_time;
      predict_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      predict_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      predict_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      predict_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      predict_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      predict_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      predict_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      predict_pose_msg.header.frame_id = &quot;/map&quot;;
      predict_pose_msg.header.stamp = current_scan_time;
      predict_pose_msg.pose.position.x = predict_pose.x;
      predict_pose_msg.pose.position.y = predict_pose.y;
      predict_pose_msg.pose.position.z = predict_pose.z;
      predict_pose_msg.pose.orientation.x = predict_q.x();
      predict_pose_msg.pose.orientation.y = predict_q.y();
      predict_pose_msg.pose.orientation.z = predict_q.z();
      predict_pose_msg.pose.orientation.w = predict_q.w();
    }

    tf::Quaternion predict_q_imu;
    predict_q_imu.setRPY(predict_pose_imu.roll, predict_pose_imu.pitch, predict_pose_imu.yaw);
    predict_pose_imu_msg.header.frame_id = &quot;map&quot;;
    predict_pose_imu_msg.header.stamp = input-&gt;header.stamp;
    predict_pose_imu_msg.pose.position.x = predict_pose_imu.x;
    predict_pose_imu_msg.pose.position.y = predict_pose_imu.y;
    predict_pose_imu_msg.pose.position.z = predict_pose_imu.z;
    predict_pose_imu_msg.pose.orientation.x = predict_q_imu.x();
    predict_pose_imu_msg.pose.orientation.y = predict_q_imu.y();
    predict_pose_imu_msg.pose.orientation.z = predict_q_imu.z();
    predict_pose_imu_msg.pose.orientation.w = predict_q_imu.w();
    predict_pose_imu_pub.publish(predict_pose_imu_msg);

    tf::Quaternion predict_q_odom;
    predict_q_odom.setRPY(predict_pose_odom.roll, predict_pose_odom.pitch, predict_pose_odom.yaw);
    predict_pose_odom_msg.header.frame_id = &quot;map&quot;;
    predict_pose_odom_msg.header.stamp = input-&gt;header.stamp;
    predict_pose_odom_msg.pose.position.x = predict_pose_odom.x;
    predict_pose_odom_msg.pose.position.y = predict_pose_odom.y;
    predict_pose_odom_msg.pose.position.z = predict_pose_odom.z;
    predict_pose_odom_msg.pose.orientation.x = predict_q_odom.x();
    predict_pose_odom_msg.pose.orientation.y = predict_q_odom.y();
    predict_pose_odom_msg.pose.orientation.z = predict_q_odom.z();
    predict_pose_odom_msg.pose.orientation.w = predict_q_odom.w();
    predict_pose_odom_pub.publish(predict_pose_odom_msg);


    tf::Quaternion predict_q_imu_odom;
    predict_q_odom.setRPY(predict_pose_imu_odom.roll, predict_pose_imu_odom.pitch, predict_pose_imu_odom.yaw);
    predict_pose_imu_odom_msg.header.frame_id = &quot;map&quot;;
    predict_pose_imu_odom_msg.header.stamp = input-&gt;header.stamp;
    predict_pose_imu_odom_msg.pose.position.x = predict_pose_imu_odom.x;
    predict_pose_imu_odom_msg.pose.position.y = predict_pose_imu_odom.y;
    predict_pose_imu_odom_msg.pose.position.z = predict_pose_imu_odom.z;
    predict_pose_imu_odom_msg.pose.orientation.x = predict_q_imu_odom.x();
    predict_pose_imu_odom_msg.pose.orientation.y = predict_q_imu_odom.y();
    predict_pose_imu_odom_msg.pose.orientation.z = predict_q_imu_odom.z();
    predict_pose_imu_odom_msg.pose.orientation.w = predict_q_imu_odom.w();
    predict_pose_imu_odom_pub.publish(predict_pose_imu_odom_msg);

    ndt_q.setRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(ndt_pose.x, ndt_pose.y, ndt_pose.z);
      tf::Transform transform(ndt_q, v);
      ndt_pose_msg.header.frame_id = &quot;/map&quot;;
      ndt_pose_msg.header.stamp = current_scan_time;
      ndt_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      ndt_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      ndt_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      ndt_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      ndt_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      ndt_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      ndt_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      ndt_pose_msg.header.frame_id = &quot;/map&quot;;
      ndt_pose_msg.header.stamp = current_scan_time;
      ndt_pose_msg.pose.position.x = ndt_pose.x;
      ndt_pose_msg.pose.position.y = ndt_pose.y;
      ndt_pose_msg.pose.position.z = ndt_pose.z;
      ndt_pose_msg.pose.orientation.x = ndt_q.x();
      ndt_pose_msg.pose.orientation.y = ndt_q.y();
      ndt_pose_msg.pose.orientation.z = ndt_q.z();
      ndt_pose_msg.pose.orientation.w = ndt_q.w();
    }

    current_q.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);
    // current_pose is published by vel_pose_mux
    /*
    current_pose_msg.header.frame_id = &quot;/map&quot;;
    current_pose_msg.header.stamp = current_scan_time;
    current_pose_msg.pose.position.x = current_pose.x;
    current_pose_msg.pose.position.y = current_pose.y;
    current_pose_msg.pose.position.z = current_pose.z;
    current_pose_msg.pose.orientation.x = current_q.x();
    current_pose_msg.pose.orientation.y = current_q.y();
    current_pose_msg.pose.orientation.z = current_q.z();
    current_pose_msg.pose.orientation.w = current_q.w();
    */

    localizer_q.setRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(localizer_pose.x, localizer_pose.y, localizer_pose.z);
      tf::Transform transform(localizer_q, v);
      localizer_pose_msg.header.frame_id = &quot;/map&quot;;
      localizer_pose_msg.header.stamp = current_scan_time;
      localizer_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      localizer_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      localizer_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      localizer_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      localizer_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      localizer_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      localizer_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      localizer_pose_msg.header.frame_id = &quot;/map&quot;;
      localizer_pose_msg.header.stamp = current_scan_time;
      localizer_pose_msg.pose.position.x = localizer_pose.x;
      localizer_pose_msg.pose.position.y = localizer_pose.y;
      localizer_pose_msg.pose.position.z = localizer_pose.z;
      localizer_pose_msg.pose.orientation.x = localizer_q.x();
      localizer_pose_msg.pose.orientation.y = localizer_q.y();
      localizer_pose_msg.pose.orientation.z = localizer_q.z();
      localizer_pose_msg.pose.orientation.w = localizer_q.w();
    }

    predict_pose_pub.publish(predict_pose_msg);
    ndt_pose_pub.publish(ndt_pose_msg);
    // current_pose is published by vel_pose_mux
    //    current_pose_pub.publish(current_pose_msg);
    localizer_pose_pub.publish(localizer_pose_msg);

    // Send TF &quot;/base_link&quot; to &quot;/map&quot;
    transform.setOrigin(tf::Vector3(current_pose.x, current_pose.y, current_pose.z));
    transform.setRotation(current_q);
    //    br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    if (_use_local_transform == true)
    {
      br.sendTransform(tf::StampedTransform(local_transform * transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    }
    else
    {
      br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    }

    matching_end = std::chrono::system_clock::now();
    exe_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(matching_end - matching_start).count() / 1000.0;
    time_ndt_matching.data = exe_time;
    time_ndt_matching_pub.publish(time_ndt_matching);

    // Set values for /estimate_twist
    estimate_twist_msg.header.stamp = current_scan_time;
    estimate_twist_msg.header.frame_id = &quot;/base_link&quot;;
    estimate_twist_msg.twist.linear.x = current_velocity;
    estimate_twist_msg.twist.linear.y = 0.0;
    estimate_twist_msg.twist.linear.z = 0.0;
    estimate_twist_msg.twist.angular.x = 0.0;
    estimate_twist_msg.twist.angular.y = 0.0;
    estimate_twist_msg.twist.angular.z = angular_velocity;

    estimate_twist_pub.publish(estimate_twist_msg);

    geometry_msgs::Vector3Stamped estimate_vel_msg;
    estimate_vel_msg.header.stamp = current_scan_time;
    estimate_vel_msg.vector.x = current_velocity;
    estimated_vel_pub.publish(estimate_vel_msg);

    // Set values for /ndt_stat
    ndt_stat_msg.header.stamp = current_scan_time;
    ndt_stat_msg.exe_time = time_ndt_matching.data;
    ndt_stat_msg.iteration = iteration;
    ndt_stat_msg.score = fitness_score;
    ndt_stat_msg.velocity = current_velocity;
    ndt_stat_msg.acceleration = current_accel;
    ndt_stat_msg.use_predict_pose = 0;

    ndt_stat_pub.publish(ndt_stat_msg);

    /* Compute NDT_Reliability */
    ndt_reliability.data = Wa * (exe_time / 100.0) * 100.0 + Wb * (iteration / 10.0) * 100.0 +
                           Wc * ((2.0 - trans_probability) / 2.0) * 100.0;
    ndt_reliability_pub.publish(ndt_reliability);


    // Write log
    if (!ofs)
    {
      std::cerr &lt;&lt; &quot;Could not open &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
      exit(1);
    }
    static ros::Time start_time = input-&gt;header.stamp;

    ofs &lt;&lt; input-&gt;header.seq &lt;&lt; &quot;,&quot; &lt;&lt; scan_points_num &lt;&lt; &quot;,&quot; &lt;&lt; step_size &lt;&lt; &quot;,&quot; &lt;&lt; trans_eps &lt;&lt; &quot;,&quot; &lt;&lt; std::fixed
        &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; std::fixed &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.y &lt;&lt; &quot;,&quot;
        &lt;&lt; std::fixed &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.pitch
        &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.y &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.z &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose.roll &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.pitch &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.x - predict_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.y - predict_pose.y &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.z - predict_pose.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll - predict_pose.roll &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.pitch - predict_pose.pitch &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw - predict_pose.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose_error &lt;&lt; &quot;,&quot; &lt;&lt; iteration &lt;&lt; &quot;,&quot; &lt;&lt; fitness_score &lt;&lt; &quot;,&quot; &lt;&lt; trans_probability &lt;&lt; &quot;,&quot;
        &lt;&lt; ndt_reliability.data &lt;&lt; &quot;,&quot; &lt;&lt; current_velocity &lt;&lt; &quot;,&quot; &lt;&lt; current_velocity_smooth &lt;&lt; &quot;,&quot; &lt;&lt; current_accel
        &lt;&lt; &quot;,&quot; &lt;&lt; angular_velocity &lt;&lt; &quot;,&quot; &lt;&lt; time_ndt_matching.data &lt;&lt; &quot;,&quot; &lt;&lt; align_time &lt;&lt; &quot;,&quot; &lt;&lt; getFitnessScore_time
        &lt;&lt; std::endl;

    std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Sequence: &quot; &lt;&lt; input-&gt;header.seq &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Timestamp: &quot; &lt;&lt; input-&gt;header.stamp &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Frame ID: &quot; &lt;&lt; input-&gt;header.frame_id &lt;&lt; std::endl;
    //		std::cout &lt;&lt; &quot;Number of Scan Points: &quot; &lt;&lt; scan_ptr-&gt;size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Number of Filtered Scan Points: &quot; &lt;&lt; scan_points_num &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;NDT has converged: &quot; &lt;&lt; ndt.hasConverged() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Fitness Score: &quot; &lt;&lt; fitness_score &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Transformation Probability: &quot; &lt;&lt; ndt.getTransformationProbability() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Execution Time: &quot; &lt;&lt; exe_time &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Number of Iterations: &quot; &lt;&lt; ndt.getFinalNumIteration() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;NDT Reliability: &quot; &lt;&lt; ndt_reliability.data &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;(x,y,z,roll,pitch,yaw): &quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;(&quot; &lt;&lt; current_pose.x &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.y &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.z &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.roll
              &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.pitch &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Transformation Matrix: &quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; t &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;

    // Update offset
    if (_offset == &quot;linear&quot;)
    {
      offset_x = diff_x;
      offset_y = diff_y;
      offset_z = diff_z;
      offset_yaw = diff_yaw;
    }
    else if (_offset == &quot;quadratic&quot;)
    {
      offset_x = (current_velocity_x + current_accel_x * secs) * secs;
      offset_y = (current_velocity_y + current_accel_y * secs) * secs;
      offset_z = diff_z;
      offset_yaw = diff_yaw;
    }
    else if (_offset == &quot;zero&quot;)
    {
      offset_x = 0.0;
      offset_y = 0.0;
      offset_z = 0.0;
      offset_yaw = 0.0;
    }
   
    offset_imu_x = 0.0;
    offset_imu_y = 0.0;
    offset_imu_z = 0.0;
    offset_imu_roll = 0.0;
    offset_imu_pitch = 0.0;
    offset_imu_yaw = 0.0;

    offset_odom_x = 0.0;
    offset_odom_y = 0.0;
    offset_odom_z = 0.0;
    offset_odom_roll = 0.0;
    offset_odom_pitch = 0.0;
    offset_odom_yaw = 0.0;

    offset_imu_odom_x = 0.0;
    offset_imu_odom_y = 0.0;
    offset_imu_odom_z = 0.0;
    offset_imu_odom_roll = 0.0;
    offset_imu_odom_pitch = 0.0;
    offset_imu_odom_yaw = 0.0;

    // Update previous_***
    previous_pose.x = current_pose.x;
    previous_pose.y = current_pose.y;
    previous_pose.z = current_pose.z;
    previous_pose.roll = current_pose.roll;
    previous_pose.pitch = current_pose.pitch;
    previous_pose.yaw = current_pose.yaw;

    previous_scan_time.sec = current_scan_time.sec;
    previous_scan_time.nsec = current_scan_time.nsec;

    previous_previous_velocity = previous_velocity;
    previous_velocity = current_velocity;
    previous_velocity_x = current_velocity_x;
    previous_velocity_y = current_velocity_y;
    previous_velocity_z = current_velocity_z;
    previous_accel = current_accel;

    previous_estimated_vel_kmph.data = estimated_vel_kmph.data;
  }
}

int main(int argc, char** argv)
{
  ros::init(argc, argv, &quot;ndt_matching&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  // Set log file name.
  char buffer[80];
  std::time_t now = std::time(NULL);
  std::tm* pnow = std::localtime(&amp;now);
  std::strftime(buffer, 80, &quot;%Y%m%d_%H%M%S&quot;, pnow);
  filename = &quot;ndt_matching_&quot; + std::string(buffer) + &quot;.csv&quot;;
  ofs.open(filename.c_str(), std::ios::app);

  // Geting parameters
  private_nh.getParam(&quot;use_gnss&quot;, _use_gnss);
  private_nh.getParam(&quot;queue_size&quot;, _queue_size);
  private_nh.getParam(&quot;offset&quot;, _offset);
  private_nh.getParam(&quot;use_openmp&quot;, _use_openmp);
  private_nh.getParam(&quot;get_height&quot;, _get_height);
  private_nh.getParam(&quot;use_local_transform&quot;, _use_local_transform);
  private_nh.getParam(&quot;use_imu&quot;, _use_imu);
  private_nh.getParam(&quot;use_odom&quot;, _use_odom);
  private_nh.getParam(&quot;imu_upside_down&quot;, _imu_upside_down);
  private_nh.getParam(&quot;imu_topic&quot;, _imu_topic);

  if (nh.getParam(&quot;localizer&quot;, _localizer) == false)
  {
    std::cout &lt;&lt; &quot;localizer is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_x&quot;, _tf_x) == false)
  {
    std::cout &lt;&lt; &quot;tf_x is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_y&quot;, _tf_y) == false)
  {
    std::cout &lt;&lt; &quot;tf_y is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_z&quot;, _tf_z) == false)
  {
    std::cout &lt;&lt; &quot;tf_z is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_roll&quot;, _tf_roll) == false)
  {
    std::cout &lt;&lt; &quot;tf_roll is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_pitch&quot;, _tf_pitch) == false)
  {
    std::cout &lt;&lt; &quot;tf_pitch is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_yaw&quot;, _tf_yaw) == false)
  {
    std::cout &lt;&lt; &quot;tf_yaw is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }

  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Log file: &quot; &lt;&lt; filename &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_gnss: &quot; &lt;&lt; _use_gnss &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;queue_size: &quot; &lt;&lt; _queue_size &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;offset: &quot; &lt;&lt; _offset &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_openmp: &quot; &lt;&lt; _use_openmp &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;get_height: &quot; &lt;&lt; _get_height &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_local_transform: &quot; &lt;&lt; _use_local_transform &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_imu: &quot; &lt;&lt; _use_imu &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_odom: &quot; &lt;&lt; _use_odom &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;imu_upside_down: &quot; &lt;&lt; _imu_upside_down &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;localizer: &quot; &lt;&lt; _localizer &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;imu_topic: &quot; &lt;&lt; _imu_topic &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;(tf_x,tf_y,tf_z,tf_roll,tf_pitch,tf_yaw): (&quot; &lt;&lt; _tf_x &lt;&lt; &quot;, &quot; &lt;&lt; _tf_y &lt;&lt; &quot;, &quot; &lt;&lt; _tf_z &lt;&lt; &quot;, &quot;
            &lt;&lt; _tf_roll &lt;&lt; &quot;, &quot; &lt;&lt; _tf_pitch &lt;&lt; &quot;, &quot; &lt;&lt; _tf_yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;

  Eigen::Translation3f tl_btol(_tf_x, _tf_y, _tf_z);                 // tl: translation
  Eigen::AngleAxisf rot_x_btol(_tf_roll, Eigen::Vector3f::UnitX());  // rot: rotation
  Eigen::AngleAxisf rot_y_btol(_tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_btol(_tf_yaw, Eigen::Vector3f::UnitZ());
  tf_btol = (tl_btol * rot_z_btol * rot_y_btol * rot_x_btol).matrix();

  Eigen::Translation3f tl_ltob((-1.0) * _tf_x, (-1.0) * _tf_y, (-1.0) * _tf_z);  // tl: translation
  Eigen::AngleAxisf rot_x_ltob((-1.0) * _tf_roll, Eigen::Vector3f::UnitX());     // rot: rotation
  Eigen::AngleAxisf rot_y_ltob((-1.0) * _tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_ltob((-1.0) * _tf_yaw, Eigen::Vector3f::UnitZ());
  tf_ltob = (tl_ltob * rot_z_ltob * rot_y_ltob * rot_x_ltob).matrix();

  // Updated in initialpose_callback or gnss_callback
  initial_pose.x = 0.0;
  initial_pose.y = 0.0;
  initial_pose.z = 0.0;
  initial_pose.roll = 0.0;
  initial_pose.pitch = 0.0;
  initial_pose.yaw = 0.0;

  // Publishers
  predict_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose&quot;, 1000);
  predict_pose_imu_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose_imu&quot;, 1000);
  predict_pose_odom_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose_odom&quot;, 1000);
  predict_pose_imu_odom_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose_imu_odom&quot;, 1000);
  ndt_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/ndt_pose&quot;, 1000);
  // current_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/current_pose&quot;, 1000);
  localizer_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/localizer_pose&quot;, 1000);
  estimate_twist_pub = nh.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;/estimate_twist&quot;, 1000);
  estimated_vel_mps_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/estimated_vel_mps&quot;, 1000);
  estimated_vel_kmph_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/estimated_vel_kmph&quot;, 1000);
  estimated_vel_pub = nh.advertise&lt;geometry_msgs::Vector3Stamped&gt;(&quot;/estimated_vel&quot;, 1000);
  time_ndt_matching_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/time_ndt_matching&quot;, 1000);
  ndt_stat_pub = nh.advertise&lt;ndt_localizer::ndt_stat&gt;(&quot;/ndt_stat&quot;, 1000);
  ndt_reliability_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/ndt_reliability&quot;, 1000);

  // Subscribers
  ros::Subscriber param_sub = nh.subscribe(&quot;config/ndt&quot;, 10, param_callback);
  ros::Subscriber gnss_sub = nh.subscribe(&quot;gnss_pose&quot;, 10, gnss_callback);
  ros::Subscriber map_sub = nh.subscribe(&quot;points_map&quot;, 10, map_callback);
  ros::Subscriber initialpose_sub = nh.subscribe(&quot;initialpose&quot;, 1000, initialpose_callback);
  ros::Subscriber points_sub = nh.subscribe(&quot;filtered_points&quot;, _queue_size, points_callback);
  ros::Subscriber odom_sub = nh.subscribe(&quot;/odom_pose&quot;, _queue_size*10, odom_callback);
  ros::Subscriber imu_sub = nh.subscribe(_imu_topic.c_str(), _queue_size*10, imu_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="59ca15735c743b46b573352927e2c7bf2bdb1d85" fix_time="0,0">
		<msg>fix a compile problem due to duplicate declaration of std and opencv3</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/yolo2/src/yolo2_node.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/yolo2/src/yolo2_node.cpp">
				<diff>@@ -6,7 +6,11 @@
 
 #include &lt;cv_tracker_msgs/image_obj.h&gt;
 
+#include &lt;opencv2/opencv.hpp&gt;
+
+#if (CV_MAJOR_VERSION != 3)
 #include &lt;opencv2/contrib/contrib.hpp&gt;
+#endif
 #include &lt;opencv2/highgui/highgui.hpp&gt;
 
 #include &lt;cv_bridge/cv_bridge.h&gt;
</diff>
				<old_file>#include &lt;ros/ros.h&gt;
#include &lt;image_transport/image_transport.h&gt;
#include &lt;runtime_manager/ConfigSsd.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;

#include &lt;cv_tracker_msgs/image_obj.h&gt;

#include &lt;opencv2/contrib/contrib.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;

#include &lt;cv_bridge/cv_bridge.h&gt;

#include &lt;string&gt;
#include &lt;vector&gt;

#include &lt;math.h&gt;
#include &lt;stdlib.h&gt;

#include &lt;rect_class_score.h&gt;

#include &quot;darknet/yolo2.h&quot;

namespace Yolo2
{
	enum YoloDetectorClasses//using coco for default cfg and weights
	{
		PERSON, BICYCLE, CAR, MOTORBIKE, AEROPLANE, BUS, TRAIN, TRUCK, BOAT, TRAFFIC_LIGHT,
		FIRE_HYDRANT, STOP_SIGN, PARKING_METER, BENCH, BIRD, CAT, DOG, HORSE, SHEEP, COW,
		ELEPHANT, BEAR, ZEBRA, GIRAFFE, BACKPACK, UMBRELLA, HANDBAG, TIE, SUITCASE, FRISBEE,
		SKIS, SNOWBOARD, SPORTS_BALL, KITE, BASEBALL_BAT, BASEBALL_GLOVE, SKATEBOARD, SURFBOARD, TENNIS_RACKET, BOTTLE,
		WINE_GLASS, CUP, FORK, KNIFE, SPOON, BOWL, BANANA, APPLE, SANDWICH, ORANGE,
		BROCCOLI, CARROT, HOT_DOG, PIZZA, DONUT, CAKE, CHAIR, SOFA, POTTEDPLANT, BED,
		DININGTABLE, TOILET, TVMONITOR, LAPTOP, MOUSE, REMOTE, KEYBOARD, CELL_PHONE, MICROWAVE, OVEN,
		TOASTER, SINK, REFRIGERATOR, BOOK, CLOCK, VASE, SCISSORS, TEDDY_BEAR, HAIR_DRIER, TOOTHBRUSH,
	};
}

class Yolo2DetectorNode
{
	ros::Subscriber subscriber_image_raw_;
	ros::Subscriber subscriber_yolo_config_;
	ros::Publisher publisher_car_objects_;
	ros::Publisher publisher_person_objects_;
	ros::NodeHandle node_handle_;

	darknet::Yolo2Detector yolo_detector_;

	image darknet_image = {};

	float score_threshold_;
	float nms_threshold_;
	double image_ratio_;//resdize ratio used to fit input image to network input size
	uint32_t image_top_bottom_border_;//black strips added to the input image to maintain aspect ratio while resizing it to fit the network input size
	uint32_t image_left_right_border_;

	void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, cv_tracker_msgs::image_obj&amp; out_message, std::string in_class)
	{
		for (unsigned int i = 0; i &lt; in_objects.size(); ++i)
		{
			if ( (in_objects[i].score &gt; score_threshold_)
				&amp;&amp; (	(in_class == &quot;car&quot;
							&amp;&amp; (in_objects[i].class_type == Yolo2::CAR
								|| in_objects[i].class_type == Yolo2::BUS
								|| in_objects[i].class_type == Yolo2::TRUCK
								|| in_objects[i].class_type == Yolo2::MOTORBIKE
								)
						)
					|| (in_class == &quot;person&quot;
							&amp;&amp; (in_objects[i].class_type == Yolo2::PERSON
								|| in_objects[i].class_type == Yolo2::BICYCLE
								|| in_objects[i].class_type == Yolo2::DOG
								|| in_objects[i].class_type == Yolo2::CAT
								|| in_objects[i].class_type == Yolo2::HORSE
								)
						)
					)
				)//check if the score is larger than minimum required
			{
				cv_tracker_msgs::image_rect rect;

				rect.x = (in_objects[i].x * darknet_image.w /image_ratio_) - image_left_right_border_/image_ratio_;
				rect.y = (in_objects[i].y * darknet_image.h /image_ratio_) - image_top_bottom_border_/image_ratio_;
				rect.width = in_objects[i].w * darknet_image.w/image_ratio_;
				rect.height = in_objects[i].h * darknet_image.h/image_ratio_;
				if (in_objects[i].x &lt; 0)
					rect.x = 0;
				if (in_objects[i].y &lt; 0)
					rect.y = 0;
				if (in_objects[i].w &lt; 0)
					rect.width = 0;
				if (in_objects[i].h &lt; 0)
					rect.height = 0;

				rect.score = in_objects[i].score;

				//std::cout &lt;&lt; &quot;x &quot;&lt;&lt; rect.x&lt;&lt; &quot; y &quot; &lt;&lt; rect.y &lt;&lt; &quot; w &quot;&lt;&lt; rect.width &lt;&lt; &quot; h &quot;&lt;&lt; rect.height&lt;&lt; &quot; s &quot; &lt;&lt; rect.score &lt;&lt; &quot; c &quot; &lt;&lt; in_objects[i].class_type &lt;&lt; std::endl;

				out_message.obj.push_back(rect);

			}
		}
	}

	void rgbgr_image(image&amp; im)
	{
		int i;
		for(i = 0; i &lt; im.w*im.h; ++i)
		{
			float swap = im.data[i];
			im.data[i] = im.data[i+im.w*im.h*2];
			im.data[i+im.w*im.h*2] = swap;
		}
	}

	image convert_ipl_to_image(const sensor_msgs::ImageConstPtr&amp; msg)
	{
		cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(msg, &quot;bgr8&quot;);//toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
		cv::Mat mat_image = cv_image-&gt;image;

		uint32_t network_input_width = yolo_detector_.get_network_width();
		uint32_t network_input_height = yolo_detector_.get_network_height();

		uint32_t image_height = msg-&gt;height,
						image_width = msg-&gt;width;

		IplImage ipl_image;
		cv::Mat final_mat;

		//ROS_INFO(&quot;Before Network (%d,%d), Image (%d,%d)&quot;, network_input_width, network_input_height, image_width, image_height);
		if (network_input_width!=image_width
				|| network_input_height != image_height)
		{
			//final_mat = cv::Mat(network_input_width, network_input_height, CV_8UC3, cv::Scalar(0,0,0));
			image_ratio_ = (double ) network_input_width /  (double)mat_image.cols;
			//std::cout &lt;&lt; &quot;Ratio:&quot; &lt;&lt; image_ratio_ &lt;&lt; std::endl;

			cv::resize(mat_image, final_mat, cv::Size(), image_ratio_, image_ratio_);
			image_top_bottom_border_ = abs(final_mat.rows-network_input_height)/2;
			image_left_right_border_ = abs(final_mat.cols-network_input_width)/2;
			cv::copyMakeBorder(final_mat, final_mat,
								image_top_bottom_border_, image_top_bottom_border_,
								image_left_right_border_, image_left_right_border_,
								cv::BORDER_CONSTANT, cv::Scalar(0,0,0));

			/*
			 //CROP CENTER
			 * uint32_t crop_x, crop_y;
			crop_x = (image_width-network_input_width)/2;
			crop_y = (image_height-network_input_height)/2;
			cv::Rect center_crop(crop_x, crop_y, network_input_width, network_input_height);
			std::cout &lt;&lt; mat_image.cols &lt;&lt; &quot;, &quot; &lt;&lt; mat_image.rows &lt;&lt; std::endl;
			cv::Mat cropped_mat = mat_image(center_crop);
			cropped_mat.copyTo(final_mat);
			*/

			//VILE RESIZE
			//cv::resize(mat_image, final_mat, cv::Size(network_input_width, network_input_height));
		}
		else
			final_mat = mat_image;

		//ROS_INFO(&quot;After Network (%d,%d), Image (%d,%d)&quot;, network_input_width, network_input_height, final_mat.cols, final_mat.rows);

		ipl_image = final_mat;

		unsigned char *data = (unsigned char *)ipl_image.imageData;
		int h = ipl_image.height;
		int w = ipl_image.width;
		int c = ipl_image.nChannels;
		int step = ipl_image.widthStep;
		int i, j, k;

		image darknet_image = make_image(w, h, c);

		for(i = 0; i &lt; h; ++i){
			for(k= 0; k &lt; c; ++k){
				for(j = 0; j &lt; w; ++j){
					darknet_image.data[k*w*h + i*w + j] = data[i*step + j*c + k]/255.;
				}
			}
		}
		rgbgr_image(darknet_image);
		return darknet_image;
	}

	void image_callback(const sensor_msgs::ImageConstPtr&amp; in_image_message)
	{
		std::vector&lt; RectClassScore&lt;float&gt; &gt; detections;
		//darknet_image = yolo_detector_.convert_image(in_image_message);

		darknet_image = convert_ipl_to_image(in_image_message);

		detections = yolo_detector_.detect(darknet_image);

		//ROS_INFO(&quot;Detections: %ud&quot;, (unsigned int)detections.size());

		//Prepare Output message
		cv_tracker_msgs::image_obj output_car_message;
		cv_tracker_msgs::image_obj output_person_message;
		output_car_message.header = in_image_message-&gt;header;
		output_car_message.type = &quot;car&quot;;

		output_person_message.header = in_image_message-&gt;header;
		output_person_message.type = &quot;person&quot;;

		convert_rect_to_image_obj(detections, output_car_message, &quot;car&quot;);
		convert_rect_to_image_obj(detections, output_person_message, &quot;person&quot;);

		publisher_car_objects_.publish(output_car_message);
		publisher_person_objects_.publish(output_person_message);

		free(darknet_image.data);
	}

	void config_cb(const runtime_manager::ConfigSsd::ConstPtr&amp; param)
	{
		score_threshold_ 	= param-&gt;score_threshold;
	}

public:
	void Run()
	{
		//ROS STUFF
		ros::NodeHandle private_node_handle(&quot;~&quot;);//to receive args

		//RECEIVE IMAGE TOPIC NAME
		std::string image_raw_topic_str;
		if (private_node_handle.getParam(&quot;image_raw_node&quot;, image_raw_topic_str))
		{
			ROS_INFO(&quot;Setting image node to %s&quot;, image_raw_topic_str.c_str());
		}
		else
		{
			ROS_INFO(&quot;No image node received, defaulting to /image_raw, you can use _image_raw_node:=YOUR_TOPIC&quot;);
			image_raw_topic_str = &quot;/image_raw&quot;;
		}

		std::string network_definition_file;
		std::string pretrained_model_file;
		if (private_node_handle.getParam(&quot;network_definition_file&quot;, network_definition_file))
		{
			ROS_INFO(&quot;Network Definition File (Config): %s&quot;, network_definition_file.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Network Definition File was received. Finishing execution.&quot;);
			return;
		}
		if (private_node_handle.getParam(&quot;pretrained_model_file&quot;, pretrained_model_file))
		{
			ROS_INFO(&quot;Pretrained Model File (Weights): %s&quot;, pretrained_model_file.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Pretrained Model File was received. Finishing execution.&quot;);
			return;
		}

		if (private_node_handle.getParam(&quot;score_threshold&quot;, score_threshold_))
		{
			ROS_INFO(&quot;Score Threshold: %f&quot;, score_threshold_);
		}
		if (private_node_handle.getParam(&quot;nms_threshold&quot;, nms_threshold_))
		{
			ROS_INFO(&quot;NMS Threshold: %f&quot;, nms_threshold_);
		}

		ROS_INFO(&quot;Initializing Yolo2 on Darknet...&quot;);
		yolo_detector_.load(network_definition_file, pretrained_model_file, score_threshold_, nms_threshold_);
		ROS_INFO(&quot;Initialization complete.&quot;);

		publisher_car_objects_ = node_handle_.advertise&lt;cv_tracker_msgs::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
		publisher_person_objects_ = node_handle_.advertise&lt;cv_tracker_msgs::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);

		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str());
		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str, 1, &amp;Yolo2DetectorNode::image_callback, this);

		std::string config_topic(&quot;/config&quot;);
		config_topic += &quot;/yolo2&quot;;
		subscriber_yolo_config_ = node_handle_.subscribe(config_topic, 1, &amp;Yolo2DetectorNode::config_cb, this);

		ros::spin();
		ROS_INFO(&quot;END Yolo2&quot;);

	}
};

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;ssd_unc&quot;);

	Yolo2DetectorNode app;

	app.Run();

	return 0;
}

</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="39a5250fc663475af8bb1f1cb69894fa6303f729" fix_time="1,59593">
		<msg>Fixes for GPU Euclidean clustering</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/includes/gpu_euclidean_clustering.h" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/includes/gpu_euclidean_clustering.h">
				<diff>@@ -24,8 +24,8 @@ public:
 	void setThreshold(double threshold);
 	void setMinClusterPts(int min_cluster_pts);
 	void setMaxClusterPts(int max_cluster_pts);
+	void extractClustersOld();
 	void extractClusters();
-	void extractClusters2();
 	std::vector&lt;GClusterIndex&gt; getOutput();
 
 	SamplePointListXYZ generateSample();
</diff>
				<old_file>#ifndef GPU_EUCLIDEAN_H_
#define GPU_EUCLIDEAN_H_

#include &lt;iostream&gt;
#include &lt;vector&gt;

class GpuEuclideanCluster {
public:
	typedef struct {
		int index_value;
		std::vector&lt;int&gt; points_in_cluster;
	} GClusterIndex;

	typedef struct {
		float *x;
		float *y;
		float *z;
		int size;
	} SamplePointListXYZ;

	GpuEuclideanCluster();

	void setInputPoints(float *x, float *y, float *z, int size);
	void setThreshold(double threshold);
	void setMinClusterPts(int min_cluster_pts);
	void setMaxClusterPts(int max_cluster_pts);
	void extractClusters();
	void extractClusters2();
	std::vector&lt;GClusterIndex&gt; getOutput();

	SamplePointListXYZ generateSample();

	~GpuEuclideanCluster();

private:
	float *x_, *y_, *z_;
	int size_;
	double threshold_;
	int *cluster_indices_;
	int *cluster_indices_host_;
	int min_cluster_pts_;
	int max_cluster_pts_;
	int cluster_num_;


	void exclusiveScan(int *input, int ele_num, int *sum);
};

#endif
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="0fccd8175a9d42fa9d626ce29d44e964767ac1b4" fix_time="0,0">
		<msg>Add roi_extractor.launch to make handling parameter easy

And fixed small bug to get parameter from ROS private parameter server</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/roi_extractor/roi_extractor.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/roi_extractor/roi_extractor.cpp">
				<diff>@@ -179,7 +179,7 @@ int main (int argc, char *argv[]) {
   ros::init(argc, argv, &quot;roi_extractor&quot;);
 
   // Get source topic name of image from ROS private parameter
-  ros::NodeHandle private_node_handler;
+  ros::NodeHandle private_node_handler(&quot;~&quot;);
   std::string image_topic_name;
   std::string target_directory_name = std::string(getenv(&quot;HOME&quot;)) + &quot;/.autoware&quot;;
   int minimum_height = 32;
</diff>
				<old_file>#include &quot;roi_extractor.h&quot;

#include &lt;sys/stat.h&gt;
#include &lt;dirent.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string&gt;
#include &lt;vector&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;opencv2/opencv.hpp&gt;


#include &quot;Context.h&quot;
#include &quot;road_wizard/Signals.h&quot;


void RoiExtractor::ImageRawCallback(const sensor_msgs::Image &amp;image) {
  // Acquire frame image from ros topic
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image, sensor_msgs::image_encodings::BGR8);
  frame_ = cv_image-&gt;image.clone();

  // Save this topic's time stamp so that same image will not be processed more than twice
  frame_timestamp_ = image.header.stamp;
} // void RoiExtractor::ImageRawCallback()


void RoiExtractor::RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos) {
  // If frame image has not been updated, do nothing
  if (frame_timestamp_ == previous_timestamp_) {
    return;
  }

  // Aquire signal positions from ros topic
  std::vector&lt;Context&gt; signal_positions;
  Context::SetContexts(signal_positions, extracted_pos, frame_.rows, frame_.cols);

  if (signal_positions.size() == 0) {
    // If signal_positions is empty, no ROI images should be saved
    return;
  }

  // Extract ROI for top signal in vector (top signal has largest estimated radius in every signals projected in a image)
  cv::Mat roi = frame_(cv::Rect(signal_positions.at(0).topLeft, signal_positions.at(0).botRight));
  std::string file_name = target_directory_ + std::to_string(file_count_) + &quot;.png&quot;;

  // Reject image if its height is smaller than threshold
  if (roi.size().height &lt; k_minimum_height_) {
    return;
  }

  // Reject image if its similarity level with previous saved ROI is higher than threshold 
  if (k_similarity_threshold_ &lt; CalculateSimilarity(roi, previous_saved_frame_)) {
    return;
  }

  cv::imwrite(file_name.c_str(), roi);
  file_count_++;
  
  previous_timestamp_ = frame_timestamp_;
  previous_saved_frame_ = roi.clone();
} // void RoiExtractor::RoiSignalCallback()


void RoiExtractor::CreateTargetDirectory(std::string base_name) {
  // Extracted ROI's images will be saved in &quot;[base_name]/tlr_TrainingDataSet/Images&quot;
  std::string target_directory_name = base_name + &quot;/tlr_TrainingDataSet/Images/&quot;;
  
  // Create target directory newly if it doesn't exist
  struct stat directory_info;
  if (stat(target_directory_name.c_str(), &amp;directory_info) != 0) {
    MakeDirectoryTree(target_directory_name, base_name, 0755);
  }

  // Count the number of files contained in the target directory
  // so that saved file is named in continuous number
  file_count_ = CountFileNum(target_directory_name);


  // Save directory name into class member
  target_directory_ = target_directory_name;

} // void RoiExtractor::CreateTargetDirectory


int RoiExtractor::CountFileNum(std::string directory_name) {
  int file_num = 0;
  struct dirent *entry;
  DIR *directory_handler = opendir(directory_name.c_str());

  // Count the number of files contained in the specified directory
  while ((entry = readdir(directory_handler)) != NULL) {
    struct stat status;
    std::string absolute_path = directory_name + std::string(entry-&gt;d_name);
    if (stat(absolute_path.c_str(), &amp;status) == 0 &amp;&amp;
        S_ISREG(status.st_mode)) {
      file_num++;
    }
  }

  closedir(directory_handler);

  return file_num;
} //int RoiExtractor::CountFileNum()


void RoiExtractor::MakeDirectoryTree(const std::string &amp;target,
                                     const std::string &amp;base,
                                     const mode_t &amp;mode) {
  // Extract directory subtree structure
  std::string sub_tree = target.substr(base.size());

  // Create directory tree one by one
  size_t separator_start = sub_tree.find(&quot;/&quot;);
  size_t separator_end = sub_tree.find(&quot;/&quot;, separator_start + 1);
  std::string path = base;
  while (separator_end != std::string::npos) {
    std::string sub_directory = sub_tree.substr(separator_start, separator_end);
    path = path + sub_directory;
    mkdir(path.c_str(), mode);
    separator_start = separator_end;
    separator_end = sub_tree.find(&quot;/&quot;, separator_start + 1);
  }
} // void RoiExtractor::MakeDirectoryTree()


// calculae similarity of specified two images
// by comparing their histogram, which is sensitive filter for color
double RoiExtractor::CalculateSimilarity(const cv::Mat &amp;image1, const cv::Mat &amp;image2) {
  if (image1.empty() || image2.empty()) {
    return 0.0;
  }

  // Compare by histogram
  cv::Mat image1_hsv, image2_hsv;
  cv::cvtColor(image1, image1_hsv, CV_BGR2HSV);
  cv::cvtColor(image2, image2_hsv, CV_BGR2HSV);

  const int channel[] = {0};

  // Hue range in OpenCV is 0 to 180
  const float hue_ranges[] = {0, 180};
  const float* ranges[] = {hue_ranges};

  // Quantize hue value into 6
  int hist_size[] = {6};

  cv::Mat histogram1;
  cv::calcHist(&amp;image1_hsv,
               1,               // Use this image only to create histogram
               channel,
               cv::Mat(),       // No mask is used
               histogram1,
               1,               // The dimension of histogram is 1
               hist_size,
               ranges);

   cv::Mat histogram2;
   cv::calcHist(&amp;image2_hsv,
                1,              // Use this image only to create histogram
                channel,
                cv::Mat(),      // No mask is used
                histogram2,
                1,              // The dimension of histogram is 1
                hist_size,
                ranges);

   double similarity = cv::compareHist(histogram1, histogram2, CV_COMP_CORREL);

   return similarity;
} // void RoiExtractor::CalculateSimilarity()


// Entry Point of this node
int main (int argc, char *argv[]) {
  // Initialize ROS node
  ros::init(argc, argv, &quot;roi_extractor&quot;);

  // Get source topic name of image from ROS private parameter
  ros::NodeHandle private_node_handler;
  std::string image_topic_name;
  std::string target_directory_name = std::string(getenv(&quot;HOME&quot;)) + &quot;/.autoware&quot;;
  int minimum_height = 32;
  double similarity_threshold = 0.9;
  private_node_handler.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name, &quot;/image_raw&quot;);
  private_node_handler.param&lt;std::string&gt;(&quot;target_directory&quot;, target_directory_name, target_directory_name);
  private_node_handler.param&lt;int&gt;(&quot;minimum_height&quot;, minimum_height, 32); // The default minimum height is 32
  private_node_handler.param&lt;double&gt;(&quot;similarity_threshold&quot;, similarity_threshold, 0.9); // The default similarity threshold is 0.9

  // Get directory name which roi images will be saved
  RoiExtractor extractor(minimum_height, similarity_threshold);
  extractor.CreateTargetDirectory(target_directory_name);

  // Launch callback function to subscribe images and signal position
  ros::NodeHandle node_handler;
  ros::Subscriber image_subscriber = node_handler.subscribe(image_topic_name,
                                                            1,
                                                            &amp;RoiExtractor::ImageRawCallback,
                                                            &amp;extractor);

  ros::Subscriber roi_signal_subscriber = node_handler.subscribe(&quot;/roi_signal&quot;,
                                                                 1,
                                                                 &amp;RoiExtractor::RoiSignalCallback,
                                                                 &amp;extractor);
  
  ros::spin();

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="bd68ddf18e2e171b5c4bf12e6ef7fcd275733c04" fix_time="0,1">
		<msg>Modify State Transition Matrix of TLR for more precise recognition

* w.r.t `region_tlr`, just fixed comment
* w.r.t `region_tlr_ssd`, applied manner of erring on the side of caution</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr/TrafficLightDetector.h" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr/TrafficLightDetector.h">
				<diff>@@ -16,7 +16,7 @@
 #define MY_COLOR_WHITE	cv::Scalar(255,255,255)
 
 const LightState STATE_TRANSITION_MATRIX[4][8] = {
-	/* current RYG: 000, 001, 010, 011, 100, 101, 110, 111 */
+	/* current GYR: 000, 001, 010, 011, 100, 101, 110, 111 */
 	{ GREEN,     UNDEFINED, YELLOW,    YELLOW, GREEN,     GREEN,     YELLOW, UNDEFINED }, /* pre = GREEN  */
 	{ YELLOW,    RED,       YELLOW,    RED,    UNDEFINED, UNDEFINED, YELLOW, UNDEFINED }, /* pre = YELLOW */
 	{ RED,       RED,       UNDEFINED, RED,    GREEN,     RED,       GREEN,  UNDEFINED }, /* pre = RED */
</diff>
				<old_file>#ifndef TRAFFIC_LIGHT_DETECTOR_H
#define TRAFFIC_LIGHT_DETECTOR_H

#include &lt;vector&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;
#include &lt;opencv2/features2d/features2d.hpp&gt;
#include &quot;Context.h&quot;

#define MY_COLOR_PURPLE	cv::Scalar(255,0,255)
#define MY_COLOR_RED	cv::Scalar(0,0,255)
#define MY_COLOR_GREEN	cv::Scalar(0,255,0)
#define MY_COLOR_YELLOW	cv::Scalar(60,255,255)
#define MY_COLOR_BLUE	cv::Scalar(255,0,0)
#define MY_COLOR_WHITE	cv::Scalar(255,255,255)

const LightState STATE_TRANSITION_MATRIX[4][8] = {
	/* current RYG: 000, 001, 010, 011, 100, 101, 110, 111 */
	{ GREEN,     UNDEFINED, YELLOW,    YELLOW, GREEN,     GREEN,     YELLOW, UNDEFINED }, /* pre = GREEN  */
	{ YELLOW,    RED,       YELLOW,    RED,    UNDEFINED, UNDEFINED, YELLOW, UNDEFINED }, /* pre = YELLOW */
	{ RED,       RED,       UNDEFINED, RED,    GREEN,     RED,       GREEN,  UNDEFINED }, /* pre = RED */
	{ UNDEFINED, RED,       YELLOW,    RED,    GREEN,     RED,       YELLOW, UNDEFINED }  /* pre = UNDEFINED */
};

double getBrightnessRatioInCircle(const cv::Mat &amp;input, const cv::Point center, const int radius);
int getCurrentLightsCode(bool display_red, bool display_yellow, bool display_green);
LightState determineState(LightState previousState, int currentLightsCode, int* stateJudgeCount);

class TrafficLightDetector {
public:
	TrafficLightDetector();
	void brightnessDetect(const cv::Mat &amp;input);
	void colorDetect(const cv::Mat &amp;input, cv::Mat &amp;output, const cv::Rect coords, int Hmin, int Hmax);
	std::vector&lt;Context&gt; contexts;
};

enum daytime_Hue_threshold {
    DAYTIME_RED_LOWER    = 340,
    DAYTIME_RED_UPPER    = 50,
    DAYTIME_YELLOW_LOWER = 50,
    DAYTIME_YELLOW_UPPER = 70,
    DAYTIME_GREEN_LOWER  = 80,//120,//140,
    DAYTIME_GREEN_UPPER  = 190,//180,
};

#define DAYTIME_S_SIGNAL_THRESHOLD ((double)0.37)//((double)0.27)
#define DAYTIME_V_SIGNAL_THRESHOLD ((double)140/255) //((double)90/255) //((double)110/255)

#define NOISE_REDUCTION_TIME 1

#define CIRCLE_LEVEL_THRESHOLD 0.75 //0.65
#define CIRCLE_AREA_THRESHOLD 0.5 //1 //5

#define CHANGE_STATE_THRESHOLD 10

/* utility functions to convert HSV value range from OpenCV to definition */
static inline double Actual_Hue(uchar hue_opencv)
{
    return ((double)2 * hue_opencv);
} /* static inline double Actual_Hue() */

static inline double Actual_Sat(uchar sat_opencv)
{
    return ((double)sat_opencv / 255);
} /* static inline double Actual_Sat() */


static inline double Actual_Val(uchar val_opencv)
{
    return ((double)val_opencv / 255);
} /* static inline double Actual_Val() */

#endif
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr_ssd/region_tlr_ssd.h" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr_ssd/region_tlr_ssd.h">
				<diff>@@ -29,12 +29,12 @@ class RegionTlrSsdRosNode {
   /* Light state transition probably happen in Japanese traffic light */
   const LightState kStateTransitionMatrix[4][4] = {
     /* current: */
-    /* GREEN   , YELLOW    , RED       , UNDEFINED  */
+    /* GREEN   , YELLOW    , RED    , UNDEFINED  */
     /* -------------------------------------------  */
-    {GREEN     , YELLOW    , UNDEFINED , GREEN}  ,  /* | previous = GREEN */
-    {UNDEFINED , YELLOW    , RED       , YELLOW} ,  /* | previous = YELLOW */
-    {GREEN     , UNDEFINED , RED       , RED}    ,  /* | previous = RED */
-    {GREEN     , YELLOW    , RED       , UNDEFINED} /* | previous = UNDEFINED */
+    {GREEN     , YELLOW    , YELLOW , GREEN}  ,  /* | previous = GREEN */
+    {UNDEFINED , YELLOW    , RED    , YELLOW} ,  /* | previous = YELLOW */
+    {GREEN     , RED       , RED    , RED}    ,  /* | previous = RED */
+    {GREEN     , YELLOW    , RED    , UNDEFINED} /* | previous = UNDEFINED */
   };
 
 
</diff>
				<old_file>#ifndef REGION_TLR_SSD_H
#define REGION_TLR_SSD_H

#include &lt;string&gt;

#include &lt;opencv2/opencv.hpp&gt;
#include &lt;ros/ros.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;

#include &quot;Context.h&quot;
#include &quot;road_wizard/Signals.h&quot;
#include &quot;traffic_light_recognizer.h&quot;

class RegionTlrSsdRosNode {
 public:
  RegionTlrSsdRosNode();
  ~RegionTlrSsdRosNode();

  void RunRecognition();
  void ImageRawCallback(const sensor_msgs::Image &amp;image);
  void RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos);

  // The vector of data structure to save traffic light state, position, ...etc
  std::vector&lt;Context&gt; contexts_;

 private:
  /* Light state transition probably happen in Japanese traffic light */
  const LightState kStateTransitionMatrix[4][4] = {
    /* current: */
    /* GREEN   , YELLOW    , RED       , UNDEFINED  */
    /* -------------------------------------------  */
    {GREEN     , YELLOW    , UNDEFINED , GREEN}  ,  /* | previous = GREEN */
    {UNDEFINED , YELLOW    , RED       , YELLOW} ,  /* | previous = YELLOW */
    {GREEN     , UNDEFINED , RED       , RED}    ,  /* | previous = RED */
    {GREEN     , YELLOW    , RED       , UNDEFINED} /* | previous = UNDEFINED */
  };


  void GetRosParam();
  void StartSubscribersAndPublishers();
  LightState DetermineState(LightState previous_state, LightState current_state, int* state_judge_count);
  void PublishTrafficLight(std::vector&lt;Context&gt; contexts);
  void PublishString(std::vector&lt;Context&gt; contexts);
  void PublishMarkerArray(std::vector&lt;Context&gt; contexts);
  void PublishImage(std::vector&lt;Context&gt; contexts);

  // Execution parameter
  std::string image_topic_name_;
  std::string network_definition_file_name_;
  std::string pretrained_model_file_name_;
  bool use_gpu_;
  int gpu_id_;

  // Subscribers
  ros::Subscriber image_subscriber;
  ros::Subscriber roi_signal_subscriber;

  // Publishers
  ros::Publisher signal_state_publisher;
  ros::Publisher signal_state_string_publisher;
  ros::Publisher marker_publisher;
  ros::Publisher superimpose_image_publisher;

  // Flag to show topic will be published in latch manner
  bool kAdvertiseInLatch_;

  // A frame image acquired from topic
  cv::Mat frame_;

  // Timestamp of a frame in process
  std_msgs::Header frame_header_;

  // The instance of the core class of traffic light recognition by SSD
  TrafficLightRecognizer recognizer;

  // The threshold of state detected times to accept the state change
  const int kChangeStateThreshold = 10;

  // constant values to pass recognition states to other nodes
  const int32_t kTrafficLightRed;
  const int32_t kTrafficLightGreen;
  const int32_t kTrafficLightUnknown;
  const std::string kStringRed;
  const std::string kStringGreen;
  const std::string kStringUnknown;
};

#endif  // REGION_TLR_SSD_H
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="ea03a1e0ad34d5771af9e67d40829b82d1e1d1f2" fix_time="0,1">
		<msg>Fix usage of std::string::substr</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/roi_extractor/roi_extractor.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/roi_extractor/roi_extractor.cpp">
				<diff>@@ -117,7 +117,7 @@ void RoiExtractor::MakeDirectoryTree(const std::string &amp;target,
   size_t separator_end = sub_tree.find(&quot;/&quot;, separator_start + 1);
   std::string path = base;
   while (separator_end != std::string::npos) {
-    std::string sub_directory = sub_tree.substr(separator_start, separator_end);
+    std::string sub_directory = sub_tree.substr(separator_start, separator_end - separator_start);
     path = path + sub_directory;
     mkdir(path.c_str(), mode);
     separator_start = separator_end;
</diff>
				<old_file>#include &quot;roi_extractor.h&quot;

#include &lt;sys/stat.h&gt;
#include &lt;dirent.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string&gt;
#include &lt;vector&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;opencv2/opencv.hpp&gt;


#include &quot;Context.h&quot;
#include &quot;road_wizard/Signals.h&quot;


void RoiExtractor::ImageRawCallback(const sensor_msgs::Image &amp;image) {
  // Acquire frame image from ros topic
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image, sensor_msgs::image_encodings::BGR8);
  frame_ = cv_image-&gt;image.clone();

  // Save this topic's time stamp so that same image will not be processed more than twice
  frame_timestamp_ = image.header.stamp;
} // void RoiExtractor::ImageRawCallback()


void RoiExtractor::RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos) {
  // If frame image has not been updated, do nothing
  if (frame_timestamp_ == previous_timestamp_) {
    return;
  }

  // Aquire signal positions from ros topic
  std::vector&lt;Context&gt; signal_positions;
  Context::SetContexts(signal_positions, extracted_pos, frame_.rows, frame_.cols);

  if (signal_positions.size() == 0) {
    // If signal_positions is empty, no ROI images should be saved
    return;
  }

  // Extract ROI for top signal in vector (top signal has largest estimated radius in every signals projected in a image)
  cv::Mat roi = frame_(cv::Rect(signal_positions.at(0).topLeft, signal_positions.at(0).botRight));
  std::string file_name = target_directory_ + std::to_string(file_count_) + &quot;.png&quot;;

  // Reject image if its height is smaller than threshold
  if (roi.size().height &lt; k_minimum_height_) {
    return;
  }

  // Reject image if its similarity level with previous saved ROI is higher than threshold 
  if (k_similarity_threshold_ &lt; CalculateSimilarity(roi, previous_saved_frame_)) {
    return;
  }

  cv::imwrite(file_name.c_str(), roi);
  file_count_++;
  
  previous_timestamp_ = frame_timestamp_;
  previous_saved_frame_ = roi.clone();
} // void RoiExtractor::RoiSignalCallback()


void RoiExtractor::CreateTargetDirectory(std::string base_name) {
  // Extracted ROI's images will be saved in &quot;[base_name]/tlr_TrainingDataSet/Images&quot;
  std::string target_directory_name = base_name + &quot;/tlr_TrainingDataSet/Images/&quot;;
  
  // Create target directory newly if it doesn't exist
  struct stat directory_info;
  if (stat(target_directory_name.c_str(), &amp;directory_info) != 0) {
    MakeDirectoryTree(target_directory_name, base_name, 0755);
  }

  // Count the number of files contained in the target directory
  // so that saved file is named in continuous number
  file_count_ = CountFileNum(target_directory_name);


  // Save directory name into class member
  target_directory_ = target_directory_name;

} // void RoiExtractor::CreateTargetDirectory


int RoiExtractor::CountFileNum(std::string directory_name) {
  int file_num = 0;
  struct dirent *entry;
  DIR *directory_handler = opendir(directory_name.c_str());

  // Count the number of files contained in the specified directory
  while ((entry = readdir(directory_handler)) != NULL) {
    struct stat status;
    std::string absolute_path = directory_name + std::string(entry-&gt;d_name);
    if (stat(absolute_path.c_str(), &amp;status) == 0 &amp;&amp;
        S_ISREG(status.st_mode)) {
      file_num++;
    }
  }

  closedir(directory_handler);

  return file_num;
} //int RoiExtractor::CountFileNum()


void RoiExtractor::MakeDirectoryTree(const std::string &amp;target,
                                     const std::string &amp;base,
                                     const mode_t &amp;mode) {
  // Extract directory subtree structure
  std::string sub_tree = target.substr(base.size());

  // Create directory tree one by one
  size_t separator_start = sub_tree.find(&quot;/&quot;);
  size_t separator_end = sub_tree.find(&quot;/&quot;, separator_start + 1);
  std::string path = base;
  while (separator_end != std::string::npos) {
    std::string sub_directory = sub_tree.substr(separator_start, separator_end);
    path = path + sub_directory;
    mkdir(path.c_str(), mode);
    separator_start = separator_end;
    separator_end = sub_tree.find(&quot;/&quot;, separator_start + 1);
  }
} // void RoiExtractor::MakeDirectoryTree()


// calculae similarity of specified two images
// by comparing their histogram, which is sensitive filter for color
double RoiExtractor::CalculateSimilarity(const cv::Mat &amp;image1, const cv::Mat &amp;image2) {
  if (image1.empty() || image2.empty()) {
    return 0.0;
  }

  // Compare by histogram
  cv::Mat image1_hsv, image2_hsv;
  cv::cvtColor(image1, image1_hsv, CV_BGR2HSV);
  cv::cvtColor(image2, image2_hsv, CV_BGR2HSV);

  const int channel[] = {0};

  // Hue range in OpenCV is 0 to 180
  const float hue_ranges[] = {0, 180};
  const float* ranges[] = {hue_ranges};

  // Quantize hue value into 6
  int hist_size[] = {6};

  cv::Mat histogram1;
  cv::calcHist(&amp;image1_hsv,
               1,               // Use this image only to create histogram
               channel,
               cv::Mat(),       // No mask is used
               histogram1,
               1,               // The dimension of histogram is 1
               hist_size,
               ranges);

   cv::Mat histogram2;
   cv::calcHist(&amp;image2_hsv,
                1,              // Use this image only to create histogram
                channel,
                cv::Mat(),      // No mask is used
                histogram2,
                1,              // The dimension of histogram is 1
                hist_size,
                ranges);

   double similarity = cv::compareHist(histogram1, histogram2, CV_COMP_CORREL);

   return similarity;
} // void RoiExtractor::CalculateSimilarity()


// Entry Point of this node
int main (int argc, char *argv[]) {
  // Initialize ROS node
  ros::init(argc, argv, &quot;roi_extractor&quot;);

  // Get source topic name of image from ROS private parameter
  ros::NodeHandle private_node_handler(&quot;~&quot;);
  std::string image_topic_name;
  std::string target_directory_name = std::string(getenv(&quot;HOME&quot;)) + &quot;/.autoware&quot;;
  int minimum_height = 32;
  double similarity_threshold = 0.9;
  private_node_handler.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name, &quot;/image_raw&quot;);
  private_node_handler.param&lt;std::string&gt;(&quot;target_directory&quot;, target_directory_name, target_directory_name);
  private_node_handler.param&lt;int&gt;(&quot;minimum_height&quot;, minimum_height, 32); // The default minimum height is 32
  private_node_handler.param&lt;double&gt;(&quot;similarity_threshold&quot;, similarity_threshold, 0.9); // The default similarity threshold is 0.9

  // Get directory name which roi images will be saved
  RoiExtractor extractor(minimum_height, similarity_threshold);
  extractor.CreateTargetDirectory(target_directory_name);

  // Launch callback function to subscribe images and signal position
  ros::NodeHandle node_handler;
  ros::Subscriber image_subscriber = node_handler.subscribe(image_topic_name,
                                                            1,
                                                            &amp;RoiExtractor::ImageRawCallback,
                                                            &amp;extractor);

  ros::Subscriber roi_signal_subscriber = node_handler.subscribe(&quot;/roi_signal&quot;,
                                                                 1,
                                                                 &amp;RoiExtractor::RoiSignalCallback,
                                                                 &amp;extractor);
  
  ros::spin();

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="c86373f03bcd290a713513901af828dd196662c3" fix_time="0,0">
		<msg>Fix bug of vector_map_server usage</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/feat_proj/feat_proj.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/feat_proj/feat_proj.cpp">
				<diff>@@ -409,10 +409,12 @@ int main (int argc, char *argv[])
 
   ros::Subscriber cameraInfoSubscriber = rosnode.subscribe (cameraInfo_topic_name, 100, cameraInfoCallback);
   ros::Subscriber adjust_xySubscriber  = rosnode.subscribe(&quot;/config/adjust_xy&quot;, 100, adjust_xyCallback);
+  ros::Subscriber current_pose_subscriber;
+  ros::Subscriber waypoint_subscriber;
   if (g_use_vector_map_server) {
     /* Create subscribers which deliver informations requested by server */
-    ros::Subscriber current_pose_subscriber = rosnode.subscribe(&quot;/current_pose&quot;, 1, &amp;VectorMapClient::set_pose, &amp;g_vector_map_client);
-    ros::Subscriber waypoint_subscriber     = rosnode.subscribe(&quot;/final_waypoints&quot;, 1, &amp;VectorMapClient::set_waypoints, &amp;g_vector_map_client);
+    current_pose_subscriber = rosnode.subscribe(&quot;/current_pose&quot;, 1, &amp;VectorMapClient::set_pose, &amp;g_vector_map_client);
+    waypoint_subscriber     = rosnode.subscribe(&quot;/final_waypoints&quot;, 1, &amp;VectorMapClient::set_waypoints, &amp;g_vector_map_client);
 
     /* Create ros client to use Server-Client communication */
     g_ros_client = rosnode.serviceClient&lt;vector_map_server::GetSignal&gt;(&quot;vector_map_server/get_signal&quot;);
</diff>
				<old_file>/*
 * signals.cpp
 *
 *  Created on: Apr 9, 2015
 *      Author: sujiwo
 */


#include &lt;iostream&gt;
#include &lt;ros/ros.h&gt;
#include &quot;Rate.h&quot;
#include &quot;vector_map.h&quot;
#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;sensor_msgs/CameraInfo.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/Pose.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;signal.h&gt;
#include &lt;cstdio&gt;
#include &quot;Math.h&quot;
#include &lt;Eigen/Eigen&gt;
#include &quot;road_wizard/Signals.h&quot;
#include &lt;runtime_manager/adjust_xy.h&gt;
#include &lt;vector_map/vector_map.h&gt;
#include &lt;vector_map_server/GetSignal.h&gt;
#include &lt;waypoint_follower/lane.h&gt;

static std::string camera_id_str;

static constexpr uint32_t SUBSCRIBE_QUEUE_SIZE = 1000;

static int adjust_proj_x = 0;
static int adjust_proj_y = 0;

typedef struct {
  double thiX;
  double thiY;
  double thiZ;
} Angle;

static VectorMap vmap;
static Angle cameraOrientation; // camera orientation = car's orientation

static Eigen::Vector3f position;
static Eigen::Quaternionf orientation;
static  float fx,
  fy,
  imageWidth,
  imageHeight,
  cx,
  cy;
static tf::StampedTransform trf;

static bool g_use_vector_map_server; // Switch flag whether vecter-map-server function will be used
static ros::ServiceClient g_ros_client;

#define SignalLampRadius 0.3

/* Define utility class to use vector map server */
namespace
{
  class VectorMapClient
  {
  private:
    geometry_msgs::PoseStamped pose_;
    waypoint_follower::lane waypoints_;

  public:
    VectorMapClient()
    {}

    ~VectorMapClient()
    {}

    geometry_msgs::PoseStamped pose() const
    {
      return pose_;
    }

    waypoint_follower::lane waypoints() const
    {
      return waypoints_;
    }

    void set_pose(const geometry_msgs::PoseStamped&amp; pose)
    {
      pose_ = pose;
    }

    void set_waypoints(const waypoint_follower::lane&amp; waypoints)
    {
      waypoints_ = waypoints;
    }
  }; // Class VectorMapClient
} // namespace
static VectorMapClient g_vector_map_client;


/* Callback function to shift projection result */
void adjust_xyCallback (const runtime_manager::adjust_xy::ConstPtr&amp; config_msg)
{
  adjust_proj_x = config_msg-&gt;x;
  adjust_proj_y = config_msg-&gt;y;
}

void cameraInfoCallback (const sensor_msgs::CameraInfo::ConstPtr camInfoMsg)
{
  fx = static_cast&lt;float&gt;(camInfoMsg-&gt;P[0]);
  fy = static_cast&lt;float&gt;(camInfoMsg-&gt;P[5]);
  imageWidth = camInfoMsg-&gt;width;
  imageHeight = camInfoMsg-&gt;height;
  cx = static_cast&lt;float&gt;(camInfoMsg-&gt;P[2]);
  cy = static_cast&lt;float&gt;(camInfoMsg-&gt;P[6]);
}


/* convert degree value into 0 to 360 range */
static double setDegree0to360(double val)
{
  if (val &lt; 0.0f) {
    return (val + 360.0f);
  }
  else if (360.0f &lt; val) {
    return (val - 360.0f);
  }

  return val;
}


static void get_cameraRollPitchYaw(double* roll,
                                   double* pitch,
                                   double* yaw)
{
  geometry_msgs::Pose cameraPose;
  cameraPose.position.x    = (double)(position.x());
  cameraPose.position.y    = (double)(position.y());
  cameraPose.position.z    = (double)(position.z());
  cameraPose.orientation.x = (double)(orientation.x());
  cameraPose.orientation.y = (double)(orientation.y());
  cameraPose.orientation.z = (double)(orientation.z());
  cameraPose.orientation.w = (double)(orientation.w());

  tf::Quaternion quat;

  tf::quaternionMsgToTF(cameraPose.orientation, quat);
  tf::Matrix3x3(quat).getRPY(*roll, *pitch, *yaw);

  /* convert from radian to degree */
  *roll  = setDegree0to360(*roll  * 180.0f / M_PI);
  *pitch = setDegree0to360(*pitch * 180.0f / M_PI);
  *yaw   = setDegree0to360(*yaw   * 180.0f / M_PI);
}


/*
  check if lower &lt; val &lt; upper
  This function also considers circulation
*/
static bool isRange(const double lower, const double upper, const double val)
{
  if (lower &lt;= upper) {
    if (lower &lt; val &amp;&amp; val &lt; upper) {
      return true;
    }
  }
  else {
    if (val &lt; upper || lower &lt; val) {
      return true;
    }
  }

  return false;
}


void getTransform (Eigen::Quaternionf &amp;ori, Point3 &amp;pos)
{
  static tf::TransformListener listener;

  // target_frame    source_frame
  ros::Time now = ros::Time();
  listener.waitForTransform (camera_id_str, &quot;map&quot;, now, ros::Duration(10.0));
  listener.lookupTransform (camera_id_str, &quot;map&quot;, now, trf);

  tf::Vector3 &amp;p = trf.getOrigin();
  tf::Quaternion o = trf.getRotation();
  pos.x()=p.x(); pos.y()=p.y(); pos.z()=p.z();
  ori.w()=o.w(); ori.x()=o.x(); ori.y()=o.y(); ori.z()=o.z();
}


Point3 transform (const Point3 &amp;psrc, tf::StampedTransform &amp;tfsource)
{
  tf::Vector3 pt3 (psrc.x(), psrc.y(), psrc.z());
  tf::Vector3 pt3s = tfsource * pt3;
  return Point3 (pt3s.x(), pt3s.y(), pt3s.z());
}


/*
 * Project a point from world coordinate to image plane
 */
bool project2 (const Point3 &amp;pt, int &amp;u, int &amp;v, bool useOpenGLCoord=false)
{
  float nearPlane = 1.0;
  float farPlane = 200.0;
  Point3 _pt = transform (pt, trf);
  float _u = _pt.x()*fx/_pt.z() + cx;
  float _v = _pt.y()*fy/_pt.z() + cy;

  u = static_cast&lt;int&gt;(_u);
  v = static_cast&lt;int&gt;(_v);
  if ( u &lt; 0 || imageWidth &lt; u || v &lt; 0 || imageHeight &lt; v || _pt.z() &lt; nearPlane || farPlane &lt; _pt.z() ) {
    u = -1, v = -1;
    return false;
  }

  if (useOpenGLCoord) {
    v = imageHeight - v;
  }

  return true;
}

double ConvertDegreeToRadian(double degree)
{
  return degree * M_PI / 180.0f;
}


double ConvertRadianToDegree(double radian)
{
  return radian * 180.0f / M_PI;
}


double GetSignalAngleInCameraSystem(double hang, double vang)
{
  // Fit the vector map format into ROS style
  double signal_pitch_in_map = ConvertDegreeToRadian(vang - 90);
  double signal_yaw_in_map   = ConvertDegreeToRadian(-hang + 90);

  tf::Quaternion signal_orientation_in_map_system;
  signal_orientation_in_map_system.setRPY(0, signal_pitch_in_map, signal_yaw_in_map);

  tf::Quaternion signal_orientation_in_cam_system = trf * signal_orientation_in_map_system;
  double signal_roll_in_cam;
  double signal_pitch_in_cam;
  double signal_yaw_in_cam;
  tf::Matrix3x3(signal_orientation_in_cam_system).getRPY(signal_roll_in_cam,
                                                         signal_pitch_in_cam,
                                                         signal_yaw_in_cam);

  return ConvertRadianToDegree(signal_pitch_in_cam);   // holizontal angle of camera is represented by pitch
}  // double GetSignalAngleInCameraSystem()


void echoSignals2 (ros::Publisher &amp;pub, bool useOpenGLCoord=false)
{
  int countPoint = 0;
  road_wizard::Signals signalsInFrame;

  /* Get signals on the path if vecter_map_server is enabled */
  if (g_use_vector_map_server) {
    vector_map_server::GetSignal service;
    /* Set server's request */
    service.request.pose = g_vector_map_client.pose();
    service.request.waypoints = g_vector_map_client.waypoints();

    /* Get server's response*/
    if (g_ros_client.call(service)) {
      /* Reset signal data container */
      vmap.signals.clear();

      /* Newle insert signal data on the path */
      for (const auto&amp; response: service.response.objects.data) {
        if (response.id == 0)
          continue;

        Signal signal;
        signal.id = response.id;
        signal.vid = response.vid;
        signal.plid = response.plid;
        signal.type = response.type;
        signal.linkid = response.linkid;

        vmap.signals.insert(std::map&lt;int, Signal&gt;::value_type(signal.id, signal));
      }
    }
  }

  for (unsigned int i=1; i&lt;=vmap.signals.size(); i++) {
    Signal signal = vmap.signals[i];
    int pid = vmap.vectors[signal.vid].pid;

    Point3 signalcenter = vmap.getPoint(pid);
    Point3 signalcenterx (signalcenter.x(), signalcenter.y(), signalcenter.z()+SignalLampRadius);

    int u, v;
    if (project2 (signalcenter, u, v, useOpenGLCoord) == true) {
      countPoint++;
      // std::cout &lt;&lt; u &lt;&lt; &quot;, &quot; &lt;&lt; v &lt;&lt; &quot;, &quot; &lt;&lt; std::endl;

      int radius;
      int ux, vx;
      project2 (signalcenterx, ux, vx, useOpenGLCoord);
      radius = (int)distance (ux, vx, u, v);

      road_wizard::ExtractedPosition sign;
      sign.signalId = signal.id;

      sign.u = u + adjust_proj_x; // shift project position by configuration value from runtime manager
      sign.v = v + adjust_proj_y; // shift project position by configuration value from runtime manager

      sign.radius = radius;
      sign.x = signalcenter.x(), sign.y = signalcenter.y(), sign.z = signalcenter.z();
      sign.hang = vmap.vectors[signal.vid].hang; // hang is expressed in [0, 360] degree
      sign.type = signal.type, sign.linkId = signal.linkid;
      sign.plId = signal.plid;

      // Get holizontal angle of signal in camera corrdinate system
      double signal_angle = GetSignalAngleInCameraSystem(vmap.vectors[signal.vid].hang + 180.0f,
                                                         vmap.vectors[signal.vid].vang + 180.0f);

      // signal_angle will be zero if signal faces to x-axis
      // Target signal should be face to -50 &lt;= z-axis (= 90 degree) &lt;= +50
      if (isRange(-50, 50, signal_angle - 90)) {
        signalsInFrame.Signals.push_back (sign);
      }
    }
  }

  signalsInFrame.header.stamp = ros::Time::now();
  pub.publish (signalsInFrame);

  // printf (&quot;There are %d out of %u signals in frame\n&quot;, countPoint, static_cast&lt;unsigned int&gt;(vmap.signals.size()));
}


void interrupt (int s)
{
  ros::shutdown();
  exit(1);
}


int main (int argc, char *argv[])
{

  ros::init(argc, argv, &quot;feat_proj&quot;, ros::init_options::NoSigintHandler);
  ros::NodeHandle rosnode;
  ros::NodeHandle private_nh(&quot;~&quot;);
  std::string cameraInfo_topic_name;
  private_nh.param&lt;std::string&gt;(&quot;camera_info_topic&quot;, cameraInfo_topic_name, &quot;/camera/camera_info&quot;);

  /* get camera ID */
  camera_id_str = cameraInfo_topic_name;
  camera_id_str.erase(camera_id_str.find(&quot;/camera/camera_info&quot;));
  if (camera_id_str == &quot;/&quot;) {
    camera_id_str = &quot;camera&quot;;
  }
  
  /* Get Flag wheter vecter_map_server function will be used  */
  private_nh.param&lt;bool&gt;(&quot;use_path_info&quot;, g_use_vector_map_server, false);

  /* load vector map */
  ros::Subscriber sub_point     = rosnode.subscribe(&quot;vector_map_info/point&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_points,
                                                    &amp;vmap);
  ros::Subscriber sub_line      = rosnode.subscribe(&quot;vector_map_info/line&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_lines,
                                                    &amp;vmap);
  ros::Subscriber sub_lane      = rosnode.subscribe(&quot;vector_map_info/lane&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_lanes,
                                                    &amp;vmap);
  ros::Subscriber sub_vector    = rosnode.subscribe(&quot;vector_map_info/vector&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_vectors,
                                                    &amp;vmap);
  ros::Subscriber sub_signal    = rosnode.subscribe(&quot;vector_map_info/signal&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_signals,
                                                    &amp;vmap);
  ros::Subscriber sub_whiteline = rosnode.subscribe(&quot;vector_map_info/white_line&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_whitelines,
                                                    &amp;vmap);
  ros::Subscriber sub_dtlane    = rosnode.subscribe(&quot;vector_map_info/dtlane&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_dtlanes,
                                                    &amp;vmap);

  /* wait until loading all vector map is completed */
  ros::Rate wait_rate(1);
  while(vmap.points.empty() || vmap.lines.empty() || vmap.whitelines.empty() ||
        vmap.lanes.empty() || vmap.dtlanes.empty() || vmap.vectors.empty() || vmap.signals.empty())
    {
      ros::spinOnce();
      wait_rate.sleep();
    }

  vmap.loaded = true;
  std::cout &lt;&lt; &quot;all vector map loaded.&quot; &lt;&lt; std::endl;

  ros::Subscriber cameraInfoSubscriber = rosnode.subscribe (cameraInfo_topic_name, 100, cameraInfoCallback);
  ros::Subscriber adjust_xySubscriber  = rosnode.subscribe(&quot;/config/adjust_xy&quot;, 100, adjust_xyCallback);
  if (g_use_vector_map_server) {
    /* Create subscribers which deliver informations requested by server */
    ros::Subscriber current_pose_subscriber = rosnode.subscribe(&quot;/current_pose&quot;, 1, &amp;VectorMapClient::set_pose, &amp;g_vector_map_client);
    ros::Subscriber waypoint_subscriber     = rosnode.subscribe(&quot;/final_waypoints&quot;, 1, &amp;VectorMapClient::set_waypoints, &amp;g_vector_map_client);

    /* Create ros client to use Server-Client communication */
    g_ros_client = rosnode.serviceClient&lt;vector_map_server::GetSignal&gt;(&quot;vector_map_server/get_signal&quot;);
  }

  ros::Publisher  signalPublisher      = rosnode.advertise &lt;road_wizard::Signals&gt; (&quot;roi_signal&quot;, 100);
  signal (SIGINT, interrupt);

  Rate loop (25);
  while (true) {

    ros::spinOnce();

    try {
      getTransform (orientation, position);
    } catch (tf::TransformException &amp;exc) {
    }

    echoSignals2 (signalPublisher, false);
    loop.sleep();
  }


}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="7b561d154bf1d7ec3a1bd41a6068fabdc0a73a4a" fix_time="0,44">
		<msg>Prepare for merge

* Fix assumed SSD path in CMakeLists.txt
* Change default path of trained model into package-internal directory
* Remove `std::cerr` statements for debug
* Add UI to boot `traffic_light_recognition_ssd.launch` from runtime-manager</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr_ssd/region_tlr_ssd.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr_ssd/region_tlr_ssd.cpp">
				<diff>@@ -95,54 +95,12 @@ void RegionTlrSsdRosNode::RoiSignalCallback(const road_wizard::Signals::ConstPtr
     // Get current state of traffic light from current frame
     LightState current_state = recognizer.RecognizeLightState(roi);
 
-    std::cerr &lt;&lt; &quot;current_state: &quot;;
-    switch(current_state) {
-    case GREEN:
-      std::cerr &lt;&lt; &quot;GREEN&quot;;
-      break;
-    case YELLOW:
-      std::cerr &lt;&lt; &quot;YELLOW&quot;;
-      break;
-    case RED:
-      std::cerr &lt;&lt; &quot;RED&quot;;
-      break;
-    case UNDEFINED:
-      std::cerr &lt;&lt; &quot;UNDEFINED&quot;;
-      break;
-    default:
-      std::cerr &lt;&lt; &quot;なにこれ？&quot;;
-      break;
-    }
-
-    std::cerr &lt;&lt; &quot;(saved: &quot; &lt;&lt; context.lightState &lt;&lt; &quot;)&quot;;
-
     // Determine the final state by referring previous state
     context.lightState = DetermineState(context.lightState, // previous state
                                         current_state,      // current state
                                         &amp;(context.stateJudgeCount)); // counter to record how many times does state recognized
-
-    std::cerr &lt;&lt; &quot;, determined: &quot;;
-    switch(context.lightState) {
-    case GREEN:
-      std::cerr &lt;&lt; &quot;GREEN | &quot;;
-      break;
-    case YELLOW:
-      std::cerr &lt;&lt; &quot;YELLOW | &quot;;
-      break;
-    case RED:
-      std::cerr &lt;&lt; &quot;RED | &quot;;
-      break;
-    case UNDEFINED:
-      std::cerr &lt;&lt; &quot;UNDEFINED | &quot;;
-      break;
-    default:
-      std::cerr &lt;&lt; &quot;なにこれ？ | &quot;;
-      break;
-    }
   }
 
-  std::cerr &lt;&lt; std::endl;
-
   // Publish recognition result as some topic format
   PublishTrafficLight(contexts_);
   PublishString(contexts_);
@@ -213,14 +171,6 @@ LightState RegionTlrSsdRosNode::DetermineState(LightState previous_state,
   // Get a candidate which considering state transition of traffic light
   LightState transition_candidate = kStateTransitionMatrix[previous_state][current_state];
 
-  std::cerr &lt;&lt; &quot; [count:&quot; &lt;&lt; *(state_judge_count) &lt;&lt; &quot;/&quot; &lt;&lt; kChangeStateThreshold
-            &lt;&lt; &quot;, pre:&quot; &lt;&lt; previous_state &lt;&lt; &quot;, cur:&quot; &lt;&lt; current_state &lt;&lt; &quot;, tra:&quot; &lt;&lt; transition_candidate &lt;&lt; &quot;]&quot;;
-
-  // if (transition_candidate == UNDEFINED) {
-  //   // If candidate is UNDEFINED, return previous state tentatively
-  //   return previous_state;
-  // }
-
   // If state change happens more than threshold times, accept that change
   if (*state_judge_count &gt; kChangeStateThreshold) {
     *state_judge_count = 0;
</diff>
				<old_file>#include &quot;region_tlr_ssd.h&quot;

#include &lt;string&gt;

#include &lt;runtime_manager/traffic_light.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;

#include &quot;Context.h&quot;

// ========================================
// Constructor of RegionTlrSsdRosNode class
// ========================================
RegionTlrSsdRosNode::RegionTlrSsdRosNode():
  image_topic_name_(&quot;/image_raw&quot;),
  network_definition_file_name_(&quot;&quot;),
  pretrained_model_file_name_(&quot;&quot;),
  use_gpu_(false),
  gpu_id_(0),
  kAdvertiseInLatch_(true),
  kTrafficLightRed(0),
  kTrafficLightGreen(1),
  kTrafficLightUnknown(2),
  kStringRed(&quot;red signal&quot;),
  kStringGreen(&quot;green signal&quot;),
  kStringUnknown(&quot;&quot;) {

} // RegionTlrSsdRosNode::RegionTlrSsdRosNode()


// ========================================
// Destructor of RegionTlrSsdRosNode class
// ========================================
RegionTlrSsdRosNode::~RegionTlrSsdRosNode() {
} // RegionTlrSsdRosNode::~RegionTlrSsdRosNode()


// =========================
// Start recognition process
// =========================
void RegionTlrSsdRosNode::RunRecognition() {
  // Get execution parameters from ROS parameter server
  GetRosParam();

  // Initialize recognizer
  recognizer.Init(network_definition_file_name_,
                  pretrained_model_file_name_,
                  use_gpu_,
                  gpu_id_);

  // Start subscribing and publishing
  StartSubscribersAndPublishers();
  ros::spin();
} // RegionTlrSsdRosNode::RunRecognition()


// ==================================
// Callback function to acquire image
// ==================================
void RegionTlrSsdRosNode::ImageRawCallback(const sensor_msgs::Image &amp;image) {
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image, sensor_msgs::image_encodings::BGR8);
  frame_ = cv_image-&gt;image.clone();

  // Save header information of this topic
  frame_header_ = image.header;

}

// ==========================================
// Callback function to acquire extracted_pos
// ==========================================
void RegionTlrSsdRosNode::RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos) {
  static ros::Time previous_timestamp;
  // If frame has not been prepared, abort this callback
  if (frame_.empty() ||
      frame_header_.stamp == previous_timestamp) {
    return;
  }

  // Acquire signal posotion on the image
  Context::SetContexts(contexts_, extracted_pos, frame_.rows, frame_.cols);

  // Recognize the color of the traffic light
  for (Context&amp; context: contexts_) {
  // for (unsigned int i = 0; i &lt; contexts_.size(); i++) {
  //   Context&amp; context = contexts_.at(i);
    if (context.topLeft.x &gt; context.botRight.x) {
      continue;
    }

    // extract region of interest from input image
    cv::Mat roi  = frame_(cv::Rect(context.topLeft, context.botRight)).clone();

    // Get current state of traffic light from current frame
    LightState current_state = recognizer.RecognizeLightState(roi);

    std::cerr &lt;&lt; &quot;current_state: &quot;;
    switch(current_state) {
    case GREEN:
      std::cerr &lt;&lt; &quot;GREEN&quot;;
      break;
    case YELLOW:
      std::cerr &lt;&lt; &quot;YELLOW&quot;;
      break;
    case RED:
      std::cerr &lt;&lt; &quot;RED&quot;;
      break;
    case UNDEFINED:
      std::cerr &lt;&lt; &quot;UNDEFINED&quot;;
      break;
    default:
      std::cerr &lt;&lt; &quot;なにこれ？&quot;;
      break;
    }

    std::cerr &lt;&lt; &quot;(saved: &quot; &lt;&lt; context.lightState &lt;&lt; &quot;)&quot;;

    // Determine the final state by referring previous state
    context.lightState = DetermineState(context.lightState, // previous state
                                        current_state,      // current state
                                        &amp;(context.stateJudgeCount)); // counter to record how many times does state recognized

    std::cerr &lt;&lt; &quot;, determined: &quot;;
    switch(context.lightState) {
    case GREEN:
      std::cerr &lt;&lt; &quot;GREEN | &quot;;
      break;
    case YELLOW:
      std::cerr &lt;&lt; &quot;YELLOW | &quot;;
      break;
    case RED:
      std::cerr &lt;&lt; &quot;RED | &quot;;
      break;
    case UNDEFINED:
      std::cerr &lt;&lt; &quot;UNDEFINED | &quot;;
      break;
    default:
      std::cerr &lt;&lt; &quot;なにこれ？ | &quot;;
      break;
    }
  }

  std::cerr &lt;&lt; std::endl;

  // Publish recognition result as some topic format
  PublishTrafficLight(contexts_);
  PublishString(contexts_);
  PublishMarkerArray(contexts_);
  PublishImage(contexts_);

  // Save timestamp of this frame so that same frame has never been process again
  previous_timestamp = frame_header_.stamp;
}

// =======================================
// Get parameter from ROS parameter server
// =======================================
void RegionTlrSsdRosNode::GetRosParam() {
  ros::NodeHandle private_node_handle(&quot;~&quot;);

  private_node_handle.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name_, &quot;/image_raw&quot;);
  private_node_handle.param&lt;std::string&gt;(&quot;network_definition_file&quot;, network_definition_file_name_, &quot;&quot;);
  private_node_handle.param&lt;std::string&gt;(&quot;pretrained_model_file&quot;, pretrained_model_file_name_, &quot;&quot;);
  private_node_handle.param&lt;bool&gt;(&quot;use_gpu&quot;, use_gpu_, false);
  private_node_handle.param&lt;int&gt;(&quot;gpu_id&quot;, gpu_id_, 0);

  // If network-definition-file or pretrained-model-file are not specified,
  // terminate program with error status
  if (network_definition_file_name_.empty()){
    ROS_FATAL(&quot;No Network Definition File was specified. Terminate program... &quot;);
    exit(EXIT_FAILURE);
  }

  if (pretrained_model_file_name_.empty()){
    ROS_FATAL(&quot;No Pretrained Model File was specified. Terminate program... &quot;);
    exit(EXIT_FAILURE);
  }
} // RegionTlrSsdRosNode::ProcessRosParam()


// ============================================================
// Register subscriber and publisher of this node in ROS Master
// ============================================================
void RegionTlrSsdRosNode::StartSubscribersAndPublishers() {
  ros::NodeHandle node_handle;
  
  // Register subscribers
  image_subscriber      = node_handle.subscribe(image_topic_name_,
                                                1,
                                                &amp;RegionTlrSsdRosNode::ImageRawCallback,
                                                this);
  roi_signal_subscriber = node_handle.subscribe(&quot;/roi_signal&quot;,
                                                1,
                                                &amp;RegionTlrSsdRosNode::RoiSignalCallback,
                                                this);

  // Register publishers
  signal_state_publisher        = node_handle.advertise&lt;runtime_manager::traffic_light&gt;(&quot;light_color&quot;, 1);
  signal_state_string_publisher = node_handle.advertise&lt;std_msgs::String&gt;(&quot;/sound_player&quot;, 1);
  marker_publisher              = node_handle.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;tlr_result&quot;, 1, kAdvertiseInLatch_);
  superimpose_image_publisher   = node_handle.advertise&lt;sensor_msgs::Image&gt;(&quot;tlr_superimpose_image&quot;, 1);

} // RegionTlrSsdRosNode::StartSubscribersAndPublishers()


// ===============================================================================
// Determine the final recognition result by comparing previous recognition result
// ===============================================================================
LightState RegionTlrSsdRosNode::DetermineState(LightState previous_state,
                                               LightState current_state,
                                               int* state_judge_count) {
  // Get a candidate which considering state transition of traffic light
  LightState transition_candidate = kStateTransitionMatrix[previous_state][current_state];

  std::cerr &lt;&lt; &quot; [count:&quot; &lt;&lt; *(state_judge_count) &lt;&lt; &quot;/&quot; &lt;&lt; kChangeStateThreshold
            &lt;&lt; &quot;, pre:&quot; &lt;&lt; previous_state &lt;&lt; &quot;, cur:&quot; &lt;&lt; current_state &lt;&lt; &quot;, tra:&quot; &lt;&lt; transition_candidate &lt;&lt; &quot;]&quot;;

  // if (transition_candidate == UNDEFINED) {
  //   // If candidate is UNDEFINED, return previous state tentatively
  //   return previous_state;
  // }

  // If state change happens more than threshold times, accept that change
  if (*state_judge_count &gt; kChangeStateThreshold) {
    *state_judge_count = 0;
    return transition_candidate;
  } else {
    if (transition_candidate != previous_state) {
      (*state_judge_count)++;
    }
    return previous_state;
  }

} // LightState RegionTlrSsdRosNode::DetermineState()


// =================================================================
// Publish recognition result as runtime_manager::traffic_light type
// =================================================================
void RegionTlrSsdRosNode::PublishTrafficLight(std::vector&lt;Context&gt; contexts) {
  runtime_manager::traffic_light topic;
  static int32_t previous_state = kTrafficLightUnknown;
  topic.traffic_light = kTrafficLightUnknown;
  for (const auto ctx: contexts) {
    switch(ctx.lightState) {
    case GREEN:
      topic.traffic_light = kTrafficLightGreen;
      break;
    case YELLOW:
    case RED:
      topic.traffic_light = kTrafficLightRed;
      break;
    case UNDEFINED:
      topic.traffic_light = kTrafficLightUnknown;
      break;
    }

    // Publish the first state in contexts,
    // which has largest estimated radius of signal.
    // This program assume that the signal which has the largest estimated radius
    // equal the nearest one from camera.
    if (topic.traffic_light != kTrafficLightUnknown) {
      break;
    }
  }

  // If state changes from previous one, publish it
  if (topic.traffic_light != previous_state) {
    signal_state_publisher.publish(topic);
    previous_state = topic.traffic_light;
  }
} // void RegionTlrSsdRosNode::PublishTrafficLight()


// =================================================================
// Publish recognition result as std_msgs::String
// =================================================================
void RegionTlrSsdRosNode::PublishString(std::vector&lt;Context&gt; contexts) {
  std_msgs::String topic;
  static std::string previous_state = kStringUnknown;
  topic.data = kStringUnknown;
  for (const auto ctx: contexts) {
    switch(ctx.lightState) {
    case GREEN:
      topic.data = kStringGreen;
      break;
    case YELLOW:
    case RED:
      topic.data = kStringRed;
      break;
    case UNDEFINED:
      topic.data = kStringUnknown;
      break;
    }

    // Publish the first state in contexts,
    // which has largest estimated radius of signal.
    // This program assume that the signal which has the largest estimated radius
    // equal the nearest one from camera.
    if (topic.data != kStringUnknown) {
      break;
    }
  }

  // If state changes from previous one, publish it
  if (topic.data != previous_state) {
    signal_state_string_publisher.publish(topic);
    previous_state = topic.data;
  }
} // void RegionTlrSsdRosNode::PublishString()


// =================================================================
// Publish recognition result as visualization_msgs::MarkerArray
// =================================================================
void RegionTlrSsdRosNode::PublishMarkerArray(std::vector&lt;Context&gt; contexts) {
  // Define color constants
  std_msgs::ColorRGBA color_black;
  color_black.r = 0.0f;
  color_black.g = 0.0f;
  color_black.b = 0.0f;
  color_black.a = 1.0f;

  std_msgs::ColorRGBA color_red;
  color_red.r = 1.0f;
  color_red.g = 0.0f;
  color_red.b = 0.0f;
  color_red.a = 1.0f;

  std_msgs::ColorRGBA color_yellow;
  color_yellow.r = 1.0f;
  color_yellow.g = 1.0f;
  color_yellow.b = 0.0f;
  color_yellow.a = 1.0f;

  std_msgs::ColorRGBA color_green;
  color_green.r = 0.0f;
  color_green.g = 1.0f;
  color_green.b = 0.0f;
  color_green.a = 1.0f;

  // publish all result as ROS MarkerArray
  for (const auto ctx: contexts) {
    visualization_msgs::MarkerArray signal_set;
    visualization_msgs::Marker red_light, yellow_light, green_light;

    // Set the frame ID
    red_light.header.frame_id    = &quot;map&quot;;
    yellow_light.header.frame_id = &quot;map&quot;;
    green_light.header.frame_id  = &quot;map&quot;;

    // Set the namespace and ID for this markers
    red_light.ns    = &quot;tlr_result_red&quot;;
    red_light.id    = ctx.signalID;

    yellow_light.ns = &quot;tlr_result_yellow&quot;;
    yellow_light.id = ctx.signalID;

    green_light.ns  = &quot;tlr_result_green&quot;;
    green_light.id  = ctx.signalID;

    // Set the markers type
    red_light.type    = visualization_msgs::Marker::SPHERE;
    yellow_light.type = visualization_msgs::Marker::SPHERE;
    green_light.type  = visualization_msgs::Marker::SPHERE;

    // Set the pose of the markers
    red_light.pose.position.x = ctx.redCenter3d.x;
    red_light.pose.position.y = ctx.redCenter3d.y;
    red_light.pose.position.z = ctx.redCenter3d.z;
    red_light.pose.orientation.x = 0.0;
    red_light.pose.orientation.y = 0.0;
    red_light.pose.orientation.z = 0.0;
    red_light.pose.orientation.w = 0.0;

    yellow_light.pose.position.x = ctx.yellowCenter3d.x;
    yellow_light.pose.position.y = ctx.yellowCenter3d.y;
    yellow_light.pose.position.z = ctx.yellowCenter3d.z;
    yellow_light.pose.orientation.x = 0.0;
    yellow_light.pose.orientation.y = 0.0;
    yellow_light.pose.orientation.z = 0.0;
    yellow_light.pose.orientation.w = 0.0;

    green_light.pose.position.x = ctx.greenCenter3d.x;
    green_light.pose.position.y = ctx.greenCenter3d.y;
    green_light.pose.position.z = ctx.greenCenter3d.z;
    green_light.pose.orientation.x = 0.0;
    green_light.pose.orientation.y = 0.0;
    green_light.pose.orientation.z = 0.0;
    green_light.pose.orientation.w = 0.0;

    // Set the scale of the markers. We assume lamp radius is 30cm in real world
    red_light.scale.x = 0.3;
    red_light.scale.y = 0.3;
    red_light.scale.z = 0.3;

    yellow_light.scale.x = 0.3;
    yellow_light.scale.y = 0.3;
    yellow_light.scale.z = 0.3;

    green_light.scale.x = 0.3;
    green_light.scale.y = 0.3;
    green_light.scale.z = 0.3;

    // Set the color for each marker
    switch(ctx.lightState) {
    case GREEN:
      red_light.color = color_black;
      yellow_light.color = color_black;
      green_light.color = color_green;
      break;
    case YELLOW:
      red_light.color = color_black;
      yellow_light.color = color_yellow;
      green_light.color = color_black;
      break;
    case RED:
      red_light.color = color_red;
      yellow_light.color = color_black;
      green_light.color = color_black;
      break;
    case UNDEFINED:
      red_light.color = color_black;
      yellow_light.color = color_black;
      green_light.color = color_black;
      break;
    }

    red_light.lifetime = ros::Duration(0.1);
    yellow_light.lifetime = ros::Duration(0.1);
    green_light.lifetime = ros::Duration(0.1);

    // Pack each light marker into one
    signal_set.markers.push_back(red_light);
    signal_set.markers.push_back(yellow_light);
    signal_set.markers.push_back(green_light);

    // Publish
    marker_publisher.publish(signal_set);
  }

} // void RegionTlrSsdRosNode::PublishMarkerArray()


// ================================================================
// Publish superimpose and recognition result as sensor_msgs::Image
// ================================================================
void RegionTlrSsdRosNode::PublishImage(std::vector&lt;Context&gt; contexts) {
  // Copy the frame image for output
  cv::Mat result_image = frame_.clone();

  // Define information for written label
  std::string  label;
  const int    kFontFace      = cv::FONT_HERSHEY_COMPLEX_SMALL;
  const double kFontScale     = 1.0;
  int          font_baseline  = 0;
  CvScalar     label_color;

  for (const auto ctx: contexts_) {
    // Draw superimpose result on image
    circle(result_image, ctx.redCenter, ctx.lampRadius, CV_RGB(255, 0, 0), 1, 0);
    circle(result_image, ctx.yellowCenter, ctx.lampRadius, CV_RGB(255, 255, 0), 1, 0);
    circle(result_image, ctx.greenCenter, ctx.lampRadius, CV_RGB(0, 255, 0), 1, 0);

    // Draw recognition result on image
    switch(ctx.lightState) {
    case GREEN:
      label = &quot;GREEN&quot;;
      label_color = CV_RGB(0, 255, 0);
      break;
    case YELLOW:
      label = &quot;YELLOW&quot;;
      label_color = CV_RGB(255, 255, 0);
      break;
    case RED:
      label = &quot;RED&quot;;
      label_color = CV_RGB(255, 0, 0);
      break;
    case UNDEFINED:
      label = &quot;UNKNOWN&quot;;
      label_color = CV_RGB(0, 0, 0);
    }

    cv::Point label_origin = cv::Point(ctx.topLeft.x, ctx.botRight.y + font_baseline);

    cv::putText(result_image, label, label_origin, kFontFace, kFontScale, label_color);
  }

  // Publish superimpose result image
  cv_bridge::CvImage converter;
  converter.header = frame_header_;
  converter.encoding = sensor_msgs::image_encodings::BGR8;
  converter.image = result_image;
  superimpose_image_publisher.publish(converter.toImageMsg());

} // void RegionTlrSsdRosNode::PublishImage()

// ========================
// Entry point of this node
// ========================
int main (int argc, char *argv[]) {
  // Initialize ros node
  ros::init(argc, argv, &quot;region_tlr_ssd&quot;);

  // Create RegionTlrRosNode class object and do initialization
  RegionTlrSsdRosNode region_tlr_ssd_ros_node;

  // Start recognition process
  region_tlr_ssd_ros_node.RunRecognition();

  return 0;
} // main()
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="22ba82fa89521ef3097e5d2f35e32f744ac9f01d" fix_time="4,79434">
		<msg>Fix for latest specification</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/feat_proj/feat_proj.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/feat_proj/feat_proj.cpp">
				<diff>@@ -24,7 +24,7 @@
 #include &lt;runtime_manager/adjust_xy.h&gt;
 #include &lt;vector_map/vector_map.h&gt;
 #include &lt;vector_map_server/GetSignal.h&gt;
-#include &lt;waypoint_follower/lane.h&gt;
+#include &lt;waypoint_follower_msgs/lane.h&gt;
 
 static std::string camera_id_str;
 
@@ -64,7 +64,7 @@ namespace
   {
   private:
     geometry_msgs::PoseStamped pose_;
-    waypoint_follower::lane waypoints_;
+    waypoint_follower_msgs::lane waypoints_;
 
   public:
     VectorMapClient()
@@ -78,7 +78,7 @@ namespace
       return pose_;
     }
 
-    waypoint_follower::lane waypoints() const
+    waypoint_follower_msgs::lane waypoints() const
     {
       return waypoints_;
     }
@@ -88,7 +88,7 @@ namespace
       pose_ = pose;
     }
 
-    void set_waypoints(const waypoint_follower::lane&amp; waypoints)
+    void set_waypoints(const waypoint_follower_msgs::lane&amp; waypoints)
     {
       waypoints_ = waypoints;
     }
</diff>
				<old_file>/*
 * signals.cpp
 *
 *  Created on: Apr 9, 2015
 *      Author: sujiwo
 */


#include &lt;iostream&gt;
#include &lt;ros/ros.h&gt;
#include &quot;Rate.h&quot;
#include &quot;vector_map.h&quot;
#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;sensor_msgs/CameraInfo.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/Pose.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;signal.h&gt;
#include &lt;cstdio&gt;
#include &quot;Math.h&quot;
#include &lt;Eigen/Eigen&gt;
#include &quot;road_wizard/Signals.h&quot;
#include &lt;runtime_manager/adjust_xy.h&gt;
#include &lt;vector_map/vector_map.h&gt;
#include &lt;vector_map_server/GetSignal.h&gt;
#include &lt;waypoint_follower/lane.h&gt;

static std::string camera_id_str;

static constexpr uint32_t SUBSCRIBE_QUEUE_SIZE = 1000;

static int adjust_proj_x = 0;
static int adjust_proj_y = 0;

typedef struct {
  double thiX;
  double thiY;
  double thiZ;
} Angle;

static VectorMap vmap;
static Angle cameraOrientation; // camera orientation = car's orientation

static Eigen::Vector3f position;
static Eigen::Quaternionf orientation;
static  float fx,
  fy,
  imageWidth,
  imageHeight,
  cx,
  cy;
static tf::StampedTransform trf;

static bool g_use_vector_map_server; // Switch flag whether vecter-map-server function will be used
static ros::ServiceClient g_ros_client;

#define SignalLampRadius 0.3

/* Define utility class to use vector map server */
namespace
{
  class VectorMapClient
  {
  private:
    geometry_msgs::PoseStamped pose_;
    waypoint_follower::lane waypoints_;

  public:
    VectorMapClient()
    {}

    ~VectorMapClient()
    {}

    geometry_msgs::PoseStamped pose() const
    {
      return pose_;
    }

    waypoint_follower::lane waypoints() const
    {
      return waypoints_;
    }

    void set_pose(const geometry_msgs::PoseStamped&amp; pose)
    {
      pose_ = pose;
    }

    void set_waypoints(const waypoint_follower::lane&amp; waypoints)
    {
      waypoints_ = waypoints;
    }
  }; // Class VectorMapClient
} // namespace
static VectorMapClient g_vector_map_client;


/* Callback function to shift projection result */
void adjust_xyCallback (const runtime_manager::adjust_xy::ConstPtr&amp; config_msg)
{
  adjust_proj_x = config_msg-&gt;x;
  adjust_proj_y = config_msg-&gt;y;
}

void cameraInfoCallback (const sensor_msgs::CameraInfo::ConstPtr camInfoMsg)
{
  fx = static_cast&lt;float&gt;(camInfoMsg-&gt;P[0]);
  fy = static_cast&lt;float&gt;(camInfoMsg-&gt;P[5]);
  imageWidth = camInfoMsg-&gt;width;
  imageHeight = camInfoMsg-&gt;height;
  cx = static_cast&lt;float&gt;(camInfoMsg-&gt;P[2]);
  cy = static_cast&lt;float&gt;(camInfoMsg-&gt;P[6]);
}


/* convert degree value into 0 to 360 range */
static double setDegree0to360(double val)
{
  if (val &lt; 0.0f) {
    return (val + 360.0f);
  }
  else if (360.0f &lt; val) {
    return (val - 360.0f);
  }

  return val;
}


static void get_cameraRollPitchYaw(double* roll,
                                   double* pitch,
                                   double* yaw)
{
  geometry_msgs::Pose cameraPose;
  cameraPose.position.x    = (double)(position.x());
  cameraPose.position.y    = (double)(position.y());
  cameraPose.position.z    = (double)(position.z());
  cameraPose.orientation.x = (double)(orientation.x());
  cameraPose.orientation.y = (double)(orientation.y());
  cameraPose.orientation.z = (double)(orientation.z());
  cameraPose.orientation.w = (double)(orientation.w());

  tf::Quaternion quat;

  tf::quaternionMsgToTF(cameraPose.orientation, quat);
  tf::Matrix3x3(quat).getRPY(*roll, *pitch, *yaw);

  /* convert from radian to degree */
  *roll  = setDegree0to360(*roll  * 180.0f / M_PI);
  *pitch = setDegree0to360(*pitch * 180.0f / M_PI);
  *yaw   = setDegree0to360(*yaw   * 180.0f / M_PI);
}


/*
  check if lower &lt; val &lt; upper
  This function also considers circulation
*/
static bool isRange(const double lower, const double upper, const double val)
{
  if (lower &lt;= upper) {
    if (lower &lt; val &amp;&amp; val &lt; upper) {
      return true;
    }
  }
  else {
    if (val &lt; upper || lower &lt; val) {
      return true;
    }
  }

  return false;
}


void getTransform (Eigen::Quaternionf &amp;ori, Point3 &amp;pos)
{
  static tf::TransformListener listener;

  // target_frame    source_frame
  ros::Time now = ros::Time();
  listener.waitForTransform (camera_id_str, &quot;map&quot;, now, ros::Duration(10.0));
  listener.lookupTransform (camera_id_str, &quot;map&quot;, now, trf);

  tf::Vector3 &amp;p = trf.getOrigin();
  tf::Quaternion o = trf.getRotation();
  pos.x()=p.x(); pos.y()=p.y(); pos.z()=p.z();
  ori.w()=o.w(); ori.x()=o.x(); ori.y()=o.y(); ori.z()=o.z();
}


Point3 transform (const Point3 &amp;psrc, tf::StampedTransform &amp;tfsource)
{
  tf::Vector3 pt3 (psrc.x(), psrc.y(), psrc.z());
  tf::Vector3 pt3s = tfsource * pt3;
  return Point3 (pt3s.x(), pt3s.y(), pt3s.z());
}


/*
 * Project a point from world coordinate to image plane
 */
bool project2 (const Point3 &amp;pt, int &amp;u, int &amp;v, bool useOpenGLCoord=false)
{
  float nearPlane = 1.0;
  float farPlane = 200.0;
  Point3 _pt = transform (pt, trf);
  float _u = _pt.x()*fx/_pt.z() + cx;
  float _v = _pt.y()*fy/_pt.z() + cy;

  u = static_cast&lt;int&gt;(_u);
  v = static_cast&lt;int&gt;(_v);
  if ( u &lt; 0 || imageWidth &lt; u || v &lt; 0 || imageHeight &lt; v || _pt.z() &lt; nearPlane || farPlane &lt; _pt.z() ) {
    u = -1, v = -1;
    return false;
  }

  if (useOpenGLCoord) {
    v = imageHeight - v;
  }

  return true;
}

double ConvertDegreeToRadian(double degree)
{
  return degree * M_PI / 180.0f;
}


double ConvertRadianToDegree(double radian)
{
  return radian * 180.0f / M_PI;
}


double GetSignalAngleInCameraSystem(double hang, double vang)
{
  // Fit the vector map format into ROS style
  double signal_pitch_in_map = ConvertDegreeToRadian(vang - 90);
  double signal_yaw_in_map   = ConvertDegreeToRadian(-hang + 90);

  tf::Quaternion signal_orientation_in_map_system;
  signal_orientation_in_map_system.setRPY(0, signal_pitch_in_map, signal_yaw_in_map);

  tf::Quaternion signal_orientation_in_cam_system = trf * signal_orientation_in_map_system;
  double signal_roll_in_cam;
  double signal_pitch_in_cam;
  double signal_yaw_in_cam;
  tf::Matrix3x3(signal_orientation_in_cam_system).getRPY(signal_roll_in_cam,
                                                         signal_pitch_in_cam,
                                                         signal_yaw_in_cam);

  return ConvertRadianToDegree(signal_pitch_in_cam);   // holizontal angle of camera is represented by pitch
}  // double GetSignalAngleInCameraSystem()


void echoSignals2 (ros::Publisher &amp;pub, bool useOpenGLCoord=false)
{
  int countPoint = 0;
  road_wizard::Signals signalsInFrame;

  /* Get signals on the path if vecter_map_server is enabled */
  if (g_use_vector_map_server) {
    vector_map_server::GetSignal service;
    /* Set server's request */
    service.request.pose = g_vector_map_client.pose();
    service.request.waypoints = g_vector_map_client.waypoints();

    /* Get server's response*/
    if (g_ros_client.call(service)) {
      /* Reset signal data container */
      vmap.signals.clear();

      /* Newle insert signal data on the path */
      for (const auto&amp; response: service.response.objects.data) {
        if (response.id == 0)
          continue;

        Signal signal;
        signal.id = response.id;
        signal.vid = response.vid;
        signal.plid = response.plid;
        signal.type = response.type;
        signal.linkid = response.linkid;

        vmap.signals.insert(std::map&lt;int, Signal&gt;::value_type(signal.id, signal));
      }
    }
  }

  for (unsigned int i=1; i&lt;=vmap.signals.size(); i++) {
    Signal signal = vmap.signals[i];
    int pid = vmap.vectors[signal.vid].pid;

    Point3 signalcenter = vmap.getPoint(pid);
    Point3 signalcenterx (signalcenter.x(), signalcenter.y(), signalcenter.z()+SignalLampRadius);

    int u, v;
    if (project2 (signalcenter, u, v, useOpenGLCoord) == true) {
      countPoint++;
      // std::cout &lt;&lt; u &lt;&lt; &quot;, &quot; &lt;&lt; v &lt;&lt; &quot;, &quot; &lt;&lt; std::endl;

      int radius;
      int ux, vx;
      project2 (signalcenterx, ux, vx, useOpenGLCoord);
      radius = (int)distance (ux, vx, u, v);

      road_wizard::ExtractedPosition sign;
      sign.signalId = signal.id;

      sign.u = u + adjust_proj_x; // shift project position by configuration value from runtime manager
      sign.v = v + adjust_proj_y; // shift project position by configuration value from runtime manager

      sign.radius = radius;
      sign.x = signalcenter.x(), sign.y = signalcenter.y(), sign.z = signalcenter.z();
      sign.hang = vmap.vectors[signal.vid].hang; // hang is expressed in [0, 360] degree
      sign.type = signal.type, sign.linkId = signal.linkid;
      sign.plId = signal.plid;

      // Get holizontal angle of signal in camera corrdinate system
      double signal_angle = GetSignalAngleInCameraSystem(vmap.vectors[signal.vid].hang + 180.0f,
                                                         vmap.vectors[signal.vid].vang + 180.0f);

      // signal_angle will be zero if signal faces to x-axis
      // Target signal should be face to -50 &lt;= z-axis (= 90 degree) &lt;= +50
      if (isRange(-50, 50, signal_angle - 90)) {
        signalsInFrame.Signals.push_back (sign);
      }
    }
  }

  signalsInFrame.header.stamp = ros::Time::now();
  pub.publish (signalsInFrame);

  // printf (&quot;There are %d out of %u signals in frame\n&quot;, countPoint, static_cast&lt;unsigned int&gt;(vmap.signals.size()));
}


void interrupt (int s)
{
  ros::shutdown();
  exit(1);
}


int main (int argc, char *argv[])
{

  ros::init(argc, argv, &quot;feat_proj&quot;, ros::init_options::NoSigintHandler);
  ros::NodeHandle rosnode;
  ros::NodeHandle private_nh(&quot;~&quot;);
  std::string cameraInfo_topic_name;
  private_nh.param&lt;std::string&gt;(&quot;camera_info_topic&quot;, cameraInfo_topic_name, &quot;/camera/camera_info&quot;);

  /* get camera ID */
  camera_id_str = cameraInfo_topic_name;
  camera_id_str.erase(camera_id_str.find(&quot;/camera/camera_info&quot;));
  if (camera_id_str == &quot;/&quot;) {
    camera_id_str = &quot;camera&quot;;
  }
  
  /* Get Flag wheter vecter_map_server function will be used  */
  private_nh.param&lt;bool&gt;(&quot;use_path_info&quot;, g_use_vector_map_server, false);

  /* load vector map */
  ros::Subscriber sub_point     = rosnode.subscribe(&quot;vector_map_info/point&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_points,
                                                    &amp;vmap);
  ros::Subscriber sub_line      = rosnode.subscribe(&quot;vector_map_info/line&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_lines,
                                                    &amp;vmap);
  ros::Subscriber sub_lane      = rosnode.subscribe(&quot;vector_map_info/lane&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_lanes,
                                                    &amp;vmap);
  ros::Subscriber sub_vector    = rosnode.subscribe(&quot;vector_map_info/vector&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_vectors,
                                                    &amp;vmap);
  ros::Subscriber sub_signal    = rosnode.subscribe(&quot;vector_map_info/signal&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_signals,
                                                    &amp;vmap);
  ros::Subscriber sub_whiteline = rosnode.subscribe(&quot;vector_map_info/white_line&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_whitelines,
                                                    &amp;vmap);
  ros::Subscriber sub_dtlane    = rosnode.subscribe(&quot;vector_map_info/dtlane&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_dtlanes,
                                                    &amp;vmap);

  /* wait until loading all vector map is completed */
  ros::Rate wait_rate(1);
  while(vmap.points.empty() || vmap.lines.empty() || vmap.whitelines.empty() ||
        vmap.lanes.empty() || vmap.dtlanes.empty() || vmap.vectors.empty() || vmap.signals.empty())
    {
      ros::spinOnce();
      wait_rate.sleep();
    }

  vmap.loaded = true;
  std::cout &lt;&lt; &quot;all vector map loaded.&quot; &lt;&lt; std::endl;

  ros::Subscriber cameraInfoSubscriber = rosnode.subscribe (cameraInfo_topic_name, 100, cameraInfoCallback);
  ros::Subscriber adjust_xySubscriber  = rosnode.subscribe(&quot;/config/adjust_xy&quot;, 100, adjust_xyCallback);
  ros::Subscriber current_pose_subscriber;
  ros::Subscriber waypoint_subscriber;
  if (g_use_vector_map_server) {
    /* Create subscribers which deliver informations requested by server */
    current_pose_subscriber = rosnode.subscribe(&quot;/current_pose&quot;, 1, &amp;VectorMapClient::set_pose, &amp;g_vector_map_client);
    waypoint_subscriber     = rosnode.subscribe(&quot;/final_waypoints&quot;, 1, &amp;VectorMapClient::set_waypoints, &amp;g_vector_map_client);

    /* Create ros client to use Server-Client communication */
    g_ros_client = rosnode.serviceClient&lt;vector_map_server::GetSignal&gt;(&quot;vector_map_server/get_signal&quot;);
  }

  ros::Publisher  signalPublisher      = rosnode.advertise &lt;road_wizard::Signals&gt; (&quot;roi_signal&quot;, 100);
  signal (SIGINT, interrupt);

  Rate loop (25);
  while (true) {

    ros::spinOnce();

    try {
      getTransform (orientation, position);
    } catch (tf::TransformException &amp;exc) {
    }

    echoSignals2 (signalPublisher, false);
    loop.sleep();
  }


}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="b2015f6d5535fd507f118b909b2795d2e0223fb3" fix_time="62,18138">
		<msg>Localization problem patch
https://github.com/CPFL/Autoware/issues/693</msg>
		<modified_files>
			<file old_path="ros/src/sensing/filters/packages/points_downsampler/include/points_downsampler.h" new_path="ros/src/sensing/filters/packages/points_downsampler/include/points_downsampler.h">
				<diff>@@ -11,19 +11,22 @@ static pcl::PointCloud&lt;pcl::PointXYZI&gt; removePointsByRange(pcl::PointCloud&lt;pcl::
 
   for(pcl::PointCloud&lt;pcl::PointXYZI&gt;::const_iterator iter = scan.begin(); iter != scan.end(); ++iter)
   {
-    pcl::PointXYZI p;
-    p.x = iter-&gt;x;
-    p.y = iter-&gt;y;
-    p.z = iter-&gt;z;
-    p.intensity = iter-&gt;intensity;
+    const pcl::PointXYZI &amp;p = *iter;
+//    p.x = iter-&gt;x;
+//    p.y = iter-&gt;y;
+//    p.z = iter-&gt;z;
+//    p.intensity = iter-&gt;intensity;
     double square_distance = p.x * p.x + p.y * p.y;
 
     if(square_min_range &lt;= square_distance &amp;&amp; square_distance &lt;= square_max_range){
       narrowed_scan.points.push_back(p);
     }
   }
-
+#if 1
   return narrowed_scan;
+#else
+  return scan;    //  This is a only tempolary patch for Localization problem.
+#endif
 }
 
 #endif // POINTS_DOWNSAMPLER_H
</diff>
				<old_file>#ifndef POINTS_DOWNSAMPLER_H
#define POINTS_DOWNSAMPLER_H

static pcl::PointCloud&lt;pcl::PointXYZI&gt; removePointsByRange(pcl::PointCloud&lt;pcl::PointXYZI&gt; scan, double min_range, double max_range)
{
  pcl::PointCloud&lt;pcl::PointXYZI&gt; narrowed_scan;
  narrowed_scan.header = scan.header;

  double square_min_range = min_range * min_range;
  double square_max_range = max_range * max_range;

  for(pcl::PointCloud&lt;pcl::PointXYZI&gt;::const_iterator iter = scan.begin(); iter != scan.end(); ++iter)
  {
    pcl::PointXYZI p;
    p.x = iter-&gt;x;
    p.y = iter-&gt;y;
    p.z = iter-&gt;z;
    p.intensity = iter-&gt;intensity;
    double square_distance = p.x * p.x + p.y * p.y;

    if(square_min_range &lt;= square_distance &amp;&amp; square_distance &lt;= square_max_range){
      narrowed_scan.points.push_back(p);
    }
  }

  return narrowed_scan;
}

#endif // POINTS_DOWNSAMPLER_H
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="92ff7941f87ab89942986e77dd08d3d7828b0f0c" fix_time="36,84179">
		<msg>ndt_mapping ndt_matching, fix typo</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_mapping/ndt_mapping.cpp" new_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_mapping/ndt_mapping.cpp">
				<diff>@@ -515,7 +515,7 @@ static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
 
   if (_use_imu == true &amp;&amp; _use_odom == true)
     imu_odom_calc(current_scan_time);
-  if(_use_imu == true &amp;&amp; _use_odom == true)
+  if (_use_imu == true &amp;&amp; _use_odom == false)
     imu_calc(current_scan_time);
   if (_use_imu == false &amp;&amp; _use_odom == true)
     odom_calc(current_scan_time);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

/*
 Localization and mapping program using Normal Distributions Transform

 Yuki KITSUKAWA
 */

#define OUTPUT  // If you want to output &quot;position_log.txt&quot;, &quot;#define OUTPUT&quot;.

#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;fstream&gt;
#include &lt;string&gt;

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/Bool.h&gt;
#include &lt;std_msgs/Float32.h&gt;
#include &lt;nav_msgs/Odometry.h&gt;
#include &lt;sensor_msgs/Imu.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;velodyne_pointcloud/point_types.h&gt;
#include &lt;velodyne_pointcloud/rawdata.h&gt;

#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_datatypes.h&gt;

#include &lt;pcl/io/io.h&gt;
#include &lt;pcl/io/pcd_io.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;

#ifdef USE_FAST_PCL
#include &lt;fast_pcl/registration/ndt.h&gt;
#include &lt;fast_pcl/filters/voxel_grid.h&gt;
#else
#include &lt;pcl/registration/ndt.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;
#endif

#include &lt;runtime_manager/ConfigNdtMapping.h&gt;
#include &lt;runtime_manager/ConfigNdtMappingOutput.h&gt;

struct pose
{
  double x;
  double y;
  double z;
  double roll;
  double pitch;
  double yaw;
};

// global variables
static pose previous_pose, guess_pose, guess_pose_imu, guess_pose_odom, guess_pose_imu_odom,current_pose, current_pose_imu, current_pose_odom, current_pose_imu_odom, ndt_pose, added_pose, localizer_pose;

static ros::Time current_scan_time;
static ros::Time previous_scan_time;
static ros::Duration scan_duration;

static double diff = 0.0;
static double diff_x = 0.0, diff_y = 0.0, diff_z = 0.0, diff_yaw; // current_pose - previous_pose
static double offset_imu_x, offset_imu_y, offset_imu_z, offset_imu_roll, offset_imu_pitch, offset_imu_yaw;
static double offset_odom_x, offset_odom_y, offset_odom_z, offset_odom_roll, offset_odom_pitch, offset_odom_yaw;
static double offset_imu_odom_x, offset_imu_odom_y, offset_imu_odom_z, offset_imu_odom_roll, offset_imu_odom_pitch, offset_imu_odom_yaw;

static double current_velocity_x = 0.0;
static double current_velocity_y = 0.0;
static double current_velocity_z = 0.0;

static double current_velocity_imu_x = 0.0;
static double current_velocity_imu_y = 0.0;
static double current_velocity_imu_z = 0.0;

static pcl::PointCloud&lt;pcl::PointXYZI&gt; map;

static pcl::NormalDistributionsTransform&lt;pcl::PointXYZI, pcl::PointXYZI&gt; ndt;
// Default values
static int max_iter = 30;            // Maximum iterations
static float ndt_res = 1.0;      // Resolution
static double step_size = 0.1;   // Step size
static double trans_eps = 0.01;  // Transformation epsilon

// Leaf size of VoxelGrid filter.
static double voxel_leaf_size = 2.0;

static ros::Time callback_start, callback_end, t1_start, t1_end, t2_start, t2_end, t3_start, t3_end, t4_start, t4_end,
    t5_start, t5_end;
static ros::Duration d_callback, d1, d2, d3, d4, d5;

static ros::Publisher ndt_map_pub;
static ros::Publisher current_pose_pub;
static ros::Publisher guess_pose_linaer_pub;
static geometry_msgs::PoseStamped current_pose_msg, guess_pose_msg;

static ros::Publisher ndt_stat_pub;
static std_msgs::Bool ndt_stat_msg;

static int initial_scan_loaded = 0;

static Eigen::Matrix4f gnss_transform = Eigen::Matrix4f::Identity();

static double min_scan_range = 5.0;
static double min_add_scan_shift = 1.0;

static double _tf_x, _tf_y, _tf_z, _tf_roll, _tf_pitch, _tf_yaw;
static Eigen::Matrix4f tf_btol, tf_ltob;

static bool isMapUpdate = true;
static bool _use_openmp = false;
static bool _use_imu = false;
static bool _use_odom = false;
static bool _imu_upside_down = false;

static std::string _imu_topic = &quot;/imu_raw&quot;;


static double fitness_score;

static sensor_msgs::Imu imu;
static nav_msgs::Odometry odom;

static void param_callback(const runtime_manager::ConfigNdtMapping::ConstPtr&amp; input)
{

  ndt_res = input-&gt;resolution;
  step_size = input-&gt;step_size;
  trans_eps = input-&gt;trans_epsilon;
  max_iter = input-&gt;max_iterations;
  voxel_leaf_size = input-&gt;leaf_size;
  min_scan_range = input-&gt;min_scan_range;
  min_add_scan_shift = input-&gt;min_add_scan_shift;

  std::cout &lt;&lt; &quot;param_callback&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;ndt_res: &quot; &lt;&lt; ndt_res &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;step_size: &quot; &lt;&lt; step_size &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;trans_epsilon: &quot; &lt;&lt; trans_eps &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;max_iter: &quot; &lt;&lt; max_iter &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;voxel_leaf_size: &quot; &lt;&lt; voxel_leaf_size &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;min_scan_range: &quot; &lt;&lt; min_scan_range &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;min_add_scan_shift: &quot; &lt;&lt; min_add_scan_shift &lt;&lt; std::endl;
}

static void output_callback(const runtime_manager::ConfigNdtMappingOutput::ConstPtr&amp; input)
{
  double filter_res = input-&gt;filter_res;
  std::string filename = input-&gt;filename;
  std::cout &lt;&lt; &quot;output_callback&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;filter_res: &quot; &lt;&lt; filter_res &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;filename: &quot; &lt;&lt; filename &lt;&lt; std::endl;

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(map));
  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr map_filtered(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());
  map_ptr-&gt;header.frame_id = &quot;map&quot;;
  map_filtered-&gt;header.frame_id = &quot;map&quot;;
  sensor_msgs::PointCloud2::Ptr map_msg_ptr(new sensor_msgs::PointCloud2);

  // Apply voxelgrid filter
  if (filter_res == 0.0)
  {
    std::cout &lt;&lt; &quot;Original: &quot; &lt;&lt; map_ptr-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    pcl::toROSMsg(*map_ptr, *map_msg_ptr);
  }
  else
  {
    pcl::VoxelGrid&lt;pcl::PointXYZI&gt; voxel_grid_filter;
    voxel_grid_filter.setLeafSize(filter_res, filter_res, filter_res);
    voxel_grid_filter.setInputCloud(map_ptr);
    voxel_grid_filter.filter(*map_filtered);
    std::cout &lt;&lt; &quot;Original: &quot; &lt;&lt; map_ptr-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Filtered: &quot; &lt;&lt; map_filtered-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    pcl::toROSMsg(*map_filtered, *map_msg_ptr);
  }

  ndt_map_pub.publish(*map_msg_ptr);

  // Writing Point Cloud data to PCD file
  if (filter_res == 0.0)
  {
    pcl::io::savePCDFileASCII(filename, *map_ptr);
    std::cout &lt;&lt; &quot;Saved &quot; &lt;&lt; map_ptr-&gt;points.size() &lt;&lt; &quot; data points to &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
  }
  else
  {
    pcl::io::savePCDFileASCII(filename, *map_filtered);
    std::cout &lt;&lt; &quot;Saved &quot; &lt;&lt; map_filtered-&gt;points.size() &lt;&lt; &quot; data points to &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
  }
}

static void imu_odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu_odom.roll  += diff_imu_roll;
  current_pose_imu_odom.pitch += diff_imu_pitch;
  current_pose_imu_odom.yaw   += diff_imu_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_imu_odom_x += diff_distance*cos(-current_pose_imu_odom.pitch)*cos(current_pose_imu_odom.yaw);
  offset_imu_odom_y += diff_distance*cos(-current_pose_imu_odom.pitch)*sin(current_pose_imu_odom.yaw);
  offset_imu_odom_z += diff_distance*sin(-current_pose_imu_odom.pitch);

  offset_imu_odom_roll  += diff_imu_roll;
  offset_imu_odom_pitch += diff_imu_pitch;
  offset_imu_odom_yaw   += diff_imu_yaw;

  guess_pose_imu_odom.x     = previous_pose.x     + offset_imu_odom_x;
  guess_pose_imu_odom.y     = previous_pose.y     + offset_imu_odom_y;
  guess_pose_imu_odom.z     = previous_pose.z     + offset_imu_odom_z;
  guess_pose_imu_odom.roll  = previous_pose.roll  + offset_imu_odom_roll;
  guess_pose_imu_odom.pitch = previous_pose.pitch + offset_imu_odom_pitch;
  guess_pose_imu_odom.yaw   = previous_pose.yaw   + offset_imu_odom_yaw;
 
  previous_time = current_time;
}


static void odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_odom_roll  = odom.twist.twist.angular.x * diff_time;
  double diff_odom_pitch = odom.twist.twist.angular.y * diff_time;
  double diff_odom_yaw   = odom.twist.twist.angular.z * diff_time;

  current_pose_odom.roll  += diff_odom_roll;
  current_pose_odom.pitch += diff_odom_pitch;
  current_pose_odom.yaw   += diff_odom_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_odom_x += diff_distance*cos(-current_pose_odom.pitch)*cos(current_pose_odom.yaw);
  offset_odom_y += diff_distance*cos(-current_pose_odom.pitch)*sin(current_pose_odom.yaw);
  offset_odom_z += diff_distance*sin(-current_pose_odom.pitch);

  offset_odom_roll  += diff_odom_roll;
  offset_odom_pitch += diff_odom_pitch;
  offset_odom_yaw   += diff_odom_yaw;

  guess_pose_odom.x     = previous_pose.x     + offset_odom_x;
  guess_pose_odom.y     = previous_pose.y     + offset_odom_y;
  guess_pose_odom.z     = previous_pose.z     + offset_odom_z;
  guess_pose_odom.roll  = previous_pose.roll  + offset_odom_roll;
  guess_pose_odom.pitch = previous_pose.pitch + offset_odom_pitch;
  guess_pose_odom.yaw   = previous_pose.yaw   + offset_odom_yaw;
 
  previous_time = current_time;
}

static void imu_calc(ros::Time current_time)
{

  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu.roll += diff_imu_roll;
  current_pose_imu.pitch += diff_imu_pitch;
  current_pose_imu.yaw += diff_imu_yaw;

  double accX1 = imu.linear_acceleration.x;
  double accY1 = std::cos(current_pose_imu.roll) * imu.linear_acceleration.y
                -std::sin(current_pose_imu.roll) * imu.linear_acceleration.z;
  double accZ1 = std::sin(current_pose_imu.roll) * imu.linear_acceleration.y
                +std::cos(current_pose_imu.roll) * imu.linear_acceleration.z;

  double accX2 = std::sin(current_pose_imu.pitch) * accZ1 + std::cos(current_pose_imu.pitch) * accX1;
  double accY2 = accY1;
  double accZ2 = std::cos(current_pose_imu.pitch) * accZ1 - std::sin(current_pose_imu.pitch) * accX1;

  double accX = std::cos(current_pose_imu.yaw) * accX2 - std::sin(current_pose_imu.yaw) * accY2;
  double accY = std::sin(current_pose_imu.yaw) * accX2 + std::cos(current_pose_imu.yaw) * accY2;
  double accZ = accZ2;

  offset_imu_x += current_velocity_imu_x * diff_time + accX * diff_time * diff_time / 2.0;
  offset_imu_y += current_velocity_imu_y * diff_time + accY * diff_time * diff_time / 2.0;
  offset_imu_z += current_velocity_imu_z * diff_time + accZ * diff_time * diff_time / 2.0;

  current_velocity_imu_x += accX * diff_time;
  current_velocity_imu_y += accY * diff_time;
  current_velocity_imu_z += accZ * diff_time;

  offset_imu_roll  += diff_imu_roll;
  offset_imu_pitch += diff_imu_pitch;
  offset_imu_yaw   += diff_imu_yaw;

  guess_pose_imu.x     = previous_pose.x     + offset_imu_x;
  guess_pose_imu.y     = previous_pose.y     + offset_imu_y;
  guess_pose_imu.z     = previous_pose.z     + offset_imu_z;
  guess_pose_imu.roll  = previous_pose.roll  + offset_imu_roll;
  guess_pose_imu.pitch = previous_pose.pitch + offset_imu_pitch;
  guess_pose_imu.yaw   = previous_pose.yaw   + offset_imu_yaw;  

  previous_time = current_time;
}


static double wrapToPm(double a_num, const double a_max)
{
    if (a_num &gt;= a_max)
    {
        a_num -= 2.0 * a_max;
    }
    return a_num;
}

static double wrapToPmPi(double a_angle_rad)
{
    return wrapToPm(a_angle_rad, M_PI);
}

static void odom_callback(const nav_msgs::Odometry::ConstPtr&amp; input)
{
  //std::cout &lt;&lt; __func__ &lt;&lt; std::endl;

  odom = *input;
  odom_calc(input-&gt;header.stamp);
}


static void imuUpsideDown(const sensor_msgs::Imu::Ptr input)
{
  double input_roll, input_pitch, input_yaw;

  tf::Quaternion input_orientation;
  tf::quaternionMsgToTF(input-&gt;orientation, input_orientation);
  tf::Matrix3x3(input_orientation).getRPY(input_roll, input_pitch, input_yaw);

  input-&gt;angular_velocity.x *= -1;
  input-&gt;angular_velocity.y *= -1;
  input-&gt;angular_velocity.z *= -1;

  input-&gt;linear_acceleration.x *= -1;
  input-&gt;linear_acceleration.y *= -1;
  input-&gt;linear_acceleration.z *= -1;

  input_roll  *= -1;
  input_pitch *= -1;
  input_yaw   *= -1;

  input-&gt;orientation = tf::createQuaternionMsgFromRollPitchYaw(input_roll, input_pitch, input_yaw);
}


static void imu_callback(const sensor_msgs::Imu::Ptr&amp; input)
{
  //std::cout &lt;&lt; __func__ &lt;&lt; std::endl;

  if(_imu_upside_down)
    imuUpsideDown(input);

  const ros::Time current_time = input-&gt;header.stamp;
  static ros::Time previous_time = current_time;
  const double diff_time =  (current_time - previous_time).toSec();

  double imu_roll, imu_pitch, imu_yaw;
  tf::Quaternion imu_orientation;
  tf::quaternionMsgToTF(input-&gt;orientation, imu_orientation);
  tf::Matrix3x3(imu_orientation).getRPY(imu_roll, imu_pitch, imu_yaw);

  imu_roll = wrapToPmPi(imu_roll);
  imu_pitch = wrapToPmPi(imu_pitch);
  imu_yaw = wrapToPmPi(imu_yaw);

  static double previous_imu_roll = imu_roll, previous_imu_pitch = imu_pitch, previous_imu_yaw = imu_yaw;
  const double diff_imu_roll  = imu_roll  - previous_imu_roll;

  const double diff_imu_pitch = imu_pitch - previous_imu_pitch;

  double diff_imu_yaw;
  if(fabs(imu_yaw - previous_imu_yaw) &gt; M_PI)
  {
    if(imu_yaw &gt; 0)
      diff_imu_yaw = (imu_yaw - previous_imu_yaw) - M_PI*2;
    else
      diff_imu_yaw = -M_PI*2 - (imu_yaw - previous_imu_yaw);
  }
  else
  diff_imu_yaw = imu_yaw - previous_imu_yaw;

  imu.header = input-&gt;header;
  imu.linear_acceleration.x = input-&gt;linear_acceleration.x;
  //imu.linear_acceleration.y = input-&gt;linear_acceleration.y;
  //imu.linear_acceleration.z = input-&gt;linear_acceleration.z;
  imu.linear_acceleration.y = 0;
  imu.linear_acceleration.z = 0;

  if(diff_time != 0)
  {
    imu.angular_velocity.x = diff_imu_roll  / diff_time;
    imu.angular_velocity.y = diff_imu_pitch / diff_time;
    imu.angular_velocity.z = diff_imu_yaw   / diff_time;
  }
  else
  {
    imu.angular_velocity.x = 0;
    imu.angular_velocity.y = 0;
    imu.angular_velocity.z = 0;
  }

  imu_calc(input-&gt;header.stamp);

  previous_time = current_time;
  previous_imu_roll  = imu_roll;
  previous_imu_pitch = imu_pitch;
  previous_imu_yaw   = imu_yaw;
}


static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  double r;
  pcl::PointXYZI p;
  pcl::PointCloud&lt;pcl::PointXYZI&gt; tmp, scan;
  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());
  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr transformed_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());
  tf::Quaternion q;

  Eigen::Matrix4f t_localizer(Eigen::Matrix4f::Identity());
  Eigen::Matrix4f t_base_link(Eigen::Matrix4f::Identity());
  tf::TransformBroadcaster br;
  tf::Transform transform;

  current_scan_time = input-&gt;header.stamp;

  pcl::fromROSMsg(*input, tmp);

  for (pcl::PointCloud&lt;pcl::PointXYZI&gt;::const_iterator item = tmp.begin(); item != tmp.end(); item++)
  {
    p.x = (double)item-&gt;x;
    p.y = (double)item-&gt;y;
    p.z = (double)item-&gt;z;
    p.intensity = (double)item-&gt;intensity;

    r = sqrt(pow(p.x, 2.0) + pow(p.y, 2.0));
    if (r &gt; min_scan_range)
    {
      scan.push_back(p);
    }
  }

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(scan));

  // Add initial point cloud to velodyne_map
  if (initial_scan_loaded == 0)
  {
    pcl::transformPointCloud(*scan_ptr, *transformed_scan_ptr, tf_btol);
    map += *transformed_scan_ptr;
    initial_scan_loaded = 1;
  }

  // Apply voxelgrid filter
  pcl::VoxelGrid&lt;pcl::PointXYZI&gt; voxel_grid_filter;
  voxel_grid_filter.setLeafSize(voxel_leaf_size, voxel_leaf_size, voxel_leaf_size);
  voxel_grid_filter.setInputCloud(scan_ptr);
  voxel_grid_filter.filter(*filtered_scan_ptr);

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(map));
  
  ndt.setTransformationEpsilon(trans_eps);
  ndt.setStepSize(step_size);
  ndt.setResolution(ndt_res);
  ndt.setMaximumIterations(max_iter);
  ndt.setInputSource(filtered_scan_ptr);

  if (isMapUpdate == true)
  {
    ndt.setInputTarget(map_ptr);
    isMapUpdate = false;
  }

  guess_pose.x = previous_pose.x + diff_x;
  guess_pose.y = previous_pose.y + diff_y;
  guess_pose.z = previous_pose.z + diff_z;
  guess_pose.roll = previous_pose.roll;
  guess_pose.pitch = previous_pose.pitch;
  guess_pose.yaw = previous_pose.yaw + diff_yaw;


  if (_use_imu == true &amp;&amp; _use_odom == true)
    imu_odom_calc(current_scan_time);
  if(_use_imu == true &amp;&amp; _use_odom == true)
    imu_calc(current_scan_time);
  if (_use_imu == false &amp;&amp; _use_odom == true)
    odom_calc(current_scan_time);

  pose guess_pose_for_ndt;
  if(_use_imu == true &amp;&amp; _use_odom == true)
    guess_pose_for_ndt = guess_pose_imu_odom;
  else if(_use_imu == true &amp;&amp; _use_odom == false)
    guess_pose_for_ndt = guess_pose_imu;
  else if(_use_imu == false &amp;&amp; _use_odom == true)
    guess_pose_for_ndt = guess_pose_odom;
  else
    guess_pose_for_ndt = guess_pose;


  Eigen::AngleAxisf init_rotation_x(guess_pose_for_ndt.roll, Eigen::Vector3f::UnitX());
  Eigen::AngleAxisf init_rotation_y(guess_pose_for_ndt.pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf init_rotation_z(guess_pose_for_ndt.yaw, Eigen::Vector3f::UnitZ());

  Eigen::Translation3f init_translation(guess_pose_for_ndt.x, guess_pose_for_ndt.y, guess_pose_for_ndt.z);

  Eigen::Matrix4f init_guess =
      (init_translation * init_rotation_z * init_rotation_y * init_rotation_x).matrix() * tf_btol;

  t3_end = ros::Time::now();
  d3 = t3_end - t3_start;

  t4_start = ros::Time::now();

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZI&gt;);
#ifdef USE_FAST_PCL
  if (_use_openmp == true)
  {
    ndt.omp_align(*output_cloud, init_guess);
    fitness_score = ndt.omp_getFitnessScore();
  }
  else
  {
#endif
    ndt.align(*output_cloud, init_guess);
    fitness_score = ndt.getFitnessScore();
#ifdef USE_FAST_PCL
  }
#endif

  t_localizer = ndt.getFinalTransformation();
  t_base_link = t_localizer * tf_ltob;

  pcl::transformPointCloud(*scan_ptr, *transformed_scan_ptr, t_localizer);

  tf::Matrix3x3 mat_l, mat_b;

  mat_l.setValue(static_cast&lt;double&gt;(t_localizer(0, 0)), static_cast&lt;double&gt;(t_localizer(0, 1)),
                 static_cast&lt;double&gt;(t_localizer(0, 2)), static_cast&lt;double&gt;(t_localizer(1, 0)),
                 static_cast&lt;double&gt;(t_localizer(1, 1)), static_cast&lt;double&gt;(t_localizer(1, 2)),
                 static_cast&lt;double&gt;(t_localizer(2, 0)), static_cast&lt;double&gt;(t_localizer(2, 1)),
                 static_cast&lt;double&gt;(t_localizer(2, 2)));

  mat_b.setValue(static_cast&lt;double&gt;(t_base_link(0, 0)), static_cast&lt;double&gt;(t_base_link(0, 1)),
                 static_cast&lt;double&gt;(t_base_link(0, 2)), static_cast&lt;double&gt;(t_base_link(1, 0)),
                 static_cast&lt;double&gt;(t_base_link(1, 1)), static_cast&lt;double&gt;(t_base_link(1, 2)),
                 static_cast&lt;double&gt;(t_base_link(2, 0)), static_cast&lt;double&gt;(t_base_link(2, 1)),
                 static_cast&lt;double&gt;(t_base_link(2, 2)));

  // Update localizer_pose.
  localizer_pose.x = t_localizer(0, 3);
  localizer_pose.y = t_localizer(1, 3);
  localizer_pose.z = t_localizer(2, 3);
  mat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1);

  // Update ndt_pose.
  ndt_pose.x = t_base_link(0, 3);
  ndt_pose.y = t_base_link(1, 3);
  ndt_pose.z = t_base_link(2, 3);
  mat_b.getRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw, 1);

  current_pose.x = ndt_pose.x;
  current_pose.y = ndt_pose.y;
  current_pose.z = ndt_pose.z;
  current_pose.roll = ndt_pose.roll;
  current_pose.pitch = ndt_pose.pitch;
  current_pose.yaw = ndt_pose.yaw;

  transform.setOrigin(tf::Vector3(current_pose.x, current_pose.y, current_pose.z));
  q.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);
  transform.setRotation(q);

  br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;map&quot;, &quot;base_link&quot;));

  scan_duration = current_scan_time - previous_scan_time;
  double secs = scan_duration.toSec();

  // Calculate the offset (curren_pos - previous_pos)
  diff_x = current_pose.x - previous_pose.x;
  diff_y = current_pose.y - previous_pose.y;
  diff_z = current_pose.z - previous_pose.z;
  diff_yaw = current_pose.yaw - previous_pose.yaw;
  diff = sqrt(diff_x * diff_x + diff_y * diff_y + diff_z * diff_z);

  current_velocity_x = diff_x / secs;
  current_velocity_y = diff_y / secs;
  current_velocity_z = diff_z / secs;

  current_pose_imu.x = current_pose.x;
  current_pose_imu.y = current_pose.y;
  current_pose_imu.z = current_pose.z;
  current_pose_imu.roll = current_pose.roll;
  current_pose_imu.pitch = current_pose.pitch;
  current_pose_imu.yaw = current_pose.yaw;

  current_pose_odom.x = current_pose.x;
  current_pose_odom.y = current_pose.y;
  current_pose_odom.z = current_pose.z;
  current_pose_odom.roll = current_pose.roll;
  current_pose_odom.pitch = current_pose.pitch;
  current_pose_odom.yaw = current_pose.yaw;

  current_pose_imu_odom.x = current_pose.x;
  current_pose_imu_odom.y = current_pose.y;
  current_pose_imu_odom.z = current_pose.z;
  current_pose_imu_odom.roll = current_pose.roll;
  current_pose_imu_odom.pitch = current_pose.pitch;
  current_pose_imu_odom.yaw = current_pose.yaw;

  current_velocity_imu_x = current_velocity_x;
  current_velocity_imu_y = current_velocity_y;
  current_velocity_imu_z = current_velocity_z;

  // Update position and posture. current_pos -&gt; previous_pos
  previous_pose.x = current_pose.x;
  previous_pose.y = current_pose.y;
  previous_pose.z = current_pose.z;
  previous_pose.roll = current_pose.roll;
  previous_pose.pitch = current_pose.pitch;
  previous_pose.yaw = current_pose.yaw;

  previous_scan_time.sec = current_scan_time.sec;
  previous_scan_time.nsec = current_scan_time.nsec;
  

  offset_imu_x = 0.0;
  offset_imu_y = 0.0;
  offset_imu_z = 0.0;
  offset_imu_roll = 0.0;
  offset_imu_pitch = 0.0;
  offset_imu_yaw = 0.0;

  offset_odom_x = 0.0;
  offset_odom_y = 0.0;
  offset_odom_z = 0.0;
  offset_odom_roll = 0.0;
  offset_odom_pitch = 0.0;
  offset_odom_yaw = 0.0;

  offset_imu_odom_x = 0.0;
  offset_imu_odom_y = 0.0;
  offset_imu_odom_z = 0.0;
  offset_imu_odom_roll = 0.0;
  offset_imu_odom_pitch = 0.0;
  offset_imu_odom_yaw = 0.0;
  
  // Calculate the shift between added_pos and current_pos
  double shift = sqrt(pow(current_pose.x - added_pose.x, 2.0) + pow(current_pose.y - added_pose.y, 2.0));
  if (shift &gt;= min_add_scan_shift)
  {
    map += *transformed_scan_ptr;
    added_pose.x = current_pose.x;
    added_pose.y = current_pose.y;
    added_pose.z = current_pose.z;
    added_pose.roll = current_pose.roll;
    added_pose.pitch = current_pose.pitch;
    added_pose.yaw = current_pose.yaw;
    isMapUpdate = true;
  }

  sensor_msgs::PointCloud2::Ptr map_msg_ptr(new sensor_msgs::PointCloud2);
  pcl::toROSMsg(*map_ptr, *map_msg_ptr);
  ndt_map_pub.publish(*map_msg_ptr);

  q.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);
  current_pose_msg.header.frame_id = &quot;map&quot;;
  current_pose_msg.header.stamp = current_scan_time;
  current_pose_msg.pose.position.x = current_pose.x;
  current_pose_msg.pose.position.y = current_pose.y;
  current_pose_msg.pose.position.z = current_pose.z;
  current_pose_msg.pose.orientation.x = q.x();
  current_pose_msg.pose.orientation.y = q.y();
  current_pose_msg.pose.orientation.z = q.z();
  current_pose_msg.pose.orientation.w = q.w();

  current_pose_pub.publish(current_pose_msg);


  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Sequence number: &quot; &lt;&lt; input-&gt;header.seq &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Number of scan points: &quot; &lt;&lt; scan_ptr-&gt;size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Number of filtered scan points: &quot; &lt;&lt; filtered_scan_ptr-&gt;size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;transformed_scan_ptr: &quot; &lt;&lt; transformed_scan_ptr-&gt;points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;map: &quot; &lt;&lt; map.points.size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;NDT has converged: &quot; &lt;&lt; ndt.hasConverged() &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Fitness score: &quot; &lt;&lt; fitness_score &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Number of iteration: &quot; &lt;&lt; ndt.getFinalNumIteration() &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;(x,y,z,roll,pitch,yaw):&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;(&quot; &lt;&lt; current_pose.x &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.y &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.z &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.roll
            &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.pitch &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Transformation Matrix:&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; t_localizer &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;shift: &quot; &lt;&lt; shift &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
}

int main(int argc, char** argv)
{
  previous_pose.x = 0.0;
  previous_pose.y = 0.0;
  previous_pose.z = 0.0;
  previous_pose.roll = 0.0;
  previous_pose.pitch = 0.0;
  previous_pose.yaw = 0.0;

  ndt_pose.x = 0.0;
  ndt_pose.y = 0.0;
  ndt_pose.z = 0.0;
  ndt_pose.roll = 0.0;
  ndt_pose.pitch = 0.0;
  ndt_pose.yaw = 0.0;

  current_pose.x = 0.0;
  current_pose.y = 0.0;
  current_pose.z = 0.0;
  current_pose.roll = 0.0;
  current_pose.pitch = 0.0;
  current_pose.yaw = 0.0;

  current_pose_imu.x = 0.0;
  current_pose_imu.y = 0.0;
  current_pose_imu.z = 0.0;
  current_pose_imu.roll = 0.0;
  current_pose_imu.pitch = 0.0;
  current_pose_imu.yaw = 0.0;

  guess_pose.x = 0.0;
  guess_pose.y = 0.0;
  guess_pose.z = 0.0;
  guess_pose.roll = 0.0;
  guess_pose.pitch = 0.0;
  guess_pose.yaw = 0.0;

  added_pose.x = 0.0;
  added_pose.y = 0.0;
  added_pose.z = 0.0;
  added_pose.roll = 0.0;
  added_pose.pitch = 0.0;
  added_pose.yaw = 0.0;

  diff_x = 0.0;
  diff_y = 0.0;
  diff_z = 0.0;
  diff_yaw = 0.0;

  offset_imu_x = 0.0;
  offset_imu_y = 0.0;
  offset_imu_z = 0.0;
  offset_imu_roll = 0.0;
  offset_imu_pitch = 0.0;
  offset_imu_yaw = 0.0;

  offset_odom_x = 0.0;
  offset_odom_y = 0.0;
  offset_odom_z = 0.0;
  offset_odom_roll = 0.0;
  offset_odom_pitch = 0.0;
  offset_odom_yaw = 0.0;

  offset_imu_odom_x = 0.0;
  offset_imu_odom_y = 0.0;
  offset_imu_odom_z = 0.0;
  offset_imu_odom_roll = 0.0;
  offset_imu_odom_pitch = 0.0;
  offset_imu_odom_yaw = 0.0;

  ros::init(argc, argv, &quot;ndt_mapping&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  // setting parameters
  private_nh.getParam(&quot;use_openmp&quot;, _use_openmp);
  private_nh.getParam(&quot;use_imu&quot;, _use_imu);
  private_nh.getParam(&quot;use_odom&quot;, _use_odom);
  private_nh.getParam(&quot;imu_upside_down&quot;, _imu_upside_down);
  private_nh.getParam(&quot;imu_topic&quot;, _imu_topic);

  std::cout &lt;&lt; &quot;use_openmp: &quot; &lt;&lt; _use_openmp &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_imu: &quot; &lt;&lt; _use_imu &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;imu_upside_down: &quot; &lt;&lt; _imu_upside_down &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_odom: &quot; &lt;&lt; _use_odom &lt;&lt; std::endl;

  std::cout &lt;&lt; &quot;imu_topic: &quot; &lt;&lt; _imu_topic &lt;&lt; std::endl;

  if (nh.getParam(&quot;tf_x&quot;, _tf_x) == false)
  {
    std::cout &lt;&lt; &quot;tf_x is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_y&quot;, _tf_y) == false)
  {
    std::cout &lt;&lt; &quot;tf_y is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_z&quot;, _tf_z) == false)
  {
    std::cout &lt;&lt; &quot;tf_z is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_roll&quot;, _tf_roll) == false)
  {
    std::cout &lt;&lt; &quot;tf_roll is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_pitch&quot;, _tf_pitch) == false)
  {
    std::cout &lt;&lt; &quot;tf_pitch is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_yaw&quot;, _tf_yaw) == false)
  {
    std::cout &lt;&lt; &quot;tf_yaw is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }

  std::cout &lt;&lt; &quot;(tf_x,tf_y,tf_z,tf_roll,tf_pitch,tf_yaw): (&quot; &lt;&lt; _tf_x &lt;&lt; &quot;, &quot; &lt;&lt; _tf_y &lt;&lt; &quot;, &quot; &lt;&lt; _tf_z &lt;&lt; &quot;, &quot;
            &lt;&lt; _tf_roll &lt;&lt; &quot;, &quot; &lt;&lt; _tf_pitch &lt;&lt; &quot;, &quot; &lt;&lt; _tf_yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;

  Eigen::Translation3f tl_btol(_tf_x, _tf_y, _tf_z);                 // tl: translation
  Eigen::AngleAxisf rot_x_btol(_tf_roll, Eigen::Vector3f::UnitX());  // rot: rotation
  Eigen::AngleAxisf rot_y_btol(_tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_btol(_tf_yaw, Eigen::Vector3f::UnitZ());
  tf_btol = (tl_btol * rot_z_btol * rot_y_btol * rot_x_btol).matrix();

  Eigen::Translation3f tl_ltob((-1.0) * _tf_x, (-1.0) * _tf_y, (-1.0) * _tf_z);  // tl: translation
  Eigen::AngleAxisf rot_x_ltob((-1.0) * _tf_roll, Eigen::Vector3f::UnitX());     // rot: rotation
  Eigen::AngleAxisf rot_y_ltob((-1.0) * _tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_ltob((-1.0) * _tf_yaw, Eigen::Vector3f::UnitZ());
  tf_ltob = (tl_ltob * rot_z_ltob * rot_y_ltob * rot_x_ltob).matrix();

  map.header.frame_id = &quot;map&quot;;

  ndt_map_pub = nh.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/ndt_map&quot;, 1000);
  current_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/current_pose&quot;, 1000);

  ros::Subscriber param_sub = nh.subscribe(&quot;config/ndt_mapping&quot;, 10, param_callback);
  ros::Subscriber output_sub = nh.subscribe(&quot;config/ndt_mapping_output&quot;, 10, output_callback);
  ros::Subscriber points_sub = nh.subscribe(&quot;points_raw&quot;, 100000, points_callback);
  ros::Subscriber odom_sub = nh.subscribe(&quot;/odom_pose&quot;, 100000, odom_callback);
  ros::Subscriber imu_sub = nh.subscribe(_imu_topic, 100000, imu_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_matching/ndt_matching.cpp" new_path="ros/src/computing/perception/localization/packages/ndt_localizer/nodes/ndt_matching/ndt_matching.cpp">
				<diff>@@ -759,7 +759,7 @@ static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
 
     if (_use_imu == true &amp;&amp; _use_odom == true)
       imu_odom_calc(current_scan_time);
-    if(_use_imu == true &amp;&amp; _use_odom == true)
+    if (_use_imu == true &amp;&amp; _use_odom == false)
       imu_calc(current_scan_time);
     if (_use_imu == false &amp;&amp; _use_odom == true)
       odom_calc(current_scan_time);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

/*
 Localization program using Normal Distributions Transform

 Yuki KITSUKAWA
 */

#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;fstream&gt;
#include &lt;string&gt;
#include &lt;chrono&gt;

#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/Float32.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;std_msgs/Bool.h&gt;
#include &lt;nav_msgs/Odometry.h&gt;
#include &lt;sensor_msgs/Imu.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;velodyne_pointcloud/point_types.h&gt;
#include &lt;velodyne_pointcloud/rawdata.h&gt;

#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/PoseWithCovarianceStamped.h&gt;

#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_broadcaster.h&gt;
#include &lt;tf/transform_datatypes.h&gt;
#include &lt;tf/transform_listener.h&gt;

#include &lt;pcl/io/io.h&gt;
#include &lt;pcl/io/pcd_io.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#ifdef USE_FAST_PCL
#include &lt;fast_pcl/registration/ndt.h&gt;
#else
#include &lt;pcl/registration/ndt.h&gt;
#endif

#include &lt;pcl_ros/point_cloud.h&gt;
#include &lt;pcl_ros/transforms.h&gt;

#include &lt;runtime_manager/ConfigNdt.h&gt;

#include &lt;ndt_localizer/ndt_stat.h&gt;

#define PREDICT_POSE_THRESHOLD 0.5

#define Wa 0.4
#define Wb 0.3
#define Wc 0.3

struct pose
{
  double x;
  double y;
  double z;
  double roll;
  double pitch;
  double yaw;
};

static pose initial_pose, predict_pose, predict_pose_imu, predict_pose_odom, predict_pose_imu_odom, previous_pose, ndt_pose, current_pose, current_pose_imu, current_pose_odom, current_pose_imu_odom, localizer_pose, previous_gnss_pose,
    current_gnss_pose;

static double offset_x, offset_y, offset_z, offset_yaw;  // current_pos - previous_pose
static double offset_imu_x, offset_imu_y, offset_imu_z, offset_imu_roll, offset_imu_pitch, offset_imu_yaw; 
static double offset_odom_x, offset_odom_y, offset_odom_z, offset_odom_roll, offset_odom_pitch, offset_odom_yaw;
static double offset_imu_odom_x, offset_imu_odom_y, offset_imu_odom_z, offset_imu_odom_roll, offset_imu_odom_pitch, offset_imu_odom_yaw;

// Can't load if typed &quot;pcl::PointCloud&lt;pcl::PointXYZRGB&gt; map, add;&quot;
static pcl::PointCloud&lt;pcl::PointXYZ&gt; map, add;

// If the map is loaded, map_loaded will be 1.
static int map_loaded = 0;
static int _use_gnss = 1;
static int init_pos_set = 0;

static pcl::NormalDistributionsTransform&lt;pcl::PointXYZ, pcl::PointXYZ&gt; ndt;
// Default values
static int max_iter = 30;        // Maximum iterations
static float ndt_res = 1.0;      // Resolution
static double step_size = 0.1;   // Step size
static double trans_eps = 0.01;  // Transformation epsilon

static ros::Publisher predict_pose_pub;
static geometry_msgs::PoseStamped predict_pose_msg;

static ros::Publisher predict_pose_imu_pub;
static geometry_msgs::PoseStamped predict_pose_imu_msg;

static ros::Publisher predict_pose_odom_pub;
static geometry_msgs::PoseStamped predict_pose_odom_msg;

static ros::Publisher predict_pose_imu_odom_pub;
static geometry_msgs::PoseStamped predict_pose_imu_odom_msg;

static ros::Publisher ndt_pose_pub;
static geometry_msgs::PoseStamped ndt_pose_msg;

// current_pose is published by vel_pose_mux
/*
static ros::Publisher current_pose_pub;
static geometry_msgs::PoseStamped current_pose_msg;
*/

static ros::Publisher localizer_pose_pub;
static geometry_msgs::PoseStamped localizer_pose_msg;

static ros::Publisher estimate_twist_pub;
static geometry_msgs::TwistStamped estimate_twist_msg;

static ros::Time current_scan_time;
static ros::Time previous_scan_time;
static ros::Duration scan_duration;

static double exe_time = 0.0;
static int iteration = 0;
static double fitness_score = 0.0;
static double trans_probability = 0.0;

static double diff = 0.0;
static double diff_x = 0.0, diff_y = 0.0, diff_z = 0.0, diff_yaw;

static double current_velocity = 0.0, previous_velocity = 0.0, previous_previous_velocity = 0.0;  // [m/s]
static double current_velocity_x = 0.0, previous_velocity_x = 0.0;
static double current_velocity_y = 0.0, previous_velocity_y = 0.0;
static double current_velocity_z = 0.0, previous_velocity_z = 0.0;
// static double current_velocity_yaw = 0.0, previous_velocity_yaw = 0.0;
static double current_velocity_smooth = 0.0;

static double current_velocity_imu_x = 0.0;
static double current_velocity_imu_y = 0.0;
static double current_velocity_imu_z = 0.0;

static double current_accel = 0.0, previous_accel = 0.0;  // [m/s^2]
static double current_accel_x = 0.0;
static double current_accel_y = 0.0;
static double current_accel_z = 0.0;
// static double current_accel_yaw = 0.0;

static double angular_velocity = 0.0;

static int use_predict_pose = 0;

static ros::Publisher estimated_vel_mps_pub, estimated_vel_kmph_pub, estimated_vel_pub;
static std_msgs::Float32 estimated_vel_mps, estimated_vel_kmph, previous_estimated_vel_kmph;

static std::chrono::time_point&lt;std::chrono::system_clock&gt; matching_start, matching_end;

static ros::Publisher time_ndt_matching_pub;
static std_msgs::Float32 time_ndt_matching;

static int _queue_size = 1000;

static ros::Publisher ndt_stat_pub;
static ndt_localizer::ndt_stat ndt_stat_msg;

static double predict_pose_error = 0.0;

static double _tf_x, _tf_y, _tf_z, _tf_roll, _tf_pitch, _tf_yaw;
static Eigen::Matrix4f tf_btol, tf_ltob;

static std::string _localizer = &quot;velodyne&quot;;
static std::string _offset = &quot;linear&quot;;  // linear, zero, quadratic

static ros::Publisher ndt_reliability_pub;
static std_msgs::Float32 ndt_reliability;

static bool _use_openmp = false;
static bool _get_height = false;
static bool _use_local_transform = false;
static bool _use_imu = false;
static bool _use_odom = false;
static bool _imu_upside_down = false;

static std::string _imu_topic = &quot;/imu_raw&quot;;

static std::ofstream ofs;
static std::string filename;

static sensor_msgs::Imu imu;
static nav_msgs::Odometry odom;


// static tf::TransformListener local_transform_listener;
static tf::StampedTransform local_transform;

static void param_callback(const runtime_manager::ConfigNdt::ConstPtr&amp; input)
{
  if (_use_gnss != input-&gt;init_pos_gnss)
  {
    init_pos_set = 0;
  }
  else if (_use_gnss == 0 &amp;&amp;
           (initial_pose.x != input-&gt;x || initial_pose.y != input-&gt;y || initial_pose.z != input-&gt;z ||
            initial_pose.roll != input-&gt;roll || initial_pose.pitch != input-&gt;pitch || initial_pose.yaw != input-&gt;yaw))
  {
    init_pos_set = 0;
  }

  _use_gnss = input-&gt;init_pos_gnss;

  // Setting parameters
  if (input-&gt;resolution != ndt_res)
  {
    ndt_res = input-&gt;resolution;
    ndt.setResolution(ndt_res);
  }
  if (input-&gt;step_size != step_size)
  {
    step_size = input-&gt;step_size;
    ndt.setStepSize(step_size);
  }
  if (input-&gt;trans_epsilon != trans_eps)
  {
    trans_eps = input-&gt;trans_epsilon;
    ndt.setTransformationEpsilon(trans_eps);
  }
  if (input-&gt;max_iterations != max_iter)
  {
    max_iter = input-&gt;max_iterations;
    ndt.setMaximumIterations(max_iter);
  }

  if (_use_gnss == 0 &amp;&amp; init_pos_set == 0)
  {
    initial_pose.x = input-&gt;x;
    initial_pose.y = input-&gt;y;
    initial_pose.z = input-&gt;z;
    initial_pose.roll = input-&gt;roll;
    initial_pose.pitch = input-&gt;pitch;
    initial_pose.yaw = input-&gt;yaw;

    if (_use_local_transform == true)
    {
      tf::Vector3 v(input-&gt;x, input-&gt;y, input-&gt;z);
      tf::Quaternion q;
      q.setRPY(input-&gt;roll, input-&gt;pitch, input-&gt;yaw);
      tf::Transform transform(q, v);
      initial_pose.x = (local_transform.inverse() * transform).getOrigin().getX();
      initial_pose.y = (local_transform.inverse() * transform).getOrigin().getY();
      initial_pose.z = (local_transform.inverse() * transform).getOrigin().getZ();

      tf::Matrix3x3 m(q);
      m.getRPY(initial_pose.roll, initial_pose.pitch, initial_pose.yaw);

      std::cout &lt;&lt; &quot;initial_pose.x: &quot; &lt;&lt; initial_pose.x &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.y: &quot; &lt;&lt; initial_pose.y &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.z: &quot; &lt;&lt; initial_pose.z &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.roll: &quot; &lt;&lt; initial_pose.roll &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.pitch: &quot; &lt;&lt; initial_pose.pitch &lt;&lt; std::endl;
      std::cout &lt;&lt; &quot;initial_pose.yaw: &quot; &lt;&lt; initial_pose.yaw &lt;&lt; std::endl;
    }

    // Setting position and posture for the first time.
    localizer_pose.x = initial_pose.x;
    localizer_pose.y = initial_pose.y;
    localizer_pose.z = initial_pose.z;
    localizer_pose.roll = initial_pose.roll;
    localizer_pose.pitch = initial_pose.pitch;
    localizer_pose.yaw = initial_pose.yaw;

    previous_pose.x = initial_pose.x;
    previous_pose.y = initial_pose.y;
    previous_pose.z = initial_pose.z;
    previous_pose.roll = initial_pose.roll;
    previous_pose.pitch = initial_pose.pitch;
    previous_pose.yaw = initial_pose.yaw;

    current_pose.x = initial_pose.x;
    current_pose.y = initial_pose.y;
    current_pose.z = initial_pose.z;
    current_pose.roll = initial_pose.roll;
    current_pose.pitch = initial_pose.pitch;
    current_pose.yaw = initial_pose.yaw;

    current_velocity = 0;
    current_velocity_x = 0;
    current_velocity_y = 0;
    current_velocity_z = 0;
    angular_velocity = 0;

    current_pose_imu.x = 0;
    current_pose_imu.y = 0;
    current_pose_imu.z = 0;
    current_pose_imu.roll = 0;
    current_pose_imu.pitch = 0;
    current_pose_imu.yaw = 0;

    current_velocity_imu_x = current_velocity_x;
    current_velocity_imu_y = current_velocity_y;
    current_velocity_imu_z = current_velocity_z;
    init_pos_set = 1;
  }
}

static void map_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  if (map_loaded == 0)
  {
    // Convert the data type(from sensor_msgs to pcl).
    pcl::fromROSMsg(*input, map);

    if (_use_local_transform == true)
    {
      tf::TransformListener local_transform_listener;
      try
      {
        ros::Time now = ros::Time(0);
        local_transform_listener.waitForTransform(&quot;/map&quot;, &quot;/world&quot;, now, ros::Duration(10.0));
        local_transform_listener.lookupTransform(&quot;/map&quot;, &quot;world&quot;, now, local_transform);
      }
      catch (tf::TransformException&amp; ex)
      {
        ROS_ERROR(&quot;%s&quot;, ex.what());
      }

      pcl_ros::transformPointCloud(map, map, local_transform.inverse());
    }

    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr map_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(map));
    // Setting point cloud to be aligned to.
    ndt.setInputTarget(map_ptr);

    // Setting NDT parameters to default values
    ndt.setMaximumIterations(max_iter);
    ndt.setResolution(ndt_res);
    ndt.setStepSize(step_size);
    ndt.setTransformationEpsilon(trans_eps);

    map_loaded = 1;
  }
}

static void gnss_callback(const geometry_msgs::PoseStamped::ConstPtr&amp; input)
{
  tf::Quaternion gnss_q(input-&gt;pose.orientation.x, input-&gt;pose.orientation.y, input-&gt;pose.orientation.z,
                        input-&gt;pose.orientation.w);
  tf::Matrix3x3 gnss_m(gnss_q);
  current_gnss_pose.x = input-&gt;pose.position.x;
  current_gnss_pose.y = input-&gt;pose.position.y;
  current_gnss_pose.z = input-&gt;pose.position.z;
  gnss_m.getRPY(current_gnss_pose.roll, current_gnss_pose.pitch, current_gnss_pose.yaw);

  if ((_use_gnss == 1 &amp;&amp; init_pos_set == 0) || fitness_score &gt;= 500.0)
  {
    previous_pose.x = previous_gnss_pose.x;
    previous_pose.y = previous_gnss_pose.y;
    previous_pose.z = previous_gnss_pose.z;
    previous_pose.roll = previous_gnss_pose.roll;
    previous_pose.pitch = previous_gnss_pose.pitch;
    previous_pose.yaw = previous_gnss_pose.yaw;

    current_pose.x = current_gnss_pose.x;
    current_pose.y = current_gnss_pose.y;
    current_pose.z = current_gnss_pose.z;
    current_pose.roll = current_gnss_pose.roll;
    current_pose.pitch = current_gnss_pose.pitch;
    current_pose.yaw = current_gnss_pose.yaw;

    current_pose_imu = current_pose_odom = current_pose_imu_odom = current_pose;

    offset_x = current_pose.x - previous_pose.x;
    offset_y = current_pose.y - previous_pose.y;
    offset_z = current_pose.z - previous_pose.z;
    offset_yaw = current_pose.yaw - previous_pose.yaw;

    init_pos_set = 1;
  }

  previous_gnss_pose.x = current_gnss_pose.x;
  previous_gnss_pose.y = current_gnss_pose.y;
  previous_gnss_pose.z = current_gnss_pose.z;
  previous_gnss_pose.roll = current_gnss_pose.roll;
  previous_gnss_pose.pitch = current_gnss_pose.pitch;
  previous_gnss_pose.yaw = current_gnss_pose.yaw;
}

static void initialpose_callback(const geometry_msgs::PoseWithCovarianceStamped::ConstPtr&amp; input)
{
  tf::TransformListener listener;
  tf::StampedTransform transform;
  try
  {
    ros::Time now = ros::Time(0);
    listener.waitForTransform(&quot;/map&quot;, &quot;/world&quot;, now, ros::Duration(10.0));
    listener.lookupTransform(&quot;/map&quot;, &quot;world&quot;, now, transform);
  }
  catch (tf::TransformException&amp; ex)
  {
    ROS_ERROR(&quot;%s&quot;, ex.what());
  }

  tf::Quaternion q(input-&gt;pose.pose.orientation.x, input-&gt;pose.pose.orientation.y, input-&gt;pose.pose.orientation.z,
                   input-&gt;pose.pose.orientation.w);
  tf::Matrix3x3 m(q);

  if (_use_local_transform == true)
  {
    current_pose.x = input-&gt;pose.pose.position.x;
    current_pose.y = input-&gt;pose.pose.position.y;
    current_pose.z = input-&gt;pose.pose.position.z;
  }
  else
  {
    current_pose.x = input-&gt;pose.pose.position.x + transform.getOrigin().x();
    current_pose.y = input-&gt;pose.pose.position.y + transform.getOrigin().y();
    current_pose.z = input-&gt;pose.pose.position.z + transform.getOrigin().z();
  }
  m.getRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);

  if (_get_height == true &amp;&amp; map_loaded == 1)
  {
    double min_distance = DBL_MAX;
    double nearest_z = current_pose.z;
    for (const auto&amp; p : map)
    {
      double distance = hypot(current_pose.x - p.x, current_pose.y - p.y);
      if (distance &lt; min_distance)
      {
        min_distance = distance;
        nearest_z = p.z;
      }
    }
    current_pose.z = nearest_z;
  }
  
  current_pose_imu = current_pose_odom = current_pose_imu_odom = current_pose;
  previous_pose.x = current_pose.x;
  previous_pose.y = current_pose.y;
  previous_pose.z = current_pose.z;
  previous_pose.roll = current_pose.roll;
  previous_pose.pitch = current_pose.pitch;
  previous_pose.yaw = current_pose.yaw;

  offset_x = 0.0;
  offset_y = 0.0;
  offset_z = 0.0;
  offset_yaw = 0.0;

  offset_imu_x = 0.0;
  offset_imu_y = 0.0;
  offset_imu_z = 0.0;
  offset_imu_roll = 0.0;
  offset_imu_pitch = 0.0;
  offset_imu_yaw = 0.0;

  offset_odom_x = 0.0;
  offset_odom_y = 0.0;
  offset_odom_z = 0.0;
  offset_odom_roll = 0.0;
  offset_odom_pitch = 0.0;
  offset_odom_yaw = 0.0;

  offset_imu_odom_x = 0.0;
  offset_imu_odom_y = 0.0;
  offset_imu_odom_z = 0.0;
  offset_imu_odom_roll = 0.0;
  offset_imu_odom_pitch = 0.0;
  offset_imu_odom_yaw = 0.0;

}

static void imu_odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu_odom.roll  += diff_imu_roll;
  current_pose_imu_odom.pitch += diff_imu_pitch;
  current_pose_imu_odom.yaw   += diff_imu_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_imu_odom_x += diff_distance*cos(-current_pose_imu_odom.pitch)*cos(current_pose_imu_odom.yaw);
  offset_imu_odom_y += diff_distance*cos(-current_pose_imu_odom.pitch)*sin(current_pose_imu_odom.yaw);
  offset_imu_odom_z += diff_distance*sin(-current_pose_imu_odom.pitch);

  offset_imu_odom_roll  += diff_imu_roll;
  offset_imu_odom_pitch += diff_imu_pitch;
  offset_imu_odom_yaw   += diff_imu_yaw;

  predict_pose_imu_odom.x     = previous_pose.x     + offset_imu_odom_x;
  predict_pose_imu_odom.y     = previous_pose.y     + offset_imu_odom_y;
  predict_pose_imu_odom.z     = previous_pose.z     + offset_imu_odom_z;
  predict_pose_imu_odom.roll  = previous_pose.roll  + offset_imu_odom_roll;
  predict_pose_imu_odom.pitch = previous_pose.pitch + offset_imu_odom_pitch;
  predict_pose_imu_odom.yaw   = previous_pose.yaw   + offset_imu_odom_yaw;
 
  previous_time = current_time;
}


static void odom_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_odom_roll  = odom.twist.twist.angular.x * diff_time;
  double diff_odom_pitch = odom.twist.twist.angular.y * diff_time;
  double diff_odom_yaw   = odom.twist.twist.angular.z * diff_time;

  current_pose_odom.roll  += diff_odom_roll;
  current_pose_odom.pitch += diff_odom_pitch;
  current_pose_odom.yaw   += diff_odom_yaw;

  double diff_distance = odom.twist.twist.linear.x * diff_time;
  offset_odom_x += diff_distance*cos(-current_pose_odom.pitch)*cos(current_pose_odom.yaw);
  offset_odom_y += diff_distance*cos(-current_pose_odom.pitch)*sin(current_pose_odom.yaw);
  offset_odom_z += diff_distance*sin(-current_pose_odom.pitch);

  offset_odom_roll  += diff_odom_roll;
  offset_odom_pitch += diff_odom_pitch;
  offset_odom_yaw   += diff_odom_yaw;

  predict_pose_odom.x     = previous_pose.x     + offset_odom_x;
  predict_pose_odom.y     = previous_pose.y     + offset_odom_y;
  predict_pose_odom.z     = previous_pose.z     + offset_odom_z;
  predict_pose_odom.roll  = previous_pose.roll  + offset_odom_roll;
  predict_pose_odom.pitch = previous_pose.pitch + offset_odom_pitch;
  predict_pose_odom.yaw   = previous_pose.yaw   + offset_odom_yaw;
 
  previous_time = current_time;

}

static void imu_calc(ros::Time current_time)
{
  static ros::Time previous_time = current_time;
  double diff_time = (current_time - previous_time).toSec();

  double diff_imu_roll  = imu.angular_velocity.x * diff_time;
  double diff_imu_pitch = imu.angular_velocity.y * diff_time;
  double diff_imu_yaw   = imu.angular_velocity.z * diff_time;

  current_pose_imu.roll += diff_imu_roll;
  current_pose_imu.pitch += diff_imu_pitch;
  current_pose_imu.yaw += diff_imu_yaw;

  double accX1 = imu.linear_acceleration.x;
  double accY1 = std::cos(current_pose_imu.roll) * imu.linear_acceleration.y
                -std::sin(current_pose_imu.roll) * imu.linear_acceleration.z;
  double accZ1 = std::sin(current_pose_imu.roll) * imu.linear_acceleration.y
                +std::cos(current_pose_imu.roll) * imu.linear_acceleration.z;

  double accX2 = std::sin(current_pose_imu.pitch) * accZ1 + std::cos(current_pose_imu.pitch) * accX1;
  double accY2 = accY1;
  double accZ2 = std::cos(current_pose_imu.pitch) * accZ1 - std::sin(current_pose_imu.pitch) * accX1;

  double accX = std::cos(current_pose_imu.yaw) * accX2 - std::sin(current_pose_imu.yaw) * accY2;
  double accY = std::sin(current_pose_imu.yaw) * accX2 + std::cos(current_pose_imu.yaw) * accY2;
  double accZ = accZ2;

  offset_imu_x += current_velocity_imu_x * diff_time + accX * diff_time * diff_time / 2.0;
  offset_imu_y += current_velocity_imu_y * diff_time + accY * diff_time * diff_time / 2.0;
  offset_imu_z += current_velocity_imu_z * diff_time + accZ * diff_time * diff_time / 2.0;

  current_velocity_imu_x += accX * diff_time;
  current_velocity_imu_y += accY * diff_time;
  current_velocity_imu_z += accZ * diff_time;

  offset_imu_roll  += diff_imu_roll;
  offset_imu_pitch += diff_imu_pitch;
  offset_imu_yaw   += diff_imu_yaw;

  predict_pose_imu.x     = previous_pose.x     + offset_imu_x;
  predict_pose_imu.y     = previous_pose.y     + offset_imu_y;
  predict_pose_imu.z     = previous_pose.z     + offset_imu_z;
  predict_pose_imu.roll  = previous_pose.roll  + offset_imu_roll;
  predict_pose_imu.pitch = previous_pose.pitch + offset_imu_pitch;
  predict_pose_imu.yaw   = previous_pose.yaw   + offset_imu_yaw;  

  previous_time = current_time;
}


static const double wrapToPm(double a_num, const double a_max)
{
    if (a_num &gt;= a_max)
    {
        a_num -= 2.0 * a_max;
    }
    return a_num;
}

static const double wrapToPmPi(double a_angle_rad)
{
    return wrapToPm(a_angle_rad, M_PI);
}


static void odom_callback(const nav_msgs::Odometry::ConstPtr&amp; input)
{
  //std::cout &lt;&lt; __func__ &lt;&lt; std::endl;

  odom = *input;
  odom_calc(input-&gt;header.stamp);
}

static void imuUpsideDown(const sensor_msgs::Imu::Ptr input)
{
  double input_roll, input_pitch, input_yaw;

  tf::Quaternion input_orientation;
  tf::quaternionMsgToTF(input-&gt;orientation, input_orientation);
  tf::Matrix3x3(input_orientation).getRPY(input_roll, input_pitch, input_yaw);

  input-&gt;angular_velocity.x *= -1;
  input-&gt;angular_velocity.y *= -1;
  input-&gt;angular_velocity.z *= -1;

  input-&gt;linear_acceleration.x *= -1;
  input-&gt;linear_acceleration.y *= -1;
  input-&gt;linear_acceleration.z *= -1;

  input_roll  *= -1;
  input_pitch *= -1;
  input_yaw   *= -1;

  input-&gt;orientation = tf::createQuaternionMsgFromRollPitchYaw(input_roll, input_pitch, input_yaw);
}

static void imu_callback(const sensor_msgs::Imu::Ptr&amp; input)
{
  //std::cout &lt;&lt; __func__ &lt;&lt; std::endl;

  if(_imu_upside_down)
    imuUpsideDown(input);

  const ros::Time current_time = input-&gt;header.stamp;
  static ros::Time previous_time = current_time;
  const double diff_time =  (current_time - previous_time).toSec();

  double imu_roll, imu_pitch, imu_yaw;
  tf::Quaternion imu_orientation;
  tf::quaternionMsgToTF(input-&gt;orientation, imu_orientation);
  tf::Matrix3x3(imu_orientation).getRPY(imu_roll, imu_pitch, imu_yaw);

  imu_roll = wrapToPmPi(imu_roll);
  imu_pitch = wrapToPmPi(imu_pitch);
  imu_yaw = wrapToPmPi(imu_yaw);

  static double previous_imu_roll = imu_roll, previous_imu_pitch = imu_pitch, previous_imu_yaw = imu_yaw;
  const double diff_imu_roll  = imu_roll  - previous_imu_roll;

  const double diff_imu_pitch = imu_pitch - previous_imu_pitch;

  double diff_imu_yaw;
  if(fabs(imu_yaw - previous_imu_yaw) &gt; M_PI)
  {
    if(imu_yaw &gt; 0)
      diff_imu_yaw = (imu_yaw - previous_imu_yaw) - M_PI*2;
    else
      diff_imu_yaw = -M_PI*2 - (imu_yaw - previous_imu_yaw);
  }
  else
  diff_imu_yaw = imu_yaw - previous_imu_yaw;

  imu.header = input-&gt;header;
  imu.linear_acceleration.x = input-&gt;linear_acceleration.x;
  //imu.linear_acceleration.y = input-&gt;linear_acceleration.y;
  //imu.linear_acceleration.z = input-&gt;linear_acceleration.z;
  imu.linear_acceleration.y = 0;
  imu.linear_acceleration.z = 0;

  if(diff_time != 0)
  {
    imu.angular_velocity.x = diff_imu_roll  / diff_time;
    imu.angular_velocity.y = diff_imu_pitch / diff_time;
    imu.angular_velocity.z = diff_imu_yaw   / diff_time;
  }
  else
  {
    imu.angular_velocity.x = 0;
    imu.angular_velocity.y = 0;
    imu.angular_velocity.z = 0;
  }

  imu_calc(input-&gt;header.stamp);

  previous_time = current_time;
  previous_imu_roll  = imu_roll;
  previous_imu_pitch = imu_pitch;
  previous_imu_yaw   = imu_yaw;
}

static void points_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  if (map_loaded == 1 &amp;&amp; init_pos_set == 1)
  {
    matching_start = std::chrono::system_clock::now();

    static tf::TransformBroadcaster br;
    tf::Transform transform;
    tf::Quaternion predict_q, ndt_q, current_q, localizer_q;

    pcl::PointXYZ p;
    pcl::PointCloud&lt;pcl::PointXYZ&gt; filtered_scan;

    current_scan_time = input-&gt;header.stamp;

    pcl::fromROSMsg(*input, filtered_scan);
    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZ&gt;(filtered_scan));
    int scan_points_num = filtered_scan_ptr-&gt;size();

    Eigen::Matrix4f t(Eigen::Matrix4f::Identity());   // base_link
    Eigen::Matrix4f t2(Eigen::Matrix4f::Identity());  // localizer

    std::chrono::time_point&lt;std::chrono::system_clock&gt; align_start, align_end, getFitnessScore_start,
        getFitnessScore_end;
    static double align_time, getFitnessScore_time = 0.0;

    // Setting point cloud to be aligned.
    ndt.setInputSource(filtered_scan_ptr);

    // Guess the initial gross estimation of the transformation
    predict_pose.x = previous_pose.x + offset_x;
    predict_pose.y = previous_pose.y + offset_y;
    predict_pose.z = previous_pose.z + offset_z;
    predict_pose.roll = previous_pose.roll;
    predict_pose.pitch = previous_pose.pitch;
    predict_pose.yaw = previous_pose.yaw + offset_yaw;


    if (_use_imu == true &amp;&amp; _use_odom == true)
      imu_odom_calc(current_scan_time);
    if(_use_imu == true &amp;&amp; _use_odom == true)
      imu_calc(current_scan_time);
    if (_use_imu == false &amp;&amp; _use_odom == true)
      odom_calc(current_scan_time);
    
    pose predict_pose_for_ndt;
    if (_use_imu == true &amp;&amp; _use_odom == true)
      predict_pose_for_ndt = predict_pose_imu_odom;
    else if (_use_imu == true &amp;&amp; _use_odom == false)
      predict_pose_for_ndt = predict_pose_imu;
    else if (_use_imu == false &amp;&amp; _use_odom == true)
      predict_pose_for_ndt = predict_pose_odom;
    else
      predict_pose_for_ndt = predict_pose;

    Eigen::Translation3f init_translation(predict_pose_for_ndt.x, predict_pose_for_ndt.y, predict_pose_for_ndt.z);
    Eigen::AngleAxisf init_rotation_x(predict_pose_for_ndt.roll, Eigen::Vector3f::UnitX());
    Eigen::AngleAxisf init_rotation_y(predict_pose_for_ndt.pitch, Eigen::Vector3f::UnitY());
    Eigen::AngleAxisf init_rotation_z(predict_pose_for_ndt.yaw, Eigen::Vector3f::UnitZ());
    Eigen::Matrix4f init_guess = (init_translation * init_rotation_z * init_rotation_y * init_rotation_x) * tf_btol;




    pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr output_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
#ifdef USE_FAST_PCL
    if (_use_openmp == true)
    {
      align_start = std::chrono::system_clock::now();
      ndt.omp_align(*output_cloud, init_guess);
      align_end = std::chrono::system_clock::now();
    }
    else
    {
#endif
      align_start = std::chrono::system_clock::now();
      ndt.align(*output_cloud, init_guess);
      align_end = std::chrono::system_clock::now();
#ifdef USE_FAST_PCL
    }
#endif

    align_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(align_end - align_start).count() / 1000.0;


    t = ndt.getFinalTransformation();  // localizer
    t2 = t * tf_ltob;                  // base_link

    iteration = ndt.getFinalNumIteration();
#ifdef USE_FAST_PCL
    if (_use_openmp == true)
    {
      getFitnessScore_start = std::chrono::system_clock::now();
      fitness_score = ndt.omp_getFitnessScore();
      getFitnessScore_end = std::chrono::system_clock::now();
    }
    else
    {
#endif
      getFitnessScore_start = std::chrono::system_clock::now();
      fitness_score = ndt.getFitnessScore();
      getFitnessScore_end = std::chrono::system_clock::now();
#ifdef USE_FAST_PCL
    }
#endif
    getFitnessScore_time =
        std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(getFitnessScore_end - getFitnessScore_start).count() /
        1000.0;


    trans_probability = ndt.getTransformationProbability();

    tf::Matrix3x3 mat_l;  // localizer
    mat_l.setValue(static_cast&lt;double&gt;(t(0, 0)), static_cast&lt;double&gt;(t(0, 1)), static_cast&lt;double&gt;(t(0, 2)),
                   static_cast&lt;double&gt;(t(1, 0)), static_cast&lt;double&gt;(t(1, 1)), static_cast&lt;double&gt;(t(1, 2)),
                   static_cast&lt;double&gt;(t(2, 0)), static_cast&lt;double&gt;(t(2, 1)), static_cast&lt;double&gt;(t(2, 2)));

    // Update localizer_pose
    localizer_pose.x = t(0, 3);
    localizer_pose.y = t(1, 3);
    localizer_pose.z = t(2, 3);
    mat_l.getRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw, 1);

    tf::Matrix3x3 mat_b;  // base_link
    mat_b.setValue(static_cast&lt;double&gt;(t2(0, 0)), static_cast&lt;double&gt;(t2(0, 1)), static_cast&lt;double&gt;(t2(0, 2)),
                   static_cast&lt;double&gt;(t2(1, 0)), static_cast&lt;double&gt;(t2(1, 1)), static_cast&lt;double&gt;(t2(1, 2)),
                   static_cast&lt;double&gt;(t2(2, 0)), static_cast&lt;double&gt;(t2(2, 1)), static_cast&lt;double&gt;(t2(2, 2)));

    // Update ndt_pose
    ndt_pose.x = t2(0, 3);
    ndt_pose.y = t2(1, 3);
    ndt_pose.z = t2(2, 3);
    mat_b.getRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw, 1);

    // Calculate the difference between ndt_pose and predict_pose
    predict_pose_error = sqrt((ndt_pose.x - predict_pose_for_ndt.x) * (ndt_pose.x - predict_pose_for_ndt.x) +
                              (ndt_pose.y - predict_pose_for_ndt.y) * (ndt_pose.y - predict_pose_for_ndt.y) +
                              (ndt_pose.z - predict_pose_for_ndt.z) * (ndt_pose.z - predict_pose_for_ndt.z));

    if (predict_pose_error &lt;= PREDICT_POSE_THRESHOLD)
    {
      use_predict_pose = 0;
    }
    else
    {
      use_predict_pose = 1;
    }
    use_predict_pose = 0;


    if (use_predict_pose == 0)
    {
      current_pose.x = ndt_pose.x;
      current_pose.y = ndt_pose.y;
      current_pose.z = ndt_pose.z;
      current_pose.roll = ndt_pose.roll;
      current_pose.pitch = ndt_pose.pitch;
      current_pose.yaw = ndt_pose.yaw;
    }
    else
    {
      current_pose.x = predict_pose_for_ndt.x;
      current_pose.y = predict_pose_for_ndt.y;
      current_pose.z = predict_pose_for_ndt.z;
      current_pose.roll = predict_pose_for_ndt.roll;
      current_pose.pitch = predict_pose_for_ndt.pitch;
      current_pose.yaw = predict_pose_for_ndt.yaw;
    }


    // Compute the velocity and acceleration
    scan_duration = current_scan_time - previous_scan_time;
    double secs = scan_duration.toSec();
    diff_x = current_pose.x - previous_pose.x;
    diff_y = current_pose.y - previous_pose.y;
    diff_z = current_pose.z - previous_pose.z;
    diff_yaw = current_pose.yaw - previous_pose.yaw;
    diff = sqrt(diff_x * diff_x + diff_y * diff_y + diff_z * diff_z);

    current_velocity = diff / secs;
    current_velocity_x = diff_x / secs;
    current_velocity_y = diff_y / secs;
    current_velocity_z = diff_z / secs;
    angular_velocity = diff_yaw / secs;

    current_pose_imu.x = current_pose.x;
    current_pose_imu.y = current_pose.y;
    current_pose_imu.z = current_pose.z;
    current_pose_imu.roll = current_pose.roll;
    current_pose_imu.pitch = current_pose.pitch;
    current_pose_imu.yaw = current_pose.yaw;

    current_velocity_imu_x = current_velocity_x;
    current_velocity_imu_y = current_velocity_y;
    current_velocity_imu_z = current_velocity_z;


    current_pose_odom.x = current_pose.x;
    current_pose_odom.y = current_pose.y;
    current_pose_odom.z = current_pose.z;
    current_pose_odom.roll = current_pose.roll;
    current_pose_odom.pitch = current_pose.pitch;
    current_pose_odom.yaw = current_pose.yaw;

    current_pose_imu_odom.x = current_pose.x;
    current_pose_imu_odom.y = current_pose.y;
    current_pose_imu_odom.z = current_pose.z;
    current_pose_imu_odom.roll = current_pose.roll;
    current_pose_imu_odom.pitch = current_pose.pitch;
    current_pose_imu_odom.yaw = current_pose.yaw;

    current_velocity_smooth = (current_velocity + previous_velocity + previous_previous_velocity) / 3.0;
    if (current_velocity_smooth &lt; 0.2)
    {
      current_velocity_smooth = 0.0;
    }

    current_accel = (current_velocity - previous_velocity) / secs;
    current_accel_x = (current_velocity_x - previous_velocity_x) / secs;
    current_accel_y = (current_velocity_y - previous_velocity_y) / secs;
    current_accel_z = (current_velocity_z - previous_velocity_z) / secs;

    estimated_vel_mps.data = current_velocity;
    estimated_vel_kmph.data = current_velocity * 3.6;

    estimated_vel_mps_pub.publish(estimated_vel_mps);
    estimated_vel_kmph_pub.publish(estimated_vel_kmph);

    // Set values for publishing pose
    predict_q.setRPY(predict_pose.roll, predict_pose.pitch, predict_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(predict_pose.x, predict_pose.y, predict_pose.z);
      tf::Transform transform(predict_q, v);
      predict_pose_msg.header.frame_id = &quot;/map&quot;;
      predict_pose_msg.header.stamp = current_scan_time;
      predict_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      predict_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      predict_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      predict_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      predict_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      predict_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      predict_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      predict_pose_msg.header.frame_id = &quot;/map&quot;;
      predict_pose_msg.header.stamp = current_scan_time;
      predict_pose_msg.pose.position.x = predict_pose.x;
      predict_pose_msg.pose.position.y = predict_pose.y;
      predict_pose_msg.pose.position.z = predict_pose.z;
      predict_pose_msg.pose.orientation.x = predict_q.x();
      predict_pose_msg.pose.orientation.y = predict_q.y();
      predict_pose_msg.pose.orientation.z = predict_q.z();
      predict_pose_msg.pose.orientation.w = predict_q.w();
    }

    tf::Quaternion predict_q_imu;
    predict_q_imu.setRPY(predict_pose_imu.roll, predict_pose_imu.pitch, predict_pose_imu.yaw);
    predict_pose_imu_msg.header.frame_id = &quot;map&quot;;
    predict_pose_imu_msg.header.stamp = input-&gt;header.stamp;
    predict_pose_imu_msg.pose.position.x = predict_pose_imu.x;
    predict_pose_imu_msg.pose.position.y = predict_pose_imu.y;
    predict_pose_imu_msg.pose.position.z = predict_pose_imu.z;
    predict_pose_imu_msg.pose.orientation.x = predict_q_imu.x();
    predict_pose_imu_msg.pose.orientation.y = predict_q_imu.y();
    predict_pose_imu_msg.pose.orientation.z = predict_q_imu.z();
    predict_pose_imu_msg.pose.orientation.w = predict_q_imu.w();
    predict_pose_imu_pub.publish(predict_pose_imu_msg);

    tf::Quaternion predict_q_odom;
    predict_q_odom.setRPY(predict_pose_odom.roll, predict_pose_odom.pitch, predict_pose_odom.yaw);
    predict_pose_odom_msg.header.frame_id = &quot;map&quot;;
    predict_pose_odom_msg.header.stamp = input-&gt;header.stamp;
    predict_pose_odom_msg.pose.position.x = predict_pose_odom.x;
    predict_pose_odom_msg.pose.position.y = predict_pose_odom.y;
    predict_pose_odom_msg.pose.position.z = predict_pose_odom.z;
    predict_pose_odom_msg.pose.orientation.x = predict_q_odom.x();
    predict_pose_odom_msg.pose.orientation.y = predict_q_odom.y();
    predict_pose_odom_msg.pose.orientation.z = predict_q_odom.z();
    predict_pose_odom_msg.pose.orientation.w = predict_q_odom.w();
    predict_pose_odom_pub.publish(predict_pose_odom_msg);


    tf::Quaternion predict_q_imu_odom;
    predict_q_imu_odom.setRPY(predict_pose_imu_odom.roll, predict_pose_imu_odom.pitch, predict_pose_imu_odom.yaw);
    predict_pose_imu_odom_msg.header.frame_id = &quot;map&quot;;
    predict_pose_imu_odom_msg.header.stamp = input-&gt;header.stamp;
    predict_pose_imu_odom_msg.pose.position.x = predict_pose_imu_odom.x;
    predict_pose_imu_odom_msg.pose.position.y = predict_pose_imu_odom.y;
    predict_pose_imu_odom_msg.pose.position.z = predict_pose_imu_odom.z;
    predict_pose_imu_odom_msg.pose.orientation.x = predict_q_imu_odom.x();
    predict_pose_imu_odom_msg.pose.orientation.y = predict_q_imu_odom.y();
    predict_pose_imu_odom_msg.pose.orientation.z = predict_q_imu_odom.z();
    predict_pose_imu_odom_msg.pose.orientation.w = predict_q_imu_odom.w();
    predict_pose_imu_odom_pub.publish(predict_pose_imu_odom_msg);

    ndt_q.setRPY(ndt_pose.roll, ndt_pose.pitch, ndt_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(ndt_pose.x, ndt_pose.y, ndt_pose.z);
      tf::Transform transform(ndt_q, v);
      ndt_pose_msg.header.frame_id = &quot;/map&quot;;
      ndt_pose_msg.header.stamp = current_scan_time;
      ndt_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      ndt_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      ndt_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      ndt_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      ndt_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      ndt_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      ndt_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      ndt_pose_msg.header.frame_id = &quot;/map&quot;;
      ndt_pose_msg.header.stamp = current_scan_time;
      ndt_pose_msg.pose.position.x = ndt_pose.x;
      ndt_pose_msg.pose.position.y = ndt_pose.y;
      ndt_pose_msg.pose.position.z = ndt_pose.z;
      ndt_pose_msg.pose.orientation.x = ndt_q.x();
      ndt_pose_msg.pose.orientation.y = ndt_q.y();
      ndt_pose_msg.pose.orientation.z = ndt_q.z();
      ndt_pose_msg.pose.orientation.w = ndt_q.w();
    }

    current_q.setRPY(current_pose.roll, current_pose.pitch, current_pose.yaw);
    // current_pose is published by vel_pose_mux
    /*
    current_pose_msg.header.frame_id = &quot;/map&quot;;
    current_pose_msg.header.stamp = current_scan_time;
    current_pose_msg.pose.position.x = current_pose.x;
    current_pose_msg.pose.position.y = current_pose.y;
    current_pose_msg.pose.position.z = current_pose.z;
    current_pose_msg.pose.orientation.x = current_q.x();
    current_pose_msg.pose.orientation.y = current_q.y();
    current_pose_msg.pose.orientation.z = current_q.z();
    current_pose_msg.pose.orientation.w = current_q.w();
    */

    localizer_q.setRPY(localizer_pose.roll, localizer_pose.pitch, localizer_pose.yaw);
    if (_use_local_transform == true)
    {
      tf::Vector3 v(localizer_pose.x, localizer_pose.y, localizer_pose.z);
      tf::Transform transform(localizer_q, v);
      localizer_pose_msg.header.frame_id = &quot;/map&quot;;
      localizer_pose_msg.header.stamp = current_scan_time;
      localizer_pose_msg.pose.position.x = (local_transform * transform).getOrigin().getX();
      localizer_pose_msg.pose.position.y = (local_transform * transform).getOrigin().getY();
      localizer_pose_msg.pose.position.z = (local_transform * transform).getOrigin().getZ();
      localizer_pose_msg.pose.orientation.x = (local_transform * transform).getRotation().x();
      localizer_pose_msg.pose.orientation.y = (local_transform * transform).getRotation().y();
      localizer_pose_msg.pose.orientation.z = (local_transform * transform).getRotation().z();
      localizer_pose_msg.pose.orientation.w = (local_transform * transform).getRotation().w();
    }
    else
    {
      localizer_pose_msg.header.frame_id = &quot;/map&quot;;
      localizer_pose_msg.header.stamp = current_scan_time;
      localizer_pose_msg.pose.position.x = localizer_pose.x;
      localizer_pose_msg.pose.position.y = localizer_pose.y;
      localizer_pose_msg.pose.position.z = localizer_pose.z;
      localizer_pose_msg.pose.orientation.x = localizer_q.x();
      localizer_pose_msg.pose.orientation.y = localizer_q.y();
      localizer_pose_msg.pose.orientation.z = localizer_q.z();
      localizer_pose_msg.pose.orientation.w = localizer_q.w();
    }

    predict_pose_pub.publish(predict_pose_msg);
    ndt_pose_pub.publish(ndt_pose_msg);
    // current_pose is published by vel_pose_mux
    //    current_pose_pub.publish(current_pose_msg);
    localizer_pose_pub.publish(localizer_pose_msg);

    // Send TF &quot;/base_link&quot; to &quot;/map&quot;
    transform.setOrigin(tf::Vector3(current_pose.x, current_pose.y, current_pose.z));
    transform.setRotation(current_q);
    //    br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    if (_use_local_transform == true)
    {
      br.sendTransform(tf::StampedTransform(local_transform * transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    }
    else
    {
      br.sendTransform(tf::StampedTransform(transform, current_scan_time, &quot;/map&quot;, &quot;/base_link&quot;));
    }

    matching_end = std::chrono::system_clock::now();
    exe_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(matching_end - matching_start).count() / 1000.0;
    time_ndt_matching.data = exe_time;
    time_ndt_matching_pub.publish(time_ndt_matching);

    // Set values for /estimate_twist
    estimate_twist_msg.header.stamp = current_scan_time;
    estimate_twist_msg.header.frame_id = &quot;/base_link&quot;;
    estimate_twist_msg.twist.linear.x = current_velocity;
    estimate_twist_msg.twist.linear.y = 0.0;
    estimate_twist_msg.twist.linear.z = 0.0;
    estimate_twist_msg.twist.angular.x = 0.0;
    estimate_twist_msg.twist.angular.y = 0.0;
    estimate_twist_msg.twist.angular.z = angular_velocity;

    estimate_twist_pub.publish(estimate_twist_msg);

    geometry_msgs::Vector3Stamped estimate_vel_msg;
    estimate_vel_msg.header.stamp = current_scan_time;
    estimate_vel_msg.vector.x = current_velocity;
    estimated_vel_pub.publish(estimate_vel_msg);

    // Set values for /ndt_stat
    ndt_stat_msg.header.stamp = current_scan_time;
    ndt_stat_msg.exe_time = time_ndt_matching.data;
    ndt_stat_msg.iteration = iteration;
    ndt_stat_msg.score = fitness_score;
    ndt_stat_msg.velocity = current_velocity;
    ndt_stat_msg.acceleration = current_accel;
    ndt_stat_msg.use_predict_pose = 0;

    ndt_stat_pub.publish(ndt_stat_msg);

    /* Compute NDT_Reliability */
    ndt_reliability.data = Wa * (exe_time / 100.0) * 100.0 + Wb * (iteration / 10.0) * 100.0 +
                           Wc * ((2.0 - trans_probability) / 2.0) * 100.0;
    ndt_reliability_pub.publish(ndt_reliability);


    // Write log
    if (!ofs)
    {
      std::cerr &lt;&lt; &quot;Could not open &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
      exit(1);
    }
    static ros::Time start_time = input-&gt;header.stamp;

    ofs &lt;&lt; input-&gt;header.seq &lt;&lt; &quot;,&quot; &lt;&lt; scan_points_num &lt;&lt; &quot;,&quot; &lt;&lt; step_size &lt;&lt; &quot;,&quot; &lt;&lt; trans_eps &lt;&lt; &quot;,&quot; &lt;&lt; std::fixed
        &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; std::fixed &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.y &lt;&lt; &quot;,&quot;
        &lt;&lt; std::fixed &lt;&lt; std::setprecision(5) &lt;&lt; current_pose.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.pitch
        &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.y &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.z &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose.roll &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.pitch &lt;&lt; &quot;,&quot; &lt;&lt; predict_pose.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.x - predict_pose.x &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.y - predict_pose.y &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.z - predict_pose.z &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.roll - predict_pose.roll &lt;&lt; &quot;,&quot;
        &lt;&lt; current_pose.pitch - predict_pose.pitch &lt;&lt; &quot;,&quot; &lt;&lt; current_pose.yaw - predict_pose.yaw &lt;&lt; &quot;,&quot;
        &lt;&lt; predict_pose_error &lt;&lt; &quot;,&quot; &lt;&lt; iteration &lt;&lt; &quot;,&quot; &lt;&lt; fitness_score &lt;&lt; &quot;,&quot; &lt;&lt; trans_probability &lt;&lt; &quot;,&quot;
        &lt;&lt; ndt_reliability.data &lt;&lt; &quot;,&quot; &lt;&lt; current_velocity &lt;&lt; &quot;,&quot; &lt;&lt; current_velocity_smooth &lt;&lt; &quot;,&quot; &lt;&lt; current_accel
        &lt;&lt; &quot;,&quot; &lt;&lt; angular_velocity &lt;&lt; &quot;,&quot; &lt;&lt; time_ndt_matching.data &lt;&lt; &quot;,&quot; &lt;&lt; align_time &lt;&lt; &quot;,&quot; &lt;&lt; getFitnessScore_time
        &lt;&lt; std::endl;

    std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Sequence: &quot; &lt;&lt; input-&gt;header.seq &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Timestamp: &quot; &lt;&lt; input-&gt;header.stamp &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Frame ID: &quot; &lt;&lt; input-&gt;header.frame_id &lt;&lt; std::endl;
    //		std::cout &lt;&lt; &quot;Number of Scan Points: &quot; &lt;&lt; scan_ptr-&gt;size() &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Number of Filtered Scan Points: &quot; &lt;&lt; scan_points_num &lt;&lt; &quot; points.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;NDT has converged: &quot; &lt;&lt; ndt.hasConverged() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Fitness Score: &quot; &lt;&lt; fitness_score &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Transformation Probability: &quot; &lt;&lt; ndt.getTransformationProbability() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Execution Time: &quot; &lt;&lt; exe_time &lt;&lt; &quot; ms.&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Number of Iterations: &quot; &lt;&lt; ndt.getFinalNumIteration() &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;NDT Reliability: &quot; &lt;&lt; ndt_reliability.data &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;(x,y,z,roll,pitch,yaw): &quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;(&quot; &lt;&lt; current_pose.x &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.y &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.z &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.roll
              &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.pitch &lt;&lt; &quot;, &quot; &lt;&lt; current_pose.yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;Transformation Matrix: &quot; &lt;&lt; std::endl;
    std::cout &lt;&lt; t &lt;&lt; std::endl;
    std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;

    // Update offset
    if (_offset == &quot;linear&quot;)
    {
      offset_x = diff_x;
      offset_y = diff_y;
      offset_z = diff_z;
      offset_yaw = diff_yaw;
    }
    else if (_offset == &quot;quadratic&quot;)
    {
      offset_x = (current_velocity_x + current_accel_x * secs) * secs;
      offset_y = (current_velocity_y + current_accel_y * secs) * secs;
      offset_z = diff_z;
      offset_yaw = diff_yaw;
    }
    else if (_offset == &quot;zero&quot;)
    {
      offset_x = 0.0;
      offset_y = 0.0;
      offset_z = 0.0;
      offset_yaw = 0.0;
    }
   
    offset_imu_x = 0.0;
    offset_imu_y = 0.0;
    offset_imu_z = 0.0;
    offset_imu_roll = 0.0;
    offset_imu_pitch = 0.0;
    offset_imu_yaw = 0.0;

    offset_odom_x = 0.0;
    offset_odom_y = 0.0;
    offset_odom_z = 0.0;
    offset_odom_roll = 0.0;
    offset_odom_pitch = 0.0;
    offset_odom_yaw = 0.0;

    offset_imu_odom_x = 0.0;
    offset_imu_odom_y = 0.0;
    offset_imu_odom_z = 0.0;
    offset_imu_odom_roll = 0.0;
    offset_imu_odom_pitch = 0.0;
    offset_imu_odom_yaw = 0.0;

    // Update previous_***
    previous_pose.x = current_pose.x;
    previous_pose.y = current_pose.y;
    previous_pose.z = current_pose.z;
    previous_pose.roll = current_pose.roll;
    previous_pose.pitch = current_pose.pitch;
    previous_pose.yaw = current_pose.yaw;

    previous_scan_time.sec = current_scan_time.sec;
    previous_scan_time.nsec = current_scan_time.nsec;

    previous_previous_velocity = previous_velocity;
    previous_velocity = current_velocity;
    previous_velocity_x = current_velocity_x;
    previous_velocity_y = current_velocity_y;
    previous_velocity_z = current_velocity_z;
    previous_accel = current_accel;

    previous_estimated_vel_kmph.data = estimated_vel_kmph.data;
  }
}

int main(int argc, char** argv)
{
  ros::init(argc, argv, &quot;ndt_matching&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  // Set log file name.
  char buffer[80];
  std::time_t now = std::time(NULL);
  std::tm* pnow = std::localtime(&amp;now);
  std::strftime(buffer, 80, &quot;%Y%m%d_%H%M%S&quot;, pnow);
  filename = &quot;ndt_matching_&quot; + std::string(buffer) + &quot;.csv&quot;;
  ofs.open(filename.c_str(), std::ios::app);

  // Geting parameters
  private_nh.getParam(&quot;use_gnss&quot;, _use_gnss);
  private_nh.getParam(&quot;queue_size&quot;, _queue_size);
  private_nh.getParam(&quot;offset&quot;, _offset);
  private_nh.getParam(&quot;use_openmp&quot;, _use_openmp);
  private_nh.getParam(&quot;get_height&quot;, _get_height);
  private_nh.getParam(&quot;use_local_transform&quot;, _use_local_transform);
  private_nh.getParam(&quot;use_imu&quot;, _use_imu);
  private_nh.getParam(&quot;use_odom&quot;, _use_odom);
  private_nh.getParam(&quot;imu_upside_down&quot;, _imu_upside_down);
  private_nh.getParam(&quot;imu_topic&quot;, _imu_topic);

  if (nh.getParam(&quot;localizer&quot;, _localizer) == false)
  {
    std::cout &lt;&lt; &quot;localizer is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_x&quot;, _tf_x) == false)
  {
    std::cout &lt;&lt; &quot;tf_x is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_y&quot;, _tf_y) == false)
  {
    std::cout &lt;&lt; &quot;tf_y is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_z&quot;, _tf_z) == false)
  {
    std::cout &lt;&lt; &quot;tf_z is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_roll&quot;, _tf_roll) == false)
  {
    std::cout &lt;&lt; &quot;tf_roll is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_pitch&quot;, _tf_pitch) == false)
  {
    std::cout &lt;&lt; &quot;tf_pitch is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }
  if (nh.getParam(&quot;tf_yaw&quot;, _tf_yaw) == false)
  {
    std::cout &lt;&lt; &quot;tf_yaw is not set.&quot; &lt;&lt; std::endl;
    return 1;
  }

  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;Log file: &quot; &lt;&lt; filename &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_gnss: &quot; &lt;&lt; _use_gnss &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;queue_size: &quot; &lt;&lt; _queue_size &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;offset: &quot; &lt;&lt; _offset &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_openmp: &quot; &lt;&lt; _use_openmp &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;get_height: &quot; &lt;&lt; _get_height &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_local_transform: &quot; &lt;&lt; _use_local_transform &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_imu: &quot; &lt;&lt; _use_imu &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;use_odom: &quot; &lt;&lt; _use_odom &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;imu_upside_down: &quot; &lt;&lt; _imu_upside_down &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;localizer: &quot; &lt;&lt; _localizer &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;imu_topic: &quot; &lt;&lt; _imu_topic &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;(tf_x,tf_y,tf_z,tf_roll,tf_pitch,tf_yaw): (&quot; &lt;&lt; _tf_x &lt;&lt; &quot;, &quot; &lt;&lt; _tf_y &lt;&lt; &quot;, &quot; &lt;&lt; _tf_z &lt;&lt; &quot;, &quot;
            &lt;&lt; _tf_roll &lt;&lt; &quot;, &quot; &lt;&lt; _tf_pitch &lt;&lt; &quot;, &quot; &lt;&lt; _tf_yaw &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;-----------------------------------------------------------------&quot; &lt;&lt; std::endl;

  Eigen::Translation3f tl_btol(_tf_x, _tf_y, _tf_z);                 // tl: translation
  Eigen::AngleAxisf rot_x_btol(_tf_roll, Eigen::Vector3f::UnitX());  // rot: rotation
  Eigen::AngleAxisf rot_y_btol(_tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_btol(_tf_yaw, Eigen::Vector3f::UnitZ());
  tf_btol = (tl_btol * rot_z_btol * rot_y_btol * rot_x_btol).matrix();

  Eigen::Translation3f tl_ltob((-1.0) * _tf_x, (-1.0) * _tf_y, (-1.0) * _tf_z);  // tl: translation
  Eigen::AngleAxisf rot_x_ltob((-1.0) * _tf_roll, Eigen::Vector3f::UnitX());     // rot: rotation
  Eigen::AngleAxisf rot_y_ltob((-1.0) * _tf_pitch, Eigen::Vector3f::UnitY());
  Eigen::AngleAxisf rot_z_ltob((-1.0) * _tf_yaw, Eigen::Vector3f::UnitZ());
  tf_ltob = (tl_ltob * rot_z_ltob * rot_y_ltob * rot_x_ltob).matrix();

  // Updated in initialpose_callback or gnss_callback
  initial_pose.x = 0.0;
  initial_pose.y = 0.0;
  initial_pose.z = 0.0;
  initial_pose.roll = 0.0;
  initial_pose.pitch = 0.0;
  initial_pose.yaw = 0.0;

  // Publishers
  predict_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose&quot;, 1000);
  predict_pose_imu_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose_imu&quot;, 1000);
  predict_pose_odom_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose_odom&quot;, 1000);
  predict_pose_imu_odom_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/predict_pose_imu_odom&quot;, 1000);
  ndt_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/ndt_pose&quot;, 1000);
  // current_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/current_pose&quot;, 1000);
  localizer_pose_pub = nh.advertise&lt;geometry_msgs::PoseStamped&gt;(&quot;/localizer_pose&quot;, 1000);
  estimate_twist_pub = nh.advertise&lt;geometry_msgs::TwistStamped&gt;(&quot;/estimate_twist&quot;, 1000);
  estimated_vel_mps_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/estimated_vel_mps&quot;, 1000);
  estimated_vel_kmph_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/estimated_vel_kmph&quot;, 1000);
  estimated_vel_pub = nh.advertise&lt;geometry_msgs::Vector3Stamped&gt;(&quot;/estimated_vel&quot;, 1000);
  time_ndt_matching_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/time_ndt_matching&quot;, 1000);
  ndt_stat_pub = nh.advertise&lt;ndt_localizer::ndt_stat&gt;(&quot;/ndt_stat&quot;, 1000);
  ndt_reliability_pub = nh.advertise&lt;std_msgs::Float32&gt;(&quot;/ndt_reliability&quot;, 1000);

  // Subscribers
  ros::Subscriber param_sub = nh.subscribe(&quot;config/ndt&quot;, 10, param_callback);
  ros::Subscriber gnss_sub = nh.subscribe(&quot;gnss_pose&quot;, 10, gnss_callback);
  ros::Subscriber map_sub = nh.subscribe(&quot;points_map&quot;, 10, map_callback);
  ros::Subscriber initialpose_sub = nh.subscribe(&quot;initialpose&quot;, 1000, initialpose_callback);
  ros::Subscriber points_sub = nh.subscribe(&quot;filtered_points&quot;, _queue_size, points_callback);
  ros::Subscriber odom_sub = nh.subscribe(&quot;/odom_pose&quot;, _queue_size*10, odom_callback);
  ros::Subscriber imu_sub = nh.subscribe(_imu_topic.c_str(), _queue_size*10, imu_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="62aebd43dd53ce621c9504ebd4f01c2b90c44555" fix_time="658,82896">
		<msg>fix to free a NULL window</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr/region_tlr.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr/region_tlr.cpp">
				<diff>@@ -373,8 +373,11 @@ static void superimpose_cb(const std_msgs::Bool::ConstPtr&amp; config_msg)
   }
 
   if (!show_superimpose_result) {
-    cv::destroyWindow(window_name);
-    cv::waitKey(1);
+	  if (cvGetWindowHandle(window_name.c_str()) != NULL)
+	  {
+		  cv::destroyWindow(window_name);
+		  cv::waitKey(1);
+	  }
   }
 
 } /* static void superimpose_cb() */
</diff>
				<old_file>#include &lt;vector&gt;
#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &quot;TrafficLight.h&quot;
#include &lt;float.h&gt;
#include &lt;math.h&gt;
#include &lt;sstream&gt;
#include &lt;runtime_manager/traffic_light.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &quot;road_wizard/TunedResult.h&quot;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;std_msgs/Bool.h&gt;

thresholdSet thSet;

static ros::Publisher signalState_pub;
static ros::Publisher signalStateString_pub;
static ros::Publisher marker_pub;
static ros::Publisher superimpose_image_pub;
static constexpr int32_t ADVERTISE_QUEUE_SIZE = 10;
static constexpr bool    ADVERTISE_LATCH      = true;
static uint32_t          shape                = visualization_msgs::Marker::SPHERE;

// Variables
static TrafficLightDetector detector;

static cv::Mat frame;

static bool              show_superimpose_result = false;
static const std::string window_name             = &quot;superimpose result&quot;;

static double cvtInt2Double_hue(int center, int range)
{
  /* convert value range from OpenCV to Definition */
  double converted = (center + range) * 2.0f;

  if (converted &lt; 0) {
    converted = 0.0f;
  } else if (360 &lt; converted) {
    converted = converted - 360.0f;
  }

  return converted;
} /* static double cvtInt2Double_hue() */


static double cvtInt2Double_sat(int center, int range)
{
  /* convert value range from OpenCV to Definition */
  double converted = (center + range) / 255.0f;
  if (converted &lt; 0) {
    converted = 0.0f;
  } else if (1.0f &lt; converted) {
    converted = 1.0f;
  }

  return converted;
} /* static double cvtInt2Double_sat() */


static double cvtInt2Double_val(int center, int range)
{
  /* convert value range from OpenCV to Definition */
  double converted = (center + range) / 255.0f;
  if (converted &lt; 0) {
    converted = 0;
  } else if (1.0f &lt; converted) {
    converted = 1.0f;
  }

  return converted;
} /* static double cvtInt2Double_val() */


static void putResult_inText(cv::Mat *image, const std::vector&lt;Context&gt; &amp;contexts)
{
  std::string label;
  const int fontFace = cv::FONT_HERSHEY_COMPLEX_SMALL;
  const float fontScale = 1.0f;
  const int fontThickness = 1;
  int baseline = 0;
  CvPoint textOrg;
  CvScalar textColor;

  for (unsigned int i=0; i&lt;contexts.size(); i++)
    {
      Context ctx = contexts.at(i);
//      if (ctx.lampRadius &lt; MINIMAM_RADIUS)
//        continue;

      switch(ctx.lightState) {
      case GREEN:
        label = &quot;GREEN&quot;;
        textColor = CV_RGB(0, 255, 0);
        break;
      case YELLOW:
        label = &quot;YELLOW&quot;;
        textColor = CV_RGB(255, 255, 0);
        break;
      case RED:
        label = &quot;RED&quot;;
        textColor = CV_RGB(255, 0, 0);
        break;
      case UNDEFINED:
        label = &quot;UNDEFINED&quot;;
        textColor = CV_RGB(0, 0, 0);
      }

      cv::getTextSize(label,
		      fontFace,
		      fontScale,
		      fontThickness,
		      &amp;baseline);

      textOrg = cv::Point(ctx.topLeft.x, ctx.botRight.y + baseline);

      putText(*image,
              label,
              textOrg,
              fontFace,
              fontScale,
              textColor,
              fontThickness,
              CV_AA);
    }
} /* static void putResult_inText() */


static void image_raw_cb(const sensor_msgs::Image&amp; image_source)
{
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
  //  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source);
  frame = cv_image-&gt;image.clone();

  /* Draw superimpose result on image */
  cv::Mat targetScope = frame.clone();
  for (unsigned int i=0; i&lt;detector.contexts.size(); i++)
    {
      /* draw superimposed position of traffic lights */
      circle(targetScope, detector.contexts.at(i).redCenter, detector.contexts.at(i).lampRadius, CV_RGB(255, 0, 0), 1, 0);
      circle(targetScope, detector.contexts.at(i).yellowCenter, detector.contexts.at(i).lampRadius, CV_RGB(255, 255, 0), 1, 0);
      circle(targetScope, detector.contexts.at(i).greenCenter, detector.contexts.at(i).lampRadius, CV_RGB(0, 255, 0), 1, 0);
    }

  /* draw detection results */
  putResult_inText(&amp;targetScope, detector.contexts);


  /* Publish superimpose result image */
  cv_bridge::CvImage msg_converter;
  msg_converter.header = image_source.header;
  msg_converter.encoding = sensor_msgs::image_encodings::BGR8;
  msg_converter.image = targetScope;
  superimpose_image_pub.publish(msg_converter.toImageMsg());

  /* Display superimpose result image in separate window*/
  if (show_superimpose_result)
    {
      if (cvGetWindowHandle(window_name.c_str()) != NULL) // Guard not to write destroyed window by using close button on the window
        {
          imshow(window_name, targetScope);
          cv::waitKey(5);
        }
    }

} /* static void image_raw_cb() */


static void extractedPos_cb(const road_wizard::Signals::ConstPtr&amp; extractedPos)
{
  if (frame.empty())
    return;

  setContexts(detector, extractedPos);

  detector.brightnessDetect(frame);

  /* publish result */
  runtime_manager::traffic_light state_msg;
  std_msgs::String state_string_msg;
  const int32_t TRAFFIC_LIGHT_RED     = 0;
  const int32_t TRAFFIC_LIGHT_GREEN   = 1;
  const int32_t TRAFFIC_LIGHT_UNKNOWN = 2;
  static int32_t prev_state = TRAFFIC_LIGHT_UNKNOWN;
  state_msg.traffic_light = TRAFFIC_LIGHT_UNKNOWN;
  for (unsigned int i=0; i&lt;detector.contexts.size(); i++) {
	  switch (detector.contexts.at(i).lightState) {
	  case GREEN:
		  state_msg.traffic_light = TRAFFIC_LIGHT_GREEN;
          state_string_msg.data = &quot;green signal&quot;;
		  break;
	  case YELLOW:
	  case RED:
		  state_msg.traffic_light = TRAFFIC_LIGHT_RED;
          state_string_msg.data = &quot;red signal&quot;;
		  break;
	  case UNDEFINED:
		  state_msg.traffic_light = TRAFFIC_LIGHT_UNKNOWN;
          state_string_msg.data = &quot;&quot;;
		  break;
	  }
	  if (state_msg.traffic_light != TRAFFIC_LIGHT_UNKNOWN)
		  break;  // publish the first state in detector.contexts
  }

  if (state_msg.traffic_light != prev_state) {
    signalState_pub.publish(state_msg);
    signalStateString_pub.publish(state_string_msg);
  } else {
    state_string_msg.data = &quot;&quot;;
    signalStateString_pub.publish(state_string_msg);
  }

  std_msgs::ColorRGBA color_black;
  color_black.r = 0.0f;
  color_black.g = 0.0f;
  color_black.b = 0.0f;
  color_black.a = 1.0f;

  std_msgs::ColorRGBA color_red;
  color_red.r = 1.0f;
  color_red.g = 0.0f;
  color_red.b = 0.0f;
  color_red.a = 1.0f;

  std_msgs::ColorRGBA color_yellow;
  color_yellow.r = 1.0f;
  color_yellow.g = 1.0f;
  color_yellow.b = 0.0f;
  color_yellow.a = 1.0f;

  std_msgs::ColorRGBA color_green;
  color_green.r = 0.0f;
  color_green.g = 1.0f;
  color_green.b = 0.0f;
  color_green.a = 1.0f;

  /* publish all detected result as ROS Marker */
  for (unsigned int i=0; i&lt;detector.contexts.size(); i++)
    {
      Context ctx = detector.contexts.at(i);
      visualization_msgs::MarkerArray signalSet;
      visualization_msgs::Marker mk_red, mk_yellow, mk_green;

      /* Set the frame ID */
      mk_red.header.frame_id    = &quot;map&quot;;
      mk_yellow.header.frame_id = &quot;map&quot;;
      mk_green.header.frame_id  = &quot;map&quot;;

      /* Set the namespace and id for this marker */
      mk_red.ns    = &quot;tlr_result_red&quot;;
      mk_yellow.ns = &quot;tlr_result_yellow&quot;;
      mk_green.ns  = &quot;tlr_result_green&quot;;
      mk_red.id    = ctx.signalID;
      mk_yellow.id = ctx.signalID;
      mk_green.id  = ctx.signalID;

      /* Set the marker type */
      mk_red.type    = shape;
      mk_yellow.type = shape;
      mk_green.type  = shape;

      /* Set the pose of the marker */
      mk_red.pose.position.x    = ctx.redCenter3d.x;
      mk_red.pose.position.y    = ctx.redCenter3d.y;
      mk_red.pose.position.z    = ctx.redCenter3d.z;
      mk_yellow.pose.position.x = ctx.yellowCenter3d.x;
      mk_yellow.pose.position.y = ctx.yellowCenter3d.y;
      mk_yellow.pose.position.z = ctx.yellowCenter3d.z;
      mk_green.pose.position.x  = ctx.greenCenter3d.x;
      mk_green.pose.position.y  = ctx.greenCenter3d.y;
      mk_green.pose.position.z  = ctx.greenCenter3d.z;

      mk_red.pose.orientation.x    = 0.0;
      mk_red.pose.orientation.y    = 0.0;
      mk_red.pose.orientation.y    = 0.0;
      mk_red.pose.orientation.w    = 0.0;
      mk_yellow.pose.orientation.x = 0.0;
      mk_yellow.pose.orientation.y = 0.0;
      mk_yellow.pose.orientation.y = 0.0;
      mk_yellow.pose.orientation.w = 0.0;
      mk_green.pose.orientation.x  = 0.0;
      mk_green.pose.orientation.y  = 0.0;
      mk_green.pose.orientation.y  = 0.0;
      mk_green.pose.orientation.w  = 0.0;

      /* Set the scale of the marker -- We assume lamp radius as 30cm */
      mk_red.scale.x    = (double)0.3;
      mk_red.scale.y    = (double)0.3;
      mk_red.scale.z    = (double)0.3;
      mk_yellow.scale.x = (double)0.3;
      mk_yellow.scale.y = (double)0.3;
      mk_yellow.scale.z = (double)0.3;
      mk_green.scale.x  = (double)0.3;
      mk_green.scale.y  = (double)0.3;
      mk_green.scale.z  = (double)0.3;

      /* Set the color */
      switch (ctx.lightState) {
      case GREEN:
        mk_red.color    = color_black;
        mk_yellow.color = color_black;
        mk_green.color  = color_green;
        break;
      case YELLOW:
        mk_red.color    = color_black;
        mk_yellow.color = color_yellow;
        mk_green.color  = color_black;
        break;
      case RED:
        mk_red.color    = color_red;
        mk_yellow.color = color_black;
        mk_green.color  = color_black;
        break;
      case UNDEFINED:
        mk_red.color    = color_black;
        mk_yellow.color = color_black;
        mk_green.color  = color_black;
        break;
      }

      mk_red.lifetime    = ros::Duration(0.1);
      mk_yellow.lifetime = ros::Duration(0.1);
      mk_green.lifetime  = ros::Duration(0.1);

      signalSet.markers.push_back(mk_red);
      signalSet.markers.push_back(mk_yellow);
      signalSet.markers.push_back(mk_green);

      marker_pub.publish(signalSet);
    }

  prev_state = state_msg.traffic_light;
} /* static void extractedPos_cb() */


static void tunedResult_cb(const road_wizard::TunedResult&amp; msg)
{
  thSet.Red.Hue.upper = cvtInt2Double_hue(msg.Red.Hue.center, msg.Red.Hue.range);
  thSet.Red.Hue.lower = cvtInt2Double_hue(msg.Red.Hue.center, -msg.Red.Hue.range);
  thSet.Red.Sat.upper = cvtInt2Double_sat(msg.Red.Sat.center, msg.Red.Sat.range);
  thSet.Red.Sat.lower = cvtInt2Double_sat(msg.Red.Sat.center, -msg.Red.Sat.range);
  thSet.Red.Val.upper = cvtInt2Double_val(msg.Red.Val.center, msg.Red.Val.range);
  thSet.Red.Val.lower = cvtInt2Double_val(msg.Red.Val.center, -msg.Red.Val.range);

  thSet.Yellow.Hue.upper = cvtInt2Double_hue(msg.Yellow.Hue.center, msg.Yellow.Hue.range);
  thSet.Yellow.Hue.lower = cvtInt2Double_hue(msg.Yellow.Hue.center, -msg.Yellow.Hue.range);
  thSet.Yellow.Sat.upper = cvtInt2Double_sat(msg.Yellow.Sat.center, msg.Yellow.Sat.range);
  thSet.Yellow.Sat.lower = cvtInt2Double_sat(msg.Yellow.Sat.center, -msg.Yellow.Sat.range);
  thSet.Yellow.Val.upper = cvtInt2Double_val(msg.Yellow.Val.center, msg.Yellow.Val.range);
  thSet.Yellow.Val.lower = cvtInt2Double_val(msg.Yellow.Val.center, -msg.Yellow.Val.range);

  thSet.Green.Hue.upper = cvtInt2Double_hue(msg.Green.Hue.center, msg.Green.Hue.range);
  thSet.Green.Hue.lower = cvtInt2Double_hue(msg.Green.Hue.center, -msg.Green.Hue.range);
  thSet.Green.Sat.upper = cvtInt2Double_sat(msg.Green.Sat.center, msg.Green.Sat.range);
  thSet.Green.Sat.lower = cvtInt2Double_sat(msg.Green.Sat.center, -msg.Green.Sat.range);
  thSet.Green.Val.upper = cvtInt2Double_val(msg.Green.Val.center, msg.Green.Val.range);
  thSet.Green.Val.lower = cvtInt2Double_val(msg.Green.Val.center, -msg.Green.Val.range);

} /* static void tunedResult_cb() */


static void superimpose_cb(const std_msgs::Bool::ConstPtr&amp; config_msg)
{
  show_superimpose_result = config_msg-&gt;data;

  if (show_superimpose_result) {
    cv::namedWindow(window_name, cv::WINDOW_NORMAL);
    cv::startWindowThread();
  }

  if (!show_superimpose_result) {
    cv::destroyWindow(window_name);
    cv::waitKey(1);
  }

} /* static void superimpose_cb() */

int main(int argc, char* argv[]) {

  //	printf(&quot;***** Traffic lights app *****\n&quot;);
#ifdef SHOW_DEBUG_INFO
  cv::namedWindow(&quot;tmpImage&quot;, cv::WINDOW_NORMAL);
  cv::namedWindow(&quot;bright_mask&quot;, cv::WINDOW_NORMAL);
  cv::startWindowThread();
#endif

  thSet.Red.Hue.upper = (double)DAYTIME_RED_UPPER;
  thSet.Red.Hue.lower = (double)DAYTIME_RED_LOWER;
  thSet.Red.Sat.upper = 1.0f;
  thSet.Red.Sat.lower = DAYTIME_S_SIGNAL_THRESHOLD;
  thSet.Red.Val.upper = 1.0f;
  thSet.Red.Val.lower = DAYTIME_V_SIGNAL_THRESHOLD;

  thSet.Yellow.Hue.upper = (double)DAYTIME_YELLOW_UPPER;
  thSet.Yellow.Hue.lower = (double)DAYTIME_YELLOW_LOWER;
  thSet.Yellow.Sat.upper = 1.0f;
  thSet.Yellow.Sat.lower = DAYTIME_S_SIGNAL_THRESHOLD;
  thSet.Yellow.Val.upper = 1.0f;
  thSet.Yellow.Val.lower = DAYTIME_V_SIGNAL_THRESHOLD;

  thSet.Green.Hue.upper = (double)DAYTIME_GREEN_UPPER;
  thSet.Green.Hue.lower = (double)DAYTIME_GREEN_LOWER;
  thSet.Green.Sat.upper = 1.0f;
  thSet.Green.Sat.lower = DAYTIME_S_SIGNAL_THRESHOLD;
  thSet.Green.Val.upper = 1.0f;
  thSet.Green.Val.lower = DAYTIME_V_SIGNAL_THRESHOLD;


  ros::init(argc, argv, &quot;region_tlr&quot;);

  ros::NodeHandle n;
  ros::NodeHandle private_nh(&quot;~&quot;);
  std::string image_topic_name;
  private_nh.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name, &quot;/image_raw&quot;);

  ros::Subscriber image_sub       = n.subscribe(image_topic_name, 1, image_raw_cb);
  ros::Subscriber position_sub    = n.subscribe(&quot;/roi_signal&quot;, 1, extractedPos_cb);
  ros::Subscriber tunedResult_sub = n.subscribe(&quot;/tuned_result&quot;, 1, tunedResult_cb);
  ros::Subscriber superimpose_sub = n.subscribe(&quot;/config/superimpose&quot;, 1, superimpose_cb);

  signalState_pub       = n.advertise&lt;runtime_manager::traffic_light&gt;(&quot;/light_color&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
  signalStateString_pub = n.advertise&lt;std_msgs::String&gt;(&quot;/sound_player&quot;, ADVERTISE_QUEUE_SIZE);
  marker_pub            = n.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;tlr_result&quot;, ADVERTISE_QUEUE_SIZE);
  superimpose_image_pub= n.advertise&lt;sensor_msgs::Image&gt;(&quot;tlr_superimpose_image&quot;, ADVERTISE_QUEUE_SIZE);

  ros::spin();

  return 0;
} /* int main() */


/*
  define magnitude relationship of context
 */
static bool compareContext(const Context left, const Context right)
{
  /* if lampRadius is bigger, context is smaller */
  return left.lampRadius &gt;= right.lampRadius;
} /* static bool compareContext() */


void setContexts(TrafficLightDetector &amp;detector,
                 const road_wizard::Signals::ConstPtr&amp; extractedPos)
{

  /* copy parts of data to local variable */
  std::vector&lt;road_wizard::ExtractedPosition&gt; signals;
  std::vector&lt;road_wizard::ExtractedPosition&gt;::iterator sig_iterator;
  for (unsigned int i=0; i&lt;extractedPos-&gt;Signals.size(); i++ )
    {
      road_wizard::ExtractedPosition tmp;
      tmp.signalId = extractedPos-&gt;Signals.at(i).signalId;
      tmp.u        = extractedPos-&gt;Signals.at(i).u;
      tmp.v        = extractedPos-&gt;Signals.at(i).v;
      tmp.radius   = extractedPos-&gt;Signals.at(i).radius;
      tmp.x        = extractedPos-&gt;Signals.at(i).x;
      tmp.y        = extractedPos-&gt;Signals.at(i).y;
      tmp.z        = extractedPos-&gt;Signals.at(i).z;
      tmp.type     = extractedPos-&gt;Signals.at(i).type;
      tmp.linkId   = extractedPos-&gt;Signals.at(i).linkId;
      tmp.plId     = extractedPos-&gt;Signals.at(i).plId;
      signals.push_back(tmp);
    }

  std::vector&lt;int&gt; plid_vector;
  for (sig_iterator=signals.begin(); sig_iterator&lt;signals.end(); sig_iterator++) {
    plid_vector.push_back(sig_iterator-&gt;plId);
  }

  /* get array that has unique PLID values as its element */
  std::sort(plid_vector.begin(), plid_vector.end());
  std::vector&lt;int&gt;::iterator new_end = std::unique(plid_vector.begin(), plid_vector.end());
  plid_vector.erase(new_end, plid_vector.end());

  std::vector&lt;Context&gt; updatedSignals;

  /* assemble fragmented signal lamp in a context */
  for (unsigned int ctx_idx=0; ctx_idx&lt;plid_vector.size(); ctx_idx++)
    {
      Context ctx;
      int min_radius  = INT_MAX;
      int most_left   = frame.cols;
      int most_top    = frame.rows;
      int most_right  = 0;
      int most_bottom = 0;

      for (sig_iterator=signals.begin(); sig_iterator&lt;signals.end(); sig_iterator++)
        {
          int img_x = sig_iterator-&gt;u;
          int img_y = sig_iterator-&gt;v;
          double map_x = sig_iterator-&gt;x;
          double map_y = sig_iterator-&gt;y;
          double map_z = sig_iterator-&gt;z;
          int radius = sig_iterator-&gt;radius;
          if (sig_iterator-&gt;plId == plid_vector.at(ctx_idx) &amp;&amp;
              0 &lt; img_x - radius - 1.5 * radius &amp;&amp; img_x + radius + 1.5 * radius &lt; frame.cols &amp;&amp;
              0 &lt; img_y - radius - 1.5 * radius &amp;&amp; img_y + radius + 1.5 * radius &lt; frame.rows)
            {
              switch (sig_iterator-&gt;type) {
              case 1:           /* RED */
                ctx.redCenter   = cv::Point( img_x, img_y );
                ctx.redCenter3d = cv::Point3d( map_x, map_y, map_z );
                break;
              case 2:           /* GREEN */
                ctx.greenCenter   = cv::Point( img_x, img_y );
                ctx.greenCenter3d = cv::Point3d( map_x, map_y, map_z );
                break;
              case 3:           /* YELLOW */
                ctx.yellowCenter   = cv::Point( img_x, img_y );
                ctx.yellowCenter3d = cv::Point3d( map_x, map_y, map_z );
                ctx.signalID       = sig_iterator-&gt;signalId; // use yellow light signalID as this context's representative
                break;
              default:          /* this signal is not for cars (for pedestrian or something) */
                continue;
              }
              min_radius    = (min_radius &gt; radius) ? radius : min_radius;
              most_left     = (most_left &gt; img_x - radius -   1.5 * min_radius)  ? img_x - radius - 1.5 * min_radius : most_left;
              most_top      = (most_top &gt; img_y - radius -    1.5 * min_radius)  ? img_y - radius - 1.5 * min_radius : most_top;
              most_right    = (most_right &lt; img_x + radius +  1.5 * min_radius)  ? img_x + radius + 1.5 * min_radius : most_right;
              most_bottom   = (most_bottom &lt; img_y + radius + 1.5 * min_radius)  ? img_y + radius + 1.5 * min_radius : most_bottom;
            }
        }

      ctx.lampRadius = min_radius;
      ctx.topLeft    = cv::Point(most_left, most_top);
      ctx.botRight   = cv::Point(most_right, most_bottom);
      ctx.lightState = UNDEFINED;
      ctx.stateJudgeCount = 0;

      /* search whether this signal has already belonged in detector.contexts */
      bool isInserted = false;
      std::vector&lt;int&gt; eraseCandidate;
      for (unsigned int i=0; i&lt;detector.contexts.size(); i++) {
        if (ctx.signalID == detector.contexts.at(i).signalID &amp;&amp; ctx.lampRadius != INT_MAX)
          {
            /* update to new information except to lightState */
            updatedSignals.push_back(ctx);
            updatedSignals.back().lightState      = detector.contexts.at(i).lightState;
            updatedSignals.back().stateJudgeCount = detector.contexts.at(i).stateJudgeCount;
            isInserted = true;
            break;
          }

      }

      if (isInserted == false &amp;&amp; ctx.lampRadius != INT_MAX)
        updatedSignals.push_back(ctx); // this ctx is new in detector.contexts

    }

  /* reset detector.contexts */
  detector.contexts.clear();
  detector.contexts.resize(updatedSignals.size());
  std::sort(updatedSignals.begin(), updatedSignals.end(), compareContext); // sort by lampRadius
  for (unsigned int i=0; i&lt;updatedSignals.size(); i++) {
    detector.contexts.at(i) = updatedSignals.at(i);
  }
} /* void setContexts() */
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="46ff1d116175f5586b4c1b904bc89f00e85dc41e" fix_time="58,71530">
		<msg>fix initializing measurement_range
https://github.com/CPFL/Autoware/issues/693</msg>
		<modified_files>
			<file old_path="ros/src/sensing/filters/packages/points_downsampler/include/points_downsampler.h" new_path="ros/src/sensing/filters/packages/points_downsampler/include/points_downsampler.h">
				<diff>@@ -5,8 +5,6 @@ static pcl::PointCloud&lt;pcl::PointXYZI&gt; removePointsByRange(pcl::PointCloud&lt;pcl::
 {
   pcl::PointCloud&lt;pcl::PointXYZI&gt; narrowed_scan;
   narrowed_scan.header = scan.header;
-
-  max_range = 100.0;    //  This is a only tempolary patch for Localization problem.
   double square_min_range = min_range * min_range;
   double square_max_range = max_range * max_range;
 
</diff>
				<old_file>#ifndef POINTS_DOWNSAMPLER_H
#define POINTS_DOWNSAMPLER_H

static pcl::PointCloud&lt;pcl::PointXYZI&gt; removePointsByRange(pcl::PointCloud&lt;pcl::PointXYZI&gt; scan, double min_range, double max_range)
{
  pcl::PointCloud&lt;pcl::PointXYZI&gt; narrowed_scan;
  narrowed_scan.header = scan.header;

  max_range = 100.0;    //  This is a only tempolary patch for Localization problem.
  double square_min_range = min_range * min_range;
  double square_max_range = max_range * max_range;

  for(pcl::PointCloud&lt;pcl::PointXYZI&gt;::const_iterator iter = scan.begin(); iter != scan.end(); ++iter)
  {
    const pcl::PointXYZI &amp;p = *iter;
//    p.x = iter-&gt;x;
//    p.y = iter-&gt;y;
//    p.z = iter-&gt;z;
//    p.intensity = iter-&gt;intensity;
    double square_distance = p.x * p.x + p.y * p.y;

    if(square_min_range &lt;= square_distance &amp;&amp; square_distance &lt;= square_max_range){
      narrowed_scan.points.push_back(p);
    }
  }
#if 1
  return narrowed_scan;
#else
  return scan;    //  This is a only tempolary patch for Localization problem.
#endif
}

#endif // POINTS_DOWNSAMPLER_H
</old_file>
			</file>
			<file old_path="ros/src/sensing/filters/packages/points_downsampler/nodes/distance_filter/distance_filter.cpp" new_path="ros/src/sensing/filters/packages/points_downsampler/nodes/distance_filter/distance_filter.cpp">
				<diff>@@ -60,7 +60,7 @@ static std::ofstream ofs;
 static std::string filename;
 
 static std::string POINTS_TOPIC;
-static double measurement_range;
+static double measurement_range=100.0;
 
 static void config_callback(const runtime_manager::ConfigDistanceFilter::ConstPtr&amp; input)
 {
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;

#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;

#include &lt;runtime_manager/ConfigDistanceFilter.h&gt;

#include &lt;points_downsampler/PointsDownsamplerInfo.h&gt;

#include &lt;algorithm&gt; // For std::min()
#include &lt;chrono&gt;

#include &quot;points_downsampler.h&quot;

#define MAX_MEASUREMENT_RANGE 200.0

ros::Publisher filtered_points_pub;

static int sample_num = 1000;

static ros::Publisher points_downsampler_info_pub;
static points_downsampler::PointsDownsamplerInfo points_downsampler_info_msg;

static std::chrono::time_point&lt;std::chrono::system_clock&gt; filter_start, filter_end;

static bool _output_log = false;
static std::ofstream ofs;
static std::string filename;

static std::string POINTS_TOPIC;
static double measurement_range;

static void config_callback(const runtime_manager::ConfigDistanceFilter::ConstPtr&amp; input)
{
  sample_num = input-&gt;sample_num;
  measurement_range = input-&gt;measurement_range;
}

static void scan_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  pcl::PointXYZI sampled_p;
  pcl::PointCloud&lt;pcl::PointXYZI&gt; scan;

  pcl::fromROSMsg(*input, scan);

  if(measurement_range != MAX_MEASUREMENT_RANGE){
    scan = removePointsByRange(scan, 0, measurement_range);
  }

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());
  filtered_scan_ptr-&gt;header = scan.header;

  int points_num = scan.size();

  double w_total = 0.0;
  double w_step = 0.0;
  int m = 0;
  double c = 0.0;

  filter_start = std::chrono::system_clock::now();

  for (pcl::PointCloud&lt;pcl::PointXYZI&gt;::const_iterator item = scan.begin(); item != scan.end(); item++)
  {
    w_total += item-&gt;x * item-&gt;x + item-&gt;y * item-&gt;y + item-&gt;z * item-&gt;z;
  }
  w_step = w_total / sample_num;

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::const_iterator item = scan.begin();
  for (m = 0; m &lt; sample_num; m++)
  {
    while (m * w_step &gt; c)
    {
      item++;
      c += item-&gt;x * item-&gt;x + item-&gt;y * item-&gt;y + item-&gt;z * item-&gt;z;
    }
    sampled_p.x = item-&gt;x;
    sampled_p.y = item-&gt;y;
    sampled_p.z = item-&gt;z;
    sampled_p.intensity = item-&gt;intensity;
    filtered_scan_ptr-&gt;points.push_back(sampled_p);
  }

  sensor_msgs::PointCloud2 filtered_msg;
  pcl::toROSMsg(*filtered_scan_ptr, filtered_msg);

  filter_end = std::chrono::system_clock::now();

  filtered_msg.header = input-&gt;header;
  filtered_points_pub.publish(filtered_msg);

  points_downsampler_info_msg.header = input-&gt;header;
  points_downsampler_info_msg.filter_name = &quot;distance_filter&quot;;
  points_downsampler_info_msg.measurement_range = measurement_range;
  points_downsampler_info_msg.original_points_size = points_num;
  points_downsampler_info_msg.filtered_points_size = std::min((int)filtered_scan_ptr-&gt;size(), points_num);
  points_downsampler_info_msg.original_ring_size = 0;
  points_downsampler_info_msg.original_ring_size = 0;
  points_downsampler_info_msg.exe_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(filter_end - filter_start).count() / 1000.0;
  points_downsampler_info_pub.publish(points_downsampler_info_msg);

  if(_output_log == true){
	  if(!ofs){
		  std::cerr &lt;&lt; &quot;Could not open &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
		  exit(1);
	  }
	  ofs &lt;&lt; points_downsampler_info_msg.header.seq &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.header.stamp &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.header.frame_id &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filter_name &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.original_points_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filtered_points_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.original_ring_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filtered_ring_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.exe_time &lt;&lt; &quot;,&quot;
		  &lt;&lt; std::endl;
  }

}

int main(int argc, char** argv)
{
  ros::init(argc, argv, &quot;distance_filter&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  private_nh.getParam(&quot;points_topic&quot;, POINTS_TOPIC);
  private_nh.getParam(&quot;output_log&quot;, _output_log);
  if(_output_log == true){
	  char buffer[80];
	  std::time_t now = std::time(NULL);
	  std::tm *pnow = std::localtime(&amp;now);
	  std::strftime(buffer,80,&quot;%Y%m%d_%H%M%S&quot;,pnow);
	  filename = &quot;distance_filter_&quot; + std::string(buffer) + &quot;.csv&quot;;
	  ofs.open(filename.c_str(), std::ios::app);
  }

  // Publishers
  filtered_points_pub = nh.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/filtered_points&quot;, 10);
  points_downsampler_info_pub = nh.advertise&lt;points_downsampler::PointsDownsamplerInfo&gt;(&quot;/points_downsampler_info&quot;, 1000);

  // Subscribers
  ros::Subscriber config_sub = nh.subscribe(&quot;config/distance_filter&quot;, 10, config_callback);
  ros::Subscriber scan_sub = nh.subscribe(POINTS_TOPIC, 10, scan_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/sensing/filters/packages/points_downsampler/nodes/random_filter/random_filter.cpp" new_path="ros/src/sensing/filters/packages/points_downsampler/nodes/random_filter/random_filter.cpp">
				<diff>@@ -58,7 +58,7 @@ static std::ofstream ofs;
 static std::string filename;
 
 static std::string POINTS_TOPIC;
-static double measurement_range;
+static double measurement_range=100.0;
 
 static void config_callback(const runtime_manager::ConfigRandomFilter::ConstPtr&amp; input)
 {
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;

#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;

#include &lt;runtime_manager/ConfigRandomFilter.h&gt;

#include &lt;points_downsampler/PointsDownsamplerInfo.h&gt;

#include &lt;chrono&gt;

#include &quot;points_downsampler.h&quot;

#define MAX_MEASUREMENT_RANGE 200.0

ros::Publisher filtered_points_pub;

static int sample_num = 1000;

static ros::Publisher points_downsampler_info_pub;
static points_downsampler::PointsDownsamplerInfo points_downsampler_info_msg;

static std::chrono::time_point&lt;std::chrono::system_clock&gt; filter_start, filter_end;

static bool _output_log = false;
static std::ofstream ofs;
static std::string filename;

static std::string POINTS_TOPIC;
static double measurement_range;

static void config_callback(const runtime_manager::ConfigRandomFilter::ConstPtr&amp; input)
{
  sample_num = input-&gt;sample_num;
  measurement_range = input-&gt;measurement_range;
}

static void scan_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  pcl::PointXYZI sampled_p;
  pcl::PointCloud&lt;pcl::PointXYZI&gt; scan;

  pcl::fromROSMsg(*input, scan);

  if(measurement_range != MAX_MEASUREMENT_RANGE){
    scan = removePointsByRange(scan, 0, measurement_range);
  }

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());
  filtered_scan_ptr-&gt;header = scan.header;

  filter_start = std::chrono::system_clock::now();

  int points_num = scan.size();
  int step = points_num / sample_num;

  if(scan.points.size() &gt;= sample_num)
  {
    for (int i = 0; i &lt; points_num; i++)
    {
      if ((int)filtered_scan_ptr-&gt;size() &lt; sample_num &amp;&amp; i % step == 0)
      {
        filtered_scan_ptr-&gt;points.push_back(scan.at(i));
      }
    }
  }else{
    filtered_scan_ptr = scan.makeShared();
  }

  sensor_msgs::PointCloud2 filtered_msg;
  pcl::toROSMsg(*filtered_scan_ptr, filtered_msg);

  filter_end = std::chrono::system_clock::now();

  filtered_msg.header = input-&gt;header;
  filtered_points_pub.publish(filtered_msg);

  points_downsampler_info_msg.header = input-&gt;header;
  points_downsampler_info_msg.filter_name = &quot;random_filter&quot;;
  points_downsampler_info_msg.measurement_range = measurement_range;
  points_downsampler_info_msg.original_points_size = points_num;
  points_downsampler_info_msg.filtered_points_size = filtered_scan_ptr-&gt;size();
  points_downsampler_info_msg.original_ring_size = 0;
  points_downsampler_info_msg.filtered_ring_size = 0;
  points_downsampler_info_msg.exe_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(filter_end - filter_start).count() / 1000.0;
  points_downsampler_info_pub.publish(points_downsampler_info_msg);

  if(_output_log == true){
	  if(!ofs){
		  std::cerr &lt;&lt; &quot;Could not open &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
		  exit(1);
	  }
	  ofs &lt;&lt; points_downsampler_info_msg.header.seq &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.header.stamp &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.header.frame_id &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filter_name &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.original_points_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filtered_points_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.original_ring_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filtered_ring_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.exe_time &lt;&lt; &quot;,&quot;
		  &lt;&lt; std::endl;
  }

}

int main(int argc, char** argv)
{
  ros::init(argc, argv, &quot;random_filter&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  private_nh.getParam(&quot;points_topic&quot;, POINTS_TOPIC);
  private_nh.getParam(&quot;output_log&quot;, _output_log);
  if(_output_log == true){
	  char buffer[80];
	  std::time_t now = std::time(NULL);
	  std::tm *pnow = std::localtime(&amp;now);
	  std::strftime(buffer,80,&quot;%Y%m%d_%H%M%S&quot;,pnow);
	  filename = &quot;random_filter_&quot; + std::string(buffer) + &quot;.csv&quot;;
	  ofs.open(filename.c_str(), std::ios::app);
  }

  // Publishers
  filtered_points_pub = nh.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/filtered_points&quot;, 10);
  points_downsampler_info_pub = nh.advertise&lt;points_downsampler::PointsDownsamplerInfo&gt;(&quot;/points_downsampler_info&quot;, 1000);

  // Subscribers
  ros::Subscriber config_sub = nh.subscribe(&quot;config/random_filter&quot;, 10, config_callback);
  ros::Subscriber scan_sub = nh.subscribe(POINTS_TOPIC, 10, scan_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/sensing/filters/packages/points_downsampler/nodes/ring_filter/ring_filter.cpp" new_path="ros/src/sensing/filters/packages/points_downsampler/nodes/ring_filter/ring_filter.cpp">
				<diff>@@ -61,7 +61,7 @@ static std::ofstream ofs;
 static std::string filename;
 
 static std::string POINTS_TOPIC;
-static double measurement_range;
+static double measurement_range=100.0;
 
 static void config_callback(const runtime_manager::ConfigRingFilter::ConstPtr&amp; input)
 {
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;

#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;

#include &lt;velodyne_pointcloud/point_types.h&gt;

#include &lt;runtime_manager/ConfigRingFilter.h&gt;

#include &lt;points_downsampler/PointsDownsamplerInfo.h&gt;

#include &lt;chrono&gt;

ros::Publisher filtered_points_pub;

// Leaf size of VoxelGrid filter.
static double voxel_leaf_size = 2.0;

int ring_max = 0;
int ring_div = 3;

static ros::Publisher points_downsampler_info_pub;
static points_downsampler::PointsDownsamplerInfo points_downsampler_info_msg;

static std::chrono::time_point&lt;std::chrono::system_clock&gt; filter_start, filter_end;

static bool _output_log = false;
static std::ofstream ofs;
static std::string filename;

static std::string POINTS_TOPIC;
static double measurement_range;

static void config_callback(const runtime_manager::ConfigRingFilter::ConstPtr&amp; input)
{
  ring_div = input-&gt;ring_div;
  voxel_leaf_size = input-&gt;voxel_leaf_size;
  measurement_range = input-&gt;measurement_range;
}

static void scan_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  pcl::PointCloud&lt;pcl::PointXYZI&gt; scan;
  pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; tmp;
  sensor_msgs::PointCloud2 filtered_msg;

  pcl::fromROSMsg(*input, scan);
  pcl::fromROSMsg(*input, tmp);

  filter_start = std::chrono::system_clock::now();

  scan.points.clear();

  for (pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::const_iterator item = tmp.begin(); item != tmp.end(); item++)
  {
    pcl::PointXYZI p;
    p.x = item-&gt;x;
    p.y = item-&gt;y;
    p.z = item-&gt;z;
    p.intensity = item-&gt;intensity;

    double distance = sqrt(p.x * p.x + p.y * p.y);

    if (item-&gt;ring % ring_div == 0 &amp;&amp; distance &lt;= measurement_range)
    {
      scan.points.push_back(p);
    }
    if (item-&gt;ring &gt; ring_max)
    {
      ring_max = item-&gt;ring;
    }
  }

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(scan));
  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());

  // if voxel_leaf_size &lt; 0.1 voxel_grid_filter cannot down sample (It is specification in PCL)
  if (voxel_leaf_size &gt;= 0.1)
  {
    // Downsampling the velodyne scan using VoxelGrid filter
    pcl::VoxelGrid&lt;pcl::PointXYZI&gt; voxel_grid_filter;
    voxel_grid_filter.setLeafSize(voxel_leaf_size, voxel_leaf_size, voxel_leaf_size);
    voxel_grid_filter.setInputCloud(scan_ptr);
    voxel_grid_filter.filter(*filtered_scan_ptr);

    pcl::toROSMsg(*filtered_scan_ptr, filtered_msg);
  }
  else
  {
    pcl::toROSMsg(*scan_ptr, filtered_msg);
  }

  filter_end = std::chrono::system_clock::now();

  filtered_msg.header = input-&gt;header;
  filtered_points_pub.publish(filtered_msg);

  points_downsampler_info_msg.header = input-&gt;header;
  points_downsampler_info_msg.filter_name = &quot;ring_filter&quot;;
  points_downsampler_info_msg.measurement_range = measurement_range;
  points_downsampler_info_msg.original_points_size = scan.size();
  if (voxel_leaf_size &gt;= 0.1)
  {
    points_downsampler_info_msg.filtered_points_size = filtered_scan_ptr-&gt;size();
  }
  else
  {
    points_downsampler_info_msg.filtered_points_size = scan_ptr-&gt;size();
  }
  points_downsampler_info_msg.original_ring_size = ring_max;
  points_downsampler_info_msg.filtered_ring_size = ring_max / ring_div;
  points_downsampler_info_msg.exe_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(filter_end - filter_start).count() / 1000.0;
  points_downsampler_info_pub.publish(points_downsampler_info_msg);

  if(_output_log == true){
	  if(!ofs){
		  std::cerr &lt;&lt; &quot;Could not open &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
		  exit(1);
	  }
	  ofs &lt;&lt; points_downsampler_info_msg.header.seq &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.header.stamp &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.header.frame_id &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filter_name &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.original_points_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filtered_points_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.original_ring_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filtered_ring_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.exe_time &lt;&lt; &quot;,&quot;
		  &lt;&lt; std::endl;
  }

}

int main(int argc, char** argv)
{
  ros::init(argc, argv, &quot;ring_filter&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  private_nh.getParam(&quot;points_topic&quot;, POINTS_TOPIC);
  private_nh.getParam(&quot;output_log&quot;, _output_log);
  if(_output_log == true){
	  char buffer[80];
	  std::time_t now = std::time(NULL);
	  std::tm *pnow = std::localtime(&amp;now);
	  std::strftime(buffer,80,&quot;%Y%m%d_%H%M%S&quot;,pnow);
	  filename = &quot;ring_filter_&quot; + std::string(buffer) + &quot;.csv&quot;;
	  ofs.open(filename.c_str(), std::ios::app);
  }

  // Publishers
  filtered_points_pub = nh.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/filtered_points&quot;, 10);
  points_downsampler_info_pub = nh.advertise&lt;points_downsampler::PointsDownsamplerInfo&gt;(&quot;/points_downsampler_info&quot;, 1000);

  // Subscribers
  ros::Subscriber config_sub = nh.subscribe(&quot;config/ring_filter&quot;, 10, config_callback);
  ros::Subscriber scan_sub = nh.subscribe(POINTS_TOPIC, 10, scan_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/sensing/filters/packages/points_downsampler/nodes/voxel_grid_filter/voxel_grid_filter.cpp" new_path="ros/src/sensing/filters/packages/points_downsampler/nodes/voxel_grid_filter/voxel_grid_filter.cpp">
				<diff>@@ -60,7 +60,7 @@ static std::ofstream ofs;
 static std::string filename;
 
 static std::string POINTS_TOPIC;
-static double measurement_range;
+static double measurement_range=100.0;
 
 static void config_callback(const runtime_manager::ConfigVoxelGridFilter::ConstPtr&amp; input)
 {
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;

#include &lt;pcl/point_types.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;

#include &lt;runtime_manager/ConfigVoxelGridFilter.h&gt;

#include &lt;points_downsampler/PointsDownsamplerInfo.h&gt;

#include &lt;chrono&gt;

#include &quot;points_downsampler.h&quot;

#define MAX_MEASUREMENT_RANGE 200.0

ros::Publisher filtered_points_pub;

// Leaf size of VoxelGrid filter.
static double voxel_leaf_size = 2.0;

static ros::Publisher points_downsampler_info_pub;
static points_downsampler::PointsDownsamplerInfo points_downsampler_info_msg;

static std::chrono::time_point&lt;std::chrono::system_clock&gt; filter_start, filter_end;

static bool _output_log = false;
static std::ofstream ofs;
static std::string filename;

static std::string POINTS_TOPIC;
static double measurement_range;

static void config_callback(const runtime_manager::ConfigVoxelGridFilter::ConstPtr&amp; input)
{
  voxel_leaf_size = input-&gt;voxel_leaf_size;
  measurement_range = input-&gt;measurement_range;
}

static void scan_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; input)
{
  pcl::PointCloud&lt;pcl::PointXYZI&gt; scan;
  pcl::fromROSMsg(*input, scan);

  if(measurement_range != MAX_MEASUREMENT_RANGE){
    scan = removePointsByRange(scan, 0, measurement_range);
  }

  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;(scan));
  pcl::PointCloud&lt;pcl::PointXYZI&gt;::Ptr filtered_scan_ptr(new pcl::PointCloud&lt;pcl::PointXYZI&gt;());

  sensor_msgs::PointCloud2 filtered_msg;

  filter_start = std::chrono::system_clock::now();

  // if voxel_leaf_size &lt; 0.1 voxel_grid_filter cannot down sample (It is specification in PCL)
  if (voxel_leaf_size &gt;= 0.1)
  {
    // Downsampling the velodyne scan using VoxelGrid filter
    pcl::VoxelGrid&lt;pcl::PointXYZI&gt; voxel_grid_filter;
    voxel_grid_filter.setLeafSize(voxel_leaf_size, voxel_leaf_size, voxel_leaf_size);
    voxel_grid_filter.setInputCloud(scan_ptr);
    voxel_grid_filter.filter(*filtered_scan_ptr);
    pcl::toROSMsg(*filtered_scan_ptr, filtered_msg);
  }
  else
  {
    pcl::toROSMsg(*scan_ptr, filtered_msg);
  }

  filter_end = std::chrono::system_clock::now();

  filtered_msg.header = input-&gt;header;
  filtered_points_pub.publish(filtered_msg);

  points_downsampler_info_msg.header = input-&gt;header;
  points_downsampler_info_msg.filter_name = &quot;voxel_grid_filter&quot;;
  points_downsampler_info_msg.measurement_range = measurement_range;
  points_downsampler_info_msg.original_points_size = scan.size();
  if (voxel_leaf_size &gt;= 0.1)
  {
    points_downsampler_info_msg.filtered_points_size = filtered_scan_ptr-&gt;size();
  }
  else
  {
    points_downsampler_info_msg.filtered_points_size = scan_ptr-&gt;size();
  }
  points_downsampler_info_msg.original_ring_size = 0;
  points_downsampler_info_msg.filtered_ring_size = 0;
  points_downsampler_info_msg.exe_time = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(filter_end - filter_start).count() / 1000.0;
  points_downsampler_info_pub.publish(points_downsampler_info_msg);

  if(_output_log == true){
	  if(!ofs){
		  std::cerr &lt;&lt; &quot;Could not open &quot; &lt;&lt; filename &lt;&lt; &quot;.&quot; &lt;&lt; std::endl;
		  exit(1);
	  }
	  ofs &lt;&lt; points_downsampler_info_msg.header.seq &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.header.stamp &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.header.frame_id &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filter_name &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.original_points_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filtered_points_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.original_ring_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.filtered_ring_size &lt;&lt; &quot;,&quot;
		  &lt;&lt; points_downsampler_info_msg.exe_time &lt;&lt; &quot;,&quot;
		  &lt;&lt; std::endl;
  }

}

int main(int argc, char** argv)
{
  ros::init(argc, argv, &quot;voxel_grid_filter&quot;);

  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  private_nh.getParam(&quot;points_topic&quot;, POINTS_TOPIC);
  private_nh.getParam(&quot;output_log&quot;, _output_log);
  if(_output_log == true){
	  char buffer[80];
	  std::time_t now = std::time(NULL);
	  std::tm *pnow = std::localtime(&amp;now);
	  std::strftime(buffer,80,&quot;%Y%m%d_%H%M%S&quot;,pnow);
	  filename = &quot;voxel_grid_filter_&quot; + std::string(buffer) + &quot;.csv&quot;;
	  ofs.open(filename.c_str(), std::ios::app);
  }

  // Publishers
  filtered_points_pub = nh.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/filtered_points&quot;, 10);
  points_downsampler_info_pub = nh.advertise&lt;points_downsampler::PointsDownsamplerInfo&gt;(&quot;/points_downsampler_info&quot;, 1000);

  // Subscribers
  ros::Subscriber config_sub = nh.subscribe(&quot;config/voxel_grid_filter&quot;, 10, config_callback);
  ros::Subscriber scan_sub = nh.subscribe(POINTS_TOPIC, 10, scan_callback);

  ros::spin();

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="8a1bfeac01a2a0b93544d46f229c6716457b4af5" fix_time="11,52163">
		<msg>Add Error handring to removePointsByRange()</msg>
		<modified_files>
			<file old_path="ros/src/sensing/filters/packages/points_downsampler/include/points_downsampler.h" new_path="ros/src/sensing/filters/packages/points_downsampler/include/points_downsampler.h">
				<diff>@@ -5,6 +5,14 @@ static pcl::PointCloud&lt;pcl::PointXYZI&gt; removePointsByRange(pcl::PointCloud&lt;pcl::
 {
   pcl::PointCloud&lt;pcl::PointXYZI&gt; narrowed_scan;
   narrowed_scan.header = scan.header;
+
+#if 1     //  This error handling should be detemind.
+  if( min_range&gt;=max_range ) {
+    ROS_ERROR_ONCE(&quot;min_range&gt;=max_range @(%lf, %lf)&quot;, min_range, max_range );
+    return scan;
+  }
+#endif
+
   double square_min_range = min_range * min_range;
   double square_max_range = max_range * max_range;
 
@@ -21,11 +29,8 @@ static pcl::PointCloud&lt;pcl::PointXYZI&gt; removePointsByRange(pcl::PointCloud&lt;pcl::
       narrowed_scan.points.push_back(p);
     }
   }
-#if 1
+
   return narrowed_scan;
-#else
-  return scan;    //  This is a only tempolary patch for Localization problem.
-#endif
 }
 
 #endif // POINTS_DOWNSAMPLER_H
</diff>
				<old_file>#ifndef POINTS_DOWNSAMPLER_H
#define POINTS_DOWNSAMPLER_H

static pcl::PointCloud&lt;pcl::PointXYZI&gt; removePointsByRange(pcl::PointCloud&lt;pcl::PointXYZI&gt; scan, double min_range, double max_range)
{
  pcl::PointCloud&lt;pcl::PointXYZI&gt; narrowed_scan;
  narrowed_scan.header = scan.header;
  double square_min_range = min_range * min_range;
  double square_max_range = max_range * max_range;

  for(pcl::PointCloud&lt;pcl::PointXYZI&gt;::const_iterator iter = scan.begin(); iter != scan.end(); ++iter)
  {
    const pcl::PointXYZI &amp;p = *iter;
//    p.x = iter-&gt;x;
//    p.y = iter-&gt;y;
//    p.z = iter-&gt;z;
//    p.intensity = iter-&gt;intensity;
    double square_distance = p.x * p.x + p.y * p.y;

    if(square_min_range &lt;= square_distance &amp;&amp; square_distance &lt;= square_max_range){
      narrowed_scan.points.push_back(p);
    }
  }
#if 1
  return narrowed_scan;
#else
  return scan;    //  This is a only tempolary patch for Localization problem.
#endif
}

#endif // POINTS_DOWNSAMPLER_H
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="f51ad58499d70f7e8e26f9f758aba8d926df3ffc" fix_time="213,45342">
		<msg>fix build issues due to autoware_msgs</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/yolo2/src/darknet/yolo2.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/yolo2/src/darknet/yolo2.cpp">
				<diff>@@ -2,7 +2,6 @@
 
 #include &lt;image_transport/image_transport.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;cv_tracker_msgs/image_obj.h&gt;
 
 #include &lt;cstdint&gt;
 #include &lt;cstdlib&gt;
</diff>
				<old_file>#include &quot;darknet/yolo2.h&quot;

#include &lt;image_transport/image_transport.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_tracker_msgs/image_obj.h&gt;

#include &lt;cstdint&gt;
#include &lt;cstdlib&gt;
#include &lt;string&gt;
#include &lt;vector&gt;

#include &lt;rect_class_score.h&gt;

extern &quot;C&quot;
{
	#undef __cplusplus
		#include &quot;detection_layer.h&quot;
		#include &quot;parser.h&quot;
		#include &quot;region_layer.h&quot;
		#include &quot;utils.h&quot;
		#include &quot;image.h&quot;
	#define __cplusplus
}

namespace darknet
{
	uint32_t Yolo2Detector::get_network_height()
	{
		return darknet_network_.h;
	}
	uint32_t Yolo2Detector::get_network_width()
	{
		return darknet_network_.w;
	}
	void Yolo2Detector::load(std::string&amp; in_model_file, std::string&amp; in_trained_file, double in_min_confidence, double in_nms_threshold)
	{
		min_confidence_ = in_min_confidence;
		nms_threshold_ = in_nms_threshold;
		darknet_network_ = parse_network_cfg(&amp;in_model_file[0]);
		load_weights(&amp;darknet_network_, &amp;in_trained_file[0]);
		set_batch_network(&amp;darknet_network_, 1);

		layer output_layer = darknet_network_.layers[darknet_network_.n - 1];
		darknet_boxes_.resize(output_layer.w * output_layer.h * output_layer.n);
		darknet_box_scores_.resize(output_layer.w * output_layer.h * output_layer.n);
		float *probs_mem = static_cast&lt;float *&gt;(calloc(darknet_box_scores_.size() * output_layer.classes, sizeof(float)));
		for (auto&amp; i : darknet_box_scores_)
		{
			i = probs_mem;
			probs_mem += output_layer.classes;
		}
	}

	Yolo2Detector::~Yolo2Detector()
	{
		free(darknet_box_scores_[0]);
		free_network(darknet_network_);
	}

	std::vector&lt; RectClassScore&lt;float&gt; &gt; Yolo2Detector::detect(image&amp; in_darknet_image)
	{
		return forward(in_darknet_image);
	}

	image Yolo2Detector::convert_image(const sensor_msgs::ImageConstPtr&amp; msg)
	{
		if (msg-&gt;encoding != sensor_msgs::image_encodings::BGR8)
		{
			ROS_ERROR(&quot;Unsupported encoding&quot;);
			exit(-1);
		}

		auto data = msg-&gt;data;
		uint32_t height = msg-&gt;height, width = msg-&gt;width, offset = msg-&gt;step - 3 * width;
		uint32_t i = 0, j = 0;
		image im = make_image(width, height, 3);

		for (uint32_t line = height; line; line--)
		{
			for (uint32_t column = width; column; column--)
			{
				for (uint32_t channel = 0; channel &lt; 3; channel++)
					im.data[i + width * height * channel] = data[j++] / 255.;
				i++;
			}
			j += offset;
		}

		if (darknet_network_.w == (int) width &amp;&amp; darknet_network_.h == (int) height)
		{
			return im;
		}
		image resized = resize_image(im, darknet_network_.w, darknet_network_.h);
		free_image(im);
		return resized;
	}

	std::vector&lt; RectClassScore&lt;float&gt; &gt; Yolo2Detector::forward(image&amp; in_darknet_image)
	{
		float * in_data = in_darknet_image.data;
		float *prediction = network_predict(darknet_network_, in_data);
		layer output_layer = darknet_network_.layers[darknet_network_.n - 1];

		output_layer.output = prediction;
		if (output_layer.type == DETECTION)
			get_detection_boxes(output_layer, 1, 1, min_confidence_, darknet_box_scores_.data(), darknet_boxes_.data(), 0);
		else if (output_layer.type == REGION)
		{
			get_region_boxes(output_layer, in_darknet_image.w, in_darknet_image.h,
							darknet_network_.w, darknet_network_.h,
							min_confidence_, darknet_box_scores_.data(), darknet_boxes_.data(),
							0, 0, 0.5, 1);
		}
		else
			error(&quot;Last layer must produce detections\n&quot;);

		int num_classes = output_layer.classes;
		do_nms(darknet_boxes_.data(), darknet_box_scores_.data(), output_layer.w * output_layer.h * output_layer.n, num_classes, nms_threshold_);
		std::vector&lt; RectClassScore&lt;float&gt; &gt; detections;

		for (unsigned i = 0; i &lt; darknet_box_scores_.size(); i++)
		{
			int class_id = max_index(darknet_box_scores_[i], num_classes);
			float prob = darknet_box_scores_[i][class_id];
			//if (prob &gt; 0.3)
			{
				RectClassScore&lt;float&gt; detection;
				box b = darknet_boxes_[i];

				detection.x = b.x - b.w/2.;
				detection.y = b.y - b.h/2.;
				detection.w = b.w;
				detection.h = b.h;
				detection.score = prob;
				detection.class_type = class_id;
				//std::cout &lt;&lt; &quot;Box:&quot;  &lt;&lt;detection.toString() &lt;&lt; std::endl;

				detections.push_back(detection);
			}
		}
		return detections;
	}
}  // namespace darknet
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/yolo2/src/yolo2_node.cpp" new_path="ros/src/computing/perception/detection/packages/cv_tracker/nodes/yolo2/src/yolo2_node.cpp">
				<diff>@@ -1,11 +1,12 @@
 #include &lt;ros/ros.h&gt;
 #include &lt;image_transport/image_transport.h&gt;
-#include &lt;autoware_msgs/ConfigSsd.h&gt;
 #include &lt;sensor_msgs/Image.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
 
+#include &lt;autoware_msgs/ConfigSsd.h&gt;
 #include &lt;autoware_msgs/image_obj.h&gt;
 
+#include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;opencv2/opencv.hpp&gt;
 
 #if (CV_MAJOR_VERSION != 3)
@@ -13,7 +14,6 @@
 #endif
 #include &lt;opencv2/highgui/highgui.hpp&gt;
 
-#include &lt;cv_bridge/cv_bridge.h&gt;
 
 #include &lt;string&gt;
 #include &lt;vector&gt;
</diff>
				<old_file>#include &lt;ros/ros.h&gt;
#include &lt;image_transport/image_transport.h&gt;
#include &lt;autoware_msgs/ConfigSsd.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;

#include &lt;autoware_msgs/image_obj.h&gt;

#include &lt;opencv2/opencv.hpp&gt;

#if (CV_MAJOR_VERSION != 3)
#include &lt;opencv2/contrib/contrib.hpp&gt;
#endif
#include &lt;opencv2/highgui/highgui.hpp&gt;

#include &lt;cv_bridge/cv_bridge.h&gt;

#include &lt;string&gt;
#include &lt;vector&gt;

#include &lt;math.h&gt;
#include &lt;stdlib.h&gt;

#include &lt;rect_class_score.h&gt;

#include &quot;darknet/yolo2.h&quot;

namespace Yolo2
{
	enum YoloDetectorClasses//using coco for default cfg and weights
	{
		PERSON, BICYCLE, CAR, MOTORBIKE, AEROPLANE, BUS, TRAIN, TRUCK, BOAT, TRAFFIC_LIGHT,
		FIRE_HYDRANT, STOP_SIGN, PARKING_METER, BENCH, BIRD, CAT, DOG, HORSE, SHEEP, COW,
		ELEPHANT, BEAR, ZEBRA, GIRAFFE, BACKPACK, UMBRELLA, HANDBAG, TIE, SUITCASE, FRISBEE,
		SKIS, SNOWBOARD, SPORTS_BALL, KITE, BASEBALL_BAT, BASEBALL_GLOVE, SKATEBOARD, SURFBOARD, TENNIS_RACKET, BOTTLE,
		WINE_GLASS, CUP, FORK, KNIFE, SPOON, BOWL, BANANA, APPLE, SANDWICH, ORANGE,
		BROCCOLI, CARROT, HOT_DOG, PIZZA, DONUT, CAKE, CHAIR, SOFA, POTTEDPLANT, BED,
		DININGTABLE, TOILET, TVMONITOR, LAPTOP, MOUSE, REMOTE, KEYBOARD, CELL_PHONE, MICROWAVE, OVEN,
		TOASTER, SINK, REFRIGERATOR, BOOK, CLOCK, VASE, SCISSORS, TEDDY_BEAR, HAIR_DRIER, TOOTHBRUSH,
	};
}

class Yolo2DetectorNode
{
	ros::Subscriber subscriber_image_raw_;
	ros::Subscriber subscriber_yolo_config_;
	ros::Publisher publisher_car_objects_;
	ros::Publisher publisher_person_objects_;
	ros::NodeHandle node_handle_;

	darknet::Yolo2Detector yolo_detector_;

	image darknet_image = {};

	float score_threshold_;
	float nms_threshold_;
	double image_ratio_;//resdize ratio used to fit input image to network input size
	uint32_t image_top_bottom_border_;//black strips added to the input image to maintain aspect ratio while resizing it to fit the network input size
	uint32_t image_left_right_border_;

	void convert_rect_to_image_obj(std::vector&lt; RectClassScore&lt;float&gt; &gt;&amp; in_objects, autoware_msgs::image_obj&amp; out_message, std::string in_class)
	{
		for (unsigned int i = 0; i &lt; in_objects.size(); ++i)
		{
			if ( (in_objects[i].score &gt; score_threshold_)
				&amp;&amp; (	(in_class == &quot;car&quot;
							&amp;&amp; (in_objects[i].class_type == Yolo2::CAR
								|| in_objects[i].class_type == Yolo2::BUS
								|| in_objects[i].class_type == Yolo2::TRUCK
								|| in_objects[i].class_type == Yolo2::MOTORBIKE
								)
						)
					|| (in_class == &quot;person&quot;
							&amp;&amp; (in_objects[i].class_type == Yolo2::PERSON
								|| in_objects[i].class_type == Yolo2::BICYCLE
								|| in_objects[i].class_type == Yolo2::DOG
								|| in_objects[i].class_type == Yolo2::CAT
								|| in_objects[i].class_type == Yolo2::HORSE
								)
						)
					)
				)//check if the score is larger than minimum required
			{
				autoware_msgs::image_rect rect;

				rect.x = (in_objects[i].x * darknet_image.w /image_ratio_) - image_left_right_border_/image_ratio_;
				rect.y = (in_objects[i].y * darknet_image.h /image_ratio_) - image_top_bottom_border_/image_ratio_;
				rect.width = in_objects[i].w * darknet_image.w/image_ratio_;
				rect.height = in_objects[i].h * darknet_image.h/image_ratio_;
				if (in_objects[i].x &lt; 0)
					rect.x = 0;
				if (in_objects[i].y &lt; 0)
					rect.y = 0;
				if (in_objects[i].w &lt; 0)
					rect.width = 0;
				if (in_objects[i].h &lt; 0)
					rect.height = 0;

				rect.score = in_objects[i].score;

				//std::cout &lt;&lt; &quot;x &quot;&lt;&lt; rect.x&lt;&lt; &quot; y &quot; &lt;&lt; rect.y &lt;&lt; &quot; w &quot;&lt;&lt; rect.width &lt;&lt; &quot; h &quot;&lt;&lt; rect.height&lt;&lt; &quot; s &quot; &lt;&lt; rect.score &lt;&lt; &quot; c &quot; &lt;&lt; in_objects[i].class_type &lt;&lt; std::endl;

				out_message.obj.push_back(rect);

			}
		}
	}

	void rgbgr_image(image&amp; im)
	{
		int i;
		for(i = 0; i &lt; im.w*im.h; ++i)
		{
			float swap = im.data[i];
			im.data[i] = im.data[i+im.w*im.h*2];
			im.data[i+im.w*im.h*2] = swap;
		}
	}

	image convert_ipl_to_image(const sensor_msgs::ImageConstPtr&amp; msg)
	{
		cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(msg, &quot;bgr8&quot;);//toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
		cv::Mat mat_image = cv_image-&gt;image;

		uint32_t network_input_width = yolo_detector_.get_network_width();
		uint32_t network_input_height = yolo_detector_.get_network_height();

		uint32_t image_height = msg-&gt;height,
						image_width = msg-&gt;width;

		IplImage ipl_image;
		cv::Mat final_mat;

		//ROS_INFO(&quot;Before Network (%d,%d), Image (%d,%d)&quot;, network_input_width, network_input_height, image_width, image_height);
		if (network_input_width!=image_width
				|| network_input_height != image_height)
		{
			//final_mat = cv::Mat(network_input_width, network_input_height, CV_8UC3, cv::Scalar(0,0,0));
			image_ratio_ = (double ) network_input_width /  (double)mat_image.cols;
			//std::cout &lt;&lt; &quot;Ratio:&quot; &lt;&lt; image_ratio_ &lt;&lt; std::endl;

			cv::resize(mat_image, final_mat, cv::Size(), image_ratio_, image_ratio_);
			image_top_bottom_border_ = abs(final_mat.rows-network_input_height)/2;
			image_left_right_border_ = abs(final_mat.cols-network_input_width)/2;
			cv::copyMakeBorder(final_mat, final_mat,
								image_top_bottom_border_, image_top_bottom_border_,
								image_left_right_border_, image_left_right_border_,
								cv::BORDER_CONSTANT, cv::Scalar(0,0,0));

			/*
			 //CROP CENTER
			 * uint32_t crop_x, crop_y;
			crop_x = (image_width-network_input_width)/2;
			crop_y = (image_height-network_input_height)/2;
			cv::Rect center_crop(crop_x, crop_y, network_input_width, network_input_height);
			std::cout &lt;&lt; mat_image.cols &lt;&lt; &quot;, &quot; &lt;&lt; mat_image.rows &lt;&lt; std::endl;
			cv::Mat cropped_mat = mat_image(center_crop);
			cropped_mat.copyTo(final_mat);
			*/

			//VILE RESIZE
			//cv::resize(mat_image, final_mat, cv::Size(network_input_width, network_input_height));
		}
		else
			final_mat = mat_image;

		//ROS_INFO(&quot;After Network (%d,%d), Image (%d,%d)&quot;, network_input_width, network_input_height, final_mat.cols, final_mat.rows);

		ipl_image = final_mat;

		unsigned char *data = (unsigned char *)ipl_image.imageData;
		int h = ipl_image.height;
		int w = ipl_image.width;
		int c = ipl_image.nChannels;
		int step = ipl_image.widthStep;
		int i, j, k;

		image darknet_image = make_image(w, h, c);

		for(i = 0; i &lt; h; ++i){
			for(k= 0; k &lt; c; ++k){
				for(j = 0; j &lt; w; ++j){
					darknet_image.data[k*w*h + i*w + j] = data[i*step + j*c + k]/255.;
				}
			}
		}
		rgbgr_image(darknet_image);
		return darknet_image;
	}

	void image_callback(const sensor_msgs::ImageConstPtr&amp; in_image_message)
	{
		std::vector&lt; RectClassScore&lt;float&gt; &gt; detections;
		//darknet_image = yolo_detector_.convert_image(in_image_message);

		darknet_image = convert_ipl_to_image(in_image_message);

		detections = yolo_detector_.detect(darknet_image);

		//ROS_INFO(&quot;Detections: %ud&quot;, (unsigned int)detections.size());

		//Prepare Output message
		autoware_msgs::image_obj output_car_message;
		autoware_msgs::image_obj output_person_message;
		output_car_message.header = in_image_message-&gt;header;
		output_car_message.type = &quot;car&quot;;

		output_person_message.header = in_image_message-&gt;header;
		output_person_message.type = &quot;person&quot;;

		convert_rect_to_image_obj(detections, output_car_message, &quot;car&quot;);
		convert_rect_to_image_obj(detections, output_person_message, &quot;person&quot;);

		publisher_car_objects_.publish(output_car_message);
		publisher_person_objects_.publish(output_person_message);

		free(darknet_image.data);
	}

	void config_cb(const autoware_msgs::ConfigSsd::ConstPtr&amp; param)
	{
		score_threshold_ 	= param-&gt;score_threshold;
	}

public:
	void Run()
	{
		//ROS STUFF
		ros::NodeHandle private_node_handle(&quot;~&quot;);//to receive args

		//RECEIVE IMAGE TOPIC NAME
		std::string image_raw_topic_str;
		if (private_node_handle.getParam(&quot;image_raw_node&quot;, image_raw_topic_str))
		{
			ROS_INFO(&quot;Setting image node to %s&quot;, image_raw_topic_str.c_str());
		}
		else
		{
			ROS_INFO(&quot;No image node received, defaulting to /image_raw, you can use _image_raw_node:=YOUR_TOPIC&quot;);
			image_raw_topic_str = &quot;/image_raw&quot;;
		}

		std::string network_definition_file;
		std::string pretrained_model_file;
		if (private_node_handle.getParam(&quot;network_definition_file&quot;, network_definition_file))
		{
			ROS_INFO(&quot;Network Definition File (Config): %s&quot;, network_definition_file.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Network Definition File was received. Finishing execution.&quot;);
			return;
		}
		if (private_node_handle.getParam(&quot;pretrained_model_file&quot;, pretrained_model_file))
		{
			ROS_INFO(&quot;Pretrained Model File (Weights): %s&quot;, pretrained_model_file.c_str());
		}
		else
		{
			ROS_INFO(&quot;No Pretrained Model File was received. Finishing execution.&quot;);
			return;
		}

		if (private_node_handle.getParam(&quot;score_threshold&quot;, score_threshold_))
		{
			ROS_INFO(&quot;Score Threshold: %f&quot;, score_threshold_);
		}
		if (private_node_handle.getParam(&quot;nms_threshold&quot;, nms_threshold_))
		{
			ROS_INFO(&quot;NMS Threshold: %f&quot;, nms_threshold_);
		}

		ROS_INFO(&quot;Initializing Yolo2 on Darknet...&quot;);
		yolo_detector_.load(network_definition_file, pretrained_model_file, score_threshold_, nms_threshold_);
		ROS_INFO(&quot;Initialization complete.&quot;);

		publisher_car_objects_ = node_handle_.advertise&lt;autoware_msgs::image_obj&gt;(&quot;/obj_car/image_obj&quot;, 1);
		publisher_person_objects_ = node_handle_.advertise&lt;autoware_msgs::image_obj&gt;(&quot;/obj_person/image_obj&quot;, 1);

		ROS_INFO(&quot;Subscribing to... %s&quot;, image_raw_topic_str.c_str());
		subscriber_image_raw_ = node_handle_.subscribe(image_raw_topic_str, 1, &amp;Yolo2DetectorNode::image_callback, this);

		std::string config_topic(&quot;/config&quot;);
		config_topic += &quot;/yolo2&quot;;
		subscriber_yolo_config_ = node_handle_.subscribe(config_topic, 1, &amp;Yolo2DetectorNode::config_cb, this);

		ros::spin();
		ROS_INFO(&quot;END Yolo2&quot;);

	}
};

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;ssd_unc&quot;);

	Yolo2DetectorNode app;

	app.Run();

	return 0;
}

</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp">
				<diff>@@ -300,7 +300,7 @@ void keepLanePoints(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
 std::vector&lt;ClusterPtr&gt; clusterAndColorGpu(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
 											pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
 											jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
-											lidar_tracker::centroids&amp; in_out_centroids,
+											autoware_msgs::centroids&amp; in_out_centroids,
 											double in_max_cluster_distance=0.5)
 {
 	std::vector&lt;ClusterPtr&gt; clusters;
</diff>
				<old_file>#include &lt;ros/ros.h&gt;

#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/PCLPointCloud2.h&gt;
#include &lt;pcl/conversions.h&gt;
#include &lt;pcl_ros/transforms.h&gt;
#include &lt;pcl_ros/point_cloud.h&gt;

#include &lt;pcl/ModelCoefficients.h&gt;
#include &lt;pcl/point_types.h&gt;

#include &lt;pcl/filters/extract_indices.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;
#include &lt;pcl/filters/conditional_removal.h&gt;

#include &lt;pcl/features/normal_3d.h&gt;
#include &lt;pcl/features/normal_3d_omp.h&gt;
#include &lt;pcl/features/don.h&gt;
#include &lt;pcl/features/fpfh_omp.h&gt;

#include &lt;pcl/kdtree/kdtree.h&gt;

#include &lt;pcl/sample_consensus/method_types.h&gt;
#include &lt;pcl/sample_consensus/model_types.h&gt;

#include &lt;pcl/segmentation/sac_segmentation.h&gt;
#include &lt;pcl/segmentation/extract_clusters.h&gt;
#include &lt;pcl/segmentation/conditional_euclidean_clustering.h&gt;

#include &lt;pcl/common/common.h&gt;

#include &lt;pcl/search/organized.h&gt;
#include &lt;pcl/search/kdtree.h&gt;

#include &lt;pcl/segmentation/extract_clusters.h&gt;

#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;

#include &lt;std_msgs/Float32MultiArray.h&gt;
#include &lt;std_msgs/MultiArrayLayout.h&gt;
#include &lt;std_msgs/MultiArrayDimension.h&gt;

#include &quot;autoware_msgs/centroids.h&quot;
#include &quot;autoware_msgs/CloudCluster.h&quot;
#include &quot;autoware_msgs/CloudClusterArray.h&quot;

#include &lt;vector_map_server/PositionState.h&gt;

#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;
#include &lt;jsk_rviz_plugins/Pictogram.h&gt;
#include &lt;jsk_rviz_plugins/PictogramArray.h&gt;

#include &lt;tf/tf.h&gt;

#include &lt;limits&gt;
#include &lt;cmath&gt;

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/core/version.hpp&gt;
#if (CV_MAJOR_VERSION == 3)
#include &quot;gencolors.cpp&quot;
#else
#include &lt;opencv2/contrib/contrib.hpp&gt;
#endif

#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
#include &lt;sstream&gt;

#include &quot;Cluster.h&quot;

//#include &lt;vector_map/vector_map.h&gt;
//#include &lt;vector_map_server/GetSignal.h&gt;

#ifdef GPU_CLUSTERING
	#include &quot;gpu_euclidean_clustering.h&quot;
#endif

using namespace cv;

std::vector&lt;cv::Scalar&gt; _colors;
ros::Publisher _pub_cluster_cloud;
ros::Publisher _pub_ground_cloud;
ros::Publisher _centroid_pub;
ros::Publisher _marker_pub;
ros::Publisher _pub_clusters_message;
ros::Publisher _pub_text_pictogram;
visualization_msgs::Marker _visualization_marker;

ros::Publisher _pub_points_lanes_cloud;
ros::Publisher _pub_jsk_boundingboxes;
ros::Publisher _pub_jsk_hulls;

ros::ServiceClient _vectormap_server;

std_msgs::Header _velodyne_header;

pcl::PointCloud&lt;pcl::PointXYZ&gt; _sensor_cloud;

std::vector&lt;double&gt; _clustering_thresholds;
std::vector&lt;double&gt; _clustering_distances;

tf::StampedTransform* _transform;
tf::StampedTransform* _velodyne_output_transform;
tf::TransformListener* _transform_listener;

std::string _output_frame;
std::string _vectormap_frame;
static bool _velodyne_transform_available;
static bool _downsample_cloud;
static bool _pose_estimation;
static double _leaf_size;
static int _cluster_size_min;
static int _cluster_size_max;

static bool _remove_ground;	//only ground

static bool _using_sensor_cloud;
static bool _use_diffnormals;
static bool _use_vector_map;

static double _clip_min_height;
static double _clip_max_height;

static bool _keep_lanes;
static double _keep_lane_left_distance;
static double _keep_lane_right_distance;

static double _max_boundingbox_side;
static double _remove_points_upto;
static double _cluster_merge_threshold;

static bool _use_gpu;
static std::chrono::system_clock::time_point _start, _end;

void transformBoundingBox(const jsk_recognition_msgs::BoundingBox&amp; in_boundingbox, jsk_recognition_msgs::BoundingBox&amp; out_boundingbox, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	geometry_msgs::PoseStamped pose_in, pose_out;
	pose_in.header = in_header;
	pose_in.pose = in_boundingbox.pose;
	try
	{
		_transform_listener-&gt;transformPose(in_target_frame, ros::Time(), pose_in, in_header.frame_id,  pose_out);
	}
	catch (tf::TransformException &amp;ex)
	{
		ROS_ERROR(&quot;transformBoundingBox: %s&quot;,ex.what());
	}
	out_boundingbox.pose = pose_out.pose;
	out_boundingbox.header = in_header;
	out_boundingbox.header.frame_id = in_target_frame;
	out_boundingbox.dimensions = in_boundingbox.dimensions;
	out_boundingbox.value = in_boundingbox.value;
	out_boundingbox.label = in_boundingbox.label;
}

void publishCloudClusters(const ros::Publisher* in_publisher, const autoware_msgs::CloudClusterArray&amp; in_clusters, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		autoware_msgs::CloudClusterArray clusters_transformed;
		clusters_transformed.header = in_header;
		clusters_transformed.header.frame_id = in_target_frame;
		for (auto i=in_clusters.clusters.begin(); i!= in_clusters.clusters.end(); i++)
		{
			autoware_msgs::CloudCluster cluster_transformed;
			cluster_transformed.header = in_header;
			try
			{
				_transform_listener-&gt;lookupTransform(in_target_frame, _velodyne_header.frame_id,
										ros::Time(), *_transform);
				pcl_ros::transformPointCloud(in_target_frame, *_transform, i-&gt;cloud, cluster_transformed.cloud);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;min_point, in_header.frame_id, cluster_transformed.min_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;max_point, in_header.frame_id, cluster_transformed.max_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;avg_point, in_header.frame_id, cluster_transformed.avg_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;centroid_point, in_header.frame_id, cluster_transformed.centroid_point);

				cluster_transformed.dimensions = i-&gt;dimensions;
				cluster_transformed.eigen_values = i-&gt;eigen_values;
				cluster_transformed.eigen_vectors = i-&gt;eigen_vectors;

				transformBoundingBox(i-&gt;bounding_box, cluster_transformed.bounding_box, in_target_frame, in_header);

				clusters_transformed.clusters.push_back(cluster_transformed);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCloudClusters: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(clusters_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_clusters);
	}
}

void publishCentroids(const ros::Publisher* in_publisher, const autoware_msgs::centroids&amp; in_centroids, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		autoware_msgs::centroids centroids_transformed;
		centroids_transformed.header = in_header;
		centroids_transformed.header.frame_id = in_target_frame;
		for (auto i=centroids_transformed.points.begin(); i!= centroids_transformed.points.end(); i++)
		{
			geometry_msgs::PointStamped centroid_in, centroid_out;
			centroid_in.header = in_header;
			centroid_in.point = *i;
			try
			{
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), centroid_in, in_header.frame_id, centroid_out);

				centroids_transformed.points.push_back(centroid_out.point);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCentroids: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(centroids_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_centroids);
	}
}

void publishBoundingBoxArray(const ros::Publisher* in_publisher, const jsk_recognition_msgs::BoundingBoxArray&amp; in_boundingbox_array, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		jsk_recognition_msgs::BoundingBoxArray boundingboxes_transformed;
		boundingboxes_transformed.header = in_header;
		boundingboxes_transformed.header.frame_id = in_target_frame;
		for (auto i=in_boundingbox_array.boxes.begin(); i!= in_boundingbox_array.boxes.end(); i++)
		{
			jsk_recognition_msgs::BoundingBox boundingbox_transformed;
			transformBoundingBox(*i, boundingbox_transformed, in_target_frame, in_header);
			boundingboxes_transformed.boxes.push_back(boundingbox_transformed);
		}
		in_publisher-&gt;publish(boundingboxes_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_boundingbox_array);
	}
}

void publishCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void publishColorCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void keepLanePoints(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
					pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr,
					float in_left_lane_threshold = 1.5,
					float in_right_lane_threshold = 1.5)
{
	pcl::PointIndices::Ptr far_indices (new pcl::PointIndices);
	for(unsigned int i=0; i&lt; in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x=in_cloud_ptr-&gt;points[i].x;
		current_point.y=in_cloud_ptr-&gt;points[i].y;
		current_point.z=in_cloud_ptr-&gt;points[i].z;

		if (
				current_point.y &gt; (in_left_lane_threshold) || current_point.y &lt; -1.0*in_right_lane_threshold
			)
		{
			far_indices-&gt;indices.push_back(i);
		}
	}
	out_cloud_ptr-&gt;points.clear();
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(far_indices);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_cloud_ptr);
}

#ifdef GPU_CLUSTERING
std::vector&lt;ClusterPtr&gt; clusterAndColorGpu(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
											pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
											jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
											lidar_tracker::centroids&amp; in_out_centroids,
											double in_max_cluster_distance=0.5)
{
	std::vector&lt;ClusterPtr&gt; clusters;

	//Convert input point cloud to vectors of x, y, and z

	int size = in_cloud_ptr-&gt;points.size();

	if (size == 0)
		return clusters;

	float *tmp_x, *tmp_y, *tmp_z;

	tmp_x = (float *)malloc(sizeof(float) * size);
	tmp_y = (float *)malloc(sizeof(float) * size);
	tmp_z = (float *)malloc(sizeof(float) * size);

	for (int i = 0; i &lt; size; i++) {
		pcl::PointXYZ tmp_point = in_cloud_ptr-&gt;at(i);

		tmp_x[i] = tmp_point.x;
		tmp_y[i] = tmp_point.y;
		tmp_z[i] = tmp_point.z;
	}

	GpuEuclideanCluster gecl_cluster;

	gecl_cluster.setInputPoints(tmp_x, tmp_y, tmp_z, size);
	gecl_cluster.setThreshold(in_max_cluster_distance);
	gecl_cluster.setMinClusterPts (_cluster_size_min);
	gecl_cluster.setMaxClusterPts (_cluster_size_max);
	gecl_cluster.extractClusters();
	std::vector&lt;GpuEuclideanCluster::GClusterIndex&gt; cluster_indices = gecl_cluster.getOutput();

	unsigned int k = 0;

	for (auto it = cluster_indices.begin(); it != cluster_indices.end(); it++)
	{
		ClusterPtr cluster(new Cluster());
		cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;points_in_cluster, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		clusters.push_back(cluster);

		k++;
	}

	free(tmp_x);
	free(tmp_y);
	free(tmp_z);

	return clusters;
}
#endif

std::vector&lt;ClusterPtr&gt; clusterAndColor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		autoware_msgs::centroids&amp; in_out_centroids,
		double in_max_cluster_distance=0.5)
{
	pcl::search::KdTree&lt;pcl::PointXYZ&gt;::Ptr tree (new pcl::search::KdTree&lt;pcl::PointXYZ&gt;);

	//create 2d pc
	pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud_2d(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
	pcl::copyPointCloud(*in_cloud_ptr, *cloud_2d);
	//make it flat
	for (size_t i=0; i&lt;cloud_2d-&gt;points.size(); i++)
	{
		cloud_2d-&gt;points[i].z = 0;
	}

	if (cloud_2d-&gt;points.size() &gt; 0)
		tree-&gt;setInputCloud (cloud_2d);

	std::vector&lt;pcl::PointIndices&gt; cluster_indices;

	//perform clustering on 2d cloud
	pcl::EuclideanClusterExtraction&lt;pcl::PointXYZ&gt; ec;
	ec.setClusterTolerance (in_max_cluster_distance); //
	ec.setMinClusterSize (_cluster_size_min);
	ec.setMaxClusterSize (_cluster_size_max);
	ec.setSearchMethod(tree);
	ec.setInputCloud (cloud_2d);
	ec.extract (cluster_indices);
	//use indices on 3d cloud

	/*pcl::ConditionalEuclideanClustering&lt;pcl::PointXYZ&gt; cec (true);
	cec.setInputCloud (in_cloud_ptr);
	cec.setConditionFunction (&amp;independentDistance);
	cec.setMinClusterSize (cluster_size_min);
	cec.setMaxClusterSize (cluster_size_max);
	cec.setClusterTolerance (_distance*2.0f);
	cec.segment (cluster_indices);*/

	/////////////////////////////////
	//---	3. Color clustered points
	/////////////////////////////////
	unsigned int k = 0;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr final_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

	std::vector&lt;ClusterPtr&gt; clusters;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr cloud_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);//coord + color cluster
	for (auto it = cluster_indices.begin(); it != cluster_indices.end(); ++it)
	{
		ClusterPtr cluster(new Cluster());
		cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;indices, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		clusters.push_back(cluster);

		k++;
	}
	//std::cout &lt;&lt; &quot;Clusters: &quot; &lt;&lt; k &lt;&lt; std::endl;
	return clusters;

}

void checkClusterMerge(size_t in_cluster_id, std::vector&lt;ClusterPtr&gt;&amp; in_clusters, std::vector&lt;bool&gt;&amp; in_out_visited_clusters, std::vector&lt;size_t&gt;&amp; out_merge_indices, double in_merge_threshold)
{
	//std::cout &lt;&lt; &quot;checkClusterMerge&quot; &lt;&lt; std::endl;
	pcl::PointXYZ point_a = in_clusters[in_cluster_id]-&gt;GetCentroid();
	for(size_t i=0; i&lt; in_clusters.size(); i++)
	{
		if (i != in_cluster_id &amp;&amp; !in_out_visited_clusters[i])
		{
			pcl::PointXYZ point_b = in_clusters[i]-&gt;GetCentroid();
			double distance = sqrt( pow(point_b.x - point_a.x,2) + pow(point_b.y - point_a.y,2) );
			if (distance &lt;= in_merge_threshold)
			{
				in_out_visited_clusters[i] = true;
				out_merge_indices.push_back(i);
				//std::cout &lt;&lt; &quot;Merging &quot; &lt;&lt; in_cluster_id &lt;&lt; &quot; with &quot; &lt;&lt; i &lt;&lt; &quot; dist:&quot; &lt;&lt; distance &lt;&lt; std::endl;
				checkClusterMerge(i, in_clusters, in_out_visited_clusters, out_merge_indices, in_merge_threshold);
			}
		}
	}
}

void mergeClusters(const std::vector&lt;ClusterPtr&gt;&amp; in_clusters, std::vector&lt;ClusterPtr&gt;&amp; out_clusters, std::vector&lt;size_t&gt; in_merge_indices, const size_t&amp; current_index, std::vector&lt;bool&gt;&amp; in_out_merged_clusters)
{
	//std::cout &lt;&lt; &quot;mergeClusters:&quot; &lt;&lt; in_merge_indices.size() &lt;&lt; std::endl;
	pcl::PointCloud&lt;pcl::PointXYZRGB&gt; sum_cloud;
	pcl::PointCloud&lt;pcl::PointXYZ&gt; mono_cloud;
	ClusterPtr merged_cluster(new Cluster());
	for (size_t i=0; i&lt;in_merge_indices.size(); i++)
	{
		sum_cloud += *(in_clusters[in_merge_indices[i]]-&gt;GetCloud());
		in_out_merged_clusters[in_merge_indices[i]] = true;
	}
	std::vector&lt;int&gt; indices(sum_cloud.points.size(), 0);
	for (size_t i=0; i&lt;sum_cloud.points.size(); i++)
	{
		indices[i]=i;
	}

	if (sum_cloud.points.size() &gt; 0)
	{
		pcl::copyPointCloud(sum_cloud, mono_cloud);
		//std::cout &lt;&lt; &quot;mergedClusters &quot; &lt;&lt; sum_cloud.points.size() &lt;&lt; &quot; mono:&quot; &lt;&lt; mono_cloud.points.size() &lt;&lt; std::endl;
		//cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;indices, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		merged_cluster-&gt;SetCloud(mono_cloud.makeShared(), indices, _velodyne_header, current_index,(int)_colors[current_index].val[0], (int)_colors[current_index].val[1], (int)_colors[current_index].val[2], &quot;&quot;, _pose_estimation);
		out_clusters.push_back(merged_cluster);
	}
}

void checkAllForMerge(std::vector&lt;ClusterPtr&gt;&amp; in_clusters, std::vector&lt;ClusterPtr&gt;&amp; out_clusters, float in_merge_threshold)
{
	//std::cout &lt;&lt; &quot;checkAllForMerge&quot; &lt;&lt; std::endl;
	std::vector&lt;bool&gt; visited_clusters(in_clusters.size(), false);
	std::vector&lt;bool&gt; merged_clusters(in_clusters.size(), false);
	size_t current_index=0;
	for (size_t i = 0; i&lt; in_clusters.size(); i++)
	{
		if (!visited_clusters[i])
		{
			visited_clusters[i] = true;
			std::vector&lt;size_t&gt; merge_indices;
			checkClusterMerge(i, in_clusters, visited_clusters, merge_indices, in_merge_threshold);
			mergeClusters(in_clusters, out_clusters, merge_indices, current_index++, merged_clusters);
		}
	}
	for(size_t i =0; i&lt; in_clusters.size(); i++)
	{
		//check for clusters not merged, add them to the output
		if (!merged_clusters[i])
		{
			out_clusters.push_back(in_clusters[i]);
		}
	}

	//ClusterPtr cluster(new Cluster());
}

void segmentByDistance(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		autoware_msgs::centroids&amp; in_out_centroids,
		autoware_msgs::CloudClusterArray&amp; in_out_clusters,
		jsk_recognition_msgs::PolygonArray&amp; in_out_polygon_array,
		jsk_rviz_plugins::PictogramArray&amp; in_out_pictogram_array)
{
	//cluster the pointcloud according to the distance of the points using different thresholds (not only one for the entire pc)
	//in this way, the points farther in the pc will also be clustered

	//0 =&gt; 0-15m d=0.5
	//1 =&gt; 15-30 d=1
	//2 =&gt; 30-45 d=1.6
	//3 =&gt; 45-60 d=2.1
	//4 =&gt; &gt;60   d=2.6

	std::vector&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr&gt; cloud_segments_array(5);

	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr tmp_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		cloud_segments_array[i] = tmp_cloud;
	}

	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x = in_cloud_ptr-&gt;points[i].x;
		current_point.y = in_cloud_ptr-&gt;points[i].y;
		current_point.z = in_cloud_ptr-&gt;points[i].z;

		float origin_distance = sqrt( pow(current_point.x,2) + pow(current_point.y,2) );

		if 		(origin_distance &lt; _clustering_distances[0] )	{cloud_segments_array[0]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[1])		{cloud_segments_array[1]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[2])		{cloud_segments_array[2]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[3])		{cloud_segments_array[3]-&gt;points.push_back (current_point);}
		else													{cloud_segments_array[4]-&gt;points.push_back (current_point);}
	}

	std::vector &lt;ClusterPtr&gt; all_clusters;
	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
#ifdef GPU_CLUSTERING
    std::vector&lt;ClusterPtr&gt; local_clusters;
		if (_use_gpu) {
			local_clusters = clusterAndColorGpu(cloud_segments_array[i], out_cloud_ptr, in_out_boundingbox_array, in_out_centroids, _clustering_thresholds[i]);
		} else {
			local_clusters = clusterAndColor(cloud_segments_array[i], out_cloud_ptr, in_out_boundingbox_array, in_out_centroids, _clustering_thresholds[i]);
		}
#else
		std::vector&lt;ClusterPtr&gt; local_clusters = clusterAndColor(cloud_segments_array[i], out_cloud_ptr, in_out_boundingbox_array, in_out_centroids, _clustering_thresholds[i]);
#endif
		all_clusters.insert(all_clusters.end(), local_clusters.begin(), local_clusters.end());
	}

	//Clusters can be merged or checked in here
	//....
	//check for mergable clusters
	std::vector&lt;ClusterPtr&gt; mid_clusters;
	std::vector&lt;ClusterPtr&gt; final_clusters;

	if (all_clusters.size() &gt; 0)
		checkAllForMerge(all_clusters, mid_clusters, _cluster_merge_threshold);
	else
		mid_clusters = all_clusters;

	if (mid_clusters.size() &gt; 0)
			checkAllForMerge(mid_clusters, final_clusters, _cluster_merge_threshold);
	else
		final_clusters = mid_clusters;

	tf::StampedTransform vectormap_transform;
	if (_use_vector_map)
	{
		cv::TickMeter timer;

		try
		{
			//if the frame of the vectormap is different than the input, obtain transform
			if (_vectormap_frame != _velodyne_header.frame_id)
			{
				_transform_listener-&gt;lookupTransform(_vectormap_frame, _velodyne_header.frame_id, ros::Time(), vectormap_transform);
			}

			timer.reset();timer.start();

			//check if centroids are inside the drivable area
			for(unsigned int i=0; i&lt;final_clusters.size(); i++)
			{
				//transform centroid points to vectormap frame
				pcl::PointXYZ pcl_centroid = final_clusters[i]-&gt;GetCentroid();
				tf::Vector3 vector_centroid (pcl_centroid.x, pcl_centroid.y, pcl_centroid.z);
				tf::Vector3 transformed_centroid;

				if (_vectormap_frame != _velodyne_header.frame_id)
					transformed_centroid = vectormap_transform*vector_centroid;
				else
					transformed_centroid = vector_centroid;

				vector_map_server::PositionState position_state;
				position_state.request.position.x = transformed_centroid.getX();
				position_state.request.position.y = transformed_centroid.getY();
				position_state.request.position.z = transformed_centroid.getZ();


				if (_vectormap_server.call(position_state))
				{
					final_clusters[i]-&gt;SetValidity(position_state.response.state);
					/*std::cout &lt;&lt; &quot;Original:&quot; &lt;&lt; pcl_centroid.x &lt;&lt; &quot;,&quot; &lt;&lt; pcl_centroid.y &lt;&lt; &quot;,&quot; &lt;&lt; pcl_centroid.z &lt;&lt;
							&quot; Transformed:&quot; &lt;&lt; transformed_centroid.x() &lt;&lt; &quot;,&quot; &lt;&lt; transformed_centroid.y() &lt;&lt; &quot;,&quot; &lt;&lt; transformed_centroid.z() &lt;&lt;
							&quot; Validity:&quot; &lt;&lt; position_state.response.state &lt;&lt; std::endl;*/
				}
				else
				{
					ROS_INFO(&quot;vectormap_filtering: VectorMap Server Call failed. Make sure vectormap_server is running. No filtering performed.&quot;);
					final_clusters[i]-&gt;SetValidity(true);
				}
			}
			timer.stop();
			//std::cout &lt;&lt; &quot;vm server took &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot; ms to check &quot; &lt;&lt; final_clusters.size() &lt;&lt; std::endl;
		}
		catch(tf::TransformException &amp;ex)
		{
			ROS_INFO(&quot;vectormap_filtering: %s&quot;, ex.what());
		}
	}
	//Get final PointCloud to be published
	in_out_polygon_array.header = _velodyne_header;
	in_out_pictogram_array.header = _velodyne_header;
	for(unsigned int i=0; i&lt;final_clusters.size(); i++)
	{
		*out_cloud_ptr = *out_cloud_ptr + *(final_clusters[i]-&gt;GetCloud());

		jsk_recognition_msgs::BoundingBox bounding_box = final_clusters[i]-&gt;GetBoundingBox();
		geometry_msgs::PolygonStamped polygon = final_clusters[i]-&gt;GetPolygon();
		jsk_rviz_plugins::Pictogram pictogram_cluster;
		pictogram_cluster.header = _velodyne_header;

		//PICTO
		pictogram_cluster.mode = pictogram_cluster.STRING_MODE;
		pictogram_cluster.pose.position.x = final_clusters[i]-&gt;GetMaxPoint().x;
		pictogram_cluster.pose.position.y = final_clusters[i]-&gt;GetMaxPoint().y;
		pictogram_cluster.pose.position.z = final_clusters[i]-&gt;GetMaxPoint().z;
		tf::Quaternion quat(0.0, -0.7, 0.0, 0.7);
		tf::quaternionTFToMsg(quat, pictogram_cluster.pose.orientation);
		pictogram_cluster.size = 4;
		std_msgs::ColorRGBA color;
		color.a = 1; color.r = 1; color.g = 1; color.b = 1;
		pictogram_cluster.color = color;
		pictogram_cluster.character = std::to_string( i );
		//PICTO

		//pcl::PointXYZ min_point = final_clusters[i]-&gt;GetMinPoint();
		//pcl::PointXYZ max_point = final_clusters[i]-&gt;GetMaxPoint();
		pcl::PointXYZ center_point = final_clusters[i]-&gt;GetCentroid();
		geometry_msgs::Point centroid;
		centroid.x = center_point.x; centroid.y = center_point.y; centroid.z = center_point.z;
		bounding_box.header = _velodyne_header;
		polygon.header = _velodyne_header;

		if (	final_clusters[i]-&gt;IsValid()
				//&amp;&amp; bounding_box.dimensions.x &gt;0 &amp;&amp; bounding_box.dimensions.y &gt;0 &amp;&amp; bounding_box.dimensions.z &gt; 0
				//&amp;&amp;	bounding_box.dimensions.x &lt; _max_boundingbox_side &amp;&amp; bounding_box.dimensions.y &lt; _max_boundingbox_side
				)
		{
			in_out_boundingbox_array.boxes.push_back(bounding_box);
			in_out_centroids.points.push_back(centroid);
			_visualization_marker.points.push_back(centroid);

			in_out_polygon_array.polygons.push_back(polygon);
			in_out_pictogram_array.pictograms.push_back(pictogram_cluster);

			autoware_msgs::CloudCluster cloud_cluster;
			final_clusters[i]-&gt;ToRosMessage(_velodyne_header, cloud_cluster);
			in_out_clusters.clusters.push_back(cloud_cluster);
		}
	}

	for(size_t i=0; i&lt; in_out_polygon_array.polygons.size();i++)
	{
		in_out_polygon_array.labels.push_back(i);
	}

}

void removeFloor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_nofloor_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_onlyfloor_cloud_ptr, float in_max_height=0.2, float in_floor_max_angle=0.1)
{
	/*pcl::PointIndicesPtr ground (new pcl::PointIndices);
	// Create the filtering object
	pcl::ProgressiveMorphologicalFilter&lt;pcl::PointXYZ&gt; pmf;
	pmf.setInputCloud (in_cloud_ptr);
	pmf.setMaxWindowSize (20);
	pmf.setSlope (1.0f);
	pmf.setInitialDistance (0.5f);
	pmf.setMaxDistance (3.0f);
	pmf.extract (ground-&gt;indices);

	// Create the filtering object
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices (ground);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_nofloor_cloud_ptr);

	//EXTRACT THE FLOOR FROM THE CLOUD
	extract.setNegative(false);//true removes the indices, false leaves only the indices
	extract.filter(*out_onlyfloor_cloud_ptr);*/

	pcl::SACSegmentation&lt;pcl::PointXYZ&gt; seg;
	pcl::PointIndices::Ptr inliers (new pcl::PointIndices);
	pcl::ModelCoefficients::Ptr coefficients (new pcl::ModelCoefficients);

	seg.setOptimizeCoefficients (true);
	seg.setModelType(pcl::SACMODEL_PERPENDICULAR_PLANE);
	seg.setMethodType(pcl::SAC_RANSAC);
	seg.setMaxIterations(100);
	seg.setAxis(Eigen::Vector3f(0,0,1));
	seg.setEpsAngle(in_floor_max_angle);

	seg.setDistanceThreshold (in_max_height);//floor distance
	seg.setOptimizeCoefficients(true);
	seg.setInputCloud(in_cloud_ptr);
	seg.segment(*inliers, *coefficients);
	if (inliers-&gt;indices.size () == 0)
	{
		std::cout &lt;&lt; &quot;Could not estimate a planar model for the given dataset.&quot; &lt;&lt; std::endl;
	}

	//REMOVE THE FLOOR FROM THE CLOUD
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(inliers);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_nofloor_cloud_ptr);

	//EXTRACT THE FLOOR FROM THE CLOUD
	extract.setNegative(false);//true removes the indices, false leaves only the indices
	extract.filter(*out_onlyfloor_cloud_ptr);
}

void downsampleCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_leaf_size=0.2)
{
	pcl::VoxelGrid&lt;pcl::PointXYZ&gt; sor;
	sor.setInputCloud(in_cloud_ptr);
	sor.setLeafSize((float)in_leaf_size, (float)in_leaf_size, (float)in_leaf_size);
	sor.filter(*out_cloud_ptr);
}

void clipCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_min_height=-1.3, float in_max_height=0.5)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		if (in_cloud_ptr-&gt;points[i].z &gt;= in_min_height &amp;&amp;
				in_cloud_ptr-&gt;points[i].z &lt;= in_max_height)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void differenceNormalsSegmentation(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr)
{
	float small_scale=0.5;
	float large_scale=2.0;
	float angle_threshold=0.5;
	pcl::search::Search&lt;pcl::PointXYZ&gt;::Ptr tree;
	if (in_cloud_ptr-&gt;isOrganized ())
	{
		tree.reset (new pcl::search::OrganizedNeighbor&lt;pcl::PointXYZ&gt; ());
	}
	else
	{
		tree.reset (new pcl::search::KdTree&lt;pcl::PointXYZ&gt; (false));
	}

	// Set the input pointcloud for the search tree
	tree-&gt;setInputCloud (in_cloud_ptr);

	pcl::NormalEstimationOMP&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	//pcl::gpu::NormalEstimation&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	normal_estimation.setInputCloud (in_cloud_ptr);
	normal_estimation.setSearchMethod (tree);

	normal_estimation.setViewPoint (std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max ());

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_small_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_large_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	normal_estimation.setRadiusSearch (small_scale);
	normal_estimation.compute (*normals_small_scale);

	normal_estimation.setRadiusSearch (large_scale);
	normal_estimation.compute (*normals_large_scale);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::copyPointCloud&lt;pcl::PointXYZ, pcl::PointNormal&gt;(*in_cloud_ptr, *diffnormals_cloud);

	// Create DoN operator
	pcl::DifferenceOfNormalsEstimation&lt;pcl::PointXYZ, pcl::PointNormal, pcl::PointNormal&gt; diffnormals_estimator;
	diffnormals_estimator.setInputCloud (in_cloud_ptr);
	diffnormals_estimator.setNormalScaleLarge (normals_large_scale);
	diffnormals_estimator.setNormalScaleSmall (normals_small_scale);

	diffnormals_estimator.initCompute();

	diffnormals_estimator.computeFeature(*diffnormals_cloud);

	pcl::ConditionOr&lt;pcl::PointNormal&gt;::Ptr range_cond (new pcl::ConditionOr&lt;pcl::PointNormal&gt;() );
	range_cond-&gt;addComparison (pcl::FieldComparison&lt;pcl::PointNormal&gt;::ConstPtr (
			new pcl::FieldComparison&lt;pcl::PointNormal&gt; (&quot;curvature&quot;, pcl::ComparisonOps::GT, angle_threshold) )
			);
	// Build the filter
	pcl::ConditionalRemoval&lt;pcl::PointNormal&gt; cond_removal;
	cond_removal.setCondition(range_cond);
	cond_removal.setInputCloud (diffnormals_cloud);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud_filtered (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	// Apply filter
	cond_removal.filter (*diffnormals_cloud_filtered);

	pcl::copyPointCloud&lt;pcl::PointNormal, pcl::PointXYZ&gt;(*diffnormals_cloud, *out_cloud_ptr);
}

void removePointsUpTo(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, const double in_distance)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		float origin_distance = sqrt( pow(in_cloud_ptr-&gt;points[i].x,2) + pow(in_cloud_ptr-&gt;points[i].y,2) );
		if (origin_distance &gt; in_distance)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void velodyne_callback(const sensor_msgs::PointCloud2ConstPtr&amp; in_sensor_cloud)
{
	_start = std::chrono::system_clock::now(); // 計測開始時間

	if (!_using_sensor_cloud)
	{
		_using_sensor_cloud = true;

		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr current_sensor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr removed_points_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr downsampled_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr inlanes_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr nofloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr onlyfloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr diffnormals_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr clipped_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr colored_clustered_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

		autoware_msgs::centroids centroids;
		autoware_msgs::CloudClusterArray cloud_clusters;
		jsk_recognition_msgs::BoundingBoxArray boundingbox_array;
		jsk_recognition_msgs::PolygonArray polygon_array;
		jsk_rviz_plugins::PictogramArray pictograms_array;

		pcl::fromROSMsg(*in_sensor_cloud, *current_sensor_cloud_ptr);

		_velodyne_header = in_sensor_cloud-&gt;header;

		if (_remove_points_upto &gt; 0.0)
		{
			removePointsUpTo(current_sensor_cloud_ptr, removed_points_cloud_ptr, _remove_points_upto);
		}
		else
			removed_points_cloud_ptr = current_sensor_cloud_ptr;

		if (_downsample_cloud)
			downsampleCloud(removed_points_cloud_ptr, downsampled_cloud_ptr, _leaf_size);
		else
			downsampled_cloud_ptr =removed_points_cloud_ptr;

		clipCloud(downsampled_cloud_ptr, clipped_cloud_ptr, _clip_min_height, _clip_max_height);

		if(_keep_lanes)
			keepLanePoints(clipped_cloud_ptr, inlanes_cloud_ptr, _keep_lane_left_distance, _keep_lane_right_distance);
		else
			inlanes_cloud_ptr = clipped_cloud_ptr;

		if(_remove_ground)
		{
			removeFloor(inlanes_cloud_ptr, nofloor_cloud_ptr, onlyfloor_cloud_ptr);
			publishCloud(&amp;_pub_ground_cloud, onlyfloor_cloud_ptr);
		}
		else
			nofloor_cloud_ptr = inlanes_cloud_ptr;

		publishCloud(&amp;_pub_points_lanes_cloud, nofloor_cloud_ptr);

		if (_use_diffnormals)
			differenceNormalsSegmentation(nofloor_cloud_ptr, diffnormals_cloud_ptr);
		else
			diffnormals_cloud_ptr = nofloor_cloud_ptr;

		segmentByDistance(diffnormals_cloud_ptr, colored_clustered_cloud_ptr, boundingbox_array, centroids, cloud_clusters, polygon_array, pictograms_array);

		publishColorCloud(&amp;_pub_cluster_cloud, colored_clustered_cloud_ptr);

		// Publish BB
		boundingbox_array.header = _velodyne_header;

		_pub_jsk_hulls.publish(polygon_array);//publish convex hulls
		_pub_text_pictogram.publish(pictograms_array);//publish_ids

		publishBoundingBoxArray(&amp;_pub_jsk_boundingboxes, boundingbox_array, _output_frame, _velodyne_header);
		centroids.header = _velodyne_header;

		publishCentroids(&amp;_centroid_pub, centroids, _output_frame, _velodyne_header);

		_marker_pub.publish(_visualization_marker);
		_visualization_marker.points.clear();//transform? is it used?
		cloud_clusters.header = _velodyne_header;

		publishCloudClusters(&amp;_pub_clusters_message, cloud_clusters, _output_frame, _velodyne_header);

		_using_sensor_cloud = false;
	}
	_end = std::chrono::system_clock::now();  // 計測終了時間
  double elapsed = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(_end-_start).count(); //処理に要した時間をミリ秒に変換
  ROS_INFO(&quot;Euclidean Clustering : %f&quot;, elapsed);
}

/*
void vectormap_callback(const visualization_msgs::MarkerArray::Ptr in_vectormap_markers)
{
	float min_x=std::numeric_limits&lt;float&gt;::max();float max_x=-std::numeric_limits&lt;float&gt;::max();
	float min_y=std::numeric_limits&lt;float&gt;::max();float max_y=-std::numeric_limits&lt;float&gt;::max();
	pcl::PointXYZ min_point;
	pcl::PointXYZ max_point;
	std::vector&lt;geometry_msgs::Point&gt; vectormap_points;
	std::string marker_frame;
	double map_scale = -10.0;
	for(auto i=in_vectormap_markers-&gt;markers.begin(); i!= in_vectormap_markers-&gt;markers.end(); i++)
	{
		visualization_msgs::Marker current_marker = *i;
		marker_frame = current_marker.header.frame_id;
		if (current_marker.ns == &quot;road_edge&quot;)
		{
			for (unsigned int j=0; j&lt; current_marker.points.size(); j++)
			{
				geometry_msgs::Point p = current_marker.points[j];
				p.x*=map_scale;
				p.y*=map_scale;
				if(p.x&lt;min_x)	min_x = p.x;
				if(p.y&lt;min_y)	min_y = p.y;
				if(p.x&gt;max_x)	max_x = p.x;
				if(p.y&gt;max_y)	max_y = p.y;
				vectormap_points.push_back(p);
			}
		}
	}
	min_point.x = min_x;	min_point.y = min_y;
	max_point.x = max_x;	max_point.y = max_y;

	min_point.x*=-1.0;
	min_point.y*=-1.0;
	//translate the points to the minimum point
	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		(*i).x+=min_point.x;
		(*i).y+=min_point.y;
	}
	max_point.x+=min_point.x;
	max_point.y+=min_point.y;
	//get world tf
	std::string error_transform_msg;
	tf::Vector3 map_origin_point;
	if(_transform_listener-&gt;waitForTransform(&quot;/map&quot;, marker_frame, ros::Time(0), ros::Duration(5), ros::Duration(0.1), &amp;error_transform_msg))
	{
		_transform_listener-&gt;lookupTransform(&quot;/map&quot;, marker_frame, ros::Time(0), *_transform);
		map_origin_point = _transform-&gt;getOrigin();
		map_origin_point.setX( map_origin_point.x() - min_point.x);
		map_origin_point.setY( map_origin_point.y() - min_point.y);
	}
	else
	{
		ROS_INFO(&quot;Euclidean Cluster (vectormap_callback): %s&quot;, error_transform_msg.c_str());
	}

	cv::Mat map_image = cv::Mat::zeros(max_point.y, max_point.x, CV_8UC3);

	std::cout &lt;&lt; &quot;W,H:&quot; &lt;&lt; max_point &lt;&lt; std::endl;

	cv::Point image_start_point (vectormap_points[0].x, vectormap_points[0].y);
	cv::Point prev_point = image_start_point;
	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		cv::line(map_image, prev_point, cv::Point((int)(i-&gt;x), (int)(i-&gt;y)), cv::Scalar::all(255));

		prev_point.x = (int)(i-&gt;x);
		prev_point.y = (int)(i-&gt;y);
	}
	cv::circle(map_image, image_start_point, 3, cv::Scalar(255,0,0));
	cv::imshow(&quot;vectormap&quot;, map_image);
	cv::waitKey(0);
}*/

int main (int argc, char** argv)
{
	// Initialize ROS
	ros::init (argc, argv, &quot;euclidean_cluster&quot;);

	ros::NodeHandle h;
	ros::NodeHandle private_nh(&quot;~&quot;);

	tf::StampedTransform transform;
	tf::TransformListener listener;

	_transform = &amp;transform;
	_transform_listener = &amp;listener;

#if (CV_MAJOR_VERSION == 3)
	generateColors(_colors, 100);
#else
	cv::generateColors(_colors, 100);
#endif

	_pub_cluster_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_cluster&quot;,1);
	_pub_ground_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_ground&quot;,1);
	_centroid_pub = h.advertise&lt;autoware_msgs::centroids&gt;(&quot;/cluster_centroids&quot;,1);
	_marker_pub = h.advertise&lt;visualization_msgs::Marker&gt;(&quot;centroid_marker&quot;,1);

	_pub_points_lanes_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_lanes&quot;,1);
	_pub_jsk_boundingboxes = h.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(&quot;/bounding_boxes&quot;,1);
	_pub_jsk_hulls = h.advertise&lt;jsk_recognition_msgs::PolygonArray&gt;(&quot;/cluster_hulls&quot;,1);
	_pub_clusters_message = h.advertise&lt;autoware_msgs::CloudClusterArray&gt;(&quot;/cloud_clusters&quot;,1);
	_pub_text_pictogram = h.advertise&lt;jsk_rviz_plugins::PictogramArray&gt;(&quot;cluster_ids&quot;, 10); ROS_INFO(&quot;output pictograms topic: %s&quot;, &quot;cluster_id&quot;);

	std::string points_topic;

	_using_sensor_cloud = false;

	if (private_nh.getParam(&quot;points_node&quot;, points_topic))
	{
		ROS_INFO(&quot;euclidean_cluster &gt; Setting points node to %s&quot;, points_topic.c_str());
	}
	else
	{
		ROS_INFO(&quot;euclidean_cluster &gt; No points node received, defaulting to points_raw, you can use _points_node:=YOUR_TOPIC&quot;);
		points_topic = &quot;/points_raw&quot;;
	}

	_use_diffnormals = false;
	if (private_nh.getParam(&quot;use_diffnormals&quot;, _use_diffnormals))
	{
		if (_use_diffnormals)
			ROS_INFO(&quot;Euclidean Clustering: Applying difference of normals on clustering pipeline&quot;);
		else
			ROS_INFO(&quot;Euclidean Clustering: Difference of Normals will not be used.&quot;);
	}

	/* Initialize tuning parameter */
	private_nh.param(&quot;downsample_cloud&quot;, _downsample_cloud, false);	ROS_INFO(&quot;downsample_cloud: %d&quot;, _downsample_cloud);
	private_nh.param(&quot;remove_ground&quot;, _remove_ground, true);		ROS_INFO(&quot;remove_ground: %d&quot;, _remove_ground);
	private_nh.param(&quot;leaf_size&quot;, _leaf_size, 0.1);					ROS_INFO(&quot;leaf_size: %f&quot;, _leaf_size);
	private_nh.param(&quot;cluster_size_min&quot;, _cluster_size_min, 20);	ROS_INFO(&quot;cluster_size_min %d&quot;, _cluster_size_min);
	private_nh.param(&quot;cluster_size_max&quot;, _cluster_size_max, 100000);ROS_INFO(&quot;cluster_size_max: %d&quot;, _cluster_size_max);
	private_nh.param(&quot;pose_estimation&quot;, _pose_estimation, false);	ROS_INFO(&quot;pose_estimation: %d&quot;, _pose_estimation);
	private_nh.param(&quot;clip_min_height&quot;, _clip_min_height, -1.3);	ROS_INFO(&quot;clip_min_height: %f&quot;, _clip_min_height);
	private_nh.param(&quot;clip_max_height&quot;, _clip_max_height, 0.5);		ROS_INFO(&quot;clip_max_height: %f&quot;, _clip_max_height);
	private_nh.param(&quot;keep_lanes&quot;, _keep_lanes, false);				ROS_INFO(&quot;keep_lanes: %d&quot;, _keep_lanes);
	private_nh.param(&quot;keep_lane_left_distance&quot;, _keep_lane_left_distance, 5.0);		ROS_INFO(&quot;keep_lane_left_distance: %f&quot;, _keep_lane_left_distance);
	private_nh.param(&quot;keep_lane_right_distance&quot;, _keep_lane_right_distance, 5.0);	ROS_INFO(&quot;keep_lane_right_distance: %f&quot;, _keep_lane_right_distance);
	private_nh.param(&quot;clustering_thresholds&quot;, _clustering_thresholds);
	private_nh.param(&quot;clustering_distances&quot;, _clustering_distances);
	private_nh.param(&quot;max_boundingbox_side&quot;, _max_boundingbox_side, 10.0);				ROS_INFO(&quot;max_boundingbox_side: %f&quot;, _max_boundingbox_side);
	private_nh.param(&quot;cluster_merge_threshold&quot;, _cluster_merge_threshold, 1.5);			ROS_INFO(&quot;cluster_merge_threshold: %f&quot;, _cluster_merge_threshold);
	private_nh.param&lt;std::string&gt;(&quot;output_frame&quot;, _output_frame, &quot;velodyne&quot;);			ROS_INFO(&quot;output_frame: %s&quot;, _output_frame.c_str());

	private_nh.param(&quot;use_vector_map&quot;, _use_vector_map, false);							ROS_INFO(&quot;use_vector_map: %d&quot;, _use_vector_map);
	private_nh.param&lt;std::string&gt;(&quot;vectormap_frame&quot;, _vectormap_frame, &quot;map&quot;);			ROS_INFO(&quot;vectormap_frame: %s&quot;, _output_frame.c_str());

	private_nh.param(&quot;remove_points_upto&quot;, _remove_points_upto, 0.0);		ROS_INFO(&quot;remove_points_upto: %f&quot;, _remove_points_upto);

	private_nh.param(&quot;use_gpu&quot;, _use_gpu, false);				ROS_INFO(&quot;use_gpu: %d&quot;, _use_gpu);

	_velodyne_transform_available = false;

	if (_clustering_distances.size()!=4)
	{
		_clustering_distances = {15, 30, 45, 60};//maximum distance from sensor origin to separate segments
	}
	if (_clustering_thresholds.size()!=5)
	{
		_clustering_thresholds = {0.5, 1.1, 1.6, 2.1, 2.6};//Nearest neighbor distance threshold for each segment
	}

	std::cout &lt;&lt; &quot;_clustering_thresholds: &quot;; for (auto i = _clustering_thresholds.begin(); i != _clustering_thresholds.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt; std::endl;
	std::cout &lt;&lt; &quot;_clustering_distances: &quot;;for (auto i = _clustering_distances.begin(); i != _clustering_distances.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt;std::endl;

	// Create a ROS subscriber for the input point cloud
	ros::Subscriber sub = h.subscribe (points_topic, 1, velodyne_callback);
	//ros::Subscriber sub_vectormap = h.subscribe (&quot;vector_map&quot;, 1, vectormap_callback);
	_vectormap_server = h.serviceClient&lt;vector_map_server::PositionState&gt;(&quot;vector_map_server/is_way_area&quot;);

	_visualization_marker.header.frame_id = &quot;velodyne&quot;;
	_visualization_marker.header.stamp = ros::Time();
	_visualization_marker.ns = &quot;my_namespace&quot;;
	_visualization_marker.id = 0;
	_visualization_marker.type = visualization_msgs::Marker::SPHERE_LIST;
	_visualization_marker.action = visualization_msgs::Marker::ADD;
	_visualization_marker.scale.x = 1.0;
	_visualization_marker.scale.y = 1.0;
	_visualization_marker.scale.z = 1.0;
	_visualization_marker.color.a = 1.0;
	_visualization_marker.color.r = 0.0;
	_visualization_marker.color.g = 0.0;
	_visualization_marker.color.b = 1.0;
	// marker.lifetime = ros::Duration(0.1);
	_visualization_marker.frame_locked = true;

	// Spin
	ros::spin ();
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/include/Context.h" new_path="ros/src/computing/perception/detection/packages/road_wizard/include/Context.h">
				<diff>@@ -3,7 +3,7 @@
 
 #include &lt;vector&gt;
 #include &lt;opencv2/core/core.hpp&gt;
-#include &quot;road_wizard/Signals.h&quot;
+#include &lt;autoware_msgs/Signals.h&gt;
 
 enum LightState { GREEN, YELLOW, RED, UNDEFINED };
 
@@ -13,7 +13,7 @@ public:
 	Context(cv::Point aRedCenter, cv::Point aYellowCenter, cv::Point aGreenCenter,
 		int aLampRadius, cv::Point aTopLeft, cv::Point aBotRight);
         static void SetContexts(std::vector&lt;Context&gt; &amp;contexts, 
-                                const road_wizard::Signals::ConstPtr &amp;extracted_pos,
+                                const autoware_msgs::Signals::ConstPtr &amp;extracted_pos,
                                 const int frame_row,
                                 const int frame_colmuns);
 
</diff>
				<old_file>#ifndef CONTEXT_H
#define CONTEXT_H

#include &lt;vector&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &quot;road_wizard/Signals.h&quot;

enum LightState { GREEN, YELLOW, RED, UNDEFINED };

class Context {
public:
	Context(){};
	Context(cv::Point aRedCenter, cv::Point aYellowCenter, cv::Point aGreenCenter,
		int aLampRadius, cv::Point aTopLeft, cv::Point aBotRight);
        static void SetContexts(std::vector&lt;Context&gt; &amp;contexts, 
                                const road_wizard::Signals::ConstPtr &amp;extracted_pos,
                                const int frame_row,
                                const int frame_colmuns);

	cv::Point redCenter;
	cv::Point yellowCenter;
	cv::Point greenCenter;
	cv::Point3d redCenter3d;
	cv::Point3d yellowCenter3d;
	cv::Point3d greenCenter3d;
	int lampRadius;
	cv::Point topLeft;
	cv::Point botRight;
	LightState lightState;
	int signalID;
	int stateJudgeCount;

 private:
        static bool CompareContext(const Context left, const Context right);
};

#endif
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/lib/Context.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/lib/Context.cpp">
				<diff>@@ -23,15 +23,15 @@ bool Context::CompareContext(const Context left, const Context right)
 
 
 void Context::SetContexts(std::vector&lt;Context&gt; &amp;contexts,
-                          const road_wizard::Signals::ConstPtr &amp;extracted_pos,
+                          const autoware_msgs::Signals::ConstPtr &amp;extracted_pos,
                           const int frame_row,
                           const int frame_column) {
   /* copy parts of data to local variable */
-  std::vector&lt;road_wizard::ExtractedPosition&gt; signals;
-  std::vector&lt;road_wizard::ExtractedPosition&gt;::iterator sig_iterator;
+  std::vector&lt;autoware_msgs::ExtractedPosition&gt; signals;
+  std::vector&lt;autoware_msgs::ExtractedPosition&gt;::iterator sig_iterator;
   for (unsigned int i=0; i&lt;extracted_pos-&gt;Signals.size(); i++ )
     {
-      road_wizard::ExtractedPosition tmp;
+      autoware_msgs::ExtractedPosition tmp;
       tmp.signalId = extracted_pos-&gt;Signals.at(i).signalId;
       tmp.u        = extracted_pos-&gt;Signals.at(i).u;
       tmp.v        = extracted_pos-&gt;Signals.at(i).v;
</diff>
				<old_file>#include &quot;Context.h&quot;

Context::Context(cv::Point aRedCenter, cv::Point aYellowCenter, cv::Point aGreenCenter,
		 int aLampRadius, cv::Point aTopLeft, cv::Point aBotRight)
{
	redCenter = aRedCenter;
	yellowCenter = aYellowCenter;
	greenCenter = aGreenCenter;
	lampRadius = aLampRadius;
	topLeft = aTopLeft;
	botRight = aBotRight;
}


/*
  define magnitude relationship of context
 */
bool Context::CompareContext(const Context left, const Context right)
{
  /* if lampRadius is bigger, context is smaller */
  return left.lampRadius &gt;= right.lampRadius;
} /* static bool compareContext() */


void Context::SetContexts(std::vector&lt;Context&gt; &amp;contexts,
                          const road_wizard::Signals::ConstPtr &amp;extracted_pos,
                          const int frame_row,
                          const int frame_column) {
  /* copy parts of data to local variable */
  std::vector&lt;road_wizard::ExtractedPosition&gt; signals;
  std::vector&lt;road_wizard::ExtractedPosition&gt;::iterator sig_iterator;
  for (unsigned int i=0; i&lt;extracted_pos-&gt;Signals.size(); i++ )
    {
      road_wizard::ExtractedPosition tmp;
      tmp.signalId = extracted_pos-&gt;Signals.at(i).signalId;
      tmp.u        = extracted_pos-&gt;Signals.at(i).u;
      tmp.v        = extracted_pos-&gt;Signals.at(i).v;
      tmp.radius   = extracted_pos-&gt;Signals.at(i).radius;
      tmp.x        = extracted_pos-&gt;Signals.at(i).x;
      tmp.y        = extracted_pos-&gt;Signals.at(i).y;
      tmp.z        = extracted_pos-&gt;Signals.at(i).z;
      tmp.type     = extracted_pos-&gt;Signals.at(i).type;
      tmp.linkId   = extracted_pos-&gt;Signals.at(i).linkId;
      tmp.plId     = extracted_pos-&gt;Signals.at(i).plId;
      signals.push_back(tmp);
    }

  std::vector&lt;int&gt; plid_vector;
  for (sig_iterator=signals.begin(); sig_iterator&lt;signals.end(); sig_iterator++) {
    plid_vector.push_back(sig_iterator-&gt;plId);
  }

  /* get array that has unique PLID values as its element */
  std::sort(plid_vector.begin(), plid_vector.end());
  std::vector&lt;int&gt;::iterator new_end = std::unique(plid_vector.begin(), plid_vector.end());
  plid_vector.erase(new_end, plid_vector.end());

  std::vector&lt;Context&gt; updatedSignals;

  /* assemble fragmented signal lamp in a context */
  for (unsigned int ctx_idx=0; ctx_idx&lt;plid_vector.size(); ctx_idx++)
    {
      Context ctx;
      int min_radius  = INT_MAX;
      int most_left   = frame_column;
      int most_top    = frame_row;
      int most_right  = 0;
      int most_bottom = 0;

      for (sig_iterator=signals.begin(); sig_iterator&lt;signals.end(); sig_iterator++)
        {
          int img_x = sig_iterator-&gt;u;
          int img_y = sig_iterator-&gt;v;
          double map_x = sig_iterator-&gt;x;
          double map_y = sig_iterator-&gt;y;
          double map_z = sig_iterator-&gt;z;
          int radius = sig_iterator-&gt;radius;
          if (sig_iterator-&gt;plId == plid_vector.at(ctx_idx) &amp;&amp;
              0 &lt; img_x - radius - 1.5 * radius &amp;&amp; img_x + radius + 1.5 * radius &lt; frame_column &amp;&amp;
              0 &lt; img_y - radius - 1.5 * radius &amp;&amp; img_y + radius + 1.5 * radius &lt; frame_row)
            {
              switch (sig_iterator-&gt;type) {
              case 1:           /* RED */
                ctx.redCenter   = cv::Point( img_x, img_y );
                ctx.redCenter3d = cv::Point3d( map_x, map_y, map_z );
                break;
              case 2:           /* GREEN */
                ctx.greenCenter   = cv::Point( img_x, img_y );
                ctx.greenCenter3d = cv::Point3d( map_x, map_y, map_z );
                break;
              case 3:           /* YELLOW */
                ctx.yellowCenter   = cv::Point( img_x, img_y );
                ctx.yellowCenter3d = cv::Point3d( map_x, map_y, map_z );
                ctx.signalID       = sig_iterator-&gt;signalId; // use yellow light signalID as this context's representative
                break;
              default:          /* this signal is not for cars (for pedestrian or something) */
                continue;
              }
              min_radius    = (min_radius &gt; radius) ? radius : min_radius;
              most_left     = (most_left &gt; img_x - radius -   1.5 * min_radius)  ? img_x - radius - 1.5 * min_radius : most_left;
              most_top      = (most_top &gt; img_y - radius -    1.5 * min_radius)  ? img_y - radius - 1.5 * min_radius : most_top;
              most_right    = (most_right &lt; img_x + radius +  1.5 * min_radius)  ? img_x + radius + 1.5 * min_radius : most_right;
              most_bottom   = (most_bottom &lt; img_y + radius + 1.5 * min_radius)  ? img_y + radius + 1.5 * min_radius : most_bottom;
            }
        }

      ctx.lampRadius = min_radius;
      ctx.topLeft    = cv::Point(most_left, most_top);
      ctx.botRight   = cv::Point(most_right, most_bottom);
      ctx.lightState = UNDEFINED;
      ctx.stateJudgeCount = 0;

      /* search whether this signal has already belonged in detector.contexts */
      bool isInserted = false;
      std::vector&lt;int&gt; eraseCandidate;
      for (unsigned int i = 0; i &lt; contexts.size(); i++) {
        if (ctx.signalID == contexts.at(i).signalID &amp;&amp; ctx.lampRadius != INT_MAX)
          {
            /* update to new information except to lightState */
            updatedSignals.push_back(ctx);
            updatedSignals.back().lightState      = contexts.at(i).lightState;
            updatedSignals.back().stateJudgeCount = contexts.at(i).stateJudgeCount;
            isInserted = true;
            break;
          }

      }

      if (isInserted == false &amp;&amp; ctx.lampRadius != INT_MAX)
        updatedSignals.push_back(ctx); // this ctx is new in detector.contexts

    }

  /* sort by lampRadius */
  std::sort(updatedSignals.begin(), updatedSignals.end(), CompareContext);

  /* reset detector.contexts */
  contexts.clear();
  contexts.resize(updatedSignals.size());
  for (unsigned int i=0; i&lt;updatedSignals.size(); i++) {
    contexts.at(i) = updatedSignals.at(i);
  }

} /* std::vector&lt;Context&gt; Context::SetContexts() */
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/feat_proj/feat_proj.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/feat_proj/feat_proj.cpp">
				<diff>@@ -20,11 +20,11 @@
 #include &lt;cstdio&gt;
 #include &quot;Math.h&quot;
 #include &lt;Eigen/Eigen&gt;
-#include &quot;road_wizard/Signals.h&quot;
-#include &lt;runtime_manager/adjust_xy.h&gt;
+#include &lt;autoware_msgs/Signals.h&gt;
+#include &lt;autoware_msgs/adjust_xy.h&gt;
 #include &lt;vector_map/vector_map.h&gt;
 #include &lt;vector_map_server/GetSignal.h&gt;
-#include &lt;waypoint_follower_msgs/lane.h&gt;
+#include &lt;autoware_msgs/lane.h&gt;
 
 static std::string camera_id_str;
 
@@ -64,7 +64,7 @@ namespace
   {
   private:
     geometry_msgs::PoseStamped pose_;
-    waypoint_follower_msgs::lane waypoints_;
+    autoware_msgs::lane waypoints_;
 
   public:
     VectorMapClient()
@@ -78,7 +78,7 @@ namespace
       return pose_;
     }
 
-    waypoint_follower_msgs::lane waypoints() const
+    autoware_msgs::lane waypoints() const
     {
       return waypoints_;
     }
@@ -88,7 +88,7 @@ namespace
       pose_ = pose;
     }
 
-    void set_waypoints(const waypoint_follower_msgs::lane&amp; waypoints)
+    void set_waypoints(const autoware_msgs::lane&amp; waypoints)
     {
       waypoints_ = waypoints;
     }
@@ -98,7 +98,7 @@ static VectorMapClient g_vector_map_client;
 
 
 /* Callback function to shift projection result */
-void adjust_xyCallback (const runtime_manager::adjust_xy::ConstPtr&amp; config_msg)
+void adjust_xyCallback (const autoware_msgs::adjust_xy::ConstPtr&amp; config_msg)
 {
   adjust_proj_x = config_msg-&gt;x;
   adjust_proj_y = config_msg-&gt;y;
@@ -260,7 +260,7 @@ double GetSignalAngleInCameraSystem(double hang, double vang)
 void echoSignals2 (ros::Publisher &amp;pub, bool useOpenGLCoord=false)
 {
   int countPoint = 0;
-  road_wizard::Signals signalsInFrame;
+  autoware_msgs::Signals signalsInFrame;
 
   /* Get signals on the path if vecter_map_server is enabled */
   if (g_use_vector_map_server) {
@@ -308,7 +308,7 @@ void echoSignals2 (ros::Publisher &amp;pub, bool useOpenGLCoord=false)
       project2 (signalcenterx, ux, vx, useOpenGLCoord);
       radius = (int)distance (ux, vx, u, v);
 
-      road_wizard::ExtractedPosition sign;
+      autoware_msgs::ExtractedPosition sign;
       sign.signalId = signal.id;
 
       sign.u = u + adjust_proj_x; // shift project position by configuration value from runtime manager
@@ -420,7 +420,7 @@ int main (int argc, char *argv[])
     g_ros_client = rosnode.serviceClient&lt;vector_map_server::GetSignal&gt;(&quot;vector_map_server/get_signal&quot;);
   }
 
-  ros::Publisher  signalPublisher      = rosnode.advertise &lt;road_wizard::Signals&gt; (&quot;roi_signal&quot;, 100);
+  ros::Publisher  signalPublisher      = rosnode.advertise &lt;autoware_msgs::Signals&gt; (&quot;roi_signal&quot;, 100);
   signal (SIGINT, interrupt);
 
   Rate loop (25);
</diff>
				<old_file>/*
 * signals.cpp
 *
 *  Created on: Apr 9, 2015
 *      Author: sujiwo
 */


#include &lt;iostream&gt;
#include &lt;ros/ros.h&gt;
#include &quot;Rate.h&quot;
#include &quot;vector_map.h&quot;
#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;sensor_msgs/CameraInfo.h&gt;
#include &lt;geometry_msgs/TwistStamped.h&gt;
#include &lt;geometry_msgs/Pose.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;signal.h&gt;
#include &lt;cstdio&gt;
#include &quot;Math.h&quot;
#include &lt;Eigen/Eigen&gt;
#include &quot;road_wizard/Signals.h&quot;
#include &lt;runtime_manager/adjust_xy.h&gt;
#include &lt;vector_map/vector_map.h&gt;
#include &lt;vector_map_server/GetSignal.h&gt;
#include &lt;waypoint_follower_msgs/lane.h&gt;

static std::string camera_id_str;

static constexpr uint32_t SUBSCRIBE_QUEUE_SIZE = 1000;

static int adjust_proj_x = 0;
static int adjust_proj_y = 0;

typedef struct {
  double thiX;
  double thiY;
  double thiZ;
} Angle;

static VectorMap vmap;
static Angle cameraOrientation; // camera orientation = car's orientation

static Eigen::Vector3f position;
static Eigen::Quaternionf orientation;
static  float fx,
  fy,
  imageWidth,
  imageHeight,
  cx,
  cy;
static tf::StampedTransform trf;

static bool g_use_vector_map_server; // Switch flag whether vecter-map-server function will be used
static ros::ServiceClient g_ros_client;

#define SignalLampRadius 0.3

/* Define utility class to use vector map server */
namespace
{
  class VectorMapClient
  {
  private:
    geometry_msgs::PoseStamped pose_;
    waypoint_follower_msgs::lane waypoints_;

  public:
    VectorMapClient()
    {}

    ~VectorMapClient()
    {}

    geometry_msgs::PoseStamped pose() const
    {
      return pose_;
    }

    waypoint_follower_msgs::lane waypoints() const
    {
      return waypoints_;
    }

    void set_pose(const geometry_msgs::PoseStamped&amp; pose)
    {
      pose_ = pose;
    }

    void set_waypoints(const waypoint_follower_msgs::lane&amp; waypoints)
    {
      waypoints_ = waypoints;
    }
  }; // Class VectorMapClient
} // namespace
static VectorMapClient g_vector_map_client;


/* Callback function to shift projection result */
void adjust_xyCallback (const runtime_manager::adjust_xy::ConstPtr&amp; config_msg)
{
  adjust_proj_x = config_msg-&gt;x;
  adjust_proj_y = config_msg-&gt;y;
}

void cameraInfoCallback (const sensor_msgs::CameraInfo::ConstPtr camInfoMsg)
{
  fx = static_cast&lt;float&gt;(camInfoMsg-&gt;P[0]);
  fy = static_cast&lt;float&gt;(camInfoMsg-&gt;P[5]);
  imageWidth = camInfoMsg-&gt;width;
  imageHeight = camInfoMsg-&gt;height;
  cx = static_cast&lt;float&gt;(camInfoMsg-&gt;P[2]);
  cy = static_cast&lt;float&gt;(camInfoMsg-&gt;P[6]);
}


/* convert degree value into 0 to 360 range */
static double setDegree0to360(double val)
{
  if (val &lt; 0.0f) {
    return (val + 360.0f);
  }
  else if (360.0f &lt; val) {
    return (val - 360.0f);
  }

  return val;
}


static void get_cameraRollPitchYaw(double* roll,
                                   double* pitch,
                                   double* yaw)
{
  geometry_msgs::Pose cameraPose;
  cameraPose.position.x    = (double)(position.x());
  cameraPose.position.y    = (double)(position.y());
  cameraPose.position.z    = (double)(position.z());
  cameraPose.orientation.x = (double)(orientation.x());
  cameraPose.orientation.y = (double)(orientation.y());
  cameraPose.orientation.z = (double)(orientation.z());
  cameraPose.orientation.w = (double)(orientation.w());

  tf::Quaternion quat;

  tf::quaternionMsgToTF(cameraPose.orientation, quat);
  tf::Matrix3x3(quat).getRPY(*roll, *pitch, *yaw);

  /* convert from radian to degree */
  *roll  = setDegree0to360(*roll  * 180.0f / M_PI);
  *pitch = setDegree0to360(*pitch * 180.0f / M_PI);
  *yaw   = setDegree0to360(*yaw   * 180.0f / M_PI);
}


/*
  check if lower &lt; val &lt; upper
  This function also considers circulation
*/
static bool isRange(const double lower, const double upper, const double val)
{
  if (lower &lt;= upper) {
    if (lower &lt; val &amp;&amp; val &lt; upper) {
      return true;
    }
  }
  else {
    if (val &lt; upper || lower &lt; val) {
      return true;
    }
  }

  return false;
}


void getTransform (Eigen::Quaternionf &amp;ori, Point3 &amp;pos)
{
  static tf::TransformListener listener;

  // target_frame    source_frame
  ros::Time now = ros::Time();
  listener.waitForTransform (camera_id_str, &quot;map&quot;, now, ros::Duration(10.0));
  listener.lookupTransform (camera_id_str, &quot;map&quot;, now, trf);

  tf::Vector3 &amp;p = trf.getOrigin();
  tf::Quaternion o = trf.getRotation();
  pos.x()=p.x(); pos.y()=p.y(); pos.z()=p.z();
  ori.w()=o.w(); ori.x()=o.x(); ori.y()=o.y(); ori.z()=o.z();
}


Point3 transform (const Point3 &amp;psrc, tf::StampedTransform &amp;tfsource)
{
  tf::Vector3 pt3 (psrc.x(), psrc.y(), psrc.z());
  tf::Vector3 pt3s = tfsource * pt3;
  return Point3 (pt3s.x(), pt3s.y(), pt3s.z());
}


/*
 * Project a point from world coordinate to image plane
 */
bool project2 (const Point3 &amp;pt, int &amp;u, int &amp;v, bool useOpenGLCoord=false)
{
  float nearPlane = 1.0;
  float farPlane = 200.0;
  Point3 _pt = transform (pt, trf);
  float _u = _pt.x()*fx/_pt.z() + cx;
  float _v = _pt.y()*fy/_pt.z() + cy;

  u = static_cast&lt;int&gt;(_u);
  v = static_cast&lt;int&gt;(_v);
  if ( u &lt; 0 || imageWidth &lt; u || v &lt; 0 || imageHeight &lt; v || _pt.z() &lt; nearPlane || farPlane &lt; _pt.z() ) {
    u = -1, v = -1;
    return false;
  }

  if (useOpenGLCoord) {
    v = imageHeight - v;
  }

  return true;
}

double ConvertDegreeToRadian(double degree)
{
  return degree * M_PI / 180.0f;
}


double ConvertRadianToDegree(double radian)
{
  return radian * 180.0f / M_PI;
}


double GetSignalAngleInCameraSystem(double hang, double vang)
{
  // Fit the vector map format into ROS style
  double signal_pitch_in_map = ConvertDegreeToRadian(vang - 90);
  double signal_yaw_in_map   = ConvertDegreeToRadian(-hang + 90);

  tf::Quaternion signal_orientation_in_map_system;
  signal_orientation_in_map_system.setRPY(0, signal_pitch_in_map, signal_yaw_in_map);

  tf::Quaternion signal_orientation_in_cam_system = trf * signal_orientation_in_map_system;
  double signal_roll_in_cam;
  double signal_pitch_in_cam;
  double signal_yaw_in_cam;
  tf::Matrix3x3(signal_orientation_in_cam_system).getRPY(signal_roll_in_cam,
                                                         signal_pitch_in_cam,
                                                         signal_yaw_in_cam);

  return ConvertRadianToDegree(signal_pitch_in_cam);   // holizontal angle of camera is represented by pitch
}  // double GetSignalAngleInCameraSystem()


void echoSignals2 (ros::Publisher &amp;pub, bool useOpenGLCoord=false)
{
  int countPoint = 0;
  road_wizard::Signals signalsInFrame;

  /* Get signals on the path if vecter_map_server is enabled */
  if (g_use_vector_map_server) {
    vector_map_server::GetSignal service;
    /* Set server's request */
    service.request.pose = g_vector_map_client.pose();
    service.request.waypoints = g_vector_map_client.waypoints();

    /* Get server's response*/
    if (g_ros_client.call(service)) {
      /* Reset signal data container */
      vmap.signals.clear();

      /* Newle insert signal data on the path */
      for (const auto&amp; response: service.response.objects.data) {
        if (response.id == 0)
          continue;

        Signal signal;
        signal.id = response.id;
        signal.vid = response.vid;
        signal.plid = response.plid;
        signal.type = response.type;
        signal.linkid = response.linkid;

        vmap.signals.insert(std::map&lt;int, Signal&gt;::value_type(signal.id, signal));
      }
    }
  }

  for (unsigned int i=1; i&lt;=vmap.signals.size(); i++) {
    Signal signal = vmap.signals[i];
    int pid = vmap.vectors[signal.vid].pid;

    Point3 signalcenter = vmap.getPoint(pid);
    Point3 signalcenterx (signalcenter.x(), signalcenter.y(), signalcenter.z()+SignalLampRadius);

    int u, v;
    if (project2 (signalcenter, u, v, useOpenGLCoord) == true) {
      countPoint++;
      // std::cout &lt;&lt; u &lt;&lt; &quot;, &quot; &lt;&lt; v &lt;&lt; &quot;, &quot; &lt;&lt; std::endl;

      int radius;
      int ux, vx;
      project2 (signalcenterx, ux, vx, useOpenGLCoord);
      radius = (int)distance (ux, vx, u, v);

      road_wizard::ExtractedPosition sign;
      sign.signalId = signal.id;

      sign.u = u + adjust_proj_x; // shift project position by configuration value from runtime manager
      sign.v = v + adjust_proj_y; // shift project position by configuration value from runtime manager

      sign.radius = radius;
      sign.x = signalcenter.x(), sign.y = signalcenter.y(), sign.z = signalcenter.z();
      sign.hang = vmap.vectors[signal.vid].hang; // hang is expressed in [0, 360] degree
      sign.type = signal.type, sign.linkId = signal.linkid;
      sign.plId = signal.plid;

      // Get holizontal angle of signal in camera corrdinate system
      double signal_angle = GetSignalAngleInCameraSystem(vmap.vectors[signal.vid].hang + 180.0f,
                                                         vmap.vectors[signal.vid].vang + 180.0f);

      // signal_angle will be zero if signal faces to x-axis
      // Target signal should be face to -50 &lt;= z-axis (= 90 degree) &lt;= +50
      if (isRange(-50, 50, signal_angle - 90)) {
        signalsInFrame.Signals.push_back (sign);
      }
    }
  }

  signalsInFrame.header.stamp = ros::Time::now();
  pub.publish (signalsInFrame);

  // printf (&quot;There are %d out of %u signals in frame\n&quot;, countPoint, static_cast&lt;unsigned int&gt;(vmap.signals.size()));
}


void interrupt (int s)
{
  ros::shutdown();
  exit(1);
}


int main (int argc, char *argv[])
{

  ros::init(argc, argv, &quot;feat_proj&quot;, ros::init_options::NoSigintHandler);
  ros::NodeHandle rosnode;
  ros::NodeHandle private_nh(&quot;~&quot;);
  std::string cameraInfo_topic_name;
  private_nh.param&lt;std::string&gt;(&quot;camera_info_topic&quot;, cameraInfo_topic_name, &quot;/camera/camera_info&quot;);

  /* get camera ID */
  camera_id_str = cameraInfo_topic_name;
  camera_id_str.erase(camera_id_str.find(&quot;/camera/camera_info&quot;));
  if (camera_id_str == &quot;/&quot;) {
    camera_id_str = &quot;camera&quot;;
  }
  
  /* Get Flag wheter vecter_map_server function will be used  */
  private_nh.param&lt;bool&gt;(&quot;use_path_info&quot;, g_use_vector_map_server, false);

  /* load vector map */
  ros::Subscriber sub_point     = rosnode.subscribe(&quot;vector_map_info/point&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_points,
                                                    &amp;vmap);
  ros::Subscriber sub_line      = rosnode.subscribe(&quot;vector_map_info/line&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_lines,
                                                    &amp;vmap);
  ros::Subscriber sub_lane      = rosnode.subscribe(&quot;vector_map_info/lane&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_lanes,
                                                    &amp;vmap);
  ros::Subscriber sub_vector    = rosnode.subscribe(&quot;vector_map_info/vector&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_vectors,
                                                    &amp;vmap);
  ros::Subscriber sub_signal    = rosnode.subscribe(&quot;vector_map_info/signal&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_signals,
                                                    &amp;vmap);
  ros::Subscriber sub_whiteline = rosnode.subscribe(&quot;vector_map_info/white_line&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_whitelines,
                                                    &amp;vmap);
  ros::Subscriber sub_dtlane    = rosnode.subscribe(&quot;vector_map_info/dtlane&quot;,
                                                    SUBSCRIBE_QUEUE_SIZE,
                                                    &amp;VectorMap::load_dtlanes,
                                                    &amp;vmap);

  /* wait until loading all vector map is completed */
  ros::Rate wait_rate(1);
  while(vmap.points.empty() || vmap.lines.empty() || vmap.whitelines.empty() ||
        vmap.lanes.empty() || vmap.dtlanes.empty() || vmap.vectors.empty() || vmap.signals.empty())
    {
      ros::spinOnce();
      wait_rate.sleep();
    }

  vmap.loaded = true;
  std::cout &lt;&lt; &quot;all vector map loaded.&quot; &lt;&lt; std::endl;

  ros::Subscriber cameraInfoSubscriber = rosnode.subscribe (cameraInfo_topic_name, 100, cameraInfoCallback);
  ros::Subscriber adjust_xySubscriber  = rosnode.subscribe(&quot;/config/adjust_xy&quot;, 100, adjust_xyCallback);
  ros::Subscriber current_pose_subscriber;
  ros::Subscriber waypoint_subscriber;
  if (g_use_vector_map_server) {
    /* Create subscribers which deliver informations requested by server */
    current_pose_subscriber = rosnode.subscribe(&quot;/current_pose&quot;, 1, &amp;VectorMapClient::set_pose, &amp;g_vector_map_client);
    waypoint_subscriber     = rosnode.subscribe(&quot;/final_waypoints&quot;, 1, &amp;VectorMapClient::set_waypoints, &amp;g_vector_map_client);

    /* Create ros client to use Server-Client communication */
    g_ros_client = rosnode.serviceClient&lt;vector_map_server::GetSignal&gt;(&quot;vector_map_server/get_signal&quot;);
  }

  ros::Publisher  signalPublisher      = rosnode.advertise &lt;road_wizard::Signals&gt; (&quot;roi_signal&quot;, 100);
  signal (SIGINT, interrupt);

  Rate loop (25);
  while (true) {

    ros::spinOnce();

    try {
      getTransform (orientation, position);
    } catch (tf::TransformException &amp;exc) {
    }

    echoSignals2 (signalPublisher, false);
    loop.sleep();
  }


}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr/TrafficLight.h" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr/TrafficLight.h">
				<diff>@@ -8,13 +8,13 @@
 #include &quot;TrafficLightDetector.h&quot;
 
 /* Extra includes */
-#include &quot;road_wizard/Signals.h&quot;
+#include &quot;autoware_msgs/Signals.h&quot;
 
 #define MAIN_WINDOW_NAME &quot;Main&quot;
 #define SETTINGS_WINDOW_NAME &quot;Settings&quot;
 
 /* Functions declarations */
-void setContexts(TrafficLightDetector &amp;detector, const road_wizard::Signals::ConstPtr&amp; extractedPos);
+void setContexts(TrafficLightDetector &amp;detector, const autoware_msgs::Signals::ConstPtr&amp; extractedPos);
 
 #define MINIMAM_RADIUS 3
 #define ROI_MARGINE 20
</diff>
				<old_file>#ifndef TRAFFIC_LIGHT_H
#define TRAFFIC_LIGHT_H

/* External includes */
#include &lt;cmath&gt;

/* Internal includes */
#include &quot;TrafficLightDetector.h&quot;

/* Extra includes */
#include &quot;road_wizard/Signals.h&quot;

#define MAIN_WINDOW_NAME &quot;Main&quot;
#define SETTINGS_WINDOW_NAME &quot;Settings&quot;

/* Functions declarations */
void setContexts(TrafficLightDetector &amp;detector, const road_wizard::Signals::ConstPtr&amp; extractedPos);

#define MINIMAM_RADIUS 3
#define ROI_MARGINE 20

static inline bool IsNearlyZero(double x)
{
  double abs_x = fabs(x);
  int scale = 100;
  return(abs_x &lt; DBL_MIN*scale);
}

struct valueSet {
    double upper;
    double lower;
};

struct hsvSet {
    valueSet Hue;
    valueSet Sat;
    valueSet Val;
};

struct thresholdSet {
    hsvSet Red;
    hsvSet Yellow;
    hsvSet Green;
};

//#define SHOW_DEBUG_INFO

#endif
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr/region_tlr.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr/region_tlr.cpp">
				<diff>@@ -7,10 +7,10 @@
 #include &lt;float.h&gt;
 #include &lt;math.h&gt;
 #include &lt;sstream&gt;
-#include &lt;runtime_manager/traffic_light.h&gt;
 #include &lt;std_msgs/String.h&gt;
-#include &quot;road_wizard/Signals.h&quot;
-#include &quot;road_wizard/TunedResult.h&quot;
+#include &lt;autoware_msgs/traffic_light.h&gt;
+#include &lt;autoware_msgs/Signals.h&gt;
+#include &lt;autoware_msgs/TunedResult.h&gt;
 #include &lt;visualization_msgs/Marker.h&gt;
 #include &lt;visualization_msgs/MarkerArray.h&gt;
 #include &lt;std_msgs/Bool.h&gt;
@@ -170,7 +170,7 @@ static void image_raw_cb(const sensor_msgs::Image&amp; image_source)
 } /* static void image_raw_cb() */
 
 
-static void extractedPos_cb(const road_wizard::Signals::ConstPtr&amp; extractedPos)
+static void extractedPos_cb(const autoware_msgs::Signals::ConstPtr&amp; extractedPos)
 {
   if (frame.empty())
     return;
@@ -181,7 +181,7 @@ static void extractedPos_cb(const road_wizard::Signals::ConstPtr&amp; extractedPos)
   detector.brightnessDetect(frame);
 
   /* publish result */
-  runtime_manager::traffic_light state_msg;
+  autoware_msgs::traffic_light state_msg;
   std_msgs::String state_string_msg;
   const int32_t TRAFFIC_LIGHT_RED     = 0;
   const int32_t TRAFFIC_LIGHT_GREEN   = 1;
@@ -339,7 +339,7 @@ static void extractedPos_cb(const road_wizard::Signals::ConstPtr&amp; extractedPos)
 } /* static void extractedPos_cb() */
 
 
-static void tunedResult_cb(const road_wizard::TunedResult&amp; msg)
+static void tunedResult_cb(const autoware_msgs::TunedResult&amp; msg)
 {
   thSet.Red.Hue.upper = cvtInt2Double_hue(msg.Red.Hue.center, msg.Red.Hue.range);
   thSet.Red.Hue.lower = cvtInt2Double_hue(msg.Red.Hue.center, -msg.Red.Hue.range);
@@ -427,7 +427,7 @@ int main(int argc, char* argv[]) {
   ros::Subscriber tunedResult_sub = n.subscribe(&quot;/tuned_result&quot;, 1, tunedResult_cb);
   ros::Subscriber superimpose_sub = n.subscribe(&quot;/config/superimpose&quot;, 1, superimpose_cb);
 
-  signalState_pub       = n.advertise&lt;runtime_manager::traffic_light&gt;(&quot;/light_color&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
+  signalState_pub       = n.advertise&lt;autoware_msgs::traffic_light&gt;(&quot;/light_color&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
   signalStateString_pub = n.advertise&lt;std_msgs::String&gt;(&quot;/sound_player&quot;, ADVERTISE_QUEUE_SIZE);
   marker_pub            = n.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;tlr_result&quot;, ADVERTISE_QUEUE_SIZE);
   superimpose_image_pub= n.advertise&lt;sensor_msgs::Image&gt;(&quot;tlr_superimpose_image&quot;, ADVERTISE_QUEUE_SIZE);
</diff>
				<old_file>#include &lt;vector&gt;
#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &quot;TrafficLight.h&quot;
#include &lt;float.h&gt;
#include &lt;math.h&gt;
#include &lt;sstream&gt;
#include &lt;runtime_manager/traffic_light.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &quot;road_wizard/Signals.h&quot;
#include &quot;road_wizard/TunedResult.h&quot;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;std_msgs/Bool.h&gt;

thresholdSet thSet;

static ros::Publisher signalState_pub;
static ros::Publisher signalStateString_pub;
static ros::Publisher marker_pub;
static ros::Publisher superimpose_image_pub;
static constexpr int32_t ADVERTISE_QUEUE_SIZE = 10;
static constexpr bool    ADVERTISE_LATCH      = true;
static uint32_t          shape                = visualization_msgs::Marker::SPHERE;

// Variables
static TrafficLightDetector detector;

static cv::Mat frame;

static bool              show_superimpose_result = false;
static const std::string window_name             = &quot;superimpose result&quot;;

static double cvtInt2Double_hue(int center, int range)
{
  /* convert value range from OpenCV to Definition */
  double converted = (center + range) * 2.0f;

  if (converted &lt; 0) {
    converted = 0.0f;
  } else if (360 &lt; converted) {
    converted = converted - 360.0f;
  }

  return converted;
} /* static double cvtInt2Double_hue() */


static double cvtInt2Double_sat(int center, int range)
{
  /* convert value range from OpenCV to Definition */
  double converted = (center + range) / 255.0f;
  if (converted &lt; 0) {
    converted = 0.0f;
  } else if (1.0f &lt; converted) {
    converted = 1.0f;
  }

  return converted;
} /* static double cvtInt2Double_sat() */


static double cvtInt2Double_val(int center, int range)
{
  /* convert value range from OpenCV to Definition */
  double converted = (center + range) / 255.0f;
  if (converted &lt; 0) {
    converted = 0;
  } else if (1.0f &lt; converted) {
    converted = 1.0f;
  }

  return converted;
} /* static double cvtInt2Double_val() */


static void putResult_inText(cv::Mat *image, const std::vector&lt;Context&gt; &amp;contexts)
{
  std::string label;
  const int fontFace = cv::FONT_HERSHEY_COMPLEX_SMALL;
  const float fontScale = 1.0f;
  const int fontThickness = 1;
  int baseline = 0;
  CvPoint textOrg;
  CvScalar textColor;

  for (unsigned int i=0; i&lt;contexts.size(); i++)
    {
      Context ctx = contexts.at(i);
//      if (ctx.lampRadius &lt; MINIMAM_RADIUS)
//        continue;

      switch(ctx.lightState) {
      case GREEN:
        label = &quot;GREEN&quot;;
        textColor = CV_RGB(0, 255, 0);
        break;
      case YELLOW:
        label = &quot;YELLOW&quot;;
        textColor = CV_RGB(255, 255, 0);
        break;
      case RED:
        label = &quot;RED&quot;;
        textColor = CV_RGB(255, 0, 0);
        break;
      case UNDEFINED:
        label = &quot;UNDEFINED&quot;;
        textColor = CV_RGB(0, 0, 0);
      }

      cv::getTextSize(label,
		      fontFace,
		      fontScale,
		      fontThickness,
		      &amp;baseline);

      textOrg = cv::Point(ctx.topLeft.x, ctx.botRight.y + baseline);

      putText(*image,
              label,
              textOrg,
              fontFace,
              fontScale,
              textColor,
              fontThickness,
              CV_AA);
    }
} /* static void putResult_inText() */


static void image_raw_cb(const sensor_msgs::Image&amp; image_source)
{
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
  //  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source);
  frame = cv_image-&gt;image.clone();

  /* Draw superimpose result on image */
  cv::Mat targetScope = frame.clone();
  for (unsigned int i=0; i&lt;detector.contexts.size(); i++)
    {
      /* draw superimposed position of traffic lights */
      circle(targetScope, detector.contexts.at(i).redCenter, detector.contexts.at(i).lampRadius, CV_RGB(255, 0, 0), 1, 0);
      circle(targetScope, detector.contexts.at(i).yellowCenter, detector.contexts.at(i).lampRadius, CV_RGB(255, 255, 0), 1, 0);
      circle(targetScope, detector.contexts.at(i).greenCenter, detector.contexts.at(i).lampRadius, CV_RGB(0, 255, 0), 1, 0);
    }

  /* draw detection results */
  putResult_inText(&amp;targetScope, detector.contexts);


  /* Publish superimpose result image */
  cv_bridge::CvImage msg_converter;
  msg_converter.header = image_source.header;
  msg_converter.encoding = sensor_msgs::image_encodings::BGR8;
  msg_converter.image = targetScope;
  superimpose_image_pub.publish(msg_converter.toImageMsg());

  /* Display superimpose result image in separate window*/
  if (show_superimpose_result)
    {
      if (cvGetWindowHandle(window_name.c_str()) != NULL) // Guard not to write destroyed window by using close button on the window
        {
          imshow(window_name, targetScope);
          cv::waitKey(5);
        }
    }

} /* static void image_raw_cb() */


static void extractedPos_cb(const road_wizard::Signals::ConstPtr&amp; extractedPos)
{
  if (frame.empty())
    return;

  /* Set subscribed signal position into detector */
  Context::SetContexts(detector.contexts, extractedPos, frame.rows, frame.cols);

  detector.brightnessDetect(frame);

  /* publish result */
  runtime_manager::traffic_light state_msg;
  std_msgs::String state_string_msg;
  const int32_t TRAFFIC_LIGHT_RED     = 0;
  const int32_t TRAFFIC_LIGHT_GREEN   = 1;
  const int32_t TRAFFIC_LIGHT_UNKNOWN = 2;
  static int32_t prev_state = TRAFFIC_LIGHT_UNKNOWN;
  state_msg.traffic_light = TRAFFIC_LIGHT_UNKNOWN;
  for (unsigned int i=0; i&lt;detector.contexts.size(); i++) {
	  switch (detector.contexts.at(i).lightState) {
	  case GREEN:
		  state_msg.traffic_light = TRAFFIC_LIGHT_GREEN;
          state_string_msg.data = &quot;green signal&quot;;
		  break;
	  case YELLOW:
	  case RED:
		  state_msg.traffic_light = TRAFFIC_LIGHT_RED;
          state_string_msg.data = &quot;red signal&quot;;
		  break;
	  case UNDEFINED:
		  state_msg.traffic_light = TRAFFIC_LIGHT_UNKNOWN;
          state_string_msg.data = &quot;&quot;;
		  break;
	  }
	  if (state_msg.traffic_light != TRAFFIC_LIGHT_UNKNOWN)
		  break;  // publish the first state in detector.contexts
  }

  if (state_msg.traffic_light != prev_state) {
    signalState_pub.publish(state_msg);
    signalStateString_pub.publish(state_string_msg);
  } else {
    state_string_msg.data = &quot;&quot;;
    signalStateString_pub.publish(state_string_msg);
  }

  std_msgs::ColorRGBA color_black;
  color_black.r = 0.0f;
  color_black.g = 0.0f;
  color_black.b = 0.0f;
  color_black.a = 1.0f;

  std_msgs::ColorRGBA color_red;
  color_red.r = 1.0f;
  color_red.g = 0.0f;
  color_red.b = 0.0f;
  color_red.a = 1.0f;

  std_msgs::ColorRGBA color_yellow;
  color_yellow.r = 1.0f;
  color_yellow.g = 1.0f;
  color_yellow.b = 0.0f;
  color_yellow.a = 1.0f;

  std_msgs::ColorRGBA color_green;
  color_green.r = 0.0f;
  color_green.g = 1.0f;
  color_green.b = 0.0f;
  color_green.a = 1.0f;

  /* publish all detected result as ROS Marker */
  for (unsigned int i=0; i&lt;detector.contexts.size(); i++)
    {
      Context ctx = detector.contexts.at(i);
      visualization_msgs::MarkerArray signalSet;
      visualization_msgs::Marker mk_red, mk_yellow, mk_green;

      /* Set the frame ID */
      mk_red.header.frame_id    = &quot;map&quot;;
      mk_yellow.header.frame_id = &quot;map&quot;;
      mk_green.header.frame_id  = &quot;map&quot;;

      /* Set the namespace and id for this marker */
      mk_red.ns    = &quot;tlr_result_red&quot;;
      mk_yellow.ns = &quot;tlr_result_yellow&quot;;
      mk_green.ns  = &quot;tlr_result_green&quot;;
      mk_red.id    = ctx.signalID;
      mk_yellow.id = ctx.signalID;
      mk_green.id  = ctx.signalID;

      /* Set the marker type */
      mk_red.type    = shape;
      mk_yellow.type = shape;
      mk_green.type  = shape;

      /* Set the pose of the marker */
      mk_red.pose.position.x    = ctx.redCenter3d.x;
      mk_red.pose.position.y    = ctx.redCenter3d.y;
      mk_red.pose.position.z    = ctx.redCenter3d.z;
      mk_yellow.pose.position.x = ctx.yellowCenter3d.x;
      mk_yellow.pose.position.y = ctx.yellowCenter3d.y;
      mk_yellow.pose.position.z = ctx.yellowCenter3d.z;
      mk_green.pose.position.x  = ctx.greenCenter3d.x;
      mk_green.pose.position.y  = ctx.greenCenter3d.y;
      mk_green.pose.position.z  = ctx.greenCenter3d.z;

      mk_red.pose.orientation.x    = 0.0;
      mk_red.pose.orientation.y    = 0.0;
      mk_red.pose.orientation.y    = 0.0;
      mk_red.pose.orientation.w    = 0.0;
      mk_yellow.pose.orientation.x = 0.0;
      mk_yellow.pose.orientation.y = 0.0;
      mk_yellow.pose.orientation.y = 0.0;
      mk_yellow.pose.orientation.w = 0.0;
      mk_green.pose.orientation.x  = 0.0;
      mk_green.pose.orientation.y  = 0.0;
      mk_green.pose.orientation.y  = 0.0;
      mk_green.pose.orientation.w  = 0.0;

      /* Set the scale of the marker -- We assume lamp radius as 30cm */
      mk_red.scale.x    = (double)0.3;
      mk_red.scale.y    = (double)0.3;
      mk_red.scale.z    = (double)0.3;
      mk_yellow.scale.x = (double)0.3;
      mk_yellow.scale.y = (double)0.3;
      mk_yellow.scale.z = (double)0.3;
      mk_green.scale.x  = (double)0.3;
      mk_green.scale.y  = (double)0.3;
      mk_green.scale.z  = (double)0.3;

      /* Set the color */
      switch (ctx.lightState) {
      case GREEN:
        mk_red.color    = color_black;
        mk_yellow.color = color_black;
        mk_green.color  = color_green;
        break;
      case YELLOW:
        mk_red.color    = color_black;
        mk_yellow.color = color_yellow;
        mk_green.color  = color_black;
        break;
      case RED:
        mk_red.color    = color_red;
        mk_yellow.color = color_black;
        mk_green.color  = color_black;
        break;
      case UNDEFINED:
        mk_red.color    = color_black;
        mk_yellow.color = color_black;
        mk_green.color  = color_black;
        break;
      }

      mk_red.lifetime    = ros::Duration(0.1);
      mk_yellow.lifetime = ros::Duration(0.1);
      mk_green.lifetime  = ros::Duration(0.1);

      signalSet.markers.push_back(mk_red);
      signalSet.markers.push_back(mk_yellow);
      signalSet.markers.push_back(mk_green);

      marker_pub.publish(signalSet);
    }

  prev_state = state_msg.traffic_light;
} /* static void extractedPos_cb() */


static void tunedResult_cb(const road_wizard::TunedResult&amp; msg)
{
  thSet.Red.Hue.upper = cvtInt2Double_hue(msg.Red.Hue.center, msg.Red.Hue.range);
  thSet.Red.Hue.lower = cvtInt2Double_hue(msg.Red.Hue.center, -msg.Red.Hue.range);
  thSet.Red.Sat.upper = cvtInt2Double_sat(msg.Red.Sat.center, msg.Red.Sat.range);
  thSet.Red.Sat.lower = cvtInt2Double_sat(msg.Red.Sat.center, -msg.Red.Sat.range);
  thSet.Red.Val.upper = cvtInt2Double_val(msg.Red.Val.center, msg.Red.Val.range);
  thSet.Red.Val.lower = cvtInt2Double_val(msg.Red.Val.center, -msg.Red.Val.range);

  thSet.Yellow.Hue.upper = cvtInt2Double_hue(msg.Yellow.Hue.center, msg.Yellow.Hue.range);
  thSet.Yellow.Hue.lower = cvtInt2Double_hue(msg.Yellow.Hue.center, -msg.Yellow.Hue.range);
  thSet.Yellow.Sat.upper = cvtInt2Double_sat(msg.Yellow.Sat.center, msg.Yellow.Sat.range);
  thSet.Yellow.Sat.lower = cvtInt2Double_sat(msg.Yellow.Sat.center, -msg.Yellow.Sat.range);
  thSet.Yellow.Val.upper = cvtInt2Double_val(msg.Yellow.Val.center, msg.Yellow.Val.range);
  thSet.Yellow.Val.lower = cvtInt2Double_val(msg.Yellow.Val.center, -msg.Yellow.Val.range);

  thSet.Green.Hue.upper = cvtInt2Double_hue(msg.Green.Hue.center, msg.Green.Hue.range);
  thSet.Green.Hue.lower = cvtInt2Double_hue(msg.Green.Hue.center, -msg.Green.Hue.range);
  thSet.Green.Sat.upper = cvtInt2Double_sat(msg.Green.Sat.center, msg.Green.Sat.range);
  thSet.Green.Sat.lower = cvtInt2Double_sat(msg.Green.Sat.center, -msg.Green.Sat.range);
  thSet.Green.Val.upper = cvtInt2Double_val(msg.Green.Val.center, msg.Green.Val.range);
  thSet.Green.Val.lower = cvtInt2Double_val(msg.Green.Val.center, -msg.Green.Val.range);

} /* static void tunedResult_cb() */


static void superimpose_cb(const std_msgs::Bool::ConstPtr&amp; config_msg)
{
  show_superimpose_result = config_msg-&gt;data;

  if (show_superimpose_result) {
    cv::namedWindow(window_name, cv::WINDOW_NORMAL);
    cv::startWindowThread();
  }

  if (!show_superimpose_result) {
	  if (cvGetWindowHandle(window_name.c_str()) != NULL)
	  {
		  cv::destroyWindow(window_name);
		  cv::waitKey(1);
	  }
  }

} /* static void superimpose_cb() */

int main(int argc, char* argv[]) {

  //	printf(&quot;***** Traffic lights app *****\n&quot;);
#ifdef SHOW_DEBUG_INFO
  cv::namedWindow(&quot;tmpImage&quot;, cv::WINDOW_NORMAL);
  cv::namedWindow(&quot;bright_mask&quot;, cv::WINDOW_NORMAL);
  cv::startWindowThread();
#endif

  thSet.Red.Hue.upper = (double)DAYTIME_RED_UPPER;
  thSet.Red.Hue.lower = (double)DAYTIME_RED_LOWER;
  thSet.Red.Sat.upper = 1.0f;
  thSet.Red.Sat.lower = DAYTIME_S_SIGNAL_THRESHOLD;
  thSet.Red.Val.upper = 1.0f;
  thSet.Red.Val.lower = DAYTIME_V_SIGNAL_THRESHOLD;

  thSet.Yellow.Hue.upper = (double)DAYTIME_YELLOW_UPPER;
  thSet.Yellow.Hue.lower = (double)DAYTIME_YELLOW_LOWER;
  thSet.Yellow.Sat.upper = 1.0f;
  thSet.Yellow.Sat.lower = DAYTIME_S_SIGNAL_THRESHOLD;
  thSet.Yellow.Val.upper = 1.0f;
  thSet.Yellow.Val.lower = DAYTIME_V_SIGNAL_THRESHOLD;

  thSet.Green.Hue.upper = (double)DAYTIME_GREEN_UPPER;
  thSet.Green.Hue.lower = (double)DAYTIME_GREEN_LOWER;
  thSet.Green.Sat.upper = 1.0f;
  thSet.Green.Sat.lower = DAYTIME_S_SIGNAL_THRESHOLD;
  thSet.Green.Val.upper = 1.0f;
  thSet.Green.Val.lower = DAYTIME_V_SIGNAL_THRESHOLD;


  ros::init(argc, argv, &quot;region_tlr&quot;);

  ros::NodeHandle n;
  ros::NodeHandle private_nh(&quot;~&quot;);
  std::string image_topic_name;
  private_nh.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name, &quot;/image_raw&quot;);

  ros::Subscriber image_sub       = n.subscribe(image_topic_name, 1, image_raw_cb);
  ros::Subscriber position_sub    = n.subscribe(&quot;/roi_signal&quot;, 1, extractedPos_cb);
  ros::Subscriber tunedResult_sub = n.subscribe(&quot;/tuned_result&quot;, 1, tunedResult_cb);
  ros::Subscriber superimpose_sub = n.subscribe(&quot;/config/superimpose&quot;, 1, superimpose_cb);

  signalState_pub       = n.advertise&lt;runtime_manager::traffic_light&gt;(&quot;/light_color&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
  signalStateString_pub = n.advertise&lt;std_msgs::String&gt;(&quot;/sound_player&quot;, ADVERTISE_QUEUE_SIZE);
  marker_pub            = n.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;tlr_result&quot;, ADVERTISE_QUEUE_SIZE);
  superimpose_image_pub= n.advertise&lt;sensor_msgs::Image&gt;(&quot;tlr_superimpose_image&quot;, ADVERTISE_QUEUE_SIZE);

  ros::spin();

  return 0;
} /* int main() */


</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr_ssd/region_tlr_ssd.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr_ssd/region_tlr_ssd.cpp">
				<diff>@@ -2,7 +2,7 @@
 
 #include &lt;string&gt;
 
-#include &lt;runtime_manager/traffic_light.h&gt;
+#include &lt;autoware_msgs/traffic_light.h&gt;
 #include &lt;std_msgs/String.h&gt;
 #include &lt;visualization_msgs/Marker.h&gt;
 #include &lt;visualization_msgs/MarkerArray.h&gt;
@@ -70,7 +70,7 @@ void RegionTlrSsdRosNode::ImageRawCallback(const sensor_msgs::Image &amp;image) {
 // ==========================================
 // Callback function to acquire extracted_pos
 // ==========================================
-void RegionTlrSsdRosNode::RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos) {
+void RegionTlrSsdRosNode::RoiSignalCallback(const autoware_msgs::Signals::ConstPtr &amp;extracted_pos) {
   static ros::Time previous_timestamp;
   // If frame has not been prepared, abort this callback
   if (frame_.empty() ||
@@ -154,7 +154,7 @@ void RegionTlrSsdRosNode::StartSubscribersAndPublishers() {
                                                 this);
 
   // Register publishers
-  signal_state_publisher        = node_handle.advertise&lt;runtime_manager::traffic_light&gt;(&quot;light_color&quot;, 1);
+  signal_state_publisher        = node_handle.advertise&lt;autoware_msgs::traffic_light&gt;(&quot;light_color&quot;, 1);
   signal_state_string_publisher = node_handle.advertise&lt;std_msgs::String&gt;(&quot;/sound_player&quot;, 1);
   marker_publisher              = node_handle.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;tlr_result&quot;, 1, kAdvertiseInLatch_);
   superimpose_image_publisher   = node_handle.advertise&lt;sensor_msgs::Image&gt;(&quot;tlr_superimpose_image&quot;, 1);
@@ -186,10 +186,10 @@ LightState RegionTlrSsdRosNode::DetermineState(LightState previous_state,
 
 
 // =================================================================
-// Publish recognition result as runtime_manager::traffic_light type
+// Publish recognition result as autoware_msgs::traffic_light type
 // =================================================================
 void RegionTlrSsdRosNode::PublishTrafficLight(std::vector&lt;Context&gt; contexts) {
-  runtime_manager::traffic_light topic;
+  autoware_msgs::traffic_light topic;
   static int32_t previous_state = kTrafficLightUnknown;
   topic.traffic_light = kTrafficLightUnknown;
   for (const auto ctx: contexts) {
</diff>
				<old_file>#include &quot;region_tlr_ssd.h&quot;

#include &lt;string&gt;

#include &lt;runtime_manager/traffic_light.h&gt;
#include &lt;std_msgs/String.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;

#include &quot;Context.h&quot;

// ========================================
// Constructor of RegionTlrSsdRosNode class
// ========================================
RegionTlrSsdRosNode::RegionTlrSsdRosNode():
  image_topic_name_(&quot;/image_raw&quot;),
  network_definition_file_name_(&quot;&quot;),
  pretrained_model_file_name_(&quot;&quot;),
  use_gpu_(false),
  gpu_id_(0),
  kAdvertiseInLatch_(true),
  kTrafficLightRed(0),
  kTrafficLightGreen(1),
  kTrafficLightUnknown(2),
  kStringRed(&quot;red signal&quot;),
  kStringGreen(&quot;green signal&quot;),
  kStringUnknown(&quot;&quot;) {

} // RegionTlrSsdRosNode::RegionTlrSsdRosNode()


// ========================================
// Destructor of RegionTlrSsdRosNode class
// ========================================
RegionTlrSsdRosNode::~RegionTlrSsdRosNode() {
} // RegionTlrSsdRosNode::~RegionTlrSsdRosNode()


// =========================
// Start recognition process
// =========================
void RegionTlrSsdRosNode::RunRecognition() {
  // Get execution parameters from ROS parameter server
  GetRosParam();

  // Initialize recognizer
  recognizer.Init(network_definition_file_name_,
                  pretrained_model_file_name_,
                  use_gpu_,
                  gpu_id_);

  // Start subscribing and publishing
  StartSubscribersAndPublishers();
  ros::spin();
} // RegionTlrSsdRosNode::RunRecognition()


// ==================================
// Callback function to acquire image
// ==================================
void RegionTlrSsdRosNode::ImageRawCallback(const sensor_msgs::Image &amp;image) {
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image, sensor_msgs::image_encodings::BGR8);
  frame_ = cv_image-&gt;image.clone();

  // Save header information of this topic
  frame_header_ = image.header;

}

// ==========================================
// Callback function to acquire extracted_pos
// ==========================================
void RegionTlrSsdRosNode::RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos) {
  static ros::Time previous_timestamp;
  // If frame has not been prepared, abort this callback
  if (frame_.empty() ||
      frame_header_.stamp == previous_timestamp) {
    return;
  }

  // Acquire signal posotion on the image
  Context::SetContexts(contexts_, extracted_pos, frame_.rows, frame_.cols);

  // Recognize the color of the traffic light
  for (Context&amp; context: contexts_) {
  // for (unsigned int i = 0; i &lt; contexts_.size(); i++) {
  //   Context&amp; context = contexts_.at(i);
    if (context.topLeft.x &gt; context.botRight.x) {
      continue;
    }

    // extract region of interest from input image
    cv::Mat roi  = frame_(cv::Rect(context.topLeft, context.botRight)).clone();

    // Get current state of traffic light from current frame
    LightState current_state = recognizer.RecognizeLightState(roi);

    // Determine the final state by referring previous state
    context.lightState = DetermineState(context.lightState, // previous state
                                        current_state,      // current state
                                        &amp;(context.stateJudgeCount)); // counter to record how many times does state recognized
  }

  // Publish recognition result as some topic format
  PublishTrafficLight(contexts_);
  PublishString(contexts_);
  PublishMarkerArray(contexts_);
  PublishImage(contexts_);

  // Save timestamp of this frame so that same frame has never been process again
  previous_timestamp = frame_header_.stamp;
}

// =======================================
// Get parameter from ROS parameter server
// =======================================
void RegionTlrSsdRosNode::GetRosParam() {
  ros::NodeHandle private_node_handle(&quot;~&quot;);

  private_node_handle.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name_, &quot;/image_raw&quot;);
  private_node_handle.param&lt;std::string&gt;(&quot;network_definition_file&quot;, network_definition_file_name_, &quot;&quot;);
  private_node_handle.param&lt;std::string&gt;(&quot;pretrained_model_file&quot;, pretrained_model_file_name_, &quot;&quot;);
  private_node_handle.param&lt;bool&gt;(&quot;use_gpu&quot;, use_gpu_, false);
  private_node_handle.param&lt;int&gt;(&quot;gpu_id&quot;, gpu_id_, 0);

  // If network-definition-file or pretrained-model-file are not specified,
  // terminate program with error status
  if (network_definition_file_name_.empty()){
    ROS_FATAL(&quot;No Network Definition File was specified. Terminate program... &quot;);
    exit(EXIT_FAILURE);
  }

  if (pretrained_model_file_name_.empty()){
    ROS_FATAL(&quot;No Pretrained Model File was specified. Terminate program... &quot;);
    exit(EXIT_FAILURE);
  }
} // RegionTlrSsdRosNode::ProcessRosParam()


// ============================================================
// Register subscriber and publisher of this node in ROS Master
// ============================================================
void RegionTlrSsdRosNode::StartSubscribersAndPublishers() {
  ros::NodeHandle node_handle;
  
  // Register subscribers
  image_subscriber      = node_handle.subscribe(image_topic_name_,
                                                1,
                                                &amp;RegionTlrSsdRosNode::ImageRawCallback,
                                                this);
  roi_signal_subscriber = node_handle.subscribe(&quot;/roi_signal&quot;,
                                                1,
                                                &amp;RegionTlrSsdRosNode::RoiSignalCallback,
                                                this);

  // Register publishers
  signal_state_publisher        = node_handle.advertise&lt;runtime_manager::traffic_light&gt;(&quot;light_color&quot;, 1);
  signal_state_string_publisher = node_handle.advertise&lt;std_msgs::String&gt;(&quot;/sound_player&quot;, 1);
  marker_publisher              = node_handle.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;tlr_result&quot;, 1, kAdvertiseInLatch_);
  superimpose_image_publisher   = node_handle.advertise&lt;sensor_msgs::Image&gt;(&quot;tlr_superimpose_image&quot;, 1);

} // RegionTlrSsdRosNode::StartSubscribersAndPublishers()


// ===============================================================================
// Determine the final recognition result by comparing previous recognition result
// ===============================================================================
LightState RegionTlrSsdRosNode::DetermineState(LightState previous_state,
                                               LightState current_state,
                                               int* state_judge_count) {
  // Get a candidate which considering state transition of traffic light
  LightState transition_candidate = kStateTransitionMatrix[previous_state][current_state];

  // If state change happens more than threshold times, accept that change
  if (*state_judge_count &gt; kChangeStateThreshold) {
    *state_judge_count = 0;
    return transition_candidate;
  } else {
    if (transition_candidate != previous_state) {
      (*state_judge_count)++;
    }
    return previous_state;
  }

} // LightState RegionTlrSsdRosNode::DetermineState()


// =================================================================
// Publish recognition result as runtime_manager::traffic_light type
// =================================================================
void RegionTlrSsdRosNode::PublishTrafficLight(std::vector&lt;Context&gt; contexts) {
  runtime_manager::traffic_light topic;
  static int32_t previous_state = kTrafficLightUnknown;
  topic.traffic_light = kTrafficLightUnknown;
  for (const auto ctx: contexts) {
    switch(ctx.lightState) {
    case GREEN:
      topic.traffic_light = kTrafficLightGreen;
      break;
    case YELLOW:
    case RED:
      topic.traffic_light = kTrafficLightRed;
      break;
    case UNDEFINED:
      topic.traffic_light = kTrafficLightUnknown;
      break;
    }

    // Publish the first state in contexts,
    // which has largest estimated radius of signal.
    // This program assume that the signal which has the largest estimated radius
    // equal the nearest one from camera.
    if (topic.traffic_light != kTrafficLightUnknown) {
      break;
    }
  }

  // If state changes from previous one, publish it
  if (topic.traffic_light != previous_state) {
    signal_state_publisher.publish(topic);
    previous_state = topic.traffic_light;
  }
} // void RegionTlrSsdRosNode::PublishTrafficLight()


// =================================================================
// Publish recognition result as std_msgs::String
// =================================================================
void RegionTlrSsdRosNode::PublishString(std::vector&lt;Context&gt; contexts) {
  std_msgs::String topic;
  static std::string previous_state = kStringUnknown;
  topic.data = kStringUnknown;
  for (const auto ctx: contexts) {
    switch(ctx.lightState) {
    case GREEN:
      topic.data = kStringGreen;
      break;
    case YELLOW:
    case RED:
      topic.data = kStringRed;
      break;
    case UNDEFINED:
      topic.data = kStringUnknown;
      break;
    }

    // Publish the first state in contexts,
    // which has largest estimated radius of signal.
    // This program assume that the signal which has the largest estimated radius
    // equal the nearest one from camera.
    if (topic.data != kStringUnknown) {
      break;
    }
  }

  // If state changes from previous one, publish it
  if (topic.data != previous_state) {
    signal_state_string_publisher.publish(topic);
    previous_state = topic.data;
  }
} // void RegionTlrSsdRosNode::PublishString()


// =================================================================
// Publish recognition result as visualization_msgs::MarkerArray
// =================================================================
void RegionTlrSsdRosNode::PublishMarkerArray(std::vector&lt;Context&gt; contexts) {
  // Define color constants
  std_msgs::ColorRGBA color_black;
  color_black.r = 0.0f;
  color_black.g = 0.0f;
  color_black.b = 0.0f;
  color_black.a = 1.0f;

  std_msgs::ColorRGBA color_red;
  color_red.r = 1.0f;
  color_red.g = 0.0f;
  color_red.b = 0.0f;
  color_red.a = 1.0f;

  std_msgs::ColorRGBA color_yellow;
  color_yellow.r = 1.0f;
  color_yellow.g = 1.0f;
  color_yellow.b = 0.0f;
  color_yellow.a = 1.0f;

  std_msgs::ColorRGBA color_green;
  color_green.r = 0.0f;
  color_green.g = 1.0f;
  color_green.b = 0.0f;
  color_green.a = 1.0f;

  // publish all result as ROS MarkerArray
  for (const auto ctx: contexts) {
    visualization_msgs::MarkerArray signal_set;
    visualization_msgs::Marker red_light, yellow_light, green_light;

    // Set the frame ID
    red_light.header.frame_id    = &quot;map&quot;;
    yellow_light.header.frame_id = &quot;map&quot;;
    green_light.header.frame_id  = &quot;map&quot;;

    // Set the namespace and ID for this markers
    red_light.ns    = &quot;tlr_result_red&quot;;
    red_light.id    = ctx.signalID;

    yellow_light.ns = &quot;tlr_result_yellow&quot;;
    yellow_light.id = ctx.signalID;

    green_light.ns  = &quot;tlr_result_green&quot;;
    green_light.id  = ctx.signalID;

    // Set the markers type
    red_light.type    = visualization_msgs::Marker::SPHERE;
    yellow_light.type = visualization_msgs::Marker::SPHERE;
    green_light.type  = visualization_msgs::Marker::SPHERE;

    // Set the pose of the markers
    red_light.pose.position.x = ctx.redCenter3d.x;
    red_light.pose.position.y = ctx.redCenter3d.y;
    red_light.pose.position.z = ctx.redCenter3d.z;
    red_light.pose.orientation.x = 0.0;
    red_light.pose.orientation.y = 0.0;
    red_light.pose.orientation.z = 0.0;
    red_light.pose.orientation.w = 0.0;

    yellow_light.pose.position.x = ctx.yellowCenter3d.x;
    yellow_light.pose.position.y = ctx.yellowCenter3d.y;
    yellow_light.pose.position.z = ctx.yellowCenter3d.z;
    yellow_light.pose.orientation.x = 0.0;
    yellow_light.pose.orientation.y = 0.0;
    yellow_light.pose.orientation.z = 0.0;
    yellow_light.pose.orientation.w = 0.0;

    green_light.pose.position.x = ctx.greenCenter3d.x;
    green_light.pose.position.y = ctx.greenCenter3d.y;
    green_light.pose.position.z = ctx.greenCenter3d.z;
    green_light.pose.orientation.x = 0.0;
    green_light.pose.orientation.y = 0.0;
    green_light.pose.orientation.z = 0.0;
    green_light.pose.orientation.w = 0.0;

    // Set the scale of the markers. We assume lamp radius is 30cm in real world
    red_light.scale.x = 0.3;
    red_light.scale.y = 0.3;
    red_light.scale.z = 0.3;

    yellow_light.scale.x = 0.3;
    yellow_light.scale.y = 0.3;
    yellow_light.scale.z = 0.3;

    green_light.scale.x = 0.3;
    green_light.scale.y = 0.3;
    green_light.scale.z = 0.3;

    // Set the color for each marker
    switch(ctx.lightState) {
    case GREEN:
      red_light.color = color_black;
      yellow_light.color = color_black;
      green_light.color = color_green;
      break;
    case YELLOW:
      red_light.color = color_black;
      yellow_light.color = color_yellow;
      green_light.color = color_black;
      break;
    case RED:
      red_light.color = color_red;
      yellow_light.color = color_black;
      green_light.color = color_black;
      break;
    case UNDEFINED:
      red_light.color = color_black;
      yellow_light.color = color_black;
      green_light.color = color_black;
      break;
    }

    red_light.lifetime = ros::Duration(0.1);
    yellow_light.lifetime = ros::Duration(0.1);
    green_light.lifetime = ros::Duration(0.1);

    // Pack each light marker into one
    signal_set.markers.push_back(red_light);
    signal_set.markers.push_back(yellow_light);
    signal_set.markers.push_back(green_light);

    // Publish
    marker_publisher.publish(signal_set);
  }

} // void RegionTlrSsdRosNode::PublishMarkerArray()


// ================================================================
// Publish superimpose and recognition result as sensor_msgs::Image
// ================================================================
void RegionTlrSsdRosNode::PublishImage(std::vector&lt;Context&gt; contexts) {
  // Copy the frame image for output
  cv::Mat result_image = frame_.clone();

  // Define information for written label
  std::string  label;
  const int    kFontFace      = cv::FONT_HERSHEY_COMPLEX_SMALL;
  const double kFontScale     = 1.0;
  int          font_baseline  = 0;
  CvScalar     label_color;

  for (const auto ctx: contexts_) {
    // Draw superimpose result on image
    circle(result_image, ctx.redCenter, ctx.lampRadius, CV_RGB(255, 0, 0), 1, 0);
    circle(result_image, ctx.yellowCenter, ctx.lampRadius, CV_RGB(255, 255, 0), 1, 0);
    circle(result_image, ctx.greenCenter, ctx.lampRadius, CV_RGB(0, 255, 0), 1, 0);

    // Draw recognition result on image
    switch(ctx.lightState) {
    case GREEN:
      label = &quot;GREEN&quot;;
      label_color = CV_RGB(0, 255, 0);
      break;
    case YELLOW:
      label = &quot;YELLOW&quot;;
      label_color = CV_RGB(255, 255, 0);
      break;
    case RED:
      label = &quot;RED&quot;;
      label_color = CV_RGB(255, 0, 0);
      break;
    case UNDEFINED:
      label = &quot;UNKNOWN&quot;;
      label_color = CV_RGB(0, 0, 0);
    }

    cv::Point label_origin = cv::Point(ctx.topLeft.x, ctx.botRight.y + font_baseline);

    cv::putText(result_image, label, label_origin, kFontFace, kFontScale, label_color);
  }

  // Publish superimpose result image
  cv_bridge::CvImage converter;
  converter.header = frame_header_;
  converter.encoding = sensor_msgs::image_encodings::BGR8;
  converter.image = result_image;
  superimpose_image_publisher.publish(converter.toImageMsg());

} // void RegionTlrSsdRosNode::PublishImage()

// ========================
// Entry point of this node
// ========================
int main (int argc, char *argv[]) {
  // Initialize ros node
  ros::init(argc, argv, &quot;region_tlr_ssd&quot;);

  // Create RegionTlrRosNode class object and do initialization
  RegionTlrSsdRosNode region_tlr_ssd_ros_node;

  // Start recognition process
  region_tlr_ssd_ros_node.RunRecognition();

  return 0;
} // main()
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr_ssd/region_tlr_ssd.h" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/region_tlr_ssd/region_tlr_ssd.h">
				<diff>@@ -10,7 +10,7 @@
 #include &lt;cv_bridge/cv_bridge.h&gt;
 
 #include &quot;Context.h&quot;
-#include &quot;road_wizard/Signals.h&quot;
+#include &quot;autoware_msgs/Signals.h&quot;
 #include &quot;traffic_light_recognizer.h&quot;
 
 class RegionTlrSsdRosNode {
@@ -20,7 +20,7 @@ class RegionTlrSsdRosNode {
 
   void RunRecognition();
   void ImageRawCallback(const sensor_msgs::Image &amp;image);
-  void RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos);
+  void RoiSignalCallback(const autoware_msgs::Signals::ConstPtr &amp;extracted_pos);
 
   // The vector of data structure to save traffic light state, position, ...etc
   std::vector&lt;Context&gt; contexts_;
</diff>
				<old_file>#ifndef REGION_TLR_SSD_H
#define REGION_TLR_SSD_H

#include &lt;string&gt;

#include &lt;opencv2/opencv.hpp&gt;
#include &lt;ros/ros.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;

#include &quot;Context.h&quot;
#include &quot;road_wizard/Signals.h&quot;
#include &quot;traffic_light_recognizer.h&quot;

class RegionTlrSsdRosNode {
 public:
  RegionTlrSsdRosNode();
  ~RegionTlrSsdRosNode();

  void RunRecognition();
  void ImageRawCallback(const sensor_msgs::Image &amp;image);
  void RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos);

  // The vector of data structure to save traffic light state, position, ...etc
  std::vector&lt;Context&gt; contexts_;

 private:
  /* Light state transition probably happen in Japanese traffic light */
  const LightState kStateTransitionMatrix[4][4] = {
    /* current: */
    /* GREEN   , YELLOW    , RED    , UNDEFINED  */
    /* -------------------------------------------  */
    {GREEN     , YELLOW    , YELLOW    , GREEN}  ,  /* | previous = GREEN */
    {UNDEFINED , YELLOW    , RED       , YELLOW} ,  /* | previous = YELLOW */
    {GREEN     , RED       , RED       , RED}    ,  /* | previous = RED */
    {GREEN     , YELLOW    , RED       , UNDEFINED} /* | previous = UNDEFINED */
  };


  void GetRosParam();
  void StartSubscribersAndPublishers();
  LightState DetermineState(LightState previous_state, LightState current_state, int* state_judge_count);
  void PublishTrafficLight(std::vector&lt;Context&gt; contexts);
  void PublishString(std::vector&lt;Context&gt; contexts);
  void PublishMarkerArray(std::vector&lt;Context&gt; contexts);
  void PublishImage(std::vector&lt;Context&gt; contexts);

  // Execution parameter
  std::string image_topic_name_;
  std::string network_definition_file_name_;
  std::string pretrained_model_file_name_;
  bool use_gpu_;
  int gpu_id_;

  // Subscribers
  ros::Subscriber image_subscriber;
  ros::Subscriber roi_signal_subscriber;

  // Publishers
  ros::Publisher signal_state_publisher;
  ros::Publisher signal_state_string_publisher;
  ros::Publisher marker_publisher;
  ros::Publisher superimpose_image_publisher;

  // Flag to show topic will be published in latch manner
  bool kAdvertiseInLatch_;

  // A frame image acquired from topic
  cv::Mat frame_;

  // Timestamp of a frame in process
  std_msgs::Header frame_header_;

  // The instance of the core class of traffic light recognition by SSD
  TrafficLightRecognizer recognizer;

  // The threshold of state detected times to accept the state change
  const int kChangeStateThreshold = 10;

  // constant values to pass recognition states to other nodes
  const int32_t kTrafficLightRed;
  const int32_t kTrafficLightGreen;
  const int32_t kTrafficLightUnknown;
  const std::string kStringRed;
  const std::string kStringGreen;
  const std::string kStringUnknown;
};

#endif  // REGION_TLR_SSD_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/roi_extractor/roi_extractor.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/roi_extractor/roi_extractor.cpp">
				<diff>@@ -14,7 +14,7 @@
 
 
 #include &quot;Context.h&quot;
-#include &quot;road_wizard/Signals.h&quot;
+#include &lt;autoware_msgs/Signals.h&gt;
 
 
 void RoiExtractor::ImageRawCallback(const sensor_msgs::Image &amp;image) {
@@ -27,7 +27,7 @@ void RoiExtractor::ImageRawCallback(const sensor_msgs::Image &amp;image) {
 } // void RoiExtractor::ImageRawCallback()
 
 
-void RoiExtractor::RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos) {
+void RoiExtractor::RoiSignalCallback(const autoware_msgs::Signals::ConstPtr &amp;extracted_pos) {
   // If frame image has not been updated, do nothing
   if (frame_timestamp_ == previous_timestamp_) {
     return;
</diff>
				<old_file>#include &quot;roi_extractor.h&quot;

#include &lt;sys/stat.h&gt;
#include &lt;dirent.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string&gt;
#include &lt;vector&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;opencv2/opencv.hpp&gt;


#include &quot;Context.h&quot;
#include &quot;road_wizard/Signals.h&quot;


void RoiExtractor::ImageRawCallback(const sensor_msgs::Image &amp;image) {
  // Acquire frame image from ros topic
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image, sensor_msgs::image_encodings::BGR8);
  frame_ = cv_image-&gt;image.clone();

  // Save this topic's time stamp so that same image will not be processed more than twice
  frame_timestamp_ = image.header.stamp;
} // void RoiExtractor::ImageRawCallback()


void RoiExtractor::RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos) {
  // If frame image has not been updated, do nothing
  if (frame_timestamp_ == previous_timestamp_) {
    return;
  }

  // Aquire signal positions from ros topic
  std::vector&lt;Context&gt; signal_positions;
  Context::SetContexts(signal_positions, extracted_pos, frame_.rows, frame_.cols);

  if (signal_positions.size() == 0) {
    // If signal_positions is empty, no ROI images should be saved
    return;
  }

  // Extract ROI for top signal in vector (top signal has largest estimated radius in every signals projected in a image)
  cv::Mat roi = frame_(cv::Rect(signal_positions.at(0).topLeft, signal_positions.at(0).botRight));
  std::string file_name = target_directory_ + std::to_string(file_count_) + &quot;.png&quot;;

  // Reject image if its height is smaller than threshold
  if (roi.size().height &lt; k_minimum_height_) {
    return;
  }

  // Reject image if its similarity level with previous saved ROI is higher than threshold 
  if (k_similarity_threshold_ &lt; CalculateSimilarity(roi, previous_saved_frame_)) {
    return;
  }

  cv::imwrite(file_name.c_str(), roi);
  file_count_++;
  
  previous_timestamp_ = frame_timestamp_;
  previous_saved_frame_ = roi.clone();
} // void RoiExtractor::RoiSignalCallback()


void RoiExtractor::CreateTargetDirectory(std::string base_name) {
  // Extracted ROI's images will be saved in &quot;[base_name]/tlr_TrainingDataSet/Images&quot;
  std::string target_directory_name = base_name + &quot;/tlr_TrainingDataSet/Images/&quot;;
  
  // Create target directory newly if it doesn't exist
  struct stat directory_info;
  if (stat(target_directory_name.c_str(), &amp;directory_info) != 0) {
    MakeDirectoryTree(target_directory_name, base_name, 0755);
  }

  // Count the number of files contained in the target directory
  // so that saved file is named in continuous number
  file_count_ = CountFileNum(target_directory_name);


  // Save directory name into class member
  target_directory_ = target_directory_name;

} // void RoiExtractor::CreateTargetDirectory


int RoiExtractor::CountFileNum(std::string directory_name) {
  int file_num = 0;
  struct dirent *entry;
  DIR *directory_handler = opendir(directory_name.c_str());

  // Count the number of files contained in the specified directory
  while ((entry = readdir(directory_handler)) != NULL) {
    struct stat status;
    std::string absolute_path = directory_name + std::string(entry-&gt;d_name);
    if (stat(absolute_path.c_str(), &amp;status) == 0 &amp;&amp;
        S_ISREG(status.st_mode)) {
      file_num++;
    }
  }

  closedir(directory_handler);

  return file_num;
} //int RoiExtractor::CountFileNum()


void RoiExtractor::MakeDirectoryTree(const std::string &amp;target,
                                     const std::string &amp;base,
                                     const mode_t &amp;mode) {
  // Extract directory subtree structure
  std::string sub_tree = target.substr(base.size());

  // Create directory tree one by one
  size_t separator_start = sub_tree.find(&quot;/&quot;);
  size_t separator_end = sub_tree.find(&quot;/&quot;, separator_start + 1);
  std::string path = base;
  while (separator_end != std::string::npos) {
    std::string sub_directory = sub_tree.substr(separator_start, separator_end - separator_start);
    path = path + sub_directory;
    mkdir(path.c_str(), mode);
    separator_start = separator_end;
    separator_end = sub_tree.find(&quot;/&quot;, separator_start + 1);
  }
} // void RoiExtractor::MakeDirectoryTree()


// calculae similarity of specified two images
// by comparing their histogram, which is sensitive filter for color
double RoiExtractor::CalculateSimilarity(const cv::Mat &amp;image1, const cv::Mat &amp;image2) {
  if (image1.empty() || image2.empty()) {
    return 0.0;
  }

  // Compare by histogram
  cv::Mat image1_hsv, image2_hsv;
  cv::cvtColor(image1, image1_hsv, CV_BGR2HSV);
  cv::cvtColor(image2, image2_hsv, CV_BGR2HSV);

  const int channel[] = {0};

  // Hue range in OpenCV is 0 to 180
  const float hue_ranges[] = {0, 180};
  const float* ranges[] = {hue_ranges};

  // Quantize hue value into 6
  int hist_size[] = {6};

  cv::Mat histogram1;
  cv::calcHist(&amp;image1_hsv,
               1,               // Use this image only to create histogram
               channel,
               cv::Mat(),       // No mask is used
               histogram1,
               1,               // The dimension of histogram is 1
               hist_size,
               ranges);

   cv::Mat histogram2;
   cv::calcHist(&amp;image2_hsv,
                1,              // Use this image only to create histogram
                channel,
                cv::Mat(),      // No mask is used
                histogram2,
                1,              // The dimension of histogram is 1
                hist_size,
                ranges);

   double similarity = cv::compareHist(histogram1, histogram2, CV_COMP_CORREL);

   return similarity;
} // void RoiExtractor::CalculateSimilarity()


// Entry Point of this node
int main (int argc, char *argv[]) {
  // Initialize ROS node
  ros::init(argc, argv, &quot;roi_extractor&quot;);

  // Get source topic name of image from ROS private parameter
  ros::NodeHandle private_node_handler(&quot;~&quot;);
  std::string image_topic_name;
  std::string target_directory_name = std::string(getenv(&quot;HOME&quot;)) + &quot;/.autoware&quot;;
  int minimum_height = 32;
  double similarity_threshold = 0.9;
  private_node_handler.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name, &quot;/image_raw&quot;);
  private_node_handler.param&lt;std::string&gt;(&quot;target_directory&quot;, target_directory_name, target_directory_name);
  private_node_handler.param&lt;int&gt;(&quot;minimum_height&quot;, minimum_height, 32); // The default minimum height is 32
  private_node_handler.param&lt;double&gt;(&quot;similarity_threshold&quot;, similarity_threshold, 0.9); // The default similarity threshold is 0.9

  // Get directory name which roi images will be saved
  RoiExtractor extractor(minimum_height, similarity_threshold);
  extractor.CreateTargetDirectory(target_directory_name);

  // Launch callback function to subscribe images and signal position
  ros::NodeHandle node_handler;
  ros::Subscriber image_subscriber = node_handler.subscribe(image_topic_name,
                                                            1,
                                                            &amp;RoiExtractor::ImageRawCallback,
                                                            &amp;extractor);

  ros::Subscriber roi_signal_subscriber = node_handler.subscribe(&quot;/roi_signal&quot;,
                                                                 1,
                                                                 &amp;RoiExtractor::RoiSignalCallback,
                                                                 &amp;extractor);
  
  ros::spin();

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/roi_extractor/roi_extractor.h" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/roi_extractor/roi_extractor.h">
				<diff>@@ -10,7 +10,7 @@
 #include &lt;opencv2/opencv.hpp&gt;
 
 #include &quot;Context.h&quot;
-#include &quot;road_wizard/Signals.h&quot;
+#include &quot;autoware_msgs/Signals.h&quot;
 
 class RoiExtractor {
  public:
@@ -24,7 +24,7 @@ class RoiExtractor {
 
   // Callback functions to obtain images and signal position
   void ImageRawCallback(const sensor_msgs::Image &amp;image);
-  void RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos);
+  void RoiSignalCallback(const autoware_msgs::Signals::ConstPtr &amp;extracted_pos);
   
   // Utility function to create directory which roi images will be saved
   void CreateTargetDirectory(std::string base_name);
</diff>
				<old_file>#ifndef ROI_EXTRACTOR_H
#define ROI_EXTRACTOR_H

#include &lt;string&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;opencv2/opencv.hpp&gt;

#include &quot;Context.h&quot;
#include &quot;road_wizard/Signals.h&quot;

class RoiExtractor {
 public:
  explicit RoiExtractor(int minimum_height, double similarity_threshold):
    k_minimum_height_(minimum_height),
    k_similarity_threshold_(similarity_threshold),
    previous_saved_frame_(cv::Mat())
  {};

  ~RoiExtractor(){};

  // Callback functions to obtain images and signal position
  void ImageRawCallback(const sensor_msgs::Image &amp;image);
  void RoiSignalCallback(const road_wizard::Signals::ConstPtr &amp;extracted_pos);
  
  // Utility function to create directory which roi images will be saved
  void CreateTargetDirectory(std::string base_name);

 private:
  // Utility function to count the number of files contained in the specified directory
  int CountFileNum(std::string directory_name);

  // Utility function to create directory tree
  void MakeDirectoryTree(const std::string &amp;target, const std::string &amp;base, const mode_t &amp;mode);

  // The function to calculate similarity of two image
  double CalculateSimilarity(const cv::Mat &amp;image1, const cv::Mat &amp;image2);

  // Directory path that extracted ROI images will be saved
  std::string target_directory_;

  // One subscribed frame image
  cv::Mat frame_;

  // Time stamp value of subscribed value
  ros::Time frame_timestamp_;
  ros::Time previous_timestamp_;

  // The number of files contained in the target directory
  int file_count_;

  // The minimum height threshold of ROI image that will be saved
  const int k_minimum_height_;

  // The threshold of the level of similarity
  const double k_similarity_threshold_;

  // The image saved last time
  cv::Mat previous_saved_frame_;
};

#endif // ROI_EXTRACTOR_H
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/tlr_tuner/tunerBody.cpp" new_path="ros/src/computing/perception/detection/packages/road_wizard/nodes/tlr_tuner/tunerBody.cpp">
				<diff>@@ -1,5 +1,5 @@
 #include &quot;tunerBody.h&quot;
-#include &quot;road_wizard/TunedResult.h&quot;
+#include &quot;autoware_msgs/TunedResult.h&quot;
 
 
 #include &lt;opencv2/core/version.hpp&gt;
@@ -152,7 +152,7 @@ void TunerBody::launch(void)
 
   ros::Subscriber image_sub = n.subscribe(image_topic_name, 1, image_raw_callBack);
 
-  ros::Publisher tunedResult_pub = n.advertise &lt;road_wizard::TunedResult&gt; (&quot;tuned_result&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
+  ros::Publisher tunedResult_pub = n.advertise &lt;autoware_msgs::TunedResult&gt; (&quot;tuned_result&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
 
   /* valiables to check status change */
   cv::Point prev_clicked = cv::Point(-1, -1);
@@ -275,7 +275,7 @@ void TunerBody::launch(void)
       prev_vw = vw;
 
       /* publish tuned result */
-      road_wizard::TunedResult res;
+      autoware_msgs::TunedResult res;
       res.Red.Hue.center = Red_set.hue.center;
       res.Red.Hue.range  = Red_set.hue.range;
       res.Red.Sat.center = Red_set.sat.center;
</diff>
				<old_file>#include &quot;tunerBody.h&quot;
#include &quot;road_wizard/TunedResult.h&quot;


#include &lt;opencv2/core/version.hpp&gt;
#if (CV_MAJOR_VERSION != 3)
#define CV cv
#else
#define CV cv::internal
#endif


static constexpr int32_t ADVERTISE_QUEUE_SIZE = 10;
static constexpr bool    ADVERTISE_LATCH      = true;

/* definition of class static private variables */
cv::Point       TunerBody::Clicked_point;
int             TunerBody::Signal_color;
cv::Mat         TunerBody::src_img;
cv::Mat         TunerBody::mask;
std::string     TunerBody::windowName;
thresholds_set  TunerBody::Red_set;
thresholds_set  TunerBody::Yellow_set;
thresholds_set  TunerBody::Green_set;
thresholds_set* TunerBody::Selected_set;
bool            TunerBody::updateImage;


/*============== Utility function ==============*/
static void onMouse(int event, int x, int y, int, void*)
{
  if (event != cv::EVENT_LBUTTONDOWN) {
    return;
  }

  TunerBody::setClickedPoint(cv::Point(x, y));

  return;
} /* void onMouse() */


/*============== Utility function ==============*/
static void colorTrack(const cv::Mat&amp; hsv_img,
                       const int hue,
                       const int sat,
                       const int val,
                       const int hw,
                       const int sw,
                       const int vw,
                       cv::Mat *dst)
{
  cv::Mat kernel = cv::Mat::ones(5, 5, CV_8U); /* kernel for dilation and erosion*/

  /* create mask image */
  cv::inRange(hsv_img, cv::Scalar(hue - hw, sat - sw, val - vw), cv::Scalar(hue + hw, sat + sw, val + vw), *dst);

  /* remove noise */
  dilate(*dst, *dst, kernel, cv::Point(-1, -1), 2);
  erode(*dst, *dst, kernel, cv::Point(-1, -1), 2);

} /* void colorTrack() */


/*============== Utility function ==============*/
static int index_max(std::vector&lt;std::vector&lt;cv::Point&gt; &gt; cnt)
{
  unsigned int max_elementNum = 0;
  int maxIdx = -1;

  for (unsigned int i=0; i&lt;cnt.size(); i++)
    {
      unsigned int elementNum = cnt[i].size();
      if (elementNum &gt; max_elementNum) {
        max_elementNum = elementNum;
        maxIdx = i;
      }
    }

  return maxIdx;

} /* int index_max() */


TunerBody::TunerBody()
{
  /* initialize private values */
  Clicked_point = cv::Point(-1, -1);
  Signal_color  = GREEN;
  H_slider_val  = 0;
  S_slider_val  = 0;
  V_slider_val  = 0;
  windowName    = &quot;Traffic Lignt Detector Tuner&quot;;

  Red_set.hue.center = 0;
  Red_set.hue.range  = 0;
  Red_set.sat.center = 0;
  Red_set.sat.range  = 0;
  Red_set.val.center = 0;
  Red_set.val.range  = 0;
  Red_set.isUpdated  = false;
  Yellow_set.hue.center = 0;
  Yellow_set.hue.range  = 0;
  Yellow_set.sat.center = 0;
  Yellow_set.sat.range  = 0;
  Yellow_set.val.center = 0;
  Yellow_set.val.range  = 0;
  Yellow_set.isUpdated  = false;
  Green_set.hue.center = 0;
  Green_set.hue.range  = 0;
  Green_set.sat.center = 0;
  Green_set.sat.range  = 0;
  Green_set.val.center = 0;
  Green_set.val.range  = 0;
  Green_set.isUpdated  = false;

  Selected_set = &amp;Green_set;

  updateImage = true;

  /* create track bars */
  cv::namedWindow(windowName);
  cv::createTrackbar(&quot;H&quot;, windowName, &amp;H_slider_val, 127, NULL, NULL);
  cv::createTrackbar(&quot;S&quot;, windowName, &amp;S_slider_val, 127, NULL, NULL);
  cv::createTrackbar(&quot;V&quot;, windowName, &amp;V_slider_val, 127, NULL, NULL);

} /* TunerBody::TunerBody() */


TunerBody::~TunerBody()
{
  cv::destroyAllWindows();
} /* TunerBody::~TunerBody() */


void TunerBody::image_raw_callBack(const sensor_msgs::Image&amp; image_msg)
{
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, sensor_msgs::image_encodings::BGR8);
  if (updateImage) {
    src_img       = cv_image-&gt;image.clone();
    updateImage   = false;
    Clicked_point = cv::Point(-1, -1); // if image is reloaded, reset clicked point to out of image
  }
} /* TunerBody::image_raw_callBack() */


void TunerBody::launch(void)
{
  ros::NodeHandle n;
  ros::NodeHandle private_nh(&quot;~&quot;);
  std::string image_topic_name;
  private_nh.param&lt;std::string&gt;(&quot;image_raw_topic&quot;, image_topic_name, &quot;/image_raw&quot;);

  ros::Subscriber image_sub = n.subscribe(image_topic_name, 1, image_raw_callBack);

  ros::Publisher tunedResult_pub = n.advertise &lt;road_wizard::TunedResult&gt; (&quot;tuned_result&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);

  /* valiables to check status change */
  cv::Point prev_clicked = cv::Point(-1, -1);
  int       prev_hw      = 0;
  int       prev_sw      = 0;
  int       prev_vw      = 0;

  while (ros::ok())
    {
      ros::spinOnce();

      if (src_img.empty())
        continue;

      base = cv::Mat::zeros(src_img.rows, src_img.cols * 2, CV_8UC3);
      mask = cv::Mat::zeros(src_img.rows, src_img.cols, CV_8UC1);

      cv::Mat result = src_img.clone();

      /* get clicked coordinates on the image */
      cv::Point targetPoint = Clicked_point;


      /* get current slider position */
      int hw = H_slider_val;
      int sw = S_slider_val;
      int vw = V_slider_val;

      cv::setMouseCallback(windowName, onMouse);

      /* convert input image to HSV color image */
      cv::Mat hsv_img;
      cv::cvtColor(src_img, hsv_img, cv::COLOR_BGR2HSV);

      if (targetPoint != prev_clicked &amp;&amp;
          targetPoint != cv::Point(-1, -1))
        {
          std::cerr &lt;&lt; &quot;Selected_set updated&quot; &lt;&lt; std::endl;
          int hue = (int)hsv_img.at&lt;cv::Vec3b&gt;(targetPoint.y, targetPoint.x)[0];
          int sat = (int)hsv_img.at&lt;cv::Vec3b&gt;(targetPoint.y, targetPoint.x)[1];
          int val = (int)hsv_img.at&lt;cv::Vec3b&gt;(targetPoint.y, targetPoint.x)[2];

          /* save HSV values into correspond variables */
          Selected_set-&gt;hue.center = hue;
          Selected_set-&gt;sat.center = sat;
          Selected_set-&gt;val.center = val;
          Selected_set-&gt;isUpdated  = true;
        }

      Selected_set-&gt;hue.range  = hw;
      Selected_set-&gt;sat.range  = sw;
      Selected_set-&gt;val.range  = vw;

      if (prev_hw != hw || prev_sw != sw || prev_vw != vw) {
        Selected_set-&gt;isUpdated = true;
      }

      colorTrack(hsv_img,
                 Selected_set-&gt;hue.center,
                 Selected_set-&gt;sat.center,
                 Selected_set-&gt;val.center,
                 Selected_set-&gt;hue.range,
                 Selected_set-&gt;sat.range,
                 Selected_set-&gt;val.range,
                 &amp;mask);

      std::vector&lt; std::vector&lt;cv::Point&gt; &gt; contours;
      std::vector&lt;cv::Vec4i&gt; hierarchy;

      cv::Mat mask_clone = mask.clone();
      cv::findContours(mask_clone,
                       contours,
                       hierarchy,
                       CV_RETR_TREE,
                       CV_CHAIN_APPROX_SIMPLE);

      int maxIndex = index_max(contours);

      std::vector&lt;cv::Point&gt; hull;
      if (maxIndex != -1)
        {
          convexHull(contours[maxIndex], hull); /*draw round detected area by line*/
          drawContours(result, std::vector&lt; std::vector&lt;cv::Point&gt; &gt;(1, hull), 0, CV_RGB(220, 30, 20), 3);
        }

      /* display result */
      cv::Mat roi_result = base(cv::Rect(0, 0, result.cols, result.rows));
      result.copyTo(roi_result);

      cv::Scalar mask_color;
      switch (Signal_color) {
      case GREEN:
        mask_color = CV_RGB(0, 255, 0);
        break;
      case YELLOW:
        mask_color = CV_RGB(255, 255, 0);
        break;
      case RED:
        mask_color = CV_RGB(255, 0, 0);
        break;
      }

      cv::Mat colorBack(mask.rows, mask.cols, CV_8UC3, mask_color);
      cv::Mat mask_colored;
      colorBack.copyTo(mask_colored, mask);

      cv::Mat roi_mask = base(cv::Rect(result.cols, 0, mask_colored.cols, mask_colored.rows));
      mask_colored.copyTo(roi_mask);

      cv::imshow(windowName, base);
      cv::waitKey(10);
      // if ( (cv::waitKey(10)) == '\x1b') { /* if 'ESC' key is typed, finish the program */
      //   break;
      // }

      /* save current status */
      prev_clicked = targetPoint;
      prev_hw = hw;
      prev_sw = sw;
      prev_vw = vw;

      /* publish tuned result */
      road_wizard::TunedResult res;
      res.Red.Hue.center = Red_set.hue.center;
      res.Red.Hue.range  = Red_set.hue.range;
      res.Red.Sat.center = Red_set.sat.center;
      res.Red.Sat.range  = Red_set.sat.range;
      res.Red.Val.center = Red_set.val.center;
      res.Red.Val.range  = Red_set.val.range;

      res.Yellow.Hue.center = Yellow_set.hue.center;
      res.Yellow.Hue.range  = Yellow_set.hue.range;
      res.Yellow.Sat.center = Yellow_set.sat.center;
      res.Yellow.Sat.range  = Yellow_set.sat.range;
      res.Yellow.Val.center = Yellow_set.val.center;
      res.Yellow.Val.range  = Yellow_set.val.range;

      res.Green.Hue.center = Green_set.hue.center;
      res.Green.Hue.range  = Green_set.hue.range;
      res.Green.Sat.center = Green_set.sat.center;
      res.Green.Sat.range  = Green_set.sat.range;
      res.Green.Val.center = Green_set.val.center;
      res.Green.Val.range  = Green_set.val.range;

      tunedResult_pub.publish(res);

    }

  cv::destroyAllWindows();

} /* void TunerBody::launch() */


void TunerBody::setColor(signal_state state)
{
  switch (state) {
  case GREEN:
    Selected_set = &amp;Green_set;
    break;
  case YELLOW:
    Selected_set = &amp;Yellow_set;
    break;
  case RED:
    Selected_set = &amp;Red_set;
    break;
  }

  Signal_color = state;

  /* update trackbar position according to current status */
  cv::setTrackbarPos(&quot;H&quot;, windowName, Selected_set-&gt;hue.range);
  cv::setTrackbarPos(&quot;S&quot;, windowName, Selected_set-&gt;sat.range);
  cv::setTrackbarPos(&quot;V&quot;, windowName, Selected_set-&gt;val.range);

  /* update mask image according to current status */
  cv::Mat hsv_img;
  cv::cvtColor(src_img, hsv_img, cv::COLOR_BGR2HSV);
  colorTrack(hsv_img,
             Selected_set-&gt;hue.center,
             Selected_set-&gt;sat.center,
             Selected_set-&gt;val.center,
             Selected_set-&gt;hue.range,
             Selected_set-&gt;sat.range,
             Selected_set-&gt;val.range,
             &amp;mask);

} /* void TunerBody::setColor() */


void TunerBody::setClickedPoint(cv::Point pt)
{
  Clicked_point = pt;
} /* void TunerBody::setClickedPoint() */



void TunerBody::saveResult(std::string fileName)
{

  if (Red_set.isUpdated == false) {
    /*
      ========== Red : Default values ==========
      340               &lt; Hue &lt; 50 (circled)
      DEFAULT_SAT_LOWER &lt; Sat &lt; DEFAULT_SAT_UPPER
      DEFAULT_VAL_LOWER &lt; Val &lt; DEFAULT_VAL_UPPER
    */
    Red_set.hue.center = ( (((360 + 50) - 340 ) / 2 ) + 340) % 360;
    Red_set.hue.range  = (((360 + 50) - 340 ) / 2 );
    Red_set.sat.center = ((DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2 ) + DEFAULT_SAT_LOWER;
    Red_set.sat.range  = (DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2;
    Red_set.val.center = ((DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2 ) + DEFAULT_VAL_LOWER;
    Red_set.val.range  = (DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2;
    std::cout &lt;&lt; &quot;Red is default setting&quot; &lt;&lt; std::endl;
  }

  if (Yellow_set.isUpdated == false) {
    /*
      ========== Yellow : Default values ==========
      50                &lt; Hue &lt; 70
      DEFAULT_SAT_LOWER &lt; Sat &lt; DEFAULT_SAT_UPPER
      DEFAULT_VAL_LOWER &lt; Val &lt; DEFAULT_VAL_UPPER
     */
    Yellow_set.hue.center = ( ((70 - 50 ) / 2 ) + 50) % 360;
    Yellow_set.hue.range  = ((70 - 50 ) / 2 );
    Yellow_set.sat.center = ((DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2 ) + DEFAULT_SAT_LOWER;
    Yellow_set.sat.range  = (DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2;
    Yellow_set.val.center = ((DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2 ) + DEFAULT_VAL_LOWER;
    Yellow_set.val.range  = (DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2;
    std::cout &lt;&lt; &quot;Yellow is default setting&quot; &lt;&lt; std::endl;
  }

  if (Green_set.isUpdated == false) {
    /*
      ========== Green : Default values ==========
      80                &lt; Hue &lt; 190
      DEFAULT_SAT_LOWER &lt; Sat &lt; DEFAULT_SAT_UPPER
      DEFAULT_VAL_LOWER &lt; Val &lt; DEFAULT_VAL_UPPER
     */
    Green_set.hue.center = ( ((190 - 80 ) / 2 ) + 80) % 360;
    Green_set.hue.range  = ((190 - 80 ) / 2 );
    Green_set.sat.center = ((DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2 ) + DEFAULT_SAT_LOWER;
    Green_set.sat.range  = (DEFAULT_SAT_UPPER - DEFAULT_SAT_LOWER) / 2;
    Green_set.val.center = ((DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2 ) + DEFAULT_VAL_LOWER;
    Green_set.val.range  = (DEFAULT_VAL_UPPER - DEFAULT_VAL_LOWER) / 2;
    std::cout &lt;&lt; &quot;Green is default setting&quot; &lt;&lt; std::endl;
  }

  /* open file strage */
  cv::FileStorage cvfs(fileName, CV_STORAGE_WRITE);

  /* write data to file */
  {
    CV::WriteStructContext st_red(cvfs, &quot;RED&quot;, CV_NODE_MAP);
    //cv::internal::WriteStructContext st_red(cvfs, &quot;RED&quot;, CV_NODE_MAP);
    {
      CV::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
      //cv::internal::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Red_set.hue.center);
      cv::write(cvfs, &quot;range&quot;, Red_set.hue.range);
    }

    {
      CV::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Red_set.sat.center);
      cv::write(cvfs, &quot;range&quot;, Red_set.sat.range);
    }

    {
      CV::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Red_set.val.center);
      cv::write(cvfs, &quot;range&quot;, Red_set.val.range);
    }
  }

  {
    CV::WriteStructContext st_yellow(cvfs, &quot;YELLOW&quot;, CV_NODE_MAP);
    //CV::WriteStructContext st_yellow(cvfs, &quot;YELLOW&quot;, CV_NODE_MAP);
    {
      CV::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
      //CV::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Yellow_set.hue.center);
      cv::write(cvfs, &quot;range&quot;, Yellow_set.hue.range);
    }

    {
      CV::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
      //CV::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Yellow_set.sat.center);
      cv::write(cvfs, &quot;range&quot;, Yellow_set.sat.range);
    }

    {
      CV::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
     // CV::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Yellow_set.val.center);
      cv::write(cvfs, &quot;range&quot;, Yellow_set.val.range);
    }
  }

  {
    CV::WriteStructContext st_green(cvfs, &quot;GREEN&quot;, CV_NODE_MAP);
    {
      CV::WriteStructContext st_hue(cvfs, &quot;Hue&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Green_set.hue.center);
      cv::write(cvfs, &quot;range&quot;, Green_set.hue.range);
    }

    {
      CV::WriteStructContext st_hue(cvfs, &quot;Saturation&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Green_set.sat.center);
      cv::write(cvfs, &quot;range&quot;, Green_set.sat.range);
    }

    {
      CV::WriteStructContext st_hue(cvfs, &quot;Value&quot;, CV_NODE_MAP);
      cv::write(cvfs, &quot;center&quot;, Green_set.val.center);
      cv::write(cvfs, &quot;range&quot;, Green_set.val.range);
    }
  }

} /* void TunerBody::saveResult() */


void TunerBody::openSetting(std::string fileName)
{
  /* open file strage */
  cv::FileStorage cvfs(fileName, CV_STORAGE_READ);

  /* read data from file */
  cv::FileNode topNode(cvfs.fs, NULL);
  {
    cv::FileNode nd_red = topNode[std::string(&quot;RED&quot;)];
    {
      cv::FileNode nd_hue = nd_red[&quot;Hue&quot;];
      Red_set.hue.center  = nd_hue[&quot;center&quot;];
      Red_set.hue.range   = nd_hue[&quot;range&quot;];
    }

    {
      cv::FileNode nd_sat = nd_red[&quot;Saturation&quot;];
      Red_set.sat.center  = nd_sat[&quot;center&quot;];
      Red_set.sat.range   = nd_sat[&quot;range&quot;];
    }

    {
      cv::FileNode nd_val = nd_red[&quot;Value&quot;];
      Red_set.val.center  = nd_val[&quot;center&quot;];
      Red_set.val.range   = nd_val[&quot;range&quot;];
    }

    Red_set.isUpdated = true;
  }

  {
    cv::FileNode nd_yellow = topNode[std::string(&quot;YELLOW&quot;)];
    {
      cv::FileNode nd_hue   = nd_yellow[&quot;Hue&quot;];
      Yellow_set.hue.center = nd_hue[&quot;center&quot;];
      Yellow_set.hue.range  = nd_hue[&quot;range&quot;];
    }

    {
      cv::FileNode nd_sat   = nd_yellow[&quot;Saturation&quot;];
      Yellow_set.sat.center = nd_sat[&quot;center&quot;];
      Yellow_set.sat.range  = nd_sat[&quot;range&quot;];
    }

    {
      cv::FileNode nd_val   = nd_yellow[&quot;Value&quot;];
      Yellow_set.val.center = nd_val[&quot;center&quot;];
      Yellow_set.val.range  = nd_val[&quot;range&quot;];
    }

    Yellow_set.isUpdated = true;
  }

  {
    cv::FileNode nd_green = topNode[std::string(&quot;GREEN&quot;)];
    {
      cv::FileNode nd_hue  = nd_green[&quot;Hue&quot;];
      Green_set.hue.center = nd_hue[&quot;center&quot;];
      Green_set.hue.range  = nd_hue[&quot;range&quot;];
    }

    {
      cv::FileNode nd_sat  = nd_green[&quot;Saturation&quot;];
      Green_set.sat.center = nd_sat[&quot;center&quot;];
      Green_set.sat.range  = nd_sat[&quot;range&quot;];
    }

    {
      cv::FileNode nd_val  = nd_green[&quot;Value&quot;];
      Green_set.val.center = nd_val[&quot;center&quot;];
      Green_set.val.range  = nd_val[&quot;range&quot;];
    }

    Green_set.isUpdated = true;
  }

  /* set trackbar position to current status */
  cv::setTrackbarPos(&quot;H&quot;, windowName, Selected_set-&gt;hue.range);
  cv::setTrackbarPos(&quot;S&quot;, windowName, Selected_set-&gt;sat.range);
  cv::setTrackbarPos(&quot;V&quot;, windowName, Selected_set-&gt;val.range);

  /* sat mask image to current status */
  cv::Mat hsv_img;
  cv::cvtColor(src_img, hsv_img, cv::COLOR_BGR2HSV);
  colorTrack(hsv_img,
             Selected_set-&gt;hue.center,
             Selected_set-&gt;sat.center,
             Selected_set-&gt;val.center,
             Selected_set-&gt;hue.range,
             Selected_set-&gt;sat.range,
             Selected_set-&gt;val.range,
             &amp;mask);

} /* void TunerBody::openSetting() */

void TunerBody::setUpdateImage(void)
{
  updateImage = true;
} /* void TunerBody::setUpdateImage() */
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/obstacle_avoid/search_info_ros.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/obstacle_avoid/search_info_ros.cpp">
				<diff>@@ -58,7 +58,7 @@ SearchInfo::~SearchInfo()
 {
 }
 
-double SearchInfo::calcPathLength(const waypoint_follower_msgs::lane &amp;lane, const int start_waypoint_index,
+double SearchInfo::calcPathLength(const autoware_msgs::lane &amp;lane, const int start_waypoint_index,
                                   const int goal_waypoint_index) const
 {
   if (lane.waypoints.size() &lt;= 1)
@@ -172,7 +172,7 @@ void SearchInfo::goalCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
 }
 
 // get waypoints
-void SearchInfo::waypointsCallback(const waypoint_follower_msgs::laneConstPtr &amp;msg)
+void SearchInfo::waypointsCallback(const autoware_msgs::laneConstPtr &amp;msg)
 {
   subscribed_waypoints_ = *msg;
 
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &quot;search_info_ros.h&quot;

namespace astar_planner
{
SearchInfo::SearchInfo()
  : map_set_(false)
  , start_set_(false)
  , goal_set_(false)
  , path_set_(false)
  , closest_waypoint_index_(-1)
  , obstacle_waypoint_index_(-1)
  , start_waypoint_index_(-1)
  , goal_waypoint_index_(-1)
  , state_(&quot;&quot;)
  , upper_bound_distance_(-1)
{
  ros::NodeHandle private_nh_(&quot;~&quot;);
  private_nh_.param&lt;std::string&gt;(&quot;map_frame&quot;, map_frame_, &quot;map&quot;);
  private_nh_.param&lt;int&gt;(&quot;obstacle_detect_count&quot;, obstacle_detect_count_, 10);
  private_nh_.param&lt;int&gt;(&quot;avoid_distance&quot;, avoid_distance_, 13);
  private_nh_.param&lt;double&gt;(&quot;avoid_velocity_limit_mps&quot;, avoid_velocity_limit_mps_, 4.166);
  private_nh_.param&lt;double&gt;(&quot;upper_bound_ratio&quot;, upper_bound_ratio_, 1.04);
  private_nh_.param&lt;bool&gt;(&quot;avoidance&quot;, avoidance_, false);
  private_nh_.param&lt;bool&gt;(&quot;change_path&quot;, change_path_, true);
}

SearchInfo::~SearchInfo()
{
}

double SearchInfo::calcPathLength(const waypoint_follower_msgs::lane &amp;lane, const int start_waypoint_index,
                                  const int goal_waypoint_index) const
{
  if (lane.waypoints.size() &lt;= 1)
    return 0;

  // calulate the length of the path
  double dist_sum = 0;
  for (int i = start_waypoint_index; i &lt; goal_waypoint_index; i++)
  {
    geometry_msgs::Pose p1 = lane.waypoints[i].pose.pose;
    geometry_msgs::Pose p2 = lane.waypoints[i + 1].pose.pose;

    dist_sum += astar_planner::calcDistance(p1.position.x, p1.position.y, p2.position.x, p2.position.y);
  }

  // return the path lengh
  return dist_sum;
}

void SearchInfo::mapCallback(const nav_msgs::OccupancyGridConstPtr &amp;msg)
{
  map_ = *msg;

  std::string map_frame = map_frame_;
  std::string ogm_frame = msg-&gt;header.frame_id;

  // Set transform between map frame and OccupancyGrid frame
  tf::StampedTransform map2ogm_frame;
  try
  {
    tf_listener_.lookupTransform(map_frame, ogm_frame, ros::Time(0), map2ogm_frame);
  }
  catch (tf::TransformException ex)
  {
    ROS_ERROR(&quot;%s&quot;, ex.what());
    return;
  }

  // Set transform between map frame and the origin of OccupancyGrid
  tf::Transform map2ogm;
  geometry_msgs::Pose ogm_in_map = astar_planner::transformPose(map_.info.origin, map2ogm_frame);
  tf::poseMsgToTF(ogm_in_map, map2ogm);
  ogm2map_ = map2ogm.inverse();

  map_set_ = true;
}

void SearchInfo::currentPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  current_pose_ = *msg;

  return;
}

void SearchInfo::currentVelocityCallback(const geometry_msgs::TwistStampedConstPtr &amp;msg)
{
  current_velocity_mps_ = msg-&gt;twist.linear.x;
}

void SearchInfo::goalCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  if (!map_set_)
    return;

  ROS_INFO(&quot;Subcscribed goal pose!&quot;);

  std::string map_frame = map_frame_;
  std::string goal_frame = msg-&gt;header.frame_id;

  // Get transform of map to the frame of goal pose
  tf::StampedTransform map2world;
  try
  {
    tf_listener_.lookupTransform(map_frame, goal_frame, ros::Time(0), map2world);
  }
  catch (tf::TransformException ex)
  {
    ROS_ERROR(&quot;%s&quot;, ex.what());
    return;
  }

  // Set goal pose
  geometry_msgs::Pose pose_msg = msg-&gt;pose;
  goal_pose_global_.pose = astar_planner::transformPose(pose_msg, map2world);
  goal_pose_global_.header = msg-&gt;header;
  goal_pose_local_.pose = astar_planner::transformPose(goal_pose_global_.pose, ogm2map_);
  goal_pose_local_.header = goal_pose_global_.header;

  goal_set_ = true;

  // Get transform of map to the frame of start pose
  std::string start_frame = current_pose_.header.frame_id;
  tf::StampedTransform map2start_frame;
  try
  {
    tf_listener_.lookupTransform(map_frame_, start_frame, ros::Time(0), map2start_frame);
  }
  catch (tf::TransformException ex)
  {
    ROS_ERROR(&quot;%s&quot;, ex.what());
    return;
  }

  // Set start pose
  start_pose_global_.pose = astar_planner::transformPose(current_pose_.pose, map2start_frame);
  start_pose_global_.header = current_pose_.header;
  start_pose_local_.pose = astar_planner::transformPose(start_pose_global_.pose, ogm2map_);
  start_pose_local_.header = start_pose_global_.header;

  start_set_ = true;
}

// get waypoints
void SearchInfo::waypointsCallback(const waypoint_follower_msgs::laneConstPtr &amp;msg)
{
  subscribed_waypoints_ = *msg;

  if (!path_set_)
  {
    current_waypoints_ = *msg;
    path_set_ = true;
  }
}

void SearchInfo::closestWaypointCallback(const std_msgs::Int32ConstPtr &amp;msg)
{
  closest_waypoint_index_ = msg-&gt;data;
}

void SearchInfo::obstacleWaypointCallback(const std_msgs::Int32ConstPtr &amp;msg)
{
  // not always avoid AND current state is not avoidance
  if (!avoidance_ &amp;&amp; state_ != &quot;OBSTACLE_AVOIDANCE&quot;)
  {
    ROS_WARN(&quot;current state is not OBSTACLE_AVOIDANCE&quot;);
    return;
  }

  // there are no obstacles
  if (msg-&gt;data &lt; 0 || closest_waypoint_index_ &lt; 0 || current_waypoints_.waypoints.empty())
  {
    return;
  }

  // msg-&gt;data : local index
  // closest   : global index
  // Conver local index to global index
  obstacle_waypoint_index_ = msg-&gt;data + closest_waypoint_index_;

  // Handle when detecting sensor noise as an obstacle
  static int prev_obstacle_waypoint_index = -1;
  static int obstacle_count = 0;
  int same_obstacle_threshold = 2;
  if (obstacle_waypoint_index_ &gt;= prev_obstacle_waypoint_index - same_obstacle_threshold &amp;&amp;
      obstacle_waypoint_index_ &lt;= prev_obstacle_waypoint_index + same_obstacle_threshold)
  {
    obstacle_count++;
  }
  else
  {
    obstacle_count = 1;
  }

  prev_obstacle_waypoint_index = obstacle_waypoint_index_;

  if (obstacle_count &lt; obstacle_detect_count_)
    return;

  // not debug mode
  if (change_path_)
    obstacle_count = 0;

  // Decide start and goal waypoints for planning
  start_waypoint_index_ = obstacle_waypoint_index_ - avoid_distance_;
  goal_waypoint_index_ = obstacle_waypoint_index_ + avoid_distance_;

  // Handle out of range
  if (start_waypoint_index_ &lt; 0)
    start_waypoint_index_ = 0;

  // Handle out of range
  if (goal_waypoint_index_ &gt;= static_cast&lt;int&gt;(getCurrentWaypoints().waypoints.size()))
    goal_waypoint_index_ = getCurrentWaypoints().waypoints.size() - 1;

  double original_path_length = calcPathLength(current_waypoints_, start_waypoint_index_, goal_waypoint_index_);
  upper_bound_distance_ = original_path_length * upper_bound_ratio_;

  // Do not avoid if (the obstacle is too close || current velocity is too fast)
  if (closest_waypoint_index_ + 1 &gt; start_waypoint_index_)
  {
    ROS_WARN(&quot;The obstacle is too close!&quot;);
    return;
  }

  // apply velocity limit for avoiding
  if (current_velocity_mps_ &gt; avoid_velocity_limit_mps_)
  {
    ROS_WARN(&quot;Velocity of the vehicle exceeds the avoid velocity limit&quot;);
    return;
  }

  // Set start pose
  start_pose_global_ = current_waypoints_.waypoints[start_waypoint_index_].pose;
  start_pose_local_.pose = astar_planner::transformPose(start_pose_global_.pose, ogm2map_);
  start_set_ = true;

  // Set transit pose
  // TODO:
  double actual_car_width = 2.5;  // [m]
  geometry_msgs::Pose relative_transit_pose;
  // TODO: always right avoidance ???
  relative_transit_pose.position.y -= actual_car_width;
  relative_transit_pose.orientation = current_waypoints_.waypoints[obstacle_waypoint_index_].pose.pose.orientation;
  tf::Pose obstacle_pose_tf;
  tf::poseMsgToTF(current_waypoints_.waypoints[obstacle_waypoint_index_].pose.pose, obstacle_pose_tf);

  transit_pose_global_.pose = astar_planner::transformPose(relative_transit_pose, obstacle_pose_tf);
  transit_pose_local_.pose = astar_planner::transformPose(transit_pose_global_.pose, ogm2map_);

  // Set goal pose
  goal_pose_global_ = current_waypoints_.waypoints[goal_waypoint_index_].pose;
  goal_pose_local_.pose = astar_planner::transformPose(goal_pose_global_.pose, ogm2map_);

  goal_set_ = true;
}

void SearchInfo::stateCallback(const std_msgs::StringConstPtr &amp;msg)
{
  state_ = msg-&gt;data;
}

void SearchInfo::reset()
{
  map_set_ = false;
  start_set_ = false;
  goal_set_ = false;
  obstacle_waypoint_index_ = -1;
}
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/obstacle_avoid/search_info_ros.h" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/obstacle_avoid/search_info_ros.h">
				<diff>@@ -32,7 +32,7 @@
 #define SEARCH_INFO_ROS_H
 
 #include &quot;astar_util.h&quot;
-#include &quot;waypoint_follower_msgs/lane.h&quot;
+#include &quot;autoware_msgs/lane.h&quot;
 #include &quot;waypoint_follower/libwaypoint_follower.h&quot;
 
 #include &lt;nav_msgs/OccupancyGrid.h&gt;
@@ -55,7 +55,7 @@ public:
   void goalCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg);
   void currentPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg);
   void currentVelocityCallback(const geometry_msgs::TwistStampedConstPtr &amp;msg);
-  void waypointsCallback(const waypoint_follower_msgs::laneConstPtr &amp;msg);
+  void waypointsCallback(const autoware_msgs::laneConstPtr &amp;msg);
   void closestWaypointCallback(const std_msgs::Int32ConstPtr &amp;msg);
   void obstacleWaypointCallback(const std_msgs::Int32ConstPtr &amp;msg);
   void stateCallback(const std_msgs::StringConstPtr &amp;msg);
@@ -101,11 +101,11 @@ public:
   {
     return current_velocity_mps_;
   }
-  waypoint_follower_msgs::lane getSubscribedWaypoints() const
+  autoware_msgs::lane getSubscribedWaypoints() const
   {
     return subscribed_waypoints_;
   }
-  waypoint_follower_msgs::lane getCurrentWaypoints() const
+  autoware_msgs::lane getCurrentWaypoints() const
   {
     return current_waypoints_;
   }
@@ -143,7 +143,7 @@ public:
   }
 
   // set method
-  void setCurrentWaypoints(const waypoint_follower_msgs::lane &amp;waypoints)
+  void setCurrentWaypoints(const autoware_msgs::lane &amp;waypoints)
   {
     current_waypoints_ = waypoints;
   }
@@ -152,7 +152,7 @@ public:
   void reset();
 
 private:
-  double calcPathLength(const waypoint_follower_msgs::lane &amp;lane, const int start_waypoint_index,
+  double calcPathLength(const autoware_msgs::lane &amp;lane, const int start_waypoint_index,
                         const int goal_waypoint_index) const;
 
   nav_msgs::OccupancyGrid map_;
@@ -186,8 +186,8 @@ private:
   int obstacle_waypoint_index_;
   int start_waypoint_index_;
   int goal_waypoint_index_;
-  waypoint_follower_msgs::lane subscribed_waypoints_;
-  waypoint_follower_msgs::lane current_waypoints_;
+  autoware_msgs::lane subscribed_waypoints_;
+  autoware_msgs::lane current_waypoints_;
   geometry_msgs::PoseStamped current_pose_;
   double current_velocity_mps_;
   std::string state_;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef SEARCH_INFO_ROS_H
#define SEARCH_INFO_ROS_H

#include &quot;astar_util.h&quot;
#include &quot;waypoint_follower_msgs/lane.h&quot;
#include &quot;waypoint_follower/libwaypoint_follower.h&quot;

#include &lt;nav_msgs/OccupancyGrid.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;std_msgs/Int32.h&gt;
#include &lt;std_msgs/String.h&gt;

namespace astar_planner
{
class SearchInfo
{
public:
  SearchInfo();
  ~SearchInfo();

  // ROS Callback
  void mapCallback(const nav_msgs::OccupancyGridConstPtr &amp;msg);
  // void startCallback(const geometry_msgs::PoseWithCovarianceStampedConstPtr &amp;msg);
  void goalCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg);
  void currentPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg);
  void currentVelocityCallback(const geometry_msgs::TwistStampedConstPtr &amp;msg);
  void waypointsCallback(const waypoint_follower_msgs::laneConstPtr &amp;msg);
  void closestWaypointCallback(const std_msgs::Int32ConstPtr &amp;msg);
  void obstacleWaypointCallback(const std_msgs::Int32ConstPtr &amp;msg);
  void stateCallback(const std_msgs::StringConstPtr &amp;msg);

  // get method
  bool getMapSet() const
  {
    return map_set_;
  }
  bool getStartSet() const
  {
    return start_set_;
  }
  bool getGoalSet() const
  {
    return goal_set_;
  }
  bool getPathSet() const
  {
    return path_set_;
  }
  nav_msgs::OccupancyGrid getMap() const
  {
    return map_;
  }
  geometry_msgs::PoseStamped getStartPose() const
  {
    return start_pose_local_;
  }
  geometry_msgs::PoseStamped getGoalPose() const
  {
    return goal_pose_local_;
  }
  geometry_msgs::PoseStamped getTransitPose() const
  {
    return transit_pose_local_;
  }
  geometry_msgs::PoseStamped getCurrentPose() const
  {
    return current_pose_;
  }
  double getCurrentVelocity() const
  {
    return current_velocity_mps_;
  }
  waypoint_follower_msgs::lane getSubscribedWaypoints() const
  {
    return subscribed_waypoints_;
  }
  waypoint_follower_msgs::lane getCurrentWaypoints() const
  {
    return current_waypoints_;
  }
  int getObstacleWaypointIndex() const
  {
    return obstacle_waypoint_index_;
  }
  int getClosestWaypointIndex() const
  {
    return closest_waypoint_index_;
  }
  int getStartWaypointIndex() const
  {
    return start_waypoint_index_;
  }
  int getGoalWaypointIndex() const
  {
    return goal_waypoint_index_;
  }
  double getUpperBoundDistance() const
  {
    return upper_bound_distance_;
  }
  double getAvoidVelocityLimitMPS() const
  {
    return avoid_velocity_limit_mps_;
  }
  bool getAvoidance() const
  {
    return avoidance_;
  }
  bool getChangePath() const
  {
    return change_path_;
  }

  // set method
  void setCurrentWaypoints(const waypoint_follower_msgs::lane &amp;waypoints)
  {
    current_waypoints_ = waypoints;
  }

  // Reset flag
  void reset();

private:
  double calcPathLength(const waypoint_follower_msgs::lane &amp;lane, const int start_waypoint_index,
                        const int goal_waypoint_index) const;

  nav_msgs::OccupancyGrid map_;
  geometry_msgs::PoseStamped start_pose_global_;
  geometry_msgs::PoseStamped goal_pose_global_;
  geometry_msgs::PoseStamped transit_pose_global_;
  geometry_msgs::PoseStamped start_pose_local_;
  geometry_msgs::PoseStamped goal_pose_local_;
  geometry_msgs::PoseStamped transit_pose_local_;
  // Transform which converts global frame (/map in Autoware) to OccupancyGrid frame
  tf::Transform ogm2map_;
  tf::TransformListener tf_listener_;

  // set data flag
  bool map_set_;
  bool start_set_;
  bool goal_set_;
  bool path_set_;

  // ROS param
  std::string map_frame_;
  int obstacle_detect_count_;        // 1 increment means 100ms
  int avoid_distance_;               // the number of waypoint
  double avoid_velocity_limit_mps_;  // m/s
  double upper_bound_ratio_;
  bool avoidance_;
  bool change_path_;

  // subscribed imformation
  int closest_waypoint_index_;
  int obstacle_waypoint_index_;
  int start_waypoint_index_;
  int goal_waypoint_index_;
  waypoint_follower_msgs::lane subscribed_waypoints_;
  waypoint_follower_msgs::lane current_waypoints_;
  geometry_msgs::PoseStamped current_pose_;
  double current_velocity_mps_;
  std::string state_;

  // for prunning
  double upper_bound_distance_;
};

}  // namespace astar_planner

#endif  // SEARCH_INFO_ROS_H
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_info.cpp" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_info.cpp">
				<diff>@@ -53,7 +53,7 @@ void VelocitySetInfo::clearPoints()
   points_.clear();
 }
 
-void VelocitySetInfo::configCallback(const runtime_manager::ConfigVelocitySetConstPtr &amp;config)
+void VelocitySetInfo::configCallback(const autoware_msgs::ConfigVelocitySetConstPtr &amp;config)
 {
   stop_distance_ = config-&gt;others_distance;
   stop_range_ = config-&gt;detection_range;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include &quot;velocity_set_info.h&quot;

VelocitySetInfo::VelocitySetInfo()
  : stop_range_(1.3),
    deceleration_range_(0),
    points_threshold_(10),
    detection_height_top_(0.2),
    detection_height_bottom_(-1.7),
    stop_distance_(10),
    decel_(0.8),
    velocity_change_limit_(2.77),
    temporal_waypoints_size_(100),
    set_pose_(false)
{
}

VelocitySetInfo::~VelocitySetInfo()
{
}

void VelocitySetInfo::clearPoints()
{
  points_.clear();
}

void VelocitySetInfo::configCallback(const runtime_manager::ConfigVelocitySetConstPtr &amp;config)
{
  stop_distance_ = config-&gt;others_distance;
  stop_range_ = config-&gt;detection_range;
  points_threshold_ = config-&gt;threshold_points;
  detection_height_top_ = config-&gt;detection_height_top;
  detection_height_bottom_ = config-&gt;detection_height_bottom;
  decel_ = config-&gt;deceleration;
  velocity_change_limit_ = config-&gt;velocity_change_limit / 3.6; // kmph -&gt; mps
  deceleration_range_ = config-&gt;deceleration_range;
  temporal_waypoints_size_ = config-&gt;temporal_waypoints_size;
}

void VelocitySetInfo::pointsCallback(const sensor_msgs::PointCloud2ConstPtr &amp;msg)
{
  pcl::PointCloud&lt;pcl::PointXYZ&gt; sub_points;
  pcl::fromROSMsg(*msg, sub_points);

  points_.clear();
  for (const auto &amp;v : sub_points)
  {
    if (v.x == 0 &amp;&amp; v.y == 0)
      continue;

    if (v.z &gt; detection_height_top_ || v.z &lt; detection_height_bottom_)
      continue;

    points_.push_back(v);
  }
}

void VelocitySetInfo::controlPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  control_pose_ = *msg;

  if (!set_pose_)
    set_pose_ = true;
}

void VelocitySetInfo::localizerPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg)
{
  localizer_pose_ = *msg;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_info.h" new_path="ros/src/computing/planning/motion/packages/astar_planner/nodes/velocity_set/velocity_set_info.h">
				<diff>@@ -36,7 +36,7 @@
 #include &lt;geometry_msgs/PoseStamped.h&gt;
 #include &lt;std_msgs/Int32.h&gt;
 
-#include &quot;runtime_manager/ConfigVelocitySet.h&quot;
+#include &quot;autoware_msgs/ConfigVelocitySet.h&quot;
 
 class VelocitySetInfo
 {
@@ -62,7 +62,7 @@ class VelocitySetInfo
   ~VelocitySetInfo();
 
   // ROS Callback
-  void configCallback(const runtime_manager::ConfigVelocitySetConstPtr &amp;msg);
+  void configCallback(const autoware_msgs::ConfigVelocitySetConstPtr &amp;msg);
   void pointsCallback(const sensor_msgs::PointCloud2ConstPtr &amp;msg);
   void controlPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg);
   void localizerPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#ifndef VELOCITY_SET_INFO_H
#define VELOCITY_SET_INFO_H

#include &lt;ros/ros.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;geometry_msgs/PoseStamped.h&gt;
#include &lt;std_msgs/Int32.h&gt;

#include &quot;runtime_manager/ConfigVelocitySet.h&quot;

class VelocitySetInfo
{
 private:
  // parameters
  double stop_range_;               // if obstacle is in this range, stop
  double deceleration_range_;       // if obstacle is in this range, decelerate
  int points_threshold_;            // points threshold to find obstacles
  double detection_height_top_;     // from sensor
  double detection_height_bottom_;  // from sensor
  double stop_distance_;            // (meter) stopping distance from obstacles
  double decel_;                    // (m/s^2) deceleration
  double velocity_change_limit_;    // (m/s)
  double temporal_waypoints_size_;  // (meter)

  pcl::PointCloud&lt;pcl::PointXYZ&gt; points_;
  geometry_msgs::PoseStamped localizer_pose_;  // pose of sensor
  geometry_msgs::PoseStamped control_pose_;    // pose of base_link
  bool set_pose_;

 public:
  VelocitySetInfo();
  ~VelocitySetInfo();

  // ROS Callback
  void configCallback(const runtime_manager::ConfigVelocitySetConstPtr &amp;msg);
  void pointsCallback(const sensor_msgs::PointCloud2ConstPtr &amp;msg);
  void controlPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg);
  void localizerPoseCallback(const geometry_msgs::PoseStampedConstPtr &amp;msg);

  void clearPoints();

  double getStopRange() const
  {
    return stop_range_;
  }

  double getDecelerationRange() const
  {
    return deceleration_range_;
  }

  int getPointsThreshold() const
  {
    return points_threshold_;
  }

  int getDetectionHeightTop() const
  {
    return detection_height_top_;
  }

  int getDetectionHeightBottom() const
  {
    return detection_height_bottom_;
  }

  int getStopDistance() const
  {
    return stop_distance_;
  }

  double getDeceleration() const
  {
    return decel_;
  }

  double getVelocityChangeLimit() const
  {
    return velocity_change_limit_;
  }

  double getTemporalWaypointsSize() const
  {
    return temporal_waypoints_size_;
  }

  pcl::PointCloud&lt;pcl::PointXYZ&gt; getPoints() const
  {
    return points_;
  }

  geometry_msgs::PoseStamped getControlPose() const
  {
    return control_pose_;
  }

  geometry_msgs::PoseStamped getLocalizerPose() const
  {
    return localizer_pose_;
  }

  bool getSetPose() const
  {
    return set_pose_;
  }
};

#endif // VELOCITY_SET_INFO_H
</old_file>
			</file>
			<file old_path="ros/src/system/sync/sync_drivers.cpp" new_path="ros/src/system/sync/sync_drivers.cpp">
				<diff>@@ -36,7 +36,7 @@
 /* user header */
 #include &quot;sensor_msgs/Image.h&quot;
 #include &quot;sensor_msgs/PointCloud2.h&quot;
-#include &quot;autoware_msgs/time_diff.h&quot;
+#include &quot;autoware_msgs/Sync_time_diff.h&quot;
 
 /* ----var---- */
 /* common var */
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/
/* ----header---- */
/* common header */
#include &quot;ros/ros.h&quot;
#include &lt;sstream&gt;
#include &lt;boost/circular_buffer.hpp&gt;
#include &quot;std_msgs/Header.h&quot;
/* user header */
#include &quot;sensor_msgs/Image.h&quot;
#include &quot;sensor_msgs/PointCloud2.h&quot;
#include &quot;autoware_msgs/time_diff.h&quot;

/* ----var---- */
/* common var */
/* user var */
sensor_msgs::Image image_raw_buf;

ros::Publisher points_raw__pub;
ros::Publisher image_raw__pub;
ros::Publisher time_diff_pub;
bool is_sim;

double fabs_time_diff(const std_msgs::Header *timespec1, const std_msgs::Header *timespec2)
{
    double time1 = (double)timespec1-&gt;stamp.sec + (double)timespec1-&gt;stamp.nsec/1000000000L;
    double time2 = (double)timespec2-&gt;stamp.sec + (double)timespec2-&gt;stamp.nsec/1000000000L;
    return fabs(time1 - time2);
}

void image_raw_callback(sensor_msgs::Image image_raw_msg)
{
    image_raw_buf = image_raw_msg;
}

void points_raw_callback(const sensor_msgs::PointCloud2::ConstPtr&amp; points_raw_msg)
{
    autoware_msgs::Sync_time_diff time_diff_msg;
    time_diff_msg.header.frame_id = &quot;0&quot;;
    time_diff_msg.header.stamp = points_raw_msg-&gt;header.stamp;
    time_diff_msg.time_diff = fabs_time_diff(&amp;(points_raw_msg-&gt;header), &amp;image_raw_buf.header)*1000.0; //msec
    time_diff_msg.camera = image_raw_buf.header.stamp;
    time_diff_msg.lidar = points_raw_msg-&gt;header.stamp;
    time_diff_pub.publish(time_diff_msg);

    image_raw_buf.header.stamp = points_raw_msg-&gt;header.stamp;
    image_raw__pub.publish(image_raw_buf);
    points_raw__pub.publish(points_raw_msg);
}



int main(int argc, char **argv)
{
  ros::init(argc, argv, &quot;sync_drivers&quot;);
  ros::NodeHandle nh;
  ros::NodeHandle private_nh(&quot;~&quot;);

  ros::Subscriber image_raw_sub = nh.subscribe(&quot;/image_raw&quot;, 1, image_raw_callback);
  ros::Subscriber points_raw_sub;
  points_raw_sub = nh.subscribe(&quot;/points_raw&quot;, 1, points_raw_callback);

  image_raw__pub = nh.advertise&lt;sensor_msgs::Image&gt;(&quot;image_raw&quot;, 1);
  points_raw__pub = nh.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;points_raw&quot;, 1);
  time_diff_pub = nh.advertise&lt;autoware_msgs::Sync_time_diff&gt;(&quot;/time_difference&quot;, 1);

  ros::spin();


  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="955c5de6a572f7b6b6cd67171db4d36f2cced2ea" fix_time="450,56015">
		<msg>fix a build issue due to autoware_msgs on the Indigo</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/lib/image/kf/src/kf.cpp" new_path="ros/src/computing/perception/detection/lib/image/kf/src/kf.cpp">
				<diff>@@ -37,10 +37,10 @@
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/Image.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;runtime_manager/ConfigCarKf.h&gt;
-#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
+#include &lt;autoware_msgs/ConfigCarKf.h&gt;
+#include &lt;autoware_msgs/image_obj_ranged.h&gt;
 
-#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
+#include &lt;autoware_msgs/image_obj_tracked.h&gt;
 #include &lt;std_msgs/Header.h&gt;
 
 //TRACKING STUFF
@@ -92,7 +92,7 @@ static bool 		USE_ORB;
 
 static bool 		track_ready_;
 static bool 		detect_ready_;
-static cv_tracker_msgs::image_obj_tracked kf_objects_msg_;
+static autoware_msgs::image_obj_tracked kf_objects_msg_;
 
 struct kstate
 {
@@ -819,7 +819,7 @@ void trackAndDrawObjects(cv::Mat&amp; image, int frameNumber, std::vector&lt;ObjectDete
 
 	//ROS
 	int num = tracked_detections.size();
-	std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; rect_ranged_array;
+	std::vector&lt;autoware_msgs::image_rect_ranged&gt; rect_ranged_array;
 	std::vector&lt;int&gt; real_data(num,0);
 	std::vector&lt;int&gt; obj_id(num, 0);
 	std::vector&lt;int&gt; lifespan(num, 0);
@@ -828,7 +828,7 @@ void trackAndDrawObjects(cv::Mat&amp; image, int frameNumber, std::vector&lt;ObjectDete
 	for (size_t i = 0; i &lt; tracked_detections.size(); i++)
 	{
 		kstate od = tracked_detections[i];
-		cv_tracker_msgs::image_rect_ranged rect_ranged_;
+		autoware_msgs::image_rect_ranged rect_ranged_;
 
 		//od.rect contains x,y, width, height
 		rectangle(image, od.pos, od.color, 3);
@@ -850,7 +850,7 @@ void trackAndDrawObjects(cv::Mat&amp; image, int frameNumber, std::vector&lt;ObjectDete
 		//ENDROS
 	}
 	//more ros
-	cv_tracker_msgs::image_obj_tracked kf_objects_msg;
+	autoware_msgs::image_obj_tracked kf_objects_msg;
 
 	kf_objects_msg.type = object_type;
 	kf_objects_msg.total_num = num;
@@ -882,12 +882,12 @@ void image_callback(const sensor_msgs::Image&amp; image_source)
 	_counter++;
 }
 
-void detections_callback(cv_tracker_msgs::image_obj_ranged image_objects_msg)
+void detections_callback(autoware_msgs::image_obj_ranged image_objects_msg)
 {
 	if(!detect_ready_)
 	{
 		unsigned int num = image_objects_msg.obj.size();
-		std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects = image_objects_msg.obj;
+		std::vector&lt;autoware_msgs::image_rect_ranged&gt; objects = image_objects_msg.obj;
 		object_type = image_objects_msg.type;
 		image_objects_header = image_objects_msg.header;
 		//points are X,Y,W,H and repeat for each instance
@@ -918,7 +918,7 @@ void detections_callback(cv_tracker_msgs::image_obj_ranged image_objects_msg)
 	publish_if_possible();
 }
 
-static void kf_config_cb(const runtime_manager::ConfigCarKf::ConstPtr&amp; param)
+static void kf_config_cb(const autoware_msgs::ConfigCarKf::ConstPtr&amp; param)
 {
 	if (param-&gt;initial_lifespan &gt; 0)
 		INITIAL_LIFESPAN	= param-&gt;initial_lifespan;
@@ -962,7 +962,7 @@ int kf_main(int argc, char* argv[])
 	ros::NodeHandle n;
 	ros::NodeHandle private_nh(&quot;~&quot;);
 
-	image_objects = n.advertise&lt;cv_tracker_msgs::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
+	image_objects = n.advertise&lt;autoware_msgs::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);
 
 #if (CV_MAJOR_VERSION == 3)
 	generateColors(_colors, 25);
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

//ROS STUFF
#include &lt;ros/ros.h&gt;

#include &lt;message_filters/subscriber.h&gt;
#include &lt;message_filters/time_synchronizer.h&gt;

#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;runtime_manager/ConfigCarKf.h&gt;
#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;

#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
#include &lt;std_msgs/Header.h&gt;

//TRACKING STUFF
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/objdetect/objdetect.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;opencv2/video/tracking.hpp&gt;
#include &lt;opencv2/calib3d/calib3d.hpp&gt;

#include &lt;iostream&gt;
#include &lt;stdio.h&gt;

#include &lt;sstream&gt;
#include &lt;algorithm&gt;
#include &lt;iterator&gt;

#define SSTR( x ) dynamic_cast&lt; std::ostringstream &amp; &gt;( \
        ( std::ostringstream() &lt;&lt; std::dec &lt;&lt; x ) ).str()

#include &lt;opencv2/core/version.hpp&gt;
#if (CV_MAJOR_VERSION == 3)
#include &quot;gencolors.cpp&quot;
#else
#include &lt;opencv2/contrib/contrib.hpp&gt;
#endif

struct ObjectDetection_
{
	//ObjectDetection_();
	//ObjectDetection_(const cv::Rect&amp; rect, float score, int classId=1);
	cv::Rect rect;
	float score;
	int classID;
};

ros::Publisher image_objects;//ROS

static int 			DEFAULT_LIFESPAN; //LIFESPAN of objects before stop being tracked, in frames
static int	 		INITIAL_LIFESPAN; //LIFESPAN of objects before stop being tracked, in frames
static int			ORB_NUM_FEATURES;
static unsigned int	ORB_MIN_MATCHES;
static float		ORB_KNN_RATIO;
static float 		NOISE_COV;
static float 		MEAS_NOISE_COV;
static float 		ERROR_ESTIMATE_COV;
static float 		OVERLAPPING_PERC;
static bool 		SHOW_PREDICTIONS;
static bool 		USE_ORB;

static bool 		track_ready_;
static bool 		detect_ready_;
static cv_tracker_msgs::image_obj_tracked kf_objects_msg_;

struct kstate
{
	cv::KalmanFilter	KF;//KalmanFilter for this object
	cv::Rect		pos;//position of the object centerx, centery, width, height
	float			score;//DPM score
	bool			active;//if too old (lifespan) don't use
	unsigned int		id;//id of this tracked object
	cv::Mat			image;//image containing the detected and tracked object
	int			lifespan;//remaining lifespan before deprecate
	//ObjectDetection_ obj;//currently not used
	cv::Scalar	color;
	int		real_data;
	//std::vector&lt;KeyPoint&gt; orbKeypoints;
	//cv::Mat				orbDescriptors;
	float range;//range to this object gotten by range_fusion
	float min_height;//minimum height detected by range_fusion
	float max_height;//maximum height detected by range_fusion
};

//tracking required code
std::vector&lt;kstate&gt; 	_kstates;
std::vector&lt;bool&gt; 	_active;
std::vector&lt;cv::Scalar&gt;	_colors;
std::vector&lt;ObjectDetection_&gt; _dpm_detections;

std::string object_type;
std::vector&lt;float&gt; _ranges;
std::vector&lt;float&gt; _min_heights;
std::vector&lt;float&gt; _max_heights;

std_msgs::Header    image_objects_header;

//static bool _ready;

long int _counter = 0;
//

void getRectFromPoints(std::vector&lt; cv::Point2f &gt; corners, cv::Rect&amp; outBoundingBox)
{
	int min_x=0, min_y=0, max_x=0, max_y=0;
	for (unsigned int i=0; i&lt;corners.size(); i++)
	{
		if (corners[i].x &gt; 0)
		{
			if (corners[i].x &lt; min_x)
				min_x = corners[i].x;
			if (corners[i].x&gt;max_x)
				max_x = corners[i].x;
		}
		if (corners[i].y &gt; 0)
		{
			if (corners[i].y &lt; min_y)
				min_y = corners[i].y;
			if (corners[i].y &gt; max_y)
				max_y = corners[i].y;
		}
	}
	outBoundingBox.x 		= min_x;
	outBoundingBox.y 		= min_y;
	outBoundingBox.width 	= max_x - min_x;
	outBoundingBox.height 	= max_y - min_y;

}

/*bool orbMatch(cv::Mat&amp; inImageScene, cv::Mat&amp; inImageObj, cv::Rect&amp; outBoundingBox, unsigned int inMinMatches=2, float inKnnRatio=0.7)
{
	//vector of keypoints
	std::vector&lt; cv::KeyPoint &gt; keypointsO;
	std::vector&lt; cv::KeyPoint &gt; keypointsS;

	cv::Mat descriptors_object, descriptors_scene;

	cv::Mat outImg;
	inImageScene.copyTo(outImg);

	//-- Step 1: Extract keypoints
	cv::OrbFeatureDetector orb(ORB_NUM_FEATURES);
	orb.detect(inImageScene, keypointsS);
	if (keypointsS.size() &lt; ORB_MIN_MATCHES)
	{
		//cout &lt;&lt; &quot;Not enough keypoints S, object not found&gt;&quot; &lt;&lt; keypointsS.size() &lt;&lt; endl;
		return false;
	}
	orb.detect(inImageObj, keypointsO);
	if (keypointsO.size() &lt; ORB_MIN_MATCHES)
	{
		//cout &lt;&lt; &quot;Not enough keypoints O, object not found&gt;&quot; &lt;&lt; keypointsO.size() &lt;&lt; endl;
		return false;
	}

	//Calculate descriptors (feature vectors)
	cv::OrbDescriptorExtractor extractor;
	extractor.compute(inImageScene, keypointsS, descriptors_scene);
	extractor.compute(inImageObj, keypointsO, descriptors_object);

	//Matching descriptor vectors using FLANN matcher
	cv::BFMatcher matcher;
	//descriptors_scene.size(), keypointsO.size(), keypointsS.size();
	std::vector&lt; std::vector&lt; cv::DMatch &gt;  &gt; matches;
	matcher.knnMatch(descriptors_object, descriptors_scene, matches, 2);
	std::vector&lt; cv::DMatch &gt; good_matches;
	good_matches.reserve(matches.size());

	for (size_t i = 0; i &lt; matches.size(); ++i)
	{
		if (matches[i].size() &lt; 3)
			continue;

		const cv::DMatch &amp;m1 = matches[i][0];
		const cv::DMatch &amp;m2 = matches[i][1];

		if (m1.distance &lt;= inKnnRatio * m2.distance)
			good_matches.push_back(m1);
	}

	if ((good_matches.size() &gt;= inMinMatches))
	{
		std::vector&lt; cv::Point2f &gt; obj;
		std::vector&lt; cv::Point2f &gt; scene;

		for (unsigned int i = 0; i &lt; good_matches.size(); i++)
		{
			// Get the keypoints from the good matches
			obj.push_back(keypointsO[good_matches[i].queryIdx].pt);
			scene.push_back(keypointsS[good_matches[i].trainIdx].pt);
		}

		cv::Mat H = findHomography(obj, scene, CV_RANSAC);

		// Get the corners from the image_1 ( the object to be &quot;detected&quot; )
		std::vector&lt; cv::Point2f &gt; obj_corners(4);
		obj_corners[0] = cvPoint(0, 0); obj_corners[1] = cvPoint(inImageObj.cols, 0);
		obj_corners[2] = cvPoint(inImageObj.cols, inImageObj.rows); obj_corners[3] = cvPoint(0, inImageObj.rows);
		std::vector&lt; cv::Point2f &gt; scene_corners(4);

		perspectiveTransform(obj_corners, scene_corners, H);

		// Draw lines between the corners (the mapped object in the scene - image_2 )
		line(outImg, scene_corners[0], scene_corners[1], cv::Scalar(255, 0, 0), 2); //TOP line
		line(outImg, scene_corners[1], scene_corners[2], cv::Scalar(255, 0, 0), 2);
		line(outImg, scene_corners[2], scene_corners[3], cv::Scalar(255, 0, 0), 2);
		line(outImg, scene_corners[3], scene_corners[0], cv::Scalar(255, 0, 0), 2);

		//imshow(&quot;Scene&quot;, outImg);
		//imshow(&quot;Obj&quot;, inImageObj);
		//cvWaitKey(5);

		return true;
	}

	return false;
}*/

///Returns true if an im1 is contained in im2 or viceversa
bool crossCorr(cv::Mat im1, cv::Mat im2)
{
	//im1 roi from the previous frame
	//im2 roi fromcurrent frame
	if (im1.rows &lt;= 0 || im1.cols &lt;= 0 || im2.rows &lt;= 0 || im2.cols &lt;= 0)
		return false;

	cv::Mat result, larger_im, smaller_im;

	/// Create the result matrix
	int result_cols;
	int result_rows;

	//select largest image
	if (im2.cols &gt; im1.cols)
	{
		larger_im = im2;
		smaller_im = im1;
	}
	else
	{
		larger_im = im1;
		smaller_im = im2;
	}
	//check rows to be also larger otherwise crop the smaller to remove extra rows
	if (larger_im.rows &lt; smaller_im.rows)
	{
		//add rows to match sizes
		cv::Mat rows = cv::Mat::ones(smaller_im.rows - larger_im.rows, larger_im.cols, larger_im.type());
		larger_im.push_back(rows);
	}

	result_cols = larger_im.cols - smaller_im.cols + 1;
	result_rows = larger_im.rows - smaller_im.rows + 1;
	result.create(result_cols, result_rows, CV_32FC1);

	/// Do the Matching and Normalize
	matchTemplate(larger_im, smaller_im, result, CV_TM_CCORR_NORMED);
	//normalize(result, result, 0, 1, NORM_MINMAX, -1, cv::Mat());

	/// Localizing the best match with minMaxLoc
	double minVal; double maxVal; cv::Point minLoc; cv::Point maxLoc;
	cv::Point matchLoc;

	minMaxLoc(result, &amp;minVal, &amp;maxVal, &amp;minLoc, &amp;maxLoc, cv::Mat());

	matchLoc = maxLoc;

	/// Show me what you got
	cv::Mat scene = larger_im.clone();
	rectangle(scene, matchLoc, cv::Point(matchLoc.x + smaller_im.cols, matchLoc.y + smaller_im.rows), cv::Scalar(0, 0, 255), 2, 8, 0);
	//imshow(image_window, scene);
	//imshow(result_window, result);

	//if (maxVal&gt;0.89 &amp;&amp; minVal &lt;0.3)
	bool ret;
	int thresWidth = (larger_im.cols)*.7;
	if ( (maxVal &gt; 0.5) &amp;&amp; (smaller_im.cols &gt; thresWidth) )//good threshold and consistent size
	{

		//std::cout &lt;&lt; &quot;matched&quot; &lt;&lt; endl;
		ret = true;
	}
	else
	{
		//std::cout &lt;&lt; &quot;non matched&quot; &lt;&lt; endl;
		ret = false;
	}
	//cv::imshow(&quot;match1&quot;, scene);
	//cv::imshow(&quot;match2&quot;, smaller_im);

	return ret;
}

void posScaleToBbox(std::vector&lt;kstate&gt; kstates, std::vector&lt;kstate&gt;&amp; trackedDetections)
{
	for (unsigned int i = 0; i &lt; kstates.size(); i++)
	{
		if (kstates[i].active)
		{
			kstate tmp;
			tmp.pos.x = kstates[i].pos.x;// -(kstates[i].pos.width / 2);
			tmp.pos.y = kstates[i].pos.y;// -(kstates[i].pos.height / 2);
			tmp.pos.width = kstates[i].pos.width;
			tmp.pos.height = kstates[i].pos.height;
			tmp.color = kstates[i].color;
			tmp.id = kstates[i].id;
			tmp.score = kstates[i].score;
			tmp.lifespan = kstates[i].lifespan;
			tmp.real_data = kstates[i].real_data;
			tmp.range = kstates[i].range;
			tmp.min_height = kstates[i].min_height;
			tmp.max_height = kstates[i].max_height;

			//fill in also LAtentSvm object
			//tmp.obj.rect = tmp.pos;
			//tmp.obj.score = tmp.score;

			if (tmp.pos.x &lt; 0)
				tmp.pos.x = 0;
			if (tmp.pos.y &lt; 0)
				tmp.pos.y = 0;

			trackedDetections.push_back(tmp);
		}
	}
}

int getAvailableIndex(std::vector&lt;kstate&gt;&amp; kstates)
{
	unsigned int cur_size = kstates.size();
	std::vector&lt;bool&gt; ids;

	ids.resize(cur_size, false);

	for (unsigned int i=0; i&lt;cur_size;i++)
	{
		ids[kstates[i].id]= true;
	}
	for (unsigned int i=0; i&lt;cur_size;i++)
	{
		if(ids[i] == false)
			return i;
	}
	return cur_size;
}

void initTracking(ObjectDetection_ object, std::vector&lt;kstate&gt;&amp; kstates,
		  ObjectDetection_ detection,
		  cv::Mat&amp; image, std::vector&lt;cv::Scalar&gt; colors, float range)
{
	kstate new_state;
	//cv::KalmanFilter KF(4, 2, 0);//XY Only
	cv::KalmanFilter KF(8, 4, 0);

	/*cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(2, 1) &lt;&lt; object.rect.x,//XY Only
		object.rect.y);*/
	cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(4, 1) &lt;&lt; object.rect.x,
		object.rect.y, object.rect.width, object.rect.height);

	/*KF.transitioncv::Matrix = (cv::Mat_&lt;float&gt;(4, 4) &lt;&lt; 1, 0, 1, 0,//XY Only
												0, 1, 0, 1,
												0, 0, 1, 0,
												0, 0, 0, 1);*/
	KF.transitionMatrix = (cv::Mat_&lt;float&gt;(8, 8)
	&lt;&lt;	1, 0, 0, 0, 1, 0, 0, 0,
		0, 1, 0, 0, 0, 1, 0, 0,
		0, 0, 1, 0, 0, 0, 1, 0,
		0, 0, 0, 1, 0, 0, 0, 1,
		0, 0, 0, 0, 1, 0, 0, 0,
		0, 0, 0, 0, 0, 1, 0, 0,
		0, 0, 0, 0, 0, 0, 1, 0,
		0, 0, 0, 0, 0, 0, 0, 1);

	//init pre
	KF.statePre.at&lt;float&gt;(0) = object.rect.x;
	KF.statePre.at&lt;float&gt;(1) = object.rect.y;
	KF.statePre.at&lt;float&gt;(2) = object.rect.width;//XY Only
	KF.statePre.at&lt;float&gt;(3) = object.rect.height;//XY Only
	//init post
	KF.statePost.at&lt;float&gt;(0) = object.rect.x;
	KF.statePost.at&lt;float&gt;(1) = object.rect.y;
	KF.statePost.at&lt;float&gt;(2) = object.rect.width;//XY Only
	KF.statePost.at&lt;float&gt;(3) = object.rect.height;//XY Only

	cv::setIdentity(KF.measurementMatrix);
	cv::setIdentity(KF.processNoiseCov, cv:: Scalar::all(NOISE_COV));//1e-4
	cv::setIdentity(KF.measurementNoiseCov, cv::Scalar::all(MEAS_NOISE_COV));//1e-3
	cv::setIdentity(KF.errorCovPost, cv::Scalar::all(ERROR_ESTIMATE_COV));//100

	//clip detection
	//check that predicted positions are inside the image
	if (detection.rect.x &lt; 0)
		detection.rect.x = 0;
	if (detection.rect.x &gt; image.cols)
		detection.rect.x = image.cols - 1;
	if (detection.rect.y &lt; 0)
		detection.rect.y = 0;
	if (detection.rect.height &gt; image.rows)
		detection.rect.height = image.rows - 1;
	if (detection.rect.width + detection.rect.x &gt; image.cols)
		detection.rect.width = image.cols - detection.rect.x;
	if (detection.rect.height + detection.rect.y &gt; image.rows)
		detection.rect.height = image.rows - detection.rect.y;

	//save data to kstate
	new_state.active = true;
	new_state.image = image(cv::Rect(detection.rect.x,
		detection.rect.y,
		detection.rect.width,
		detection.rect.height)).clone();//Crop image and obtain only object (ROI)
	new_state.KF = KF;
	new_state.lifespan = INITIAL_LIFESPAN;//start only with 1
	new_state.pos = object.rect;
	new_state.score = object.score;
	new_state.id = getAvailableIndex(kstates);
	new_state.color = colors[new_state.id];
	new_state.real_data = 1;
	new_state.range = range;

	//extractOrbFeatures(new_state.image, new_state.orbKeypoints, new_state.orbDescriptors, ORB_NUM_FEATURES);

	kstates.push_back(new_state);

}

//checks whether an index was previously removed
bool isInRemoved(std::vector&lt;unsigned int&gt; removedIndices, unsigned int index)
{
	for (unsigned int i=0; i&lt; removedIndices.size(); i++)
	{
		if (index == removedIndices[i])
			return true;
	}
	return false;
}

void removeUnusedObjects(std::vector&lt;kstate&gt;&amp; states)
{
	std::vector&lt;kstate&gt;::iterator it;
	for(it = states.begin(); it != states.end();)
	{
		if (!(it-&gt;active))
			it = states.erase(it);
		else
			it++;
	}
}

bool alreadyMatched(int check_index, std::vector&lt;int&gt;&amp; matched_indices)
{
	for (unsigned int i = 0; i &lt; matched_indices.size(); i++)
	{
		if (matched_indices[i] == check_index)
			return true;
	}
	return false;
}

void Sort(const std::vector&lt;float&gt; in_scores, std::vector&lt;unsigned int&gt;&amp; in_out_indices)
{
	for (unsigned int i = 0; i &lt; in_scores.size(); i++)
		for (unsigned int j = i + 1; j &lt; in_scores.size(); j++)
		{
			if (in_scores[in_out_indices[j]] &gt; in_scores[in_out_indices[i]])
			{
				//float x_tmp = x[i];
				int index_tmp = in_out_indices[i];
				//x[i] = x[j];
				in_out_indices[i] = in_out_indices[j];
				//x[j] = x_tmp;
				in_out_indices[j] = index_tmp;
			}
		}
}

void ApplyNonMaximumSuppresion(std::vector&lt; kstate &gt;&amp; in_source, float in_nms_threshold)
{
	std::vector&lt; kstate &gt; tmp_source = in_source;

	if (tmp_source.empty())
		return ;

	unsigned int size = in_source.size();

	std::vector&lt;float&gt; area(size);
	std::vector&lt;float&gt; scores(size);
	std::vector&lt;int&gt; x1(size);
	std::vector&lt;int&gt; y1(size);
	std::vector&lt;int&gt; x2(size);
	std::vector&lt;int&gt; y2(size);
	std::vector&lt;unsigned int&gt; indices(size);
	std::vector&lt;bool&gt; is_suppresed(size);

	for(unsigned int i = 0; i&lt; in_source.size(); i++)
	{
		kstate tmp = in_source[i];
		area[i] = tmp.pos.width * tmp.pos.height;
		indices[i] = i;
		is_suppresed[i] = false;
		scores[i] = tmp.score;
		x1[i] = tmp.pos.x;
		y1[i] = tmp.pos.y;
		x2[i] = tmp.pos.width + tmp.pos.x;
		y2[i] = tmp.pos.height + tmp.pos.y;
	}

	Sort(scores, indices);//returns indices ordered based on scores

	for(unsigned int i=0; i&lt; size; i++)
	{
		if(!is_suppresed[indices[i]])
		{
			for(unsigned int j= i+1; j&lt; size; j++)
			{
				int x1_max = std::max(x1[indices[i]], x1[indices[j]]);
				int x2_min = std::min(x2[indices[i]], x2[indices[j]]);
				int y1_max = std::max(y1[indices[i]], y1[indices[j]]);
				int y2_min = std::min(y2[indices[i]], y2[indices[j]]);
				int overlap_width = x2_min - x1_max + 1;
				int overlap_height = y2_min - y1_max + 1;
				if(overlap_width &gt; 0 &amp;&amp; overlap_height&gt;0)
				{
					float overlap_part = (overlap_width*overlap_height)/area[indices[j]];
					if(overlap_part &gt; in_nms_threshold)
					{
						is_suppresed[indices[j]] = true;
					}
				}
			}
		}
	}

	unsigned int size_out = 0;
	for (unsigned int i = 0; i &lt; size; i++)
	{
		if (!is_suppresed[i])
			size_out++;
	}

	std::vector&lt; kstate &gt; filtered_detections(size_out);

	unsigned int index = 0;
	for(unsigned int i = 0 ; i &lt; size_out; i++)
	{
		if(!is_suppresed[indices[i]])
		{
			filtered_detections[index] = in_source[indices[i]];//x1[indices[i]];
			index++;
		}
	}
	in_source = filtered_detections;
}

void doTracking(std::vector&lt;ObjectDetection_&gt;&amp; detections, int frameNumber,
		std::vector&lt;kstate&gt;&amp; kstates, std::vector&lt;bool&gt;&amp; active, cv::Mat&amp; image,
		std::vector&lt;kstate&gt;&amp; trackedDetections, std::vector&lt;cv::Scalar&gt; &amp; colors)
{
	std::vector&lt;ObjectDetection_&gt; objects;
	//vector&lt;LatentSvmDetector::ObjectDetection_&gt; tracked_objects;
	std::vector&lt;bool&gt; predict_indices;//this will correspond to kstates i
	std::vector&lt;bool&gt; correct_indices;//this will correspond to kstates i
	std::vector&lt;int&gt; correct_detection_indices;//this will correspond to kstates i, used to store the index of the corresponding object
	std::vector&lt;bool&gt; add_as_new_indices;//this will correspond to detections j

	//predict_indices.assign(kstates.size(), true);//always predict
	correct_indices.assign(kstates.size(), false);//correct only those matched
	correct_detection_indices.assign(kstates.size(), false);//correct only those matched
	add_as_new_indices.assign(detections.size(), true);//if the detection was not found add as new

	//Convert Bounding box coordinates from (x1,y1,w,h) to (BoxCenterX, BoxCenterY, width, height)
	objects = detections;//bboxToPosScale(detections);

	std::vector&lt;int&gt; already_matched;
	//compare detections from this frame with tracked objects
	for (unsigned int j = 0; j &lt; detections.size(); j++)
	{
		for (unsigned int i = 0; i &lt; kstates.size(); i++)
		{
			//compare only to active tracked objects(not too old)
			if (kstates[i].active)
			{
				//extend the roi 20%
				int new_x = (detections[j].rect.x - detections[j].rect.width*.1);
				int new_y = (detections[j].rect.y - detections[j].rect.height*.1);

				if (new_x &lt; 0)			new_x = 0;
				if (new_x &gt; image.cols)	new_x = image.cols;
				if (new_y &lt; 0)			new_y = 0;
				if (new_y &gt; image.rows) new_y = image.rows;

				int new_width = detections[j].rect.width*1.2;
				int new_height = detections[j].rect.height*1.2;

				if (new_width  + new_x &gt; image.cols)	new_width  = image.cols - new_x;
				if (new_height + new_y &gt; image.rows)	new_height = image.rows - new_y;

				cv::Rect roi_20(new_x, new_y, new_width, new_height);
				//cv::Rect roi(detections[j].rect);
				cv::Rect roi(roi_20);
				cv::Mat currentObjectROI = image(roi).clone();//Crop image and obtain only object (ROI)

				//cv::Rect intersect = detections[j].rect &amp; kstates[i].pos;//check overlapping

				cv::Rect boundingbox;
				bool matched = false;
				//try to match with previous frame
				//if ( !USE_ORB )
					matched = ( !alreadyMatched(j, already_matched) &amp;&amp; crossCorr(kstates[i].image, currentObjectROI));
				//else
				//	matched = (!alreadyMatched(j, already_matched) &amp;&amp; orbMatch(currentObjectROI, kstates[i].image, boundingbox, ORB_MIN_MATCHES, ORB_KNN_RATIO));

				if(matched)
				{
					correct_indices[i] = true;//if ROI on this frame is matched to a previous object, correct
					correct_detection_indices[i] = j;//store the index of the detection corresponding to matched kstate
					add_as_new_indices[j] = false;//if matched do not add as new
					//kstates[i].image = currentObjectROI;//update image with current frame data
					kstates[i].score = detections[j].score;
					kstates[i].range = _ranges[j];
					already_matched.push_back(j);
				}//crossCorr

			}//kstates[i].active
		}//for (int i = 0; i &lt; kstates.size(); i++)
	}//for (int j = 0; j &lt; detections.size(); j++)


	//do prediction and correction for the marked states
	for (unsigned int i = 0; i &lt; kstates.size(); i++)
	{
		if (kstates[i].active)//predict and correct only active states
		{
			//update params before predicting
			cv::setIdentity(kstates[i].KF.measurementMatrix);
			cv::setIdentity(kstates[i].KF.processNoiseCov, cv::Scalar::all(NOISE_COV));//1e-4
			cv::setIdentity(kstates[i].KF.measurementNoiseCov, cv::Scalar::all(MEAS_NOISE_COV));//1e-3
			cv::setIdentity(kstates[i].KF.errorCovPost, cv::Scalar::all(ERROR_ESTIMATE_COV));//100

			cv::Mat prediction = kstates[i].KF.predict();
			cv::Mat correction;
			kstates[i].pos.x = prediction.at&lt;float&gt;(0);
			kstates[i].pos.y = prediction.at&lt;float&gt;(1);
			kstates[i].pos.width = prediction.at&lt;float&gt;(2);
			kstates[i].pos.height = prediction.at&lt;float&gt;(3);
			kstates[i].real_data = 0;
			kstates[i].range = 0.0f;//fixed to zero temporarily as this is not real_data
			kstates[i].min_height = 0.0f;//fixed to zero temporarily as this is not real_data
			kstates[i].max_height = 0.0f;//fixed to zero temporarily as this is not real_data

			//now do respective corrections on KFs (updates)
			if (correct_indices[i])
			{
				//a match was found hence update KF measurement
				int j = correct_detection_indices[i];//obtain the index of the detection

				//cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(2, 1) &lt;&lt; objects[j].rect.x, //XY ONLY
				//												objects[j].rect.y);
				cv::Mat_&lt;float&gt; measurement = (cv::Mat_&lt;float&gt;(4, 1) &lt;&lt; objects[j].rect.x,
					objects[j].rect.y,
					objects[j].rect.width,
					objects[j].rect.height);

				correction = kstates[i].KF.correct(measurement);//UPDATE KF with new info
				kstates[i].lifespan = DEFAULT_LIFESPAN; //RESET Lifespan of object

				//kstates[i].pos.width = objects[j].rect.width;//XY ONLY
				//kstates[i].pos.height = objects[j].rect.height;//XY ONLY

				//use real data instead of predicted if set
				kstates[i].pos.x = objects[j].rect.x;
				kstates[i].pos.y = objects[j].rect.y;
				kstates[i].pos.width = objects[j].rect.width;
				kstates[i].pos.height = objects[j].rect.height;
				kstates[i].real_data = 1;
				//cv::Mat im1 = image(kstates[i].pos);
				//cv::Mat im2 = image(objects[j].rect);
				kstates[i].range = _ranges[j];
				kstates[i].min_height = _min_heights[j];
				kstates[i].max_height = _max_heights[j];
			}


			//check that new widths and heights don't go beyond the image size
			if (kstates[i].pos.width + kstates[i].pos.x &gt; image.cols)
				kstates[i].pos.width = image.cols - kstates[i].pos.x;
			if (kstates[i].pos.height + kstates[i].pos.y &gt; image.rows)
				kstates[i].pos.height = image.rows - kstates[i].pos.y;

			//check that predicted positions are inside the image
			if (kstates[i].pos.x &lt; 0)
				kstates[i].pos.x = 0;
			if (kstates[i].pos.x &gt; image.cols)
				kstates[i].pos.x = image.cols;
			if (kstates[i].pos.y &lt; 0)
				kstates[i].pos.y = 0;
			if (kstates[i].pos.y &gt; image.rows)
				kstates[i].pos.y = image.rows;

			//remove those where the dimensions of are unlikely to be real
			if (kstates[i].pos.width &gt; kstates[i].pos.height*4)
				kstates[i].active = false;

			if (kstates[i].pos.height &gt; kstates[i].pos.width*2)
				kstates[i].active = false;

			kstates[i].lifespan--;//reduce lifespan
			if (kstates[i].lifespan &lt;= 0)
			{
				kstates[i].active = false; //Too old, stop tracking.
			}
		}
	}

	//finally add non matched detections as new
	for (unsigned int i = 0; i &lt; add_as_new_indices.size(); i++)
	{
		if (add_as_new_indices[i])
		{
			initTracking(objects[i], kstates, detections[i], image, colors, _ranges[i]);
		}
	}
	/*
	//check overlapping states and remove them
	float overlap = (OVERLAPPING_PERC/100);
	std::vector&lt;unsigned int&gt; removedIndices;
	for (unsigned int i = 0; i &lt; kstates.size() ; i++)
	{
		for (unsigned int j = kstates.size() - 1; j &gt; 0; j--)
		{
			if (i==j || isInRemoved(removedIndices, i) || isInRemoved(removedIndices, j))
				continue;
			//cout &lt;&lt; &quot;i:&quot; &lt;&lt; i &lt;&lt; &quot; j:&quot; &lt;&lt; j &lt;&lt; endl;
			cv::Rect intersection = kstates[i].pos &amp; kstates[j].pos;

			if ( ( (intersection.width &gt;= kstates[i].pos.width * overlap) &amp;&amp; (intersection.height &gt;= kstates[i].pos.height * overlap) ) ||
				( (intersection.width &gt;= kstates[j].pos.width * overlap) &amp;&amp; (intersection.height &gt;= kstates[j].pos.height * overlap) ) )
			{
				//if one state is overlapped by &quot;overlap&quot; % remove it (mark it as unused
				if (kstates[i].real_data &amp;&amp; !(kstates[j].real_data))
				{
					kstates[j].active = false;
					removedIndices.push_back(j);
				}
				else if (!(kstates[i].real_data) &amp;&amp; (kstates[j].real_data))
				{
					kstates[i].active = false;
					removedIndices.push_back(i);
				}
				else
				{
					kstates[j].active = false;
					removedIndices.push_back(j);
				}
			}
		}
	}*/
	ApplyNonMaximumSuppresion(kstates, OVERLAPPING_PERC);

	removeUnusedObjects(kstates);

	//return to x,y,w,h
	posScaleToBbox(kstates, trackedDetections);

}

void publish_if_possible()
{
	if (track_ready_ &amp;&amp; detect_ready_)
	{
		image_objects.publish(kf_objects_msg_);
		track_ready_ = false;
		detect_ready_ = false;
	}
}

void trackAndDrawObjects(cv::Mat&amp; image, int frameNumber, std::vector&lt;ObjectDetection_&gt; detections,
			 std::vector&lt;kstate&gt;&amp; kstates, std::vector&lt;bool&gt;&amp; active,
			 std::vector&lt;cv::Scalar&gt; colors, const sensor_msgs::Image&amp; image_source)
{
	std::vector&lt;kstate&gt; tracked_detections;

	cv::TickMeter tm;
	tm.start();
	//std::cout &lt;&lt; &quot;START tracking...&quot;;
	doTracking(detections, frameNumber, kstates, active, image, tracked_detections, colors);
	tm.stop();
	//std::cout &lt;&lt; &quot;END Tracking time = &quot; &lt;&lt; tm.getTimeSec() &lt;&lt; &quot; sec&quot; &lt;&lt; std::endl;

	//ROS
	int num = tracked_detections.size();
	std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; rect_ranged_array;
	std::vector&lt;int&gt; real_data(num,0);
	std::vector&lt;int&gt; obj_id(num, 0);
	std::vector&lt;int&gt; lifespan(num, 0);
	//ENDROS

	for (size_t i = 0; i &lt; tracked_detections.size(); i++)
	{
		kstate od = tracked_detections[i];
		cv_tracker_msgs::image_rect_ranged rect_ranged_;

		//od.rect contains x,y, width, height
		rectangle(image, od.pos, od.color, 3);
		putText(image, SSTR(od.id), cv::Point(od.pos.x + 4, od.pos.y + 13), cv::FONT_HERSHEY_SIMPLEX, 0.55, od.color, 2);
		//ROS
		obj_id[i] = od.id; // ?
		rect_ranged_.rect.x	= od.pos.x;
		rect_ranged_.rect.y	= od.pos.y;
		rect_ranged_.rect.width	= od.pos.width;
		rect_ranged_.rect.height = od.pos.height;
		rect_ranged_.range	= od.range;
		rect_ranged_.min_height	= od.min_height;
		rect_ranged_.max_height	= od.max_height;

		rect_ranged_array.push_back(rect_ranged_);

		real_data[i] = od.real_data;
		lifespan[i] = od.lifespan;
		//ENDROS
	}
	//more ros
	cv_tracker_msgs::image_obj_tracked kf_objects_msg;

	kf_objects_msg.type = object_type;
	kf_objects_msg.total_num = num;
	copy(rect_ranged_array.begin(), rect_ranged_array.end(), back_inserter(kf_objects_msg.rect_ranged)); // copy vector
	copy(real_data.begin(), real_data.end(), back_inserter(kf_objects_msg.real_data)); // copy vector
	copy(obj_id.begin(), obj_id.end(), back_inserter(kf_objects_msg.obj_id)); // copy vector
	copy(lifespan.begin(), lifespan.end(), back_inserter(kf_objects_msg.lifespan)); // copy vector

//	kf_objects_msg_.header = image_source.header;
	kf_objects_msg.header = image_objects_header;
	kf_objects_msg_ = kf_objects_msg;;
	track_ready_ = true;
	publish_if_possible();

	//cout &lt;&lt; &quot;.&quot;&lt;&lt; endl;
}

void image_callback(const sensor_msgs::Image&amp; image_source)
{
	//if (!_ready)
	//	return;

	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
	cv::Mat imageTrack = cv_image-&gt;image;
	trackAndDrawObjects(imageTrack, _counter, _dpm_detections, _kstates, _active, _colors, image_source);
	//_ready=false;
	//imshow(&quot;Tracked&quot;, imageTrack);

	_counter++;
}

void detections_callback(cv_tracker_msgs::image_obj_ranged image_objects_msg)
{
	if(!detect_ready_)
	{
		unsigned int num = image_objects_msg.obj.size();
		std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects = image_objects_msg.obj;
		object_type = image_objects_msg.type;
		image_objects_header = image_objects_msg.header;
		//points are X,Y,W,H and repeat for each instance
		_dpm_detections.clear();
		_ranges.clear();
		_min_heights.clear();
		_max_heights.clear();

		for (unsigned int i=0; i&lt;num;i++)
		{
			cv::Rect tmp;
			tmp.x = objects.at(i).rect.x;
			tmp.y = objects.at(i).rect.y;
			tmp.width = objects.at(i).rect.width;
			tmp.height = objects.at(i).rect.height;
			ObjectDetection_ obj_tmp;
			obj_tmp.rect = tmp; obj_tmp.score=0;
			_dpm_detections.push_back(obj_tmp);
			_ranges.push_back(objects.at(i).range);
			_min_heights.push_back(objects.at(i).min_height);
			_max_heights.push_back(objects.at(i).max_height);
		}
		//_ready = true;
		detect_ready_ = true;
	}
	//cout &lt;&lt; &quot;received pos&quot; &lt;&lt; endl;

	publish_if_possible();
}

static void kf_config_cb(const runtime_manager::ConfigCarKf::ConstPtr&amp; param)
{
	if (param-&gt;initial_lifespan &gt; 0)
		INITIAL_LIFESPAN	= param-&gt;initial_lifespan;
	if (param-&gt;default_lifespan &gt; 0)
		DEFAULT_LIFESPAN	= param-&gt;default_lifespan;
	if(param-&gt;noise_covariance &gt; 0)
		NOISE_COV			= param-&gt;noise_covariance;
	if(param-&gt;measurement_noise_covariance &gt; 0)
		MEAS_NOISE_COV		= param-&gt;measurement_noise_covariance;
	if(param-&gt;error_estimate_covariance &gt; 0)
		ERROR_ESTIMATE_COV	= param-&gt;error_estimate_covariance;
	if(param-&gt;percentage_of_overlapping &gt; 0)
		OVERLAPPING_PERC	= param-&gt;percentage_of_overlapping;

	ORB_NUM_FEATURES	= 2000;
	ORB_MIN_MATCHES		= 3;
	ORB_KNN_RATIO		= 0.7;

	USE_ORB				= param-&gt;use_orb;
}

void init_params()
{
	DEFAULT_LIFESPAN	= 8;
	INITIAL_LIFESPAN	= 4;
	NOISE_COV			= 1;
	MEAS_NOISE_COV		= 25;
	ERROR_ESTIMATE_COV	= 1000000;
	OVERLAPPING_PERC	= 80.0;
	SHOW_PREDICTIONS	= false;

	ORB_NUM_FEATURES	= 2000;
	ORB_MIN_MATCHES		= 3;
	ORB_KNN_RATIO		= 0.7;
	USE_ORB				= false;
}

int kf_main(int argc, char* argv[])
{
	ros::init(argc, argv, &quot;kf&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	image_objects = n.advertise&lt;cv_tracker_msgs::image_obj_tracked&gt;(&quot;image_obj_tracked&quot;, 1);

#if (CV_MAJOR_VERSION == 3)
	generateColors(_colors, 25);
#else
	cv::generateColors(_colors, 25);

#endif
	std::string image_topic;
	std::string obj_topic;
	if (private_nh.getParam(&quot;image_node&quot;, image_topic))
    	{
        	ROS_INFO(&quot;Setting image node to %s&quot;, image_topic.c_str());
    	}
	else
	{
		ROS_INFO(&quot;No image node received, defaulting to image_raw, you can use _image_node:=YOUR_TOPIC&quot;);
		image_topic = &quot;/image_raw&quot;;
	}
	if (private_nh.getParam(&quot;object_node&quot;, image_topic))
    	{
        	ROS_INFO(&quot;Setting object node to %s&quot;, image_topic.c_str());
    	}
	else
	{
		ROS_INFO(&quot;No object node received, defaulting to image_obj_ranged, you can use _object_node:=YOUR_TOPIC&quot;);
		obj_topic = &quot;image_obj_ranged&quot;;
	}

	init_params();

	ros::Subscriber sub_image = n.subscribe(image_topic, 1, image_callback);
	ros::Subscriber sub_dpm = n.subscribe(obj_topic, 1, detections_callback);


	std::string config_topic(&quot;/config&quot;);
	config_topic += ros::this_node::getNamespace() + &quot;/kf&quot;;
	ros::Subscriber config_subscriber = n.subscribe(config_topic, 1, kf_config_cb);

	//TimeSynchronizer&lt;Image, dpm::ImageObjects&gt; sync(image_sub, pos_sub, 10);

	//sync.registerCallback(boost::bind(&amp;sync_callback, _1, _2));
	track_ready_ = false;
	detect_ready_ = false;

	ros::spin();
	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_d_viewer/image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_d_viewer/image_d_viewer.cpp">
				<diff>@@ -36,7 +36,7 @@
 #include &quot;ros/ros.h&quot;
 #include &lt;sensor_msgs/image_encodings.h&gt;
 #include &lt;sensor_msgs/CompressedImage.h&gt;
-#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
+#include &quot;autoware_msgs/image_obj_ranged.h&quot;
 #include &lt;math.h&gt;
 #include &lt;float.h&gt;
 #define NO_DATA 0
@@ -49,8 +49,8 @@ static IplImage temp;
 static IplImage *image;
 static double ratio = 1;	//resize ratio
 
-static cv_tracker_msgs::image_obj_ranged car_fused_objects;
-static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
+static autoware_msgs::image_obj_ranged car_fused_objects;
+static autoware_msgs::image_obj_ranged pedestrian_fused_objects;
 
 static const int OBJ_RECT_THICKNESS = 3;
 static void showImage();
@@ -64,7 +64,7 @@ static inline bool isNearlyNODATA(float x)
 }
 
 void showRects(IplImage *Image,
-               std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
+               std::vector&lt;autoware_msgs::image_rect_ranged&gt; objects,
                double ratio,
                CvScalar col)
 {
@@ -80,7 +80,7 @@ void showRects(IplImage *Image,
     }
 }
 
-static void obj_carCallback(const cv_tracker_msgs::image_obj_ranged&amp; fused_objects)
+static void obj_carCallback(const autoware_msgs::image_obj_ranged&amp; fused_objects)
 {
     if(image == NULL){
       return;
@@ -89,7 +89,7 @@ static void obj_carCallback(const cv_tracker_msgs::image_obj_ranged&amp; fused_objec
     showImage();
 }
 
-static void obj_personCallback(const cv_tracker_msgs::image_obj_ranged&amp; fused_objects)
+static void obj_personCallback(const autoware_msgs::image_obj_ranged&amp; fused_objects)
 {
     if(image == NULL){
       return;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;

#include &quot;ros/ros.h&quot;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;sensor_msgs/CompressedImage.h&gt;
#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
#include &lt;math.h&gt;
#include &lt;float.h&gt;
#define NO_DATA 0

static char window_name_base[] = &quot;image_d_viewer&quot;;
static std::string window_name;
//for imageCallback
static cv_bridge::CvImagePtr cv_image;
static IplImage temp;
static IplImage *image;
static double ratio = 1;	//resize ratio

static cv_tracker_msgs::image_obj_ranged car_fused_objects;
static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;

static const int OBJ_RECT_THICKNESS = 3;
static void showImage();

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
  float abs_x  = (float)fabs(x);
  const int rangeScale = 100;
  return(abs_x &lt; FLT_MIN*rangeScale);
}

void showRects(IplImage *Image,
               std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
               double ratio,
               CvScalar col)
{
    unsigned int object_num = objects.size();
    for(unsigned int i = 0; i &lt; object_num; i++)
    {
        if (!isNearlyNODATA(objects.at(i).range))
        {
            CvPoint p1=cvPoint(objects.at(i).rect.x, objects.at(i).rect.y);
            CvPoint p2=cvPoint(objects.at(i).rect.x + objects.at(i).rect.width, objects.at(i).rect.y + objects.at(i).rect.height);
            cvRectangle(Image,p1,p2,col,OBJ_RECT_THICKNESS);
        }
    }
}

static void obj_carCallback(const cv_tracker_msgs::image_obj_ranged&amp; fused_objects)
{
    if(image == NULL){
      return;
    }
    car_fused_objects = fused_objects;
    showImage();
}

static void obj_personCallback(const cv_tracker_msgs::image_obj_ranged&amp; fused_objects)
{
    if(image == NULL){
      return;
    }
    pedestrian_fused_objects = fused_objects;
    showImage();
}

static void imageCallback(const sensor_msgs::Image&amp; image_source)
{
    cv_image = cv_bridge::toCvCopy(image_source, sensor_msgs::image_encodings::BGR8);
    temp = cv_image-&gt;image;
    image = &amp;temp;
    showImage();
}

static void showImage()
{
    IplImage* image_clone = cvCloneImage(image);
    char distance_string[32];
    CvFont dfont;
    float hscale      = 0.7f;
    float vscale      = 0.7f;
    float italicscale = 0.0f;
    int  thickness    = 1;

    std::string objectLabel;
    CvFont      dfont_label;
    float       hscale_label = 0.5f;
    float       vscale_label = 0.5f;
    CvSize      text_size;
    int         baseline     = 0;

    cvInitFont(&amp;dfont_label, CV_FONT_HERSHEY_COMPLEX, hscale_label, vscale_label, italicscale, thickness, CV_AA);
    objectLabel = car_fused_objects.type;
    cvGetTextSize(objectLabel.data(),
                  &amp;dfont_label,
                  &amp;text_size,
                  &amp;baseline);

    /*
     * Plot obstacle frame
     */
    showRects(image_clone,
              car_fused_objects.obj,
              ratio,
              cvScalar(255.0,255.0,0.0));
    showRects(image_clone,
              pedestrian_fused_objects.obj,
              ratio,
              cvScalar(0.0,255.0,0.0));


    /*
     * Plot car distance data on image
     */
    for (unsigned int i = 0; i &lt; car_fused_objects.obj.size(); i++) {
      if(!isNearlyNODATA(car_fused_objects.obj.at(i).range)) {
          int rect_x      = car_fused_objects.obj.at(i).rect.x;
          int rect_y      = car_fused_objects.obj.at(i).rect.y;
          int rect_width  = car_fused_objects.obj.at(i).rect.width;
          int rect_height = car_fused_objects.obj.at(i).rect.height;
          float range     = car_fused_objects.obj.at(i).range;

          /* put label */
          CvPoint labelOrg = cvPoint(rect_x - OBJ_RECT_THICKNESS,
                                     rect_y - baseline - OBJ_RECT_THICKNESS);
          cvRectangle(image_clone,
                      cvPoint(labelOrg.x + 0, labelOrg.y + baseline),
                      cvPoint(labelOrg.x + text_size.width, labelOrg.y - text_size.height),
                      CV_RGB(0, 0, 0), // label background color is black
                      -1, 8, 0
                      );
          cvPutText(image_clone,
                    objectLabel.data(),
                    labelOrg,
                    &amp;dfont_label,
                    CV_RGB(255, 255, 255) // label text color is white
                    );

          /* put distance data */
            cvRectangle(image_clone,
                        cv::Point(rect_x + (rect_width/2) - (((int)log10(range/100)+1) * 5 + 45),
                                  rect_y + rect_height + 5),
                        cv::Point(rect_x + (rect_width/2) + (((int)log10(range/100)+1) * 8 + 38),
                                  rect_y + rect_height + 30),
                        cv::Scalar(255,255,255), -1);
            cvInitFont (&amp;dfont, CV_FONT_HERSHEY_COMPLEX , hscale, vscale, italicscale, thickness, CV_AA);
            sprintf(distance_string, &quot;%.2f m&quot;, range / 100); //unit of length is meter
            cvPutText(image_clone,
                      distance_string,
                      cvPoint(rect_x + (rect_width/2) - (((int)log10(range/100)+1) * 5 + 40),
                              rect_y + rect_height + 25),
                      &amp;dfont,
                      CV_RGB(255, 0, 0));
        }
    }

    objectLabel = pedestrian_fused_objects.type;
    cvGetTextSize(objectLabel.data(),
                  &amp;dfont_label,
                  &amp;text_size,
                  &amp;baseline);

    /*
     * Plot pedestrian distance data on image
     */
    for (unsigned int i = 0; i &lt; pedestrian_fused_objects.obj.size(); i++) {
      if(!isNearlyNODATA(pedestrian_fused_objects.obj.at(i).range)) {
          int rect_x      = pedestrian_fused_objects.obj.at(i).rect.x;
          int rect_y      = pedestrian_fused_objects.obj.at(i).rect.y;
          int rect_width  = pedestrian_fused_objects.obj.at(i).rect.width;
          int rect_height = pedestrian_fused_objects.obj.at(i).rect.height;
          float range     = pedestrian_fused_objects.obj.at(i).range;

          /* put label */
          CvPoint labelOrg = cvPoint(rect_x - OBJ_RECT_THICKNESS,
                                     rect_y - baseline - OBJ_RECT_THICKNESS);
          cvRectangle(image_clone,
                      cvPoint(labelOrg.x + 0, labelOrg.y + baseline),
                      cvPoint(labelOrg.x + text_size.width, labelOrg.y - text_size.height),
                      CV_RGB(0, 0, 0), // label background color is black
                      -1, 8, 0
                      );
          cvPutText(image_clone,
                    objectLabel.data(),
                    labelOrg,
                    &amp;dfont_label,
                    CV_RGB(255, 255, 255) // label text color is white
                    );

          /* put distance data */
            cvRectangle(image_clone,
                        cv::Point(rect_x + (rect_width/2) - (((int)log10(range/100)+1) * 5 + 45),
                                  rect_y + rect_height + 5),
                        cv::Point(rect_x + (rect_width/2) + (((int)log10(range/100)+1) * 8 + 38),
                                  rect_y + rect_height + 30),
                        cv::Scalar(255,255,255), -1);
            cvInitFont (&amp;dfont, CV_FONT_HERSHEY_COMPLEX , hscale, vscale, italicscale, thickness, CV_AA);
            sprintf(distance_string, &quot;%.2f m&quot;, range / 100); //unit of length is meter
            cvPutText(image_clone,
                      distance_string,
                      cvPoint(rect_x + (rect_width/2) - (((int)log10(range/100)+1) * 5 + 40),
                              rect_y + rect_height + 25),
                      &amp;dfont,
                      CV_RGB(255, 0, 0));
        }
    }

    /*
     * Show image
     */
    if (cvGetWindowHandle(window_name.c_str()) != NULL) // Guard not to write destroyed window by using close button on the window
      {
        cvShowImage(window_name.c_str(), image_clone);
        cvWaitKey(2);
      }
    cvReleaseImage(&amp;image_clone);
}

int main(int argc, char **argv)
{
   /**
    * The ros::init() function needs to see argc and argv so that it can perform
    * any ROS arguments and name remapping that were provided at the command line. For programmatic
    * remappings you can use a different version of init() which takes remappings
    * directly, but for most command-line programs, passing argc and argv is the easiest
    * way to do it.  The third argument to init() is the name of the node.
    *
    * You must call one of the versions of ros::init() before using any other
    * part of the ROS system.
    */


    ros::init(argc, argv, &quot;image_d_viewer&quot;);

    /**
     * NodeHandle is the main access point to communications with the ROS system.
     * The first NodeHandle constructed will fully initialize this node, and the last
     * NodeHandle destructed will close down the node.
     */
    ros::NodeHandle n;
    ros::NodeHandle private_nh(&quot;~&quot;);

    /**
     * The subscribe() call is how you tell ROS that you want to receive messages
     * on a given topic.  This invokes a call to the ROS
     * master node, which keeps a registry of who is publishing and who
     * is subscribing.  Messages are passed to a callback function, here
     * called Callback.  subscribe() returns a Subscriber object that you
     * must hold on to until you want to unsubscribe.  When all copies of the Subscriber
     * object go out of scope, this callback will automatically be unsubscribed from
     * this topic.
     *
     * The second parameter to the subscribe() function is the size of the message
     * queue.  If messages are arriving faster than they are being processed, this
     * is the number of messages that will be buffered up before beginning to throw
     * away the oldest ones.
     */
    std::string image_topic;
    std::string car_topic;
    std::string person_topic;

    if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic)) {
      ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic.c_str());
    } else {
      ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
      image_topic = &quot;/image_raw&quot;;
    }

    if (!private_nh.getParam(&quot;car_topic&quot;, car_topic)) {
      car_topic = &quot;/obj_car/image_obj_ranged&quot;;
    }

    if (!private_nh.getParam(&quot;person_topic&quot;, person_topic)) {
      person_topic = &quot;/obj_person/image_obj_ranged&quot;;
    }

    std::string name_space_str = ros::this_node::getNamespace();
    if (name_space_str != &quot;/&quot;) {
      window_name = std::string(window_name_base) + &quot; (&quot; + ros::this_node::getNamespace() + &quot;)&quot;;
    }
    else {
      window_name = std::string(window_name_base);
    }
    cvNamedWindow(window_name.c_str(), 2);
    cvStartWindowThread();
    image = NULL;
    car_fused_objects.obj.clear();
    pedestrian_fused_objects.obj.clear();

    ros::Subscriber image_sub = n.subscribe(image_topic, 1, imageCallback);
    ros::Subscriber obj_car_sub = n.subscribe(car_topic, 1, obj_carCallback);
    ros::Subscriber obj_person_sub = n.subscribe(person_topic, 1, obj_personCallback);

    /**
     * ros::spin() will enter a loop, pumping callbacks.  With this version, all
     * callbacks will be called from within this thread (the main one).  ros::spin()
     * will exit when Ctrl-C is pressed, or the node is shutdown by the master.
     */
    ros::spin();
    cvDestroyWindow(window_name.c_str());

    return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_viewer/image_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/image_viewer/image_viewer.cpp">
				<diff>@@ -44,8 +44,8 @@
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
 
-#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
-#include &lt;cv_tracker_msgs/image_obj.h&gt;
+#include &lt;autoware_msgs/image_obj_tracked.h&gt;
+#include &lt;autoware_msgs/image_obj.h&gt;
 
 //DPM related
 static std::vector&lt;cv::Rect&gt; cars;		//objects detected
@@ -215,7 +215,7 @@ static void image_viewer_callback(const sensor_msgs::Image&amp; image_source)
 	_drawing = false;
 }
 
-static void image_obj_update_cb(const cv_tracker_msgs::image_obj&amp; image_objs)
+static void image_obj_update_cb(const autoware_msgs::image_obj&amp; image_objs)
 {
 	if(_drawing)
 		return;
@@ -245,7 +245,7 @@ static void image_obj_update_cb(const cv_tracker_msgs::image_obj&amp; image_objs)
 	}
 }
 
-static void image_obj_updater_cb_tracked(const cv_tracker_msgs::image_obj_tracked&amp; image_objs_tracked_msg)
+static void image_obj_updater_cb_tracked(const autoware_msgs::image_obj_tracked&amp; image_objs_tracked_msg)
 {
 	if(_drawing)
 		return;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *	list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *	this list of conditions and the following disclaimer in the documentation
 *	and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *	contributors may be used to endorse or promote products derived from
 *	this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;string&gt;
#include &lt;vector&gt;

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/core/version.hpp&gt;
#if (CV_MAJOR_VERSION == 3)
#include &quot;gencolors.cpp&quot;
#else
#include &lt;opencv2/contrib/contrib.hpp&gt;
#endif

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;

#include &lt;cv_tracker_msgs/image_obj_tracked.h&gt;
#include &lt;cv_tracker_msgs/image_obj.h&gt;

//DPM related
static std::vector&lt;cv::Rect&gt; cars;		//objects detected
static std::vector&lt;float&gt; cars_score;		//score of each object
//KF related
static std::vector&lt;cv::Rect&gt; cars_tracked;	//objects tracked for current frame
static std::vector&lt;int&gt; cars_tracked_lifespan;	//remaining lifespan
static std::vector&lt;int&gt; cars_tracked_id;	//objects' id
static std::vector&lt;int&gt; cars_tracked_real_data;	//states if the data contained in the index is real or prediction

//DPM related
static std::vector&lt;cv::Rect&gt; peds;
static std::vector&lt;float&gt; peds_score;
//KF related
static std::vector&lt;cv::Rect&gt; peds_tracked;
static std::vector&lt;int&gt; peds_tracked_lifespan;
static std::vector&lt;int&gt; peds_tracked_id;
static std::vector&lt;int&gt; peds_tracked_real_data;

static std::vector&lt;cv::Scalar&gt; _colors;

static const int OBJ_RECT_THICKNESS = 3;

static bool _drawing = false;
static bool car_track_ready = false;
static bool car_dpm_ready = false;
static bool ped_track_ready = false;
static bool ped_dpm_ready = false;

static bool car_image_obj_ready = false;
static bool pedestrian_image_obj_ready = false;

static const std::string window_name = &quot;Image Viewer&quot;;

/*static void dashed_rectangle(cv::Mat&amp; img, const cv::Rect&amp; r, const cv::Scalar&amp; color,
			     int thickness = 2, int dash_length = 10)
{
	//draw horizontal dashed lines
	for (int i = 0; i &lt; r.width; i+=dash_length) {
		cv::line(img, cv::Point(r.x+i, r.y),  cv::Point(r.x+i+(dash_length/2), r.y), color, thickness);
		cv::line(img, cv::Point(r.x+i, r.y + r.height), cv::Point(r.x+i+(dash_length/2), r.y + r.height), color, thickness);
	}

	//draw vertical dashes lines
	for (int i = 0; i &lt; r.height; i+=dash_length) {
		cv::line(img, cv::Point(r.x, r.y+i), cv::Point(r.x, r.y+i+(dash_length/2)), color, thickness);
		cv::line(img, cv::Point(r.x +r.width, r.y+i), cv::Point(r.x+ r.width, r.y+i+(dash_length/2)), color, thickness);
	}
}*/

static void drawDetections(std::vector&lt;cv::Rect&gt; dets, std::vector&lt;float&gt; scores, std::string objectLabel, IplImage frame)
{
	/* variables for object label */
	CvFont font;
	const float hscale = 0.5f;
	const float vscale = 0.5f;
	const float italicScale = 0.0f;
	const int thickness = 1;
	CvSize text_size;
	int baseline = 0;

	cvInitFont(&amp;font, CV_FONT_HERSHEY_COMPLEX, hscale, vscale, italicScale, thickness, CV_AA);

	//UNTRACKED
	for(std::size_t i = 0; i &lt; dets.size(); ++i) {
#ifdef TEMP_DISABLED
		//temporal way to avoid drawing detections in the sky
		if (dets[i].y &lt;= frame.height * 0.3)
			continue;
#endif
		std::ostringstream label;
		label &lt;&lt; objectLabel &lt;&lt; &quot;:&quot; &lt;&lt; std::setprecision(2) &lt;&lt; scores[i];
		std::string text = label.str();

		//get text size
		cvGetTextSize(text.data(),
			&amp;font,
			&amp;text_size,
			&amp;baseline);

		//cvRectangle( &amp;frame,
			//cvPoint(dets[i].x, dets[i].y),
			//cvPoint(dets[i].x+dets[i].width, dets[i].y+dets[i].height),
			//CV_RGB(0, 0, 255), OBJ_RECT_THICKNESS, CV_AA, 0);
		cvCircle(&amp;frame, cvPoint(dets[i].x+dets[i].width/2, dets[i].y+dets[i].height/2), 30, cvScalar(0,255,0),3);		/* draw object label */
		CvPoint textOrg = cvPoint(dets[i].x - OBJ_RECT_THICKNESS, dets[i].y - baseline - OBJ_RECT_THICKNESS);

		cvRectangle(&amp;frame,
			cvPoint(textOrg.x + 0 , textOrg.y + baseline),
			cvPoint(textOrg.x + text_size.width, textOrg.y - text_size.height),
			CV_RGB(0, 0, 0), // text background is black
			-1, 8, 0);
		cvPutText(&amp;frame,
			text.data(),
			textOrg,
			&amp;font,
			CV_RGB(255, 255, 255) // text color is white
			);
	}
}

static void drawTracked(std::vector&lt;cv::Rect&gt; dets, std::vector&lt;int&gt; lifespan, std::vector&lt;int&gt; obj_id,
			std::vector&lt;int&gt; real_data, std::string objectLabel, cv::Mat imageTrack)
{
	for(std::size_t i=0; i&lt;dets.size();i++) {
#ifdef TEMP_DISABLED
		//temporal way to avoid drawing detections in the sky
		if (dets[i].y &lt;= imageTrack.rows * 0.3)
			continue;
#endif

		std::ostringstream label;
		label &lt;&lt; objectLabel &lt;&lt; &quot;_&quot; &lt;&lt; obj_id[i] &lt;&lt; &quot;:&quot; &lt;&lt; std::setprecision(2) &lt;&lt; lifespan[i];
		std::string text = label.str();

		//if (real_data[i])
			//rectangle(imageTrack, dets[i], _colors[obj_id[i]], 3);
	//	else
			//dashed_rectangle(imageTrack, dets[i], _colors[obj_id[i]], 3, 10);

		putText(imageTrack, text.c_str(), cv::Point(dets[i].x + 4, dets[i].y + 15),
			cv::FONT_HERSHEY_SIMPLEX, 0.55, _colors[obj_id[i]], 2);
		cv::circle(imageTrack, cv::Point(dets[i].x+dets[i].width/2, dets[i].y+dets[i].height/2), 30, _colors[obj_id[i]],3);
	}
}

static void image_viewer_callback(const sensor_msgs::Image&amp; image_source)
{
	_drawing = true;

	const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_source,
							     encoding);
	IplImage frame = cv_image-&gt;image;

	cv::Mat matImage(cv_image-&gt;image);
	cv::Mat imageTrack = matImage.clone();

	//UNTRACKED
	putText(matImage, &quot;PIXEL_XY&quot;, cv::Point(10,10), cv::FONT_HERSHEY_SIMPLEX, 0.55, cv::Scalar(0, 0, 255), 2);
	if (car_dpm_ready)
		drawDetections(cars, cars_score, &quot;car&quot;, frame);
	if (ped_dpm_ready)
		drawDetections(peds, peds_score, &quot;pedestrian&quot;, frame);

	if (car_image_obj_ready)
		drawDetections(cars, cars_score, &quot;car&quot;, frame);
	if (pedestrian_image_obj_ready)
		drawDetections(peds, peds_score, &quot;pedestrian&quot;, frame);

	//TRACKED
	putText(imageTrack, &quot;PIXEL_XY_TRACKED&quot;, cv::Point(10,10), cv::FONT_HERSHEY_SIMPLEX, 0.55, cv::Scalar(0, 255, 0), 2);
	if(car_track_ready)
		drawTracked(cars_tracked, cars_tracked_lifespan, cars_tracked_id, cars_tracked_real_data, &quot;car&quot;, imageTrack);
	if(ped_track_ready)
		drawTracked(peds_tracked, peds_tracked_lifespan, peds_tracked_id, peds_tracked_real_data, &quot;pedestrian&quot;, imageTrack);

	cv::Mat merged;
	hconcat(matImage, imageTrack, merged);

	if (cvGetWindowHandle(window_name.c_str()) != NULL) // Guard not to write destroyed window by using close button on the window
		{
			imshow(window_name, merged);
			cvWaitKey(2);
		}

	_drawing = false;
}

static void image_obj_update_cb(const cv_tracker_msgs::image_obj&amp; image_objs)
{
	if(_drawing)
		return;

	bool is_car = (image_objs.type == &quot;car&quot;);
	std::vector&lt;cv::Rect&gt;&amp; objs = is_car ? cars : peds;
	std::vector&lt;float&gt;&amp; scores = is_car ? cars_score : peds_score;
	
	objs.clear();
	scores.clear();

	for (const auto&amp; obj : image_objs.obj) {
		cv::Rect tmp;
		tmp.x = obj.x;
		tmp.y = obj.y;
		tmp.width = obj.width;
		tmp.height = obj.height;

		objs.push_back(tmp);
		scores.push_back(obj.score);
	}

	if (is_car) {
		car_image_obj_ready = true;
	} else {
		pedestrian_image_obj_ready = true;
	}
}

static void image_obj_updater_cb_tracked(const cv_tracker_msgs::image_obj_tracked&amp; image_objs_tracked_msg)
{
	if(_drawing)
		return;
	bool is_car = (image_objs_tracked_msg.type == &quot;car&quot;);
	std::vector&lt;cv::Rect&gt;&amp; objs_tracked = is_car ? cars_tracked : peds_tracked;
	std::vector&lt;int&gt;&amp; objs_tracked_lifespan = is_car ? cars_tracked_lifespan : peds_tracked_lifespan;
	std::vector&lt;int&gt;&amp; objs_tracked_id = is_car ? cars_tracked_id : peds_tracked_id;
	std::vector&lt;int&gt;&amp; objs_tracked_real_data = is_car ? cars_tracked_real_data : peds_tracked_real_data;

	objs_tracked_lifespan = image_objs_tracked_msg.lifespan;
	objs_tracked_id = image_objs_tracked_msg.obj_id;
	objs_tracked_real_data = image_objs_tracked_msg.real_data;

	objs_tracked.clear();
	for (const auto&amp; rect_ranged : image_objs_tracked_msg.rect_ranged)
		{
			cv::Rect tmp;
			tmp.x = rect_ranged.rect.x;
			tmp.y = rect_ranged.rect.y;
			tmp.width = rect_ranged.rect.width;
			tmp.height = rect_ranged.rect.height;

			objs_tracked.push_back(tmp);
		}

	if(is_car) {
		car_track_ready = true;
	} else {
		ped_track_ready = true;
	}
}

int main(int argc, char **argv)
{

	/* create resizable window */
	cv::namedWindow(window_name, cv::WINDOW_NORMAL);
	cv::startWindowThread();

	ros::init(argc, argv, &quot;image_viewer&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	std::string image_topic_name;

	if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
		ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
	} else {
		ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
		image_topic_name = &quot;/image_raw&quot;;
	}

#if (CV_MAJOR_VERSION == 3)
	generateColors(_colors, 25);
#else
	cv::generateColors(_colors, 25);
#endif

	ros::Subscriber scriber = n.subscribe(image_topic_name, 1, image_viewer_callback);

	ros::Subscriber scriber_car = n.subscribe(&quot;/obj_car/image_obj&quot;, 1,
						image_obj_update_cb);
	ros::Subscriber scriber_ped = n.subscribe(&quot;/obj_person/image_obj&quot;, 1,
						image_obj_update_cb);

	ros::Subscriber scriber_ped_tracked = n.subscribe(&quot;/obj_person/image_obj_tracked&quot;, 1,
						image_obj_updater_cb_tracked);
	ros::Subscriber scriber_car_tracked = n.subscribe(&quot;/obj_car/image_obj_tracked&quot;, 1,
						image_obj_updater_cb_tracked);

	ros::spin();

	/* destroy window */
	cv::destroyWindow(window_name);

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/points_image_d_viewer/points_image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/points_image_d_viewer/points_image_d_viewer.cpp">
				<diff>@@ -42,9 +42,9 @@
 #include &lt;ros/ros.h&gt;
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;points2image/PointsImage.h&gt;
+#include &lt;autoware_msgs/PointsImage.h&gt;
 
-#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
+#include &quot;autoware_msgs/image_obj_ranged.h&quot;
 #include &lt;vector&gt;
 #include &lt;iostream&gt;
 #include &lt;math.h&gt;
@@ -56,15 +56,15 @@ static char window_name[] = &quot;points_image_d_viewer&quot;;
 static bool existImage = false;
 static bool existPoints = false;
 static sensor_msgs::Image image_msg;
-static points2image::PointsImageConstPtr points_msg;
+static autoware_msgs::PointsImageConstPtr points_msg;
 static cv::Mat colormap;
 
 #if 0
 static std::vector&lt;cv::Rect&gt; cars;
 static std::vector&lt;cv::Rect&gt; peds;
 #else
-static cv_tracker_msgs::image_obj_ranged car_fused_objects;
-static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
+static autoware_msgs::image_obj_ranged car_fused_objects;
+static autoware_msgs::image_obj_ranged pedestrian_fused_objects;
 #endif
 
 /* check whether floating value x is nearly 0 or not */
@@ -83,7 +83,7 @@ static std::vector&lt;cv::Scalar&gt; _colors;
 static const int OBJ_RECT_THICKNESS = 3;
 
 static void drawRects(IplImage *Image,
-                      std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
+                      std::vector&lt;autoware_msgs::image_rect_ranged&gt; objects,
                       CvScalar color,
                       int threshold_height)
 {
@@ -98,7 +98,7 @@ static void drawRects(IplImage *Image,
 }
 
 static void putDistance(IplImage *Image,
-                        std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
+                        std::vector&lt;autoware_msgs::image_rect_ranged&gt; objects,
                         int threshold_height,
                         const char* objectLabel)
 {
@@ -283,7 +283,7 @@ static void car_updater_callback(dpm::ImageObjects image_objects_msg)
   }
 }
 #else
-static void car_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
+static void car_updater_callback(const autoware_msgs::image_obj_ranged&amp; fused_car_msg)
 {
   car_fused_objects = fused_car_msg;
   //  show();
@@ -308,7 +308,7 @@ static void ped_updater_callback(dpm::ImageObjects image_objects_msg)
   }
 }
 #else
-static void ped_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
+static void ped_updater_callback(const autoware_msgs::image_obj_ranged&amp; fused_pds_msg)
 {
   pedestrian_fused_objects = fused_pds_msg;
   //  show();
@@ -322,7 +322,7 @@ static void image_cb(const sensor_msgs::Image&amp; msg)
   show();
 }
 
-static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
+static void points_cb(const autoware_msgs::PointsImageConstPtr&amp; msg)
 {
   points_msg = msg;
   existPoints = true;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/opencv.hpp&gt;

#include &lt;opencv2/core/version.hpp&gt;
#if (CV_MAJOR_VERSION == 3)
#include &quot;gencolors.cpp&quot;
#else
#include &lt;opencv2/contrib/contrib.hpp&gt;
#endif

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;points2image/PointsImage.h&gt;

#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
#include &lt;float.h&gt;

#define NO_DATA 0
static char window_name[] = &quot;points_image_d_viewer&quot;;

static bool existImage = false;
static bool existPoints = false;
static sensor_msgs::Image image_msg;
static points2image::PointsImageConstPtr points_msg;
static cv::Mat colormap;

#if 0
static std::vector&lt;cv::Rect&gt; cars;
static std::vector&lt;cv::Rect&gt; peds;
#else
static cv_tracker_msgs::image_obj_ranged car_fused_objects;
static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
#endif

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
  float abs_x  = (float)fabs(x);
  const int rangeScale = 100;
  return(abs_x &lt; FLT_MIN*rangeScale);
}

static std::vector&lt;cv::Scalar&gt; _colors;

#define	IMAGE_WIDTH	800
#define	IMAGE_HEIGHT	600

static const int OBJ_RECT_THICKNESS = 3;

static void drawRects(IplImage *Image,
                      std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                      CvScalar color,
                      int threshold_height)
{
  unsigned int object_num = objects.size();
  for(unsigned int i = 0; i &lt; object_num; i++) {
    if (objects.at(i).rect.y &gt; threshold_height &amp;&amp; !isNearlyNODATA(objects.at(i).range)) {  // temporal way to avoid drawing detections in the sky
      CvPoint p1=cvPoint(objects.at(i).rect.x, objects.at(i).rect.y);
      CvPoint p2=cvPoint(objects.at(i).rect.x + objects.at(i).rect.width, objects.at(i).rect.y + objects.at(i).rect.height);
      cvRectangle(Image,p1,p2,color,OBJ_RECT_THICKNESS);
    }
  }
}

static void putDistance(IplImage *Image,
                        std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                        int threshold_height,
                        const char* objectLabel)
{
  char distance_string[32];
  CvFont dfont;
  float hscale	    = 0.7f;
  float vscale	    = 0.7f;
  float italicscale = 0.0f;
  int	thickness   = 1;

  CvFont      dfont_label;
  float       hscale_label = 0.5f;
  float       vscale_label = 0.5f;
  CvSize      text_size;
  int         baseline     = 0;

  cvInitFont(&amp;dfont_label, CV_FONT_HERSHEY_COMPLEX, hscale_label, vscale_label, italicscale, thickness, CV_AA);
  cvGetTextSize(objectLabel,
                &amp;dfont_label,
                &amp;text_size,
                &amp;baseline);

  for (unsigned int i=0; i&lt;objects.size(); i++)
    {
      if (objects.at(i).rect.y &gt; threshold_height) // temporal way to avoid drawing detections in the sky
        {
          if (!isNearlyNODATA(objects.at(i).range))
            {

              /*put label */
              CvPoint labelOrg = cvPoint(objects.at(i).rect.x - OBJ_RECT_THICKNESS,
                                         objects.at(i).rect.y - baseline - OBJ_RECT_THICKNESS);

              cvRectangle(Image,
                          cvPoint(labelOrg.x + 0, labelOrg.y + baseline),
                          cvPoint(labelOrg.x + text_size.width, labelOrg.y - text_size.height),
                          CV_RGB(0, 0, 0), // label background is black
                          -1, 8, 0
                          );
              cvPutText(Image,
                        objectLabel,
                        labelOrg,
                        &amp;dfont_label,
                        CV_RGB(255, 255, 255) // label text color is white
                        );

              /* put distance data */
              cvRectangle(Image,
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 45),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 5),
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) + (((int)log10(objects.at(i).range/100)+1) * 8 + 38),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 30),
                          cv::Scalar(255,255,255),
                          -1);

              cvInitFont (&amp;dfont,
                          CV_FONT_HERSHEY_COMPLEX,
                          hscale,
                          vscale,
                          italicscale,
                          thickness,
                          CV_AA);

              sprintf(distance_string, &quot;%.2f m&quot;, objects.at(i).range / 100); //unit of length is meter
              cvPutText(Image,
                        distance_string,
                        cvPoint(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 40),
                                objects.at(i).rect.y + objects.at(i).rect.height + 25),
                        &amp;dfont,
                        CV_RGB(255, 0, 0));
            }

        }
    }
}

void show(void)
{
  if(!existImage || !existPoints){
    return;
  }
  const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
  cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, encoding);
  IplImage frame = cv_image-&gt;image;

  cv::Mat matImage = cv::cvarrToMat(&amp;frame);//(&amp;frame, false);

  /* DRAW RECTANGLES of detected objects */
#if 0
  for(std::size_t i=0; i&lt;cars.size();i++) {
      if(cars[i].y &gt; matImage.rows*.3) { //temporal way to avoid drawing detections in the sky
          cvRectangle( &amp;frame,
                       cvPoint(cars[i].x, cars[i].y),
                       cvPoint(cars[i].x+cars[i].width, cars[i].y+cars[i].height),
                       _colors[0], 3, 8,0 );
    }
  }
  for(std::size_t i=0; i&lt;peds.size();i++) {
    if(peds[i].y &gt; matImage.rows*.3) {
      cvRectangle( &amp;frame,
                   cvPoint(peds[i].x, peds[i].y),
                   cvPoint(peds[i].x+peds[i].width, peds[i].y+peds[i].height),
                   _colors[1], 3, 8,0 );
    }
  }
#else
  drawRects(&amp;frame,
            car_fused_objects.obj,
            cvScalar(255.0, 255.0, 0,0),
            matImage.rows*.10);

  drawRects(&amp;frame,
            pedestrian_fused_objects.obj,
            cvScalar(0.0, 255.0, 0,0),
            matImage.rows*.10);
#endif
  /* PUT DISTANCE text on image */
  putDistance(&amp;frame,
              car_fused_objects.obj,
              matImage.rows*.10,
              car_fused_objects.type.c_str());
  putDistance(&amp;frame,
              pedestrian_fused_objects.obj,
              matImage.rows*.10,
              pedestrian_fused_objects.type.c_str());

  /* DRAW POINTS of lidar scanning */
  int w = matImage.size().width;
  int h = matImage.size().height;

  int n = w * h;
  float min_d = 1&lt;&lt;16, max_d = -1;
  //	int min_i = 1&lt;&lt;8, max_i = -1;
  for(int i=0; i&lt;n; i++){
    int di = points_msg-&gt;distance[i];
    max_d = di &gt; max_d ? di : max_d;
    min_d = di &lt; min_d ? di : min_d;
    // int it = points_msg-&gt;intensity[i];
    // max_i = it &gt; max_i ? it : max_i;
    // min_i = it &lt; min_i ? it : min_i;
  }
  float wid_d = max_d - min_d;

  for(int y=0; y&lt;h; y++){
    for(int x=0; x&lt;w; x++){
      int j = y * w + x;
      double distance = points_msg-&gt;distance[j];
      if(distance == 0){
        continue;
      }
      int colorid= wid_d ? ( (distance - min_d) * 255 / wid_d ) : 128;
      cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
      int g = color[1];
      int b = color[2];
      int r = color[0];
      cvRectangle(&amp;frame, cvPoint(x, y), cvPoint(x+1, y+1), CV_RGB(r, g, b));
    }
  }

  if (cvGetWindowHandle(window_name) != NULL) // Guard not to write destroyed window by using close button on the window
    {
      cvShowImage(window_name, &amp;frame);
      cvWaitKey(2);
    }
}

#if 0
static void car_updater_callback(dpm::ImageObjects image_objects_msg)
{
  int num = image_objects_msg.car_num;
  std::vector&lt;int&gt; points = image_objects_msg.corner_point;
  //points are X,Y,W,H and repeat for each instance
  cars.clear();

  for (int i=0; i&lt;num;i++) {
    cv::Rect tmp;
    tmp.x = points[i*4 + 0];
    tmp.y = points[i*4 + 1];
    tmp.width = points[i*4 + 2];
    tmp.height = points[i*4 + 3];
    cars.push_back(tmp);
  }
}
#else
static void car_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
{
  car_fused_objects = fused_car_msg;
  //  show();
}
#endif

#if 0
static void ped_updater_callback(dpm::ImageObjects image_objects_msg)
{
  int num = image_objects_msg.car_num;
  std::vector&lt;int&gt; points = image_objects_msg.corner_point;
  //points are X,Y,W,H and repeat for each instance
  peds.clear();

  for (int i=0; i&lt;num;i++) {
    cv::Rect tmp;
    tmp.x = points[i*4 + 0];
    tmp.y = points[i*4 + 1];
    tmp.width = points[i*4 + 2];
    tmp.height = points[i*4 + 3];
    peds.push_back(tmp);
  }
}
#else
static void ped_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
{
  pedestrian_fused_objects = fused_pds_msg;
  //  show();
}
#endif

static void image_cb(const sensor_msgs::Image&amp; msg)
{
  image_msg = msg;
  existImage = true;
  show();
}

static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
{
  points_msg = msg;
  existPoints = true;
  show();
}

int main(int argc, char **argv)
{
  /* create resizable window */
  cvNamedWindow(window_name, CV_WINDOW_NORMAL);
  cvStartWindowThread();

  ros::init(argc, argv, &quot;points_image_d_viewer&quot;);
  ros::NodeHandle n;
  ros::NodeHandle private_nh(&quot;~&quot;);

  std::string image_topic_name;
  std::string car_node;
  std::string pedestrian_node;
  std::string points_node;

  if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
    ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
  } else {
    ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
    image_topic_name = &quot;/image_raw&quot;;
  }

  if (private_nh.getParam(&quot;car_node&quot;, car_node)) {
    ROS_INFO(&quot;Setting car positions node to %s&quot;, car_node.c_str());
  } else {
    ROS_INFO(&quot;No car positions node received, defaulting to car_pixel_xyz, you can use _car_node:=YOUR_TOPIC&quot;);
    car_node = &quot;/obj_car/image_obj_ranged&quot;;
  }

  if (private_nh.getParam(&quot;pedestrian_node&quot;, pedestrian_node)) {
    ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, pedestrian_node.c_str());
  } else {
    ROS_INFO(&quot;No pedestrian positions node received, defaulting to pedestrian_pixel_xyz, you can use _pedestrian_node:=YOUR_TOPIC&quot;);
    pedestrian_node = &quot;/obj_person/image_obj_ranged&quot;;
  }

  if (private_nh.getParam(&quot;points_node&quot;, points_node)) {
    ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, points_node.c_str());
  } else {
    ROS_INFO(&quot;No points node received, defaulting to points_image, you can use _points_node:=YOUR_TOPIC&quot;);
    points_node = &quot;/points_image&quot;;
  }

#if (CV_MAJOR_VERSION == 3)
	generateColors(_colors, 25);
#else
	cv::generateColors(_colors, 25);
#endif

  ros::Subscriber scriber = n.subscribe(image_topic_name, 1,
                                        image_cb);
  ros::Subscriber scriber_car = n.subscribe(car_node, 1,
                                            car_updater_callback);
  ros::Subscriber scriber_ped = n.subscribe(pedestrian_node, 1,
                                            ped_updater_callback);
  ros::Subscriber scriber_points = n.subscribe(points_node, 1,
                                               points_cb);

  cv::Mat grayscale(256,1,CV_8UC1);
  for(int i=0;i&lt;256;i++) {
    grayscale.at&lt;uchar&gt;(i)=i;
  }
  cv::applyColorMap(grayscale,colormap,cv::COLORMAP_JET);

  ros::spin();

  cvDestroyWindow(window_name);

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/points_image_viewer/points_image_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/points_image_viewer/points_image_viewer.cpp">
				<diff>@@ -35,7 +35,7 @@
 
 #include &quot;ros/ros.h&quot;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &quot;points2image/PointsImage.h&quot;
+#include &quot;autoware_msgs/PointsImage.h&quot;
 
 #define IMAGE_WIDTH 800
 #define IMAGE_HEIGHT 640
@@ -43,7 +43,7 @@
 static bool existImage = false;
 static bool existPoints = false;
 static sensor_msgs::Image image_msg;
-static points2image::PointsImageConstPtr points_msg;
+static autoware_msgs::PointsImageConstPtr points_msg;
 static cv::Mat colormap;
 
 static const char window_name_base[] = &quot;points_image_viewer&quot;;
@@ -103,7 +103,7 @@ static void image_cb(const sensor_msgs::Image&amp; msg)
 	show();
 }
 
-static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
+static void points_cb(const autoware_msgs::PointsImageConstPtr&amp; msg)
 {
 	points_msg = msg;
 	existPoints = true;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;

#include &quot;ros/ros.h&quot;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &quot;points2image/PointsImage.h&quot;

#define IMAGE_WIDTH 800
#define IMAGE_HEIGHT 640

static bool existImage = false;
static bool existPoints = false;
static sensor_msgs::Image image_msg;
static points2image::PointsImageConstPtr points_msg;
static cv::Mat colormap;

static const char window_name_base[] = &quot;points_image_viewer&quot;;
static std::string window_name;

static void show(void)
{
	if(!existImage || !existPoints){
		return;
	}
	const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, encoding);
	IplImage frame = cv_image-&gt;image;

	cv::Mat matImage = cv::cvarrToMat(&amp;frame);//(&amp;frame, false);

	int w = matImage.size().width;
	int h = matImage.size().height;
	int n = w * h;

	float min_d, max_d;
	min_d = max_d = points_msg-&gt;distance[0];
	for(int i=1; i&lt;n; i++){
		float di = points_msg-&gt;distance[i];
		max_d = di &gt; max_d ? di : max_d;
		min_d = di &lt; min_d ? di : min_d;
	}
	float wid_d = max_d - min_d;

	for(int y=0; y&lt;h; y++){
		for(int x=0; x&lt;w; x++){
			int j = y * w + x;
			float distance = points_msg-&gt;distance[j];
			if(distance == 0){
				continue;
			}
			int colorid= wid_d ? ( (distance - min_d) * 255 / wid_d ) : 128;
			cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
			int g = color[1];
			int b = color[2];
			int r = color[0];
			cvRectangle(&amp;frame, cvPoint(x, y), cvPoint(x+1, y+1), CV_RGB(r, g, b));
		}
	}

	if (cvGetWindowHandle(window_name.c_str()) != NULL) // Guard not to write destroyed window by using close button on the window
	{
		cvShowImage(window_name.c_str(), &amp;frame);
		cvWaitKey(2);
	}
}

static void image_cb(const sensor_msgs::Image&amp; msg)
{
	image_msg = msg;
	existImage = true;
	show();
}

static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
{
	points_msg = msg;
	existPoints = true;
	show();
}

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;points_image_viewer&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	std::string points_topic;
	if (!private_nh.getParam(&quot;points_topic&quot;, points_topic)) {
		points_topic = &quot;points_image&quot;;
	}

	std::string image_topic;
	if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic)) {
		ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic.c_str());
	} else {
		ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
		image_topic = &quot;/image_raw&quot;;
	}

	std::string name_space_str = ros::this_node::getNamespace();
	window_name = std::string(window_name_base);
	if (name_space_str != &quot;/&quot;) {
		window_name += &quot; (&quot; + name_space_str + &quot;)&quot;;
	}

	/* create resizable window */
	cvNamedWindow(window_name.c_str(), CV_WINDOW_NORMAL);
	cvStartWindowThread();

	ros::Subscriber sub_image = n.subscribe(image_topic, 1, image_cb);
	ros::Subscriber sub_points = n.subscribe(points_topic, 1, points_cb);

	cv::Mat grayscale(256,1,CV_8UC1);
	for(int i=0;i&lt;256;i++)
	{
		grayscale.at&lt;uchar&gt;(i)=i;
	}
	cv::applyColorMap(grayscale,colormap,cv::COLORMAP_JET);

	ros::spin();

	cvDestroyWindow(window_name.c_str());
	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/scan_image_d_viewer/scan_image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/scan_image_d_viewer/scan_image_d_viewer.cpp">
				<diff>@@ -42,8 +42,8 @@
 #include &lt;iostream&gt;
 #include &lt;math.h&gt;
 #include &lt;float.h&gt;
-#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
-#include &quot;scan2image/ScanImage.h&quot;
+#include &quot;autoware_msgs/image_obj_ranged.h&quot;
+#include &quot;autoware_msgs/ScanImage.h&quot;
 
 #define IMAGE_WIDTH 800
 #define IMAGE_HEIGHT 600
@@ -53,13 +53,13 @@ char window_name[] = &quot;SCAN_IMAGE_VIEWER&quot;;
 //for imageCallback
 cv_bridge::CvImagePtr cv_image;
 IplImage image;
-scan2image::ScanImage scan_image;
+autoware_msgs::ScanImage scan_image;
 bool exist_image = false;
 bool exist_scan = false;
 cv::Mat colormap;
 
-cv_tracker_msgs::image_obj_ranged car_fused_objects;
-cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
+autoware_msgs::image_obj_ranged car_fused_objects;
+autoware_msgs::image_obj_ranged pedestrian_fused_objects;
 static const int OBJ_RECT_THICKNESS = 3;
 
 /* check whether floating value x is nearly 0 or not */
@@ -71,7 +71,7 @@ static inline bool isNearlyNODATA(float x)
 }
 
 static void putDistance(IplImage *Image,
-                        std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
+                        std::vector&lt;autoware_msgs::image_rect_ranged&gt; objects,
                         int threshold_height,
                         const char* objectLabel)
 {
@@ -147,7 +147,7 @@ static void putDistance(IplImage *Image,
 }
 
 static void drawRects(IplImage *Image,
-                      std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
+                      std::vector&lt;autoware_msgs::image_rect_ranged&gt; objects,
                       CvScalar color,
                       int threshold_height)
 {
@@ -229,20 +229,20 @@ static void show()
     cvReleaseImage(&amp;image_view);
 }
 
-static void scan_image_callback(const scan2image::ScanImage&amp; scan_image_msg)
+static void scan_image_callback(const autoware_msgs::ScanImage&amp; scan_image_msg)
 {
     scan_image = scan_image_msg;
     exist_scan = true;
     show();
 }
 
-static void car_fusion_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
+static void car_fusion_callback(const autoware_msgs::image_obj_ranged&amp; fused_car_msg)
 {
   car_fused_objects = fused_car_msg;
 //  show();
 }
 
-static void ped_fusion_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
+static void ped_fusion_callback(const autoware_msgs::image_obj_ranged&amp; fused_pds_msg)
 {
   pedestrian_fused_objects = fused_pds_msg;
 //  show();
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

//openCV library
#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv/cxcore.h&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &quot;ros/ros.h&quot;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
#include &lt;float.h&gt;
#include &quot;cv_tracker_msgs/image_obj_ranged.h&quot;
#include &quot;scan2image/ScanImage.h&quot;

#define IMAGE_WIDTH 800
#define IMAGE_HEIGHT 600
#define NO_DATA 0

char window_name[] = &quot;SCAN_IMAGE_VIEWER&quot;;
//for imageCallback
cv_bridge::CvImagePtr cv_image;
IplImage image;
scan2image::ScanImage scan_image;
bool exist_image = false;
bool exist_scan = false;
cv::Mat colormap;

cv_tracker_msgs::image_obj_ranged car_fused_objects;
cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
static const int OBJ_RECT_THICKNESS = 3;

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
    float abs_x  = (float)fabs(x);
    const int rangeScale = 100;
    return(abs_x &lt; FLT_MIN*rangeScale);
}

static void putDistance(IplImage *Image,
                        std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                        int threshold_height,
                        const char* objectLabel)
{
  char distance_string[32];
  CvFont dfont;
  float hscale	    = 0.7f;
  float vscale	    = 0.7f;
  float italicscale = 0.0f;
  int	thickness   = 1;

  CvFont      dfont_label;
  float       hscale_label = 0.5f;
  float       vscale_label = 0.5f;
  CvSize      text_size;
  int         baseline     = 0;

  cvInitFont(&amp;dfont_label, CV_FONT_HERSHEY_COMPLEX, hscale_label, vscale_label, italicscale, thickness, CV_AA);
  cvGetTextSize(objectLabel,
                &amp;dfont_label,
                &amp;text_size,
                &amp;baseline);

  for (unsigned int i=0; i&lt;objects.size(); i++)
    {
      if (objects.at(i).rect.y &gt; threshold_height) // temporal way to avoid drawing detections in the sky
        {
          if (!isNearlyNODATA(objects.at(i).range))
            {
              /* put label */
              CvPoint labelOrg = cvPoint(objects.at(i).rect.x - OBJ_RECT_THICKNESS,
                                         objects.at(i).rect.y - baseline - OBJ_RECT_THICKNESS);

              cvRectangle(Image,
                          cvPoint(labelOrg.x + 0, labelOrg.y + baseline),
                          cvPoint(labelOrg.x + text_size.width, labelOrg.y - text_size.height),
                          CV_RGB(0, 0, 0), // label background is black
                          -1, 8, 0
                          );
              cvPutText(Image,
                        objectLabel,
                        labelOrg,
                        &amp;dfont_label,
                        CV_RGB(255, 255, 255) // label text color is white
                        );

              /* put distance data */
              cvRectangle(Image,
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 45),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 5),
                          cv::Point(objects.at(i).rect.x + (objects.at(i).rect.width/2) + (((int)log10(objects.at(i).range/100)+1) * 8 + 38),
                                    objects.at(i).rect.y + objects.at(i).rect.height + 30),
                          cv::Scalar(255,255,255),
                          -1);

              cvInitFont (&amp;dfont,
                          CV_FONT_HERSHEY_COMPLEX,
                          hscale,
                          vscale,
                          italicscale,
                          thickness,
                          CV_AA);

              sprintf(distance_string, &quot;%.2f m&quot;, objects.at(i).range / 100); //unit of length is meter
              cvPutText(Image,
                        distance_string,
                        cvPoint(objects.at(i).rect.x + (objects.at(i).rect.width/2) - (((int)log10(objects.at(i).range/100)+1) * 5 + 40),
                                objects.at(i).rect.y + objects.at(i).rect.height + 25),
                        &amp;dfont,
                        CV_RGB(255, 0, 0));
            }
        }
    }
}

static void drawRects(IplImage *Image,
                      std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
                      CvScalar color,
                      int threshold_height)
{
    unsigned int object_num = objects.size();
    for(unsigned int i = 0; i &lt; object_num; i++)
    {
        if (objects.at(i).rect.y &gt; threshold_height &amp;&amp; !isNearlyNODATA(objects.at(i).range)) // temporal way to avoid drawing detections in the sky
        {
            CvPoint p1=cvPoint(objects.at(i).rect.x, objects.at(i).rect.y);
            CvPoint p2=cvPoint(objects.at(i).rect.x + objects.at(i).rect.width, objects.at(i).rect.y + objects.at(i).rect.height);
            cvRectangle(Image,p1,p2,color,OBJ_RECT_THICKNESS);
        }
    }
}

static void show()
{
    if(!exist_image || !exist_scan){
        return;
    }

    IplImage* image_view = cvCreateImage(cvGetSize(&amp;image), image.depth, image.nChannels);
    cvCopy(&amp;image, image_view);

	float min_d, max_d;
	min_d = max_d = scan_image.distance.at(0);
	for(int i = 1; i &lt; IMAGE_WIDTH * IMAGE_HEIGHT; i++){
		float di = scan_image.distance.at(i);
		max_d = di &gt; max_d ? di : max_d;
		min_d = di &lt; min_d ? di : min_d;
	}
	float wid_d = max_d - min_d;

    /*
     * Plot depth points on an image
     */
    CvPoint pt;
    int height, width;
    for(int i = 0; i &lt; (int)scan_image.distance.size(); i++) {
        height = (int)(i % IMAGE_HEIGHT);
        width = (int)(i / IMAGE_HEIGHT);
        if(scan_image.distance.at(i) != 0.0) {
            pt.x = width;
            pt.y = height;
			int colorid= wid_d ? ( (scan_image.distance.at(i) - min_d) * 255 / wid_d ) : 128;
			cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
			int g = color[1];
			int b = color[2];
			int r = color[0];
            cvCircle(image_view, pt, 2, CV_RGB (r, g, b), CV_FILLED, 8, 0);
        }
    }


  drawRects(image_view,
            car_fused_objects.obj,
            cvScalar(255.0, 255.0, 0,0),
            (image_view-&gt;height)*.3);

  drawRects(image_view,
            pedestrian_fused_objects.obj,
            cvScalar(0.0, 255.0, 0,0),
            (image_view-&gt;height)*.3);
  /* PUT DISTANCE text on image */
  putDistance(image_view,
              car_fused_objects.obj,
              (image_view-&gt;height)*.3,
              car_fused_objects.type.c_str());
  putDistance(image_view,
              pedestrian_fused_objects.obj,
              (image_view-&gt;height)*.3,
              pedestrian_fused_objects.type.c_str());

    /*
     * Show image
     */
    cvShowImage(window_name, image_view);
    cvWaitKey(2);
    cvReleaseImage(&amp;image_view);
}

static void scan_image_callback(const scan2image::ScanImage&amp; scan_image_msg)
{
    scan_image = scan_image_msg;
    exist_scan = true;
    show();
}

static void car_fusion_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
{
  car_fused_objects = fused_car_msg;
//  show();
}

static void ped_fusion_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
{
  pedestrian_fused_objects = fused_pds_msg;
//  show();
}

static void image_callback(const sensor_msgs::Image&amp; image_msg)
{
    cv_image = cv_bridge::toCvCopy(image_msg, sensor_msgs::image_encodings::BGR8);
    image = cv_image-&gt;image;
    exist_image = true;
    show();
}

int main(int argc, char **argv)
{
    ros::init(argc, argv, &quot;sca_image_d_viewer&quot;);
    ros::NodeHandle n;
    ros::NodeHandle private_nh(&quot;~&quot;);
    std::string image_topic_name;
    if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
      ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
    } else {
      ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
      image_topic_name = &quot;/image_raw&quot;;
    }

    ros::Subscriber scan_image_sub = n.subscribe(&quot;/scan_image&quot;, 1, scan_image_callback);
    ros::Subscriber image_sub = n.subscribe(image_topic_name, 1, image_callback);
    ros::Subscriber car_fusion_sub = n.subscribe(&quot;/obj_car/image_obj_ranged&quot;, 1, car_fusion_callback);
    ros::Subscriber pedestrian_fusion_sub = n.subscribe(&quot;/obj_person/image_obj_ranged&quot;, 1, ped_fusion_callback);

    cv::Mat grayscale(256,1,CV_8UC1);
    for(int i = 0; i &lt; 256; i++) {
        grayscale.at&lt;uchar&gt;(i)=i;
    }
    cv::applyColorMap(grayscale, colormap, cv::COLORMAP_JET);
    cvNamedWindow(window_name, 2);

    ros::spin();

    cvDestroyWindow(window_name);
    return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/scan_image_viewer/scan_image_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/scan_image_viewer/scan_image_viewer.cpp">
				<diff>@@ -38,14 +38,14 @@
 #include &quot;ros/ros.h&quot;
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &quot;scan2image/ScanImage.h&quot;
+#include &quot;autoware_msgs/ScanImage.h&quot;
 #include &lt;sensor_msgs/CameraInfo.h&gt;
 
 static char window_name[] = &quot;SCAN_IMAGE_VIEWER&quot;;
 //for imageCallback
 static cv_bridge::CvImagePtr cv_image;
 static IplImage image;
-static scan2image::ScanImage scan_image;
+static autoware_msgs::ScanImage scan_image;
 static bool exist_image = false;
 static bool exist_scan = false;
 static cv::Mat colormap;
@@ -96,7 +96,7 @@ static void show()
     cvReleaseImage(&amp;image_view);
 }
 
-static void scan_image_callback(const scan2image::ScanImage&amp; scan_image_msg)
+static void scan_image_callback(const autoware_msgs::ScanImage&amp; scan_image_msg)
 {
     scan_image = scan_image_msg;
     exist_scan = true;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

//openCV library
#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv/cxcore.h&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &quot;ros/ros.h&quot;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &quot;scan2image/ScanImage.h&quot;
#include &lt;sensor_msgs/CameraInfo.h&gt;

static char window_name[] = &quot;SCAN_IMAGE_VIEWER&quot;;
//for imageCallback
static cv_bridge::CvImagePtr cv_image;
static IplImage image;
static scan2image::ScanImage scan_image;
static bool exist_image = false;
static bool exist_scan = false;
static cv::Mat colormap;
static cv::Size imageSize;

static void show()
{
    if(!exist_image || !exist_scan){
        return;
    }

    IplImage* image_view = cvCreateImage(cvGetSize(&amp;image), image.depth, image.nChannels);
    cvCopy(&amp;image, image_view);

    float min_d, max_d;
    min_d = max_d = scan_image.distance.at(0);
    for(int i = 1; i &lt; imageSize.width * imageSize.height; i++){
        float di = scan_image.distance.at(i);
        max_d = di &gt; max_d ? di : max_d;
        min_d = di &lt; min_d ? di : min_d;
    }

    float wid_d = max_d - min_d;

    /*
     * Plot depth points on an image
     */
    CvPoint pt;
    for(int i = 0; i &lt; (int)scan_image.distance.size(); i++) {
        int height = (int)(i % imageSize.height);
        int width = (int)(i / imageSize.height);
        if(scan_image.distance.at(i) != 0.0) {
            pt.x = width;
            pt.y = height;
			int colorid= wid_d ? ( (scan_image.distance.at(i) - min_d) * 255 / wid_d ) : 128;
			cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
			int g = color[1];
			int b = color[2];
			int r = color[0];
            cvCircle(image_view, pt, 2, CV_RGB (r, g, b), CV_FILLED, 8, 0);
        }
    }
    /*
     * Show image
     */
    cvShowImage(window_name, image_view);
    cvWaitKey(2);
    cvReleaseImage(&amp;image_view);
}

static void scan_image_callback(const scan2image::ScanImage&amp; scan_image_msg)
{
    scan_image = scan_image_msg;
    exist_scan = true;
    show();
}

static void image_callback(const sensor_msgs::Image&amp; image_msg)
{
    imageSize.height = image_msg.height;
    imageSize.width = image_msg.width;
    cv_image = cv_bridge::toCvCopy(image_msg, sensor_msgs::image_encodings::BGR8);
    image = cv_image-&gt;image;
    exist_image = true;
    show();
}

int main(int argc, char **argv)
{
    ros::init(argc, argv, &quot;scan_image_viewer&quot;);
    ros::NodeHandle n;
    ros::NodeHandle private_nh(&quot;~&quot;);
    std::string image_topic_name;

    if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
        ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
    } else {
        ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
        image_topic_name = &quot;/image_raw&quot;;
    }

    ros::Subscriber scan_image_sub = n.subscribe(&quot;/scan_image&quot;, 1, scan_image_callback);
    ros::Subscriber image_sub = n.subscribe(image_topic_name, 1, image_callback);

    cv::Mat grayscale(256,1,CV_8UC1);
    for(int i = 0; i &lt; 256; i++) {
        grayscale.at&lt;uchar&gt;(i)=i;
    }
    cv::applyColorMap(grayscale, colormap, cv::COLORMAP_JET);
    cvNamedWindow(window_name, 2);

    ros::spin();

    cvDestroyWindow(window_name);
    return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/traffic_light_viewer/traffic_light_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/traffic_light_viewer/traffic_light_viewer.cpp">
				<diff>@@ -1,5 +1,5 @@
 #include &lt;ros/ros.h&gt;
-#include &lt;runtime_manager/traffic_light.h&gt;
+#include &lt;autoware_msgs/traffic_light.h&gt;
 #include &lt;opencv2/core/core.hpp&gt;
 #include &lt;opencv2/highgui/highgui.hpp&gt;
 #include &lt;opencv2/imgproc/imgproc.hpp&gt;
@@ -13,7 +13,7 @@ static const int32_t TRAFFIC_LIGHT_RED     = 0;
 static const int32_t TRAFFIC_LIGHT_GREEN   = 1;
 static const int32_t TRAFFIC_LIGHT_UNKNOWN = 2;
 
-static void signalState_cb(const runtime_manager::traffic_light::ConstPtr&amp; msg)
+static void signalState_cb(const autoware_msgs::traffic_light::ConstPtr&amp; msg)
 {
   const int   fontFace      = cv::FONT_HERSHEY_COMPLEX;
   const float fontScale     = 1.0f;
</diff>
				<old_file>#include &lt;ros/ros.h&gt;
#include &lt;runtime_manager/traffic_light.h&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;

#define WINDOW_NAME &quot;traffic light detection result&quot;
#define WINDOW_SIZE 500
#define RADIUS      200


static const int32_t TRAFFIC_LIGHT_RED     = 0;
static const int32_t TRAFFIC_LIGHT_GREEN   = 1;
static const int32_t TRAFFIC_LIGHT_UNKNOWN = 2;

static void signalState_cb(const runtime_manager::traffic_light::ConstPtr&amp; msg)
{
  const int   fontFace      = cv::FONT_HERSHEY_COMPLEX;
  const float fontScale     = 1.0f;
  const int   fontThickness = 1;
  int         baseLine      = 0;
  cv::Point   textOrg;
  std::string label;
  cv::Scalar  textColor;
  cv::Scalar  signalColor;

  switch (msg-&gt;traffic_light) {
  case TRAFFIC_LIGHT_RED:
    label       = &quot;RED&quot;;
    textColor   = CV_RGB(255, 0, 0);
    signalColor = CV_RGB(255, 0, 0);
    break;
  case TRAFFIC_LIGHT_GREEN:
    label       = &quot;GREEN&quot;;
    textColor   = CV_RGB(0, 255, 0);
    signalColor = CV_RGB(0, 255, 0);
    break;
  default:
    label       = &quot;NO SIGNAL DETECTED&quot;;
    textColor   = CV_RGB(255, 255, 255);
    signalColor = CV_RGB(0, 0, 0);
    break;
  }

  cv::Mat result(WINDOW_SIZE, WINDOW_SIZE, CV_8UC3, cv::Scalar(0));

  cv::circle(result, cv::Point(WINDOW_SIZE/2, WINDOW_SIZE/2), RADIUS, signalColor, CV_FILLED);

  cv::Size textSize = cv::getTextSize(label,
                                      fontFace,
                                      fontScale,
                                      fontThickness,
                                      &amp;baseLine);

  textOrg = cv::Point(0, textSize.height + baseLine);

  cv::putText(result,
              label,
              textOrg,
              fontFace,
              fontScale,
              textColor,
              fontThickness,
              CV_AA);

  if (cvGetWindowHandle(WINDOW_NAME) != NULL) // Guard not to write destroyed window by using close button on the window
    {
      cv::imshow(WINDOW_NAME, result);
      cv::waitKey(5);
    }


}

int main(int argc, char* argv[])
{
  cv::namedWindow(WINDOW_NAME, cv::WINDOW_NORMAL);
  cv::startWindowThread();

  ros::init(argc, argv, &quot;traffic_light_viewer&quot;);

  ros::NodeHandle n;

  ros::Subscriber signalState_sub = n.subscribe(&quot;/light_color&quot;, 1, signalState_cb);

  ros::spin();

  cv::destroyWindow(WINDOW_NAME);

  return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/vscan_image_d_viewer/vscan_image_d_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/vscan_image_d_viewer/vscan_image_d_viewer.cpp">
				<diff>@@ -33,9 +33,9 @@
 #include &lt;ros/ros.h&gt;
 #include &lt;cv_bridge/cv_bridge.h&gt;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &lt;points2image/PointsImage.h&gt;
+#include &lt;autoware_msgs/PointsImage.h&gt;
 
-#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
+#include &lt;autoware_msgs/image_obj_ranged.h&gt;
 #include &lt;vector&gt;
 #include &lt;iostream&gt;
 #include &lt;math.h&gt;
@@ -51,15 +51,15 @@ static char window_name[] = &quot;vscan_image_d_viewer&quot;;
 static bool existImage = false;
 static bool existPoints = false;
 static sensor_msgs::Image image_msg;
-static points2image::PointsImageConstPtr points_msg;
+static autoware_msgs::PointsImageConstPtr points_msg;
 static cv::Mat colormap;
 
 #if 0
 static std::vector&lt;cv::Rect&gt; cars;
 static std::vector&lt;cv::Rect&gt; peds;
 #else
-static cv_tracker_msgs::image_obj_ranged car_fused_objects;
-static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
+static autoware_msgs::image_obj_ranged car_fused_objects;
+static autoware_msgs::image_obj_ranged pedestrian_fused_objects;
 #endif
 
 /* check whether floating value x is nearly 0 or not */
@@ -80,7 +80,7 @@ static std::vector&lt;cv::Scalar&gt; _colors;
 static const int OBJ_RECT_THICKNESS = 3;
 
 static void drawRects(cv::Mat image,
-                    std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
+                    std::vector&lt;autoware_msgs::image_rect_ranged&gt; objects,
 					CvScalar color,
 					int threshold_height,
 					std::string objectClass)
@@ -176,13 +176,13 @@ static void show(void)
 		cvWaitKey(2);
 	}
 }
-static void car_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
+static void car_updater_callback(const autoware_msgs::image_obj_ranged&amp; fused_car_msg)
 {
 	car_fused_objects = fused_car_msg;
 	//  show();
 }
 
-static void ped_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
+static void ped_updater_callback(const autoware_msgs::image_obj_ranged&amp; fused_pds_msg)
 {
   pedestrian_fused_objects = fused_pds_msg;
   //  show();
@@ -195,7 +195,7 @@ static void image_cb(const sensor_msgs::Image&amp; msg)
 	show();
 }
 
-static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
+static void points_cb(const autoware_msgs::PointsImageConstPtr&amp; msg)
 {
 	points_msg = msg;
 	existPoints = true;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv2/opencv.hpp&gt;

#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;points2image/PointsImage.h&gt;

#include &lt;cv_tracker_msgs/image_obj_ranged.h&gt;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;math.h&gt;
#include &lt;float.h&gt;

#include &lt;opencv2/core/core.hpp&gt;

#include &quot;gencolors.cpp&quot;

#define NO_DATA 0
static char window_name[] = &quot;vscan_image_d_viewer&quot;;

static bool existImage = false;
static bool existPoints = false;
static sensor_msgs::Image image_msg;
static points2image::PointsImageConstPtr points_msg;
static cv::Mat colormap;

#if 0
static std::vector&lt;cv::Rect&gt; cars;
static std::vector&lt;cv::Rect&gt; peds;
#else
static cv_tracker_msgs::image_obj_ranged car_fused_objects;
static cv_tracker_msgs::image_obj_ranged pedestrian_fused_objects;
#endif

/* check whether floating value x is nearly 0 or not */
static inline bool isNearlyNODATA(float x)
{
	float abs_x  = (float)fabs(x);
	const int rangeScale = 100;
	return(abs_x &lt; FLT_MIN*rangeScale);
}

static std::vector&lt;cv::Scalar&gt; _colors;

#define	IMAGE_WIDTH		800
#define	IMAGE_HEIGHT 	600

#define POINTS_THRESHOLD 0.1

static const int OBJ_RECT_THICKNESS = 3;

static void drawRects(cv::Mat image,
                    std::vector&lt;cv_tracker_msgs::image_rect_ranged&gt; objects,
					CvScalar color,
					int threshold_height,
					std::string objectClass)
{
	int object_num = objects.size();
	char distance_string[32];
	int fontFace = cv::FONT_HERSHEY_SIMPLEX; double fontScale = 0.55; int fontThick = 2;
	std::vector&lt;int&gt; pointsInBoundingBox;
	for(int i = 0; i &lt; object_num; i++)
	{
		//corner_point[0]=&gt;X1		corner_point[1]=&gt;Y1
		//corner_point[2]=&gt;width	corner_point[3]=&gt;height
		cv::Rect detection = cv::Rect(objects.at(i).rect.x, objects.at(i).rect.y, objects.at(i).rect.width, objects.at(i).rect.height);

		rectangle(image, detection, color, OBJ_RECT_THICKNESS);//draw bounding box
		putText(image, objectClass, cv::Point(detection.x + 4, detection.y + 10), fontFace, fontScale, color, fontThick);//draw label text

		sprintf(distance_string, &quot;D:%.2f m H:%.1f,%.1f&quot;, objects.at(i).range / 100, objects.at(i).min_height, objects.at(i).max_height);
		//Size textSize = getTextSize(string(distance_string), fontFace, fontScale, fontThick, 0);
		//rectangle(image, cv::Rect( detection.x, detection.y, textSize.width + 4, textSize.height + 10), Scalar::all(0), CV_FILLED);//draw fill distance rectangle
		putText(image, std::string(distance_string), cv::Point(detection.x + 4, detection.y - 10), fontFace, fontScale, color, fontThick);//draw distance text
	}
}

static void drawVScanPoints(cv::Mat image)
{
	/* DRAW POINTS of lidar scanning */
    int w = image.size().width;
	int h = image.size().height;

	int i, n = w * h;
	float min_d = 1&lt;&lt;16, max_d = -1;
	//	int min_i = 1&lt;&lt;8, max_i = -1;
	for(i=0; i&lt;n; i++){
		int di = points_msg-&gt;distance[i];
		max_d = di &gt; max_d ? di : max_d;
		min_d = di &lt; min_d ? di : min_d;
		// int it = points_msg-&gt;intensity[i];
		// max_i = it &gt; max_i ? it : max_i;
		// min_i = it &lt; min_i ? it : min_i;
	}
	float wid_d = max_d - min_d;

	int x, y;
	for(y=0; y&lt;h; y++){
		for(x=0; x&lt;w; x++){
			int i = y * w + x;
			double distance = points_msg-&gt;distance[i];

			if(distance == 0){
				continue;
			}
			int colorid= wid_d ? ( (distance - min_d) * 255 / wid_d ) : 128;
			cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
			int g = color[1];
			int b = color[2];
			int r = color[0];
			rectangle(image, cv::Rect(x, y,1, 1), cv::Scalar(r, g, b), OBJ_RECT_THICKNESS);
		}
	}
}

static void show(void)
{
	if(!existImage || !existPoints){
		return;
	}
	const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, encoding);
	IplImage frame = cv_image-&gt;image;

	cv::Mat matImage=cv::cvarrToMat(&amp;frame);//(&amp;frame, false);

	//Draw VScan Points
	drawVScanPoints(matImage);

	/* DRAW RECTANGLES of detected objects */
	drawRects(matImage,
		  car_fused_objects.obj,
		  cv::Scalar(255.0, 255.0, 0,0),
		  matImage.rows*.25,
		  car_fused_objects.type);

	drawRects(matImage,
		  pedestrian_fused_objects.obj,
		  cv::Scalar(0.0, 255.0, 0,0),
		  matImage.rows*.25,
		  pedestrian_fused_objects.type);

	if (cvGetWindowHandle(window_name) != NULL) // Guard not to write destroyed window by using close button on the window
	{
		cvShowImage(window_name, &amp;frame);
		cvWaitKey(2);
	}
}
static void car_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_car_msg)
{
	car_fused_objects = fused_car_msg;
	//  show();
}

static void ped_updater_callback(const cv_tracker_msgs::image_obj_ranged&amp; fused_pds_msg)
{
  pedestrian_fused_objects = fused_pds_msg;
  //  show();
}

static void image_cb(const sensor_msgs::Image&amp; msg)
{
	image_msg = msg;
	existImage = true;
	show();
}

static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
{
	points_msg = msg;
	existPoints = true;
	show();
}

int main(int argc, char **argv)
{
	/* create resizable window */
	cvNamedWindow(window_name, CV_WINDOW_NORMAL);
	cvStartWindowThread();

	ros::init(argc, argv, &quot;vscan_image_d_viewer&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	std::string image_topic_name;
	std::string car_node;
	std::string pedestrian_node;
	std::string points_node;

	if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name))
	{
		ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
	}
	else
	{
		ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
		image_topic_name = &quot;/image_raw&quot;;
	}

	if (private_nh.getParam(&quot;car_node&quot;, car_node))
	{
		ROS_INFO(&quot;Setting car positions node to %s&quot;, car_node.c_str());
	}
	else
	{
		ROS_INFO(&quot;No car positions node received, defaulting to car_pixel_xyz, you can use _car_node:=YOUR_TOPIC&quot;);
		car_node = &quot;/obj_car/image_obj_ranged&quot;;
	}

	if (private_nh.getParam(&quot;pedestrian_node&quot;, pedestrian_node))
	{
		ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, pedestrian_node.c_str());
	}
	else
	{
		ROS_INFO(&quot;No pedestrian positions node received, defaulting to pedestrian_pixel_xyz, you can use _pedestrian_node:=YOUR_TOPIC&quot;);
		pedestrian_node = &quot;/obj_person/image_obj_ranged&quot;;
	}

	if (private_nh.getParam(&quot;points_node&quot;, points_node))
	{
		ROS_INFO(&quot;Setting pedestrian positions node to %s&quot;, points_node.c_str());
	}
	else
	{
		ROS_INFO(&quot;No points node received, defaulting to points_image, you can use _points_node:=YOUR_TOPIC&quot;);
		points_node = &quot;/vscan_image&quot;;
	}
#if (CV_MAJOR_VERSION == 3)
	generateColors(_colors, 25);
#else
	cv::generateColors(_colors, 25);
#endif

	ros::Subscriber scriber = n.subscribe(image_topic_name, 1,
					    image_cb);
	ros::Subscriber scriber_car = n.subscribe(car_node, 1,
						car_updater_callback);
	ros::Subscriber scriber_ped = n.subscribe(pedestrian_node, 1,
						ped_updater_callback);
	ros::Subscriber scriber_points = n.subscribe(points_node, 1,
						points_cb);

	cv::Mat grayscale(256,1,CV_8UC1);
	for(int i=0;i&lt;256;i++)
	{
		grayscale.at&lt;uchar&gt;(i)=i;
	}
	cv::applyColorMap(grayscale,colormap,cv::COLORMAP_JET);

	ros::spin();

	cvDestroyWindow(window_name);

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/computing/perception/detection/packages/viewers/nodes/vscan_image_viewer/vscan_image_viewer.cpp" new_path="ros/src/computing/perception/detection/packages/viewers/nodes/vscan_image_viewer/vscan_image_viewer.cpp">
				<diff>@@ -35,7 +35,7 @@
 
 #include &quot;ros/ros.h&quot;
 #include &lt;sensor_msgs/image_encodings.h&gt;
-#include &quot;points2image/PointsImage.h&quot;
+#include &quot;autoware_msgs/PointsImage.h&quot;
 
 #define IMAGE_WIDTH 800
 #define IMAGE_HEIGHT 640
@@ -43,7 +43,7 @@
 static bool existImage = false;
 static bool existPoints = false;
 static sensor_msgs::Image image_msg;
-static points2image::PointsImageConstPtr points_msg;
+static autoware_msgs::PointsImageConstPtr points_msg;
 static cv::Mat colormap;
 
 static const char window_name[] = &quot;vscan_image_viewer&quot;;
@@ -102,7 +102,7 @@ static void image_cb(const sensor_msgs::Image&amp; msg)
 	show();
 }
 
-static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
+static void points_cb(const autoware_msgs::PointsImageConstPtr&amp; msg)
 {
 	points_msg = msg;
 	existPoints = true;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;

#include &quot;ros/ros.h&quot;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &quot;points2image/PointsImage.h&quot;

#define IMAGE_WIDTH 800
#define IMAGE_HEIGHT 640

static bool existImage = false;
static bool existPoints = false;
static sensor_msgs::Image image_msg;
static points2image::PointsImageConstPtr points_msg;
static cv::Mat colormap;

static const char window_name[] = &quot;vscan_image_viewer&quot;;

static void show(void)
{
	if(!existImage || !existPoints){
		return;
	}
	const auto&amp; encoding = sensor_msgs::image_encodings::BGR8;
	cv_bridge::CvImagePtr cv_image = cv_bridge::toCvCopy(image_msg, encoding);
	IplImage frame = cv_image-&gt;image;

	cv::Mat matImage=cv::cvarrToMat(&amp;frame);//(&amp;frame, false);

	int w = matImage.size().width;
	int h = matImage.size().height;
	int n = w * h;

	float min_d, max_d;
	min_d = max_d = points_msg-&gt;distance[0];
	for(int i=1; i&lt;n; i++){
		float di = points_msg-&gt;distance[i];
		max_d = di &gt; max_d ? di : max_d;
		min_d = di &lt; min_d ? di : min_d;
	}
	float wid_d = max_d - min_d;

	for(int y=0; y&lt;h; y++){
		for(int x=0; x&lt;w; x++){
			int j = y * w + x;
			float distance = points_msg-&gt;distance[j];
			if(distance == 0){
				continue;
			}
			int colorid= wid_d ? ( (distance - min_d) * 255 / wid_d ) : 128;
			cv::Vec3b color=colormap.at&lt;cv::Vec3b&gt;(colorid);
			int g = color[1];
			int b = color[2];
			int r = color[0];
			cvRectangle(&amp;frame, cvPoint(x, y), cvPoint(x+1, y+1), CV_RGB(r, g, b));
		}
	}

	if (cvGetWindowHandle(window_name) != NULL) // Guard not to write destroyed window by using close button on the window
	{
		cvShowImage(window_name, &amp;frame);
		cvWaitKey(2);
	}
}

static void image_cb(const sensor_msgs::Image&amp; msg)
{
	image_msg = msg;
	existImage = true;
	show();
}

static void points_cb(const points2image::PointsImageConstPtr&amp; msg)
{
	points_msg = msg;
	existPoints = true;
	show();
}

int main(int argc, char **argv)
{
	/* create resizable window */
	cvNamedWindow(window_name, CV_WINDOW_NORMAL);
	cvStartWindowThread();

	ros::init(argc, argv, &quot;vscan_image_viewer&quot;);
	ros::NodeHandle n;
	ros::NodeHandle private_nh(&quot;~&quot;);

	std::string image_topic_name;
	if (private_nh.getParam(&quot;image_raw_topic&quot;, image_topic_name)) {
		ROS_INFO(&quot;Setting image topic to %s&quot;, image_topic_name.c_str());
	} else {
		ROS_INFO(&quot;No image topic received, defaulting to image_raw, you can use _image_raw_topic:=YOUR_NODE&quot;);
		image_topic_name = &quot;/image_raw&quot;;
	}

	ros::Subscriber sub_image = n.subscribe(image_topic_name, 1, image_cb);

	ros::Subscriber sub_points = n.subscribe(&quot;vscan_image&quot;, 1, points_cb);

	cv::Mat grayscale(256,1,CV_8UC1);
	for(int i=0;i&lt;256;i++)
	{
		grayscale.at&lt;uchar&gt;(i)=i;
	}
	cv::applyColorMap(grayscale,colormap,cv::COLORMAP_JET);

	ros::spin();

	cvDestroyWindow(window_name);

	return 0;
}
</old_file>
			</file>
			<file old_path="ros/src/sensing/polygon/packages/points2polygon/nodes/points2polygon/points2polygon.cpp" new_path="ros/src/sensing/polygon/packages/points2polygon/nodes/points2polygon/points2polygon.cpp">
				<diff>@@ -32,7 +32,7 @@
 #include &lt;ros/console.h&gt;
 
 #include &lt;sensor_msgs/PointCloud2.h&gt;
-#include &lt;runtime_manager/ConfigPoints2Polygon.h&gt;
+#include &lt;autoware_msgs/ConfigPoints2Polygon.h&gt;
 
 #include &lt;pcl/point_types.h&gt;
 #include &lt;pcl/io/pcd_io.h&gt;
@@ -115,7 +115,7 @@ static void points_to_polygon(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr&amp; cloud)
 	pcl::io::saveVTKFile(points_polygon_vtk, triangles);
 }
 
-static void config_callback(const runtime_manager::ConfigPoints2Polygon&amp; msg)
+static void config_callback(const autoware_msgs::ConfigPoints2Polygon&amp; msg)
 {
 	config_k_search = msg.k_search;
 	config_search_radius = msg.search_radius;
</diff>
				<old_file>/*
 *  Copyright (c) 2015, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include &lt;ros/ros.h&gt;
#include &lt;ros/console.h&gt;

#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;runtime_manager/ConfigPoints2Polygon.h&gt;

#include &lt;pcl/point_types.h&gt;
#include &lt;pcl/io/pcd_io.h&gt;
#include &lt;pcl/io/vtk_io.h&gt;
#include &lt;pcl/kdtree/kdtree_flann.h&gt;
#include &lt;pcl/features/normal_3d.h&gt;
#include &lt;pcl/surface/gp3.h&gt;

#include &lt;pcl_conversions/pcl_conversions.h&gt;

static constexpr uint32_t SUBSCRIBE_QUEUE_SIZE = 1;

static constexpr bool USE_PCD_FILE = false;
static const std::string VELODYNE_POINTS_PCD = &quot;/tmp/velodyne_points.pcd&quot;;
static const std::string POINTS_POLYGON_VTK = &quot;/tmp/points_polygon.vtk&quot;;

static int config_k_search = 20;
static double config_search_radius = 0.025;
static double config_mu = 2.5;
static int config_maximum_nearest_neighbors = 100;
static double config_maximum_surface_angle = M_PI / 4; // 45 degrees
static double config_minimum_angle = M_PI / 18; // 10 degrees
static double config_maximum_angle = 2 * M_PI / 3; // 120 degrees
static bool config_normal_consistency = false;

static bool use_pcd_file;
static std::string velodyne_points_pcd;
static std::string points_polygon_vtk;

static void points_to_polygon(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr&amp; cloud)
{
	// Normal estimation
	pcl::NormalEstimation&lt;pcl::PointXYZ, pcl::Normal&gt; n;
	pcl::PointCloud&lt;pcl::Normal&gt;::Ptr
		normals(new pcl::PointCloud&lt;pcl::Normal&gt;);
	pcl::search::KdTree&lt;pcl::PointXYZ&gt;::Ptr
		tree(new pcl::search::KdTree&lt;pcl::PointXYZ&gt;);
	tree-&gt;setInputCloud(cloud);
	n.setInputCloud(cloud);
	n.setSearchMethod(tree);
	n.setKSearch(config_k_search);
	n.compute(*normals);

	// Concatenate the XYZ and normal fields
	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr
		cloud_with_normals(new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::concatenateFields(*cloud, *normals, *cloud_with_normals);

	// Create search tree
	pcl::search::KdTree&lt;pcl::PointNormal&gt;::Ptr
		tree2(new pcl::search::KdTree&lt;pcl::PointNormal&gt;);
	tree2-&gt;setInputCloud(cloud_with_normals);

	// Initialize objects
	pcl::GreedyProjectionTriangulation&lt;pcl::PointNormal&gt; gp3;
	pcl::PolygonMesh triangles;

	// Set the maximum distance between connected points
	// (maximum edge length)
	gp3.setSearchRadius(config_search_radius);

	// Set typical values for the parameters
	gp3.setMu(config_mu);
	gp3.setMaximumNearestNeighbors(config_maximum_nearest_neighbors);
	gp3.setMaximumSurfaceAngle(config_maximum_surface_angle);
	gp3.setMinimumAngle(config_minimum_angle);
	gp3.setMaximumAngle(config_maximum_angle);
	gp3.setNormalConsistency(config_normal_consistency);

	// Get result
	gp3.setInputCloud(cloud_with_normals);
	gp3.setSearchMethod(tree2);
	gp3.reconstruct(triangles);

	// Additional vertex information
	std::vector&lt;int&gt; parts = gp3.getPartIDs();
	std::vector&lt;int&gt; states = gp3.getPointStates();

	// Save result into a output file
	pcl::io::saveVTKFile(points_polygon_vtk, triangles);
}

static void config_callback(const runtime_manager::ConfigPoints2Polygon&amp; msg)
{
	config_k_search = msg.k_search;
	config_search_radius = msg.search_radius;
	config_mu = msg.mu;
	config_maximum_nearest_neighbors = msg.maximum_nearest_neighbors;
	config_maximum_surface_angle = msg.maximum_surface_angle;
	config_minimum_angle = msg.minimum_angle;
	config_maximum_angle = msg.maximum_angle;
	config_normal_consistency = msg.normal_consistency;

	if (use_pcd_file) {
		// Load input file into a PointCloud&lt;T&gt; with an appropriate
		// type
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr
			cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PCLPointCloud2 cloud_blob;
		pcl::io::loadPCDFile(velodyne_points_pcd, cloud_blob);
		pcl::fromPCLPointCloud2(cloud_blob, *cloud);

		points_to_polygon(cloud);
	}
}

static void velodyne_points_callback(const sensor_msgs::PointCloud2&amp; msg)
{
	if (use_pcd_file)
		ROS_WARN(&quot;use_pcd_file: true&quot;);
	else {
		// Load ROS message into a PointCloud&lt;T&gt; with an appropriate
		// type
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr
			cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::fromROSMsg(msg, *cloud);

		points_to_polygon(cloud);
	}
}

int main(int argc, char **argv)
{
	ros::init(argc, argv, &quot;points2polygon&quot;);

	ros::NodeHandle n;
	n.param&lt;bool&gt;(&quot;points2polygon/use_pcd_file&quot;,
		      use_pcd_file, USE_PCD_FILE);
	n.param&lt;std::string&gt;(&quot;points2polygon/velodyne_points_pcd&quot;,
			     velodyne_points_pcd, VELODYNE_POINTS_PCD);
	n.param&lt;std::string&gt;(&quot;points2polygon/points_polygon_vtk&quot;,
			     points_polygon_vtk, POINTS_POLYGON_VTK);

	ros::Subscriber sub_config = n.subscribe(&quot;config/points2polygon&quot;,
						 SUBSCRIBE_QUEUE_SIZE,
						 config_callback);
	ros::Subscriber sub_points = n.subscribe(&quot;points_raw&quot;,
						 SUBSCRIBE_QUEUE_SIZE,
						 velodyne_points_callback);

	if (use_pcd_file) {
		// Load input file into a PointCloud&lt;T&gt; with an appropriate
		// type
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr
			cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PCLPointCloud2 cloud_blob;
		pcl::io::loadPCDFile(velodyne_points_pcd, cloud_blob);
		pcl::fromPCLPointCloud2(cloud_blob, *cloud);

		points_to_polygon(cloud);
	}

	ros::spin();

	return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="c0dc6cff7b9068dd121c5185b08b00a4cdca02a9" fix_time="0,52173">
		<msg>ROS_WARN_ONCE &quot; VectorMap Server Call failed&quot;</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/euclidean_cluster/euclidean_cluster.cpp">
				<diff>@@ -607,7 +607,7 @@ void segmentByDistance(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
 				}
 				else
 				{
-					ROS_WARN(&quot;vectormap_filtering: VectorMap Server Call failed. Make sure vectormap_server is running. No filtering performed.&quot;);
+					ROS_WARN_ONCE(&quot;vectormap_filtering: VectorMap Server Call failed. Make sure vectormap_server is running. No filtering performed.&quot;);
 					final_clusters[i]-&gt;SetValidity(true);
 				}
 			}
</diff>
				<old_file>#include &lt;ros/ros.h&gt;

#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/PCLPointCloud2.h&gt;
#include &lt;pcl/conversions.h&gt;
#include &lt;pcl_ros/transforms.h&gt;
#include &lt;pcl_ros/point_cloud.h&gt;

#include &lt;pcl/ModelCoefficients.h&gt;
#include &lt;pcl/point_types.h&gt;

#include &lt;pcl/filters/extract_indices.h&gt;
#include &lt;pcl/filters/voxel_grid.h&gt;
#include &lt;pcl/filters/conditional_removal.h&gt;

#include &lt;pcl/features/normal_3d.h&gt;
#include &lt;pcl/features/normal_3d_omp.h&gt;
#include &lt;pcl/features/don.h&gt;
#include &lt;pcl/features/fpfh_omp.h&gt;

#include &lt;pcl/kdtree/kdtree.h&gt;

#include &lt;pcl/sample_consensus/method_types.h&gt;
#include &lt;pcl/sample_consensus/model_types.h&gt;

#include &lt;pcl/segmentation/sac_segmentation.h&gt;
#include &lt;pcl/segmentation/extract_clusters.h&gt;
#include &lt;pcl/segmentation/conditional_euclidean_clustering.h&gt;

#include &lt;pcl/common/common.h&gt;

#include &lt;pcl/search/organized.h&gt;
#include &lt;pcl/search/kdtree.h&gt;

#include &lt;pcl/segmentation/extract_clusters.h&gt;

#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;visualization_msgs/Marker.h&gt;

#include &lt;std_msgs/Float32MultiArray.h&gt;
#include &lt;std_msgs/MultiArrayLayout.h&gt;
#include &lt;std_msgs/MultiArrayDimension.h&gt;

#include &quot;autoware_msgs/centroids.h&quot;
#include &quot;autoware_msgs/CloudCluster.h&quot;
#include &quot;autoware_msgs/CloudClusterArray.h&quot;

#include &lt;vector_map_server/PositionState.h&gt;

#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;
#include &lt;jsk_rviz_plugins/Pictogram.h&gt;
#include &lt;jsk_rviz_plugins/PictogramArray.h&gt;

#include &lt;tf/tf.h&gt;

#include &lt;limits&gt;
#include &lt;cmath&gt;

#include &lt;opencv/cv.h&gt;
#include &lt;opencv/highgui.h&gt;
#include &lt;opencv2/core/version.hpp&gt;
#if (CV_MAJOR_VERSION == 3)
#include &quot;gencolors.cpp&quot;
#else
#include &lt;opencv2/contrib/contrib.hpp&gt;
#endif

#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;string&gt;
#include &lt;sstream&gt;

#include &quot;Cluster.h&quot;

//#include &lt;vector_map/vector_map.h&gt;
//#include &lt;vector_map_server/GetSignal.h&gt;

#ifdef GPU_CLUSTERING
	#include &quot;gpu_euclidean_clustering.h&quot;
#endif

using namespace cv;

std::vector&lt;cv::Scalar&gt; _colors;
ros::Publisher _pub_cluster_cloud;
ros::Publisher _pub_ground_cloud;
ros::Publisher _centroid_pub;
ros::Publisher _marker_pub;
ros::Publisher _pub_clusters_message;
ros::Publisher _pub_text_pictogram;
visualization_msgs::Marker _visualization_marker;

ros::Publisher _pub_points_lanes_cloud;
ros::Publisher _pub_jsk_boundingboxes;
ros::Publisher _pub_jsk_hulls;

ros::ServiceClient _vectormap_server;

std_msgs::Header _velodyne_header;

pcl::PointCloud&lt;pcl::PointXYZ&gt; _sensor_cloud;

std::vector&lt;double&gt; _clustering_thresholds;
std::vector&lt;double&gt; _clustering_distances;

tf::StampedTransform* _transform;
tf::StampedTransform* _velodyne_output_transform;
tf::TransformListener* _transform_listener;

std::string _output_frame;
std::string _vectormap_frame;
static bool _velodyne_transform_available;
static bool _downsample_cloud;
static bool _pose_estimation;
static double _leaf_size;
static int _cluster_size_min;
static int _cluster_size_max;

static bool _remove_ground;	//only ground

static bool _using_sensor_cloud;
static bool _use_diffnormals;
static bool _use_vector_map;

static double _clip_min_height;
static double _clip_max_height;

static bool _keep_lanes;
static double _keep_lane_left_distance;
static double _keep_lane_right_distance;

static double _max_boundingbox_side;
static double _remove_points_upto;
static double _cluster_merge_threshold;

static bool _use_gpu;
static std::chrono::system_clock::time_point _start, _end;

void transformBoundingBox(const jsk_recognition_msgs::BoundingBox&amp; in_boundingbox, jsk_recognition_msgs::BoundingBox&amp; out_boundingbox, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	geometry_msgs::PoseStamped pose_in, pose_out;
	pose_in.header = in_header;
	pose_in.pose = in_boundingbox.pose;
	try
	{
		_transform_listener-&gt;transformPose(in_target_frame, ros::Time(), pose_in, in_header.frame_id,  pose_out);
	}
	catch (tf::TransformException &amp;ex)
	{
		ROS_ERROR(&quot;transformBoundingBox: %s&quot;,ex.what());
	}
	out_boundingbox.pose = pose_out.pose;
	out_boundingbox.header = in_header;
	out_boundingbox.header.frame_id = in_target_frame;
	out_boundingbox.dimensions = in_boundingbox.dimensions;
	out_boundingbox.value = in_boundingbox.value;
	out_boundingbox.label = in_boundingbox.label;
}

void publishCloudClusters(const ros::Publisher* in_publisher, const autoware_msgs::CloudClusterArray&amp; in_clusters, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		autoware_msgs::CloudClusterArray clusters_transformed;
		clusters_transformed.header = in_header;
		clusters_transformed.header.frame_id = in_target_frame;
		for (auto i=in_clusters.clusters.begin(); i!= in_clusters.clusters.end(); i++)
		{
			autoware_msgs::CloudCluster cluster_transformed;
			cluster_transformed.header = in_header;
			try
			{
				_transform_listener-&gt;lookupTransform(in_target_frame, _velodyne_header.frame_id,
										ros::Time(), *_transform);
				pcl_ros::transformPointCloud(in_target_frame, *_transform, i-&gt;cloud, cluster_transformed.cloud);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;min_point, in_header.frame_id, cluster_transformed.min_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;max_point, in_header.frame_id, cluster_transformed.max_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;avg_point, in_header.frame_id, cluster_transformed.avg_point);
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), i-&gt;centroid_point, in_header.frame_id, cluster_transformed.centroid_point);

				cluster_transformed.dimensions = i-&gt;dimensions;
				cluster_transformed.eigen_values = i-&gt;eigen_values;
				cluster_transformed.eigen_vectors = i-&gt;eigen_vectors;

				transformBoundingBox(i-&gt;bounding_box, cluster_transformed.bounding_box, in_target_frame, in_header);

				clusters_transformed.clusters.push_back(cluster_transformed);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCloudClusters: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(clusters_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_clusters);
	}
}

void publishCentroids(const ros::Publisher* in_publisher, const autoware_msgs::centroids&amp; in_centroids, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		autoware_msgs::centroids centroids_transformed;
		centroids_transformed.header = in_header;
		centroids_transformed.header.frame_id = in_target_frame;
		for (auto i=centroids_transformed.points.begin(); i!= centroids_transformed.points.end(); i++)
		{
			geometry_msgs::PointStamped centroid_in, centroid_out;
			centroid_in.header = in_header;
			centroid_in.point = *i;
			try
			{
				_transform_listener-&gt;transformPoint(in_target_frame, ros::Time(), centroid_in, in_header.frame_id, centroid_out);

				centroids_transformed.points.push_back(centroid_out.point);
			}
			catch (tf::TransformException &amp;ex)
			{
				ROS_ERROR(&quot;publishCentroids: %s&quot;,ex.what());
			}
		}
		in_publisher-&gt;publish(centroids_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_centroids);
	}
}

void publishBoundingBoxArray(const ros::Publisher* in_publisher, const jsk_recognition_msgs::BoundingBoxArray&amp; in_boundingbox_array, const std::string&amp; in_target_frame, const std_msgs::Header&amp; in_header)
{
	if (in_target_frame!=in_header.frame_id)
	{
		jsk_recognition_msgs::BoundingBoxArray boundingboxes_transformed;
		boundingboxes_transformed.header = in_header;
		boundingboxes_transformed.header.frame_id = in_target_frame;
		for (auto i=in_boundingbox_array.boxes.begin(); i!= in_boundingbox_array.boxes.end(); i++)
		{
			jsk_recognition_msgs::BoundingBox boundingbox_transformed;
			transformBoundingBox(*i, boundingbox_transformed, in_target_frame, in_header);
			boundingboxes_transformed.boxes.push_back(boundingbox_transformed);
		}
		in_publisher-&gt;publish(boundingboxes_transformed);
	}
	else
	{
		in_publisher-&gt;publish(in_boundingbox_array);
	}
}

void publishCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void publishColorCloud(const ros::Publisher* in_publisher, const pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr in_cloud_to_publish_ptr)
{
	sensor_msgs::PointCloud2 cloud_msg;
	pcl::toROSMsg(*in_cloud_to_publish_ptr, cloud_msg);
	cloud_msg.header=_velodyne_header;
	in_publisher-&gt;publish(cloud_msg);
}

void keepLanePoints(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
					pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr,
					float in_left_lane_threshold = 1.5,
					float in_right_lane_threshold = 1.5)
{
	pcl::PointIndices::Ptr far_indices (new pcl::PointIndices);
	for(unsigned int i=0; i&lt; in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x=in_cloud_ptr-&gt;points[i].x;
		current_point.y=in_cloud_ptr-&gt;points[i].y;
		current_point.z=in_cloud_ptr-&gt;points[i].z;

		if (
				current_point.y &gt; (in_left_lane_threshold) || current_point.y &lt; -1.0*in_right_lane_threshold
			)
		{
			far_indices-&gt;indices.push_back(i);
		}
	}
	out_cloud_ptr-&gt;points.clear();
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(far_indices);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_cloud_ptr);
}

#ifdef GPU_CLUSTERING
std::vector&lt;ClusterPtr&gt; clusterAndColorGpu(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
											pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
											jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
											autoware_msgs::centroids&amp; in_out_centroids,
											double in_max_cluster_distance=0.5)
{
	std::vector&lt;ClusterPtr&gt; clusters;

	//Convert input point cloud to vectors of x, y, and z

	int size = in_cloud_ptr-&gt;points.size();

	if (size == 0)
		return clusters;

	float *tmp_x, *tmp_y, *tmp_z;

	tmp_x = (float *)malloc(sizeof(float) * size);
	tmp_y = (float *)malloc(sizeof(float) * size);
	tmp_z = (float *)malloc(sizeof(float) * size);

	for (int i = 0; i &lt; size; i++) {
		pcl::PointXYZ tmp_point = in_cloud_ptr-&gt;at(i);

		tmp_x[i] = tmp_point.x;
		tmp_y[i] = tmp_point.y;
		tmp_z[i] = tmp_point.z;
	}

	GpuEuclideanCluster gecl_cluster;

	gecl_cluster.setInputPoints(tmp_x, tmp_y, tmp_z, size);
	gecl_cluster.setThreshold(in_max_cluster_distance);
	gecl_cluster.setMinClusterPts (_cluster_size_min);
	gecl_cluster.setMaxClusterPts (_cluster_size_max);
	gecl_cluster.extractClusters();
	std::vector&lt;GpuEuclideanCluster::GClusterIndex&gt; cluster_indices = gecl_cluster.getOutput();

	unsigned int k = 0;

	for (auto it = cluster_indices.begin(); it != cluster_indices.end(); it++)
	{
		ClusterPtr cluster(new Cluster());
		cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;points_in_cluster, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		clusters.push_back(cluster);

		k++;
	}

	free(tmp_x);
	free(tmp_y);
	free(tmp_z);

	return clusters;
}
#endif

std::vector&lt;ClusterPtr&gt; clusterAndColor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		autoware_msgs::centroids&amp; in_out_centroids,
		double in_max_cluster_distance=0.5)
{
	pcl::search::KdTree&lt;pcl::PointXYZ&gt;::Ptr tree (new pcl::search::KdTree&lt;pcl::PointXYZ&gt;);

	//create 2d pc
	pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud_2d(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
	pcl::copyPointCloud(*in_cloud_ptr, *cloud_2d);
	//make it flat
	for (size_t i=0; i&lt;cloud_2d-&gt;points.size(); i++)
	{
		cloud_2d-&gt;points[i].z = 0;
	}

	if (cloud_2d-&gt;points.size() &gt; 0)
		tree-&gt;setInputCloud (cloud_2d);

	std::vector&lt;pcl::PointIndices&gt; cluster_indices;

	//perform clustering on 2d cloud
	pcl::EuclideanClusterExtraction&lt;pcl::PointXYZ&gt; ec;
	ec.setClusterTolerance (in_max_cluster_distance); //
	ec.setMinClusterSize (_cluster_size_min);
	ec.setMaxClusterSize (_cluster_size_max);
	ec.setSearchMethod(tree);
	ec.setInputCloud (cloud_2d);
	ec.extract (cluster_indices);
	//use indices on 3d cloud

	/*pcl::ConditionalEuclideanClustering&lt;pcl::PointXYZ&gt; cec (true);
	cec.setInputCloud (in_cloud_ptr);
	cec.setConditionFunction (&amp;independentDistance);
	cec.setMinClusterSize (cluster_size_min);
	cec.setMaxClusterSize (cluster_size_max);
	cec.setClusterTolerance (_distance*2.0f);
	cec.segment (cluster_indices);*/

	/////////////////////////////////
	//---	3. Color clustered points
	/////////////////////////////////
	unsigned int k = 0;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr final_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

	std::vector&lt;ClusterPtr&gt; clusters;
	//pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr cloud_cluster (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);//coord + color cluster
	for (auto it = cluster_indices.begin(); it != cluster_indices.end(); ++it)
	{
		ClusterPtr cluster(new Cluster());
		cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;indices, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		clusters.push_back(cluster);

		k++;
	}
	//std::cout &lt;&lt; &quot;Clusters: &quot; &lt;&lt; k &lt;&lt; std::endl;
	return clusters;

}

void checkClusterMerge(size_t in_cluster_id, std::vector&lt;ClusterPtr&gt;&amp; in_clusters, std::vector&lt;bool&gt;&amp; in_out_visited_clusters, std::vector&lt;size_t&gt;&amp; out_merge_indices, double in_merge_threshold)
{
	//std::cout &lt;&lt; &quot;checkClusterMerge&quot; &lt;&lt; std::endl;
	pcl::PointXYZ point_a = in_clusters[in_cluster_id]-&gt;GetCentroid();
	for(size_t i=0; i&lt; in_clusters.size(); i++)
	{
		if (i != in_cluster_id &amp;&amp; !in_out_visited_clusters[i])
		{
			pcl::PointXYZ point_b = in_clusters[i]-&gt;GetCentroid();
			double distance = sqrt( pow(point_b.x - point_a.x,2) + pow(point_b.y - point_a.y,2) );
			if (distance &lt;= in_merge_threshold)
			{
				in_out_visited_clusters[i] = true;
				out_merge_indices.push_back(i);
				//std::cout &lt;&lt; &quot;Merging &quot; &lt;&lt; in_cluster_id &lt;&lt; &quot; with &quot; &lt;&lt; i &lt;&lt; &quot; dist:&quot; &lt;&lt; distance &lt;&lt; std::endl;
				checkClusterMerge(i, in_clusters, in_out_visited_clusters, out_merge_indices, in_merge_threshold);
			}
		}
	}
}

void mergeClusters(const std::vector&lt;ClusterPtr&gt;&amp; in_clusters, std::vector&lt;ClusterPtr&gt;&amp; out_clusters, std::vector&lt;size_t&gt; in_merge_indices, const size_t&amp; current_index, std::vector&lt;bool&gt;&amp; in_out_merged_clusters)
{
	//std::cout &lt;&lt; &quot;mergeClusters:&quot; &lt;&lt; in_merge_indices.size() &lt;&lt; std::endl;
	pcl::PointCloud&lt;pcl::PointXYZRGB&gt; sum_cloud;
	pcl::PointCloud&lt;pcl::PointXYZ&gt; mono_cloud;
	ClusterPtr merged_cluster(new Cluster());
	for (size_t i=0; i&lt;in_merge_indices.size(); i++)
	{
		sum_cloud += *(in_clusters[in_merge_indices[i]]-&gt;GetCloud());
		in_out_merged_clusters[in_merge_indices[i]] = true;
	}
	std::vector&lt;int&gt; indices(sum_cloud.points.size(), 0);
	for (size_t i=0; i&lt;sum_cloud.points.size(); i++)
	{
		indices[i]=i;
	}

	if (sum_cloud.points.size() &gt; 0)
	{
		pcl::copyPointCloud(sum_cloud, mono_cloud);
		//std::cout &lt;&lt; &quot;mergedClusters &quot; &lt;&lt; sum_cloud.points.size() &lt;&lt; &quot; mono:&quot; &lt;&lt; mono_cloud.points.size() &lt;&lt; std::endl;
		//cluster-&gt;SetCloud(in_cloud_ptr, it-&gt;indices, _velodyne_header, k, (int)_colors[k].val[0], (int)_colors[k].val[1], (int)_colors[k].val[2], &quot;&quot;, _pose_estimation);
		merged_cluster-&gt;SetCloud(mono_cloud.makeShared(), indices, _velodyne_header, current_index,(int)_colors[current_index].val[0], (int)_colors[current_index].val[1], (int)_colors[current_index].val[2], &quot;&quot;, _pose_estimation);
		out_clusters.push_back(merged_cluster);
	}
}

void checkAllForMerge(std::vector&lt;ClusterPtr&gt;&amp; in_clusters, std::vector&lt;ClusterPtr&gt;&amp; out_clusters, float in_merge_threshold)
{
	//std::cout &lt;&lt; &quot;checkAllForMerge&quot; &lt;&lt; std::endl;
	std::vector&lt;bool&gt; visited_clusters(in_clusters.size(), false);
	std::vector&lt;bool&gt; merged_clusters(in_clusters.size(), false);
	size_t current_index=0;
	for (size_t i = 0; i&lt; in_clusters.size(); i++)
	{
		if (!visited_clusters[i])
		{
			visited_clusters[i] = true;
			std::vector&lt;size_t&gt; merge_indices;
			checkClusterMerge(i, in_clusters, visited_clusters, merge_indices, in_merge_threshold);
			mergeClusters(in_clusters, out_clusters, merge_indices, current_index++, merged_clusters);
		}
	}
	for(size_t i =0; i&lt; in_clusters.size(); i++)
	{
		//check for clusters not merged, add them to the output
		if (!merged_clusters[i])
		{
			out_clusters.push_back(in_clusters[i]);
		}
	}

	//ClusterPtr cluster(new Cluster());
}

void segmentByDistance(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr,
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr out_cloud_ptr,
		jsk_recognition_msgs::BoundingBoxArray&amp; in_out_boundingbox_array,
		autoware_msgs::centroids&amp; in_out_centroids,
		autoware_msgs::CloudClusterArray&amp; in_out_clusters,
		jsk_recognition_msgs::PolygonArray&amp; in_out_polygon_array,
		jsk_rviz_plugins::PictogramArray&amp; in_out_pictogram_array)
{
	//cluster the pointcloud according to the distance of the points using different thresholds (not only one for the entire pc)
	//in this way, the points farther in the pc will also be clustered

	//0 =&gt; 0-15m d=0.5
	//1 =&gt; 15-30 d=1
	//2 =&gt; 30-45 d=1.6
	//3 =&gt; 45-60 d=2.1
	//4 =&gt; &gt;60   d=2.6

	std::vector&lt;pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr&gt; cloud_segments_array(5);

	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr tmp_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		cloud_segments_array[i] = tmp_cloud;
	}

	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		pcl::PointXYZ current_point;
		current_point.x = in_cloud_ptr-&gt;points[i].x;
		current_point.y = in_cloud_ptr-&gt;points[i].y;
		current_point.z = in_cloud_ptr-&gt;points[i].z;

		float origin_distance = sqrt( pow(current_point.x,2) + pow(current_point.y,2) );

		if 		(origin_distance &lt; _clustering_distances[0] )	{cloud_segments_array[0]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[1])		{cloud_segments_array[1]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[2])		{cloud_segments_array[2]-&gt;points.push_back (current_point);}
		else if(origin_distance &lt; _clustering_distances[3])		{cloud_segments_array[3]-&gt;points.push_back (current_point);}
		else													{cloud_segments_array[4]-&gt;points.push_back (current_point);}
	}

	std::vector &lt;ClusterPtr&gt; all_clusters;
	for(unsigned int i=0; i&lt;cloud_segments_array.size(); i++)
	{
#ifdef GPU_CLUSTERING
    std::vector&lt;ClusterPtr&gt; local_clusters;
		if (_use_gpu) {
			local_clusters = clusterAndColorGpu(cloud_segments_array[i], out_cloud_ptr, in_out_boundingbox_array, in_out_centroids, _clustering_thresholds[i]);
		} else {
			local_clusters = clusterAndColor(cloud_segments_array[i], out_cloud_ptr, in_out_boundingbox_array, in_out_centroids, _clustering_thresholds[i]);
		}
#else
		std::vector&lt;ClusterPtr&gt; local_clusters = clusterAndColor(cloud_segments_array[i], out_cloud_ptr, in_out_boundingbox_array, in_out_centroids, _clustering_thresholds[i]);
#endif
		all_clusters.insert(all_clusters.end(), local_clusters.begin(), local_clusters.end());
	}

	//Clusters can be merged or checked in here
	//....
	//check for mergable clusters
	std::vector&lt;ClusterPtr&gt; mid_clusters;
	std::vector&lt;ClusterPtr&gt; final_clusters;

	if (all_clusters.size() &gt; 0)
		checkAllForMerge(all_clusters, mid_clusters, _cluster_merge_threshold);
	else
		mid_clusters = all_clusters;

	if (mid_clusters.size() &gt; 0)
			checkAllForMerge(mid_clusters, final_clusters, _cluster_merge_threshold);
	else
		final_clusters = mid_clusters;

	tf::StampedTransform vectormap_transform;
	if (_use_vector_map)
	{
		cv::TickMeter timer;

		try
		{
			//if the frame of the vectormap is different than the input, obtain transform
			if (_vectormap_frame != _velodyne_header.frame_id)
			{
				_transform_listener-&gt;lookupTransform(_vectormap_frame, _velodyne_header.frame_id, ros::Time(), vectormap_transform);
			}

			timer.reset();timer.start();

			//check if centroids are inside the drivable area
			for(unsigned int i=0; i&lt;final_clusters.size(); i++)
			{
				//transform centroid points to vectormap frame
				pcl::PointXYZ pcl_centroid = final_clusters[i]-&gt;GetCentroid();
				tf::Vector3 vector_centroid (pcl_centroid.x, pcl_centroid.y, pcl_centroid.z);
				tf::Vector3 transformed_centroid;

				if (_vectormap_frame != _velodyne_header.frame_id)
					transformed_centroid = vectormap_transform*vector_centroid;
				else
					transformed_centroid = vector_centroid;

				vector_map_server::PositionState position_state;
				position_state.request.position.x = transformed_centroid.getX();
				position_state.request.position.y = transformed_centroid.getY();
				position_state.request.position.z = transformed_centroid.getZ();


				if (_vectormap_server.call(position_state))
				{
					final_clusters[i]-&gt;SetValidity(position_state.response.state);
					/*std::cout &lt;&lt; &quot;Original:&quot; &lt;&lt; pcl_centroid.x &lt;&lt; &quot;,&quot; &lt;&lt; pcl_centroid.y &lt;&lt; &quot;,&quot; &lt;&lt; pcl_centroid.z &lt;&lt;
							&quot; Transformed:&quot; &lt;&lt; transformed_centroid.x() &lt;&lt; &quot;,&quot; &lt;&lt; transformed_centroid.y() &lt;&lt; &quot;,&quot; &lt;&lt; transformed_centroid.z() &lt;&lt;
							&quot; Validity:&quot; &lt;&lt; position_state.response.state &lt;&lt; std::endl;*/
				}
				else
				{
					ROS_WARN(&quot;vectormap_filtering: VectorMap Server Call failed. Make sure vectormap_server is running. No filtering performed.&quot;);
					final_clusters[i]-&gt;SetValidity(true);
				}
			}
			timer.stop();
			//std::cout &lt;&lt; &quot;vm server took &quot; &lt;&lt; timer.getTimeMilli() &lt;&lt; &quot; ms to check &quot; &lt;&lt; final_clusters.size() &lt;&lt; std::endl;
		}
		catch(tf::TransformException &amp;ex)
		{
			ROS_INFO(&quot;vectormap_filtering: %s&quot;, ex.what());
		}
	}
	//Get final PointCloud to be published
	in_out_polygon_array.header = _velodyne_header;
	in_out_pictogram_array.header = _velodyne_header;
	for(unsigned int i=0; i&lt;final_clusters.size(); i++)
	{
		*out_cloud_ptr = *out_cloud_ptr + *(final_clusters[i]-&gt;GetCloud());

		jsk_recognition_msgs::BoundingBox bounding_box = final_clusters[i]-&gt;GetBoundingBox();
		geometry_msgs::PolygonStamped polygon = final_clusters[i]-&gt;GetPolygon();
		jsk_rviz_plugins::Pictogram pictogram_cluster;
		pictogram_cluster.header = _velodyne_header;

		//PICTO
		pictogram_cluster.mode = pictogram_cluster.STRING_MODE;
		pictogram_cluster.pose.position.x = final_clusters[i]-&gt;GetMaxPoint().x;
		pictogram_cluster.pose.position.y = final_clusters[i]-&gt;GetMaxPoint().y;
		pictogram_cluster.pose.position.z = final_clusters[i]-&gt;GetMaxPoint().z;
		tf::Quaternion quat(0.0, -0.7, 0.0, 0.7);
		tf::quaternionTFToMsg(quat, pictogram_cluster.pose.orientation);
		pictogram_cluster.size = 4;
		std_msgs::ColorRGBA color;
		color.a = 1; color.r = 1; color.g = 1; color.b = 1;
		pictogram_cluster.color = color;
		pictogram_cluster.character = std::to_string( i );
		//PICTO

		//pcl::PointXYZ min_point = final_clusters[i]-&gt;GetMinPoint();
		//pcl::PointXYZ max_point = final_clusters[i]-&gt;GetMaxPoint();
		pcl::PointXYZ center_point = final_clusters[i]-&gt;GetCentroid();
		geometry_msgs::Point centroid;
		centroid.x = center_point.x; centroid.y = center_point.y; centroid.z = center_point.z;
		bounding_box.header = _velodyne_header;
		polygon.header = _velodyne_header;

		if (	final_clusters[i]-&gt;IsValid()
				//&amp;&amp; bounding_box.dimensions.x &gt;0 &amp;&amp; bounding_box.dimensions.y &gt;0 &amp;&amp; bounding_box.dimensions.z &gt; 0
				//&amp;&amp;	bounding_box.dimensions.x &lt; _max_boundingbox_side &amp;&amp; bounding_box.dimensions.y &lt; _max_boundingbox_side
				)
		{
			in_out_boundingbox_array.boxes.push_back(bounding_box);
			in_out_centroids.points.push_back(centroid);
			_visualization_marker.points.push_back(centroid);

			in_out_polygon_array.polygons.push_back(polygon);
			in_out_pictogram_array.pictograms.push_back(pictogram_cluster);

			autoware_msgs::CloudCluster cloud_cluster;
			final_clusters[i]-&gt;ToRosMessage(_velodyne_header, cloud_cluster);
			in_out_clusters.clusters.push_back(cloud_cluster);
		}
	}

	for(size_t i=0; i&lt; in_out_polygon_array.polygons.size();i++)
	{
		in_out_polygon_array.labels.push_back(i);
	}

}

void removeFloor(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_nofloor_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_onlyfloor_cloud_ptr, float in_max_height=0.2, float in_floor_max_angle=0.1)
{
	/*pcl::PointIndicesPtr ground (new pcl::PointIndices);
	// Create the filtering object
	pcl::ProgressiveMorphologicalFilter&lt;pcl::PointXYZ&gt; pmf;
	pmf.setInputCloud (in_cloud_ptr);
	pmf.setMaxWindowSize (20);
	pmf.setSlope (1.0f);
	pmf.setInitialDistance (0.5f);
	pmf.setMaxDistance (3.0f);
	pmf.extract (ground-&gt;indices);

	// Create the filtering object
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices (ground);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_nofloor_cloud_ptr);

	//EXTRACT THE FLOOR FROM THE CLOUD
	extract.setNegative(false);//true removes the indices, false leaves only the indices
	extract.filter(*out_onlyfloor_cloud_ptr);*/

	pcl::SACSegmentation&lt;pcl::PointXYZ&gt; seg;
	pcl::PointIndices::Ptr inliers (new pcl::PointIndices);
	pcl::ModelCoefficients::Ptr coefficients (new pcl::ModelCoefficients);

	seg.setOptimizeCoefficients (true);
	seg.setModelType(pcl::SACMODEL_PERPENDICULAR_PLANE);
	seg.setMethodType(pcl::SAC_RANSAC);
	seg.setMaxIterations(100);
	seg.setAxis(Eigen::Vector3f(0,0,1));
	seg.setEpsAngle(in_floor_max_angle);

	seg.setDistanceThreshold (in_max_height);//floor distance
	seg.setOptimizeCoefficients(true);
	seg.setInputCloud(in_cloud_ptr);
	seg.segment(*inliers, *coefficients);
	if (inliers-&gt;indices.size () == 0)
	{
		std::cout &lt;&lt; &quot;Could not estimate a planar model for the given dataset.&quot; &lt;&lt; std::endl;
	}

	//REMOVE THE FLOOR FROM THE CLOUD
	pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;
	extract.setInputCloud (in_cloud_ptr);
	extract.setIndices(inliers);
	extract.setNegative(true);//true removes the indices, false leaves only the indices
	extract.filter(*out_nofloor_cloud_ptr);

	//EXTRACT THE FLOOR FROM THE CLOUD
	extract.setNegative(false);//true removes the indices, false leaves only the indices
	extract.filter(*out_onlyfloor_cloud_ptr);
}

void downsampleCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_leaf_size=0.2)
{
	pcl::VoxelGrid&lt;pcl::PointXYZ&gt; sor;
	sor.setInputCloud(in_cloud_ptr);
	sor.setLeafSize((float)in_leaf_size, (float)in_leaf_size, (float)in_leaf_size);
	sor.filter(*out_cloud_ptr);
}

void clipCloud(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, float in_min_height=-1.3, float in_max_height=0.5)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		if (in_cloud_ptr-&gt;points[i].z &gt;= in_min_height &amp;&amp;
				in_cloud_ptr-&gt;points[i].z &lt;= in_max_height)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void differenceNormalsSegmentation(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr)
{
	float small_scale=0.5;
	float large_scale=2.0;
	float angle_threshold=0.5;
	pcl::search::Search&lt;pcl::PointXYZ&gt;::Ptr tree;
	if (in_cloud_ptr-&gt;isOrganized ())
	{
		tree.reset (new pcl::search::OrganizedNeighbor&lt;pcl::PointXYZ&gt; ());
	}
	else
	{
		tree.reset (new pcl::search::KdTree&lt;pcl::PointXYZ&gt; (false));
	}

	// Set the input pointcloud for the search tree
	tree-&gt;setInputCloud (in_cloud_ptr);

	pcl::NormalEstimationOMP&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	//pcl::gpu::NormalEstimation&lt;pcl::PointXYZ, pcl::PointNormal&gt; normal_estimation;
	normal_estimation.setInputCloud (in_cloud_ptr);
	normal_estimation.setSearchMethod (tree);

	normal_estimation.setViewPoint (std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max (), std::numeric_limits&lt;float&gt;::max ());

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_small_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr normals_large_scale (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	normal_estimation.setRadiusSearch (small_scale);
	normal_estimation.compute (*normals_small_scale);

	normal_estimation.setRadiusSearch (large_scale);
	normal_estimation.compute (*normals_large_scale);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud (new pcl::PointCloud&lt;pcl::PointNormal&gt;);
	pcl::copyPointCloud&lt;pcl::PointXYZ, pcl::PointNormal&gt;(*in_cloud_ptr, *diffnormals_cloud);

	// Create DoN operator
	pcl::DifferenceOfNormalsEstimation&lt;pcl::PointXYZ, pcl::PointNormal, pcl::PointNormal&gt; diffnormals_estimator;
	diffnormals_estimator.setInputCloud (in_cloud_ptr);
	diffnormals_estimator.setNormalScaleLarge (normals_large_scale);
	diffnormals_estimator.setNormalScaleSmall (normals_small_scale);

	diffnormals_estimator.initCompute();

	diffnormals_estimator.computeFeature(*diffnormals_cloud);

	pcl::ConditionOr&lt;pcl::PointNormal&gt;::Ptr range_cond (new pcl::ConditionOr&lt;pcl::PointNormal&gt;() );
	range_cond-&gt;addComparison (pcl::FieldComparison&lt;pcl::PointNormal&gt;::ConstPtr (
			new pcl::FieldComparison&lt;pcl::PointNormal&gt; (&quot;curvature&quot;, pcl::ComparisonOps::GT, angle_threshold) )
			);
	// Build the filter
	pcl::ConditionalRemoval&lt;pcl::PointNormal&gt; cond_removal;
	cond_removal.setCondition(range_cond);
	cond_removal.setInputCloud (diffnormals_cloud);

	pcl::PointCloud&lt;pcl::PointNormal&gt;::Ptr diffnormals_cloud_filtered (new pcl::PointCloud&lt;pcl::PointNormal&gt;);

	// Apply filter
	cond_removal.filter (*diffnormals_cloud_filtered);

	pcl::copyPointCloud&lt;pcl::PointNormal, pcl::PointXYZ&gt;(*diffnormals_cloud, *out_cloud_ptr);
}

void removePointsUpTo(const pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr in_cloud_ptr, pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr out_cloud_ptr, const double in_distance)
{
	out_cloud_ptr-&gt;points.clear();
	for (unsigned int i=0; i&lt;in_cloud_ptr-&gt;points.size(); i++)
	{
		float origin_distance = sqrt( pow(in_cloud_ptr-&gt;points[i].x,2) + pow(in_cloud_ptr-&gt;points[i].y,2) );
		if (origin_distance &gt; in_distance)
		{
			out_cloud_ptr-&gt;points.push_back(in_cloud_ptr-&gt;points[i]);
		}
	}
}

void velodyne_callback(const sensor_msgs::PointCloud2ConstPtr&amp; in_sensor_cloud)
{
	_start = std::chrono::system_clock::now(); // 計測開始時間

	if (!_using_sensor_cloud)
	{
		_using_sensor_cloud = true;

		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr current_sensor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr removed_points_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr downsampled_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr inlanes_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr nofloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr onlyfloor_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr diffnormals_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr clipped_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZ&gt;);
		pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr colored_clustered_cloud_ptr (new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;);

		autoware_msgs::centroids centroids;
		autoware_msgs::CloudClusterArray cloud_clusters;
		jsk_recognition_msgs::BoundingBoxArray boundingbox_array;
		jsk_recognition_msgs::PolygonArray polygon_array;
		jsk_rviz_plugins::PictogramArray pictograms_array;

		pcl::fromROSMsg(*in_sensor_cloud, *current_sensor_cloud_ptr);

		_velodyne_header = in_sensor_cloud-&gt;header;

		if (_remove_points_upto &gt; 0.0)
		{
			removePointsUpTo(current_sensor_cloud_ptr, removed_points_cloud_ptr, _remove_points_upto);
		}
		else
			removed_points_cloud_ptr = current_sensor_cloud_ptr;

		if (_downsample_cloud)
			downsampleCloud(removed_points_cloud_ptr, downsampled_cloud_ptr, _leaf_size);
		else
			downsampled_cloud_ptr =removed_points_cloud_ptr;

		clipCloud(downsampled_cloud_ptr, clipped_cloud_ptr, _clip_min_height, _clip_max_height);

		if(_keep_lanes)
			keepLanePoints(clipped_cloud_ptr, inlanes_cloud_ptr, _keep_lane_left_distance, _keep_lane_right_distance);
		else
			inlanes_cloud_ptr = clipped_cloud_ptr;

		if(_remove_ground)
		{
			removeFloor(inlanes_cloud_ptr, nofloor_cloud_ptr, onlyfloor_cloud_ptr);
			publishCloud(&amp;_pub_ground_cloud, onlyfloor_cloud_ptr);
		}
		else
			nofloor_cloud_ptr = inlanes_cloud_ptr;

		publishCloud(&amp;_pub_points_lanes_cloud, nofloor_cloud_ptr);

		if (_use_diffnormals)
			differenceNormalsSegmentation(nofloor_cloud_ptr, diffnormals_cloud_ptr);
		else
			diffnormals_cloud_ptr = nofloor_cloud_ptr;

		segmentByDistance(diffnormals_cloud_ptr, colored_clustered_cloud_ptr, boundingbox_array, centroids, cloud_clusters, polygon_array, pictograms_array);

		publishColorCloud(&amp;_pub_cluster_cloud, colored_clustered_cloud_ptr);

		// Publish BB
		boundingbox_array.header = _velodyne_header;

		_pub_jsk_hulls.publish(polygon_array);//publish convex hulls
		_pub_text_pictogram.publish(pictograms_array);//publish_ids

		publishBoundingBoxArray(&amp;_pub_jsk_boundingboxes, boundingbox_array, _output_frame, _velodyne_header);
		centroids.header = _velodyne_header;

		publishCentroids(&amp;_centroid_pub, centroids, _output_frame, _velodyne_header);

		_marker_pub.publish(_visualization_marker);
		_visualization_marker.points.clear();//transform? is it used?
		cloud_clusters.header = _velodyne_header;

		publishCloudClusters(&amp;_pub_clusters_message, cloud_clusters, _output_frame, _velodyne_header);

		_using_sensor_cloud = false;
	}
	_end = std::chrono::system_clock::now();  // 計測終了時間
  double elapsed = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(_end-_start).count(); //処理に要した時間をミリ秒に変換
  ROS_INFO(&quot;Euclidean Clustering : %f&quot;, elapsed);
}

/*
void vectormap_callback(const visualization_msgs::MarkerArray::Ptr in_vectormap_markers)
{
	float min_x=std::numeric_limits&lt;float&gt;::max();float max_x=-std::numeric_limits&lt;float&gt;::max();
	float min_y=std::numeric_limits&lt;float&gt;::max();float max_y=-std::numeric_limits&lt;float&gt;::max();
	pcl::PointXYZ min_point;
	pcl::PointXYZ max_point;
	std::vector&lt;geometry_msgs::Point&gt; vectormap_points;
	std::string marker_frame;
	double map_scale = -10.0;
	for(auto i=in_vectormap_markers-&gt;markers.begin(); i!= in_vectormap_markers-&gt;markers.end(); i++)
	{
		visualization_msgs::Marker current_marker = *i;
		marker_frame = current_marker.header.frame_id;
		if (current_marker.ns == &quot;road_edge&quot;)
		{
			for (unsigned int j=0; j&lt; current_marker.points.size(); j++)
			{
				geometry_msgs::Point p = current_marker.points[j];
				p.x*=map_scale;
				p.y*=map_scale;
				if(p.x&lt;min_x)	min_x = p.x;
				if(p.y&lt;min_y)	min_y = p.y;
				if(p.x&gt;max_x)	max_x = p.x;
				if(p.y&gt;max_y)	max_y = p.y;
				vectormap_points.push_back(p);
			}
		}
	}
	min_point.x = min_x;	min_point.y = min_y;
	max_point.x = max_x;	max_point.y = max_y;

	min_point.x*=-1.0;
	min_point.y*=-1.0;
	//translate the points to the minimum point
	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		(*i).x+=min_point.x;
		(*i).y+=min_point.y;
	}
	max_point.x+=min_point.x;
	max_point.y+=min_point.y;
	//get world tf
	std::string error_transform_msg;
	tf::Vector3 map_origin_point;
	if(_transform_listener-&gt;waitForTransform(&quot;/map&quot;, marker_frame, ros::Time(0), ros::Duration(5), ros::Duration(0.1), &amp;error_transform_msg))
	{
		_transform_listener-&gt;lookupTransform(&quot;/map&quot;, marker_frame, ros::Time(0), *_transform);
		map_origin_point = _transform-&gt;getOrigin();
		map_origin_point.setX( map_origin_point.x() - min_point.x);
		map_origin_point.setY( map_origin_point.y() - min_point.y);
	}
	else
	{
		ROS_INFO(&quot;Euclidean Cluster (vectormap_callback): %s&quot;, error_transform_msg.c_str());
	}

	cv::Mat map_image = cv::Mat::zeros(max_point.y, max_point.x, CV_8UC3);

	std::cout &lt;&lt; &quot;W,H:&quot; &lt;&lt; max_point &lt;&lt; std::endl;

	cv::Point image_start_point (vectormap_points[0].x, vectormap_points[0].y);
	cv::Point prev_point = image_start_point;
	for (auto i=vectormap_points.begin(); i!=vectormap_points.end(); i++)
	{
		cv::line(map_image, prev_point, cv::Point((int)(i-&gt;x), (int)(i-&gt;y)), cv::Scalar::all(255));

		prev_point.x = (int)(i-&gt;x);
		prev_point.y = (int)(i-&gt;y);
	}
	cv::circle(map_image, image_start_point, 3, cv::Scalar(255,0,0));
	cv::imshow(&quot;vectormap&quot;, map_image);
	cv::waitKey(0);
}*/

int main (int argc, char** argv)
{
	// Initialize ROS
	ros::init (argc, argv, &quot;euclidean_cluster&quot;);

	ros::NodeHandle h;
	ros::NodeHandle private_nh(&quot;~&quot;);

	tf::StampedTransform transform;
	tf::TransformListener listener;

	_transform = &amp;transform;
	_transform_listener = &amp;listener;

#if (CV_MAJOR_VERSION == 3)
	generateColors(_colors, 100);
#else
	cv::generateColors(_colors, 100);
#endif

	_pub_cluster_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_cluster&quot;,1);
	_pub_ground_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_ground&quot;,1);
	_centroid_pub = h.advertise&lt;autoware_msgs::centroids&gt;(&quot;/cluster_centroids&quot;,1);
	_marker_pub = h.advertise&lt;visualization_msgs::Marker&gt;(&quot;centroid_marker&quot;,1);

	_pub_points_lanes_cloud = h.advertise&lt;sensor_msgs::PointCloud2&gt;(&quot;/points_lanes&quot;,1);
	_pub_jsk_boundingboxes = h.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(&quot;/bounding_boxes&quot;,1);
	_pub_jsk_hulls = h.advertise&lt;jsk_recognition_msgs::PolygonArray&gt;(&quot;/cluster_hulls&quot;,1);
	_pub_clusters_message = h.advertise&lt;autoware_msgs::CloudClusterArray&gt;(&quot;/cloud_clusters&quot;,1);
	_pub_text_pictogram = h.advertise&lt;jsk_rviz_plugins::PictogramArray&gt;(&quot;cluster_ids&quot;, 10); ROS_INFO(&quot;output pictograms topic: %s&quot;, &quot;cluster_id&quot;);

	std::string points_topic;

	_using_sensor_cloud = false;

	if (private_nh.getParam(&quot;points_node&quot;, points_topic))
	{
		ROS_INFO(&quot;euclidean_cluster &gt; Setting points node to %s&quot;, points_topic.c_str());
	}
	else
	{
		ROS_INFO(&quot;euclidean_cluster &gt; No points node received, defaulting to points_raw, you can use _points_node:=YOUR_TOPIC&quot;);
		points_topic = &quot;/points_raw&quot;;
	}

	_use_diffnormals = false;
	if (private_nh.getParam(&quot;use_diffnormals&quot;, _use_diffnormals))
	{
		if (_use_diffnormals)
			ROS_INFO(&quot;Euclidean Clustering: Applying difference of normals on clustering pipeline&quot;);
		else
			ROS_INFO(&quot;Euclidean Clustering: Difference of Normals will not be used.&quot;);
	}

	/* Initialize tuning parameter */
	private_nh.param(&quot;downsample_cloud&quot;, _downsample_cloud, false);	ROS_INFO(&quot;downsample_cloud: %d&quot;, _downsample_cloud);
	private_nh.param(&quot;remove_ground&quot;, _remove_ground, true);		ROS_INFO(&quot;remove_ground: %d&quot;, _remove_ground);
	private_nh.param(&quot;leaf_size&quot;, _leaf_size, 0.1);					ROS_INFO(&quot;leaf_size: %f&quot;, _leaf_size);
	private_nh.param(&quot;cluster_size_min&quot;, _cluster_size_min, 20);	ROS_INFO(&quot;cluster_size_min %d&quot;, _cluster_size_min);
	private_nh.param(&quot;cluster_size_max&quot;, _cluster_size_max, 100000);ROS_INFO(&quot;cluster_size_max: %d&quot;, _cluster_size_max);
	private_nh.param(&quot;pose_estimation&quot;, _pose_estimation, false);	ROS_INFO(&quot;pose_estimation: %d&quot;, _pose_estimation);
	private_nh.param(&quot;clip_min_height&quot;, _clip_min_height, -1.3);	ROS_INFO(&quot;clip_min_height: %f&quot;, _clip_min_height);
	private_nh.param(&quot;clip_max_height&quot;, _clip_max_height, 0.5);		ROS_INFO(&quot;clip_max_height: %f&quot;, _clip_max_height);
	private_nh.param(&quot;keep_lanes&quot;, _keep_lanes, false);				ROS_INFO(&quot;keep_lanes: %d&quot;, _keep_lanes);
	private_nh.param(&quot;keep_lane_left_distance&quot;, _keep_lane_left_distance, 5.0);		ROS_INFO(&quot;keep_lane_left_distance: %f&quot;, _keep_lane_left_distance);
	private_nh.param(&quot;keep_lane_right_distance&quot;, _keep_lane_right_distance, 5.0);	ROS_INFO(&quot;keep_lane_right_distance: %f&quot;, _keep_lane_right_distance);
	private_nh.param(&quot;clustering_thresholds&quot;, _clustering_thresholds);
	private_nh.param(&quot;clustering_distances&quot;, _clustering_distances);
	private_nh.param(&quot;max_boundingbox_side&quot;, _max_boundingbox_side, 10.0);				ROS_INFO(&quot;max_boundingbox_side: %f&quot;, _max_boundingbox_side);
	private_nh.param(&quot;cluster_merge_threshold&quot;, _cluster_merge_threshold, 1.5);			ROS_INFO(&quot;cluster_merge_threshold: %f&quot;, _cluster_merge_threshold);
	private_nh.param&lt;std::string&gt;(&quot;output_frame&quot;, _output_frame, &quot;velodyne&quot;);			ROS_INFO(&quot;output_frame: %s&quot;, _output_frame.c_str());

	private_nh.param(&quot;use_vector_map&quot;, _use_vector_map, false);							ROS_INFO(&quot;use_vector_map: %d&quot;, _use_vector_map);
	private_nh.param&lt;std::string&gt;(&quot;vectormap_frame&quot;, _vectormap_frame, &quot;map&quot;);			ROS_INFO(&quot;vectormap_frame: %s&quot;, _output_frame.c_str());

	private_nh.param(&quot;remove_points_upto&quot;, _remove_points_upto, 0.0);		ROS_INFO(&quot;remove_points_upto: %f&quot;, _remove_points_upto);

	private_nh.param(&quot;use_gpu&quot;, _use_gpu, false);				ROS_INFO(&quot;use_gpu: %d&quot;, _use_gpu);

	_velodyne_transform_available = false;

	if (_clustering_distances.size()!=4)
	{
		_clustering_distances = {15, 30, 45, 60};//maximum distance from sensor origin to separate segments
	}
	if (_clustering_thresholds.size()!=5)
	{
		_clustering_thresholds = {0.5, 1.1, 1.6, 2.1, 2.6};//Nearest neighbor distance threshold for each segment
	}

	std::cout &lt;&lt; &quot;_clustering_thresholds: &quot;; for (auto i = _clustering_thresholds.begin(); i != _clustering_thresholds.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt; std::endl;
	std::cout &lt;&lt; &quot;_clustering_distances: &quot;;for (auto i = _clustering_distances.begin(); i != _clustering_distances.end(); ++i)  std::cout &lt;&lt; *i &lt;&lt; ' '; std::cout &lt;&lt;std::endl;

	// Create a ROS subscriber for the input point cloud
	ros::Subscriber sub = h.subscribe (points_topic, 1, velodyne_callback);
	//ros::Subscriber sub_vectormap = h.subscribe (&quot;vector_map&quot;, 1, vectormap_callback);
	_vectormap_server = h.serviceClient&lt;vector_map_server::PositionState&gt;(&quot;vector_map_server/is_way_area&quot;);

	_visualization_marker.header.frame_id = &quot;velodyne&quot;;
	_visualization_marker.header.stamp = ros::Time();
	_visualization_marker.ns = &quot;my_namespace&quot;;
	_visualization_marker.id = 0;
	_visualization_marker.type = visualization_msgs::Marker::SPHERE_LIST;
	_visualization_marker.action = visualization_msgs::Marker::ADD;
	_visualization_marker.scale.x = 1.0;
	_visualization_marker.scale.y = 1.0;
	_visualization_marker.scale.z = 1.0;
	_visualization_marker.color.a = 1.0;
	_visualization_marker.color.r = 0.0;
	_visualization_marker.color.g = 0.0;
	_visualization_marker.color.b = 1.0;
	// marker.lifetime = ros::Duration(0.1);
	_visualization_marker.frame_locked = true;

	// Spin
	ros::spin ();
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="3425662de7b23ac9955e5569f0f9ef61222d072c" fix_time="422,53938">
		<msg>TierFusion Driver Updated (#742)

Added Support for new firmware version.
Features:
-IP Address changed to the same as Velodyne's
-Automatic Device Initialization &quot;PlugAndPlay&quot;

Host IP Address MUST be set 192.168.1.1
TierFusion address is fixed to 192.168.1.200
Velodyne address is considered as default value, 192.168.1.201

Tested in 14.04 and 16.04</msg>
		<modified_files>
			<file old_path="ros/src/sensing/drivers/camera/packages/vectacam/nodes/vectacam/VectaCam.cpp" new_path="ros/src/sensing/drivers/camera/packages/vectacam/nodes/vectacam/VectaCam.cpp">
				<diff>@@ -1,6 +1,6 @@
 #include &quot;VectaCam.h&quot;
 
-VectaCam::VectaCam(unsigned int in_configuration_port, unsigned int in_data_port, std::string in_parameter_file)
+VectaCam::VectaCam(std::string in_camera_ip, unsigned int in_configuration_port, unsigned int in_data_port, std::string in_parameter_file)
 {
 	this-&gt;data_port_ 			= in_data_port;
 	this-&gt;configuration_port_ 	= in_configuration_port;
@@ -14,6 +14,7 @@ VectaCam::VectaCam(unsigned int in_configuration_port, unsigned int in_data_port
 	this-&gt;image_height_ 		= VECTACAM_IMG_HEIGHT;
 	this-&gt;image_buffer_ 		= new char[image_width_ * 3 * image_height_];
 	this-&gt;parameter_file_ 		= in_parameter_file;
+	this-&gt;camera_ip_			= in_camera_ip;
 	_initialize_camera(configuration_port_, data_port_, parameter_file_);
 }
 
@@ -61,7 +62,7 @@ void VectaCam::_send_commands_to_camera(unsigned int in_port, std::vector&lt;VectaC
 	memset((char *) &amp;socket_address, 0, sizeof(socket_address));
 	socket_address.sin_family = AF_INET;
 	socket_address.sin_port = htons(in_port);
-	if (inet_aton(&quot;10.0.0.1&quot;, &amp;socket_address.sin_addr)==0)
+	if (inet_aton(camera_ip_.c_str(), &amp;socket_address.sin_addr)==0)
 	{
 		std::cout &lt;&lt; &quot;Invalid IP address&quot; &lt;&lt; std::endl;
 		return;
@@ -121,7 +122,7 @@ void VectaCam::_enable_camera(unsigned int in_port, bool in_enable)
 	memset((char *) &amp;socket_address, 0, sizeof(socket_address));
 	socket_address.sin_family = AF_INET;
 	socket_address.sin_port = htons(in_port);
-	if (inet_aton(VECTACAM_CAMERA_IP, &amp;socket_address.sin_addr)==0)
+	if (inet_aton(camera_ip_.c_str(), &amp;socket_address.sin_addr)==0)
 	{
 		std::cout &lt;&lt; &quot;Invalid IP address&quot; &lt;&lt; std::endl;
 		return;
@@ -167,7 +168,6 @@ long int VectaCam::GetFrameNumber()
 
 void VectaCam::StartCamera()
 {
-
 	int 		socket_descriptor;
 	struct 		sockaddr_in socket_address;
 	socklen_t length;
@@ -177,6 +177,7 @@ void VectaCam::StartCamera()
 		std::cout &lt;&lt; &quot;Problem creating socket\n&quot;;
 		return;
 	}
+	std::cout &lt;&lt; &quot;Socket Created\n&quot;;
 
 	socket_address.sin_family = AF_INET;
 	socket_address.sin_addr.s_addr = htonl(INADDR_ANY);
@@ -187,6 +188,7 @@ void VectaCam::StartCamera()
 		std::cout &lt;&lt; &quot;Problem binding&quot; &lt;&lt; std::endl;
 		return;
 	}
+	std::cout &lt;&lt; &quot;Binded...&quot; &lt;&lt; std::endl;
 
 	length = sizeof(socket_address);
 	if (getsockname(socket_descriptor, reinterpret_cast&lt;sockaddr *&gt; (&amp;socket_address), &amp;length) &lt; 0)
@@ -241,6 +243,7 @@ void VectaCam::_udp_receive(int in_socket_descriptor)
 		}
 		else
 		{
+			//std::cout &lt;&lt; &quot;Received data &quot; &lt;&lt; n &lt;&lt; std::endl;
 			uint32_t packet_offset = ntohl(*(uint32_t*)(buffer_in + 4));
 			uint32_t packet_length = ntohl(*(uint32_t*)(buffer_in + 8));
 			uint32_t header = ntohl(*(uint32_t*)(buffer_in + 12));
@@ -256,7 +259,6 @@ void VectaCam::_udp_receive(int in_socket_descriptor)
 			}
 			else
 			{
-
 				line_number = header - 1;
 				_form_image(line_number, buffer_in, packet_offset, packet_length);
 			}
</diff>
				<old_file>#include &quot;VectaCam.h&quot;

VectaCam::VectaCam(unsigned int in_configuration_port, unsigned int in_data_port, std::string in_parameter_file)
{
	this-&gt;data_port_ 			= in_data_port;
	this-&gt;configuration_port_ 	= in_configuration_port;
	this-&gt;camera_ready_ 		= false;
	this-&gt;running_ 				= false;
	this-&gt;fps_ 					= 0.0;
	this-&gt;frame_number_			= 0;
	this-&gt;frame_counter_		= 0;
	this-&gt;payload_offset_ 		= 16;
	this-&gt;image_width_ 			= VECTACAM_IMG_WIDTH * VECTACAM_NUM_CAMERAS;
	this-&gt;image_height_ 		= VECTACAM_IMG_HEIGHT;
	this-&gt;image_buffer_ 		= new char[image_width_ * 3 * image_height_];
	this-&gt;parameter_file_ 		= in_parameter_file;
	_initialize_camera(configuration_port_, data_port_, parameter_file_);
}

void VectaCam::_parse_parameter_file(std::string in_parameter_file, std::vector&lt;VectaCamCommand&gt;&amp; out_commands)
{
	std::string line;
	std::ifstream config_file (parameter_file_);
	std::string delimiter = &quot;:&quot;;
	out_commands.clear();
	if (!config_file.is_open())
	{
		std::cout &lt;&lt; &quot;Unable to open file:&quot; &lt;&lt; parameter_file_;
		return;
	}

	while ( getline (config_file,line) )
	{
		std::vector&lt;std::string&gt; tokens;
		boost::split(tokens, line, boost::is_any_of(&quot;:&quot;));
		if (tokens.size()==2)
		{
			VectaCamCommand current_command;
			int full_address = std::stoi(tokens[0], NULL, 16);
			current_command.low_nibble_address = (unsigned char)( (full_address&gt;&gt;0) &amp; 0xFF);
			current_command.high_nibble_address = (unsigned char)((full_address&gt;&gt;8) &amp; 0xFF);
			current_command.command_data = std::stoi(tokens[1], NULL, 16);
			out_commands.push_back(current_command);
		}
		else
			std::cout &lt;&lt; &quot;Unrecognized command in configuration file: &quot; &lt;&lt; parameter_file_ &lt;&lt; std::endl;
	}
	config_file.close();
}

void VectaCam::_send_commands_to_camera(unsigned int in_port, std::vector&lt;VectaCamCommand&gt; in_commands)
{

	int socket_descriptor;
	struct sockaddr_in socket_address;
	if ((socket_descriptor=socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP)) &lt; 0)
	{
		std::cout &lt;&lt; &quot;Problem creating socket\n&quot;;
		return;
	}
	memset((char *) &amp;socket_address, 0, sizeof(socket_address));
	socket_address.sin_family = AF_INET;
	socket_address.sin_port = htons(in_port);
	if (inet_aton(&quot;10.0.0.1&quot;, &amp;socket_address.sin_addr)==0)
	{
		std::cout &lt;&lt; &quot;Invalid IP address&quot; &lt;&lt; std::endl;
		return;
	}
	for (unsigned int i=0; i&lt; in_commands.size(); i++)
	{
		VectaCamCommand current_command = in_commands[i];
		unsigned char command_buffer[12] = {0x05, 0x00, 0x36, 0x00, 0x00, 0x00,
									current_command.low_nibble_address, current_command.high_nibble_address, current_command.command_data,
									0x00, 0x00, 0x00};
		ssize_t sent_data = sendto(socket_descriptor, command_buffer, sizeof(command_buffer), 0,(struct sockaddr *) &amp;socket_address, sizeof(socket_address));
		if (sent_data &lt; 0)
		{
			std::cout &lt;&lt; &quot;Could not send the data to the camera socket&quot; &lt;&lt; std::endl;
		}
		else
			std::cout &lt;&lt; (int)current_command.high_nibble_address &lt;&lt;
						(int)current_command.low_nibble_address &lt;&lt; &quot;:&quot; &lt;&lt;
						(int)current_command.command_data &lt;&lt; std::endl;
		usleep(50000);
	}
}

void VectaCam::_enable_camera(unsigned int in_port, bool in_enable)
{
	unsigned char camonoff = in_enable ? 0xff : 0x00;
	unsigned char enable_command[] =	{0x00, 0x00, // upldest = 0
				 0x00, // inspect target
				 0x02, // command(write)
				 0x00, 0x00, 0x00, 0x00, // data_output
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00,
				 0x00, 0x00, 0x00, (camonoff),
				 0x00, 0x00, 0x00, 0x00, // module_reset
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00, //
				 0x00, 0x00, 0x00, 0x00 };
	int socket_descriptor;
	struct sockaddr_in socket_address;
	if ((socket_descriptor=socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP)) &lt; 0)
	{
		std::cout &lt;&lt; &quot;Problem creating socket\n&quot;;
		return;
	}
	memset((char *) &amp;socket_address, 0, sizeof(socket_address));
	socket_address.sin_family = AF_INET;
	socket_address.sin_port = htons(in_port);
	if (inet_aton(VECTACAM_CAMERA_IP, &amp;socket_address.sin_addr)==0)
	{
		std::cout &lt;&lt; &quot;Invalid IP address&quot; &lt;&lt; std::endl;
		return;
	}
	if (sendto(socket_descriptor, enable_command, sizeof(enable_command), 0, reinterpret_cast&lt;sockaddr *&gt;(&amp;socket_address), sizeof(socket_address)) &lt; 0)
	{
		std::cout &lt;&lt; &quot;Could not send the enable command to the camera socket&quot; &lt;&lt; std::endl;
	}
}

void VectaCam::_initialize_camera(unsigned int in_configuration_port, unsigned int in_data_port, std::string in_parameter_file)
{
	std::cout &lt;&lt; &quot;Reading configuration file...&quot;;
	_parse_parameter_file(parameter_file_, camera_commands_);
	std::cout &lt;&lt; &quot;DONE&quot; &lt;&lt; std::endl &lt;&lt; &quot;Configuring camera.&quot;;
	_send_commands_to_camera(in_configuration_port, camera_commands_);
	std::cout &lt;&lt; &quot;DONE&quot; &lt;&lt; std::endl &lt;&lt; &quot;Enabling camera.&quot;;
	_enable_camera(in_data_port, true);
	std::cout &lt;&lt; &quot;DONE&quot; &lt;&lt; std::endl;
}

VectaCam::~VectaCam()
{
	this-&gt;running_=false;
	delete[] this-&gt;image_buffer_;
}

void VectaCam::GetImage(cv::Mat&amp; out_image)
{
	out_image = camera_image_.clone();
}

void VectaCam::StopCamera()
{
	this-&gt;running_ = false;
	_enable_camera(data_port_, false);
}

long int VectaCam::GetFrameNumber()
{
	return this-&gt;frame_number_;
}

void VectaCam::StartCamera()
{

	int 		socket_descriptor;
	struct 		sockaddr_in socket_address;
	socklen_t length;

	if ((socket_descriptor = socket( PF_INET, SOCK_DGRAM, 0)) &lt; 0)
	{
		std::cout &lt;&lt; &quot;Problem creating socket\n&quot;;
		return;
	}

	socket_address.sin_family = AF_INET;
	socket_address.sin_addr.s_addr = htonl(INADDR_ANY);
	socket_address.sin_port = htons(this-&gt;data_port_);

	if (bind(socket_descriptor, reinterpret_cast&lt;sockaddr *&gt; (&amp;socket_address), sizeof(socket_address)) &lt; 0)
	{
		std::cout &lt;&lt; &quot;Problem binding&quot; &lt;&lt; std::endl;
		return;
	}

	length = sizeof(socket_address);
	if (getsockname(socket_descriptor, reinterpret_cast&lt;sockaddr *&gt; (&amp;socket_address), &amp;length) &lt; 0)
	{
		std::cout &lt;&lt; &quot;Error getsockname&quot; &lt;&lt; std::endl;
		return;
	}
	this-&gt;camera_ready_ = true;
	this-&gt;running_ = true;

	std::cout &lt;&lt; &quot;Listening camera in UDP port number &quot; &lt;&lt; ntohs(socket_address.sin_port) &lt;&lt; std::endl;

	_udp_receive(socket_descriptor);
}

void VectaCam::_form_image(int in_line_number, char* in_buffer, uint32_t in_packet_offset, uint32_t in_packet_length)
{
	int p = in_packet_offset * 3;
	int k = payload_offset_ + 4 * in_packet_length;
	int total = (in_packet_length);
	if (in_line_number &lt; image_height_ &amp;&amp; total &lt; 1500 &amp;&amp; p &lt; image_width_ * 3
			&amp;&amp; total &gt; 10)
	{
		for (int i = 0; i &lt; total; ++i)
		{
			image_buffer_[in_line_number * image_width_ * 3 + p + 2] = (((((int) in_buffer[k + 0]) &lt;&lt; 4) &amp; 0x3f0) + ((((int) in_buffer[k + 1]) &gt;&gt; 4) &amp; 0xf)) &gt;&gt; 2; // R
			image_buffer_[in_line_number * image_width_ * 3 + p + 1] = (((((int) in_buffer[k + 1]) &lt;&lt; 6) &amp; 0x3c0) + ((((int) in_buffer[k + 2]) &gt;&gt; 2) &amp; 0x3f)) &gt;&gt;2; // G
			image_buffer_[in_line_number * image_width_ * 3 + p + 0] = (((((int) in_buffer[k + 2]) &lt;&lt; 8) &amp; 0x300)	+ ((((int) in_buffer[k + 3]) &gt;&gt; 0) &amp; 0xff)) &gt;&gt; 2; // B

			p += 3;
			k -= 4;
		}
	}
}

void VectaCam::_udp_receive(int in_socket_descriptor)
{
	int 			n;
	size_t			length;
	char 			buffer_in[VECTACAM_MAX_BUFFER];
	struct 			sockaddr_in remote;
	length = sizeof(remote);

	int line_number = 0;

	while (this-&gt;running_)
	{
		n = recvfrom(in_socket_descriptor, buffer_in, VECTACAM_MAX_BUFFER, 0, reinterpret_cast&lt;sockaddr *&gt; (&amp;remote), (unsigned int*) &amp;length);
		if (n &lt; 0)
		{
			std::cout &lt;&lt; &quot;Error receiving data&quot; &lt;&lt; std::endl;
		}
		else
		{
			uint32_t packet_offset = ntohl(*(uint32_t*)(buffer_in + 4));
			uint32_t packet_length = ntohl(*(uint32_t*)(buffer_in + 8));
			uint32_t header = ntohl(*(uint32_t*)(buffer_in + 12));

			if (header == VECTACAM_FRAME_START) {
				// frame start
			}
			else if (header == VECTACAM_FRAME_END)
			{
				// frame end
				this-&gt;camera_image_ = cv::Mat(image_height_, image_width_, CV_8UC3, image_buffer_);
				frame_number_++;
			}
			else
			{

				line_number = header - 1;
				_form_image(line_number, buffer_in, packet_offset, packet_length);
			}
		}
	}
}

</old_file>
			</file>
			<file old_path="ros/src/sensing/drivers/camera/packages/vectacam/nodes/vectacam/VectaCam.h" new_path="ros/src/sensing/drivers/camera/packages/vectacam/nodes/vectacam/VectaCam.h">
				<diff>@@ -40,7 +40,7 @@ struct VectaCamCommand
 class VectaCam
 {
 public:
-	VectaCam(unsigned int in_configuration_port, unsigned int in_data_port, std::string in_parameter_file);
+	VectaCam(std::string in_camera_ip, unsigned int in_configuration_port, unsigned int in_data_port, std::string in_parameter_file);
 	void 			GetImage(cv::Mat&amp; out_image);
 	virtual 		~VectaCam();
 	void 			StartCamera();
@@ -61,6 +61,7 @@ private:
 	int				image_width_;
 	int				image_height_;
 	char			*image_buffer_;
+	std::string		camera_ip_;
 	void 			_udp_receive(int in_socket_descriptor);
 	void			_initialize_camera(unsigned int in_configuration_port, unsigned int in_data_port, std::string in_parameter_file);
 	void			_parse_parameter_file(std::string in_parameter_file, std::vector&lt;VectaCamCommand&gt;&amp; out_commands);
</diff>
				<old_file>#ifndef VECTACAM_H_
#define VECTACAM_H_

#include &lt;unistd.h&gt;     /* defines STDIN_FILENO, system calls,etc */
#include &lt;sys/types.h&gt;  /* system data type definitions */
#include &lt;sys/socket.h&gt; /* socket specific definitions */
#include &lt;netinet/in.h&gt; /* INET constants and stuff */
#include &lt;arpa/inet.h&gt;  /* IP address conversion stuff */
#include &lt;netdb.h&gt;      /* gethostbyname */

#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;boost/algorithm/string.hpp&gt;

#include &quot;opencv2/core/core.hpp&quot;

#define VECTACAM_CONFIG_PORT 		16385
#define VECTACAM_DATA_PORT 			16386
#define VECTACAM_NUM_CAMERAS		8

#define VECTACAM_FRAME_START 		(0x01000000)
#define VECTACAM_FRAME_END   		(0x02000000)

#define VECTACAM_DATA_OFFSET 		(16)

#define VECTACAM_MAX_BUFFER 			1024*1024

#define VECTACAM_IMG_WIDTH			640
#define VECTACAM_IMG_HEIGHT			480

#define VECTACAM_CAMERA_IP			&quot;10.0.0.1&quot;

struct VectaCamCommand
{
	unsigned char low_nibble_address;
	unsigned char high_nibble_address;
	unsigned char command_data;
};

class VectaCam
{
public:
	VectaCam(unsigned int in_configuration_port, unsigned int in_data_port, std::string in_parameter_file);
	void 			GetImage(cv::Mat&amp; out_image);
	virtual 		~VectaCam();
	void 			StartCamera();
	void 			StopCamera();
	long int		GetFrameNumber();
	std::string 	GetFps();

private:
	int 			data_port_;
	int 			configuration_port_;
	bool 			running_;
	cv::Mat			camera_image_;
	bool			camera_ready_;
	long 	 		frame_counter_;
	long 	 		frame_number_;
	double 			fps_;
	int 			payload_offset_;
	int				image_width_;
	int				image_height_;
	char			*image_buffer_;
	void 			_udp_receive(int in_socket_descriptor);
	void			_initialize_camera(unsigned int in_configuration_port, unsigned int in_data_port, std::string in_parameter_file);
	void			_parse_parameter_file(std::string in_parameter_file, std::vector&lt;VectaCamCommand&gt;&amp; out_commands);
	void			_send_commands_to_camera(unsigned int in_port, std::vector&lt;VectaCamCommand&gt; in_commands);
	void 			_enable_camera(unsigned int in_port, bool in_enable);
	void 			_form_image(int in_line_number, char* in_buffer, uint32_t in_packet_offset, uint32_t in_packet_length);
	std::string		parameter_file_;
	std::vector&lt;VectaCamCommand&gt; camera_commands_;
};

#endif /* VECTACAM_H_ */
</old_file>
			</file>
			<file old_path="ros/src/sensing/drivers/camera/packages/vectacam/nodes/vectacam/vectacam_node.cpp" new_path="ros/src/sensing/drivers/camera/packages/vectacam/nodes/vectacam/vectacam_node.cpp">
				<diff>@@ -76,7 +76,7 @@ public:
 			publishers_cameras_[i] = node_handle_.advertise&lt;sensor_msgs::Image&gt;(current_topic, 1);
 		}
 
-		VectaCam vectacamera(VECTACAM_CONFIG_PORT, VECTACAM_DATA_PORT, config_file_path);
+		VectaCam vectacamera(camera_ip, VECTACAM_CONFIG_PORT, VECTACAM_DATA_PORT, config_file_path);
 		std::thread *capture_thread= new std::thread(&amp;VectaCam::StartCamera, &amp;vectacamera);
 
 		cv::Mat image;
</diff>
				<old_file>/*
 *  Copyright (c) 2016, Nagoya University
 *  All rights reserved.
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *  * Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 *  * Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 *  * Neither the name of Autoware nor the names of its
 *    contributors may be used to endorse or promote products derived from
 *    this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 *  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
 *  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 *  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 *  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 *  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 *  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
#include &lt;ros/ros.h&gt;
#include &quot;ros/package.h&quot;
#include &lt;image_transport/image_transport.h&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;sensor_msgs/Image.h&gt;
#include &lt;thread&gt;
#include &lt;signal.h&gt;
#include&lt;unistd.h&gt;

#include &quot;VectaCam.h&quot;

class RosVectaCam
{
public:
	void Run()
	{
		std::string config_file_path;
		std::string camera_ip;

		ros::NodeHandle private_node_handle(&quot;~&quot;);

		if (private_node_handle.getParam(&quot;configfile&quot;, config_file_path))
		{
			ROS_INFO(&quot;Setting config file path to %s&quot;, config_file_path.c_str());
		}
		else
		{
			ROS_INFO(&quot;No config file received. Terminating...&quot;);
			config_file_path = ros::package::getPath(ros::this_node::getName())+&quot;/initialization_params.txt&quot;;
			//return;
		}
		if (private_node_handle.getParam(&quot;camera_ip&quot;, camera_ip))
		{
			ROS_INFO(&quot;Setting camera IP to %s&quot;, camera_ip.c_str());
		}
		else
		{
			ROS_INFO(&quot;No IP, defaulting to %s, you can use _img_obj_node:=YOUR_TOPIC&quot;, VECTACAM_CAMERA_IP);
			camera_ip = VECTACAM_CAMERA_IP;
		}

		for (unsigned int i=0; i&lt; VECTACAM_NUM_CAMERAS; i++)
		{
			std::string current_topic = &quot;camera&quot; + std::to_string(i) + &quot;/image_raw&quot;;
			publishers_cameras_[i] = node_handle_.advertise&lt;sensor_msgs::Image&gt;(current_topic, 1);
		}

		VectaCam vectacamera(VECTACAM_CONFIG_PORT, VECTACAM_DATA_PORT, config_file_path);
		std::thread *capture_thread= new std::thread(&amp;VectaCam::StartCamera, &amp;vectacamera);

		cv::Mat image;
		std::vector&lt;cv::Mat&gt; camera_images(VECTACAM_NUM_CAMERAS);
		unsigned long int counter = 0;
		ros::Rate loop_rate(7); // Hz
		ros::Publisher full_publisher = node_handle_.advertise&lt;sensor_msgs::Image&gt;(&quot;image_raw&quot;, 1);
		while(ros::ok())
		{
			vectacamera.GetImage(image);
			if(!image.empty())
			{
				cv::flip(image, image, 0);
				_publish_image(image, full_publisher, counter);
				for (unsigned int i=0; i&lt; VECTACAM_NUM_CAMERAS; i++)
				{
					camera_images[i]= image(cv::Rect(i*image.cols/VECTACAM_NUM_CAMERAS, 0, image.cols/VECTACAM_NUM_CAMERAS,image.rows));
					//if(!camera_images[i].empty())
						_publish_image(camera_images[i], publishers_cameras_[i], counter);
					//else
						//std::cout &lt;&lt; &quot;Empty frame from image: &quot; &lt;&lt; i &lt;&lt; &quot; at frame &quot; &lt;&lt; counter &lt;&lt; std::endl;
				}
				//_publish_image(image, publishers_cameras_[NUM_CAMERAS], counter);

				counter++;
				if (counter&lt;=2)
					std::cout &lt;&lt; &quot;Image received&quot; &lt;&lt; std::endl;
			}
			else
			{
				std::cout &lt;&lt; &quot;No image received&quot; &lt;&lt; std::endl;
			}
			loop_rate.sleep();
		}
		vectacamera.StopCamera();
		capture_thread-&gt;join();
		delete capture_thread;
	}
private:
	ros::Publisher 		publishers_cameras_[VECTACAM_NUM_CAMERAS];
	ros::NodeHandle 	node_handle_;

	void _publish_image(cv::Mat &amp;in_image, ros::Publisher &amp;in_publisher, unsigned long int in_counter)
	{
		sensor_msgs::ImagePtr msg;
		std_msgs::Header header;
		msg = cv_bridge::CvImage(std_msgs::Header(), &quot;bgr8&quot;, in_image).toImageMsg();
		msg-&gt;header.frame_id = &quot;camera&quot;;
		msg-&gt;header.stamp.sec = ros::Time::now().sec;
		msg-&gt;header.stamp.nsec = ros::Time::now().nsec;
		msg-&gt;header.seq = in_counter;

		in_publisher.publish(msg);
	}
};

int main(int argc, char* argv[])
{
	ros::init(argc, argv, &quot;vectacam&quot;);

	RosVectaCam app;

	app.Run();

	return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="046b973dae7e21b1cfa73f772fade9557e5b1157" fix_time="0,71784">
		<msg>Fixed a bug that caused missing points</msg>
		<modified_files>
			<file old_path="ros/src/sensing/filters/packages/points_preprocessor/nodes/ground_filter/ground_filter.cpp" new_path="ros/src/sensing/filters/packages/points_preprocessor/nodes/ground_filter/ground_filter.cpp">
				<diff>@@ -162,7 +162,8 @@ void GroundFilter::FilterGround(const pcl::PointCloud&lt;velodyne_pointcloud::Point
 
 	velodyne_pointcloud::PointXYZIR point;
 
-	horizontal_res_ = int(in_cloud_msg-&gt;points.size() / vertical_res_);
+	//This line is not necessary
+	//horizontal_res_ = int(in_cloud_msg-&gt;points.size() / vertical_res_);
 	InitDepthMap(horizontal_res_);
 
 	for (size_t i = 0; i &lt; in_cloud_msg-&gt;points.size(); i++)
@@ -259,6 +260,11 @@ void GroundFilter::FilterGround(const pcl::PointCloud&lt;velodyne_pointcloud::Point
 						}
 						point_index_size = 0;
 					}
+					//These line were missing
+					r_ref = r0;
+					z_ref = z0;
+					point_index[point_index_size] = j;
+					point_index_size++;
 				}
 			}
 			if (j == 0)
@@ -332,6 +338,20 @@ void GroundFilter::FilterGround(const pcl::PointCloud&lt;velodyne_pointcloud::Point
 						}
 					}
 					else
+					{
+						if(cluster_index_size &gt; 1)
+						{
+							PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_groundless_points);
+						}
+						else
+						{
+							PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_ground_points);
+						}
+						cluster_index[cluster_index_size] = unknown_index[m];
+						cluster_index_size++;
+						centroid = r0;
+					}
+					if (m == 0)
 					{
 						if(cluster_index_size &gt; 1)
 						{
</diff>
				<old_file>/*
 * ground_filter.cpp
 *
 * Created on	: May 19, 2017
 * Author	: Patiphon Narksri					
 */
#include &lt;ros/ros.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;pcl_ros/point_cloud.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;velodyne_pointcloud/point_types.h&gt;
#include &lt;opencv/cv.h&gt;

enum Label
{
	GROUND,
	VERTICAL,
	UNKNOWN //Initial state, not classified
};

class GroundFilter
{
public:
	
	GroundFilter();

private:

	ros::NodeHandle node_handle_;
	ros::Subscriber points_node_sub_;
	ros::Publisher groundless_points_pub_;
	ros::Publisher ground_points_pub_;

	std::string point_topic_;
	int 		sensor_model_;
	double 		sensor_height_;
	double 		max_slope_;
	int 		min_point_;
	double 		clipping_thres_;
	double 		gap_thres_;
	double		point_distance_;
	bool		floor_removal_;

	int 		vertical_res_;
	int 		horizontal_res_;
	double 		limiting_ratio_;
	cv::Mat 	index_map_;
	Label 		class_label_[64];

	boost::chrono::high_resolution_clock::time_point t1_;
	boost::chrono::high_resolution_clock::time_point t2_;
	boost::chrono::nanoseconds elap_time_;

	const int 	DEFAULT_HOR_RES = 2000;

	void InitLabelArray(int in_model);
	void InitDepthMap(int in_width);
	void PublishPointCloud(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg,
				int in_indices[], int &amp;in_out_index_size, 
				pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;in_cloud);


	void VelodyneCallback(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg);
	void FilterGround(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg,
				pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_groundless_points,
				pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_ground_points);

};

GroundFilter::GroundFilter() : node_handle_(&quot;~&quot;)
{
	ROS_INFO(&quot;Inititalizing Ground Filter...&quot;);
	node_handle_.param&lt;std::string&gt;(&quot;point_topic&quot;, point_topic_, &quot;/points_raw&quot;);
	ROS_INFO(&quot;Input Point Cloud: %s&quot;, point_topic_.c_str());
 	node_handle_.param(&quot;remove_floor&quot;,  floor_removal_,  true);
 	ROS_INFO(&quot;Floor Removal: %d&quot;, floor_removal_);
	node_handle_.param(&quot;sensor_model&quot;, sensor_model_, 64);
	ROS_INFO(&quot;Sensor Model: %d&quot;, sensor_model_);
	node_handle_.param(&quot;sensor_height&quot;, sensor_height_, 1.72);
	ROS_INFO(&quot;Sensor Height: %f&quot;, sensor_height_);
	node_handle_.param(&quot;max_slope&quot;, max_slope_, 20.0);
	ROS_INFO(&quot;Max Slope: %f&quot;, max_slope_);
	node_handle_.param(&quot;point_distance&quot;, point_distance_, 0.05);
	ROS_INFO(&quot;Point Distance: %f&quot;, point_distance_);
	node_handle_.param(&quot;min_point&quot;, min_point_, 3);
	ROS_INFO(&quot;Min Points: %d&quot;, min_point_);
	node_handle_.param(&quot;clipping_thres&quot;, clipping_thres_, 0.5);
	ROS_INFO(&quot;Lower Clipping Threshold: %f&quot;, clipping_thres_);
	node_handle_.param(&quot;gap_thres&quot;, gap_thres_, 0.5);
	ROS_INFO(&quot;Point Gap Threshold: %f&quot;, gap_thres_);

	std::string no_ground_topic, ground_topic;
	node_handle_.param&lt;std::string&gt;(&quot;no_ground_point_topic&quot;, no_ground_topic, &quot;/points_no_ground&quot;);
	ROS_INFO(&quot;No Ground Output Point Cloud: %s&quot;, no_ground_topic.c_str());
	node_handle_.param&lt;std::string&gt;(&quot;ground_point_topic&quot;, ground_topic, &quot;/points_ground&quot;);
	ROS_INFO(&quot;Only Ground Output Point Cloud: %s&quot;, ground_topic.c_str());

	int default_horizontal_res;
	switch(sensor_model_)
	{
		case 64:
			default_horizontal_res = 2083;
			break;
		case 32:
			default_horizontal_res = 2250;
			break;
		case 16:
			default_horizontal_res = 1800;
			break;
		default:
			default_horizontal_res = DEFAULT_HOR_RES;
			break;
	}
	node_handle_.param(&quot;horizontal_res&quot;, horizontal_res_, default_horizontal_res);

	points_node_sub_ = node_handle_.subscribe(point_topic_, 2, &amp;GroundFilter::VelodyneCallback, this);
	groundless_points_pub_ = node_handle_.advertise&lt;sensor_msgs::PointCloud2&gt;(no_ground_topic, 2);
	ground_points_pub_ = node_handle_.advertise&lt;sensor_msgs::PointCloud2&gt;(ground_topic, 2);

	vertical_res_ = sensor_model_;
	InitLabelArray(sensor_model_);
	limiting_ratio_ = tan(max_slope_*M_PI/180);

}

void GroundFilter::InitLabelArray(int in_model)
{
	for(int a = 0; a &lt; vertical_res_; a++)
	{
		class_label_[a] = UNKNOWN;
	}
}

void GroundFilter::InitDepthMap(int in_width)
{
	const int mOne = -1;
	index_map_ = cv::Mat_&lt;int&gt;(vertical_res_, in_width, mOne);
}

void GroundFilter::PublishPointCloud(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg,
				int in_indices[], int &amp;in_out_index_size, 
				pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;in_cloud)
{
	velodyne_pointcloud::PointXYZIR point;
	for (int i = 0; i &lt; in_out_index_size; i++)
	{
		point.x = in_cloud_msg-&gt;points[in_indices[i]].x;
		point.y = in_cloud_msg-&gt;points[in_indices[i]].y;
		point.z = in_cloud_msg-&gt;points[in_indices[i]].z;
		point.intensity = in_cloud_msg-&gt;points[in_indices[i]].intensity;
		point.ring = in_cloud_msg-&gt;points[in_indices[i]].ring;
		in_cloud.push_back(point);
	}
	in_out_index_size = 0;	
}

void GroundFilter::FilterGround(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg,
			pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_groundless_points,
			pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_ground_points)
{

	velodyne_pointcloud::PointXYZIR point;

	horizontal_res_ = int(in_cloud_msg-&gt;points.size() / vertical_res_);
	InitDepthMap(horizontal_res_);

	for (size_t i = 0; i &lt; in_cloud_msg-&gt;points.size(); i++)
	{
		double u = atan2(in_cloud_msg-&gt;points[i].y,in_cloud_msg-&gt;points[i].x) * 180/M_PI;
		if (u &lt; 0) { u = 360 + u; }
		int column = horizontal_res_ - (int)((double)horizontal_res_ * u / 360.0) - 1;
		int row = vertical_res_ - 1 - in_cloud_msg-&gt;points[i].ring;
		index_map_.at&lt;int&gt;(row, column) = i;
	}
	
	for (int i = 0; i &lt; horizontal_res_; i++)
	{
		Label point_class[vertical_res_];
		int unknown_index[vertical_res_];
		int point_index[vertical_res_];
		int unknown_index_size = 0;
		int point_index_size = 0;
		double z_ref = 0;
		double r_ref = 0;
		std::copy(class_label_, class_label_ + vertical_res_, point_class); 

		for (int j = vertical_res_ - 1; j &gt;= 0; j--)
		{
			if (index_map_.at&lt;int&gt;(j,i) &gt; -1 &amp;&amp; point_class[j] == UNKNOWN)
			{
				double x0 = in_cloud_msg-&gt;points[index_map_.at&lt;int&gt;(j, i)].x;
				double y0 = in_cloud_msg-&gt;points[index_map_.at&lt;int&gt;(j, i)].y;
				double z0 = in_cloud_msg-&gt;points[index_map_.at&lt;int&gt;(j, i)].z;
				double r0 = sqrt(x0*x0 + y0*y0);
				double r_diff = r0 - r_ref;
				double z_diff = fabs(z0 - z_ref);
				double pair_angle;

				if (r_diff != 0.)
				{
					pair_angle = z_diff/r_diff;
				}
				else
				{//this should never execute due to Sensor specs
					ROS_ERROR(&quot;GrooundFilter: Division by Zero avoided on pair_angle&quot;);
					pair_angle = 0;
				}
				if (
					 (	(pair_angle &gt; 0 &amp;&amp; pair_angle &lt; limiting_ratio_)
						&amp;&amp; z_diff &lt; gap_thres_
						&amp;&amp; z0 &lt; clipping_thres_
					 )
					|| point_index_size == 0
					)
				{
					r_ref = r0;
					z_ref = z0;
					point_index[point_index_size] = j;
					point_index_size++;
				}
				else
				{
					if (point_index_size &gt; min_point_)
					{
						for (int m = 0; m &lt; point_index_size; m++)
						{
							int index = index_map_.at&lt;int&gt;(point_index[m],i);
							point.x = in_cloud_msg-&gt;points[index].x;
							point.y = in_cloud_msg-&gt;points[index].y;
							point.z = in_cloud_msg-&gt;points[index].z;
							point.intensity = in_cloud_msg-&gt;points[index].intensity;
							point.ring = in_cloud_msg-&gt;points[index].ring;
							out_ground_points.push_back(point);
							point_class[point_index[m]] = GROUND;
						}
						point_index_size = 0;
					}
					else
					{
						for (int m = 0; m &lt; point_index_size; m++)
						{
							int index = index_map_.at&lt;int&gt;(point_index[m],i);
							point.z = in_cloud_msg-&gt;points[index].z;
							if (point.z &gt; clipping_thres_ - sensor_height_)
							{
								point.x = in_cloud_msg-&gt;points[index].x;
								point.y = in_cloud_msg-&gt;points[index].y;
								point.intensity = in_cloud_msg-&gt;points[index].intensity;
								point.ring = in_cloud_msg-&gt;points[index].ring;
								out_groundless_points.push_back(point);
								point_class[point_index[m]] = VERTICAL;
							}
							else
							{
								unknown_index[unknown_index_size] = index;
								unknown_index_size++;
							}
						}
						point_index_size = 0;
					}
				}
			}
			if (j == 0)
			{
				if (point_index_size != 0)
				{
					if (point_index_size &gt; min_point_)
					{
						for (int m = 0; m &lt; point_index_size; m++)
						{
							int index = index_map_.at&lt;int&gt;(point_index[m],i);
							point.x = in_cloud_msg-&gt;points[index].x;
							point.y = in_cloud_msg-&gt;points[index].y;
							point.z = in_cloud_msg-&gt;points[index].z;
							point.intensity = in_cloud_msg-&gt;points[index].intensity;
							point.ring = in_cloud_msg-&gt;points[index].ring;
							out_ground_points.push_back(point);
							point_class[point_index[m]] = GROUND;
						}
						point_index_size = 0;
					}
					else
					{
						for (int m = 0; m &lt; point_index_size; m++)
						{
							int index = index_map_.at&lt;int&gt;(point_index[m],i);
							point.z = in_cloud_msg-&gt;points[index].z;
							if (point.z &gt; clipping_thres_ - sensor_height_)
							{
								point.x = in_cloud_msg-&gt;points[index].x;
								point.y = in_cloud_msg-&gt;points[index].y;
								point.intensity = in_cloud_msg-&gt;points[index].intensity;
								point.ring = in_cloud_msg-&gt;points[index].ring;
								out_groundless_points.push_back(point);
								point_class[point_index[m]] = VERTICAL;
							}
							else
							{
								unknown_index[unknown_index_size] = index;
								unknown_index_size++;
							}
						}
						point_index_size = 0;
					}//end else
				}//end if (point_index_size != 0)

				double centroid = 0;
				int cluster_index[vertical_res_];
				int cluster_index_size = 0;
				for (int m = unknown_index_size - 1; m &gt;= 0; m--)
				{
					double x0 = in_cloud_msg-&gt;points[unknown_index[m]].x;
					double y0 = in_cloud_msg-&gt;points[unknown_index[m]].y;
					double r0 = sqrt(x0*x0 + y0*y0);
					double r_diff = fabs(r0 - centroid);
					if ((r_diff &lt; point_distance_) || cluster_index_size == 0)
					{
						cluster_index[cluster_index_size] = unknown_index[m];
						cluster_index_size++;
						centroid = r0;
						if (m == 0)
						{
							if(cluster_index_size &gt; 1)
							{
								PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_groundless_points);
							}
							else
							{
								PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_ground_points);
							}
						}
					}
					else
					{
						if(cluster_index_size &gt; 1)
						{
							PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_groundless_points);
						}
						else
						{
							PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_ground_points);
						}
					}
				}//end for (int m = unknown_index_size - 1; m &gt;= 0; m--)
			}//end if (j == 0)
		}
	}

}

void GroundFilter::VelodyneCallback(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg)
{

	pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; vertical_points;
	pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; ground_points;
	vertical_points.header = in_cloud_msg-&gt;header;
	ground_points.header = in_cloud_msg-&gt;header;
	vertical_points.clear();
	ground_points.clear();

	FilterGround(in_cloud_msg, vertical_points, ground_points);

	if (!floor_removal_)
	{
		vertical_points = *in_cloud_msg;
	} 
	
	groundless_points_pub_.publish(vertical_points);
	ground_points_pub_.publish(ground_points);

}

int main(int argc, char **argv)
{

	ros::init(argc, argv, &quot;ground_filter&quot;);
	GroundFilter node;
	ros::spin();

	return 0;

}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="29b934b98b12aec3f9053e23bb3e0517dde925cf" fix_time="0,24037">
		<msg>Typo Fix</msg>
		<modified_files>
			<file old_path="ros/src/sensing/filters/packages/points_preprocessor/nodes/ground_filter/ground_filter.cpp" new_path="ros/src/sensing/filters/packages/points_preprocessor/nodes/ground_filter/ground_filter.cpp">
				<diff>@@ -204,7 +204,7 @@ void GroundFilter::FilterGround(const pcl::PointCloud&lt;velodyne_pointcloud::Point
 				}
 				else
 				{//this should never execute due to Sensor specs
-					ROS_ERROR(&quot;GrooundFilter: Division by Zero avoided on pair_angle&quot;);
+					ROS_ERROR(&quot;GroundFilter: Division by Zero avoided on pair_angle&quot;);
 					pair_angle = 0;
 				}
 				if (
</diff>
				<old_file>/*
 * ground_filter.cpp
 *
 * Created on	: May 19, 2017
 * Author	: Patiphon Narksri					
 */
#include &lt;ros/ros.h&gt;
#include &lt;sensor_msgs/PointCloud2.h&gt;
#include &lt;pcl_ros/point_cloud.h&gt;
#include &lt;pcl_conversions/pcl_conversions.h&gt;
#include &lt;pcl/point_types.h&gt;
#include &lt;velodyne_pointcloud/point_types.h&gt;
#include &lt;opencv/cv.h&gt;

enum Label
{
	GROUND,
	VERTICAL,
	UNKNOWN //Initial state, not classified
};

class GroundFilter
{
public:
	
	GroundFilter();

private:

	ros::NodeHandle node_handle_;
	ros::Subscriber points_node_sub_;
	ros::Publisher groundless_points_pub_;
	ros::Publisher ground_points_pub_;

	std::string point_topic_;
	int 		sensor_model_;
	double 		sensor_height_;
	double 		max_slope_;
	int 		min_point_;
	double 		clipping_thres_;
	double 		gap_thres_;
	double		point_distance_;
	bool		floor_removal_;

	int 		vertical_res_;
	int 		horizontal_res_;
	double 		limiting_ratio_;
	cv::Mat 	index_map_;
	Label 		class_label_[64];

	boost::chrono::high_resolution_clock::time_point t1_;
	boost::chrono::high_resolution_clock::time_point t2_;
	boost::chrono::nanoseconds elap_time_;

	const int 	DEFAULT_HOR_RES = 2000;

	void InitLabelArray(int in_model);
	void InitDepthMap(int in_width);
	void PublishPointCloud(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg,
				int in_indices[], int &amp;in_out_index_size, 
				pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;in_cloud);


	void VelodyneCallback(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg);
	void FilterGround(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg,
				pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_groundless_points,
				pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_ground_points);

};

GroundFilter::GroundFilter() : node_handle_(&quot;~&quot;)
{
	ROS_INFO(&quot;Inititalizing Ground Filter...&quot;);
	node_handle_.param&lt;std::string&gt;(&quot;point_topic&quot;, point_topic_, &quot;/points_raw&quot;);
	ROS_INFO(&quot;Input Point Cloud: %s&quot;, point_topic_.c_str());
 	node_handle_.param(&quot;remove_floor&quot;,  floor_removal_,  true);
 	ROS_INFO(&quot;Floor Removal: %d&quot;, floor_removal_);
	node_handle_.param(&quot;sensor_model&quot;, sensor_model_, 64);
	ROS_INFO(&quot;Sensor Model: %d&quot;, sensor_model_);
	node_handle_.param(&quot;sensor_height&quot;, sensor_height_, 1.72);
	ROS_INFO(&quot;Sensor Height: %f&quot;, sensor_height_);
	node_handle_.param(&quot;max_slope&quot;, max_slope_, 20.0);
	ROS_INFO(&quot;Max Slope: %f&quot;, max_slope_);
	node_handle_.param(&quot;point_distance&quot;, point_distance_, 0.05);
	ROS_INFO(&quot;Point Distance: %f&quot;, point_distance_);
	node_handle_.param(&quot;min_point&quot;, min_point_, 3);
	ROS_INFO(&quot;Min Points: %d&quot;, min_point_);
	node_handle_.param(&quot;clipping_thres&quot;, clipping_thres_, 0.5);
	ROS_INFO(&quot;Lower Clipping Threshold: %f&quot;, clipping_thres_);
	node_handle_.param(&quot;gap_thres&quot;, gap_thres_, 0.5);
	ROS_INFO(&quot;Point Gap Threshold: %f&quot;, gap_thres_);

	std::string no_ground_topic, ground_topic;
	node_handle_.param&lt;std::string&gt;(&quot;no_ground_point_topic&quot;, no_ground_topic, &quot;/points_no_ground&quot;);
	ROS_INFO(&quot;No Ground Output Point Cloud: %s&quot;, no_ground_topic.c_str());
	node_handle_.param&lt;std::string&gt;(&quot;ground_point_topic&quot;, ground_topic, &quot;/points_ground&quot;);
	ROS_INFO(&quot;Only Ground Output Point Cloud: %s&quot;, ground_topic.c_str());

	int default_horizontal_res;
	switch(sensor_model_)
	{
		case 64:
			default_horizontal_res = 2083;
			break;
		case 32:
			default_horizontal_res = 2250;
			break;
		case 16:
			default_horizontal_res = 1800;
			break;
		default:
			default_horizontal_res = DEFAULT_HOR_RES;
			break;
	}
	node_handle_.param(&quot;horizontal_res&quot;, horizontal_res_, default_horizontal_res);

	points_node_sub_ = node_handle_.subscribe(point_topic_, 2, &amp;GroundFilter::VelodyneCallback, this);
	groundless_points_pub_ = node_handle_.advertise&lt;sensor_msgs::PointCloud2&gt;(no_ground_topic, 2);
	ground_points_pub_ = node_handle_.advertise&lt;sensor_msgs::PointCloud2&gt;(ground_topic, 2);

	vertical_res_ = sensor_model_;
	InitLabelArray(sensor_model_);
	limiting_ratio_ = tan(max_slope_*M_PI/180);

}

void GroundFilter::InitLabelArray(int in_model)
{
	for(int a = 0; a &lt; vertical_res_; a++)
	{
		class_label_[a] = UNKNOWN;
	}
}

void GroundFilter::InitDepthMap(int in_width)
{
	const int mOne = -1;
	index_map_ = cv::Mat_&lt;int&gt;(vertical_res_, in_width, mOne);
}

void GroundFilter::PublishPointCloud(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg,
				int in_indices[], int &amp;in_out_index_size, 
				pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;in_cloud)
{
	velodyne_pointcloud::PointXYZIR point;
	for (int i = 0; i &lt; in_out_index_size; i++)
	{
		point.x = in_cloud_msg-&gt;points[in_indices[i]].x;
		point.y = in_cloud_msg-&gt;points[in_indices[i]].y;
		point.z = in_cloud_msg-&gt;points[in_indices[i]].z;
		point.intensity = in_cloud_msg-&gt;points[in_indices[i]].intensity;
		point.ring = in_cloud_msg-&gt;points[in_indices[i]].ring;
		in_cloud.push_back(point);
	}
	in_out_index_size = 0;	
}

void GroundFilter::FilterGround(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg,
			pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_groundless_points,
			pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; &amp;out_ground_points)
{

	velodyne_pointcloud::PointXYZIR point;

	//This line is not necessary
	//horizontal_res_ = int(in_cloud_msg-&gt;points.size() / vertical_res_);
	InitDepthMap(horizontal_res_);

	for (size_t i = 0; i &lt; in_cloud_msg-&gt;points.size(); i++)
	{
		double u = atan2(in_cloud_msg-&gt;points[i].y,in_cloud_msg-&gt;points[i].x) * 180/M_PI;
		if (u &lt; 0) { u = 360 + u; }
		int column = horizontal_res_ - (int)((double)horizontal_res_ * u / 360.0) - 1;
		int row = vertical_res_ - 1 - in_cloud_msg-&gt;points[i].ring;
		index_map_.at&lt;int&gt;(row, column) = i;
	}
	
	for (int i = 0; i &lt; horizontal_res_; i++)
	{
		Label point_class[vertical_res_];
		int unknown_index[vertical_res_];
		int point_index[vertical_res_];
		int unknown_index_size = 0;
		int point_index_size = 0;
		double z_ref = 0;
		double r_ref = 0;
		std::copy(class_label_, class_label_ + vertical_res_, point_class); 

		for (int j = vertical_res_ - 1; j &gt;= 0; j--)
		{
			if (index_map_.at&lt;int&gt;(j,i) &gt; -1 &amp;&amp; point_class[j] == UNKNOWN)
			{
				double x0 = in_cloud_msg-&gt;points[index_map_.at&lt;int&gt;(j, i)].x;
				double y0 = in_cloud_msg-&gt;points[index_map_.at&lt;int&gt;(j, i)].y;
				double z0 = in_cloud_msg-&gt;points[index_map_.at&lt;int&gt;(j, i)].z;
				double r0 = sqrt(x0*x0 + y0*y0);
				double r_diff = r0 - r_ref;
				double z_diff = fabs(z0 - z_ref);
				double pair_angle;

				if (r_diff != 0.)
				{
					pair_angle = z_diff/r_diff;
				}
				else
				{//this should never execute due to Sensor specs
					ROS_ERROR(&quot;GrooundFilter: Division by Zero avoided on pair_angle&quot;);
					pair_angle = 0;
				}
				if (
					 (	(pair_angle &gt; 0 &amp;&amp; pair_angle &lt; limiting_ratio_)
						&amp;&amp; z_diff &lt; gap_thres_
						&amp;&amp; z0 &lt; clipping_thres_
					 )
					|| point_index_size == 0
					)
				{
					r_ref = r0;
					z_ref = z0;
					point_index[point_index_size] = j;
					point_index_size++;
				}
				else
				{
					if (point_index_size &gt; min_point_)
					{
						for (int m = 0; m &lt; point_index_size; m++)
						{
							int index = index_map_.at&lt;int&gt;(point_index[m],i);
							point.x = in_cloud_msg-&gt;points[index].x;
							point.y = in_cloud_msg-&gt;points[index].y;
							point.z = in_cloud_msg-&gt;points[index].z;
							point.intensity = in_cloud_msg-&gt;points[index].intensity;
							point.ring = in_cloud_msg-&gt;points[index].ring;
							out_ground_points.push_back(point);
							point_class[point_index[m]] = GROUND;
						}
						point_index_size = 0;
					}
					else
					{
						for (int m = 0; m &lt; point_index_size; m++)
						{
							int index = index_map_.at&lt;int&gt;(point_index[m],i);
							point.z = in_cloud_msg-&gt;points[index].z;
							if (point.z &gt; clipping_thres_ - sensor_height_)
							{
								point.x = in_cloud_msg-&gt;points[index].x;
								point.y = in_cloud_msg-&gt;points[index].y;
								point.intensity = in_cloud_msg-&gt;points[index].intensity;
								point.ring = in_cloud_msg-&gt;points[index].ring;
								out_groundless_points.push_back(point);
								point_class[point_index[m]] = VERTICAL;
							}
							else
							{
								unknown_index[unknown_index_size] = index;
								unknown_index_size++;
							}
						}
						point_index_size = 0;
					}
					//These line were missing
					r_ref = r0;
					z_ref = z0;
					point_index[point_index_size] = j;
					point_index_size++;
				}
			}
			if (j == 0)
			{
				if (point_index_size != 0)
				{
					if (point_index_size &gt; min_point_)
					{
						for (int m = 0; m &lt; point_index_size; m++)
						{
							int index = index_map_.at&lt;int&gt;(point_index[m],i);
							point.x = in_cloud_msg-&gt;points[index].x;
							point.y = in_cloud_msg-&gt;points[index].y;
							point.z = in_cloud_msg-&gt;points[index].z;
							point.intensity = in_cloud_msg-&gt;points[index].intensity;
							point.ring = in_cloud_msg-&gt;points[index].ring;
							out_ground_points.push_back(point);
							point_class[point_index[m]] = GROUND;
						}
						point_index_size = 0;
					}
					else
					{
						for (int m = 0; m &lt; point_index_size; m++)
						{
							int index = index_map_.at&lt;int&gt;(point_index[m],i);
							point.z = in_cloud_msg-&gt;points[index].z;
							if (point.z &gt; clipping_thres_ - sensor_height_)
							{
								point.x = in_cloud_msg-&gt;points[index].x;
								point.y = in_cloud_msg-&gt;points[index].y;
								point.intensity = in_cloud_msg-&gt;points[index].intensity;
								point.ring = in_cloud_msg-&gt;points[index].ring;
								out_groundless_points.push_back(point);
								point_class[point_index[m]] = VERTICAL;
							}
							else
							{
								unknown_index[unknown_index_size] = index;
								unknown_index_size++;
							}
						}
						point_index_size = 0;
					}//end else
				}//end if (point_index_size != 0)

				double centroid = 0;
				int cluster_index[vertical_res_];
				int cluster_index_size = 0;
				for (int m = unknown_index_size - 1; m &gt;= 0; m--)
				{
					double x0 = in_cloud_msg-&gt;points[unknown_index[m]].x;
					double y0 = in_cloud_msg-&gt;points[unknown_index[m]].y;
					double r0 = sqrt(x0*x0 + y0*y0);
					double r_diff = fabs(r0 - centroid);
					if ((r_diff &lt; point_distance_) || cluster_index_size == 0)
					{
						cluster_index[cluster_index_size] = unknown_index[m];
						cluster_index_size++;
						centroid = r0;
						if (m == 0)
						{
							if(cluster_index_size &gt; 1)
							{
								PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_groundless_points);
							}
							else
							{
								PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_ground_points);
							}
						}
					}
					else
					{
						if(cluster_index_size &gt; 1)
						{
							PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_groundless_points);
						}
						else
						{
							PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_ground_points);
						}
						cluster_index[cluster_index_size] = unknown_index[m];
						cluster_index_size++;
						centroid = r0;
					}
					if (m == 0)
					{
						if(cluster_index_size &gt; 1)
						{
							PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_groundless_points);
						}
						else
						{
							PublishPointCloud(in_cloud_msg, cluster_index, cluster_index_size, out_ground_points);
						}
					}
				}//end for (int m = unknown_index_size - 1; m &gt;= 0; m--)
			}//end if (j == 0)
		}
	}

}

void GroundFilter::VelodyneCallback(const pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt;::ConstPtr &amp;in_cloud_msg)
{

	pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; vertical_points;
	pcl::PointCloud&lt;velodyne_pointcloud::PointXYZIR&gt; ground_points;
	vertical_points.header = in_cloud_msg-&gt;header;
	ground_points.header = in_cloud_msg-&gt;header;
	vertical_points.clear();
	ground_points.clear();

	FilterGround(in_cloud_msg, vertical_points, ground_points);

	if (!floor_removal_)
	{
		vertical_points = *in_cloud_msg;
	} 
	
	groundless_points_pub_.publish(vertical_points);
	ground_points_pub_.publish(ground_points);

}

int main(int argc, char **argv)
{

	ros::init(argc, argv, &quot;ground_filter&quot;);
	GroundFilter node;
	ros::spin();

	return 0;

}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="8d05bdaf8f345078fb3fb879a317fe2d919ebc4f" fix_time="236,75358">
		<msg>Fix coodinate bug and small refactor</msg>
		<modified_files>
			<file old_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/obj_fusion/obj_fusion.cpp" new_path="ros/src/computing/perception/detection/packages/lidar_tracker/nodes/obj_fusion/obj_fusion.cpp">
				<diff>@@ -22,8 +22,8 @@ using vector_map::Node;
 using vector_map::Point;
 using vector_map::Key;
 
-static constexpr uint32_t SUBSCRIBE_QUEUE_SIZE = 100;
-static constexpr uint32_t ADVERTISE_QUEUE_SIZE = 10;
+static constexpr uint32_t SUBSCRIBE_QUEUE_SIZE = 1;
+static constexpr uint32_t ADVERTISE_QUEUE_SIZE = 1;
 static constexpr bool ADVERTISE_LATCH = false;
 static constexpr double LOOP_RATE = 15.0;
 
@@ -152,7 +152,7 @@ void fusion_cb(const autoware_msgs::obj_label::ConstPtr &amp;obj_label_msg,
   autoware_msgs::CloudClusterArray cloud_clusters_msg;
   cloud_clusters_msg.header = header;
   visualization_msgs::MarkerArray marker_array_msg;
-  int id = 0;
+  int marker_id = 0;
 
   for (unsigned int i = 0; i &lt; obj_label.obj_id.size(); ++i) {
     if (obj_indices.at(i) == -1) continue;
@@ -171,13 +171,13 @@ void fusion_cb(const autoware_msgs::obj_label::ConstPtr &amp;obj_label_msg,
     bounding_box = v_cloud_cluster.at(obj_indices.at(i)).bounding_box;
 
     /* adjust object rotation using lane in vector_map */
-    tf::Quaternion q1(bounding_box.pose.orientation.x,
+    tf::Quaternion q_obj(bounding_box.pose.orientation.x,
       bounding_box.pose.orientation.y,
       bounding_box.pose.orientation.z,
       bounding_box.pose.orientation.w);
     bool fixed_rotation = false;
     if (use_vmap) {
-      int mi = 0; // number of rotaiton 90deg
+      int rot_n = 0; // yaw' = yaw + n*pi/2
       vector_map_server::GetLane get_lane;
       get_lane.request.pose.pose = bounding_box.pose;
       tf::Vector3 orgpt(bounding_box.pose.position.x,
@@ -202,25 +202,26 @@ void fusion_cb(const autoware_msgs::obj_label::ConstPtr &amp;obj_label_msg,
           double my = get_lane.request.pose.pose.position.y;
           if ((mx-fp.ly)*(mx-fp.ly)+(my-fp.bx)*(my-fp.bx) &lt; vmap_threshold) {
             fixed_rotation = true;
-            tf::Quaternion ql;
-            ql.setRPY(0, 0, atan2(fp.bx - bp.bx, fp.ly - bp.ly)); // y,x
-            tf::Quaternion qb = tform * q1;
-            tf::Quaternion qm;
-            qm.setRPY(0, 0, M_PI/2);
-            double mr = M_PI;
+            tf::Quaternion qm_lane;   // map-cood
+            qm_lane.setRPY(0, 0, atan2(fp.bx - bp.bx, fp.ly - bp.ly)); // y,x
+            tf::Quaternion q_step;  // 90 deg
+            q_step.setRPY(0, 0, M_PI/2);
+            double r_max = M_PI;
             // search in 0,90,180,270-degree
+            tf::Quaternion qr_obj = q_obj; // rotated
             for (int i = 0; i &lt; 4; i++) {
-              double r = ql.angle(qb);
+              tf::Quaternion qrm_obj = tform * qr_obj;  // map-cood
+              double r = qm_lane.angle(qrm_obj);
               r = (r &gt;= M_PI/2) ? (r - M_PI):r;
-              if (fabs(r) &lt; mr) {
-                mr = fabs(r);
-                mi = i;
+              if (fabs(r) &lt; r_max) {
+                r_max = fabs(r);
+                rot_n = i;
               }
-              qb *= qm;
+              qr_obj *= q_step;
             }
             double roll, pitch, yaw;
-            tf::Matrix3x3(q1).getRPY(roll, pitch, yaw);
-            ROS_INFO(&quot; %d roll=%f pitch=%f yaw=%f&quot;, mi*90, roll, pitch, yaw);
+            tf::Matrix3x3(q_obj).getRPY(roll, pitch, yaw);
+            ROS_INFO(&quot; %d roll=%f pitch=%f yaw=%f&quot;, rot_n*90, roll, pitch, yaw);
             break;
           }
         }
@@ -228,24 +229,25 @@ void fusion_cb(const autoware_msgs::obj_label::ConstPtr &amp;obj_label_msg,
         ROS_INFO(&quot;%s: VectorMap Server call failed.&quot;, __FUNCTION__);
       }
       // determine rotation
-      tf::Quaternion dq1;
-      dq1.setRPY(0, 0, M_PI*mi/2);
-      q1 *= dq1;
+      tf::Quaternion dq_obj;
+      dq_obj.setRPY(0, 0, M_PI*rot_n/2);
+      q_obj *= dq_obj;
       // bounding_box
-      bounding_box.pose.orientation.x = q1.x();
-      bounding_box.pose.orientation.y = q1.y();
-      bounding_box.pose.orientation.z = q1.z();
-      bounding_box.pose.orientation.w = q1.w();
-      if (mi % 2 == 1) { // swap x-y at 90,270 deg
+      bounding_box.pose.orientation.x = q_obj.x();
+      bounding_box.pose.orientation.y = q_obj.y();
+      bounding_box.pose.orientation.z = q_obj.z();
+      bounding_box.pose.orientation.w = q_obj.w();
+      if (rot_n % 2 == 1) { // swap x-y at 90,270 deg
         std::swap(bounding_box.dimensions.x, bounding_box.dimensions.y);
       }
+      // cloud clusters
       v_cloud_cluster.at(obj_indices.at(i)).bounding_box = bounding_box;
     }
 
     // x-axis
     visualization_msgs::Marker marker;
     marker.header = header;
-    marker.id = id++;
+    marker.id = marker_id++;
     marker.lifetime = ros::Duration(0.1);
     marker.type = visualization_msgs::Marker::ARROW;
     marker.pose.position = bounding_box.pose.position;
@@ -258,28 +260,28 @@ void fusion_cb(const autoware_msgs::obj_label::ConstPtr &amp;obj_label_msg,
     marker_array_msg.markers.push_back(marker);
 
     // y-axis
-    tf::Quaternion q2;
-    q2.setRPY(0, 0, M_PI/2);
-    q1 *= q2;
-    marker.id = id++;
-    marker.pose.orientation.x = q1.x();
-    marker.pose.orientation.y = q1.y();
-    marker.pose.orientation.z = q1.z();
-    marker.pose.orientation.w = q1.w();
+    tf::Quaternion qy;
+    qy.setRPY(0, 0, M_PI/2);
+    q_obj *= qy;
+    marker.id = marker_id++;
+    marker.pose.orientation.x = q_obj.x();
+    marker.pose.orientation.y = q_obj.y();
+    marker.pose.orientation.z = q_obj.z();
+    marker.pose.orientation.w = q_obj.w();
     marker.color.r = 0.0;
     marker.color.g = 1.0;
     marker.color.a = 1.0;
     marker_array_msg.markers.push_back(marker);
 
     // z-axis
-    tf::Quaternion q3;
-    q3.setRPY(0, -M_PI/2, 0);
-    q1 *= q3;
-    marker.id = id++;
-    marker.pose.orientation.x = q1.x();
-    marker.pose.orientation.y = q1.y();
-    marker.pose.orientation.z = q1.z();
-    marker.pose.orientation.w = q1.w();
+    tf::Quaternion qz;
+    qz.setRPY(0, -M_PI/2, 0);
+    q_obj *= qz;
+    marker.id = marker_id++;
+    marker.pose.orientation.x = q_obj.x();
+    marker.pose.orientation.y = q_obj.y();
+    marker.pose.orientation.z = q_obj.z();
+    marker.pose.orientation.w = q_obj.w();
     marker.color.g = 0.0;
     marker.color.b = 1.0;
     marker.color.a = 1.0;
@@ -287,14 +289,14 @@ void fusion_cb(const autoware_msgs::obj_label::ConstPtr &amp;obj_label_msg,
 
     // rotated by lane
     if (fixed_rotation) {
-      marker.id = id++;
+      marker.id = marker_id++;
       marker.type = visualization_msgs::Marker::SPHERE;
       marker.scale.x = 1.0;
       marker.scale.y = 1.0;
       marker.scale.z = 1.0;
+      marker.color.r = 1.0;
       marker.color.g = 1.0;
       marker.color.b = 1.0;
-      marker.color.a = 1.0;
       marker_array_msg.markers.push_back(marker);
     }
 
</diff>
				<old_file>#include &lt;float.h&gt;
#include &lt;geometry_msgs/Point.h&gt;
#include &lt;visualization_msgs/MarkerArray.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBox.h&gt;
#include &lt;jsk_recognition_msgs/BoundingBoxArray.h&gt;
#include &quot;autoware_msgs/obj_label.h&quot;
#include &quot;autoware_msgs/CloudCluster.h&quot;
#include &quot;autoware_msgs/CloudClusterArray.h&quot;
#include &lt;math.h&gt;
#include &lt;mutex&gt;
#include &lt;ros/ros.h&gt;
#include &lt;std_msgs/Time.h&gt;
#include &lt;tf/tf.h&gt;
#include &lt;tf/transform_listener.h&gt;
#include &lt;vector_map/vector_map.h&gt;
#include &lt;vector_map_server/GetLane.h&gt;
#include &lt;message_filters/subscriber.h&gt;
#include &lt;message_filters/synchronizer.h&gt;
#include &lt;message_filters/sync_policies/approximate_time.h&gt;

using vector_map::Node;
using vector_map::Point;
using vector_map::Key;

static constexpr uint32_t SUBSCRIBE_QUEUE_SIZE = 100;
static constexpr uint32_t ADVERTISE_QUEUE_SIZE = 10;
static constexpr bool ADVERTISE_LATCH = false;
static constexpr double LOOP_RATE = 15.0;

ros::Publisher obj_pose_pub;
ros::Publisher obj_pose_timestamp_pub;
ros::Publisher cluster_class_pub;
ros::Publisher marker_array_pub;

static std::string object_type;
static std::vector&lt;geometry_msgs::Point&gt; centroids;
static std_msgs::Header sensor_header;
static std::vector&lt;autoware_msgs::CloudCluster&gt; v_cloud_cluster;
static ros::Time obj_pose_timestamp;
static double threshold_min_dist;

static vector_map::VectorMap vmap;
static ros::ServiceClient vmap_server;
static bool use_vmap;
static double vmap_threshold;

struct obj_label_t {
  std::vector&lt;geometry_msgs::Point&gt; reprojected_positions;
  std::vector&lt;int&gt; obj_id;
};
obj_label_t obj_label;

static double euclid_distance(const geometry_msgs::Point pos1,
                              const geometry_msgs::Point pos2) {
  return sqrt(pow(pos1.x - pos2.x, 2) + pow(pos1.y - pos2.y, 2) +
              pow(pos1.z - pos2.z, 2));

} /* static double distance() */

/* fusion reprojected position and pointcloud centroids */
void fusion_cb(const autoware_msgs::obj_label::ConstPtr &amp;obj_label_msg,
  const autoware_msgs::CloudClusterArray::ConstPtr &amp;in_cloud_cluster_array_ptr) {

  tf::StampedTransform tform;
  tf::TransformListener tflistener;
  try {
    ros::Time now = ros::Time(0);
    tflistener.waitForTransform(&quot;/map&quot;, &quot;/velodyne&quot;, now, ros::Duration(10));
    tflistener.lookupTransform(&quot;/map&quot;, &quot;/velodyne&quot;, now, tform);
  } catch (tf::TransformException ex) {
    ROS_INFO(&quot;%s: %s&quot;, __FUNCTION__, ex.what());
    return;
  }

  obj_label_t obj_label;
  object_type = obj_label_msg-&gt;type;
  obj_pose_timestamp = obj_label_msg-&gt;header.stamp;

  for (unsigned int i = 0; i &lt; obj_label_msg-&gt;obj_id.size(); ++i) {
    obj_label.reprojected_positions.push_back(
        obj_label_msg-&gt;reprojected_pos.at(i));
    obj_label.obj_id.push_back(obj_label_msg-&gt;obj_id.at(i));
  }

  std::vector&lt;autoware_msgs::CloudCluster&gt; v_cloud_cluster;
  std_msgs::Header header = sensor_header;
  std::vector&lt;geometry_msgs::Point&gt; centroids;

  for (int i(0); i &lt; (int)in_cloud_cluster_array_ptr-&gt;clusters.size(); ++i) {
    autoware_msgs::CloudCluster cloud_cluster =
        in_cloud_cluster_array_ptr-&gt;clusters.at(i);
    /* convert centroids coodinate from velodyne frame to map frame */
    tf::Vector3 pt(cloud_cluster.centroid_point.point.x,
                   cloud_cluster.centroid_point.point.y,
                   cloud_cluster.centroid_point.point.z);
    tf::Vector3 converted = tform * pt;
    sensor_header = cloud_cluster.header;
    v_cloud_cluster.push_back(cloud_cluster);
    geometry_msgs::Point point_in_map;
    point_in_map.x = converted.x();
    point_in_map.y = converted.y();
    point_in_map.z = converted.z();

    centroids.push_back(point_in_map);
  }

  if (centroids.empty() ||
      obj_label.reprojected_positions.empty() ||
      obj_label.obj_id.empty()) {
    jsk_recognition_msgs::BoundingBoxArray pub_msg;
    pub_msg.header = header;
    std_msgs::Time time;
    obj_pose_pub.publish(pub_msg);
    autoware_msgs::CloudClusterArray cloud_clusters_msg;
    cloud_clusters_msg.header = header;
    cluster_class_pub.publish(cloud_clusters_msg);
    visualization_msgs::MarkerArray marker_array_msg;
    marker_array_pub.publish(marker_array_msg);
    time.data = obj_pose_timestamp;
    obj_pose_timestamp_pub.publish(time);
    return;
  }

  std::vector&lt;int&gt; obj_indices;
  for (unsigned int i = 0; i &lt; obj_label.obj_id.size(); ++i) {
    unsigned int min_idx = 0;
    double min_distance = DBL_MAX;

    /* calculate each euclid distance between reprojected position and centroids
     */
    for (unsigned int j = 0; j &lt; centroids.size(); j++) {
      double distance =
          euclid_distance(obj_label.reprojected_positions.at(i),
                          centroids.at(j));

      /* Nearest centroid correspond to this reprojected object */
      if (distance &lt; min_distance) {
        min_distance = distance;
        min_idx = j;
      }
    }
    if (min_distance &lt; threshold_min_dist) {
      obj_indices.push_back(min_idx);
    } else {
      obj_indices.push_back(-1);
    }
  }

  /* Publish marker with centroids coordinates */
  jsk_recognition_msgs::BoundingBoxArray pub_msg;
  pub_msg.header = header;
  autoware_msgs::CloudClusterArray cloud_clusters_msg;
  cloud_clusters_msg.header = header;
  visualization_msgs::MarkerArray marker_array_msg;
  int id = 0;

  for (unsigned int i = 0; i &lt; obj_label.obj_id.size(); ++i) {
    if (obj_indices.at(i) == -1) continue;

    v_cloud_cluster.at(obj_indices.at(i)).label = object_type;
    if (object_type == &quot;car&quot;) {
      v_cloud_cluster.at(obj_indices.at(i)).bounding_box.label = 0;
    } else if (object_type == &quot;person&quot;) {
      v_cloud_cluster.at(obj_indices.at(i)).bounding_box.label = 1;
    } else {
      v_cloud_cluster.at(obj_indices.at(i)).bounding_box.label = 2;
      v_cloud_cluster.at(obj_indices.at(i)).label = &quot;unknown&quot;;
    }

    jsk_recognition_msgs::BoundingBox bounding_box;
    bounding_box = v_cloud_cluster.at(obj_indices.at(i)).bounding_box;

    /* adjust object rotation using lane in vector_map */
    tf::Quaternion q1(bounding_box.pose.orientation.x,
      bounding_box.pose.orientation.y,
      bounding_box.pose.orientation.z,
      bounding_box.pose.orientation.w);
    bool fixed_rotation = false;
    if (use_vmap) {
      int mi = 0; // number of rotaiton 90deg
      vector_map_server::GetLane get_lane;
      get_lane.request.pose.pose = bounding_box.pose;
      tf::Vector3 orgpt(bounding_box.pose.position.x,
        bounding_box.pose.position.y,
        bounding_box.pose.position.z);
      tf::Vector3 convpt = tform * orgpt;
      get_lane.request.pose.pose.position.x = convpt.x();
      get_lane.request.pose.pose.position.y = convpt.y();
      get_lane.request.pose.pose.position.z = convpt.z();
      ROS_INFO(&quot;pos x=%f y=%f z=%f&quot;,
        get_lane.request.pose.pose.position.x,
        get_lane.request.pose.pose.position.y,
        get_lane.request.pose.pose.position.z);
      if (vmap_server.call(get_lane)) {
        for (const auto&amp; lane : get_lane.response.objects.data) {
          Node bn = vmap.findByKey(Key&lt;Node&gt;(lane.bnid));
          Point bp = vmap.findByKey(Key&lt;Point&gt;(bn.pid));
          Node fn = vmap.findByKey(Key&lt;Node&gt;(lane.fnid));
          Point fp = vmap.findByKey(Key&lt;Point&gt;(fn.pid));
          ROS_INFO(&quot; lane bn=(%f,%f) fn=(%f,%f)&quot;, bp.ly, bp.bx, fp.ly, fp.bx);
          double mx = get_lane.request.pose.pose.position.x;
          double my = get_lane.request.pose.pose.position.y;
          if ((mx-fp.ly)*(mx-fp.ly)+(my-fp.bx)*(my-fp.bx) &lt; vmap_threshold) {
            fixed_rotation = true;
            tf::Quaternion ql;
            ql.setRPY(0, 0, atan2(fp.bx - bp.bx, fp.ly - bp.ly)); // y,x
            tf::Quaternion qb = tform * q1;
            tf::Quaternion qm;
            qm.setRPY(0, 0, M_PI/2);
            double mr = M_PI;
            // search in 0,90,180,270-degree
            for (int i = 0; i &lt; 4; i++) {
              double r = ql.angle(qb);
              r = (r &gt;= M_PI/2) ? (r - M_PI):r;
              if (fabs(r) &lt; mr) {
                mr = fabs(r);
                mi = i;
              }
              qb *= qm;
            }
            double roll, pitch, yaw;
            tf::Matrix3x3(q1).getRPY(roll, pitch, yaw);
            ROS_INFO(&quot; %d roll=%f pitch=%f yaw=%f&quot;, mi*90, roll, pitch, yaw);
            break;
          }
        }
      } else {
        ROS_INFO(&quot;%s: VectorMap Server call failed.&quot;, __FUNCTION__);
      }
      // determine rotation
      tf::Quaternion dq1;
      dq1.setRPY(0, 0, M_PI*mi/2);
      q1 *= dq1;
      // bounding_box
      bounding_box.pose.orientation.x = q1.x();
      bounding_box.pose.orientation.y = q1.y();
      bounding_box.pose.orientation.z = q1.z();
      bounding_box.pose.orientation.w = q1.w();
      if (mi % 2 == 1) { // swap x-y at 90,270 deg
        std::swap(bounding_box.dimensions.x, bounding_box.dimensions.y);
      }
      v_cloud_cluster.at(obj_indices.at(i)).bounding_box = bounding_box;
    }

    // x-axis
    visualization_msgs::Marker marker;
    marker.header = header;
    marker.id = id++;
    marker.lifetime = ros::Duration(0.1);
    marker.type = visualization_msgs::Marker::ARROW;
    marker.pose.position = bounding_box.pose.position;
    marker.pose.orientation = bounding_box.pose.orientation;
    marker.scale.x = 2.0;
    marker.scale.y = 0.2;
    marker.scale.z = 0.1;
    marker.color.r = 1.0;
    marker.color.a = 1.0;
    marker_array_msg.markers.push_back(marker);

    // y-axis
    tf::Quaternion q2;
    q2.setRPY(0, 0, M_PI/2);
    q1 *= q2;
    marker.id = id++;
    marker.pose.orientation.x = q1.x();
    marker.pose.orientation.y = q1.y();
    marker.pose.orientation.z = q1.z();
    marker.pose.orientation.w = q1.w();
    marker.color.r = 0.0;
    marker.color.g = 1.0;
    marker.color.a = 1.0;
    marker_array_msg.markers.push_back(marker);

    // z-axis
    tf::Quaternion q3;
    q3.setRPY(0, -M_PI/2, 0);
    q1 *= q3;
    marker.id = id++;
    marker.pose.orientation.x = q1.x();
    marker.pose.orientation.y = q1.y();
    marker.pose.orientation.z = q1.z();
    marker.pose.orientation.w = q1.w();
    marker.color.g = 0.0;
    marker.color.b = 1.0;
    marker.color.a = 1.0;
    marker_array_msg.markers.push_back(marker);

    // rotated by lane
    if (fixed_rotation) {
      marker.id = id++;
      marker.type = visualization_msgs::Marker::SPHERE;
      marker.scale.x = 1.0;
      marker.scale.y = 1.0;
      marker.scale.z = 1.0;
      marker.color.g = 1.0;
      marker.color.b = 1.0;
      marker.color.a = 1.0;
      marker_array_msg.markers.push_back(marker);
    }

    v_cloud_cluster.at(obj_indices.at(i)).bounding_box.value
      = obj_label.obj_id.at(i);
    pub_msg.boxes.push_back(bounding_box);
    cloud_clusters_msg.clusters.push_back(
      v_cloud_cluster.at(obj_indices.at(i)));
  }

  marker_array_pub.publish(marker_array_msg);
  obj_pose_pub.publish(pub_msg);
  cluster_class_pub.publish(cloud_clusters_msg);
  std_msgs::Time time;
  time.data = obj_pose_timestamp;
  obj_pose_timestamp_pub.publish(time);
}

int main(int argc, char *argv[]) {
  /* ROS initialization */
  ros::init(argc, argv, &quot;obj_fusion&quot;);

  ros::NodeHandle n;
  ros::NodeHandle private_n(&quot;~&quot;);

  private_n.param(&quot;min_dist&quot;, threshold_min_dist, 2.0);
  private_n.param(&quot;use_vmap&quot;, use_vmap, true);
  private_n.param(&quot;vmap_threshold&quot;, vmap_threshold, 5.0);
  vmap_threshold *= vmap_threshold; // squared

  typedef message_filters::sync_policies::ApproximateTime&lt;
    autoware_msgs::obj_label, autoware_msgs::CloudClusterArray&gt; SyncPolicy;
  message_filters::Subscriber&lt;autoware_msgs::obj_label&gt; obj_label_sub(
    n, &quot;obj_label&quot;, SUBSCRIBE_QUEUE_SIZE);
  message_filters::Subscriber&lt;autoware_msgs::CloudClusterArray&gt; cluster_centroids_sub(
    n, &quot;/cloud_clusters&quot;, SUBSCRIBE_QUEUE_SIZE);
  message_filters::Synchronizer&lt;SyncPolicy&gt; sync(
    SyncPolicy(SUBSCRIBE_QUEUE_SIZE), obj_label_sub, cluster_centroids_sub);
  sync.registerCallback(boost::bind(&amp;fusion_cb, _1, _2));

  obj_pose_pub = n.advertise&lt;jsk_recognition_msgs::BoundingBoxArray&gt;(
      &quot;obj_pose&quot;, ADVERTISE_QUEUE_SIZE, ADVERTISE_LATCH);
  cluster_class_pub = n.advertise&lt;autoware_msgs::CloudClusterArray&gt;(
      &quot;/cloud_clusters_class&quot;, ADVERTISE_QUEUE_SIZE);
  obj_pose_timestamp_pub =
      n.advertise&lt;std_msgs::Time&gt;(&quot;obj_pose_timestamp&quot;, ADVERTISE_QUEUE_SIZE);
  marker_array_pub = n.advertise&lt;visualization_msgs::MarkerArray&gt;(&quot;obj_pose_arrow&quot;, 1, true);
  vmap_server = n.serviceClient&lt;vector_map_server::GetLane&gt;(&quot;/vector_map_server/get_lane&quot;);
  vmap.subscribe(n, vector_map::Category::POINT | vector_map::Category::NODE,
                 ros::Duration(0)); // non-blocking

  ros::spin();

  return 0;
}
</old_file>
			</file>
		</modified_files>
	</commit>
	<commit hash="2f215effe591e992383f02745da8f8b3e7ea1d6c" fix_time="61,8059">
		<msg>revise bugs in planninghelpers.cpp</msg>
		<modified_files>
			<file old_path="ros/src/computing/planning/common/lib/openplanner/op_planner/src/PlanningHelpers.cpp" new_path="ros/src/computing/planning/common/lib/openplanner/op_planner/src/PlanningHelpers.cpp">
				<diff>@@ -1391,7 +1391,7 @@ WayPoint* PlanningHelpers::BuildPlanningSearchTreeV2(WayPoint* pStart,
 
 				wp-&gt;cost = pH-&gt;cost + d;
 				wp-&gt;pRight = pH;
-				wp-&gt;pRight = 0;
+				wp-&gt;pLeft = 0;
 
 				nextLeafToTrace.push_back(make_pair(pH, wp));
 				all_cells_to_delete.push_back(wp);
</diff>
				<old_file>/*
 * PlanningHelpers.cpp
 *
 *  Created on: Jun 16, 2016
 *      Author: hatem
 */

#include &quot;PlanningHelpers.h&quot;
#include &quot;MatrixOperations.h&quot;
#include &lt;string&gt;
//#include &quot;spline.hpp&quot;



using namespace UtilityHNS;
using namespace std;



namespace PlannerHNS {



PlanningHelpers::PlanningHelpers()
{
}

PlanningHelpers::~PlanningHelpers()
{
}

bool PlanningHelpers::GetRelativeInfoRange(const std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; trajectories, const WayPoint&amp; p,const double&amp; searchDistance, RelativeInfo&amp; info)
{
	if(trajectories.size() == 0) return false;

	vector&lt;RelativeInfo&gt; infos;
	for(unsigned int i=0; i &lt; trajectories.size(); i++)
	{
		RelativeInfo info_item;
		GetRelativeInfo(trajectories.at(i), p, info_item);
		double angle_diff = UtilityH::AngleBetweenTwoAnglesPositive(info_item.perp_point.pos.a, p.pos.a)*RAD2DEG;
		if(angle_diff &lt; 75)
		{
			info_item.iGlobalPath = i;
			infos.push_back(info_item);
		}
	}

	if(infos.size() == 0)
		return false;
	else if(infos.size() == 1)
	{
		info = infos.at(0);
		return true;
	}

	double minCost = 9999999999;
	int min_index = 0;

	for(unsigned int i=0 ; i&lt; infos.size(); i++)
	{
		if(searchDistance &gt; 0)
		{
			double laneChangeCost = trajectories.at(infos.at(i).iGlobalPath).at(infos.at(i).iFront).laneChangeCost;
			if(fabs(infos.at(i).perp_distance) &lt; searchDistance &amp;&amp; laneChangeCost &lt; minCost)
			{
				min_index = i;
				minCost = laneChangeCost;
			}
		}
		else
		{
			if(fabs(infos.at(i).perp_distance) &lt; minCost)
			{
				min_index = i;
				minCost = infos.at(i).perp_distance;
			}
		}
	}

	info = infos.at(min_index);

	return true;
}

bool PlanningHelpers::GetRelativeInfo(const std::vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p, RelativeInfo&amp; info, const int&amp; prevIndex )
{
	if(trajectory.size() &lt; 2) return false;

	WayPoint p0, p1;
	if(trajectory.size()==2)
	{
		p0 = trajectory.at(0);
		p1 = WayPoint((trajectory.at(0).pos.x+trajectory.at(1).pos.x)/2.0,
					  (trajectory.at(0).pos.y+trajectory.at(1).pos.y)/2.0,
					  (trajectory.at(0).pos.z+trajectory.at(1).pos.z)/2.0, trajectory.at(0).pos.a);
		info.iFront = 1;
		info.iBack = 0;
	}
	else
	{
		info.iFront = GetClosestNextPointIndex(trajectory, p, prevIndex);

		if(info.iFront &gt; 0)
			info.iBack = info.iFront -1;
		else
			info.iBack = 0;

		if(info.iFront == 0)
		{
			p0 = trajectory.at(info.iFront);
			p1 = trajectory.at(info.iFront+1);
		}
		else if(info.iFront &gt; 0 &amp;&amp; info.iFront &lt; trajectory.size()-1)
		{
			p0 = trajectory.at(info.iFront-1);
			p1 = trajectory.at(info.iFront);
		}
		else
		{
			p0 = trajectory.at(info.iFront-1);
			p1 = WayPoint((p0.pos.x+trajectory.at(info.iFront).pos.x)/2.0, (p0.pos.y+trajectory.at(info.iFront).pos.y)/2.0, (p0.pos.z+trajectory.at(info.iFront).pos.z)/2.0, p0.pos.a);
		}
	}

	WayPoint prevWP = p0;
	Mat3 rotationMat(-p1.pos.a);
	Mat3 translationMat(-p.pos.x, -p.pos.y);
	Mat3 invRotationMat(p1.pos.a);
	Mat3 invTranslationMat(p.pos.x, p.pos.y);

	p0.pos = translationMat*p0.pos;
	p0.pos = rotationMat*p0.pos;

	p1.pos = translationMat*p1.pos;
	p1.pos = rotationMat*p1.pos;

	double m = (p1.pos.y-p0.pos.y)/(p1.pos.x-p0.pos.x);
	info.perp_distance = p1.pos.y - m*p1.pos.x; // solve for x = 0

	if(isnan(info.perp_distance) || isinf(info.perp_distance)) info.perp_distance = 0;

	info.to_front_distance = fabs(p1.pos.x); // distance on the x axes


	info.perp_point = p1;
	info.perp_point.pos.x = 0; // on the same y axis of the car
	info.perp_point.pos.y = info.perp_distance; //perp distance between the car and the trajectory

	info.perp_point.pos = invRotationMat  * info.perp_point.pos;
	info.perp_point.pos = invTranslationMat  * info.perp_point.pos;

	info.from_back_distance = hypot(info.perp_point.pos.y - prevWP.pos.y, info.perp_point.pos.x - prevWP.pos.x);

	info.angle_diff = UtilityH::AngleBetweenTwoAnglesPositive(p1.pos.a, p.pos.a)*RAD2DEG;

	return true;
}

WayPoint PlanningHelpers::GetFollowPointOnTrajectory(const std::vector&lt;WayPoint&gt;&amp; trajectory, const RelativeInfo&amp; init_p, const double&amp; distance, unsigned int&amp; point_index)
{
	WayPoint follow_point;

	if(trajectory.size()==0) return follow_point;

	//condition 1, if far behind the first point on the trajectory
	int local_i = init_p.iFront;

	if(init_p.iBack == 0 &amp;&amp; init_p.iBack == init_p.iFront &amp;&amp; init_p.from_back_distance &gt; distance)
	{
		follow_point = trajectory.at(init_p.iFront);
		follow_point.pos.x = init_p.perp_point.pos.x + distance * cos(follow_point.pos.a);
		follow_point.pos.y = init_p.perp_point.pos.y + distance * sin(follow_point.pos.a);
	}
	//condition 2, if far after the last point on the trajectory
	else if(init_p.iFront == trajectory.size() -1)
	{
		follow_point = trajectory.at(init_p.iFront);
		follow_point.pos.x = init_p.perp_point.pos.x + distance * cos(follow_point.pos.a);
		follow_point.pos.y = init_p.perp_point.pos.y + distance * sin(follow_point.pos.a);
	}
	else
	{
		double d = init_p.to_front_distance;
		while(local_i &lt; trajectory.size()-1 &amp;&amp; d &lt; distance)
		{
			local_i++;
			d += hypot(trajectory.at(local_i).pos.y - trajectory.at(local_i-1).pos.y, trajectory.at(local_i).pos.x - trajectory.at(local_i-1).pos.x);
		}

		double d_part = distance - d;

		follow_point = trajectory.at(local_i);
		follow_point.pos.x = follow_point.pos.x + d_part * cos(follow_point.pos.a);
		follow_point.pos.y = follow_point.pos.y + d_part * sin(follow_point.pos.a);
	}

	point_index = local_i;

	return follow_point;
}

double PlanningHelpers::GetExactDistanceOnTrajectory(const std::vector&lt;WayPoint&gt;&amp; trajectory, const RelativeInfo&amp; p1,const RelativeInfo&amp; p2)
{
	if(trajectory.size() == 0) return 0;

	if(p2.iFront == p1.iFront &amp;&amp; p2.iBack == p1.iBack)
	{
		return p2.to_front_distance - p1.to_front_distance;
	}
	else if(p2.iBack &gt;= p1.iFront)
	{
		double d_on_path = p1.to_front_distance + p2.from_back_distance;
		for(unsigned int i = p1.iFront; i &lt; p2.iBack; i++)
			d_on_path += hypot(trajectory.at(i+1).pos.y - trajectory.at(i).pos.y, trajectory.at(i+1).pos.x - trajectory.at(i).pos.x);

		return d_on_path;
	}
	else if(p2.iFront &lt;= p1.iBack)
	{
		double d_on_path = p1.from_back_distance + p2.to_front_distance;
		for(unsigned int i = p2.iFront; i &lt; p1.iBack; i++)
			d_on_path += hypot(trajectory.at(i+1).pos.y - trajectory.at(i).pos.y, trajectory.at(i+1).pos.x - trajectory.at(i).pos.x);

		return -d_on_path;
	}
	else
	{
		return 0;
	}
}

int PlanningHelpers::GetClosestNextPointIndex(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p,const int&amp; prevIndex )
{
	if(trajectory.size() == 0 || prevIndex &lt; 0) return 0;

	double d = 0, minD = 9999999999;
	int min_index  = prevIndex;

	for(unsigned int i=prevIndex; i&lt; trajectory.size(); i++)
	{
		d  = distance2pointsSqr(trajectory.at(i).pos, p.pos);
		if(d &lt; minD)
		{
			min_index = i;
			minD = d;
		}
	}

	if(min_index &lt; (int)trajectory.size()-2)
	{
		GPSPoint curr, next;
		curr = trajectory.at(min_index).pos;
		next = trajectory.at(min_index+1).pos;
		POINT2D v_1(p.pos.x - curr.x   ,p.pos.y - curr.y);
		double norm1 = pointNorm(v_1);
		POINT2D v_2(next.x - curr.x,next.y - curr.y);
		double norm2 = pointNorm(v_2);
		double dot_pro = v_1.x*v_2.x + v_1.y*v_2.y;
		double a = UtilityH::FixNegativeAngle(acos(dot_pro/(norm1*norm2)));
		if(a &lt;= M_PI_2)
			min_index = min_index+1;
	}

	return min_index;
}

int PlanningHelpers::GetClosestNextPointIndexDirection(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p,const int&amp; prevIndex )
{
	if(trajectory.size() == 0 || prevIndex &lt; 0) return 0;

	double d = 0, minD = 9999999999;
	int min_index  = prevIndex;

	for(unsigned int i=prevIndex; i&lt; trajectory.size(); i++)
	{
		d  = distance2pointsSqr(trajectory.at(i).pos, p.pos);
		double angle_diff = UtilityH::AngleBetweenTwoAnglesPositive(trajectory.at(i).pos.a, p.pos.a)*RAD2DEG;

		if(d &lt; minD &amp;&amp; angle_diff &lt; 45)
		{
			min_index = i;
			minD = d;
		}
	}

	if(min_index &lt; (int)trajectory.size()-2)
	{
		GPSPoint curr, next;
		curr = trajectory.at(min_index).pos;
		next = trajectory.at(min_index+1).pos;
		POINT2D v_1(p.pos.x - curr.x   ,p.pos.y - curr.y);
		double norm1 = pointNorm(v_1);
		POINT2D v_2(next.x - curr.x,next.y - curr.y);
		double norm2 = pointNorm(v_2);
		double dot_pro = v_1.x*v_2.x + v_1.y*v_2.y;
		double a = UtilityH::FixNegativeAngle(acos(dot_pro/(norm1*norm2)));
		if(a &lt;= M_PI_2)
			min_index = min_index+1;
	}

	return min_index;
}

int PlanningHelpers::GetClosestPointIndex_obsolete(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p,const int&amp; prevIndex )
{
	if(trajectory.size() == 0 || prevIndex &lt; 0) return 0;

	double d = 0, minD = 9999999999;
	int min_index  = prevIndex;

	for(unsigned int i=prevIndex; i&lt; trajectory.size(); i++)
	{
		d  = distance2pointsSqr(trajectory.at(i).pos, p.pos);
		if(d &lt; minD)
		{
			min_index = i;
			minD = d;
		}
	}

	return min_index;
}

WayPoint PlanningHelpers::GetPerpendicularOnTrajectory_obsolete(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p, double&amp; distance, const int&amp; prevIndex )
{
	if(trajectory.size() &lt; 2) return p;

	WayPoint p0, p1, p2, perp;
	if(trajectory.size()==2)
	{
		p0 = trajectory.at(0);
		p1 = WayPoint((trajectory.at(0).pos.x+trajectory.at(1).pos.x)/2.0,
					  (trajectory.at(0).pos.y+trajectory.at(1).pos.y)/2.0,
					  (trajectory.at(0).pos.z+trajectory.at(1).pos.z)/2.0, trajectory.at(0).pos.a);
		p2 = trajectory.at(1);
	}
	else
	{
		int next_index = GetClosestNextPointIndex(trajectory, p, prevIndex);

		if(next_index == 0)
		{
			p0 = trajectory[next_index];
			p1 = trajectory[next_index+1];
			p2 = trajectory[next_index+2];
		}
		else if(next_index &gt; 0 &amp;&amp; next_index &lt; trajectory.size()-1)
		{
			p0 = trajectory[next_index-1];
			p1 = trajectory[next_index];
			p2 = trajectory[next_index+1];
		}
		else
		{
			p0 = trajectory[next_index-1];
			p2 = trajectory[next_index];

			p1 = WayPoint((p0.pos.x+p2.pos.x)/2.0, (p0.pos.y+p2.pos.y)/2.0, (p0.pos.z+p2.pos.z)/2.0, p0.pos.a);

		}
	}

	Mat3 rotationMat(-p1.pos.a);
	Mat3 translationMat(-p.pos.x, -p.pos.y);
	Mat3 invRotationMat(p1.pos.a);
	Mat3 invTranslationMat(p.pos.x, p.pos.y);

	p0.pos = translationMat*p0.pos;
	p0.pos = rotationMat*p0.pos;

	p1.pos = translationMat*p1.pos;
	p1.pos = rotationMat*p1.pos;

	p2.pos = translationMat*p2.pos;
	p2.pos= rotationMat*p2.pos;

	double m = (p1.pos.y-p0.pos.y)/(p1.pos.x-p0.pos.x);
	double d = p1.pos.y - m*p1.pos.x; // solve for x = 0
	distance = p1.pos.x; // distance on the x axes

	perp = p1;
	perp.pos.x = 0; // on the same y axis of the car
	perp.pos.y = d; //perp distance between the car and the trajectory

	perp.pos = invRotationMat  * perp.pos;
	perp.pos = invTranslationMat  * perp.pos;

	return perp;
}

double PlanningHelpers::GetPerpDistanceToTrajectorySimple_obsolete(const vector&lt;WayPoint&gt;&amp; trajectory, const WayPoint&amp; p,const int&amp; prevIndex)
{

	if(trajectory.size() &lt; 2)
		return 0;

	WayPoint p0, p1, p2;
	int next_index = 0;
	if(trajectory.size()==2)
	{
		p0 = trajectory.at(0);
		p2 = trajectory.at(1);
		p1 = WayPoint((p0.pos.x+p2.pos.x)/2.0, (p0.pos.y+p2.pos.y)/2.0, (p0.pos.z+p2.pos.z)/2.0, p0.pos.a);

	}
	else
	{
		next_index = GetClosestNextPointIndex(trajectory, p, prevIndex);
		if(next_index == 0)
		{
			p0 = trajectory[next_index];
			p1 = trajectory[next_index+1];
			p2 = trajectory[next_index+2];
		}
		else if(next_index &gt; 0 &amp;&amp; next_index &lt; trajectory.size()-1)
		{
			p0 = trajectory[next_index-1];
			p1 = trajectory[next_index];
			p2 = trajectory[next_index+1];
		}
		else
		{
			p0 = trajectory[next_index-1];
			p2 = trajectory[next_index];

			p1 = WayPoint((p0.pos.x+p2.pos.x)/2.0, (p0.pos.y+p2.pos.y)/2.0, (p0.pos.z+p2.pos.z)/2.0, p0.pos.a);

		}

	}


	Mat3 rotationMat(-p1.pos.a);
	Mat3 translationMat(-p.pos.x, -p.pos.y);

	p0.pos = translationMat*p0.pos;
	p0.pos = rotationMat*p0.pos;

	p1.pos = translationMat*p1.pos;
	p1.pos = rotationMat*p1.pos;

	p2.pos = translationMat*p2.pos;
	p2.pos = rotationMat*p2.pos;

	double m = (p1.pos.y-p0.pos.y)/(p1.pos.x-p0.pos.x);
	double d = p1.pos.y - m*p1.pos.x;

	if(isnan(d) || isinf(d))
	{
	  //assert(false);
	  d = 0;
	}

	return d;
}

double PlanningHelpers::GetPerpDistanceToVectorSimple_obsolete(const WayPoint&amp; point1, const WayPoint&amp; point2, const WayPoint&amp; pose)
{
	WayPoint p1 = point1, p2 = point2;
	Mat3 rotationMat(-p1.pos.a);
	Mat3 translationMat(-pose.pos.x, -pose.pos.y);

	p1.pos = translationMat*p1.pos;
	p1.pos = rotationMat*p1.pos;

	p2.pos = translationMat*p2.pos;
	p2.pos = rotationMat*p2.pos;

	double m = (p2.pos.y-p1.pos.y)/(p2.pos.x-p1.pos.x);
	double d = p2.pos.y - m*p2.pos.x;

	if(isnan(d) || isinf(d))
	{
	  //assert(false);
	  d = 0;
	}

	return d;
}

WayPoint PlanningHelpers::GetNextPointOnTrajectory_obsolete(const vector&lt;WayPoint&gt;&amp; trajectory, const double&amp; distance, const int&amp; currIndex)
{
	assert(trajectory.size()&gt;0);

	int local_currIndex = currIndex;

	if(local_currIndex &lt; 0 || local_currIndex &gt;= trajectory.size())
		return trajectory.at(0);

	WayPoint p1 = trajectory.at(local_currIndex);
	WayPoint p2;

	double d = 0;
	while(local_currIndex &lt; (trajectory.size()-1) &amp;&amp; d &lt; distance)
	{
		local_currIndex++;
		p2 = p1;
		p1 = trajectory.at(local_currIndex);
		d += distance2points(p1.pos, p2.pos);
	}

	if(local_currIndex &gt;= trajectory.size()-1)
	  return p1;

	double distance_diff = distance -  d;

	p2 = trajectory.at(local_currIndex);
	p1 = trajectory.at(local_currIndex+1);

	POINT2D uv(p1.pos.x - p2.pos.x, p1.pos.y - p2.pos.y);
	double v_norm = pointNorm(uv);

	assert(v_norm != 0);

	uv.x = (uv.x / v_norm) * distance_diff;
	uv.y = (uv.y / v_norm) * distance_diff;

	double ydiff = p1.pos.y-p2.pos.y;
	double xdiff = p1.pos.x-p2.pos.x;
	double a =  atan2(ydiff,xdiff);

	WayPoint abs_waypoint = p2;

	abs_waypoint.pos.x = p2.pos.x + uv.x;
	abs_waypoint.pos.y = p2.pos.y + uv.y;
	abs_waypoint.pos.a = a;

	return abs_waypoint;
}

double PlanningHelpers::GetDistanceOnTrajectory_obsolete(const std::vector&lt;WayPoint&gt;&amp; path, const int&amp; start_index, const WayPoint&amp; p)
{

	int end_point_index = GetClosestPointIndex_obsolete(path, p);
	if(end_point_index &gt; 0)
		end_point_index--;

	double padding_distance = distance2points(path.at(end_point_index).pos, p.pos);

	double d_on_path = 0;
	if(end_point_index &gt;= start_index)
	{
		for(unsigned int i = start_index; i &lt; end_point_index; i++)
			d_on_path += distance2points(path.at(i).pos, path.at(i+1).pos);

		d_on_path += padding_distance;
	}
	else
	{
		for(unsigned int i = start_index; i &gt; end_point_index; i--)
			d_on_path -= distance2points(path.at(i).pos, path.at(i-1).pos);
	}

	return d_on_path;
}

bool PlanningHelpers::CompareTrajectories(const std::vector&lt;WayPoint&gt;&amp; path1, const std::vector&lt;WayPoint&gt;&amp; path2)
{
	if(path1.size() != path2.size())
		return false;

	for(unsigned int i=0; i&lt; path1.size(); i++)
	{
		if(path1.at(i).v != path2.at(i).v || path1.at(i).pos.x != path2.at(i).pos.x || path1.at(i).pos.y != path2.at(i).pos.y || path1.at(i).pos.alt != path2.at(i).pos.alt || path1.at(i).pos.lon != path2.at(i).pos.lon)
			return false;
	}

	return true;
}

double PlanningHelpers::GetDistanceToClosestStopLineAndCheck(const std::vector&lt;WayPoint&gt;&amp; path, const WayPoint&amp; p, int&amp; stopLineID, int&amp; stopSignID, int&amp; trafficLightID, const int&amp; prevIndex)
{

//	trafficLightID = stopSignID = stopLineID = -1;
//
//	RelativeInfo info;
//	GetRelativeInfo(path, p, info);
//
//	for(unsigned int i=info.iBack; i&lt;path.size(); i++)
//	{
//		if(path.at(i).pLane &amp;&amp; path.at(i).pLane-&gt;stopLines.size() &gt; 0)
//		{
//			stopSignID = path.at(i).pLane-&gt;stopLines.at(0).stopSignID;
//			trafficLightID = path.at(i).pLane-&gt;stopLines.at(0).trafficLightID;
//			return 1;
////			for(unsigned int j = 0; j &lt; path.at(i).pLane-&gt;stopLines.size(); j++)
////			{
////				RelativeInfo local_info;
////				WayPoint stopLineWP;
////				stopLineWP.pos = path.at(i).pLane-&gt;stopLines.at(j).points.at(0);
////
////				GetRelativeInfo(path, stopLineWP, local_info, i);
////
////				double d = GetExactDistanceOnTrajectory(path, info, local_info);
////				if(d &gt; 0)
////				{
////						stopSignID = path.at(i).pLane-&gt;stopLines.at(j).stopSignID;
////						trafficLightID = path.at(i).pLane-&gt;stopLines.at(j).trafficLightID;
////						return d;
////				}
////			}
//		}
//	}

	trafficLightID = stopSignID = stopLineID = -1;

	RelativeInfo info;
	GetRelativeInfo(path, p, info, prevIndex);

	for(unsigned int i=info.iBack; i&lt;path.size(); i++)
	{
		if(path.at(i).stopLineID &gt; 0 &amp;&amp; path.at(i).pLane)
		{
			for(unsigned int j = 0; j &lt; path.at(i).pLane-&gt;stopLines.size(); j++)
			{
				if(path.at(i).pLane-&gt;stopLines.at(j).id == path.at(i).stopLineID)
				{
					stopLineID = path.at(i).stopLineID;

					RelativeInfo stop_info;
					WayPoint stopLineWP ;
					stopLineWP.pos = path.at(i).pLane-&gt;stopLines.at(j).points.at(0);
					GetRelativeInfo(path, stopLineWP, stop_info);
					double localDistance = GetExactDistanceOnTrajectory(path, info, stop_info);

					if(localDistance&gt;0)
					{
						stopSignID = path.at(i).pLane-&gt;stopLines.at(j).stopSignID;
						trafficLightID = path.at(i).pLane-&gt;stopLines.at(j).trafficLightID;
						return localDistance;
					}
				}
			}
		}
	}

	return -1;
}

void PlanningHelpers::FixPathDensity(vector&lt;WayPoint&gt;&amp; path, const double&amp; distanceDensity)
{
	if(path.size() == 0 || distanceDensity==0) return;

	double d = 0, a = 0;
	double margin = distanceDensity*0.01;
	double remaining = 0;
	int nPoints = 0;
	vector&lt;WayPoint&gt; fixedPath;
	fixedPath.push_back(path.at(0));
	for(unsigned int si = 0, ei=1; ei &lt; path.size(); )
	{
		d += hypot(path.at(ei).pos.x- path.at(ei-1).pos.x, path.at(ei).pos.y- path.at(ei-1).pos.y) + remaining;
		a = atan2(path.at(ei).pos.y - path.at(si).pos.y, path.at(ei).pos.x - path.at(si).pos.x);

		if(d &lt; distanceDensity - margin ) // skip
		{
			ei++;
			remaining = 0;
		}
		else if(d &gt; (distanceDensity +  margin)) // skip
		{
			WayPoint pm = path.at(si);
			nPoints = d  / distanceDensity;
			for(int k = 0; k &lt; nPoints; k++)
			{
				pm.pos.x = pm.pos.x + distanceDensity * cos(a);
				pm.pos.y = pm.pos.y + distanceDensity * sin(a);
				fixedPath.push_back(pm);
			}
			remaining = d - nPoints*distanceDensity;
			si++;
			path.at(si).pos = pm.pos;
			d = 0;
			ei++;
		}
		else
		{
			d = 0;
			remaining = 0;
			fixedPath.push_back(path.at(ei));
			ei++;
			si = ei - 1;
		}
	}

	path = fixedPath;
}

void PlanningHelpers::SmoothPath(vector&lt;WayPoint&gt;&amp; path, double weight_data,
		double weight_smooth, double tolerance)
{

	if (path.size() &lt;= 2 )
	{
		cout &lt;&lt; &quot;Can't Smooth Path, Path_in Size=&quot; &lt;&lt; path.size() &lt;&lt; endl;
		return;
	}

	const vector&lt;WayPoint&gt;&amp; path_in = path;
	vector&lt;WayPoint&gt; smoothPath_out =  path_in;

	double change = tolerance;
	double xtemp, ytemp;
	int nIterations = 0;

	int size = path_in.size();

	while (change &gt;= tolerance)
	{
		change = 0.0;
		for (int i = 1; i &lt; size - 1; i++)
		{
//			if (smoothPath_out[i].pos.a != smoothPath_out[i - 1].pos.a)
//				continue;

			xtemp = smoothPath_out[i].pos.x;
			ytemp = smoothPath_out[i].pos.y;

			smoothPath_out[i].pos.x += weight_data
					* (path_in[i].pos.x - smoothPath_out[i].pos.x);
			smoothPath_out[i].pos.y += weight_data
					* (path_in[i].pos.y - smoothPath_out[i].pos.y);

			smoothPath_out[i].pos.x += weight_smooth
					* (smoothPath_out[i - 1].pos.x + smoothPath_out[i + 1].pos.x
							- (2.0 * smoothPath_out[i].pos.x));
			smoothPath_out[i].pos.y += weight_smooth
					* (smoothPath_out[i - 1].pos.y + smoothPath_out[i + 1].pos.y
							- (2.0 * smoothPath_out[i].pos.y));

			change += fabs(xtemp - smoothPath_out[i].pos.x);
			change += fabs(ytemp - smoothPath_out[i].pos.y);

		}
		nIterations++;
	}

	path = smoothPath_out;
}

//double PlanningHelpers::CalcAngleAndCostSimple(vector&lt;WayPoint&gt;&amp; path, const double&amp; lastCost)
//{
//	if(path.size() &lt;= 2) return 0;
//
//	path[0].pos.a = atan2(path[1].pos.y - path[0].pos.y, path[1].pos.x - path[0].pos.x );
//	path[0].cost = lastCost;
//
//	for(int j = 1; j &lt; path.size()-1; j++)
//	{
//		path[j].pos.a 	= atan2(path[j+1].pos.y - path[j].pos.y, path[j+1].pos.x - path[j].pos.x );
//		path[j].cost 	= path[j-1].cost +  hypot(path[j-1].pos.y- path[j].pos.y, path[j-1].pos.x- path[j].pos.x);
//	}
//
//	int j = (int)path.size()-1;
//
//	path[j].pos.a 	= path[j-1].pos.a;
//	path[j].cost 	= path[j-1].cost + hypot(path[j-1].pos.y- path[j].pos.y, path[j-1].pos.x- path[j].pos.x);
//
//	for(int j = 0; j &lt; path.size()-1; j++)
//	{
//		if(path.at(j).pos.x == path.at(j+1).pos.x &amp;&amp; path.at(j).pos.y == path.at(j+1).pos.y)
//			path.at(j).pos.a = path.at(j+1).pos.a;
//	}
//
//	return path[j].cost;
//}

double PlanningHelpers::CalcAngleAndCost(vector&lt;WayPoint&gt;&amp; path, const double&amp; lastCost, const bool&amp; bSmooth)
{
	if(path.size() &lt;= 2) return 0;

	path[0].pos.a = UtilityH::FixNegativeAngle(atan2(path[1].pos.y - path[0].pos.y, path[1].pos.x - path[0].pos.x ));
	path[0].cost = lastCost;

	for(int j = 1; j &lt; path.size()-1; j++)
	{
		path[j].pos.a 		= UtilityH::FixNegativeAngle(atan2(path[j+1].pos.y - path[j].pos.y, path[j+1].pos.x - path[j].pos.x ));
		path[j].cost 	= path[j-1].cost +  distance2points(path[j-1].pos, path[j].pos);
	}

	int j = (int)path.size()-1;

	path[j].pos.a 		= path[j-1].pos.a;
	path[j].cost 	= path[j-1].cost + distance2points(path[j-1].pos, path[j].pos);

	for(int j = 0; j &lt; path.size()-1; j++)
	{
		if(path.at(j).pos.x == path.at(j+1).pos.x &amp;&amp; path.at(j).pos.y == path.at(j+1).pos.y)
			path.at(j).pos.a = path.at(j+1).pos.a;
	}

	return path[j].cost;
}

double PlanningHelpers::CalcAngleAndCostAndCurvatureAnd2D(vector&lt;WayPoint&gt;&amp; path, const double&amp; lastCost)
{
	path[0].pos.a 	= atan2(path[1].pos.y - path[0].pos.y, path[1].pos.x - path[0].pos.x );
	path[0].cost 	= lastCost;

	double k = 0;
	GPSPoint center;

	for(unsigned int j = 1; j &lt; path.size()-1; j++)
	{
		k =  CalcCircle(path[j-1].pos,path[j].pos, path[j+1].pos, center);
		if(k &gt; 150.0 || isnan(k))
			k = 150.0;

		if(k&lt;1.0)
			path[j].cost = 0;
		else
			path[j].cost = 1.0-1.0/k;

		path[j].pos.a 	= atan2(path[j+1].pos.y - path[j].pos.y, path[j+1].pos.x - path[j].pos.x );
	}
	unsigned int j = path.size()-1;

	path[0].cost    = path[1].cost;
	path[j].cost 	= path[j-1].cost;
	path[j].pos.a 	= path[j-1].pos.a;
	path[j].cost 	= path[j-1].cost ;

	return path[j].cost;
}

double PlanningHelpers::CalcCircle(const GPSPoint&amp; pt1, const GPSPoint&amp; pt2, const GPSPoint&amp; pt3, GPSPoint&amp; center)
{
	double yDelta_a= pt2.y - pt1.y;
	double xDelta_a= pt2.x - pt1.x;
	double yDelta_b= pt3.y - pt2.y;
	double xDelta_b= pt3.x - pt2.x;

	if (fabs(xDelta_a) &lt;= 0.000000000001 &amp;&amp; fabs(yDelta_b) &lt;= 0.000000000001)
	{
		center.x= 0.5*(pt2.x + pt3.x);
		center.y= 0.5*(pt1.y + pt2.y);
		return distance2points(center,pt1);
	}

	double aSlope=yDelta_a/xDelta_a;
	double bSlope=yDelta_b/xDelta_b;
	if (fabs(aSlope-bSlope) &lt;= 0.000000000001)
	{
		return 100000;
	}

	center.x= (aSlope*bSlope*(pt1.y - pt3.y) + bSlope*(pt1.x + pt2 .x) - aSlope*(pt2.x+pt3.x) )/(2.0* (bSlope-aSlope) );
	center.y = -1.0*(center.x - (pt1.x+pt2.x)/2.0)/aSlope +  (pt1.y+pt2.y)/2.0;

	return  distance2points(center,pt1);
}

void PlanningHelpers::ExtractPartFromPointToDistance(const vector&lt;WayPoint&gt;&amp; originalPath, const WayPoint&amp; pos, const double&amp; minDistance,
		const double&amp; pathDensity, vector&lt;WayPoint&gt;&amp; extractedPath, const double&amp; SmoothDataWeight, const double&amp; SmoothWeight, const double&amp; SmoothTolerance)
{
	extractedPath.clear();
	unsigned int close_index = GetClosestNextPointIndexDirection(originalPath, pos);
	vector&lt;WayPoint&gt; tempPath;
	double d_limit = 0;
	if(close_index &gt;= 5) close_index -=5;
	else close_index = 0;

	for(unsigned int i=close_index; i&lt; originalPath.size(); i++)
	{
		tempPath.push_back(originalPath.at(i));

		if(i&gt;0)
			d_limit += hypot(originalPath.at(i).pos.y - originalPath.at(i-1).pos.y, originalPath.at(i).pos.x - originalPath.at(i-1).pos.x);

		if(d_limit &gt; minDistance)
			break;
	}

	if(tempPath.size() &lt; 2)
	{
		cout &lt;&lt; endl &lt;&lt; &quot;### Planner Z . Extracted Rollout Path is too Small, Size = &quot; &lt;&lt; tempPath.size() &lt;&lt; endl;
		return;
	}

	FixPathDensity(tempPath, pathDensity);
	SmoothPath(tempPath, SmoothDataWeight, SmoothWeight , SmoothTolerance);
	CalcAngleAndCost(tempPath);

	extractedPath = tempPath;
	//tempPath.clear();
	//TestQuadraticSpline(extractedPath, tempPath);
}

void PlanningHelpers::CalculateRollInTrajectories(const WayPoint&amp; carPos, const double&amp; speed, const vector&lt;WayPoint&gt;&amp; originalCenter, int&amp; start_index,
		int&amp; end_index, vector&lt;double&gt;&amp; end_laterals ,
		vector&lt;vector&lt;WayPoint&gt; &gt;&amp; rollInPaths, const double&amp; max_roll_distance,
		const double&amp; maxSpeed, const double&amp;  carTipMargin, const double&amp; rollInMargin,
		const double&amp; rollInSpeedFactor, const double&amp; pathDensity, const double&amp; rollOutDensity,
		const int&amp; rollOutNumber, const double&amp; SmoothDataWeight, const double&amp; SmoothWeight,
		const double&amp; SmoothTolerance, const bool&amp; bHeadingSmooth,
		std::vector&lt;WayPoint&gt;&amp; sampledPoints)
{
	WayPoint p;
	double dummyd = 0;

	int iLimitIndex = (carTipMargin/0.3)/pathDensity;
	if(iLimitIndex &gt;= originalCenter.size())
		iLimitIndex = originalCenter.size() - 1;

	//Get Closest Index
	RelativeInfo info;
	GetRelativeInfo(originalCenter, carPos, info);
	double remaining_distance = 0;
	int close_index = info.iBack;
	for(unsigned int i=close_index; i&lt; originalCenter.size()-1; i++)
	  {
		if(i&gt;0)
			remaining_distance += distance2points(originalCenter[i].pos, originalCenter[i+1].pos);
	  }

	double initial_roll_in_distance = info.perp_distance ; //GetPerpDistanceToTrajectorySimple(originalCenter, carPos, close_index);


	vector&lt;WayPoint&gt; RollOutStratPath;
	///***   Smoothing From Car Heading Section ***///
//	if(bHeadingSmooth)
//	{
//		unsigned int num_of_strait_points = carTipMargin / pathDensity;
//		int closest_for_each_iteration = 0;
//		WayPoint np = GetPerpendicularOnTrajectory(originalCenter, rearPos, dummyd, closest_for_each_iteration);
//		np.pos = rearPos.pos;
//
//		RollOutStratPath.push_back(np);
//		for(unsigned int i = 0; i &lt; num_of_strait_points; i++)
//		{
//			p = RollOutStratPath.at(i);
//			p.pos.x = p.pos.x +  pathDensity*cos(p.pos.a);
//			p.pos.y = p.pos.y +  pathDensity*sin(p.pos.a);
//			np = GetPerpendicularOnTrajectory(originalCenter, p, dummyd, closest_for_each_iteration);
//			np.pos = p.pos;
//			RollOutStratPath.push_back(np);
//		}
//
//		initial_roll_in_distance = GetPerpDistanceToTrajectorySimple(originalCenter, RollOutStratPath.at(RollOutStratPath.size()-1), close_index);
//	}
	///***   -------------------------------- ***///


	//printf(&quot;\n Lateral Distance: %f&quot; , initial_roll_in_distance);

	//calculate the starting index
	double d_limit = 0;
	unsigned int far_index = close_index;

	//calculate end index
	double start_distance = rollInSpeedFactor*speed+rollInMargin;
	if(start_distance &gt; remaining_distance)
		start_distance = remaining_distance;

	d_limit = 0;
	for(unsigned int i=close_index; i&lt; originalCenter.size(); i++)
	  {
		  if(i&gt;0)
			  d_limit += distance2points(originalCenter[i].pos, originalCenter[i-1].pos);

		  if(d_limit &gt;= start_distance)
		  {
			  far_index = i;
			  break;
		  }
	  }

	int centralTrajectoryIndex = rollOutNumber/2;
	vector&lt;double&gt; end_distance_list;
	for(int i=0; i&lt; rollOutNumber+1; i++)
	  {
		  double end_roll_in_distance = rollOutDensity*(i - centralTrajectoryIndex);
		  end_distance_list.push_back(end_roll_in_distance);
	  }

	start_index = close_index;
	end_index = far_index;
	end_laterals = end_distance_list;

	//calculate the actual calculation starting index
	d_limit = 0;
	unsigned int smoothing_start_index = start_index;
	unsigned int smoothing_end_index = end_index;

	for(unsigned int i=smoothing_start_index; i&lt; originalCenter.size(); i++)
	{
		if(i &gt; 0)
			d_limit += distance2points(originalCenter[i].pos, originalCenter[i-1].pos);
		if(d_limit &gt; carTipMargin)
			break;

		smoothing_start_index++;
	}

	d_limit = 0;
	for(unsigned int i=end_index; i&lt; originalCenter.size(); i++)
	{
		if(i &gt; 0)
			d_limit += distance2points(originalCenter[i].pos, originalCenter[i-1].pos);
		if(d_limit &gt; carTipMargin)
			break;

		smoothing_end_index++;
	}

	int nSteps = end_index - smoothing_start_index;


	vector&lt;double&gt; inc_list;
	rollInPaths.clear();
	vector&lt;double&gt; inc_list_inc;
	for(int i=0; i&lt; rollOutNumber+1; i++)
	{
		double diff = end_laterals.at(i)-initial_roll_in_distance;
		inc_list.push_back(diff/(double)nSteps);
		rollInPaths.push_back(vector&lt;WayPoint&gt;());
		inc_list_inc.push_back(0);
	}



	vector&lt;vector&lt;WayPoint&gt; &gt; execluded_from_smoothing;
	for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
		execluded_from_smoothing.push_back(vector&lt;WayPoint&gt;());



	//Insert First strait points within the tip of the car range
	for(unsigned int j = start_index; j &lt; smoothing_start_index; j++)
	{
		p = originalCenter.at(j);
		double original_speed = p.v;
	  for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
	  {
		  p.pos.x = originalCenter.at(j).pos.x -  initial_roll_in_distance*cos(p.pos.a + M_PI_2);
		  p.pos.y = originalCenter.at(j).pos.y -  initial_roll_in_distance*sin(p.pos.a + M_PI_2);
		  if(i!=centralTrajectoryIndex)
			  p.v = original_speed * LANE_CHANGE_SPEED_FACTOR;
		  else
			  p.v = original_speed ;

		  if(j &lt; iLimitIndex)
			  execluded_from_smoothing.at(i).push_back(p);
		  else
			  rollInPaths.at(i).push_back(p);

		  sampledPoints.push_back(p);
	  }
	}

	for(unsigned int j = smoothing_start_index; j &lt; end_index; j++)
	  {
		  p = originalCenter.at(j);
		  double original_speed = p.v;
		  for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
		  {
			  inc_list_inc[i] += inc_list[i];
			  double d = inc_list_inc[i];
			  p.pos.x = originalCenter.at(j).pos.x -  initial_roll_in_distance*cos(p.pos.a + M_PI_2) - d*cos(p.pos.a+ M_PI_2);
			  p.pos.y = originalCenter.at(j).pos.y -  initial_roll_in_distance*sin(p.pos.a + M_PI_2) - d*sin(p.pos.a+ M_PI_2);
			  if(i!=centralTrajectoryIndex)
				  p.v = original_speed * LANE_CHANGE_SPEED_FACTOR;
			  else
				  p.v = original_speed ;

			  rollInPaths.at(i).push_back(p);

			  sampledPoints.push_back(p);
		  }
	  }

	//Insert last strait points to make better smoothing
	for(unsigned int j = end_index; j &lt; smoothing_end_index; j++)
	{
		p = originalCenter.at(j);
		double original_speed = p.v;
	  for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
	  {
		  double d = end_laterals.at(i);
		  p.pos.x  = originalCenter.at(j).pos.x - d*cos(p.pos.a + M_PI_2);
		  p.pos.y  = originalCenter.at(j).pos.y - d*sin(p.pos.a + M_PI_2);
		  if(i!=centralTrajectoryIndex)
			  p.v = original_speed * LANE_CHANGE_SPEED_FACTOR;
		  else
			  p.v = original_speed ;
		  rollInPaths.at(i).push_back(p);

		  sampledPoints.push_back(p);
	  }
	}

	for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
		rollInPaths.at(i).insert(rollInPaths.at(i).begin(), execluded_from_smoothing.at(i).begin(), execluded_from_smoothing.at(i).end());

	///***   Smoothing From Car Heading Section ***///
//	if(bHeadingSmooth)
//	{
//		for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
//		{
//			unsigned int cut_index = GetClosestNextPointIndex(rollInPaths.at(i), RollOutStratPath.at(RollOutStratPath.size()-1));
//			rollInPaths.at(i).erase(rollInPaths.at(i).begin(), rollInPaths.at(i).begin()+cut_index);
//			rollInPaths.at(i).insert(rollInPaths.at(i).begin(), RollOutStratPath.begin(), RollOutStratPath.end());
//		}
//	}
	///***   -------------------------------- ***///

	for(unsigned int i=0; i&lt; rollOutNumber+1 ; i++)
	{
		SmoothPath(rollInPaths.at(i), SmoothDataWeight, SmoothWeight, SmoothTolerance);
	}

	d_limit = 0;
	for(unsigned int j = smoothing_end_index; j &lt; originalCenter.size(); j++)
	  {
		if(j &gt; 0)
			d_limit += distance2points(originalCenter.at(j).pos, originalCenter.at(j-1).pos);

		if(d_limit &gt; max_roll_distance)
			break;

			p = originalCenter.at(j);
			double original_speed = p.v;
		  for(unsigned int i=0; i&lt; rollInPaths.size() ; i++)
		  {
			  double d = end_laterals.at(i);
			  p.pos.x  = originalCenter.at(j).pos.x - d*cos(p.pos.a + M_PI_2);
			  p.pos.y  = originalCenter.at(j).pos.y - d*sin(p.pos.a + M_PI_2);

			  if(i!=centralTrajectoryIndex)
				  p.v = original_speed * LANE_CHANGE_SPEED_FACTOR;
			  else
				  p.v = original_speed ;

			  rollInPaths.at(i).push_back(p);

			  sampledPoints.push_back(p);
		  }
	  }

//	for(unsigned int i=0; i&lt; rollInPaths.size(); i++)
//		CalcAngleAndCost(rollInPaths.at(i));
}

bool PlanningHelpers::FindInList(const std::vector&lt;int&gt;&amp; list,const int&amp; x)
{
	for(unsigned int i = 0 ; i &lt; list.size(); i++)
	{
		if(list.at(i) == x)
			return true;
	}
	return false;
}

void PlanningHelpers::RemoveWithValue(std::vector&lt;int&gt;&amp; list,const int&amp; x)
{
	for(unsigned int i = 0 ; i &lt; list.size(); i++)
	{
		if(list.at(i) == x)
		{
			list.erase(list.begin()+i);
		}
	}
}

std::vector&lt;int&gt; PlanningHelpers::GetUniqueLeftRightIds(const std::vector&lt;WayPoint&gt;&amp; path)
{
	 vector&lt;int&gt; sideLanes;
	for(unsigned int iwp = 0; iwp &lt; path.size(); iwp++)
	 {
		 if(path.at(iwp).LeftLaneId&gt;0)
		 {
			 bool bFound = false;
			 for(unsigned int is = 0 ; is &lt; sideLanes.size(); is++)
			 {
				 if(sideLanes.at(is) == path.at(iwp).LeftLaneId)
				 {
					 bFound = true;
					 break;
				 }
			 }

			 if(!bFound)
				 sideLanes.push_back(path.at(iwp).LeftLaneId);
		 }

		 if(path.at(iwp).RightLaneId&gt;0)
		 {
			 bool bFound = false;
			 for(unsigned int is = 0 ; is &lt; sideLanes.size(); is++)
			 {
				 if(sideLanes.at(is) == path.at(iwp).RightLaneId)
				 {
					 bFound = true;
					 break;
				 }
			 }

			 if(!bFound)
				 sideLanes.push_back(path.at(iwp).RightLaneId);
		 }

		 //RemoveWithValue(sideLanes, path.at(iwp).laneId);
	 }
	return sideLanes;
}

void PlanningHelpers::SmoothSpeedProfiles(vector&lt;WayPoint&gt;&amp; path_in, double weight_data, double weight_smooth, double tolerance	)
{

	if (path_in.size() &lt;= 1)
		return;
	vector&lt;WayPoint&gt; newpath = path_in;

	double change = tolerance;
	double xtemp;
	int nIterations = 0;
	int size = newpath.size();

	while (change &gt;= tolerance)
	{
		change = 0.0;
		for (int i = 1; i &lt; size -1; i++)
		{
			xtemp = newpath[i].v;
			newpath[i].v += weight_data * (path_in[i].v - newpath[i].v);
			newpath[i].v += weight_smooth * (newpath[i - 1].v + newpath[i + 1].v - (2.0 * newpath[i].v));
			change += fabs(xtemp - newpath[i].v);

		}
		nIterations++;
	}

	path_in = newpath;
}

void PlanningHelpers::SmoothCurvatureProfiles(vector&lt;WayPoint&gt;&amp; path_in, double weight_data, double weight_smooth, double tolerance)
{
	if (path_in.size() &lt;= 1)
			return;
	vector&lt;WayPoint&gt; newpath = path_in;

	double change = tolerance;
	double xtemp;
	int nIterations = 0;
	int size = newpath.size();

	while (change &gt;= tolerance)
	{
		change = 0.0;
		for (int i = 1; i &lt; size -1; i++)
		{
			xtemp = newpath[i].cost;
			newpath[i].cost += weight_data * (path_in[i].cost - newpath[i].cost);
			newpath[i].cost += weight_smooth * (newpath[i - 1].cost + newpath[i + 1].cost - (2.0 * newpath[i].cost));
			change += fabs(xtemp - newpath[i].cost);

		}
		nIterations++;
	}
	path_in = newpath;
}

void PlanningHelpers::SmoothWayPointsDirections(vector&lt;WayPoint&gt;&amp; path_in, double weight_data, double weight_smooth, double tolerance	)
{

	if (path_in.size() &lt;= 1)
		return;

	vector&lt;WayPoint&gt; newpath = path_in;

	double change = tolerance;
	double xtemp;
	int nIterations = 0;
	int size = newpath.size();

	while (change &gt;= tolerance)
	{
		change = 0.0;
		for (int i = 1; i &lt; size -1; i++)
		{
			xtemp = newpath[i].pos.a;
			newpath[i].pos.a += weight_data * (path_in[i].pos.a - newpath[i].pos.a);
			newpath[i].pos.a += weight_smooth * (newpath[i - 1].pos.a + newpath[i + 1].pos.a - (2.0 * newpath[i].pos.a));
			change += fabs(xtemp - newpath[i].pos.a);

		}
		nIterations++;
	}
	path_in = newpath;
}

void PlanningHelpers::GenerateRecommendedSpeed(vector&lt;WayPoint&gt;&amp; path, const double&amp; max_speed, const double&amp; speedProfileFactor)
{
	FixPathDensity(path, 0.5);

	CalcAngleAndCostAndCurvatureAnd2D(path);

	SmoothCurvatureProfiles(path, 0.3, 0.49, 0.01);

	for(unsigned int i = 0 ; i &lt; path.size(); i++)
	{
		double k_ratio = path.at(i).cost*10.0;

		if(k_ratio &gt;= 9.5)
			path.at(i).v = max_speed;
		else if(k_ratio &lt;= 8.5)
			path.at(i).v = 1.0*speedProfileFactor;
		else
		{
			k_ratio = k_ratio - 8.5;
			path.at(i).v = (max_speed - 1.0) * k_ratio + 1.0;
			path.at(i).v = path.at(i).v*speedProfileFactor;
		}

		if(path.at(i).v &gt; max_speed)
			path.at(i).v = max_speed;

	}

	//SmoothSpeedProfiles(path, 0.15,0.45, 0.1);
}

WayPoint* PlanningHelpers::BuildPlanningSearchTreeV2(WayPoint* pStart,
		const WayPoint&amp; goalPos,
		const vector&lt;int&gt;&amp; globalPath,
		const double&amp; DistanceLimit,
		const bool&amp; bEnableLaneChange,
		vector&lt;WayPoint*&gt;&amp; all_cells_to_delete)
{
	if(!pStart) return NULL;

	vector&lt;pair&lt;WayPoint*, WayPoint*&gt; &gt;nextLeafToTrace;

	WayPoint* pZero = 0;
	WayPoint* wp    = new WayPoint();
	*wp = *pStart;
	nextLeafToTrace.push_back(make_pair(pZero, wp));
	all_cells_to_delete.push_back(wp);

	double 		distance 		= 0;
	WayPoint* 	pGoalCell 		= 0;
	double 		nCounter 		= 0;


	while(nextLeafToTrace.size()&gt;0)
	{
		nCounter++;

		unsigned int min_cost_index = 0;
		double min_cost = 99999999999;

		for(unsigned int i=0; i &lt; nextLeafToTrace.size(); i++)
		{
			if(nextLeafToTrace.at(i).second-&gt;cost &lt; min_cost)
			{
				min_cost = nextLeafToTrace.at(i).second-&gt;cost;
				min_cost_index = i;
			}
		}

		WayPoint* pH 	= nextLeafToTrace.at(min_cost_index).second;

		assert(pH != 0);

		nextLeafToTrace.erase(nextLeafToTrace.begin()+min_cost_index);

		double distance_to_goal = distance2points(pH-&gt;pos, goalPos.pos);
		double angle_to_goal = UtilityH::AngleBetweenTwoAnglesPositive(UtilityH::FixNegativeAngle(pH-&gt;pos.a), UtilityH::FixNegativeAngle(goalPos.pos.a));
		if( distance_to_goal &lt;= 0.1 &amp;&amp; angle_to_goal &lt; M_PI_4)
		{
			cout &lt;&lt; &quot;Goal Found, LaneID: &quot; &lt;&lt; pH-&gt;laneId &lt;&lt;&quot;, Distance : &quot; &lt;&lt; distance_to_goal &lt;&lt; &quot;, Angle: &quot; &lt;&lt; angle_to_goal*RAD2DEG &lt;&lt; endl;
			pGoalCell = pH;
			break;
		}
		else
		{

			if(pH-&gt;pLeft &amp;&amp; !CheckLaneExits(all_cells_to_delete, pH-&gt;pLeft-&gt;pLane) &amp;&amp; bEnableLaneChange)
			{
				wp = new WayPoint();
				*wp = *pH-&gt;pLeft;
				double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
				distance += d;

				for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
				{
					//if(wp-&gt;actionCost.at(a).first == LEFT_TURN_ACTION)
						d += wp-&gt;actionCost.at(a).second;
				}

				wp-&gt;cost = pH-&gt;cost + d;
				wp-&gt;pRight = pH;
				wp-&gt;pRight = 0;

				nextLeafToTrace.push_back(make_pair(pH, wp));
				all_cells_to_delete.push_back(wp);
			}

			if(pH-&gt;pRight &amp;&amp; !CheckLaneExits(all_cells_to_delete, pH-&gt;pRight-&gt;pLane) &amp;&amp; bEnableLaneChange)
			{
				wp = new WayPoint();
				*wp = *pH-&gt;pRight;
				double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
				distance += d;

				for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
				{
					//if(wp-&gt;actionCost.at(a).first == RIGHT_TURN_ACTION)
						d += wp-&gt;actionCost.at(a).second;
				}

				wp-&gt;cost = pH-&gt;cost + d ;
				wp-&gt;pLeft = pH;
				wp-&gt;pRight = 0;
				nextLeafToTrace.push_back(make_pair(pH, wp));
				all_cells_to_delete.push_back(wp);
			}

			for(unsigned int i =0; i&lt; pH-&gt;pFronts.size(); i++)
			{
				if(CheckLaneIdExits(globalPath, pH-&gt;pLane) &amp;&amp; pH-&gt;pFronts.at(i) &amp;&amp; !CheckNodeExits(all_cells_to_delete, pH-&gt;pFronts.at(i)))
				{
					wp = new WayPoint();
					*wp = *pH-&gt;pFronts.at(i);

					double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
					distance += d;

					for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
					{
						//if(wp-&gt;actionCost.at(a).first == FORWARD_ACTION)
							d += wp-&gt;actionCost.at(a).second;
					}

					wp-&gt;cost = pH-&gt;cost + d;
					wp-&gt;pBacks.push_back(pH);

					nextLeafToTrace.push_back(make_pair(pH, wp));
					all_cells_to_delete.push_back(wp);
				}
			}
		}

		if(distance &gt; DistanceLimit &amp;&amp; globalPath.size()==0)
		{
			//if(!pGoalCell)
			cout &lt;&lt; &quot;Goal Not Found, LaneID: &quot; &lt;&lt; pH-&gt;laneId &lt;&lt;&quot;, Distance : &quot; &lt;&lt; distance &lt;&lt; endl;
			pGoalCell = pH;
			break;
		}

		//pGoalCell = pH;
	}

	while(nextLeafToTrace.size()!=0)
		nextLeafToTrace.pop_back();
	//closed_nodes.clear();

	return pGoalCell;
}

WayPoint* PlanningHelpers::BuildPlanningSearchTreeStraight(WayPoint* pStart,
		const double&amp; DistanceLimit,
		vector&lt;WayPoint*&gt;&amp; all_cells_to_delete)
{
	if(!pStart) return NULL;

	vector&lt;pair&lt;WayPoint*, WayPoint*&gt; &gt;nextLeafToTrace;

	WayPoint* pZero = 0;
	WayPoint* wp    = new WayPoint();
	*wp = *pStart;
	nextLeafToTrace.push_back(make_pair(pZero, wp));
	all_cells_to_delete.push_back(wp);

	double 		distance 		= 0;
	WayPoint* 	pGoalCell 		= 0;
	double 		nCounter 		= 0;

	while(nextLeafToTrace.size()&gt;0)
	{
		nCounter++;

		unsigned int min_cost_index = 0;
		double min_cost = 99999999999;

		for(unsigned int i=0; i &lt; nextLeafToTrace.size(); i++)
		{
			if(nextLeafToTrace.at(i).second-&gt;cost &lt; min_cost)
			{
				min_cost = nextLeafToTrace.at(i).second-&gt;cost;
				min_cost_index = i;
			}
		}

		WayPoint* pH 	= nextLeafToTrace.at(min_cost_index).second;
		assert(pH != 0);

		nextLeafToTrace.erase(nextLeafToTrace.begin()+min_cost_index);

		for(unsigned int i =0; i&lt; pH-&gt;pFronts.size(); i++)
		{
			if(pH-&gt;pFronts.at(i) &amp;&amp; !CheckNodeExits(all_cells_to_delete, pH-&gt;pFronts.at(i)))
			{
				wp = new WayPoint();
				*wp = *pH-&gt;pFronts.at(i);

				double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
				distance += d;

				for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
				{
					//if(wp-&gt;actionCost.at(a).first == FORWARD_ACTION)
						d += wp-&gt;actionCost.at(a).second;
				}

				wp-&gt;cost = pH-&gt;cost + d;
				wp-&gt;pBacks.push_back(pH);
				if(wp-&gt;cost &lt; DistanceLimit)
				{
					nextLeafToTrace.push_back(make_pair(pH, wp));
					all_cells_to_delete.push_back(wp);
				}
				else
					delete wp;
			}
		}

//		if(pH-&gt;pLeft &amp;&amp; !CheckLaneExits(all_cells_to_delete, pH-&gt;pLeft-&gt;pLane))
//		{
//			wp = new WayPoint();
//			*wp = *pH-&gt;pLeft;
//			double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);
//
//			for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
//			{
//				//if(wp-&gt;actionCost.at(a).first == LEFT_TURN_ACTION)
//					d += wp-&gt;actionCost.at(a).second;
//			}
//
//			wp-&gt;cost = pH-&gt;cost + d + LANE_CHANGE_COST;
//			wp-&gt;pRight = pH;
//			wp-&gt;pRight = 0;
//
//			nextLeafToTrace.push_back(make_pair(pH, wp));
//			all_cells_to_delete.push_back(wp);
//		}
//
//		if(pH-&gt;pRight &amp;&amp; !CheckLaneExits(all_cells_to_delete, pH-&gt;pRight-&gt;pLane))
//		{
//			wp = new WayPoint();
//			*wp = *pH-&gt;pRight;
//			double d = hypot(wp-&gt;pos.y - pH-&gt;pos.y, wp-&gt;pos.x - pH-&gt;pos.x);;
//
//			for(unsigned int a = 0; a &lt; wp-&gt;actionCost.size(); a++)
//			{
//				//if(wp-&gt;actionCost.at(a).first == RIGHT_TURN_ACTION)
//					d += wp-&gt;actionCost.at(a).second;
//			}
//
//			wp-&gt;cost = pH-&gt;cost + d + LANE_CHANGE_COST;
//			wp-&gt;pLeft = pH;
//			wp-&gt;pRight = 0;
//			nextLeafToTrace.push_back(make_pair(pH, wp));
//			all_cells_to_delete.push_back(wp);
//		}

		pGoalCell = pH;
	}

	while(nextLeafToTrace.size()!=0)
		nextLeafToTrace.pop_back();

	return pGoalCell;
}

int PlanningHelpers::PredictiveDP(WayPoint* pStart, const double&amp; DistanceLimit,
		vector&lt;WayPoint*&gt;&amp; all_cells_to_delete,vector&lt;WayPoint*&gt;&amp; end_waypoints)
{
	if(!pStart) return 0;

	vector&lt;pair&lt;WayPoint*, WayPoint*&gt; &gt;nextLeafToTrace;

	WayPoint* pZero = 0;
	WayPoint* wp    = new WayPoint();
	*wp = *pStart;
	wp-&gt;pLeft = 0;
	wp-&gt;pRight = 0;
	nextLeafToTrace.push_back(make_pair(pZero, wp));
	all_cells_to_delete.push_back(wp);

	double 		distance 		= 0;
	end_waypoints.clear();
	double 		nCounter 		= 0;

	while(nextLeafToTrace.size()&gt;0)
	{
		nCounter++;

		WayPoint* pH 	= nextLeafToTrace.at(0).second;

		assert(pH != 0);

		nextLeafToTrace.erase(nextLeafToTrace.begin()+0);

		for(unsigned int i =0; i&lt; pH-&gt;pFronts.size(); i++)
		{
			if(pH-&gt;pFronts.at(i) &amp;&amp; !CheckNodeExits(all_cells_to_delete, pH-&gt;pFronts.at(i)))
			{
				if(pH-&gt;cost &lt; DistanceLimit)
				{
					wp = new WayPoint();
					*wp = *pH-&gt;pFronts.at(i);

					double d = distance2points(wp-&gt;pos, pH-&gt;pos);
					distance += d;
					wp-&gt;cost = pH-&gt;cost + d;
					wp-&gt;pBacks.push_back(pH);
					wp-&gt;pLeft = 0;
					wp-&gt;pRight = 0;

					nextLeafToTrace.push_back(make_pair(pH, wp));
					all_cells_to_delete.push_back(wp);
				}
				else
				{
					end_waypoints.push_back(pH);
				}
			}
		}
	}

	while(nextLeafToTrace.size()!=0)
		nextLeafToTrace.pop_back();
	//closed_nodes.clear();

	return end_waypoints.size();
}

bool PlanningHelpers::CheckLaneIdExits(const std::vector&lt;int&gt;&amp; lanes, const Lane* pL)
{
	if(lanes.size()==0) return true;

	for(unsigned int i=0; i&lt; lanes.size(); i++)
	{
		if(lanes.at(i) == pL-&gt;id)
			return true;
	}

	return false;
}

WayPoint* PlanningHelpers::CheckLaneExits(const vector&lt;WayPoint*&gt;&amp; nodes, const Lane* pL)
{
	if(nodes.size()==0) return 0;

	for(unsigned int i=0; i&lt; nodes.size(); i++)
	{
		if(nodes.at(i)-&gt;pLane == pL)
			return nodes.at(i);
	}

	return 0;
}

WayPoint* PlanningHelpers::CheckNodeExits(const vector&lt;WayPoint*&gt;&amp; nodes, const WayPoint* pL)
{
	if(nodes.size()==0) return 0;

	for(unsigned int i=0; i&lt; nodes.size(); i++)
	{
		if(nodes.at(i)-&gt;id == pL-&gt;id)
			return nodes.at(i);
	}

	return 0;
}

WayPoint* PlanningHelpers::CreateLaneHeadCell(Lane* pLane, WayPoint* pLeft, WayPoint* pRight,
		WayPoint* pBack)
{
	if(!pLane) return 0;
	if(pLane-&gt;points.size()==0) return 0;

	WayPoint* c = new WayPoint;
	c-&gt;pLane 		= pLane;
	c-&gt;pos 			= pLane-&gt;points.at(0).pos;
	c-&gt;v			= pLane-&gt;speed;
	c-&gt;laneId  		= pLane-&gt;id;
	c-&gt;pLeft 		= pLeft;
	if(pLeft)
		c-&gt;cost		= pLeft-&gt;cost;

	c-&gt;pRight		= pRight;
	if(pRight)
		c-&gt;cost = pRight-&gt;cost;

	if(pBack)
	{
		pBack-&gt;pFronts.push_back(c);
		c-&gt;pBacks.push_back(pBack);
		c-&gt;cost = pBack-&gt;cost + distance2points(c-&gt;pos, pBack-&gt;pos);

		for(unsigned int i=0; i&lt; c-&gt;pBacks.size(); i++)
		{
				if(c-&gt;pBacks.at(i)-&gt;cost &lt; c-&gt;cost)
					c-&gt;cost = c-&gt;pBacks.at(i)-&gt;cost;
		}
	}
	return c;
}

double PlanningHelpers::GetLanePoints(Lane* l, const WayPoint&amp; prevWayPointIndex,
		const double&amp; minDistance , const double&amp; prevCost, vector&lt;WayPoint&gt;&amp; points)
{
	if(l == NULL || minDistance&lt;=0) return 0;

	int index = 0;
	WayPoint  p1, p2;
	WayPoint idx;

	p2 = p1 = l-&gt;points.at(index);
	p1.pLane = l;
	p1.cost = prevCost;
	p2.cost = p1.cost + distance2points(p1.pos, p2.pos);

	points.push_back(p1);

	for(unsigned int i=index+1; i&lt;l-&gt;points.size(); i++)
	{

		p2 = l-&gt;points.at(i);
		p2.pLane = l;
		p2.cost = p1.cost + distance2points(p1.pos, p2.pos);
		points.push_back(p2);

		if(p2.cost &gt;= minDistance)
				break;
		p1 = p2;
	}
	return p2.cost;
}

WayPoint* PlanningHelpers::GetMinCostCell(const vector&lt;WayPoint*&gt;&amp; cells, const vector&lt;int&gt;&amp; globalPathIds)
{
	if(cells.size() == 1)
	{
//		for(unsigned int j = 0; j &lt; cells.at(0)-&gt;actionCost.size(); j++)
//			cout &lt;&lt; &quot;Cost (&quot; &lt;&lt; cells.at(0)-&gt;laneId &lt;&lt; &quot;) of going : &quot; &lt;&lt; cells.at(0)-&gt;actionCost.at(j).first &lt;&lt; &quot;, is : &quot; &lt;&lt; cells.at(0)-&gt;actionCost.at(j).second &lt;&lt; endl;
		return cells.at(0);
	}

	WayPoint* pC = cells.at(0); //cost is distance
	for(unsigned int i=1; i &lt; cells.size(); i++)
	{
		bool bFound = false;
		if(globalPathIds.size()==0)
			bFound = true;

		int iLaneID = cells.at(i)-&gt;id;
		for(unsigned int j=0; j &lt; globalPathIds.size(); j++)
		{
			if(globalPathIds.at(j) == iLaneID)
			{
				bFound = true;
				break;
			}
		}

//		for(unsigned int j = 0; j &lt; cells.at(0)-&gt;actionCost.size(); j++)
//			cout &lt;&lt; &quot;Cost (&quot;&lt;&lt; i &lt;&lt;&quot;) of going : &quot; &lt;&lt; cells.at(0)-&gt;actionCost.at(j).first &lt;&lt; &quot;, is : &quot; &lt;&lt; cells.at(0)-&gt;actionCost.at(j).second &lt;&lt; endl;


		if(cells.at(i)-&gt;cost &lt; pC-&gt;cost &amp;&amp; bFound == true)
			pC = cells.at(i);
	}


	return pC;
}

void PlanningHelpers::ExtractPlanAlernatives(const std::vector&lt;WayPoint&gt;&amp; singlePath, std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; allPaths)
{
	allPaths.clear();
	std::vector&lt;WayPoint&gt; path;
	path.push_back(singlePath.at(0));
	double skip_distance = 8;
	double d = 0;
	bool bStartSkip = false;
	for(unsigned int i= 1; i &lt; singlePath.size(); i++)
	{
		if(singlePath.at(i).bDir != FORWARD_DIR &amp;&amp; singlePath.at(i).pLane &amp;&amp; singlePath.at(i).pFronts.size() &gt; 0)
		{

			bStartSkip = true;
			WayPoint start_point = singlePath.at(i-1);

			cout &lt;&lt; &quot;Current Velocity = &quot; &lt;&lt; start_point.v &lt;&lt; endl;

			RelativeInfo start_info;
			PlanningHelpers::GetRelativeInfo(start_point.pLane-&gt;points, start_point, start_info);
			vector&lt;WayPoint*&gt; local_cell_to_delete;
			PlannerHNS::WayPoint* pStart = &amp;start_point.pLane-&gt;points.at(start_info.iFront);
			WayPoint* pLaneCell =  PlanningHelpers::BuildPlanningSearchTreeStraight(pStart, BACKUP_STRAIGHT_PLAN_DISTANCE, local_cell_to_delete);
			if(pLaneCell)
			{
				vector&lt;WayPoint&gt; straight_path;
				vector&lt;vector&lt;WayPoint&gt; &gt; tempCurrentForwardPathss;
				vector&lt;int&gt; globalPathIds;
				PlanningHelpers::TraversePathTreeBackwards(pLaneCell, pStart, globalPathIds, straight_path, tempCurrentForwardPathss);
				if(straight_path.size() &gt; 2)
				{
					straight_path.insert(straight_path.begin(), path.begin(), path.end());
					for(unsigned int ic = 0; ic &lt; straight_path.size(); ic++)
						straight_path.at(ic).laneChangeCost = 1;
					allPaths.push_back(straight_path);
				}
			}
		}

		if(bStartSkip)
		{
			d += hypot(singlePath.at(i).pos.y - singlePath.at(i-1).pos.y, singlePath.at(i).pos.x - singlePath.at(i-1).pos.x);
			if(d &gt; skip_distance)
			{
				d = 0;
				bStartSkip = false;
			}
		}

		if(!bStartSkip)
			path.push_back(singlePath.at(i));
	}

	allPaths.push_back(path);
}

void PlanningHelpers::TraversePathTreeBackwards(WayPoint* pHead, WayPoint* pStartWP,const vector&lt;int&gt;&amp; globalPathIds,
		vector&lt;WayPoint&gt;&amp; localPath, std::vector&lt;std::vector&lt;WayPoint&gt; &gt;&amp; localPaths)
{
	if(pHead != NULL &amp;&amp; pHead != pStartWP)
	{
		if(pHead-&gt;pBacks.size()&gt;0)
		{
			localPaths.push_back(localPath);
			TraversePathTreeBackwards(GetMinCostCell(pHead-&gt;pBacks, globalPathIds),pStartWP, globalPathIds, localPath, localPaths);
			pHead-&gt;bDir = FORWARD_DIR;
			localPath.push_back(*pHead);
		}
		else if(pHead-&gt;pLeft &amp;&amp; pHead-&gt;cost &gt; 0)
		{
			//vector&lt;Vector2D&gt; forward_path;
			//TravesePathTreeForwards(pHead-&gt;pLeft, forward_path, FORWARD_RIGHT);
			//localPaths.push_back(forward_path);
			cout &lt;&lt; &quot;Global Lane Change  Right &quot; &lt;&lt; endl;
			TraversePathTreeBackwards(pHead-&gt;pLeft,pStartWP, globalPathIds, localPath, localPaths);
			pHead-&gt;bDir = FORWARD_RIGHT_DIR;
			localPath.push_back(*pHead);
		}
		else if(pHead-&gt;pRight &amp;&amp; pHead-&gt;cost &gt; 0)
		{
			//vector&lt;Vector2D&gt; forward_path;
			//TravesePathTreeForwards(pHead-&gt;pRight, forward_path, FORWARD_LEFT);
			//localPaths.push_back(forward_path);

			cout &lt;&lt; &quot;Global Lane Change  Left &quot; &lt;&lt; endl;
			TraversePathTreeBackwards(pHead-&gt;pRight,pStartWP, globalPathIds, localPath, localPaths);
			pHead-&gt;bDir = FORWARD_LEFT_DIR;
			localPath.push_back(*pHead);
		}
//		else
//			cout &lt;&lt; &quot;Err: PlannerZ -&gt; NULL Back Pointer &quot; &lt;&lt; pHead;
	}
	else
		assert(pHead);
}

ACTION_TYPE PlanningHelpers::GetBranchingDirection(WayPoint&amp; currWP, WayPoint&amp; nextWP)
{
	ACTION_TYPE t = FORWARD_ACTION;

//	//first Get the average of the next 3 waypoint directions
//	double angle = 0;
//	if(nextWP.pLane-&gt;id == 487)
//		angle = 11;
//
//	int counter = 0;
//	angle = 0;
//
//	for(unsigned int i=0; i &lt; nextWP.pLane-&gt;points.size() &amp;&amp; counter &lt; 10; i++, counter++)
//	{
//		angle += nextWP.pLane-&gt;points.at(i).pos.a;
//	}
//	angle = angle / counter;
//
//	//Get Circular angle for correct subtraction
//	double circle_angle = UtilityH::GetCircularAngle(currWP.pos.a, angle);
//
//	if( currWP.pos.a - circle_angle &gt; (7.5*DEG2RAD))
//	{
//		t = RIGHT_TURN_ACTION;
//		cout &lt;&lt; &quot;Right Lane, Average Angle = &quot; &lt;&lt; angle*RAD2DEG &lt;&lt; &quot;, Circle Angle = &quot; &lt;&lt; circle_angle*RAD2DEG &lt;&lt; &quot;, currAngle = &quot; &lt;&lt; currWP.pos.a*RAD2DEG &lt;&lt; endl;
//	}
//	else if( currWP.pos.a - circle_angle &lt; (-7.5*DEG2RAD))
//	{
//		t = LEFT_TURN_ACTION;
//		cout &lt;&lt; &quot;Left Lane, Average Angle = &quot; &lt;&lt; angle*RAD2DEG &lt;&lt; &quot;, Circle Angle = &quot; &lt;&lt; circle_angle*RAD2DEG &lt;&lt; &quot;, currAngle = &quot; &lt;&lt; currWP.pos.a*RAD2DEG &lt;&lt; endl;
//	}

	return t;
}

void PlanningHelpers::CalcContourPointsForDetectedObjects(const WayPoint&amp; currPose, vector&lt;DetectedObject&gt;&amp; obj_list, const double&amp; filterDistance)
{
	vector&lt;DetectedObject&gt; res_list;
	for(unsigned int i = 0; i &lt; obj_list.size(); i++)
	{
		GPSPoint center = obj_list.at(i).center.pos;
		double distance = distance2points(center, currPose.pos);

		if(distance &lt; filterDistance)
		{
			DetectedObject obj = obj_list.at(i);

			Mat3 rotationMat(center.a);
			Mat3 translationMat(center.x, center.y);
			double w2 = obj.w/2.0;
			double h2 = obj.l/2.0;
			double z = center.z + obj.h/2.0;

			GPSPoint left_bottom(-w2, -h2, z,0);
			GPSPoint right_bottom(w2,-h2, z,0);
			GPSPoint right_top(w2,h2, z,0);
			GPSPoint left_top(-w2,h2, z,0);

			left_bottom 	= rotationMat * left_bottom;
			right_bottom 	= rotationMat * right_bottom;
			right_top 		= rotationMat * right_top;
			left_top 		= rotationMat * left_top;

			left_bottom 	= translationMat * left_bottom;
			right_bottom 	= translationMat * right_bottom;
			right_top 		= translationMat * right_top;
			left_top 		= translationMat * left_top;

			obj.contour.clear();
			obj.contour.push_back(left_bottom);
			obj.contour.push_back(right_bottom);
			obj.contour.push_back(right_top);
			obj.contour.push_back(left_top);

			res_list.push_back(obj);
		}
	}

	obj_list = res_list;
}

double PlanningHelpers::GetVelocityAhead(const std::vector&lt;WayPoint&gt;&amp; path, const WayPoint&amp; pose, const double&amp; distance)
{
	int iStart = GetClosestNextPointIndex(path, pose);

	double d = 0;
	double min_v = 99999;
	for(unsigned int i=iStart; i&lt; path.size(); i++)
	{
		d  += distance2points(path.at(i).pos, pose.pos);

		if(path.at(i).v &lt; min_v)
			min_v = path.at(i).v;

		if(d &gt;= distance)
			return min_v;
	}
	return 0;
}

void PlanningHelpers::WritePathToFile(const string&amp; fileName, const vector&lt;WayPoint&gt;&amp; path)
{
	DataRW  dataFile;
	ostringstream str_header;
	str_header &lt;&lt; &quot;laneID&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;wpID&quot;  &lt;&lt; &quot;,&quot; &quot;x&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;y&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;a&quot;&lt;&lt;&quot;,&quot;&lt;&lt; &quot;cost&quot; &lt;&lt; &quot;,&quot; &lt;&lt; &quot;Speed&quot; &lt;&lt; &quot;,&quot; ;
	vector&lt;string&gt; dataList;
	 for(unsigned int i=0; i&lt;path.size(); i++)
	 {
		 ostringstream strwp;
		 strwp &lt;&lt; path.at(i).laneId &lt;&lt; &quot;,&quot; &lt;&lt; path.at(i).id &lt;&lt;&quot;,&quot;&lt;&lt;path.at(i).pos.x&lt;&lt;&quot;,&quot;&lt;&lt; path.at(i).pos.y
				 &lt;&lt;&quot;,&quot;&lt;&lt; path.at(i).pos.a &lt;&lt; &quot;,&quot; &lt;&lt; path.at(i).cost &lt;&lt; &quot;,&quot; &lt;&lt; path.at(i).v &lt;&lt; &quot;,&quot;;
		 dataList.push_back(strwp.str());
	 }

	 dataFile.WriteLogData(&quot;&quot;, fileName, str_header.str(), dataList);
}

void PlanningHelpers::TestQuadraticSpline (const std::vector&lt;WayPoint&gt;&amp; center_line, std::vector&lt;WayPoint&gt;&amp; path)
{

//  int N = center_line.size();
//  int i;
//	int ibcbeg;
//	int ibcend;
//	int j;
//	int jhi;
//	int k;
//	double t[N];
//	double tval;
//	double y[N];
//	double ybcbeg;
//	double ybcend;
//	double *ypp;
//	double yppval;
//	double ypval;
//	double yval;
//
//  cout &lt;&lt; &quot;\n&quot;;
//  cout &lt;&lt; &quot;TEST24\n&quot;;
//  cout &lt;&lt; &quot;  SPLINE_QUADRATIC_VAL evaluates a\n&quot;;
//  cout &lt;&lt; &quot;    quadratic spline.\n&quot;;
//  cout &lt;&lt; &quot;\n&quot;;
//  cout &lt;&lt; &quot;  Runge''s function, evenly spaced knots.\n&quot;;
//
//  for ( i = 0; i &lt; N; i++ )
//  {
//    t[i] =  center_line.at(i).pos.x;
//    y[i] =  center_line.at(i).pos.y;
//  }
//
//  //
//  //  Try various boundary conditions.
//  //
//    for ( k = 0; k &lt;= 4; k++ )
//    {
//      if ( k == 0 )
//      {
//        ibcbeg = 0;
//        ybcbeg = 0.0;
//
//        ibcend = 0;
//        ybcend = 0.0;
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Boundary condition 0 at both ends:\n&quot;;
//        cout &lt;&lt; &quot;  Spline is quadratic in boundary intervals.\n&quot;;
//      }
//      else if ( k == 1 )
//      {
//        ibcbeg = 1;
//        ybcbeg = t[0];
//
//        ibcend = 1;
//        ybcend = t[N-1] ;
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Boundary condition 1 at both ends:\n&quot;;
//        cout &lt;&lt; &quot;  Y'(left) =  &quot; &lt;&lt; ybcbeg &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Y'(right) = &quot; &lt;&lt; ybcend &lt;&lt; &quot;\n&quot;;
//
//      }
//      else if ( k == 2 )
//      {
//        ibcbeg = 2;
//        ybcbeg = fpprunge ( t[0] );
//
//        ibcend = 2;
//        ybcend = fpprunge ( t[N-1] );
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Boundary condition 2 at both ends:\n&quot;;
//        cout &lt;&lt; &quot;  YP''(left) =  &quot; &lt;&lt; ybcbeg &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  YP''(right) = &quot; &lt;&lt; ybcend &lt;&lt; &quot;\n&quot;;
//      }
//      else if ( k == 3 )
//      {
//        ibcbeg = 2;
//        ybcbeg = 0.0;
//
//        ibcend = 2;
//        ybcend = 0.0;
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  Natural spline:\n&quot;;
//        cout &lt;&lt; &quot;  YP''(left) =  &quot; &lt;&lt; ybcbeg &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  YP''(right) = &quot; &lt;&lt; ybcend &lt;&lt; &quot;\n&quot;;
//      }
//      else if ( k == 4 )
//      {
//        ibcbeg = 3;
//        ibcend = 3;
//
//        cout &lt;&lt; &quot;\n&quot;;
//        cout &lt;&lt; &quot;  \&quot;Not-a-knot\&quot; spline:\n&quot;;
//      }
//
//      ypp = spline_cubic_set ( N, t, y, ibcbeg, ybcbeg, ibcend, ybcend );
//
//      cout &lt;&lt; &quot;\n&quot;;
//      cout &lt;&lt; &quot;  SPLINE''(T), F''(T):\n&quot;;
//      cout &lt;&lt; &quot;\n&quot;;
//      for ( i = 0; i &lt; N; i++ )
//      {
//        cout &lt;&lt; ypp[i] &lt;&lt; &quot;  &quot;
//             &lt;&lt; fpprunge ( t[i] ) &lt;&lt; &quot;\n&quot;;
//      }
//
//      cout &lt;&lt; &quot;\n&quot;;
//      cout &lt;&lt; &quot;  T, SPLINE(T), F(T)\n&quot;;
//      cout &lt;&lt; &quot;\n&quot;;
//
//      for ( i = 0; i &lt;= N; i++ )
//      {
//        if ( i == 0 )
//        {
//          jhi = 1;
//        }
//        else if ( i &lt; N )
//        {
//          jhi = 2;
//        }
//        else
//        {
//          jhi = 2;
//        }
//
//        for ( j = 1; j &lt;= jhi; j++ )
//        {
//          if ( i == 0 )
//          {
//            tval = t[0] - 1.0;
//          }
//          else if ( i &lt; N )
//          {
//            tval = (
//                ( double ) ( jhi - j + 1 ) * t[i-1]
//              + ( double ) (       j - 1 ) * t[i] )
//              / ( double ) ( jhi         );
//          }
//          else
//          {
//            if ( j == 1 )
//            {
//              tval = t[N-1];
//            }
//            else
//            {
//              tval = t[N-1] + 1.0;
//            }
//          }
//
//          yval = spline_cubic_val ( N, t, y, ypp, tval, &amp;ypval, &amp;yppval );
//
//          cout &lt;&lt; tval &lt;&lt; &quot;  &quot;
//               &lt;&lt; yval &lt;&lt; &quot;  &quot;
//               &lt;&lt; frunge ( tval ) &lt;&lt; &quot;\n&quot;;
//        }
//      }
//      delete [] ypp;
//    }
//
//    return;
}

double PlanningHelpers::frunge ( double x )
{
  double fx;

  fx = 1.0 / ( 1.0 + 25.0 * x * x );

  return fx;
}

double PlanningHelpers::fprunge ( double x )
{
  double bot;
  double fx;

  bot = 1.0 + 25.0 * x * x;
  fx = -50.0 * x / ( bot * bot );

  return fx;
}

double PlanningHelpers::fpprunge ( double x )
{
  double bot;
  double fx;

  bot = 1.0 + 25.0 * x * x;
  fx = ( -50.0 + 3750.0 * x * x ) / ( bot * bot * bot );

  return fx;
}


} /* namespace PlannerHNS */
</old_file>
			</file>
		</modified_files>
	</commit>
</Root>
